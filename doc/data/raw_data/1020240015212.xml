<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:28.5128</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0015212</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자기시점 비디오 분석을 위한 시간적 비전 트랜스포머</inventionTitle><inventionTitleEng>TEMPORAL VISION TRANSFORMER FOR EGOCENTRIC VIDEO ANALYSIS</inventionTitleEng><openDate>2025.08.07</openDate><openNumber>10-2025-0119250</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.01.31</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 서울특별시 서울경제진흥원 2023년도 제6회 서울혁신챌린지 결선(IC230014) &quot;실감 인터랙션을 위한 지능형 VR 인터페이스&quot;를 통해 개발된 기술이다. 자기시점 비디오 분석을 위한 시간적 비전 트랜스포머를 동작시키는 방법은, 1인칭 비디오 클립을 복수의 연속 세그먼트로 분할하는 단계와, 복수의 연속 세그먼트 각각을 시간적 비전 트랜스포머에 제공하여 시간적 비전 트랜스포머로 하여금, 해당 세그먼트 내의 각각의 프레임에 대해, 추정된 3차원 손 자세에 관한 손 자세 정보를 생성하게 하는 단계를 포함하되, 시간적 비전 트랜스포머는, 해당 세그먼트의 인코딩된 특징의 시퀀스를 생성하는 트랜스포머 인코더(시퀀스 내의 각각의 인코딩된 특징은 해당 세그먼트 내의 각자의 프레임에 대응함)와, 해당 세그먼트 내의 각각의 프레임에 대해 손 자세 벡터 및 손 형상 벡터를, 인코딩된 특징의 시퀀스에 기반하여 생성하는 신경망 층과, 손 자세 벡터 및 손 형상 벡터를 3차원 손 메쉬의 재구성을 위한 파라미터화된 손 모델의 입력 파라미터로서 사용함으로써, 추정된 손 메쉬 정점의 세트를 생성하는 일반 손 모델 층과, 추정된 손 메쉬 정점의 세트에 기반하여, 그리고 시퀀스에 포함된, 해당 프레임에 대응하는 인코딩된 특징에 또한 기반하여, 손 자세 정보를 생성하는 피드 포워드 신경망을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 자기시점 비디오 분석을 위한 시간적 비전 트랜스포머(temporal vision transformer)를 동작시키는 방법으로서,1인칭 비디오 클립을 복수의 연속 세그먼트로 분할하는 단계와,상기 복수의 연속 세그먼트 각각을 상기 시간적 비전 트랜스포머에 제공하여 상기 시간적 비전 트랜스포머로 하여금, 상기 각각의 세그먼트 내의 각각의 프레임에 대해, 추정된 3차원 손 자세에 관한 손 자세 정보를 생성하게 하는 단계를 포함하되, 상기 시간적 비전 트랜스포머는,상기 각각의 세그먼트의 인코딩된 특징의 시퀀스를 생성하는 트랜스포머 인코더 - 상기 시퀀스 내의 각각의 인코딩된 특징은 상기 각각의 세그먼트 내의 각자의 프레임에 대응함 - 와,상기 각각의 세그먼트 내의 각각의 프레임에 대해 손 자세 벡터 및 손 형상 벡터를, 인코딩된 특징의 상기 시퀀스에 기반하여 생성하는 신경망 층과,상기 손 자세 벡터 및 상기 손 형상 벡터를 3차원 손 메쉬(mesh)의 재구성을 위한 파라미터화된 손 모델(parameterized hand model)의 입력 파라미터로서 사용함으로써, 추정된 손 메쉬 정점(vertex)의 세트를 생성하는 일반 손 모델 층과,추정된 손 메쉬 정점의 상기 세트에 기반하여, 그리고 상기 시퀀스에 포함되고 상기 각각의 프레임에 대응하는 인코딩된 특징에 또한 기반하여, 상기 손 자세 정보를 생성하는 피드 포워드 신경망(feed-forward neural network)을 포함하는,방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 시간적 비전 트랜스포머는 상기 각각의 세그먼트의 프레임별 특징의 시퀀스를 생성하는 합성곱 신경망(convolutional neural network)을 더 포함하고, 상기 트랜스포머 인코더는, 프레임별 특징의 상기 시퀀스에 기반하여, 인코딩된 특징의 상기 시퀀스를 상기 각각의 세그먼트의 시간적 특징의 프레임별 인코딩된 표현의 시퀀스로서 생성하는,방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 합성곱 신경망은 잔차 신경망(residual neural network)인,방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 신경망 층은 전 연결 층(fully-connected layer)인,방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 파라미터화된 손 모델은 MANO(hand Model with Articulated and Non-rigid defOrmations)에 기반하는,방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,추정된 손 메쉬 정점의 상기 세트는 손 정렬형(hand-aligned) 좌표로 된, 손 관절의 추정된 위치의 세트를 포함하는,방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 피드 포워드 신경망은 다층 퍼셉트론(Multi-Layer Perceptron: MLP)인,방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 손 자세 정보는 상기 1인칭 비디오 클립에 포착된 손에 의해 상기 각각의 프레임에서 취해진 2차원 자세의 추정치에 관한 제1 정보 및 상기 1인칭 비디오 클립을 촬영한 카메라에 대한 상기 각각의 프레임에서의 상기 손의 깊이의 추정치에 관한 제2 정보를 포함하고, 상기 시간적 비전 트랜스포머는, 상기 손 자세 정보에 응답하여, 상기 제1 정보를 상기 제2 정보와 조합하여 상기 카메라의 시점으로부터의 3차원 좌표계에서의 상기 추정된 3차원 손 자세의 표현을 생성하는,방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 시간적 비전 트랜스포머는 상기 손에 의해 취해진 액션(action)의 인식에서의 사용을 위한 토큰(token)을 상기 제1 정보에 기반하여, 그리고 상기 시퀀스에 포함되고 상기 각각의 프레임에 대응하는 인코딩된 특징에 또한 기반하여 생성하는 추가적인 신경망 층을 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 프로세서에 의해 실행되는 경우에 상기 프로세서로 하여금 제1항 내지 제9항 중 어느 한 항의 방법을 수행하게 하는 컴퓨터 실행가능 명령어를 포함하는 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>11. 컴퓨팅 장치로서,프로세서와,상기 프로세서에 의해 실행되는 경우에 상기 프로세서로 하여금 자기시점 비디오 분석을 위한 시간적 비전 트랜스포머를 구현하게 하는 명령어가 저장된 메모리를 포함하되, 상기 시간적 비전 트랜스포머는,1인칭 비디오 클립의 복수의 연속 세그먼트 중의 각각의 세그먼트의 인코딩된 특징의 시퀀스를 생성하는 트랜스포머 인코더 - 상기 시퀀스 내의 각각의 인코딩된 특징은 상기 각각의 세그먼트 내의 각자의 프레임에 대응함 - 와,상기 각각의 세그먼트 내의 각각의 프레임에 대해 손 자세 벡터 및 손 형상 벡터를, 인코딩된 특징의 상기 시퀀스에 기반하여 생성하는 신경망 층과,상기 손 자세 벡터 및 상기 손 형상 벡터를 3차원 손 메쉬의 재구성을 위한 파라미터화된 손 모델의 입력 파라미터로서 사용함으로써, 추정된 손 메쉬 정점의 세트를 생성하는 일반 손 모델 층과,추정된 손 메쉬 정점의 상기 세트에 기반하여, 그리고 상기 시퀀스에 포함되고 상기 각각의 프레임에 대응하는 인코딩된 특징에 또한 기반하여, 상기 각각의 세그먼트 내의 각각의 프레임에 대해, 추정된 3차원 손 자세에 관한 손 자세 정보를 생성하는 피드 포워드 신경망을 포함하는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 시간적 비전 트랜스포머는 상기 각각의 세그먼트의 프레임별 특징의 시퀀스를 생성하는 합성곱 신경망을 더 포함하고, 상기 트랜스포머 인코더는, 프레임별 특징의 상기 시퀀스에 기반하여, 인코딩된 특징의 상기 시퀀스를 상기 각각의 세그먼트의 시간적 특징의 프레임별 인코딩된 표현의 시퀀스로서 생성하는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,추정된 손 메쉬 정점의 상기 세트는 손 정렬형 좌표로 된, 손 관절의 추정된 위치의 세트를 포함하는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,상기 손 자세 정보는 상기 1인칭 비디오 클립에 포착된 손에 의해 상기 각각의 프레임에서 취해진 2차원 자세의 추정치에 관한 제1 정보 및 상기 1인칭 비디오 클립을 촬영한 카메라에 대한 상기 각각의 프레임에서의 상기 손의 깊이의 추정치에 관한 제2 정보를 포함하고, 상기 시간적 비전 트랜스포머는, 상기 손 자세 정보에 응답하여, 상기 제1 정보를 상기 제2 정보와 조합하여 상기 카메라의 시점으로부터의 3차원 좌표계에서의 상기 추정된 3차원 손 자세의 표현을 생성하는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 훈련된 시간적 비전 트랜스포머를 제공하는 시스템으로서,훈련 1인칭 비디오 클립의 세트가 저장된 저장 유닛과,훈련 프로세스의 에포크(epoch)를 완료하기 위해 훈련 1인칭 비디오 클립의 상기 세트에 걸쳐 제1항 내지 제9항 중 어느 하나에 기재된 방법의 반복을 수행하는 처리 유닛을 포함하되, 상기 에포크에서의 각각의 훈련 스텝에 대해 상기 세트로부터 선택된 훈련 1인칭 비디오 클립이 상기 1인칭 비디오 클립으로서 주어지고, 상기 처리 유닛은 또한 상기 각각의 훈련 스텝에서 상기 피드 포워드 신경망의 가중치 파라미터를 갱신하고, 상기 가중치 파라미터의 상기 갱신은,상기 손 자세 정보 및 상기 추정된 3차원 손 자세에 관한 정답(ground truth) 정보에 기반하여 손실(loss)을 계산하는 것과,상기 계산된 손실에 기반하여 상기 가중치 파라미터를 갱신하는 것을 포함하는,시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서초구...</address><code>120230752356</code><country>대한민국</country><engName>WHATs LAB Corp.</engName><name>주식회사 왓츠랩</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>BAE, Jihyun</engName><name>배지현</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>SIM, Donghyun</engName><name>심동현</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>SONG, Hyewon</engName><name>송혜원</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>LEE, Miran</engName><name>이미란</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 율곡로 ** (안국동) *층 *호(에스피특허법률사무소)</address><code>920100005485</code><country>대한민국</country><engName>KIM HYUN SEUNG</engName><name>김현승</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.01.31</receiptDate><receiptNumber>1-1-2024-0125640-75</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240015212.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9301e5fd02ecca5429110f02084da9679c5c0c35ded0b69e78757fb0a20a31c365ba645c968dfe5a9538da735a5521634f51b2831a85c5f69a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe8b26345af8682eceab5840f2cf05a35aa1878776f7edf7308cfc1612129a1573d3947ecec3d61da8fdfc7c3b81ef0916f923fd2b2089bd6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>