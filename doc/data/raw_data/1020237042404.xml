<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:36.436</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2018.05.04</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2023-7042404</applicationNumber><claimCount>17</claimCount><examinerName> </examinerName><finalDisposal>등록결정(재심사후)</finalDisposal><inventionTitle>감지된 입 움직임 및/또는 시선을 기반으로 자동화된 어시스턴트 적응</inventionTitle><inventionTitleEng>ADAPTING AUTOMATED ASSISTANT BASED ON DETECTED MOUTH  MOVEMENT AND/OR GAZE</inventionTitleEng><openDate>2023.12.26</openDate><openNumber>10-2023-0173211</openNumber><originalApplicationDate>2018.05.04</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2020-7034907</originalApplicationNumber><originalExaminationRequestDate>2023.12.07</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.12.07</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/19</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020207034907</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 자동화된 어시스턴트를 조정하는 것은, 사용자의 입의 움직임 및/또는 자동화된 어시스턴트의 자동화된 어시스턴트 인터페이스(시각적 및/또는 청각적)를 제공하는 어시스턴트 디바이스를 향하는 사용자의 시선을 검출하는 것에 기초한다. 입 움직임 및/또는 지향된 시선의 검출은 어시스턴트 디바이스에 통합된 카메라와 같은 어시스턴트 디바이스와 관련된 하나 이상의 비전 컴포넌트들로부터의 비전 데이터 처리에 기초할 수 있다. 검출되는 입 움직임은 사용자(상기 움직이는 입의) 가 말하는 움직임을 나타낼 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2019.11.07</internationOpenDate><internationOpenNumber>WO2019212569</internationOpenNumber><internationalApplicationDate>2018.05.04</internationalApplicationDate><internationalApplicationNumber>PCT/US2018/031170</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 한 명 이상의 사용자들과 자동화된 어시스턴트 간의 터치 없는 상호 작용을 용이하게하는 클라이언트 디바이스의 하나 이상의 프로세서들에 의해 구현되는 방법으로서,상기 클라이언트 디바이스의 하나 이상의 카메라들로부터의 출력에 기초한 이미지 프레임들의 스트림을 수신하는 단계;상기 클라이언트 디바이스의 하나 이상의 카메라들을 향한 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 모니터링하기 위해, 상기 클라이언트 디바이스에 국부적으로 저장된 적어도 하나의 훈련된 기계 학습 모델을 사용하여 상기 스트림의 이미지 프레임들을 처리하는 단계; 상기 모니터링에 기초하여, 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 단계 -상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생은 상기 클라이언트 디바이스에 의해 가청 사용자 인터페이스 출력(audible user interface output)이 렌더링되는 동안 검출되고; 그리고 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하기 전에, 상기 클라이언트 디바이스에서 캡처된 오디오 데이터는 상기 자동화된 어시스턴트와 관련된 원격 서버로 전송되지 않고 상기 클라이언트 디바이스에서만 국부적이고 일시적으로 버퍼링됨-; 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여, 상기 클라이언트 디바이스의 사용자 인터페이스 출력의 렌더링을 조정하는 단계 -상기 클라이언트 디바이스의 사용자 인터페이스 출력의 렌더링을 조정하는 단계는, 상기 클라이언트 디바이스에 의해 렌더링되는 상기 가청 사용자 인터페이스 출력의 볼륨을 줄이는 단계, 또는 상기 클라이언트 디바이스에 의해 렌더링된 상기 가청 사용자 인터페이스 출력의 렌더링을 중지하는 단계를 포함함-; 그리고상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여, 상기 일시적으로 버퍼링된 오디오 데이터를 상기 자동화된 어시스턴트와 관련된 원격 서버로 전송하는 단계를 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 클라이언트 디바이스에 의해 오디오 데이터 처리를 조정하는 것은, 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여 수행되는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 사용자의 입의 움직임에 시간적으로 대응하는 오디오 데이터의 음성 활동 검출을 수행하는 단계와;상기 사용자의 입 움직임에 시간적으로 대응하는 오디오 데이터의 음성 활동 검출에 기초하여 음성 활동의 발생을 결정하는 단계와;상기 클라이언트 디바이스에 의해 렌더링되는 가청 사용자 인터페이스 출력의 볼륨을 줄이는 것은, 또한, 음성 활동의 발생을 결정하는 것에 응답하고 그리고 상기 사용자의 입 움직임에 시간적으로 대응하는 오디오 데이터에 대한 상기 음성 활동의 발생을 기초로 하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 사용자의 입의 움직임에 시간적으로 대응하는 오디오 데이터의 음성 활동 검출을 수행하는 단계와; 그리고 상기 사용자의 입 움직임에 시간적으로 대응하는 오디오 데이터의 음성 활동 검출에 기초하여 음성 활동의 발생을 결정하는 단계를 더 포함하고,상기 클라이언트 디바이스에 의해 렌더링된 가청 사용자 인터페이스 출력의 렌더링을 중지하는 것은, 또한, 음성 활동의 발생을 결정하는 것에 응답하고 그리고 상기 사용자의 입 움직임에 시간적으로 대응하는 오디오 데이터에 대한 상기 음성 활동의 발생을 기초로 하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 클라이언트 디바이스의 사용자 인터페이스 출력의 렌더링을 조정하는 것은 인간이 인지할 수 있는 큐(cue)를 렌더링하는 것을 더 포함하고;상기 클라이언트 디바이스에 의해 오디오 데이터 처리를 조정하는 것은, 상기 클라이언트 디바이스에서 로컬 자동 음성 인식을 시작하는 것, 또는 상기 자동화된 어시스턴트와 관련된 원격 서버로 상기 클라이언트 디바이스의 하나 이상의 마이크로폰들을 통해 캡처된 오디오 데이터의 전송을 시작하는 것을 포함하며; 그리고상기 로컬 자동 음성 인식을 시작하는 것 또는 상기 원격 서버로 오디오 데이터의 전송을 시작하는 것은, 또한, 사용자의 시선이 큐의 렌더링 이후에 상기 클라이언트 디바이스의 하나 이상의 카메라들을 향해 계속해서 향하는 것을 검출하는 것에 응답하는 것을 특징으로 하는방법. </claim></claimInfo><claimInfo><claim>6. 제2항에 있어서, 상기 클라이언트 디바이스에 의해 오디오 데이터 처리를 조정하는 것은, 상기 클라이언트 디바이스에서 로컬 자동 음성 인식을 시작하는 것을 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>7. 제2항에 있어서,상기 클라이언트 디바이스에 의해 오디오 데이터 처리를 조정하는 것은, 상기 자동화된 어시스턴트와 관련된 원격 서버로 상기 클라이언트 디바이스의 하나 이상의 마이크로폰들을 통해 캡처된 오디오 데이터의 전송을 시작하는 것을 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 사용자의 입의 움직임에 시간적으로 대응하는 특정 오디오 데이터의 음성 활동 분석을 수행하는 단계 - 상기 특정 오디오 데이터는 상기 오디오 데이터에 포함되거나 오디오 데이터에 선행하며 - 와; 그리고 상기 사용자의 입 움직임에 시간적으로 대응하는 상기 특정 오디오 데이터의 음성 활동 분석에 기초하여 음성 활동의 발생을 결정하는 단계를 포함하며,상기 오디오 데이터의 전송을 시작하는 것은, 또한, 음성 활동의 발생을 결정하는 것에 응답하고 그리고 상기 사용자의 입 움직임에 시간적으로 대응하는 오디오 데이터에 대한 상기 음성 활동의 발생을 기초로 하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>9. 제2항에 있어서, 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여 상기 클라이언트 디바이스에 의해 오디오 데이터 처리를 조정하는 것은,하나 이상의 이미지 프레임들에 기초하여 상기 클라이언트 디바이스에 대한 상기 사용자의 위치를 결정하는 단계와; 그리고상기 클라이언트 디바이스의 하나 이상의 마이크로폰들을 통해 캡처된 오디오 데이터를 처리할 때 상기 사용자의 위치를 사용하는 단계를 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 클라이언트 디바이스의 하나 이상의 마이크로폰들을 통해 캡처된 오디오 데이터를 처리할 때 상기 사용자의 위치를 사용하는 단계는, 상기 사용자의 음성 발화에 대응하는 상기 오디오 데이터의 부분들을 분리하는 위치를 사용하는 단계를 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서, 상기 클라이언트 디바이스의 하나 이상의 마이크로폰들을 통해 캡처된 오디오 데이터를 처리할 때 상기 사용자의 위치를 사용하는 단계는, 상기 오디오 데이터로부터 배경 소음을 제거하는 위치를 사용하는 단계를 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 모니터링하기 위해, 상기 클라이언트 디바이스에 국부적으로 저장된 적어도 하나의 훈련된 기계 학습 모델을 사용하여 상기 스트림의 이미지 프레임들을 처리하는 단계는;상기 사용자의 시선 발생을 모니터링하기 위해 제1 훈련된 기계 학습 모델을 사용하는 단계와; 그리고상기 사용자의 입의 움직임을 모니터링하기 위해 제2 훈련된 기계 학습 모델을 사용하는 단계를 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,존재 센서로부터의 신호에 기초하여, 인간이 상기 클라이언트 디바이스의 환경에 존재한다는 것을 검출하는 단계와; 그리고상기 인간이 상기 클라이언트 디바이스의 환경에 존재한다는 것을 검출하는 것에 응답하여 상기 하나 이상의 카메라들이 상기 이미지 프레임들의 스트림을 제공하도록 하는 단계를 더 포함하는 것을 특징으로 하는방법.</claim></claimInfo><claimInfo><claim>14. 클라이언트 디바이스로서,적어도 하나의 비전 컴포넌트와;적어도 하나의 마이크로폰과;하나 이상의 프로세서들과; 그리고상기 하나 이상의 프로세서들과 작동 가능하게 결합된 메모리를 포함하고,상기 메모리는, 상기 하나 이상의 프로세서들에 의한 명령어들의 실행에 응답하여 상기 하나 이상의 프로세서들이 동작들을 수행하도록 하는 명령어들을 저장하고,상기 동작들은:상기 클라이언트 디바이스의 비전 컴포넌트로부터의 출력에 기초한 비전 데이터의 스트림을 수신하는 동작;상기 클라이언트 디바이스의 비전 컴포넌트를 향한 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 모니터링하기 위해, 상기 클라이언트 디바이스에 국부적으로 저장된 적어도 하나의 훈련된 기계 학습 모델을 사용하여 상기 스트림의 비전 데이터를 처리하는 동작; 상기 모니터링에 기초하여, 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 동작 -상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생은 상기 클라이언트 디바이스에 의해 가청 사용자 인터페이스 출력(audible user interface output)이 렌더링되는 동안 검출되고; 그리고 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하기 전에, 상기 클라이언트 디바이스에서 캡처된 오디오 데이터는 자동화된 어시스턴트와 관련된 원격 서버로 전송되지 않고 상기 클라이언트 디바이스에서만 국부적이고 일시적으로 버퍼링됨-; 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여, 상기 클라이언트 디바이스의 사용자 인터페이스 출력의 렌더링을 조정하는 동작 -상기 클라이언트 디바이스의 사용자 인터페이스 출력의 렌더링을 조정하는 동작은, 상기 클라이언트 디바이스에 의해 렌더링되는 상기 가청 사용자 인터페이스 출력의 볼륨을 줄이는 동작, 또는  상기 클라이언트 디바이스에 의해 렌더링된 상기 가청 사용자 인터페이스 출력의 렌더링을 중지하는 동작을 포함함-; 그리고상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여, 상기 일시적으로 버퍼링된 오디오 데이터를 상기 자동화된 어시스턴트와 관련된 원격 서버로 전송하는 동작을 포함하는 것을 특징으로 하는클라이언트 디바이스.</claim></claimInfo><claimInfo><claim>15. 시스템으로서,적어도 하나의 비전 컴포넌트와;하나 이상의 마이크로폰들과; 그리고상기 비전 컴포넌트의 출력을 기반으로 하는 비전 데이터의 스트림을 수신하는 하나 이상의 프로세서들을 포함하며,상기 하나 이상의 프로세서들은:     상기 비전 컴포넌트를 향한 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 모니터링하기 위해, 적어도 하나의 훈련된 기계 학습 모델을 사용하여 상기 스트림의 이미지 프레임들을 처리하고;      상기 모니터링에 기초하여, 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하고 -상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생은 클라이언트 디바이스에 의해 가청 사용자 인터페이스 출력(audible user interface output)이 렌더링되는 동안 검출되고; 그리고 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하기 전에, 상기 클라이언트 디바이스에서 캡처된 오디오 데이터는 자동화된 어시스턴트와 관련된 원격 서버로 전송되지 않고 상기 클라이언트 디바이스에서만 국부적이고 일시적으로 버퍼링됨-;      상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여, 상기 클라이언트 디바이스의 사용자 인터페이스 출력의 렌더링을 조정하고 -상기 클라이언트 디바이스의 사용자 인터페이스 출력의 렌더링을 조정하는 것은, 상기 클라이언트 디바이스에 의해 렌더링되는 상기 가청 사용자 인터페이스 출력의 볼륨을 줄이는 것, 또는 상기 클라이언트 디바이스에 의해 렌더링된 상기 가청 사용자 인터페이스 출력의 렌더링을 중지하는 것을 포함함-; 그리고 상기 사용자의 시선 및 상기 사용자의 입의 움직임 모두의 발생을 검출하는 것에 응답하여, 상기 일시적으로 버퍼링된 오디오 데이터를 상기 자동화된 어시스턴트와 관련된 원격 서버로 전송하도록 구성되는 것을 특징으로 하는시스템.</claim></claimInfo><claimInfo><claim>16. 하나 이상의 프로세서들에 의해 실행될 때, 하나 이상의 프로세서들로 하여금 제1항 내지 제13항 중 어느 한 항의 방법을 수행하도록 하는 명령어들을 포함하는 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제13항 중 어느 한 항의 방법을 수행하기 위한 하나 이상의 프로세서들을 포함하는 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>MIXTER, Kenneth</engName><name>믹스터 케네스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>YUAN, Yuan</engName><name>유안 유안</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>NGUYEN, Tuan</engName><name>은구옌 투안</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2023.12.07</receiptDate><receiptNumber>1-1-2023-1373104-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2024.06.27</receiptDate><receiptNumber>9-5-2024-0539669-88</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-1-2024-0777006-18</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-1-2024-0777005-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Decision to Refuse a Patent</documentEngName><documentName>거절결정서</documentName><receiptDate>2025.01.24</receiptDate><receiptNumber>9-5-2025-0092781-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인 (Acceptance of amendment) </commonCodeName><documentEngName>Amendment to Description, etc(Reexamination)</documentEngName><documentName>[명세서등 보정]보정서(재심사)</documentName><receiptDate>2025.04.14</receiptDate><receiptNumber>1-1-2025-0418757-36</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.04.14</receiptDate><receiptNumber>1-1-2025-0418756-91</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Decision to Grant Registration</documentEngName><documentName>등록결정서</documentName><receiptDate>2025.10.20</receiptDate><receiptNumber>9-5-2025-1013162-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237042404.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f8c87084f49e1d992181bdd1a40efa666531e1d1c13e44410828c59f88ecf9ac945ba2b0ddfdaf2b595fd78e4d15f0110cd19d684b303ef5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf087b30a0f66fde575e74825338f3cd89b303d70a1b5557551acb9f65d5bcaf5ccb8207726d03a3b3ecaebcb5925b5731c4b569e4ae0a381f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>