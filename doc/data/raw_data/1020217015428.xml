<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:04.54</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.11.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-7015428</applicationNumber><claimCount>29</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>레이더 딥 러닝</inventionTitle><inventionTitleEng>RADAR DEEP LEARNING</inventionTitleEng><openDate>2021.08.05</openDate><openNumber>10-2021-0096607</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.10.31</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2021.05.21</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 13/86</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 13/86</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 7/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 7/295</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 7/41</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 13/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 13/89</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 13/931</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/89</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/931</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/2413</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 레이더 신호들을 분석하기 위해 딥 러닝을 사용하기 위한 기법들이 개시된다. 일 양상에서, 호스트 차량의 온-보드 컴퓨터는, 차량의 레이더 센서로부터 복수의 레이더 프레임들을 수신하고, 복수의 레이더 프레임들의 서브세트에 대해 뉴럴 네트워크를 실행하고, 그리고 복수의 레이더 프레임들의 서브세트에 대한 뉴럴 네트워크의 실행에 기초하여 복수의 레이더 프레임들의 서브세트에서 하나 이상의 오브젝트들을 검출한다. 추가로, 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하기 위한 기법들이 개시된다. 일 양상에서, 뉴럴 네트워크는 극 좌표 공간에서 복수의 레이더 프레임들을 수신하고, 뉴럴 네트워크의 극-데카르트 변환 계층은 복수의 레이더 프레임들을 데카르트 좌표 공간으로 변환하고, 뉴럴 네트워크는 데카르트 좌표 공간에서 복수의 레이더 프레임들을 출력한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2020.06.04</internationOpenDate><internationOpenNumber>WO2020113160</internationOpenNumber><internationalApplicationDate>2019.11.29</internationalApplicationDate><internationalApplicationNumber>PCT/US2019/063849</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법으로서,상기 호스트 차량의 레이더 센서로부터 복수의 레이더 프레임들을 수신하는 단계;상기 복수의 레이더 프레임들의 적어도 서브세트에 대해 뉴럴 네트워크를 실행하는 단계; 및상기 복수의 레이더 프레임들의 서브세트에 대한 상기 뉴럴 네트워크의 실행에 기초하여 상기 복수의 레이더 프레임들의 서브세트에서 하나 이상의 오브젝트들을 검출하는 단계를 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 뉴럴 네트워크는 반복적 뉴럴 네트워크를 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,상기 반복적 뉴럴 네트워크의 실행에 기초하여 상기 하나 이상의 오브젝트들을 검출하는 단계는 상기 반복적 뉴럴 네트워크의 실행 동안 생성된 피처 맵들에 단일 컨볼루셔널(convolutional) LSTM(long short-term memory) 모듈을 적용하는 것에 기초하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,상기 뉴럴 네트워크의 실행은 상기 복수의 레이더 프레임들의 서브세트 내의 상이한 위치들에 상이한 컨볼루션 가중치들을 적용하기 위해 로컬 공간 컨볼루션의 적용을 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,상기 뉴럴 네트워크의 실행은 상이한 공간 변형 커널들에 대한 모든 가중치들을 생성하는 얕은 뉴럴 네트워크를 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,상기 뉴럴 네트워크의 실행은 상기 뉴럴 네트워크의 각각의 가중치에 대한 명시적 변환의 사용을 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 뉴럴 네트워크의 실행은 오버랩하는 바운딩 박스(bounding box)들을 억제하기 위해 비-최대 억제(non-maximum suppression)를 사용하는 것을 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 오버랩하는 바운딩 박스들에 기초하여 상기 하나 이상의 오브젝트들을 검출하는 불확실성을 추정하는 단계를 더 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,상기 복수의 레이더 프레임들의 서브세트는 상기 복수의 레이더 프레임들의 키 프레임들만을 포함하고, 그리고상기 키 프레임들 사이의 상기 복수의 레이더 프레임들의 레이더 프레임들은 예측된 프레임들(p-프레임들)을 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,이상 검출 뉴럴 네트워크는 상기 복수의 레이더 프레임들의 p-프레임에서 오브젝트의 초기 검출에 기초하여 키 프레임의 경계를 리셋할 시기를 식별하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1 항에 있어서,상기 뉴럴 네트워크의 실행은,범위-방위각 슬라이스, 범위-도플러 슬라이스 및 방위각-도플러 슬라이스를 포함하는 슬라이스들의 세트 각각에 대해 상기 뉴럴 네트워크의 별개의 피처 추출 계층들을 사용하는 것; 및프로세싱된 슬라이스들의 세트를 범위, 방위각 및 도플러에 대한 파라미터들을 포함하는 3차원 슬라이스로 융합하는 것을 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1 항에 있어서,상기 뉴럴 네트워크의 실행은,상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임에 대한 피처 맵을 생성하기 위해 상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임에 대해 피처 추출을 수행하는 것 — 상기 피처 맵은 에고 좌표(ego coordinates)에 있음 — ;상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임 사이의 에고 모션(ego motion)을 획득하는 것;상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임의 에고 좌표를 세계 좌표(world coordinates)로 변환하는 것; 및상기 복수의 레이더 프레임들의 서브세트의 피처 맵들을 결합하는 것을 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1 항에 있어서,상기 뉴럴 네트워크는 LiDAR(Light Detection And Ranging) 데이터 및/또는 카메라 데이터를 갖는 상기 복수의 레이더 프레임들의 서브세트에 기초한 주석들을 사용하여 훈련되는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>14. 제1 항에 있어서,상기 복수의 레이더 프레임들의 서브세트에 대해 상기 뉴럴 네트워크를 실행하기 이전에 상기 복수의 레이더 프레임들을 정규화하는 단계를 더 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,상기 정규화하는 단계는,상기 복수의 레이더 프레임들의 각각의 범위에서 상기 복수의 레이더 프레임들의 각각의 레이더 프레임의 평균 및 표준 편차를 계산하는 단계;상기 계산의 결과에 함수를 맞추는 단계; 및범위 차원을 따라 상기 복수의 레이더 프레임들을 정규화하기 위해 상기 함수를 사용하는 단계를 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>16. 제1 항에 있어서,LiDAR 데이터는 상기 복수의 레이더 프레임들의 서브세트에 대해 상기 뉴럴 네트워크를 실행하기 이전에 원시 레이더 데이트와 단일 입력 텐서로 연접되는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1 항에 있어서,레이더 데이터가 상기 뉴럴 네트워크의 제1 브랜치(branch)에 의해 프로세싱되고, LiDAR 데이터가 상기 뉴럴 네트워크의 제2 브랜치에 의해 프로세싱되고, 두 브랜치들의 피처들이 동일한 좌표 공간으로 변환되고 연접되며, 상기 하나 이상의 오브젝트들이 상기 두 브랜치들의 피처들에 기초하여 검출되는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 레이더 신호들을 분석하기 위해 딥 러닝을 사용하는 방법.</claim></claimInfo><claimInfo><claim>18. 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법으로서,극 좌표 공간에서 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 수신하는 단계;상기 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 극 좌표 공간으로부터 데카르트 좌표 공간으로 변환하는 단계; 및상기 데카르트 좌표 공간에서 상기 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 출력하는 단계를 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법.</claim></claimInfo><claimInfo><claim>19. 제18 항에 있어서,극-데카르트(polar-to-Cartesian) 변환 계층은 가장 가까운 이웃 맵핑, 이중 선형 보간 또는 이중 입방 보간을 사용하여 상기 변환을 수행하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법.</claim></claimInfo><claimInfo><claim>20. 제18 항에 있어서,극-데카르트 변환 계층은 상기 변환 동안 상기 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 크로핑(crop)하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법.</claim></claimInfo><claimInfo><claim>21. 제18 항에 있어서,상기 뉴럴 네트워크의 극-데카르트 변환 계층은 상기 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 상기 극 좌표 공간으로부터 상기 데카르트 좌표 공간으로 변환하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법.</claim></claimInfo><claimInfo><claim>22. 제18 항에 있어서,상기 데카르트 좌표 공간에서 출력된 상기 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들에서 하나 이상의 오브젝트들을 검출하는 단계를 더 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법.</claim></claimInfo><claimInfo><claim>23. 제22 항에 있어서,상기 하나 이상의 오브젝트들을 검출하는 것에 기초하여 자율 주행 동작을 수행하는 단계를 더 포함하는, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법.</claim></claimInfo><claimInfo><claim>24. 제23 항에 있어서,상기 자율 주행 동작은 제동, 가속, 스티어링(steering), 크루즈 제어 세팅 조정 또는 시그널링 중 하나 이상인, 호스트 차량의 온-보드 컴퓨터에 의해 수행되는 뉴럴 네트워크에서 극 좌표를 데카르트 좌표로 변환하는 방법.</claim></claimInfo><claimInfo><claim>25. 호스트 차량의 온-보드 컴퓨터로서,적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는, 상기 호스트 차량의 레이더 센서로부터 복수의 레이더 프레임들을 수신하고; 상기 복수의 레이더 프레임들의 적어도 서브세트에 대해 뉴럴 네트워크를 실행하고; 그리고 상기 복수의 레이더 프레임들의 서브세트에 대한 상기 뉴럴 네트워크의 실행에 기초하여 상기 복수의 레이더 프레임들의 서브세트에서 하나 이상의 오브젝트들을 검출하도록 구성되는, 호스트 차량의 온-보드 컴퓨터.</claim></claimInfo><claimInfo><claim>26. 제25 항에 있어서,상기 복수의 레이더 프레임들의 서브세트는 상기 복수의 레이더 프레임들의 키 프레임들만을 포함하고, 그리고상기 키 프레임들 사이의 상기 복수의 레이더 프레임들의 레이더 프레임들은 예측된 프레임들(p-프레임들)을 포함하는, 호스트 차량의 온-보드 컴퓨터.</claim></claimInfo><claimInfo><claim>27. 제26 항에 있어서,이상 검출 뉴럴 네트워크는 상기 복수의 레이더 프레임들의 p-프레임에서 오브젝트의 초기 검출에 기초하여 키 프레임의 경계를 리셋할 시기를 식별하는, 호스트 차량의 온-보드 컴퓨터.</claim></claimInfo><claimInfo><claim>28. 제25 항에 있어서,상기 뉴럴 네트워크를 실행하도록 구성되는 상기 적어도 하나의 프로세서는, 범위-방위각 슬라이스, 범위-도플러 슬라이스 및 방위각-도플러 슬라이스를 포함하는 슬라이스들의 세트 각각에 대해 상기 뉴럴 네트워크의 별개의 피처 추출 계층들을 사용하고; 그리고 프로세싱된 슬라이스들의 세트를 범위, 방위각 및 도플러에 대한 파라미터들을 포함하는 3차원 슬라이스로 융합하도록 구성되는 적어도 하나의 프로세서를 포함하는, 호스트 차량의 온-보드 컴퓨터.</claim></claimInfo><claimInfo><claim>29. 제25 항에 있어서,상기 뉴럴 네트워크를 실행하도록 구성되는 상기 적어도 하나의 프로세서는, 상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임에 대한 피처 맵을 생성하기 위해 상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임에 대해 피처 추출을 수행하고 — 상기 피처 맵은 에고 좌표에 있음 — ; 상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임 사이의 에고 모션을 획득하고; 상기 복수의 레이더 프레임들의 서브세트의 각각의 레이더 프레임의 에고 좌표를 세계 좌표로 변환하고; 그리고 상기 복수의 레이더 프레임들의 서브세트의 피처 맵들을 결합하도록 구성되는 적어도 하나의 프로세서를 포함하는, 호스트 차량의 온-보드 컴퓨터.</claim></claimInfo><claimInfo><claim>30. 호스트 차량의 온-보드 컴퓨터로서,적어도 하나의 프로세서를 포함하며,상기 적어도 하나의 프로세서는, 극 좌표 공간에서 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 수신하고; 상기 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 극 좌표 공간으로부터 데카르트 좌표 공간으로 변환하고; 그리고 상기 데카르트 좌표 공간에서 상기 복수의 레이더 프레임들 또는 상기 복수의 레이더 프레임들의 하나 이상의 잠재 표현들을 출력하도록 구성되는, 호스트 차량의 온-보드 컴퓨터.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980798710</code><country>미국</country><engName>QUALCOMM INCORPORATED</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>FONTIJNE, Daniel Hendricus Franciscus</engName><name>폰틴, 다니엘 헨드리쿠스 프란치스코</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>ANSARI, Amin</engName><name>안사리, 아민</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>MAJOR, Bence</engName><name>메이저, 벤스</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>SUKHAVASI, Ravi Teja</engName><name>수카바시, 라비 테자</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>GOWAIKAR, Radhika Dilip</engName><name>고와이카, 라디카 딜립</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>WU, Xinzhou</engName><name>우, 신조우</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>SUBRAMANIAN, Sundar</engName><name>수브라마니안, 선다</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포...</address><code> </code><country> </country><engName>HAMILTON, Michael John</engName><name>해밀턴, 마이클 존</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 서소문로**(서소문동, 정안빌딩*층)</address><code>920121001826</code><country>대한민국</country><engName>NAM &amp; NAM</engName><name>특허법인 남앤남</name></agentInfo><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2018.11.30</priorityApplicationDate><priorityApplicationNumber>62/774,018</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.11.27</priorityApplicationDate><priorityApplicationNumber>16/698,870</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2021.05.21</receiptDate><receiptNumber>1-1-2021-0587555-91</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2021.07.05</receiptDate><receiptNumber>1-5-2021-0106891-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.10.31</receiptDate><receiptNumber>1-1-2022-1151474-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.03.22</receiptDate><receiptNumber>1-1-2024-0326927-87</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.11.18</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2024.12.11</receiptDate><receiptNumber>9-6-2025-0031193-90</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.04.08</receiptDate><receiptNumber>9-5-2025-0346711-72</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.05.26</receiptDate><receiptNumber>1-1-2025-0587768-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.05.26</receiptDate><receiptNumber>1-1-2025-0587767-12</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020217015428.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9354067d7a4f0a9cf4832894e52958e65322fde10ee961d7ea0716ab05760348b00ae3e20a65a7b5362981b5c7ae98bc4a2f5d556b75b45204</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe1f0d43739e601fc09e922a37c307f90e3ad72ca3fd899684dc5f0464a371af95991eedbd7854bd733bce1f62fc57d41c7560497f4f7e92b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>