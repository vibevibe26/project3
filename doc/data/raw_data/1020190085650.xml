<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:35.4135</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.07.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2019-0085650</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR DETERMINING TARGET OBJECT IN  IMAGE BASED ON INTERACTIVE INPUT</inventionTitleEng><openDate>2020.06.24</openDate><openNumber>10-2020-0073967</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.07.13</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/426</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 인터랙티브(interactive) 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법 및 장치가 개시된다. 목표 오브젝트를 결정하는 방법은, 이미지에 대응하는 제1 특징 정보 및 인터랙티브 입력에 대응하는 제2 특징 정보를 획득하고, 제1 특징 정보 및 제2 특징 정보에 따라, 이미지의 오브젝트 중, 인터랙티브 입력에 대응하는 목표 오브젝트를 결정한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지에 대응하는 제1 특징 정보 및 인터랙티브(interactive) 입력에 대응하는 제2 특징 정보를 획득하는 단계; 및상기 제1 특징 정보 및 상기 제2 특징 정보에 따라, 상기 이미지에 포함된 오브젝트 중에서 상기 인터랙티브 입력에 대응하는 목표 오브젝트를 결정하는 단계를 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 이미지에 대응하는 상기 제1 특징 정보 및 상기 인터랙티브 입력에 대응하는 상기 제2 특징 정보를 획득하는 단계는,상기 이미지에 대응하는 상기 제1 특징 정보를 획득할 때, 상기 이미지에 포함된 각 오브젝트와 상기 이미지에 포함된 적어도 하나의 다른 오브젝트 간의 시맨틱 특징 정보를 획득하는 단계를 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 이미지에 포함된 각 오브젝트와 상기 이미지에 포함된 적어도 하나의 다른 오브젝트 간의 상기 시맨틱 특징 정보를 획득하는 단계는,상기 이미지에 포함된 각 오브젝트의 위치 정보에 기반하여, 상기 이미지에 포함된 각각의 오브젝트와 적어도 하나의 다른 오브젝트 간의 상기 시맨틱 특징 정보를 획득하는 단계를 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 이미지에 포함된 각 오브젝트와 상기 이미지에 포함된 적어도 하나의 다른 오브젝트 간의 상기 시맨틱 특징 정보를 획득하는 단계는,상기 이미지에 포함된 각 오브젝트 및 적어도 하나의 다른 오브젝트에 기반하여 적어도 하나의 후보 영역을 결정하는 단계;상기 후보 영역 내의 오브젝트의 분류 특징 정보를 획득하는 단계;상기 후보 영역 내의 오브젝트들 간의 영역 시맨틱 특징 정보를 획득하는 단계; 및상기 분류 특징 정보와 상기 영역 시맨틱 특징 정보에 기반하여 상기 이미지에 포함된 각 오브젝트와 적어도 하나의 다른 오브젝트 간의 상기 시맨틱 특징 정보를 생성하는 단계를 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 이미지에 포함된 각 오브젝트와 적어도 하나의 다른 오브젝트 간의 상기 시맨틱 특징 정보를 생성하는 단계 이전에, 상기 분류 특징 정보와 상기 영역 시맨틱 특징 정보에 기반하여, 상기 분류 특징 정보 및 상기 영역 시맨틱 특징 정보에 대해서 조인트 변경（joint correction）을 수행하는 단계를 더 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>6. 제4항에 있어서, 상기 이미지에 포함된 각 오브젝트와 적어도 하나의 다른 오브젝트 간의 상기 시맨틱 특징 정보를 생성하는 단계 이전에, 상기 후보 영역에 따라 기준 영역을 결정하는 단계;상기 기준 영역의 영역 특징 정보를 획득하는 단계; 및상기 분류 특징 정보, 상기 영역 시맨틱 특징 정보 및 상기 영역 특징 정보에 기반하여, 상기 분류 특징 정보, 상기 영역 시맨틱 특징 정보 및 상기 영역 특징 정보에 대해서 조인트 변경을 수행하는 단계를 더 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>7. 제4항에 있어서, 상기 후보 영역은,상기 이미지에 포함된 오브젝트 중 한 개와 상기 이미지에 포함된 적어도 하나의 다른 오브젝트 중 한 개를 포함하는인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 제1 특징 정보는,상기 이미지에 대응하는 글로벌 시각 특징 정보,상기 이미지에 포함된 각 오브젝트에 각각 대응하는 시각 특징 정보,상기 이미지에 포함된 오브젝트들 간의 상대적 위치 정보,상기 이미지에 포함된 오브젝트들 간의 상대적 사이즈 특징 정보 및상기 이미지에 포함된 오브젝트들 간의 시맨틱 특징 정보중에서 적어도 하나를 포함하는인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 이미지에 포함된 오브젝트 중에서 상기 인터랙티브 입력에 대응하는 목표 오브젝트를 결정하는 단계는,상기 목표 오브젝트를 결정하기 전에, 상기 제1 특징 정보에 융합 처리(fusion processing)를 수행하는 단계를 더 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 샘플 이미지를 포함하는 트레이닝 데이터를 획득하는 단계; 상기 샘플 이미지에 포함된 각 오브젝트와 상기 샘플 이미지에 포함된 적어도 하나의 다른 오브젝트에 기반하여 적어도 하나의 후보 영역을 결정하는 단계;상기 후보 영역에 따라 기준 영역을 결정하고, 상기 기준 영역의 영역 특징 정보를 획득하는 단계;상기 영역 특징 정보에 따라 영역 제목을 생성하는 단계; 및상기 영역 제목을 가지고 감독된 트레이닝 데이터로 이용하여, 이미지에 포함된 오브젝트들 간의 시맨틱 특징 정보를 획득하기 위한 뉴럴 네트워크 모델에 대해 트레이닝을 수행하는 단계를 더 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 이미지에 대응하는 상기 제1 특징 정보 및 상기 인터랙티브 입력에 대응하는 상기 제2 특징 정보를 획득하는 단계는,상기 인터랙티브 입력에 대해 단어 벡터 변환을 수행하는 단계; 및상기 단어 벡터에 기반하여 상기 인터랙티브 입력에 대응하는 상기 제2 특징 정보를 획득하는 단계를 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 이미지에 대응하는 상기 제1 특징 정보 및 상기 인터랙티브 입력에 대응하는 상기 제2 특징 정보를 획득하는 단계는,상기 인터랙티브 입력에 대해 상기 단어 벡터 변환을 수행하는 단계 이전에,상기 인터랙티브 입력의 단어가 설정된 제1 단어에 속하는지 여부를 판단하는 단계를 더 포함하고,상기 인터랙티브 입력에 대해 상기 단어 벡터 변환을 수행하는 단계는,상기 인터랙티브 입력의 단어가 설정된 상기 제1 단어에 속할 경우, 상기 제1 단어의 단어 벡터와 유사성이 높은 제2 단어의 단어 벡터를 상기 제1 단어에 대응하는 단어 벡터로 이용하는 단계를 포함하는인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제1 단어는,사용 빈도수가 제1 설정값 보다 낮은 단어를 나타내고, 상기 제2 단어는,사용 빈도수가 제2 설정값 보다 높은 단어를 나타내는,인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 인터랙티브 입력은,음성 입력 및 텍스트 입력 중에서 적어도 하나를 포함하는, 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 방법. </claim></claimInfo><claimInfo><claim>15. 이미지에 대응하는 제1 특징 정보 및 인터랙티브 입력에 대응하는 제2 특징 정보를 획득하는 특징 획득부; 및상기 제1 특징 정보 및 상기 제2 특징 정보에 따라, 상기 이미지에 포함된 오브젝트 중에서 상기 인터랙티브 입력에 대응하는 목표 오브젝트를 결정하는 목표 결정부를 포함하는 인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 제1 특징 정보는,상기 이미지에 대응하는 글로벌 시각 특징 정보,상기 이미지에 포함된 각 오브젝트에 각각 대응하는 시각 특징 정보,상기 이미지에 포함된 오브젝트들 간의 상대적 위치 정보,상기 이미지에 포함된 오브젝트들 간의 상대적 사이즈 특징 정보 및상기 이미지에 포함된 오브젝트들 간의 시맨틱 특징 정보중에서 적어도 하나를 포함하는인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 특징 획득부는,상기 이미지에 포함된 각 오브젝트 및 적어도 하나의 다른 오브젝트에 기반하여 적어도 하나의 후보 영역을 결정하고,상기 후보 영역 내의 오브젝트의 분류 특징 정보를 획득하고,상기 후보 영역 내의 오브젝트들 간의 영역 시맨틱 특징 정보를 획득하고,상기 후보 영역에 따라 기준 영역을 결정하고,상기 기준 영역의 영역 특징 정보를 획득하고,상기 분류 특징 정보, 상기 영역 시맨틱 특징 정보 및 상기 영역 특징 정보에 기반하여, 상기 분류 특징 정보, 상기 영역 시맨틱 특징 정보 및 상기 영역 특징 정보에 대해서 조인트 변경을 수행하는 단계; 및상기 정정된 분류 특징 정보, 상기 정정된 영역 시맨틱 특징 정보 및 상기 정정된 영역 특징 정보에 기반하여 상기 이미지에 포함된 각 오브젝트와 적어도 하나의 다른 오브젝트 간의 상기 시맨틱 특징 정보를 생성하는인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 장치.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 상기 특징 획득부는,상기 인터랙티브 입력에 대해 단어 벡터 변환을 수행하고,상기 단어 벡터에 기반하여 상기 인터랙티브 입력에 대응하는 상기 제2 특징 정보를 획득하는인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 장치.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서, 상기 특징 획득부는,상기 인터랙티브 입력에 대해 상기 단어 벡터 변환을 수행할 때, 상기 인터랙티브 입력의 단어가 설정된 제1 단어에 속하는지 여부를 판단하고, 상기 인터랙티브 입력의 단어가 설정된 상기 제1 단어에 속할 경우, 상기 제1 단어의 단어 벡터와 유사성이 높은 제2 단어의 단어 벡터를 상기 제1 단어에 대응하는 단어 벡터로 이용하고,상기 제1 단어는,사용 빈도수가 제1 설정값 보다 낮은 단어를 나타내고, 상기 제2 단어는,사용 빈도수가 제2 설정값 보다 높은 단어를 나타내는,인터랙티브 입력에 기반하여 이미지에서 목표 오브젝트를 결정하는 장치.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제14항 중 어느 한 항의 방법을 실행하기 위한 프로그램이 기록되어 있는 것을 특징으로 하는 컴퓨터에서 판독 가능한 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420180786048</code><country>대한민국</country><engName>LEE, Hyong Euk</engName><name>이형욱</name></inventorInfo><inventorInfo><address>중화인민공화국 ****** 베이징 조...</address><code> </code><country> </country><engName>Qiang Wang</engName><name>치앙 왕</name></inventorInfo><inventorInfo><address>중화인민공화국 ****** 베이징 조...</address><code> </code><country> </country><engName>Chao Zhang</engName><name>차오 장</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2018.12.14</priorityApplicationDate><priorityApplicationNumber>201811532287.7</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2019.07.16</receiptDate><receiptNumber>1-1-2019-0726921-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2019.07.18</receiptDate><receiptNumber>9-1-2019-9005854-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.07.13</receiptDate><receiptNumber>1-1-2022-0727767-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2023.07.19</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2023.09.15</receiptDate><receiptNumber>9-6-2023-0174982-92</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.03.20</receiptDate><receiptNumber>9-5-2025-0276057-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.04.25</receiptDate><receiptNumber>1-1-2025-0470491-06</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.25</receiptDate><receiptNumber>1-1-2025-0470492-41</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020190085650.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=2ba38663aa11ff0f6ca91af6061a2e004cdb7ae9e53e3b32b3a9d86c527bd13113d567511ac4ed0264dd6df25a06e8a231b77756fe560474db3f9fa37a6cc317239bed3bf5c5ac31</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf07d3479a01359593739e8371087c7658bbb161fe26b377692f8948ecb450dce5a3b3a827678fa44d89e7e7dded4a4a3f79a4f9d71fd50936</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>