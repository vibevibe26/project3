<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:30.3730</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0186298</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>서로 다른 종류의 카메라들로부터 획득된 이미지를 처리하는 헤드 마운티드 디스플레이 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>HEAD MOUNTED DISPLAY DEVICE FOR PROCESSING IMAGES OBTAINED  BY USING DIFFERENT TYPE OF CAMERAS AND METHOD FOR OPERATING  THE SAME</inventionTitleEng><openDate>2025.04.28</openDate><openNumber>10-2025-0056741</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/156</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/178</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/239</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/271</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/128</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/332</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 서로 다른 시야(Field of View, FOV)를 갖는 서로 다른 종류의 카메라들에 의해 획득된 이미지들의 시야를 확장하는 이미지 처리(image processing)를 수행함으로써, 사용자에게 몰입감(immersiveness)을 제공하는 헤드 마운티드 디스플레이 장치를 제공한다. 본 개시의 일 실시예에 따른 헤드 마운티드 디스플레이 장치는 외부 디바이스로부터 서로 다른 시야를 갖는 복수의 이미지를 획득하고, 복수의 이미지 중 상대적으로 시야가 넓은 제1 이미지에 기초하여 제2 이미지의 시야를 확장하며, 시야가 확장된 제2 이미지 및 제1 이미지를 이용하여 깊이 정보를 포함하는 공간 이미지를 생성하고, 복수의 공간 이미지로 구성된 공간 비디오를 디스플레이할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 서로 다른 종류의 카메라들로부터 획득된 이미지를 처리하는 헤드 마운티드 디스플레이(Head Mounted Display; HMD) 장치(100)에 있어서, 적어도 하나의 명령어들(instructions)를 저장하는 메모리(130); 상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(120); 및디스플레이부(140);를 포함하고, 상기 적어도 하나의 프로세서(120)는, 서로 다른 종류의 복수의 카메라들에 의해 촬영된 서로 다른 시야(Field of View; FOV)를 갖는 복수의 이미지를 획득하고, 상기 복수의 이미지 중 제1 시야를 갖는 제1 이미지의 표시 영역에 기초하여 상기 제1 시야 보다 작은 제2 시야를 갖는 제2 이미지의 표시 영역을 확장함으로써, 상기 제2 이미지의 시야를 확장하고, 상기 제1 이미지 및 상기 시야가 확장된 제2 이미지를 이용하여 깊이 정보를 포함하는 공간 이미지를 생성하고, 상기 공간 이미지를 상기 디스플레이부를 통해 디스플레이하는, 헤드 마운티드 디스플레이 장치(100). </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 복수의 이미지의 메타 데이터(metadata)로부터 상기 복수의 이미지 각각의 시야(FOV)에 관한 정보를 획득하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>3. 제1 항 및 제2 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 제1 이미지의 표시 영역 중 상기 제2 이미지와 중복되는 공통 영역을 제외한 주변 영역을 상기 제2 이미지와 병합(merge)하여, 상기 제2 이미지의 표시 영역을 확장하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>4. 제1 항 및 제2 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 제1 이미지의 표시 영역 중 상기 제2 이미지와 중복되는 공통 영역을 제외한 주변 영역을 상기 제2 이미지와 합성(composite)하는 이미지 스티칭(image stitching)을 수행하여 상기 제2 이미지의 표시 영역을 확장하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 적어도 하나의 프로세서(120)는, 상기 제1 이미지를 획득하는 제1 카메라와 상기 제2 이미지를 획득하는 제2 카메라의 초점 거리(focal length), 주점(principal point), 및 이미지 센서 포맷 중 적어도 하나를 포함하는 카메라 파라미터 및 상기 제1 카메라와 상기 제2 카메라 간의 회전(rotation) 및 평행 이동(translation)에 관한 상대적 위치 관계를 포함하는 캘리브레이션 데이터(calibration data)에 기초하여 상기 제1 이미지 및 상기 제2 이미지에 관한 이미지 워핑(image warping)을 수행하는, 헤드 마운티드 디스플레이 장치(100). </claim></claimInfo><claimInfo><claim>6. 제1 항 및 제2 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120)는, 인공지능 모델에 상기 제2 이미지를 입력하여 상기 제1 이미지를 가이드 이미지(guide image)로 이용하는 아웃페인팅(outpainting)을 수행함으로써, 상기 제2 이미지의 표시 영역을 확장하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>7. 제1 항 및 제2 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 프로세서(120)는, 상기 제1 이미지의 표시 영역 중 상기 제2 이미지와 중복되는 공통 영역을 제외한 주변 영역을 상기 제2 이미지와 병합(merge)하여 병합 이미지를 획득하고,이미지 하모나이제이션(image harmonization) 알고리즘을 이용하여 상기 병합 이미지 내의 상기 제2 이미지와 상기 주변 영역 간의 경계에 해당되는 픽셀들의 픽셀 값 차이를 조정하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>8. 제1 항 내지 제7 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 제1 이미지를 기준으로 상기 시야가 확장된 제2 이미지를 시차(disparity)만큼 이동(shift)하여 깊이 정보를 제공하는 스테레오 이미지(stereoscopic image)를 획득하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제7 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120)는, 스테레오 이미지 기반 깊이 예측 알고리즘(stereo image-based depth estimation)을 통해 상기 제1 이미지의 표시 영역과 상기 제2 이미지의 표시 영역 간 중복되는 공통 영역에 대한 제1 깊이 값을 예측하고, 단일 이미지 기반 깊이 예측 알고리즘(mono image-based depth estimation)을 통해 상기 시야가 확장된 제2 이미지의 전체 표시 영역 중 상기 공통 영역을 제외한 확장 영역(extended area)에 대한 제2 깊이 값을 예측하고,  상기 공통 영역으로부터 예측된 상기 제1 깊이 값과 상기 확장 영역으로부터 예측된 상기 제2 깊이 값 간의 상관 관계를 나타내는 매핑 함수(mapping function)를 획득하고, 상기 매핑 함수에 기초하여 상기 제2 깊이 값을 변환(transform)함으로써, 상기 공통 영역 및 상기 주변 영역을 포함하는 전체 영역에 대한 깊이 값 정보를 획득하며, 상기 획득된 깊이 값 정보를 이용하여 상기 공간 이미지를 생성하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제7 항 중 어느 하나의 항에 있어서,객체의 깊이 값 정보를 획득하도록 구성되는 깊이 센서(depth sensor);를 더 포함하고, 상기 적어도 하나의 프로세서(120)는, 상기 깊이 센서를 이용하여 상기 제1 이미지와 상기 제2 이미지 간의 중복되는 공통 영역 및 상기 제1 이미지에만 포함되는 주변 영역에 위치하는 객체들의 깊이 값 정보를 획득하고, 상기 획득된 깊이 값 정보를 이용하여 상기 공간 이미지를 생성하는, 헤드 마운티드 디스플레이 장치(100).</claim></claimInfo><claimInfo><claim>11. 헤드 마운티드 디스플레이 장치(100)의 동작 방법에 있어서, 서로 다른 종류의 복수의 카메라들에 의해 촬영된 서로 다른 시야(Field of View; FOV)를 갖는 복수의 이미지를 획득하는 단계(S210); 상기 복수의 이미지 중 제1 시야를 갖는 제1 이미지의 표시 영역에 기초하여 상기 제1 시야 보다 작은 제2 시야를 갖는 제2 이미지의 표시 영역을 확장함으로써, 상기 제2 이미지의 시야를 확장하는 단계(S220); 상기 제1 이미지 및 상기 시야가 확장된 제2 이미지를 이용하여 깊이 정보(depth information)를 포함하는 공간 이미지를 생성하는 단계(S230); 및상기 생성된 공간 이미지를 디스플레이하는 단계(S240);를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 복수의 이미지의 메타 데이터(metadata)로부터 상기 복수의 이미지 각각의 시야(FOV)에 관한 정보를 획득하는 단계;를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>13. 제11 항 및 제12 항 중 어느 하나의 항에 있어서,상기 제2 이미지의 시야를 확장하는 단계(S220)는, 상기 제1 이미지의 표시 영역 중 상기 제2 이미지와 중복되는 공통 영역을 제외한 주변 영역을 상기 제2 이미지와 병합(merge)하여, 상기 제2 이미지의 표시 영역을 확장하는, 방법. </claim></claimInfo><claimInfo><claim>14. 제11 항 및 제12 항 중 어느 하나의 항에 있어서,상기 제2 이미지의 시야를 확장하는 단계(S220)는, 상기 제1 이미지의 표시 영역 중 상기 제2 이미지와 중복되는 공통 영역을 제외한 주변 영역을 상기 제2 이미지와 합성(composite)하는 이미지 스티칭(image stitching)을 수행하여 상기 제2 이미지의 표시 영역을 확장하는, 방법. </claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서, 상기 제2 이미지의 시야를 확장하는 단계(S220)는, 상기 제1 이미지를 획득하는 제1 카메라와 상기 제2 이미지를 획득하는 제2 카메라의 초점 거리(focal length), 주점(principal point), 및 이미지 센서 포맷 중 적어도 하나를 포함하는 카메라 파라미터 및 상기 제1 카메라와 상기 제2 카메라 간의 회전(rotation) 및 평행 이동(translation)에 관한 상대적 위치 관계를 포함하는 캘리브레이션 데이터(calibration data)에 기초하여 상기 제1 이미지 및 상기 제2 이미지에 관한 이미지 워핑(image warping)을 수행하는 단계; 를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>16. 제11 항 및 제12 항 중 어느 하나의 항에 있어서,상기 제2 이미지의 시야를 확장하는 단계(S220)는, 인공지능 모델에 상기 제2 이미지를 입력하여, 상기 제1 이미지를 가이드 이미지(guide image)로 이용하는 아웃페인팅(outpainting)을 수행함으로써, 상기 제2 이미지의 표시 영역을 확장하는, 방법. </claim></claimInfo><claimInfo><claim>17. 제11 항 및 제12 항 중 어느 하나의 항에 있어서, 상기 제2 이미지의 시야를 확장하는 단계(S220)는, 상기 제1 이미지의 표시 영역 중 상기 제2 이미지와 중복되는 공통 영역을 제외한 주변 영역을 상기 제2 이미지와 병합(merge)하여 병합 이미지를 획득하는 단계; 및 이미지 하모나이제이션(image harmonization) 알고리즘을 이용하여 상기 병합 이미지 내의 상기 제2 이미지와 상기 주변 영역 간의 경계에 해당되는 픽셀들의 픽셀 값 차이를 조정하는 단계; 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>18. 제11 항 내지 제17 항 중 어느 하나의 항에 있어서,상기 공간 이미지를 생성하는 단계(S230)는, 상기 제1 이미지를 기준으로 상기 시야가 확장된 제2 이미지를 시차(disparity)만큼 이동(shift)하여 깊이 정보를 제공하는 스테레오 이미지(stereoscopic image)를 획득하는, 방법. </claim></claimInfo><claimInfo><claim>19. 제11 항 내지 제17 항 중 어느 하나의 항에 있어서,상기 공간 이미지를 생성하는 단계(S230)는, 스테레오 이미지 기반 깊이 예측 알고리즘(stereo image-based depth estimation)을 통해 상기 제1 이미지의 표시 영역과 상기 제2 이미지의 표시 영역 간 중복되는 공통 영역에 대한 제1 깊이 값을 예측하는 단계(S1010); 단일 이미지 기반 깊이 예측 알고리즘(mono image-based depth estimation)을 통해 상기 시야가 확장된 제2 이미지의 전체 표시 영역 중 상기 공통 영역을 제외한 확장 영역(extended area)에 대한 제2 깊이 값을 예측하는 단계(S1020); 상기 공통 영역으로부터 예측된 상기 제1 깊이 값과 상기 확장 영역으로부터 예측된 상기 제2 깊이 값 간의 상관 관계를 나타내는 매핑 함수(mapping function)를 획득하는 단계(S1030); 상기 매핑 함수에 기초하여 상기 제2 깊이 값을 변환(transform)함으로써, 상기 공통 영역 및 상기 주변 영역을 포함하는 전체 영역에 대한 깊이 값 정보를 획득하는 단계(S1040); 및상기 획득된 깊이 값 정보를 이용하여 상기 공간 이미지를 생성하는 단계(S1050);를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>20. 서로 다른 종류의 카메라들로부터 획득된 이미지를 처리하는 모바일 디바이스(200)에 있어서, 서로 다른 시야(Field of View; FOV)를 갖는 이미지를 획득하도록 구성되는 복수의 카메라(211, 212); 적어도 하나의 명령어들(instructions)를 저장하는 메모리(230); 상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(220); 및외부 디바이스와 페어링(pairing)하여 데이터를 송수신하도록 구성되는 통신 인터페이스(240); 를 포함하고,상기 적어도 하나의 프로세서(220)는, 상기 복수의 카메라(211, 212) 중 제1 시야를 갖는 제1 카메라(211)를 통해 제1 이미지를 획득하고, 상기 제1 시야 보다 작은 제2 시야를 갖는 제2 카메라(212)를 통해 제2 이미지를 획득하고, 상기 제1 이미지의 표시 영역에 기초하여 제2 이미지의 표시 영역을 확장함으로써 상기 제2 이미지의 시야를 확장하고, 상기 제1 이미지 및 상기 시야가 확장된 제2 이미지를 이용하여 깊이 정보를 포함하는 공간 이미지를 생성하고, 상기 통신 인터페이스(240)를 통해 페어링된 헤드 마운티드 디스플레이 장치(100)에 상기 공간 이미지를 전송하고, 상기 공간 이미지는 상기 헤드 마운티드 디스플레이 장치(100)에 의해 디스플레이되는, 모바일 디바이스(200). </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Song Hyeon</engName><name>김송현</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YEO, Yoon Jae</engName><name>여윤재</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JI, Seo Won</engName><name>지서원</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Hyo Kak</engName><name>김효각</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>WON, Seung Jae</engName><name>원승재</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEONG, Jae Yun</engName><name>정재윤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.10.18</priorityApplicationDate><priorityApplicationNumber>1020230139896</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.19</receiptDate><receiptNumber>1-1-2023-1427727-32</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230186298.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9341682f32baa2b85fb9fd98b30aa306ecf1cf58c24e44f2a51fa05cae8c92970e3f302587f607a9ef57ec53ca9e47edaa81a10659af4bddec</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbc464f0344d09260401504e4f4eef6c9ad2a2976bdbefa4b996ff47e3d35f7ecd6a8fb42d1078d6e82867c223eded4f5270ef0b522741ee6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>