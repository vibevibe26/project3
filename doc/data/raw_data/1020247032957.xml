<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:03:36.336</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.05.02</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2024-7032957</applicationNumber><claimCount>9</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자동화된 어시스턴트 기능(들)의 핫-워드 프리 적응</inventionTitle><inventionTitleEng>HOT-WORD FREE ADAPTATION OF AUTOMATED ASSISTANT FUNCTION(S)</inventionTitleEng><openDate>2024.10.21</openDate><openNumber>10-2024-0152401</openNumber><originalApplicationDate>2019.05.02</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2023-7009211</originalApplicationNumber><originalExaminationRequestDate>2024.10.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.10.02</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/98</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/24</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020237009211</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 자동화된 어시스턴트의 하나 이상의 기능(들)의 핫-워드 프리 적응이 설명된다. (그래픽적인 그리고/또는 청취가능한) 자동화된 어시스턴트 인터페이스를 제공하는 어시스턴트 디바이스의 하나 이상의 센서 컴포넌트들로부터의 센서 데이터가, 어시스턴트 디바이스에 근접한 사용자의 다양한 속성들의 발생 및/또는 신뢰도 메트릭(들)을 결정하기 위해 프로세싱된다. 자동화된 어시스턴트의 기능(들) 중 하나 이상의 기능들 각각을 적응시킬지 여부가, 다양한 속성들 중 하나 이상의 속성의 발생 및/또는 신뢰도에 근거한다. 예를 들어, 센서 데이터의 적어도 일부의 특정 프로세싱이 개시될 수 있는데, 예컨대, 센서 데이터의 적어도 일부의 이전에 휴면상태인 로컬 프로세싱을 개시하는 것, 그리고/또는 오디오 데이터의 적어도 일부를 원격 자동화된 어시스턴트 컴포넌트(들)로 전송하는 것을 개시하는 것이 행해질 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2020.03.12</internationOpenDate><internationOpenNumber>WO2020050882</internationOpenNumber><internationalApplicationDate>2019.05.02</internationalApplicationDate><internationalApplicationNumber>PCT/US2019/030487</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 사용자(user)와 자동화된 어시스턴트(automated assistant) 간의 핫-워드 프리(hot-word free) 및 터치-프리 제스처(touch-free gesture) 상호작용(interaction)을 용이하게 하는 방법으로서, 상기 방법은 하나 이상의 프로세서(processor)들에 의해 구현되고, 상기 방법은,클라이언트 디바이스(client device)에서, 상기 클라이언트 디바이스의 하나 이상의 카메라들로부터의 출력에 근거하는 이미지 프레임(image frame)들의 스트림(stream)을 수신하는 것과;상기 클라이언트 디바이스에서, 상기 클라이언트 디바이스를 향해 지향된 사용자의 응시(gaze)의 발생을 검출하기 위해 상기 클라이언트 디바이스 상에 로컬로(locally) 저장된 적어도 하나의 훈련된 머신 러닝 모델(machine learning model)을 사용하여 상기 스트림의 상기 이미지 프레임들을 프로세싱(processing)하는 것과;상기 사용자의 상기 응시의 상기 발생을 검출함에 근거하여, 상기 스트림의 상기 이미지 프레임들 중 하나 이상의 이미지 프레임에 의해 캡처(capture)된 상기 사용자의 제스처에 대한 응답을 발생시킬 것을 결정하는 것과;상기 사용자의 상기 제스처에 대한 상기 응답을 발생시키는 것과, 여기서 상기 응답을 발생시키는 것은, 상기 스트림의 상기 이미지 프레임들 중 상기 하나 이상의 이미지 프레임을 프로세싱하는 것에 근거하여 상기 사용자의 상기 제스처를 결정하는 것과, 그리고 상기 사용자의 상기 제스처에 근거하여, 그리고 상기 제스처가 일어난 때 상기 클라이언트 디바이스에 의해 렌더링(rendering)되고 있는 콘텐츠(content)에 근거하여, 상기 응답을 발생시키는 것을 포함하고; 그리고상기 클라이언트 디바이스에서 상기 응답을 발효(effectuating)시키는 것을포함하는 것을 특징으로 하는 사용자와 자동화된 어시스턴트 간의 핫-워드 프리 및 터치-프리 제스처 상호작용을 용이하게 하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 사용자의 상기 제스처에 근거하여, 그리고 상기 제스처들이 일어난 때 상기 클라이언트 디바이스에 의해 렌더링되고 있는 상기 콘텐츠에 근거하여, 상기 응답을 발생시키는 것은, 상기 제스처가 복수의 응답형 액션(responsive action)들에 할당됨을 결정하는 것과, 상기 제스처가 일어난 때 상기 클라이언트 디바이스에 의해 렌더링되고 있는 상기 콘텐츠에 근거하여, 상기 복수의 응답형 액션들로부터, 단일의 응답형 액션을 선택하는 것과, 그리고 상기 선택된 단일의 응답형 액션의 수행을 일으키도록 상기 응답을 발생시키는 것을포함하는 것을 특징으로 하는 사용자와 자동화된 어시스턴트 간의 핫-워드 프리 및 터치-프리 제스처 상호작용을 용이하게 하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 방법은 또한,상기 클라이언트 디바이스에서, 상기 클라이언트 디바이스에 대한 상기 사용자의 거리를 결정하는 것을 포함하고,여기서 상기 클라이언트 디바이스에 대한 상기 사용자의 상기 거리를 결정하는 것은, 상기 이미지 프레임들 중 하나 이상의 이미지 프레임, 및 상기 클라이언트 디바이스의 추가적인 센서로부터의 추가적인 센서 데이터중 하나 혹은 양쪽 모두에 근거하고,상기 사용자의 상기 제스처에 대한 상기 응답을 발생시킬 것을 결정하는 것은 또한, 상기 사용자의 상기 거리의 크기에 근거하는 것을 특징으로 하는 사용자와 자동화된 어시스턴트 간의 핫-워드 프리 및 터치-프리 제스처 상호작용을 용이하게 하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 사용자의 상기 거리에 또한 근거하여 상기 사용자의 상기 제스처에 대한 상기 응답을 발생시킬 것을 결정하는 것은, 상기 사용자의 상기 거리가 거리 임계치를 만족시키는 것에 근거하여 상기 응답을 발생시킬 것을 결정하는 것을 포함하는 것을 특징으로 하는 사용자와 자동화된 어시스턴트 간의 핫-워드 프리 및 터치-프리 제스처 상호작용을 용이하게 하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 하나의 항에 있어서,상기 방법은 또한,상기 클라이언트 디바이스에서 로컬로 상기 이미지 프레임들 중 하나 이상의 이미지 프레임을 프로세싱하는 것에 근거하여 상기 사용자가 인식된 사용자임을 결정하는 것을 포함하고,상기 사용자의 상기 제스처에 대한 상기 응답을 발생시킬 것을 결정하는 것은 또한, 상기 사용자가 인식된 사용자임을 결정하는 것에 근거하는 것을 특징으로 하는 사용자와 자동화된 어시스턴트 간의 핫-워드 프리 및 터치-프리 제스처 상호작용을 용이하게 하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 사용자의 상기 제스처에 대한 상기 응답을 발생시킬 것을 결정하는 것은 또한, 동일한 상기 인식된 사용자가 상기 클라이언트 디바이스에 의해 렌더링되고 있는 상기 콘텐츠의 제공을 개시했다는 결정에 근거하는 것을 특징으로 하는 사용자와 자동화된 어시스턴트 간의 핫-워드 프리 및 터치-프리 제스처 상호작용을 용이하게 하는 방법.</claim></claimInfo><claimInfo><claim>7. 클라이언트 디바이스로서, 상기 클라이언트 디바이스는,적어도 하나의 비전 컴포넌트(vision component);적어도 하나의 마이크로폰(microphone);적어도 하나의 디스플레이(display);하나 이상의 프로세서들을 포함하고,상기 하나 이상의 프로세서들은 제1항 내지 제6항 중 어느 하나의 항의 방법을 수행하기 위해 로컬로 저장된 명령들을 실행하는 것을 특징으로 하는 클라이언트 디바이스.</claim></claimInfo><claimInfo><claim>8. 명령들을 저장한 컴퓨터 판독가능 저장 매체로서, 상기 명령들은 하나 이상의 프로세서들에 의해 실행될 때 상기 하나 이상의 프로세서들로 하여금 제1항 내지 제6항 중 어느 하나의 항의 방법을 수행하도록 하는 것을 특징으로 하는 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제6항 중 어느 하나의 항의 방법을 수행하기 위한 하나 이상의 프로세서들을 포함하는 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 *****...</address><code> </code><country> </country><engName>KONZELMANN, Jaclyn</engName><name>콘젤만 재클린</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****...</address><code> </code><country> </country><engName>MIXTER, Kenneth</engName><name>믹스터 케네쓰</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****...</address><code> </code><country> </country><engName>CHAUDHURI, Sourish</engName><name>차우드후리 사우어리쉬</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****...</address><code> </code><country> </country><engName>NGUYEN, Tuan</engName><name>응우엔 투안</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****...</address><code> </code><country> </country><engName>MATSUI, Hideaki</engName><name>마추이 히데아키</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****...</address><code> </code><country> </country><engName>PANTOFARU, Caroline</engName><name>팬토파루 캐롤라인</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****...</address><code> </code><country> </country><engName>BETTADAPURA, Vinay</engName><name>베타다푸라 비나이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2018.05.04</priorityApplicationDate><priorityApplicationNumber>PCT/US2018/031164</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2018.05.04</priorityApplicationDate><priorityApplicationNumber>PCT/US2018/031170</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2024.10.02</receiptDate><receiptNumber>1-1-2024-1073835-41</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247032957.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b300355984cd2fa9982c7b4a2c4708af9f8f8242a85b591f48de3c90e7cb56db9453f7d3087053daf629290868356f45647f435a5c51f62b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfde8fb9fd41b1bb7fb1ae3de04b0efac9639fd0c2f9b363d3bd9be02d49a8869b9cdf71f5eb4bbe2cff87963cdde65a0c265cdcd87a1fa86e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>