<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:40.540</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.22</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0110137</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>손 관절의 3차원 위치 정보를 획득하는 증강 현실 디바이스 및 그 동작 방법</inventionTitle><inventionTitleEng>AN AUGMENTED REALITY DEVICE FOR OBTAINING THREE-DIMENSIONAL  POSITION INFORMATION OF JOINTS OF USER'S HAND AND  A METHOD FOR OPERATING THE SAME</inventionTitleEng><openDate>2025.03.04</openDate><openNumber>10-2025-0028905</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 복수의 카메라를 통해 획득된 복수의 이미지로부터 손 관절의 3차원 위치 정보를 획득하는 증강 현실 디바이스 및 그 동작 방법을 개시한다. 본 개시의 일 실시예에 따른 증강 현실 디바이스는 복수의 카메라를 통해 사용자의 손을 촬영하여 획득된 복수의 이미지로부터 손 관절의 특징점에 관한 2차원 관절 좌표값을 획득하고, 복수의 이미지 중 적어도 2개 이상의 이미지들의 조합으로 구성된 이미지 조합들로부터 획득된 2차원 관절 좌표값의 조합에 기초하여 손 관절의 3차원 관절 좌표값을 추정하고, 이미지 조합들 중 추정된 3차원 관절 좌표값에 의해 계산된 오차 거리(error distance)가 최소인 이미지 조합을 선택하며, 선택된 이미지 조합을 구성하는 적어도 2개 이상의 이미지들에 의한 2차원 관절 좌표값의 조합에 기초하여 손 관절의 3차원 위치 정보를 획득할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 증강 현실 디바이스(100)가 손 관절의 3차원 위치 정보를 획득하는 방법에 있어서, 복수의 카메라(111, 112, 113, 114)를 통해 사용자의 손을 촬영하여 획득된 복수의 이미지로부터 손 관절의 특징점에 관한 2차원 관절 좌표값을 획득하는 단계(S210); 상기 복수의 이미지 중 적어도 2개 이상의 이미지들의 조합으로 구성된 이미지 조합들로부터 획득된 상기 2차원 관절 좌표값의 조합에 기초하여 상기 손 관절의 3차원 관절 좌표값을 추정하는 단계(S220); 상기 이미지 조합들 중 상기 추정된 3차원 관절 좌표값에 의해 계산된 오차 거리(error distance)가 최소인 이미지 조합을 선택하는 단계(S230); 및상기 선택된 이미지 조합을 구성하는 적어도 2개 이상의 이미지들에 의한 2차원 관절 좌표값의 조합에 기초하여 상기 손 관절의 3차원 위치 정보를 획득하는 단계(S240); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 이미지 조합을 선택하는 단계(S230)는,상기 손 관절의 길이가 메모리 내에 저장되어 있지 않은 경우, 상기 이미지 조합들 각각을 구성하는 상기 적어도 2개 이상의 이미지들로부터 획득된 상기 2차원 관절 좌표값들을 상기 3차원 관절 좌표값으로 변환 시 발생되는 오차 거리를 계산하는 단계(S520); 및상기 이미지 조합들 중 상기 계산된 오차 거리가 최소인 이미지 조합을 선택하는 단계(S530); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,상기 오차 거리를 계산하는 단계(S520)는, 상기 복수의 카메라(111, 112, 113, 114) 중 적어도 2개 이상의 카메라의 중심 위치로부터 상기 적어도 2개 이상의 이미지 내의 2차원 관절 좌표값들을 향하여 뻗어나가는 선(ray)들이 형성하는 가상의 3차원 구조의 중심점 위치에 관한 정보를 획득하는 단계(S610); 및상기 가상의 3차원 구조의 중심점 위치로부터 상기 선들 각각에 도달하는 최단 거리에 기초하여 상기 오차 거리를 계산하는 단계(S620); 를 포함하는, 방법.  </claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서, 상기 이미지 조합을 선택하는 단계(S230)는,상기 추정된 3차원 관절 좌표값에 기초하여 상기 손 관절의 길이를 측정하는 단계(S810); 상기 측정된 손 관절의 길이 및 메모리 내에 기 저장된 관절 길이 정보에 기초하여 상기 오차 거리를 계산하는 단계(S820); 및 상기 이미지 조합들 중 상기 계산된 오차 거리가 최소인 이미지 조합을 선택하는 단계(S560); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 오차 거리를 계산하는 단계(S820)는, 상기 측정된 손 관절의 길이와 상기 기 저장된 관절 길이의 평균의 차이값 및 상기 기 저장된 관절 길이의 표준 편차에 기초하여 상기 오차 거리를 정규화(normalize)하는 단계;를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>6. 제1 항 내지 제5 항 중 어느 하나의 항에 있어서, 상기 이미지 조합을 선택하는 단계(S230)는, 상기 계산된 오차 거리가 동일한 이미지 조합이 복수 개 식별되거나, 또는 상기 계산된 오차 거리가 임계값 이하인 이미지 조합이 복수 개 식별되는 경우, 상기 복수의 카메라(111, 112, 113, 114) 중 기 설정된 우선 순위에 기초하여 적어도 2개 이상의 카메라를 선택하는 단계(S1020); 및 상기 선택된 적어도 이상의 카메라를 통해 촬영되어 획득된 적어도 2개 이상의 이미지들로 구성된 이미지 조합을 선택하는 단계(S1030); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>7. 제1 항 내지 제6 항 중 어느 하나의 항에 있어서, 제1 이미지 프레임의 이미지 조합으로부터 상기 손 관절의 3차원 위치 정보가 획득된 이후, 상기 복수의 카메라(111, 112, 113, 114) 중 상기 선택된 이미지 조합에 포함되는 적어도 2개 이상의 이미지를 촬영하도록 구성되는 적어도 2개 이상의 카메라만을 이용하여 적어도 2개 이상의 제2 이미지 프레임을 획득하는 단계; 및상기 적어도 2개 이상의 제2 이미지 프레임의 조합에 의해 획득된 2차원 관절 좌표값의 조합에 기초하여 상기 손 관절의 3차원 위치 정보를 획득하는 단계;를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>8. 제1 항 내지 제7 항 중 어느 하나의 항에 있어서, 상기 이미지 조합을 선택하는 단계(S230)는, 상기 계산된 오차 거리가 기 설정된 임계값을 초과하는 이미지 조합을 식별하는 단계(S1310); 상기 식별된 이미지 조합의 하위 조합에 대해서는 오차 거리 계산을 수행하지 않고, 스킵(skip)하는 단계(S1320); 및상기 오차 거리가 계산된 이미지 조합들 중 상기 오차 거리가 최소인 이미지 조합을 선택하는 단계(S1330);를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 하나의 항에 있어서, 상기 이미지 조합을 선택하는 단계(S230)는, 상기 복수의 이미지들 중 조합 가능한 이미지의 최대 개수를 설정하는 단계(S1610); 상기 설정된 최대 개수의 이하의 이미지들의 조합으로 구성된 이미지 조합에 대해서만 상기 오차 거리를 계산하는 단계(S1620); 및상기 오차 거리가 계산된 이미지 조합 중 상기 오차 거리가 최소인 이미지 조합을 선택하는 단계(S1630); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 하나의 항에 있어서, 상기 손 관절의 3차원 위치 정보를 획득하는 단계(S240)는, 상기 선택된 이미지 조합에 포함된 이미지들 외에 나머지 이미지들로부터 획득된 2차원 관절 좌표값들 중 기 저장된 관절 길이와 유사한 손 관절 길이를 형성하는 적어도 하나의 2차원 관절 좌표값을 추가로 선택하는 단계; 및 상기 선택된 이미지 조합에 포함된 적어도 2개 이상의 이미지들에 의해 획득된 2차원 관절 좌표값의 조합 및 상기 추가로 선택된 적어도 하나의 2차원 관절 좌표값을 함께 이용하여 상기 손 관절의 3차원 위치 정보를 획득하는 단계; 를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서, 상기 적어도 하나의 2차원 관절 좌표값을 추가로 선택하는 단계는, 상기 나머지 이미지들로부터 획득된 적어도 하나의 2차원 관절 좌표값들 중 인체의 근골격계의 해부학적 제약에 따른 관절의 가동(可動) 각도 범위 내의 손 관절의 특징점을 나타내는 2차원 관절 좌표값을 선택하는, 방법. </claim></claimInfo><claimInfo><claim>12. 손 관절의 3차원 위치 정보를 획득하는 증강 현실 디바이스(100)에 있어서, 사용자의 손을 촬영하여 복수의 이미지를 획득하는 복수의 카메라(111, 112, 113, 114);적어도 하나의 명령어들(instructions)를 저장하는 메모리(130); 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(120); 를 포함하고, 상기 적어도 하나의 프로세서(120)는, 상기 복수의 카메라(111, 112, 113, 114)를 통해 획득된 복수의 이미지로부터 손 관절의 특징점에 관한 2차원 관절 좌표값을 획득하고, 상기 복수의 이미지 중 적어도 2개 이상의 이미지들의 조합으로 구성된 이미지 조합들로부터 획득된 상기 2차원 관절 좌표값의 조합에 기초하여 상기 손 관절의 3차원 관절 좌표값을 추정하고, 상기 이미지 조합들 중 상기 추정된 3차원 관절 좌표값에 의해 계산된 오차 거리(error distance)가 최소인 이미지 조합을 선택하고, 상기 선택된 이미지 조합을 구성하는 적어도 2개 이상의 이미지들에 의한 2차원 관절 좌표값의 조합에 기초하여 상기 손 관절의 3차원 위치 정보를 획득하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 손 관절의 길이가 메모리(130) 내에 저장되어 있지 않은 경우, 상기 이미지 조합들 각각을 구성하는 상기 적어도 2개 이상의 이미지들로부터 획득된 상기 2차원 관절 좌표값들을 상기 3차원 관절 좌표값으로 변환 시 발생되는 오차 거리를 계산하고, 상기 이미지 조합들 중 상기 계산된 오차 거리가 최소인 이미지 조합을 선택하는, 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 적어도 하나의 프로세서(120)는, 상기 복수의 카메라(111, 112, 113, 114) 중 적어도 2개 이상의 카메라의 중심 위치로부터 상기 적어도 2개 이상의 이미지 내의 2차원 관절 좌표값들을 향하여 뻗어나가는 선(ray)들이 형성하는 가상의 3차원 구조의 중심점 위치에 관한 정보를 획득하고, 상기 가상의 3차원 구조의 중심점 위치로부터 상기 선들 각각에 도달하는 최단 거리에 기초하여 상기 오차 거리를 계산하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>15. 제12 항에 있어서, 상기 적어도 하나의 프로세서(120)는, 상기 추정된 3차원 관절 좌표값에 기초하여 상기 손 관절의 길이를 측정하고, 상기 측정된 손 관절의 길이 및 메모리(130) 내에 기 저장된 관절 길이 정보에 기초하여 상기 오차 거리를 계산하고,  상기 이미지 조합들 중 상기 계산된 오차 거리가 최소인 이미지 조합을 선택하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>16. 제12 항 내지 제15 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 프로세서(120)는, 상기 계산된 오차 거리가 동일한 이미지 조합이 복수 개 식별되거나, 또는 상기 계산된 오차 거리가 임계값 이하인 이미지 조합이 복수 개 식별되는 경우, 상기 복수의 카메라(111, 112, 113, 114) 중 기 설정된 우선 순위에 기초하여 적어도 2개 이상의 카메라를 선택하고, 상기 선택된 적어도 이상의 카메라를 통해 촬영되어 획득된 적어도 2개 이상의 이미지들로 구성된 이미지 조합을 선택하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>17. 제12 항 내지 제16 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 프로세서(120)는, 제1 이미지 프레임의 이미지 조합으로부터 상기 손 관절의 3차원 위치 정보가 획득된 이후, 상기 복수의 카메라(111, 112, 113, 114) 중 상기 선택된 이미지 조합에 포함되는 적어도 2개 이상의 이미지를 촬영하도록 구성되는 적어도 2개 이상의 카메라만을 이용하여 적어도 2개 이상의 제2 이미지 프레임을 획득하고,상기 적어도 2개 이상의 제2 이미지 프레임의 조합에 의해 획득된 2차원 관절 좌표값의 조합에 기초하여 상기 손 관절의 3차원 위치 정보를 획득하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>18. 제12 항 내지 제17 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 프로세서(120)는, 상기 계산된 오차 거리가 기 설정된 임계값을 초과하는 이미지 조합을 식별하고, 상기 식별된 이미지 조합의 하위 조합에 대해서는 오차 거리 계산을 수행하지 않고, 스킵(skip)하고, 상기 오차 거리가 계산된 이미지 조합들 중 상기 오차 거리가 최소인 이미지 조합을 선택하는, 증강 현실 디바이스(100).  </claim></claimInfo><claimInfo><claim>19. 제12 항 내지 제18 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 프로세서(120)는, 상기 복수의 이미지들 중 조합 가능한 이미지의 최대 개수를 설정하고, 상기 설정된 최대 개수의 이하의 이미지들의 조합으로 구성된 이미지 조합에 대해서만 상기 오차 거리를 계산하고, 상기 오차 거리가 계산된 이미지 조합 중 상기 오차 거리가 최소인 이미지 조합을 선택하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>20. 제1 항 내지 제11 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Deok Ho</engName><name>김덕호</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KWAK, Jun Ho</engName><name>곽준호</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Hwang Pil</engName><name>박황필</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Gun Ill</engName><name>이건일</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Won Woo</engName><name>이원우</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEONG, Ji Won</engName><name>정지원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.22</receiptDate><receiptNumber>1-1-2023-0925597-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230110137.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93665ac818b216ffc58e4c199dff989d0e1fc851951074d73fad4674717f25f0aefeacbceab3cdeb4a845b4d220598f7be88683d428803ed28</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf95fc9c1fad04230fa8bf0f9e0f2fafbcfd06b06f624ac062b1d31ed9a08d5858bf45356398df1e75970c3302e5147f2a358417e4a7c6693b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>