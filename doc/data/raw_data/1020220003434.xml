<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:41.541</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.01.10</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0003434</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 인식 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR OBJECT RECOGNITION</inventionTitleEng><openDate>2023.07.18</openDate><openNumber>10-2023-0108075</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/42</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/54</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 객체 인식 방법 및 장치가 제공된다. 일 실시예에 따르면, 객체 인식 방법은 입력 영상으로부터 로컬 특징 표현들을 포함하는 특징 맵들을 추출하고, 로컬 특징 표현들을 융합하여 입력 영상에 대응하는 글로벌 특징 표현을 결정하고, 로컬 특징 표현들 및 글로벌 특징 표현에 기초하여 입력 영상에 관한 인식 작업을 수행하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 영상으로부터 로컬 특징 표현들을 포함하는 특징 맵들을 추출하는 단계;상기 로컬 특징 표현들을 융합하여 상기 입력 영상에 대응하는 글로벌 특징 표현을 결정하는 단계; 및상기 로컬 특징 표현들 및 상기 글로벌 특징 표현에 기초하여 상기 입력 영상에 관한 인식 작업을 수행하는 단계를 포함하는 객체 인식 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 글로벌 특징 표현을 결정하는 단계는상기 로컬 특징 표현들에 대응하는 풀링 결과들을 융합하여 상기 글로벌 특징 표현을 결정하는 단계를 포함하는,객체 인식 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 글로벌 특징 표현을 결정하는 단계는상기 인식 작업에 대응하여 미리 트레이닝된 쿼리 데이터를 이용한 어텐션 메커니즘을 수행하여 상기 글로벌 특징 표현을 결정하는 단계를 포함하는,객체 인식 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 어텐션 메커니즘을 수행하여 상기 글로벌 특징 표현을 결정하는 단계는상기 로컬 특징 표현들에 대응하는, 키 데이터 및 밸류 데이터를 결정하는 단계;상기 키 데이터와 상기 쿼리 데이터 간의 유사도에 기초하여 상기 밸류 데이터의 가중 합을 결정하는 단계; 및상기 가중 합에 기초하여 상기 글로벌 특징 표현을 결정하는 단계를 포함하는, 객체 인식 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 인식 작업을 수행하는 단계는제1 인식 모델을 이용하여 상기 로컬 특징 표현들에 대응하는 제1 인식 결과를 추정하는 단계; 및제2 인식 모델을 이용하여 상기 글로벌 특징 표현에 대응하는 제2 인식 결과를 추정하는 단계를 포함하는, 객체 인식 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 제1 인식 모델은상기 로컬 특징 표현들 각각에 대응하는 검출 결과를 추정하는 객체 검출 모델이고,상기 제2 인식 모델은상기 글로벌 특징 표현에 대응하는 분류 결과를 추정하는 분류 모델인,객체 인식 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 검출 결과는상기 로컬 특징 표현들 각각에 대응하는, 바운딩 박스 정보, 객체성(objectness) 정보, 및 클래스 정보 중 적어도 일부를 포함하고,상기 분류 결과는멀티-클래스 분류 정보, 상황 분류 정보, 및 객체 카운트 정보 중 적어도 일부를 포함하는,객체 인식 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 제1 인식 모델 및 상기 제2 인식 모델은서로에게 영향을 주도록 하나의 통합 모델로서 트레이닝되는,객체 인식 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,상기 인식 작업을 수행하는 단계는상기 제1 인식 결과 및 상기 제2 인식 결과를 융합하여 상기 인식 작업에 관한 작업 결과를 결정하는 단계를 더 포함하는,객체 인식 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 인식 작업은복수의 작업 후보들 중에 하나에 해당하고,상기 글로벌 특징 표현을 결정하는 단계는상기 복수의 작업 후보들 각각에 대응하여 미리 트레이닝된 쿼리 데이터 중 상기 인식 작업에 대응하는 쿼리 데이터에 기초하여 어텐션 메커니즘을 수행하여 상기 글로벌 특징 표현을 결정하는 단계를 포함하는,객체 인식 방법.</claim></claimInfo><claimInfo><claim>11. 특징 추출 모델을 이용하여 입력 영상으로부터 로컬 특징 표현들을 포함하는 특징 맵들을 추출하는 단계;특징 융합 모델을 이용하여 상기 로컬 특징 표현들을 융합하여 상기 입력 영상에 대응하는 글로벌 특징 표현을 결정하는 단계;제1 인식 모델을 이용하여 상기 로컬 특징 표현들에 대응하는 제1 인식 결과를 추정하는 단계;제2 인식 모델을 이용하여 상기 글로벌 특징 표현에 대응하는 제2 인식 결과를 추정하는 단계;상기 제1 인식 결과 및 상기 제2 인식 결과에 따른 트레이닝 손실을 결정하는 단계; 및상기 트레이닝 손실에 기초하여 상기 특징 추출 모델, 상기 특징 융합 모델, 상기 제1 인식 모델, 및 상기 제2 인식 모델 중 적어도 일부를 트레이닝하는 단계를 포함하는 트레이닝 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 제1 인식 모델 및 상기 제2 인식 모델은서로에게 영향을 주도록 하나의 통합 모델로서 트레이닝되는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 제2 인식 모델은복수의 작업 후보들 각각에 대응하는 복수의 분류 모델들을 포함하고,상기 특징 융합 모델은 상기 복수의 작업 후보들 중 현재 작업 후보에 대응하는 쿼리 데이터에 기초하여 어텐션 메커니즘을 수행하여 상기 글로벌 특징 표현을 결정하고,상기 트레이닝 손실을 결정하는 단계는상기 복수의 분류 모델들 중 상기 현재 작업 후보에 대응하는 분류 모델의 분류 결과를 상기 제2 인식 결과로 보고 상기 트레이닝 손실을 결정하는 단계를 포함하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>14. 하드웨어와 결합되어 제1항 내지 제13항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 입력 영상을 생성하는 카메라; 및상기 입력 영상으로부터 로컬 특징 표현들을 포함하는 특징 맵들을 추출하고,상기 로컬 특징 표현들을 융합하여 상기 입력 영상에 대응하는 글로벌 특징 표현을 결정하고,상기 로컬 특징 표현들 및 상기 글로벌 특징 표현에 기초하여 상기 입력 영상에 관한 인식 작업을 수행하는, 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 프로세서는상기 로컬 특징 표현들에 대응하는 풀링 결과들을 융합하여 상기 글로벌 특징 표현을 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 프로세서는상기 인식 작업에 대응하여 미리 트레이닝된 쿼리 데이터를 이용한 어텐션 메커니즘을 수행하여 상기 글로벌 특징 표현을 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서,상기 프로세서는제1 인식 모델을 이용하여 상기 로컬 특징 표현들에 대응하는 제1 인식 결과를 추정하고,제2 인식 모델을 이용하여 상기 글로벌 특징 표현에 대응하는 제2 인식 결과를 추정하는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 제1 인식 모델은상기 로컬 특징 표현들 각각에 대응하는 검출 결과를 추정하는 객체 검출 모델이고,상기 제2 인식 모델은상기 글로벌 특징 표현에 대응하는 분류 결과를 추정하는 분류 모델인,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 프로세서는상기 제1 인식 결과 및 상기 제2 인식 결과를 융합하여 상기 인식 작업에 관한 작업 결과를 결정하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code>420180510946</code><country>대한민국</country><engName>KIM, In Soo</engName><name>김인수</name></inventorInfo><inventorInfo><address>경기도 화성시 메타폴리스로 ...</address><code>420210582014</code><country>대한민국</country><engName>Kim, kikyung</engName><name>김기경</name></inventorInfo><inventorInfo><address>서울특별시 동작구...</address><code>420170481940</code><country>대한민국</country><engName>HAN, Seung Ju</engName><name>한승주</name></inventorInfo><inventorInfo><address>경기도 화성...</address><code>420190207179</code><country>대한민국</country><engName>BAEK, Ji Won</engName><name>백지원</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code>420170731631</code><country>대한민국</country><engName>Han, Jae Joon</engName><name>한재준</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.01.10</receiptDate><receiptNumber>1-1-2022-0030374-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.12.26</receiptDate><receiptNumber>1-1-2024-1439577-40</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220003434.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9306f90203ddbf23267401d35f16f1fc6dfe22d6ad1752b6148545cd2b7dabfafb36a1663c341ab74bf55164ab9fd671dca1dba0c0a2beadc6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4a232176a6af17a67d954ee866d5f1b98a123c92781b0b18359fa9df0f77f7e2a06e77949973673bd88adac86877cc9b70ddbba2f123acd2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>