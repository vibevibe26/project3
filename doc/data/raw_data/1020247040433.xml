<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:23:14.2314</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.05.10</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7040433</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다중-모드 인간 상호작용 제어 증강 현실</inventionTitle><inventionTitleEng>MULTI-MODAL HUMAN INTERACTION CONTROLLED AUGMENTED REALITY</inventionTitleEng><openDate>2025.01.09</openDate><openNumber>10-2025-0005475</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.12.05</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/03</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0481</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에서의 시스템들 및 방법들은 다중-모드 상호작용 시스템을 설명한다. 다중-모드 상호작용 시스템은 컴퓨터 디바이스 상의 애플리케이션 내에서 증강 현실(AR) 경험의 선택을 수신하고, 컴퓨터 디바이스의 그래픽 사용자 인터페이스(GUI) 상에 AR 경험과 연관된 AR 객체 세트를 디스플레이하고, GUI 상에 증강 현실 객체 세트와 연관된 텍스트 큐들을 디스플레이하고, 손 제스처 및 음성 커맨드를 수신하고, 손 제스처 및 음성 커맨드에 기초하여 증강 현실 객체 세트의 증강 현실 객체 서브세트를 수정하고, GUI 상에 수정된 증강 현실 객체 서브세트를 디스플레이한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.11.16</internationOpenDate><internationOpenNumber>WO2023220163</internationOpenNumber><internationalApplicationDate>2023.05.10</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/021715</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,프로세서에 의해, 컴퓨터 디바이스 상의 애플리케이션 내에서 증강 현실 경험의 선택을 수신하는 단계;상기 컴퓨터 디바이스의 그래픽 사용자 인터페이스(GUI) 상에 상기 증강 현실 경험과 연관된 증강 현실 객체 세트(a set of augmented reality objects)의 디스플레이를 야기하는 단계;상기 GUI 상에 상기 증강 현실 객체 세트와 연관된 텍스트 큐들(textual cues)의 디스플레이를 야기하는 단계;상기 디스플레이된 텍스트 큐들에 응답하여, 상기 컴퓨터 디바이스로부터 손 제스처 및 음성 커맨드를 수신하는 단계;상기 손 제스처 및 상기 음성 커맨드에 기초하여 상기 증강 현실 객체 세트의 증강 현실 객체 서브세트(a subset of augmented reality objects)를 수정하는 단계; 및상기 GUI 상에 상기 수정된 증강 현실 객체 서브세트의 디스플레이를 야기하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 선택은 상기 컴퓨터 디바이스에서 수신된 사용자 입력인, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 증강 현실 경험은 상기 애플리케이션 내에서 선택가능한 사용자 인터페이스 요소로서 디스플레이되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 텍스트 큐들은 상기 손 제스처 및 상기 음성 커맨드와 연관된 힌트들인, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 텍스트 큐들은 미리 결정된 시간 지속기간(predetermined duration of time) 동안 상기 GUI 상에 일시적으로 디스플레이되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 손 제스처를 수신하는 것은:상기 컴퓨터 디바이스의 하나 이상의 이미지 센서를 사용하여 사용자의 손을 검출하는 것;상기 사용자의 손의 관절 위치 세트(a set of joint locations)를 식별하는 것;상기 관절 위치 세트에 기초하여 포즈를 식별하는 것;상기 포즈에 기초하여 상기 손 제스처를 결정하는 것; 및상기 결정된 손 제스처에 기초하여 제1 수정 데이터 세트(a first set of modification data)를 생성하는 것을 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 음성 커맨드를 수신하는 것은:상기 컴퓨터 디바이스의 하나 이상의 마이크로폰으로부터 오디오 데이터를 수신하는 것;머신 학습 모델을 사용하여 상기 오디오 데이터를 분석하는 것 - 상기 머신 학습 모델은 상기 오디오 데이터에서 키워드들을 식별하도록 트레이닝됨 -; 및상기 식별된 키워드들을 사용하여 제2 수정 데이터 세트를 생성하는 것을 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 GUI 상에 상기 식별된 키워드들의 디스플레이를 야기하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서, 상기 증강 현실 객체 세트의 상기 증강 현실 객체 서브세트를 수정하는 단계는:상기 제1 수정 데이터 세트를 사용하여 상기 증강 현실 객체 서브세트를 식별하는 단계; 및상기 제2 수정 데이터 세트를 상기 증강 현실 객체 서브세트에 적용하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 증강 현실 객체 서브세트를 식별하는 단계는:상기 증강 현실 객체 서브세트의 임시 윤곽(temporary outline)을 생성하는 단계; 및상기 증강 현실 객체 서브세트의 상기 임시 윤곽의 디스플레이를 야기하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨팅 시스템으로서,프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때,컴퓨터 디바이스 상의 애플리케이션 내에서 증강 현실 경험의 선택을 수신하고;상기 컴퓨터 디바이스의 그래픽 사용자 인터페이스(GUI) 상에 상기 증강 현실 경험과 연관된 증강 현실 객체 세트의 디스플레이를 야기하고;상기 GUI 상에 상기 증강 현실 객체 세트와 연관된 텍스트 큐들의 디스플레이를 야기하고;상기 디스플레이된 텍스트 큐들에 응답하여, 상기 컴퓨터 디바이스로부터 손 제스처 및 음성 커맨드를 수신하고;상기 손 제스처 및 상기 음성 커맨드에 기초하여 상기 증강 현실 객체 세트의 증강 현실 객체 서브세트를 수정하고;상기 GUI 상에 상기 수정된 증강 현실 객체 서브세트의 디스플레이를 야기하도록 상기 시스템을 구성하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 선택은 상기 컴퓨터 디바이스에서 수신된 사용자 입력인, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 증강 현실 경험은 상기 애플리케이션 내에서 선택가능한 사용자 인터페이스 요소로서 디스플레이되는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 텍스트 큐들은 상기 손 제스처 및 상기 음성 커맨드와 연관된 힌트들인, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 텍스트 큐들은 미리 결정된 시간 지속기간 동안 상기 GUI 상에 일시적으로 디스플레이되는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 손 제스처를 수신하는 것은:상기 컴퓨터 디바이스의 하나 이상의 이미지 센서를 사용하여 사용자의 손을 검출하는 것;상기 사용자의 손의 관절 위치 세트를 식별하는 것;상기 관절 위치 세트에 기초하여 포즈를 식별하는 것;상기 포즈에 기초하여 상기 손 제스처를 결정하는 것; 및상기 결정된 손 제스처에 기초하여 제1 수정 데이터 세트를 생성하는 것을 추가로 포함하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 음성 커맨드를 수신하는 것은:상기 컴퓨터 디바이스의 하나 이상의 마이크로폰으로부터 오디오 데이터를 수신하는 것;머신 학습 모델을 사용하여 상기 오디오 데이터를 분석하는 것 - 상기 머신 학습 모델은 상기 오디오 데이터에서 키워드들을 식별하도록 트레이닝됨 -; 및상기 식별된 키워드들을 사용하여 제2 수정 데이터 세트를 생성하는 것을 추가로 포함하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 시스템은:상기 GUI 상에 상기 식별된 키워드들의 디스플레이를 야기하도록 추가로 구성되는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>19. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금,컴퓨터 디바이스 상의 애플리케이션 내에서 증강 현실 경험의 선택을 수신하게 하고;상기 컴퓨터 디바이스의 그래픽 사용자 인터페이스(GUI) 상에 상기 증강 현실 경험과 연관된 증강 현실 객체 세트의 디스플레이를 야기하게 하고;상기 GUI 상에 상기 증강 현실 객체 세트와 연관된 텍스트 큐들의 디스플레이를 야기하게 하고;상기 디스플레이된 텍스트 큐들에 응답하여, 상기 컴퓨터 디바이스로부터 손 제스처 및 음성 커맨드를 수신하게 하고;상기 손 제스처 및 상기 음성 커맨드에 기초하여 상기 증강 현실 객체 세트의 증강 현실 객체 서브세트를 수정하게 하고;상기 GUI 상에 상기 수정된 증강 현실 객체 서브세트의 디스플레이를 야기하게 하는, 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 선택은 상기 컴퓨터 디바이스에서 수신된 사용자 입력인, 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>미국</country><engName>SOLICHIN, Jonathan</engName><name>솔리친, 조나단</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>WANG, Xinyao</engName><name>왕, 신야오</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.05.10</priorityApplicationDate><priorityApplicationNumber>17/740,567</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.12.05</receiptDate><receiptNumber>1-1-2024-1348831-31</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.12.10</receiptDate><receiptNumber>1-5-2024-0201475-92</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247040433.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93816f0a5464987b153abbb3fef236ebb628c60f7ed6926189bddac2f2ea111870dea205f5390f0365f2426df4d0383b043d5e8dbbdad9a211</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf376d170fe022674c0d8af29e877eab215eaecd1bb3800c907b15fab6ec3ca029a445a07192216252c50228edafe6fd8dee557af8a79e37d7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>