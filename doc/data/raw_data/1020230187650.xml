<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:09:55.955</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0187650</applicationNumber><claimCount>5</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>딥러닝 기반의 자세 패턴 분석을 이용한 행동 분류 모델을 구현하는 방법</inventionTitle><inventionTitleEng>METHOD OF IMPLEMENTING MOTION CLASSIFICATION MODEL USING  POSE PATTERN ANALYSIS BASED ON DEEP LEARNING</inventionTitleEng><openDate>2025.06.27</openDate><openNumber>10-2025-0096419</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 딥러닝 기반의 자세 패턴 분석을 이용한 행동 분류 모델을 구현하는 방법에 관한 것으로써, 데이터 학습자료로서 이미지 전체를 사용하는 것이 아니라 이미지 내의 객체만 잘라내어 학습을 수행하고, 더 나아가 대용량의 이미지 데이터를 자세 패턴 텐서로 변형하여 객체가 나타나는 행동을 손상시키지 않고 행동을 분류하여 경량화된 학습 데이터셋을 이용하여 객체의 행동 패턴을 빠르고 정확하게 분석할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 딥러닝 기반의 자세 패턴 분석을 이용한 행동 분류 모델을 구현하는 방법에 있어서, 객체 탐지 모델을 통해 객체 및 배경이 포함된 이미지를 탐지하고, 상기 이미지에서 배경이 최소화된 객체 이미지 데이터셋을 생성하는, 전처리 단계(S100);상기 객체 이미지 데이터셋을 자세 별로 분류하고 학습 데이터로 사용하여 학습된 이미지 분류 모델을 생성하고, 상기 학습된 이미지 분류 모델에 행동 이미지를 프레임 단위로 입력하여 프레임 내의 객체의 자세를 프레임 순서 별로 추출된 자세 텐서를 추출하는, 자세 텐서 추출 단계(S200);시퀀스 패턴 마이닝 알고리즘을 통해, 상기 자세 텐서를 분석하여 행동 별로 빈번하게 발생한 패턴을 자세 패턴 텐서로 추출하는, 시퀀스 패턴 마이닝 단계(S300); 및상기 자세 패턴 텐서를 시계열적 알고리즘에 입력하여 행동 분류를 수행하는, 행동 분류 단계(S400);를 포함하는, 행동 분류 모델을 구현하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 전처리 단계(S100)는,상기 이미지에서 객체 이미지에 경계 박스를 생성하고, 경계 박스 외의 이미지에 대해 잘라내기(Cropping)를 수행하여 상기 객체 이미지 데이터셋을 생성하는, 행동 분류 모델을 구현하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 자세 텐서 추출 단계(S200)는,행동의 연속성을 기준으로, 복수개의 프레임에 순차적으로 클래스 넘버를 부여하는 넘버링 단계(S200-1);를 포함하는, 행동 분류 모델을 구현하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 시퀀스 패턴 마이닝 알고리즘은, PrefixSPan 알고리즘인, 행동 분류 모델을 구현하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항의 방법에 의해 구현된 행동 분류 모델.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>220050169907</code><country>대한민국</country><engName>Kyonggi University Industry &amp; Academia Cooperation Foundation</engName><name>경기대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 화성시 영통로**번길 **...</address><code> </code><country> </country><engName>KIM, Kwang Hoon</engName><name>김광훈 </name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>CHUNG, Kyungyong</engName><name>정경용 </name></inventorInfo><inventorInfo><address>강원도 원주...</address><code> </code><country> </country><engName>YOO, Hyun</engName><name>유현</name></inventorInfo><inventorInfo><address>경기도 수원시 장안구...</address><code> </code><country> </country><engName>LEE, Seo El</engName><name>이서엘</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로*길 **, *층 ***호실(역삼동, 청원빌딩)</address><code>920101000618</code><country>대한민국</country><engName>SINJI PATENT FIRM</engName><name>특허법인 신지</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.20</receiptDate><receiptNumber>1-1-2023-1434682-30</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230187650.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93077b17865ae086e1bbde7bdeed961a7a80793432b255b9c6b1818aa4565106b0489e354c9ec12eaa853c86dcff94d9a43fd8d514a2df45e2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf23fa01a3efe0f671ed42a21d6aeefd1f202db25fe4f77df86e71a826b1cb9604c60e31a1d51fc28956eeca017ff84fb642c18a95493d15a0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>