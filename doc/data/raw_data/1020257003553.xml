<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:20.120</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7003553</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전사된 음성 데이터 없이 정렬된 텍스트 및 음성 표현을 사용하여 자동 음성 인식 모델 트레이닝</inventionTitle><inventionTitleEng>USING ALIGNED TEXT AND SPEECH REPRESENTATIONS TO TRAIN AUTOMATIC SPEECH RECOGNITION MODELS WITHOUT TRANSCRIBED SPEECH DATA</inventionTitleEng><openDate>2025.02.28</openDate><openNumber>10-2025-0028493</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.04</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.02.04</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법(700)은 타겟 언어의 비구두화(unspoken) 텍스트 발화들(320)을 포함하는 트레이닝 데이터를 수신하는 단계를 포함한다. 각 비구두 텍스트 발화는 비합성 음성의 임의의 대응하는 구두화(spoken) 발화와 쌍을 이루지 않는다. 본 방법은 또한, 타겟 언어와 각각 상이한 하나 이상의 트레이닝 언어들의 전사된 음성 발화(304)에 대해 트레이닝된 정렬 모델(400)을 사용하여, 각 비구두 텍스트 발화에 대한 대응하는 정렬 출력(402)을 생성하는 단계를 포함한다. 본 방법은 또한, 텍스트 인코더(202)를 사용하여 각 정렬 출력에 대한 대응하는 인코딩된 텍스트 표현(312)을 생성하는 단계, 및 정렬 출력들에 대해 생성된 인코딩된 텍스트 표현들에 대해 음성 인식 모델(200)을 트레이닝하는 단계를 포함한다. 음성 인식 모델을 트레이닝하면 음성 인식 모델이 타겟 언어의 음성을 인식하는 방법을 학습하게 된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.01.25</internationOpenDate><internationOpenNumber>WO2024020154</internationOpenNumber><internationalApplicationDate>2023.07.20</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/028267</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 데이터 프로세싱 하드웨어(810)에서 실행될 때 데이터 프로세싱 하드웨어(810)로 하여금 동작들을 수행하게 하는 컴퓨터 구현 방법(700)으로서, 상기 동작들은:타겟 언어의 비구두(unspoken) 텍스트 발화들(320)을 포함하는 트레이닝 데이터를 수신하는 단계 — 각 비구두 텍스트 발화(320)는 비합성 음성의 임의의 대응하는 구두(spoken) 발화와 쌍을 이루지 않음 —;정렬 모델(400)을 사용하여, 수신된 트레이닝 데이터의 각 비구두 텍스트 발화(320)에 대한 대응하는 정렬 출력(402)을 생성하는 단계 — 상기 정렬 모델(400)은 타겟 언어와 각각 상이한 하나 이상의 트레이닝 언어의 전사된 음성 발화들(304)에 대해 트레이닝됨 —;텍스트 인코더(202)를 사용하여, 각 정렬 출력(402)에 대한 대응하는 인코딩된 텍스트 표현(312)을 생성하는 단계; 및타겟 언어의 음성을 인식하는 방법을 학습하도록 음성 인식 모델(400)을 가르치기 위해 타겟 언어의 비구두 텍스트 발화들(320)에 대응하는 정렬 출력들(402)에 대해 생성된 인코딩된 텍스트 표현들(312)에 대해 음성 인식 모델(200)을 트레이닝하는 단계를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 음성 인식 모델(200)을 트레이닝하는 단계는,지도 학습을 위해 상기 타겟 언어의 임의의 전사된 음성 발화를 사용하지 않고 음성 인식 모델(200)을 트레이닝하는 단계를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 음성 인식 모델(200)은 오디오 인코더(210) 및 디코더(220, 230)를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 디코더(220, 230)는 순환 신경망 트랜스듀서(RNN-T) 아키텍처를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>5. 제3항 또는 제4항에 있어서, 상기 오디오 인코더(210)는,텍스트 인코더(202);음성 인코더(204); 및공유 인코더(250)를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>6. 제3항 내지 제5항 중 어느 한 항에 있어서, 상기 오디오 인코더(210)는 복수의 멀티 헤드 셀프-어텐션 계층을 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>7. 제3항 내지 제6항 중 어느 한 항에 있어서, 상기 오디오 인코더(210)는 컨포머 인코더를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>8. 제3항 내지 제7항 중 어느 한 항에 있어서, 상기 동작들은,타겟 언어를 고유하게 식별하는 언어 식별자(321)에 대해 오디오 인코더(210) 또는 디코더(220, 230) 중 적어도 하나를 컨디셔닝하는 단계를 더 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 오디오 인코더(210) 또는 디코더(220, 230) 중 적어도 하나를 컨디셔닝하는 단계는,잔여 어댑터(residual adaptor) 계층들(330)을 사용하여 언어 식별자(321)에 대해 오디오 인코더(210) 또는 디코더(220, 230) 중 적어도 하나를 컨디셔닝하는 단계를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 음성 인식 모델(200)을 트레이닝하는 단계는,각 정렬 출력(402)에 대해, 공유 인코더(250)를 사용하여, 공유 잠재 표현 공간에서 상기 정렬 출력(402)의 제1 인코딩된 공유 표현(322)을 생성하는 단계;하나 이상의 트레이닝 언어의 각 전사된 음성 발화(304)에 대해: 음성 인코더(204)를 사용하여, 상기 전사된 음성 발화(304)의 인코딩된 오디오 표현(314)을 결정하는 단계; 및 공유 인코더(250)를 사용하여, 상기 공유 잠재 표현 공간에서 상기 전사된 음성 발화(304)의 제2 인코딩된 공유 표현(324)을 생성하는 단계를 포함하며,상기 음성 인식 모델(200)을 트레이닝하는 단계는 타겟 언어의 비구두 텍스트 발화들(320)에 대응하는 정렬 출력들(402)에 대해 생성된 제1 인코딩된 공유 표현들(322) 및 하나 이상의 트레이닝 언어의 상기 전사된 음성 발화들(304)에 대해 생성된 제2 인코딩된 공유 표현들(324)에 대해 음성 인식 모델(200)을 트레이닝하는 단계를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 각 비구두 텍스트 발화(320)는 단어들, 단어조각들, 자소들, 및/또는 음소들의 시퀀스를 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 동작들은,발음 모델을 사용하여, 타겟 언어의 비구두 텍스트 발화들(320)의 스크립트를 다수의 언어에 걸쳐 공유되는 음성(phonetic) 표현으로 변환하는 단계를 더 포함하는, 컴퓨터 구현 방법(700).</claim></claimInfo><claimInfo><claim>13. 시스템(100)으로서,데이터 프로세싱 하드웨어(810); 및데이터 프로세싱 하드웨어(810)와 통신하는 메모리 하드웨어(820)를 포함하며, 상기 메모리 하드웨어(820)는 데이터 프로세싱 하드웨어(810)에서 실행될 때  데이터 프로세싱 하드웨어(810)로 하여금 동작들을 수행하게 하는 명령어를 저장하며, 상기 동작들은: 타겟 언어의 비구두 텍스트 발화들(320)을 포함하는 트레이닝 데이터를 수신하는 동작 — 각 비구두 텍스트 발화(320)는 비합성 음성의 임의의 대응하는 구두 발화와 쌍을 이루지 않음 —; 정렬 모델(400)을 사용하여, 수신된 트레이닝 데이터의 각 비구두 텍스트 발화(320)에 대한 대응하는 정렬 출력(402)을 생성하는 동작 — 상기 정렬 모델(400)은 타겟 언어와 각각 상이한 하나 이상의 트레이닝 언어들의 전사된 음성 발화들(304)에 대해 트레이닝됨 —; 텍스트 인코더(202)를 사용하여, 각 정렬 출력(402)에 대한 대응하는 인코딩된 텍스트 표현(312)을 생성하는 동작; 및 타겟 언어의 음성을 인식하는 방법을 학습하도록 음성 인식 모델(400)을 가르치기 위해 타겟 언어의 비구두 텍스트 발화들(320)에 대응하는 정렬 출력들(402)에 대해 생성된 인코딩된 텍스트 표현들(312)에 대해 음성 인식 모델(200)을 트레이닝하는 동작을 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 음성 인식 모델(200)을 트레이닝하는 동작은,지도 학습을 위해 상기 타겟 언어의 임의의 전사된 음성 발화를 사용하지 않고 음성 인식 모델(200)을 트레이닝하는 동작을 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>15. 제13항 또는 제14항에 있어서, 상기 음성 인식 모델(200)은 오디오 인코더(210) 및 디코더(220, 230)를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 디코더(220, 230)는 순환 신경망 트랜스듀서(RNN-T) 아키텍처를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>17. 제15항 또는 제16항에 있어서, 상기 오디오 인코더(210)는,상기 텍스트 인코더(202);음성 인코더(204); 및공유 인코더(250)를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>18. 제15항 내지 제17항 중 어느 한 항에 있어서, 상기 오디오 인코더(210)는 복수의 멀티 헤드 셀프-어텐션 계층을 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>19. 제15항 내지 제18항 중 어느 한 항에 있어서, 상기 오디오 인코더(210)는 컨포머 인코더를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>20. 제15항 내지 제19항 중 어느 한 항에 있어서, 상기 동작들은,타겟 언어를 고유하게 식별하는 언어 식별자(321)에 대해 오디오 인코더(210) 또는 디코더(220, 230) 중 적어도 하나를 컨디셔닝하는 동작을 더 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 오디오 인코더(210) 또는 디코더(220, 230) 중 적어도 하나를 컨디셔닝하는 동작은,잔여 어댑터 계층들(330)을 사용하여 언어 식별자(321)에 대해 오디오 인코더(210) 또는 디코더(220, 230) 중 적어도 하나를 컨디셔닝하는 동작을 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>22. 제13항 내지 제21항 중 어느 한 항에 있어서, 상기 음성 인식 모델(200)을 트레이닝하는 동작은,각 정렬 출력(402)에 대해, 공유 인코더(250)를 사용하여, 공유 잠재 표현 공간에서 정렬 출력(402)의 제1 인코딩된 공유 표현(322)을 생성하는 동작;하나 이상의 트레이닝 언어들의 각 전사된 음성 발화(304)에 대해: 음성 인코더(204)를 사용하여, 전사된 음성 발화(304)의 인코딩된 오디오 표현(314)을 결정하는 동작; 및 공유 인코더(250)를 사용하여, 공유 잠재 표현 공간에서 상기 전사된 음성 발화(304)의 제2 인코딩된 공유 표현(324)을 생성하는 동작을 포함하며,상기 음성 인식 모델(200)을 트레이닝하는 동작은 타겟 언어의 비구두 텍스트 발화들(320)에 대응하는 정렬 출력들(402)에 대해 생성된 제1 인코딩된 공유 표현들(322) 및 하나 이상의 트레이닝 언어들의 전사된 음성 발화들(304)에 대해 생성된 제2 인코딩된 공유 표현들(324)에 대해 음성 인식 모델(200)을 트레이닝하는 동작을 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>23. 제13항 내지 제22항 중 어느 한 항에 있어서, 각 비구두 텍스트 발화(320)는 단어들, 단어조각들, 자소들, 및/또는 음소들의 시퀀스를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>24. 제13항 내지 제23항 중 어느 한 항에 있어서, 상기 동작들은,발음 모델을 사용하여, 타겟 언어의 상기 비구두 텍스트 발화들(320)의 스크립트를 다수의 언어들에 걸쳐 공유되는 음성 표현으로 변환하는 동작을 더 포함하는, 시스템(100).</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>미국</country><engName>ROSENBERG, Andrew</engName><name>로젠버그 앤드류</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>중국</country><engName>CHEN, Zhehuai</engName><name>천 제화이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>인도</country><engName>BAPNA, Ankur</engName><name>바프나 안쿠르</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>중국</country><engName>ZHANG, Yu</engName><name>장 유</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>미국</country><engName>RAMABHADRAN, Bhuvana</engName><name>라마바드란 부바나</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.07.22</priorityApplicationDate><priorityApplicationNumber>63/369,213</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.02.04</receiptDate><receiptNumber>1-1-2025-0124417-66</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.02.04</receiptDate><receiptNumber>1-1-2025-0125220-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.02.06</receiptDate><receiptNumber>1-5-2025-0021206-95</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257003553.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9311487273ec768278367f2b3b9b97f09fb886ec254a997c494927f727c77709a9906441f7c68cfd04d662f1a81871b01854eb7baa5528db24</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf3ad4c6fb2b259ee804e8c0db3483dbb7514e47ee8971c8602b33641b94a47437a0edc9855faaf919cc71990e6b7cf2f17971ab48b7b50e4b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>