<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:48.448</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0042088</applicationNumber><claimCount>13</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>2차원 이미지 간의 대응점 매칭 장치, 방법 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>APPARATUS, METHOD, AND COMPUTER PROGRAM FOR MATCHING POINTS  OF CORRESPONDENCE BETWEEN TWO-DIMENSIONAL IMAGES</inventionTitleEng><openDate>2025.10.13</openDate><openNumber>10-2025-0144806</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 2차원 이미지로부터 3차원 공간 정보를 복원하는데 이용되는 이미지 간의 대응점 매칭 기술에 관한 것이다. 본 발명의 일 측면에 따르면, 2차원 이미지 간의 대응점 매칭 방법은, 복수의 2차원 이미지를 획득하는 단계; 복수의 2차원 이미지 각각으로부터 coarse-level 2차원 특징을 생성하고, coarse-level 2차원 특징 간의 제1 대응점 대응점 매칭 정보를 생성하며, 제1 대응점 매칭 정보를 기반으로 coarse-level 2차원 특징으로부터 복수의 2차원 이미지 각각에 대한 fine-level 2차원 특징을 생성하고, fine-level 2차원 특징 간의 제2 대응점 매칭 정보를 생성하는 단계; 및 제2 대응점 매칭 정보를 복수의 2차원 이미지 간의 대응점 매칭 결과로 출력하는 단계;를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 2차원 이미지 간의 대응점 매칭 장치가 수행하는 방법으로서,복수의 2차원 이미지를 획득하는 단계;상기 복수의 2차원 이미지 각각으로부터 coarse-level 2차원 특징을 생성하고, 상기 coarse-level 2차원 특징 간의 제1 대응점 대응점 매칭 정보를 생성하며, 상기 제1 대응점 매칭 정보를 기반으로 상기 coarse-level 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 fine-level 2차원 특징을 생성하고, 상기 fine-level 2차원 특징 간의 제2 대응점 매칭 정보를 생성하는 단계; 및상기 제2 대응점 매칭 정보를 상기 복수의 2차원 이미지 간의 대응점 매칭 결과로 출력하는 단계;를 포함하는, 2차원 이미지 간의 대응점 매칭 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제2 대응점 매칭 정보를 생성하는 단계는,상기 복수의 2차원 이미지 각각으로부터 2차원 특징을 생성하고, 상기 2차원 특징으로부터 상기 상기 coarse-level 2차원 특징을 생성하는, 2차원 이미지 간의 대응점 매칭 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서상기 제2 대응점 매칭 정보를 생성하는 단계는,상기 2차원 특징을 생성하는 2차원 인코더 모델, 상기 coarse-level 2차원 특징을 생성하는 coarse-level 트랜스포머 모델, 상기 제1 대응점 매칭 정보를 생성하는 제1 매칭 모델, 상기 fine-level 2차원 특징을 생성하는 fine-level 트랜스포터 모델 및 상기 제2 대응점 매칭 정보를 생성하는 제2 매칭 모델을 포함하는, 이미지 대응점 매칭 모델을 이용하여, 상기 제2 대응점 매칭 정보를 생성하는, 2차원 이미지 간의 대응점 매칭 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서상기 제1 매칭 모델은, 제1 사이즈의 복셀 단위를 기준으로, coarse-level 매칭을 수행하도록 미리 학습되고, 상기 제2 매칭 모델은 상기 제1 사이즈 보다 작은 제2 사이즈의 복셀 단위를 기준으로, fine-level 매칭을 수행하도록 미리 학습된, 2차원 이미지 간의 대응점 매칭 방법.</claim></claimInfo><claimInfo><claim>5. 2차원 이미지 간의 대응점 매칭 장치가 수행하는 방법으로서,서로 상이한 위치에서 촬영된 복수의 2차원 이미지와, 상기 복수의 2차원 이미지에 대응하는 3차원 포인트 클라우드와, 상기 복수의 2차원 이미지와 상기 3차원 포인트 클라우드로 간의 실제 대응점 매칭 정보를 포함하는 학습 데이터를 획득하는 단계;2차원 인코더 모델을 이용하여, 상기 복수의 2차원 이미지 각각으로부터 2차원 특징을 생성하고, coarse-level 트랜스포머 모델을 이용하여, 상기 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 coarse-level 2차원 특징을 생성하며, 제1 3차원 인코더 모델을 이용하여, 제1 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 제1 3차원 특징을 생성하고,제1 매칭 모델을 이용하여, 상기 3차원 특징 및 상기 coarse-level 2차원 특징을 기반으로 상기 복수의 2차원 이미지 간의 제1 대응점 매칭 정보를 생성하고,상기 실제 대응점 매칭 정보를 기반으로, 상기 2차원 인코더 모델, 상기 coarse-level 트랜스포머 모델, 제1 3차원 인코더 모델 및 상기 제1 매칭 모델의 파라미터를 업데이트하는 제1 학습을 수행하는 단계;제1 학습된 2차원 인코더 모델을 이용하여, 상기 복수의 2차원 이미지 각각으로부터 제1 학습된 2차원 특징을 생성하고, 제1 학습된 coarse-level 트랜스포머 모델을 이용하여, 상기 제1 학습된 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 제1 학습된 coarse-level 2차원 특징을 생성하며,제1 학습된 제1 3차원 인코더 모델을 이용하여, 상기 제1 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 업데이트된 제1 3차원 특징을 생성하고,제1 학습된 제1 매칭 모델을 이용하여, 상기 업데이트된 제1 3차원 특징 및 상기 제1 학습된 coarse-level 2차원 특징을 기반으로 상기 복수의 2차원 이미지 간의 업데이트된 제1 대응점 매칭 정보를 생성하고,Fine-level 트랜스포머 모델을 이용하여, 상기 제1 학습된 coarse-level 2차원 특징 및 상기 업데이트된 제1 대응점 매칭 정보를 기반으로 fine-level 2차원 특징을 생성하고,제2 3차원 인코더 모델을 이용하여, 상기 제1 사이즈 보다 작은 제2 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 제2 3차원 특징을 생성하고,제2 매칭 모델을 이용하여, 상기 제2 3차원 특징 및 상기 fine-level 2차원 특징을 기반으로, 상기 복수의 2차원 이미지 간의 제2 대응점 매칭 정보를 생성하고, 상기 실제 대응점 매칭 정보를 기반으로, 상기 제1 학습된 2차원 인코더 모델, 상기 제1 학습된 coarse-level 트랜스포머 모델, 상기 제1 학습된 제1 3차원 인코더 모델, 상기 제1 학습된 제1 매칭 모델, 상기 Fine-level 트랜스포머 모델 및 제2 3차원 인코더 모델의 파라미터를 업데이트하는 제2 학습을 수행하는 단계; 및제2 학습된 2차원 인코더 모델, 제2 학습된 coarse-level 트랜스포머 모델, 제2 학습된 제1 매칭 모델, 제2 학습된 Fine-level 트랜스포머 모델 및 제2 학습된 제2 매칭 모델을 포함하는 이미지 대응점 매칭 모델을 생성하는 단계;를 포함하는, 이미지 대응점 매칭 모델 생성 방법. </claim></claimInfo><claimInfo><claim>6. 복수의 2차원 이미지를 획득하는 입력부;상기 복수의 2차원 이미지 각각으로부터 coarse-level 2차원 특징을 생성하고, 상기 coarse-level 2차원 특징 간의 제1 대응점 대응점 매칭 정보를 생성하며, 상기 제1 대응점 매칭 정보를 기반으로 상기 coarse-level 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 fine-level 2차원 특징을 생성하고, 상기 fine-level 2차원 특징 간의 제2 대응점 매칭 정보를 생성하는 대응점 매칭 정보 생성부; 및상기 제2 대응점 매칭 정보를 상기 복수의 2차원 이미지 간의 대응점 매칭 결과로 출력하는 출력부;를 포함하는, 2차원 이미지 간의 대응점 매칭 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 대응점 매칭 정보 생성부는,상기 복수의 2차원 이미지 각각으로부터 2차원 특징을 생성하고, 상기 2차원 특징으로부터 상기 상기 coarse-level 2차원 특징을 생성하는, 2차원 이미지 간의 대응점 매칭 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서상기 대응점 매칭 정보 생성부는,상기 2차원 특징을 생성하는 2차원 인코더 모델, 상기 coarse-level 2차원 특징을 생성하는 coarse-level 트랜스포머 모델, 상기 제1 대응점 매칭 정보를 생성하는 제1 매칭 모델, 상기 fine-level 2차원 특징을 생성하는 fine-level 트랜스포터 모델 및 상기 제2 대응점 매칭 정보를 생성하는 제2 매칭 모델을 포함하는, 이미지 대응점 매칭 모델을 이용하여, 상기 제2 대응점 매칭 정보를 생성하는, 2차원 이미지 간의 대응점 매칭 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서상기 제1 매칭 모델은, 제1 사이즈의 복셀 단위를 기준으로, coarse-level 매칭을 수행하도록 미리 학습되고, 상기 제2 매칭 모델은 상기 제1 사이즈 보다 작은 제2 사이즈의 복셀 단위를 기준으로, fine-level 매칭을 수행하도록 미리 학습된, 2차원 이미지 간의 대응점 매칭 장치.</claim></claimInfo><claimInfo><claim>10. 서로 상이한 위치에서 촬영된 복수의 2차원 이미지와, 상기 복수의 2차원 이미지에 대응하는 3차원 포인트 클라우드와, 상기 복수의 2차원 이미지와 상기 3차원 포인트 클라우드로 간의 실제 대응점 매칭 정보를 포함하는 학습 데이터를 획득하는 입력부;2차원 인코더 모델을 이용하여, 상기 복수의 2차원 이미지 각각으로부터 2차원 특징을 생성하고, coarse-level 트랜스포머 모델을 이용하여, 상기 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 coarse-level 2차원 특징을 생성하며, 제1 3차원 인코더 모델을 이용하여, 제1 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 제1 3차원 특징을 생성하고,제1 매칭 모델을 이용하여, 상기 3차원 특징 및 상기 coarse-level 2차원 특징을 기반으로 상기 복수의 2차원 이미지 간의 제1 대응점 매칭 정보를 생성하고,상기 실제 대응점 매칭 정보를 기반으로, 상기 2차원 인코더 모델, 상기 coarse-level 트랜스포머 모델, 제1 3차원 인코더 모델 및 상기 제1 매칭 모델의 파라미터를 업데이트하는 제1 학습을 수행하는 제1 학습부;제1 학습된 2차원 인코더 모델을 이용하여, 상기 복수의 2차원 이미지 각각으로부터 제1 학습된 2차원 특징을 생성하고, 제1 학습된 coarse-level 트랜스포머 모델을 이용하여, 상기 제1 학습된 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 제1 학습된 coarse-level 2차원 특징을 생성하며,제1 학습된 제1 3차원 인코더 모델을 이용하여, 상기 제1 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 업데이트된 제1 3차원 특징을 생성하고,제1 학습된 제1 매칭 모델을 이용하여, 상기 업데이트된 제1 3차원 특징 및 상기 제1 학습된 coarse-level 2차원 특징을 기반으로 상기 복수의 2차원 이미지 간의 업데이트된 제1 대응점 매칭 정보를 생성하고,Fine-level 트랜스포머 모델을 이용하여, 상기 제1 학습된 coarse-level 2차원 특징 및 상기 업데이트된 제1 대응점 매칭 정보를 기반으로 fine-level 2차원 특징을 생성하고,제2 3차원 인코더 모델을 이용하여, 상기 제1 사이즈 보다 작은 제2 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 제2 3차원 특징을 생성하고,제2 매칭 모델을 이용하여, 상기 제2 3차원 특징 및 상기 fine-level 2차원 특징을 기반으로, 상기 복수의 2차원 이미지 간의 제2 대응점 매칭 정보를 생성하고, 상기 실제 대응점 매칭 정보를 기반으로, 상기 제1 학습된 2차원 인코더 모델, 상기 제1 학습된 coarse-level 트랜스포머 모델, 상기 제1 학습된 제1 3차원 인코더 모델, 상기 제1 학습된 제1 매칭 모델, 상기 Fine-level 트랜스포머 모델 및 제2 3차원 인코더 모델의 파라미터를 업데이트하는 제2 학습을 수행하는 제2 학습부; 및제2 학습된 2차원 인코더 모델, 제2 학습된 coarse-level 트랜스포머 모델, 제2 학습된 제1 매칭 모델, 제2 학습된 Fine-level 트랜스포머 모델 및 제2 학습된 제2 매칭을 포함하는 이미지 대응점 매칭 모델을 생성하는 대응점 매칭 모델 생성부;를 포함하는, 이미지 대응점 매칭 모델 생성 장치. </claim></claimInfo><claimInfo><claim>11. 컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은,제1항 내지 제5항 중 어느 한 항에 따른 방법을 프로세서가 수행하도록 하기 위한 명령어를 포함하는, 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 명령어를 포함하는 메모리; 및상기 명령어를 실행함으로써, 복수의 2차원 이미지를 획득하는 단계; 상기 복수의 2차원 이미지 각각으로부터 coarse-level 2차원 특징을 생성하고, 상기 coarse-level 2차원 특징 간의 제1 대응점 대응점 매칭 정보를 생성하며, 상기 제1 대응점 매칭 정보를 기반으로 상기 coarse-level 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 fine-level 2차원 특징을 생성하고, 상기 fine-level 2차원 특징 간의 제2 대응점 매칭 정보를 생성하는 단계; 및 상기 제2 대응점 매칭 정보를 상기 복수의 2차원 이미지 간의 대응점 매칭 결과로 출력하는 단계;를 포함하는, 2차원 이미지 간의 대응점 매칭 방법을 수행하는, 프로세서;를 포함하는, 이미지 대응점 매칭 모델 생성 장치.</claim></claimInfo><claimInfo><claim>13. 명령어를 포함하는 메모리; 및상기 명령어를 실행함으로써, 2차원 이미지 간의 대응점 매칭 장치가 수행하는 방법으로서,서로 상이한 위치에서 촬영된 복수의 2차원 이미지와, 상기 복수의 2차원 이미지에 대응하는 3차원 포인트 클라우드와, 상기 복수의 2차원 이미지와 상기 3차원 포인트 클라우드로 간의 실제 대응점 매칭 정보를 포함하는 학습 데이터를 획득하는 단계;2차원 인코더 모델을 이용하여, 상기 복수의 2차원 이미지 각각으로부터 2차원 특징을 생성하고, coarse-level 트랜스포머 모델을 이용하여, 상기 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 coarse-level 2차원 특징을 생성하며, 제1 3차원 인코더 모델을 이용하여, 제1 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 제1 3차원 특징을 생성하고,제1 매칭 모델을 이용하여, 상기 3차원 특징 및 상기 coarse-level 2차원 특징을 기반으로 상기 복수의 2차원 이미지 간의 제1 대응점 매칭 정보를 생성하고,상기 실제 대응점 매칭 정보를 기반으로, 상기 2차원 인코더 모델, 상기 coarse-level 트랜스포머 모델, 제1 3차원 인코더 모델 및 상기 제1 매칭 모델의 파라미터를 업데이트하는 제1 학습을 수행하는 단계;제1 학습된 2차원 인코더 모델을 이용하여, 상기 복수의 2차원 이미지 각각으로부터 제1 학습된 2차원 특징을 생성하고, 제1 학습된 coarse-level 트랜스포머 모델을 이용하여, 상기 제1 학습된 2차원 특징으로부터 상기 복수의 2차원 이미지 각각에 대한 제1 학습된 coarse-level 2차원 특징을 생성하며,제1 학습된 제1 3차원 인코더 모델을 이용하여, 상기 제1 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 업데이트된 제1 3차원 특징을 생성하고,제1 학습된 제1 매칭 모델을 이용하여, 상기 업데이트된 제1 3차원 특징 및 상기 제1 학습된 coarse-level 2차원 특징을 기반으로 상기 복수의 2차원 이미지 간의 업데이트된 제1 대응점 매칭 정보를 생성하고,Fine-level 트랜스포머 모델을 이용하여, 상기 제1 학습된 coarse-level 2차원 특징 및 상기 업데이트된 제1 대응점 매칭 정보를 기반으로 fine-level 2차원 특징을 생성하고,제2 3차원 인코더 모델을 이용하여, 상기 제1 사이즈 보다 작은 제2 사이즈의 복셀 단위로, 상기 3차원 포인트 클라우드로부터 제2 3차원 특징을 생성하고,제2 매칭 모델을 이용하여, 상기 제2 3차원 특징 및 상기 fine-level 2차원 특징을 기반으로, 상기 복수의 2차원 이미지 간의 제2 대응점 매칭 정보를 생성하고, 상기 실제 대응점 매칭 정보를 기반으로, 상기 제1 학습된 2차원 인코더 모델, 상기 제1 학습된 coarse-level 트랜스포머 모델, 상기 제1 학습된 제1 3차원 인코더 모델, 상기 제1 학습된 제1 매칭 모델, 상기 Fine-level 트랜스포머 모델 및 제2 3차원 인코더 모델의 파라미터를 업데이트하는 제2 학습을 수행하는 단계; 및제2 학습된 2차원 인코더 모델, 제2 학습된 coarse-level 트랜스포머 모델, 제2 학습된 제1 매칭 모델, 제2 학습된 Fine-level 트랜스포머 모델 및 제2 학습된 제2 매칭을 포함하는 이미지 대응점 매칭 모델을 생성하는 단계;를 포함하는, 이미지 대응점 매칭 모델 생성 방법을 수행하는 프로세서;를 포함하는, 이미지 대응점 매칭 모델 생성 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980058262</code><country>대한민국</country><engName>AGENCY FOR DEFENSE DEVELOPMENT</engName><name>국방과학연구소</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Park, Hwisung</engName><name>박휘성</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Yoon, Kuk Jin</engName><name>윤국진</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Kweon, Hyeokjun</engName><name>권혁준</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.27</receiptDate><receiptNumber>1-1-2024-0345094-49</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240042088.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93522e59d419c828ebb188cd9ea10957513a65d7874a948ea3a866c46907c5d4c996faf0015ab24fcbd1946f02a10abcd0c81c0c5f6e7e5b9d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff65f6b5fe7a7ae0584f674ea4203383a1d53618c96d9cb74c9c61b7a886e862372d3f33b29e6a766e2a97b7feb0af468757e233897a000b0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>