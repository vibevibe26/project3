<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:31.531</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0117658</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>상호작용하는 양손 모양의 어텐션 기반 암시적 표현 학습을 위한 시스템 및 그 방법</inventionTitle><inventionTitleEng>SYSTEM AND METHOD FOR LEARNING ATTENTIVE IMPLICIT  REPRESENTATION OF INTERACTING TWO-HAND SHAPES</inventionTitleEng><openDate>2025.03.12</openDate><openNumber>10-2025-0035249</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.25</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 상호작용하는 양손 모양의 어텐션 기반 암시적 표현 학습을 위한 시스템 및 그 방법이 개시된다. 상호작용하는 양손 모양의 어텐션 기반 암시적 표현 학습을 위한 시스템은, 입력 영상에 대한 3D 쿼리 포인트(query point)가 주어지는 경우 상기 3D 쿼리 포인트에 대한 3D 점유 필드(occupancy field)를 학습한 신경 암시적 표현(neural implicit representation)을 통해 상호작용하는 양손을 재건할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 장치에서 실행되는 양손 모델링 방법에 있어서,상기 컴퓨터 장치는 메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고,상기 양손 모델링 방법은,상기 적어도 하나의 프로세서에 의해, 입력 영상에 대한 3D 쿼리 포인트(query point)가 주어지는 경우 상기 3D 쿼리 포인트에 대한 3D 점유 필드(occupancy field)를 학습한 신경 암시적 표현(neural implicit representation)을 통해 상호작용하는 양손을 재건하는 단계를 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 재건하는 단계는,쿼리-이미지 어텐션(query-image attention)을 사용하여 각 손에 대한 초기 손 점유도(initial hand occupancy)를 예측하는 단계; 및쿼리-앵커 어텐션(query-anchor attention)을 사용하여 손 간의 상호작용을 고려한 양손 점유도(two-hand occupancy)를 예측하는 단계를 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 재건하는 단계는,각 손의 점유 필드를 정규화된 공간(canonical space)에서 예측하는 단계를 포함하고,상기 예측하는 단계는,상기 3D 쿼리 포인트에 대한 쿼리 정규화를 수행하여 자세에 의존하는 손 변형(pose-dependent deformations)을 포착하는 단계; 및상기 3D 쿼리 포인트에 대해 쿼리-이미지 어텐션을 사용하여 형태에 의존하는 손 변형(shape-dependent deformations)을 모델링하는 단계를 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 재건하는 단계는,두 손의 점유 필드를 자세 공간(posed space)에서 개선하는 단계를 포함하고,상기 개선하는 단계는,포인트 클라우드로 표현된 각 손의 형상을 이용하여 손 간의 상호작용을 고려한 양손 점유도를 추정하는 단계를 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 재건하는 단계는,상기 3D 쿼리 포인트가 주어지면 상기 입력 영상에 해당되는 RGB 영상과 상기 RGB 영상으로부터 추출된 양손 키포인트(two-hand keypoint)를 조건으로 하는 각 손의 초기 점유 확률을 예측하는 단계를 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 각 손의 초기 점유 확률을 예측하는 단계는,상기 3D 쿼리 포인트에 대해 정규화된 쿼리, 상기 양손 키포인트로부터 계산된 뼈 길이 피처(bone length feature)와 글로벌 자세 피처(global pose feature), 및 쿼리-이미지 어텐션을 통해 상기 3D 쿼리 포인트와 관련된 영상 패치 영역에 의한 쿼리 모양 피처(query shape feature)를 이용하여 각 손 별 정규화 공간에서의 초기 점유를 모델링하는 단계를 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 재건하는 단계는,상기 각 손의 초기 점유 확률과 상기 RGB 영상에 의해 추정된 쿼리 포인트에서 개선된 두 손 점유 확률을 예측하는 단계를 더 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 두 손 점유 확률을 예측하는 단계는,자세 공간에서 개선된 각 손의 초기 점유 필드, 초기 손 기하학에 대한 정보를 인코딩하는 로컬 잠재 디스크립터, 및 양손 상호 작용과 상기 RGB 영상의 글로벌 컨텍스트를 인코딩하는 글로벌 잠재 디스크립터의 조건화를 통해 상기 두 손 점유 확률을 추정하는 것을 특징으로 하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>9. 제5항에 있어서,상기 각 손의 초기 점유 확률을 예측하는 단계는,상기 양손 키포인트의 노이즈를 완화하는 단계를 더 포함하고,상기 완화하는 단계는,MLP(multi-layer perception)를 사용하여 상기 RGB 영상에서 초기 키포인트 피처를 추출하는 단계;상기 초기 키포인트 피처를 이용하여 두 손 골격 그래프를 구축하는 단계;상기 두 손 골격 그래프로부터 추가 키포인트 피처를 추출하는 단계; 및상기 추가 키포인트 피처를 기초로 두 손 키포인트 위치를 회귀하는 단계를 포함하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>10. 제2항에 있어서,상기 초기 손 점유도의 예측을 위한 네트워크와 상기 양손 점유도의 예측을 위한 네트워크는 실제 값(ground truth)과 예측된 점유 확률 사이의 편차를 측정하는 MSE(mean squared error) 손실에 의해 학습되는 것을 특징으로 하는 양손 모델링 방법.</claim></claimInfo><claimInfo><claim>11. 양손 모델링 방법을 컴퓨터에 실행시키기 위해 컴퓨터 판독가능한 기록 매체에 저장되는 컴퓨터 프로그램에 있어서,상기 양손 모델링 방법은,입력 영상에 대한 3D 쿼리 포인트(query point)가 주어지는 경우 상기 3D 쿼리 포인트에 대한 3D 점유 필드(occupancy field)를 학습한 신경 암시적 표현(neural implicit representation)을 통해 상호작용하는 양손을 재건하는 단계를 포함하는, 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 컴퓨터 장치에 있어서,메모리에 포함된 컴퓨터 판독가능한 명령들을 실행하도록 구성된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,입력 영상에 대한 3D 쿼리 포인트(query point)가 주어지는 경우 상기 3D 쿼리 포인트에 대한 3D 점유 필드(occupancy field)를 학습한 신경 암시적 표현(neural implicit representation)을 통해 상호작용하는 양손을 재건하는 과정을 처리하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 적어도 하나의 프로세서는,쿼리-이미지 어텐션(query-image attention)을 사용하여 각 손에 대한 초기 손 점유도(initial hand occupancy)를 예측하고,쿼리-앵커 어텐션(query-anchor attention)을 사용하여 손 간의 상호작용을 고려한 양손 점유도(two-hand occupancy)를 예측하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 적어도 하나의 프로세서는,각 손의 점유 필드를 정규화된 공간(canonical space)에서 예측하는 것으로,상기 3D 쿼리 포인트에 대한 쿼리 정규화를 수행하여 자세에 의존하는 손 변형(pose-dependent deformations)을 포착하고,상기 3D 쿼리 포인트에 대해 쿼리-이미지 어텐션을 사용하여 형태에 의존하는 손 변형(shape-dependent deformations)을 모델링하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 적어도 하나의 프로세서는,두 손의 점유 필드를 자세 공간(posed space)에서 개선하는 것으로,포인트 클라우드로 표현된 각 손의 형상을 이용하여 손 간의 상호작용을 고려한 양손 점유도를 추정하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 적어도 하나의 프로세서는,상기 3D 쿼리 포인트가 주어지면 상기 입력 영상에 해당되는 RGB 영상과 상기 RGB 영상으로부터 추출된 양손 키포인트(two-hand keypoint)를 조건으로 하는 각 손의 초기 점유 확률을 예측하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 적어도 하나의 프로세서는,상기 3D 쿼리 포인트에 대해 정규화된 쿼리, 상기 양손 키포인트로부터 계산된 뼈 길이 피처(bone length feature)와 글로벌 자세 피처(global pose feature), 및 쿼리-이미지 어텐션을 통해 상기 3D 쿼리 포인트와 관련된 영상 패치 영역에 의한 쿼리 모양 피처(query shape feature)를 이용하여 각 손 별 정규화 공간에서의 초기 점유를 모델링하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 적어도 하나의 프로세서는,상기 각 손의 초기 점유 확률과 상기 RGB 영상에 의해 추정된 쿼리 포인트에서 개선된 두 손 점유 확률을 예측하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 적어도 하나의 프로세서는,자세 공간에서 개선된 각 손의 초기 점유 필드, 초기 손 기하학에 대한 정보를 인코딩하는 로컬 잠재 디스크립터, 및 양손 상호 작용과 상기 RGB 영상의 글로벌 컨텍스트를 인코딩하는 글로벌 잠재 디스크립터의 조건화를 통해 상기 두 손 점유 확률을 추정하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서,상기 적어도 하나의 프로세서는,상기 양손 키포인트의 노이즈를 완화하는 것으로,MLP(multi-layer perception)를 사용하여 상기 RGB 영상에서 초기 키포인트 피처를 추출하고,상기 초기 키포인트 피처를 이용하여 두 손 골격 그래프를 구축하고,상기 두 손 골격 그래프로부터 추가 키포인트 피처를 추출하고,상기 추가 키포인트 피처를 기초로 두 손 키포인트 위치를 회귀하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980988661</code><country>대한민국</country><engName>Korea Advanced Institute of Science and Technology</engName><name>한국과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Kim, Tae Kyun</engName><name>김태균</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Lee, Jihyun</engName><name>이지현</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Sung, Minhyuk</engName><name>성민혁</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Choi, Honggyu</engName><name>최홍규</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로***길 ** (논현동) 삼성빌딩 *층(피앤티특허법률사무소)</address><code>920050004530</code><country>대한민국</country><engName>Yang,Sung Bo</engName><name>양성보</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.09.05</receiptDate><receiptNumber>1-1-2023-0980274-09</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.03.25</receiptDate><receiptNumber>1-1-2025-0337508-52</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230117658.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93202d7f0e18ca33d94f6137640a9a482157445f0e7ba4cc65d2fb9c82407f563185af006e5d01a671956de2d2077e95337b5603e21cde6b39</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf94a57c936f6555af5c9e9ab292c70c56379656f01b64431be60a4404cdd434835ba9a2d7449686c693f32afe3f92267822425e3e042fb9c1</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>