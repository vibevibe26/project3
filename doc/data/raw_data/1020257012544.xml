<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:13.4013</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7012544</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공지능 추론 컴파일러 및 런타임 툴 체인</inventionTitle><inventionTitleEng>AI INFERENCE COMPILER AND RUNTIME TOOL CHAIN</inventionTitleEng><openDate>2025.06.10</openDate><openNumber>10-2025-0083496</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.16</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/063</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/762</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 8/41</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 9/4401</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 실시예들은 센서 데이터를 처리하고 에고들(예: 자율 주행 차량들, 로봇들)의 하드웨어의 동작 명령어들을 생성하기 위한 시스템들 및 방법들을 포함한다. 에고는, 센서 데이터를 처리하고 에고 주변의 환경을 인식하며 에고의 행동에 대한 결정들을 내리기 위하여, 종종 뉴럴 네트워크 아키텍처들인, 임의 개수의 머신 러닝 아키텍처를 포함한다. 에고의 뉴럴 네트워크 아키텍처들은, 센서 데이터를 입력 받고, 센서 데이터를 사용하여 객체 인식 또는 경로 계획과 같은 특정 도메인 또는 작업에 관련된 임의 개수의 동작을 실행한다. 그래프 파티셔너는 특정 하드웨어 프로세싱 유닛에 뉴럴 네트워크들의 소프트웨어 내 기능들 및 센서 데이터를 할당하도록 학습되고 구성될 수 있다. 복수의 컴파일러들은 할당된 프로세싱 유닛의 유형에 기반하여 명령어들을 생성하는데 사용된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.04.04</internationOpenDate><internationOpenNumber>WO2024073115</internationOpenNumber><internationalApplicationDate>2023.09.29</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/034233</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터가, 뉴럴 네트워크 아키텍처의 복수의 서브 뉴럴 네트워크들의 복수의 기능들을 포함하는 소프트웨어 프로그래밍을 획득하는 단계; 상기 컴퓨터가, 상기 하나 이상의 서브 뉴럴 네트워크를 상기 에고(ego)의 복수의 프로세싱 유닛들에 할당하는 단계 - 각 서브 뉴럴 네트워크에 대하여 상기 컴퓨터는 상기 서브 뉴럴 네트워크의 상기 복수의 기능들을 연산하도록 프로세싱 유닛을 할당함-; 및상기 컴퓨터가, 각 서브 네트워크의 상기 복수의 기능들을 대상으로 복수의 컴파일러들을 실행하여, 상기 복수의 프로세싱 유닛들을 위한 복수의 실행 명령어들을 생성하는 단계 - 각 실행 명령어에 대해 상기 컴퓨터는, 상기 서브 뉴럴 네트워크의 상기 복수의 기능들에 할당된 상기 에고의 상기 프로세싱 유닛에 따라, 상기 복수의 컴파일러들 중 하나의 컴파일러를 사용함 -를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 컴퓨터가, 상기 복수의 서브 뉴럴 네트워크들을 실행하기 위하여, 상기 복수의 프로세싱 유닛들을 위한 상기 복수의 실행 명령어들을 포함하는 컴퓨터 파일을 생성하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 컴퓨터가, 상기 컴퓨터 파일을 상기 에고로 전송하는 단계를 더 포함하는,방법</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,적어도 하나의 실행 명령어는 상기 복수의 칩들을 포함하는 상기 에고의 회로로 하여금, 상기 복수의 실행 명령어들의 병렬 실행을 위한 확장된 컴퓨팅 모드에서 동작하도록 하는 것인, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,적어도 하나의 실행 명령어는 상기 복수의 프로세싱 유닛들을 포함하는 복수의 칩들을 포함하는 상기 에고의 회로가, 상기 복수의 칩들 중 1차 칩에 의한 상기 복수의 실행 명령어들의 1차 실행을 위한 이중화 모드에서 동작하도록 지시하는 것인,방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 컴퓨터가, 상기 실행 명령어들의 실행 스케쥴을 생성하기 위하여, 상기 실행 명령어들을 대상으로 스케쥴 옵티마이저 엔진을 적용하는 단계 - 상기 스케쥴 옵티마이저 엔진은, 지연을 최소화하기 위한 상기 실행 스케쥴을 생성하도록 학습된 뉴럴 네트워크 레이어들을 포함함 -를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 하나 이상의 프로세싱 유닛은 GPU, CPU, 액셀러레이터 디바이스 중 적어도 하나를 포함하는,방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 하나 이상의 프로세싱 유닛은 적어도 두 가지 유형의 프로세싱 유닛들을 포함하는, 이기종인,방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 컴퓨터는 상기 복수의 프로세싱 유닛들을 가지는 상기 에고의 회로 아키텍처를 나타내는 하나 이상의 그래프에 따라 상기 서브 뉴럴 네트워크를 적용하도록 상기 에고의 상기 복수의 프로세싱 유닛들 중 상기 프로세싱 유닛을 할당하는,방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 컴퓨터가, 상기 하나 이상의 프로세싱 유닛을 기반으로 한 양자화 인지 학습을 위하여, 의도된 양자화 특성을 가진 데이터를 포함하는 학습 데이터 세트를 대상으로 각 서브 뉴럴 네트워크를 적용함으로써 상기 하나 이상의 서브 뉴럴 네트워크를 학습시키는 단계 를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 시스템에 있어서, 프로세서를 포함하는 컴퓨터를 포함하고,상기 컴퓨터는뉴럴 네트워크 아키텍처의 복수의 서브 뉴럴 네트워크들의 복수의 기능들을 포함하는 소프트웨어 프로그래밍을 획득하고; 상기 하나 이상의 서브 뉴럴 네트워크를 상기 에고의 복수의 프로세싱 유닛들에 할당하고 - 각 서브 뉴럴 네트워크에 대하여 상기 컴퓨터는 상기 서브 뉴럴 네트워크의 상기 복수의 기능들을 연산하도록 프로세싱 유닛을 할당함 -; 및각 서브 네트워크의 상기 복수의 기능들을 대상으로 복수의 컴파일러들을 실행하여, 상기 에고의 상기 복수의 프로세싱 유닛들을 위한 복수의 실행 명령어들을 생성하도록 - 각 실행 명령어에 대해 상기 컴퓨터는, 상기 서브 뉴럴 네트워크의 상기 복수의 기능들에 할당된 상기 에고의 상기 프로세싱 유닛에 따라, 상기 복수의 컴파일러들 중 하나의 컴파일러를 사용함 - 구성된, 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 컴퓨터는 상기 복수의 서브 뉴럴 네트워크들을 실행하기 위하여, 상기 복수의 프로세싱 유닛들을 위한 상기 복수의 실행 명령어들을 포함하는 컴퓨터 파일을 생성하도록 더 구성된,시스템.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 컴퓨터는 상기 컴퓨터 파일을 상기 에고로 전송하도록 더 구성된,시스템.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,적어도 하나의 실행 명령어는상기 에고의 상기 복수의 칩들로 하여금, 상기 복수의 실행 명령어들의 병렬 실행을 위한 확장된 컴퓨팅 모드에서 동작하도록 하는,시스템.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서,적어도 하나의 실행 명령어는상기 에고의 상기 복수의 칩들로 하여금, 상기 복수의 칩들 중 1차 칩에 의한 상기 복수의 실행 명령어들의 1차 실행을 위한 이중화 모드에서 동작하도록 하는,시스템.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서,상기 컴퓨터는 상기 실행 명령어들의 실행 스케쥴을 생성하기 위하여, 상기 실행 명령어들을 대상으로 스케쥴 옵티마이저 엔진을 적용하도록 - 상기 스케쥴 옵티마이저 엔진은 지연을 최소화하기 위한 상기 명령어들을 생성하도록 학습된 뉴럴 네트워크 레이어들을 포함함 - 더 구성된,시스템.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서,상기 복수의 프로세싱 유닛들은 GPU, CPU, 액셀러레이터 디바이스 중 적어도 하나를 포함하는,시스템. </claim></claimInfo><claimInfo><claim>18. 제11항에 있어서,상기 복수의 프로세싱 유닛들은 적어도 두 가지 유형의 프로세싱 유닛들을 포함하는, 이기종인,시스템.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서,상기 컴퓨터는 상기 복수의 프로세싱 유닛들을 가지는 상기 에고의 회로 아키텍처를 나타내는 하나 이상의 그래프에 따라 상기 서브 뉴럴 네트워크에 상기 에고의 상기 복수의 프로세싱 유닛들 중 상기 프로세싱 유닛을 할당하는,시스템.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서,상기 컴퓨터는 상기 하나 이상의 프로세싱 유닛을 기반으로 한 양자화 인지 학습을 위하여 데이터베이스에 저장된 학습 데이터 세트를 대상으로 각 서브 뉴럴 네트워크를 적용함으로써 - 학습 데이터 세트는 의도된 양자화 특성을 가진 데이터를 포함함 - 하나 이상의 서브 뉴럴 네트워크를 학습시키도록 더 구성된,시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 텍사스 ***** 오스틴 테슬라 로드 *</address><code>520090433647</code><country>미국</country><engName>Tesla, Inc.</engName><name>테슬라, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 텍사스 ***...</address><code> </code><country>미국</country><engName>SAMPATHKUMAR, Srihari</engName><name>삼파스쿠마르, 스리하리</name></inventorInfo><inventorInfo><address>미국 텍사스 ***...</address><code> </code><country>미국</country><engName>KHORASANI, Farzad</engName><name>호라사니, 파르자드</name></inventorInfo><inventorInfo><address>미국 텍사스 ***...</address><code> </code><country>미국</country><engName>RAMES, Alexandre</engName><name>라메스, 알렉상드르</name></inventorInfo><inventorInfo><address>미국 텍사스 ***...</address><code> </code><country>미국</country><engName>SHEVCHENKO, Igor</engName><name>셰브첸코, 이고르</name></inventorInfo><inventorInfo><address>미국 텍사스 ***...</address><code> </code><country>미국</country><engName>YU, Zhenhua</engName><name>유, 전화</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.30</priorityApplicationDate><priorityApplicationNumber>63/377,954</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.16</receiptDate><receiptNumber>1-1-2025-0431425-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.05.09</receiptDate><receiptNumber>1-5-2025-0077062-52</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257012544.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b5315f492ca7c5e900291b515756768270e1996fbe7f53ab0742cf25fb0c7183d82a74a6b378948ac122ff96948151af6dca112fd44a8c31</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf40a4916ea9f0c7cb4bad33f1903bee062c532eac6b39920d766b288f300cf23bc5df2260fbdbf6577d6ec53d4cf6450cef8d0610a8dc51f4</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>