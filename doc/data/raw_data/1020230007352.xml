<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:38.038</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0007352</applicationNumber><claimCount>16</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>트랜스포머 기반 인루프 필터를 이용하는 비디오 코딩방법 및 장치</inventionTitle><inventionTitleEng>Method And Apparatus for Video Coding Using  Inloop Filter Based on Transformer</inventionTitleEng><openDate>2023.08.29</openDate><openNumber>10-2023-0125733</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/117</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/176</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/105</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/513</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 트랜스포머 기반 인루프 필터를 이용하는 비디오 코딩방법 및 장치에 관한 개시로서, 본 실시예는, 현재 비디오 블록을 딥러닝 모델인 트랜스포머(transformer)의 어텐션 모듈(attention module)에 적용하고, 이에 따른 트랜스포머 기반 인루프 필터를 이용하는 비디오 코딩방법 및 장치를 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 영상 복호화 장치가 수행하는, 복원(reconstructed) 프레임의 화질을 개선하는 방법에 있어서,상기 복원 프레임으로부터 기설정된 크기의 입력 영역을 획득하는 단계, 여기서, 상기 복원 프레임은, 원본(original) 프레임을 복원한 프레임으로서, 상기 영상 복호화 장치에 의해 사전에 복원됨; 및상기 입력 영역을 딥러닝 기반 인루프 필터(inloop filter)에 입력하여 상기 원본 프레임을 근사하는 개선 비디오 영역을 생성하는 단계를 포함하되, 상기 인루프 필터는 K(여기서, K는 자연수) 개의 연속된 트랜스포머(transformer) 블록들을 포함하고, 상기 개선 비디오 영역을 생성하는 단계는,상기 트랜스포머 블록들을 이용하여, 어텐션 연산(attention operation)을 기반으로 상기 입력 영상을 최종 출력 특성으로 변환하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 인루프 필터는 제1 CNN(Convolutional Neural Network)을 더 포함하고, 상기 개선 비디오 영역을 생성하는 단계는,상기 입력 영역을 상기 제1 CNN에 입력하여 입력 특성(feature)을 생성하는 단계; 및상기 트랜스포머 블록들을 이용하여, 상기 어텐션 연산을 기반으로 상기 입력 특성을 상기 최종 출력 특성으로 변환하는 단계를 더 포함하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 인루프 필터는 제2 CNN을 더 포함하고, 상기 개선 비디오 영역을 생성하는 단계는,상기 최종 출력 특성을 상기 제2 CNN에 입력하여 상기 개선 비디오 영역을 생성하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 변환하는 단계는,각 트랜스포머 블록의 입력 특성을 패치들로 분할하고, 각 패치에 상기 어텐션 연산을 적용하여, 상기 각 트랜스포머 블록의 입력 특성에 대해 출력 특성을 생성하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 변환하는 단계는,상기 각 패치를 큐어리로 설정하는 단계; 상기 어텐션 연산에 이용되는 두 패치들 간의 유사도에 기초하여, 상기 각 패치에 대한 셀프 어텐션 스코어(attention score), 및 상기 각 패치와 다른 패치들 간의 어텐션 스코어들을 산정하는 단계; 및상기 어텐션 스코어들을 가중합하여 상기 각 패치의 어텐션 값(attention value)을 생성하는 단계를 포함하는 것을 특징을 하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>6. 제4항에 있어서 상기 변환하는 단계는,상기 어텐션 연산에 이용되는 두 패치들의 크기가 동일하지 않은 경우, 상기 두 패치들의 크기가 동일하여지도록 패딩을 적용하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서, 상기 변환하는 단계는,상기 어텐션 연산에 이용되는 두 패치들이 상기 입력 특성에 함께 존재하지 않는 경우, 상기 어텐션 스코어를 연산하지 않는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제5항에 있어서, 상기 변환하는 단계는,상기 어텐션 연산에 이용되는 두 패치들이 상이한 데이터 처리 단위들에 존재하는 경우, 상기 어텐션 스코어를 연산하지 않되, 상기 데이터 처리 단위는, CTU(Coding Tree Unit) 또는 VPDU(Virtual Pipeline Data Unit)인 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>9. 제4항에 있어서,상기 변환하는 단계는,상기 각 패치가 기설정된 데이터 처리 단위의 경계를 벗어나는 경우, 상기 각 패치에 상기 어테션 연산을 적용하지 않고, 상기 각 패치의 일부가 상기 경계를 벗어나는 경우, 상기 경계를 벗어난 일부 영역을 표시하는 마스크(mask)를 이용하여, 상기 마스크로 표시된 영역에 대해 상기 어텐션 연산을 적용하지 않는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>10. 제4항에 있어서, 상기 변환하는 단계는,상기 각 패치가 현재블록의 복호화 순서보다 후순위에 있는 경우, 상기 각 패치에 상기 어테션 연산을 적용하지 않고, 상기 각 패치의 일부가 상기 후순위에 존재하는 경우, 상기 후순위에 존재하는 일부 영역을 표시하는 마스크를 이용하여, 상기 마스크로 표시된 영역에 대해 상기 어텐션 연산을 적용하지 않는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>11. 제4항에 있어서, 상기 각 트랜스포머 블록은,연속하는 트랜스포머 계층(transformer layer)들을 포함하고, 하나의 콘볼루션 레이어를 선택적으로 포함하며, 각 트랜스포머 계층은 하나의 인코더 층과 하나의 디코더 층을 포함하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 각 트랜스포머 블록은,스킵 연결(skip connection)을 이용하여 상기 트랜스포머 계층들의 잔차 블록(residual block) 형태로 구성되는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>13. 영상 부호화 장치가 수행하는, 복원(reconstructed) 프레임의 화질을 개선하는 방법에 있어서,상기 복원 프레임으로부터 기설정된 크기의 입력 영역을 획득하는 단계, 여기서, 상기 복원 프레임은, 원본(original) 프레임을 복원한 프레임으로서, 상기 영상 부호화 장치에 의해 사전에 복원됨; 및상기 입력 영역을 딥러닝 기반 인루프 필터(inloop filter)에 입력하여 상기 원본 프레임을 근사하는 개선 비디오 영역을 생성하는 단계를 포함하되, 상기 인루프 필터는 K(여기서, K는 자연수) 개의 연속된 트랜스포머(transformer) 블록들을 포함하고, 상기 개선 비디오 영역을 생성하는 단계는,상기 트랜스포머 블록들을 이용하여, 어텐션 연산(attention operation)을 기반으로 상기 입력 영상을 최종 출력 특성으로 변환하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 인루프 필터는 제1 CNN(Convolutional Neural Network)을 더 포함하고, 상기 개선 비디오 영역을 생성하는 단계는,상기 입력 영역을 상기 제1 CNN에 입력하여 입력 특성을 생성하는 단계; 및상기 트랜스포머 블록들을 이용하여, 상기 어텐션 연산을 기반으로 상기 입력 특성을 상기 최종 출력 특성으로 변환하는 단계를 더 포함하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 인루프 필터는 제2 CNN을 더 포함하고, 상기 개선 비디오 영역을 생성하는 단계는,상기 최종 출력 특성을 상기 제2 CNN에 입력하여 상기 개선 비디오 영역을 생성하는 것을 특징으로 하는, 방법. </claim></claimInfo><claimInfo><claim>16. 영상 부호화 방법에 의해 생성된 비트스트림을 저장하는 컴퓨터 판독 가능한 기록매체로서, 상기 영상 부호화 방법은,복원 프레임으로부터 기설정된 크기의 입력 영역을 획득하는 단계, 여기서, 상기 복원 프레임은, 원본(original) 프레임을 복원한 프레임으로서, 상기 영상 부호화 장치에 의해 사전에 복원됨; 및상기 입력 영역을 딥러닝 기반 인루프 필터(inloop filter)에 입력하여 상기 원본 프레임을 근사하는 개선 비디오 영역을 생성하는 단계를 포함하되, 상기 인루프 필터는 K(여기서, K는 자연수) 개의 연속된 트랜스포머(transformer) 블록들을 포함하고, 상기 개선 비디오 영역을 생성하는 단계는,상기 트랜스포머 블록들을 이용하여, 어텐션 연산(attention operation)을 기반으로 상기 입력 영상을 최종 출력 특성으로 변환하는 것을 특징으로 하는, 기록매체. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서초구...</address><code>119980045675</code><country>대한민국</country><engName>HYUNDAI MOTOR COMPANY</engName><name>현대자동차주식회사</name></applicantInfo><applicantInfo><address>서울특별시 서초구...</address><code>119980003181</code><country>대한민국</country><engName>Kia Corporation</engName><name>기아 주식회사</name></applicantInfo><applicantInfo><address>서울특별시 서대문구...</address><code>220040083301</code><country>대한민국</country><engName>Ewha University - Industry Collaboration Foundation</engName><name>이화여자대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 마포구...</address><code> </code><country> </country><engName>KANG, Je Won</engName><name>강제원</name></inventorInfo><inventorInfo><address>경기도 용인시 수지구...</address><code> </code><country> </country><engName>HEO, Jin</engName><name>허진</name></inventorInfo><inventorInfo><address>경기도 용인시 수지구...</address><code> </code><country> </country><engName>PARK, Seung Wook</engName><name>박승욱</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 사임당로 **, **층 (서초동, 재우빌딩)(마루특허법률사무소)</address><code>920030001993</code><country>대한민국</country><engName>Sung Byung Kee</engName><name>성병기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.02.21</priorityApplicationDate><priorityApplicationNumber>1020220022404</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.01.18</receiptDate><receiptNumber>1-1-2023-0069002-28</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.09.16</receiptDate><receiptNumber>1-1-2025-1058926-35</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230007352.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936a9b5a1d49b4e845f3be9b8893a8761f7e21cadc22c076998f975863e45babc39360d76a1ba1d8c6e34a33fc8b79030b9dfa5a784f268981</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd827885b592c6731b286fa688fd469bf6c932b4ccaa343d59db1520469a590805ad06d7d8a75ae103692e5489c7b8e7369ad044c27bf1535</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>