<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:26.5326</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.21</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0188723</applicationNumber><claimCount>21</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>경로 생성 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND DEVICE FOR GENERATING PATH</inventionTitleEng><openDate>2025.06.30</openDate><openNumber>10-2025-0097437</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>B60W 60/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B60W 40/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B60W 50/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 경로 생성 방법이 개시된다. 일 실시예에 따른 경로 생성 방법은 인식 센서 데이터 및 상태 데이터를 포함하는 입력 데이터를 획득하는 단계, 입력 데이터를 인공 신경망 모델에 입력하여, 싱글 포워드 프로세스(single forward process)로 입력 데이터에 대응하는 출력 데이터를 출력하는 단계 및 출력 데이터에 기초하여, 경로 데이터 및 경로 데이터에 대응하는 제어 데이터를 획득하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 인식 센서 데이터 및 상태 데이터를 포함하는 입력 데이터를 획득하는 단계;상기 입력 데이터를 인공 신경망 모델에 입력하여, 싱글 포워드 프로세스(single forward process)로 상기 입력 데이터에 대응하는 출력 데이터를 출력하는 단계; 및상기 출력 데이터에 기초하여, 경로 데이터 및 상기 경로 데이터에 대응하는 제어 데이터를 획득하는 단계를 포함하는 경로 생성 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 출력 데이터를 출력하는 단계는상기 입력 데이터를 상기 인공 신경망 모델에 입력하여, 복수의 예측 타임 스탬프들 각각에 대응하는 복수의 출력 엘리먼트들로 구성된 상기 출력 데이터를 출력하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제어 데이터를 획득하는 단계는상기 경로 데이터에 대응하는 스티어링(steering) 데이터를 획득하는 단계; 및상기 경로 데이터에 대응하는 가속(acceleration) 데이터를 획득하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 출력 데이터를 출력하는 단계는상기 입력 데이터를 상기 인공 신경망 모델에 입력하여, 상기 입력 데이터에 대응하는 쿼터니언(quaternion) 데이터를 출력하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 출력 데이터를 출력하는 단계는상기 입력 데이터를 상기 인공 신경망 모델에 입력하여, 상기 입력 데이터에 대응하는 듀얼 쿼터니언(dual quaternion) 데이터를 출력하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 경로 데이터 및 상기 제어 데이터를 획득하는 단계는상기 듀얼 쿼터니언 데이터를 구성하는 듀얼 쿼터니언 엘리먼트들의 좌표(coordinate)에 기초하여 상기 경로 데이터를 획득하는 단계;상기 듀얼 쿼터니언 엘리먼트들 사이의 로테이션 변환(rotation transformation) 연산에 기초하여 상기 경로 데이터에 대응하는 스티어링 데이터를 획득하는 단계; 및상기 듀얼 쿼터니언 엘리먼트들 사이의 트렌슬래이션 변환(translation transformation) 연산에 기초하여 상기 경로 데이터에 대응하는 가속 데이터를 획득하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 듀얼 쿼터니언 엘리먼트들의 좌표에 기초하여 상기 경로 데이터를 획득하는 단계는보간(interpolation) 연산을 통해 상기 듀얼 쿼터니언 엘리먼트들의 좌표 사이의 경로 데이터를 획득하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 입력 데이터를 인코더에 입력하여, 상기 입력 데이터에 대응하는 피쳐 데이터를 획득하는 단계를 더 포함하고,상기 출력 데이터를 출력하는 단계는상기 피쳐 데이터를 상기 인공 신경망 모델에 입력하여, 상기 피쳐 데이터에 대응하는 출력 데이터를 출력하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 피쳐 데이터를 획득하는 단계는상기 인식 센서 데이터를 제1 인코더에 입력하여, 상기 인식 센서 데이터에 대응하는 제1 피쳐 데이터를 획득하는 단계; 및상기 상태 데이터를 제2 인코더에 입력하여, 상기 상태 데이터에 대응하는 제2 피쳐 데이터를 획득하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 입력 데이터를 획득하는 단계는이미지 데이터 및 라이다 데이터 중 적어도 하나를 포함하는 상기 인식 센서 데이터를 획득하는 단계; 및자율 주행 장치의 속도 데이터, 방향 데이터 및 가속도 정보 중 적어도 하나를 포함하는 상기 상태 데이터를 획득하는 단계를 포함하는, 경로 생성 방법.</claim></claimInfo><claimInfo><claim>11. 하드웨어와 결합되어 제1항 내지 제10항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 적어도 하나의 명령어를 저장하는 메모리; 및상기 메모리에 저장된 명령어를 실행함으로써,인식 센서 데이터 및 상태 데이터를 포함하는 입력 데이터를 획득하고,상기 입력 데이터를 인공 신경망 모델에 입력하여, 싱글 포워드 프로세스(single forward process)로 상기 입력 데이터에 대응하는 출력 데이터를 출력하고,상기 출력 데이터에 기초하여, 경로 데이터 및 상기 경로 데이터에 대응하는 제어 데이터를 획득하는 프로세서를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 프로세서는상기 입력 데이터를 상기 인공 신경망 모델에 입력하여, 복수의 예측 타임 스탬프들 각각에 대응하는 복수의 출력 엘리먼트들로 구성된 상기 출력 데이터를 출력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 프로세서는상기 경로 데이터에 대응하는 스티어링(steering) 데이터를 획득하고,상기 경로 데이터에 대응하는 가속(acceleration) 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 프로세서는상기 입력 데이터를 상기 인공 신경망 모델에 입력하여, 상기 입력 데이터에 대응하는 쿼터니언(quaternion) 데이터를 출력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 프로세서는상기 입력 데이터를 상기 인공 신경망 모델에 입력하여, 상기 입력 데이터에 대응하는 듀얼 쿼터니언(dual quaternion) 데이터를 출력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 프로세서는상기 듀얼 쿼터니언 데이터를 구성하는 듀얼 쿼터니언 엘리먼트들의 좌표(coordinate)에 기초하여 상기 경로 데이터를 획득하고,상기 듀얼 쿼터니언 엘리먼트들 사이의 로테이션 변환(rotation transformation) 연산에 기초하여 상기 경로 데이터에 대응하는 스티어링 데이터를 획득하고,상기 듀얼 쿼터니언 엘리먼트들 사이의 트렌슬래이션 변환(translation transformation) 연산에 기초하여 상기 경로 데이터에 대응하는 가속 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서는보간(interpolation) 연산을 통해 상기 듀얼 쿼터니언 엘리먼트들의 좌표 사이의 경로 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제12항에 있어서,상기 프로세서는상기 입력 데이터를 인코더에 입력하여, 상기 입력 데이터에 대응하는 피쳐 데이터를 획득하고,상기 피쳐 데이터를 상기 인공 신경망 모델에 입력하여, 상기 피쳐 데이터에 대응하는 출력 데이터를 출력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 프로세서는상기 인식 센서 데이터를 제1 인코더에 입력하여, 상기 인식 센서 데이터에 대응하는 제1 피쳐 데이터를 획득하고,상기 상태 데이터를 제2 인코더에 입력하여, 상기 상태 데이터에 대응하는 제2 피쳐 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>21. 제12항에 있어서,이미지 데이터 및 라이다 데이터 중 적어도 하나를 포함하는 상기 인식 센서 데이터를 획득하는 제1 센서부; 및자율 주행 장치의 속도 데이터, 방향 데이터 및 가속도 정보 중 적어도 하나를 포함하는 상기 상태 데이터를 획득하는 제2 센서부를 더 포함하는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420220660891</code><country>대한민국</country><engName>JUNG, Younghwa</engName><name>정용화</name></inventorInfo><inventorInfo><address>경기도 용인시 수지구...</address><code>420200358138</code><country>대한민국</country><engName>CHOI, Jae Seok</engName><name>최재석</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.21</receiptDate><receiptNumber>1-1-2023-1440596-08</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230188723.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936c4c8f55f7f72fe19a419ee7fb5640988c2b994e8d80e90a3d81d83b6733786cec944f4651f642f6f182fba16e4f896e5e8eac63ddbd94e8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf68335ebf85af476bfb480b0d88aefe0a74e95b68495807425961afedc02348c9763d396e49836626862f074adbcec0081ebdc6f05e8024ef</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>