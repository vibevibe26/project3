<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:36:48.3648</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0100562</applicationNumber><claimCount>8</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법</inventionTitle><inventionTitleEng>Method for building a training dataset to learn  language models for various schema</inventionTitleEng><openDate>2025.02.11</openDate><openNumber>10-2025-0019759</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.08.01</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/088</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/2452</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/242</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/248</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/21</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/279</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법에 관한 것으로, (a) 자연어 질문이 입력으로 들어오면, 데이터 생성부가 엔티티 링커(Entity Linker)를 통해 엔티티 링킹 정보를 생성하고 스키마 리트리버(Schema Retriever)를 통해 DB 스키마 정보를 생성하는 단계와, (b) 입력으로 들어온 자연어 질문으로 엔티티 링킹 정보와 DB 스키마 정보가 생성된 후에, 데이터 생성부가 〔자연어 질문, 엔티티 링킹 정보, DB 스키마 정보〕를 입력값(Input)으로 하여 쿼리 생성기를 통해 자연어 질문에 대한 쿼리문(Output)을 생성하는 단계에 의해 학습 데이터셋인 〔자연어 질문, 엔티티 링킹 정보, DB 스키마 정보, 쿼리문〕을 구축함으로써, 언어 모델이 임의의 다양한 그래프 데이터베이스에 입력되는 사용자의 자연어 질문을 DB 스키마에 적합한 쿼리문으로 변환할 수 있도록, 다양한 그래프 데이터베이스에 대해 자연어 질문상 엔티티에 연결된 스키마를 효과적으로 학습할 수 있는 학습 데이터셋의 효율적인 구축이 가능하다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. (a) 자연어 질문이 입력으로 들어오면, 데이터 생성부(11)가 엔티티 링커(Entity Linker)를 통해 엔티티 링킹 정보를 생성하고 스키마 리트리버(Schema Retriever)를 통해 DB 스키마 정보를 생성하는 단계(S10)와,(b) 입력으로 들어온 자연어 질문으로 엔티티 링킹 정보와 DB 스키마 정보가 생성된 후에, 데이터 생성부(11)가 〔자연어 질문, 엔티티 링킹 정보, DB 스키마 정보〕를 입력값(Input)으로 하여 쿼리 생성기를 통해 자연어 질문에 대한 쿼리문(Output)을 생성하는 단계(S20)에 의해 학습 데이터셋인 〔자연어 질문, 엔티티 링킹 정보, DB 스키마 정보, 쿼리문〕을 구축하는 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 엔티티 링커와 스키마 리트리버로는 BERT, RoBERTa, DeBERTa와 같은 언어 모델(LM)이 활용되고, 상기 쿼리 생성기로는 ChatGPT, GPT4, alpaca와 같은 대규모 언어 모델(LLM)이 활용되는 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,생성된 학습 데이터셋인 〔자연어 질문, 엔티티 링킹 정보, DB 스키마 정보, 쿼리문〕에서 상기 쿼리문이 원하는 타겟(Target, 정답값인 Output)인지를 또 다른 대규모 언어 모델(LLM)인 쿼리 검수기를 통해 검수하며, 상기 검수를 통해 원하는 타겟이 아닌 쿼리문은 제외시키는 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,(c) 학습 데이터셋이 구축된 후에, 데이터 증강부(12)가 상기 자연어 질문과 쿼리문을 템플릿화하는 단계(S30)와;(d) 데이터 증강부(12)가 상기 사용자 질문이 질의하는 데이터베이스(DB)와 동일한 데이터베이스(DB)내에서 기존 쿼리 구조와 동일한 구조를 가지는 엔티티를 선택하여 자연어 질문에 포함된 엔티티를 대체하고 쿼리문의 엔티티를 교체하며, 엔티티 링커(Entity Linker)를 통해 엔티티 링킹 정보를 생성하고 스키마 리트리버(Schema Retriever)를 통해 DB 스키마 정보를 생성하는 단계(S40), 및(e) 데이터 증강부(12)가 상기 단계(d)에서 엔티티가 대체된 자연어 질문에 대해 AI 패러프레이징을 통해 증강하는 단계(S50)가 추가로 이루어지되,상기 AI 패러프레이징은 상기 단계(d)에서 생성된 엔티티 링킹 정보와 DB 스키마 정보의 결과가 유지될 수 있도록 AI 페러프레이징 모델을 통해 의미가 동일하거나 비슷한 자연어 질문으로 확장 생성하여 학습 데이터셋인 〔패러프레이징된 자연어 질문, 엔티티 링킹 정보, DB 스키마 정보, 쿼리문〕을 추가로 구축하는 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,(f) 데이터 구축부(10)에서의 자연어 질문과는 다른 자연어 질문이 입력으로 들어오면, DB 정보 생성부(21)가 엔티티 링커(Entity Linker)를 통해 엔티티 링킹 정보를 생성하고 스키마 리트리버(Schema Retriever)를 통해 DB 스키마 정보를 생성하는 단계(S60)와;(g) DB 정보 대조부(22)가 상기 단계(f)에서 생성된 DB 스키마 정보를 데이터 구축부(10)에서 생성된 DB 스키마 정보와 비교함으로써, 상기 단계(f)에서의 자연어 질문이 데이터 구축부(10)에서의 자연어 질문과 비교하여 새로운 자연어 질문이어서 갱신이 필요한지 판정하는 단계(S70), 및(h) 상기 단계(g)에서 상기 단계(f)에서의 자연어 질문이 새로운 자연어 질문으로 판정되면 다시 데이터 생성부(11') 및 데이터 증강부(12')로 진행하는 단계(S80)가 추가로 이루어짐으로써, 데이터 갱신부(20)를 통해 만들어진 갱신된 학습 데이터셋이 상기 데이터 구축부(10)에서 생성된 학습 데이터셋에 추가되는 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo><claimInfo><claim>6. 제 1 항, 제 4 항 및 제 5 항 중 어느 한 항에 있어서,엔티티 링킹 정보 생성시 엔티티 링커(Entity Linker)에 의한 엔티티 링킹(Entity Linking)은,(i) Mention Detection 알고리즘을 통해 자연어 질문 내에서 Mention(엔티티 후보군)을 추출하는, 자연어 질문상 엔티티 후보군 탐지(Mention Detection) 단계(S61)와;(j) 자연어 질문과 Mention Detection을 통해 인식한 Mention이 입력으로 들어왔을 때에, 자연어 질문에 대한 DB에 존재하는 엔티티 중 자연어 질문에 존재하는 Mention과 유사한 상위 엔티티 후보군을 산출하는, DB상 엔티티 후보군 생성(Candidate Generation) 단계(S62), 및(k) 상기 상위 엔티티 후보군 중 가장 유사한 엔티티를 선택하는 단계(S63)로 이루어지되,상기 단계(j)에서 상위 엔티티 후보군 산출은 엔티티에 대한 점숫값 산출식인 다음의 수학식, (여기서, i는 엔티티 후보군의 인덱스,   = LM(자연어 질문 + Mention)으로 Mention이 인식된 자연어 질문에 대한 벡터 표현,  = LM(엔티티 및 설명)으로 엔티티에 대한 벡터 표현, LM은 언어 모델)을 이용하여 각각의 엔티티 후보군에 대해 점숫값을 산출하고 산출된 점숫값 중에서 상위 k개의 엔티티 후보군을 선택하는 것이고,상기 단계(k)에서 가장 유사한 엔티티의 선택은 엔티티에 대한 점숫값 산출식인 다음의 수학식, (여기서, i는 1부터 k까지인데 k는 상기 상위 점숫값을 갖는 선택된 엔티티 후보군의 갯수, linear_layer는 레이어가 하나인 모델,  = LM(자연어 질문 + Mention + 엔티티 및 설명)으로 언어 모델(LM)의 입력값으로 상기 (자연어 질문 + Mention)과 (엔티티 및 설명)을 합친 것)을 이용하여 k개의 각각의 엔티티 후보군에 대해 점숫값을 산출하고 점숫값이 제일 높은 해당 엔티티 후보군을 엔티티 링킹 정보로 결정하는 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,DB 스키마 정보 생성시 스키마 리트리버(Schema Retriever)에 의한 스키마 리트리벌(Schema Retrieval)은 DB 스키마에 대한 점숫값 산출식인 다음의 수학식, (여기서, linear_layer는 레이어가 하나인 모델, j는 점숫값이 제일 높은 상기 엔티티 후보군과 관련된 DB 스키마 인덱스,  = LM(자연어 질문 + schema_j)로 스키마에 대한 벡터 표현,  schema_j는 점숫값이 제일 높은 상기 엔티티 후보군과 관련된 DB 스키마, LM은 언어 모델)을 이용하여 각각의 DB 스키마에 대해 점숫값을 산출하고 산출된 점숫값 중에서 상위 n개의 점숫값을 갖는 해당 DB 스키마를 추출하여 생성되는 DB 스키마 정보는 (자연어 질문 + schema_top1 + schema_top2 + schema_top3 + ... + schema_topn)인 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo><claimInfo><claim>8. 제 7 항에 있어서,상기 단계(g)는,DB 정보 대조부(22)가 상기 DB 정보 생성부(21)에서 만들어진 DB 스키마 정보를 상기 데이터 구축부(10)에서 구축된 학습 데이터셋의 DB 스키마 정보와 비교하여 유사도값인  다음 수학식,  (여기서, 은 데이터 구축부에서의 스키마에 대한 벡터 표현, 은 DB 정보 생성부에서의 스키마에 대한 벡터 표현, 와 은 각각 로 산출, n은 상위 n개의 DB 스키마 추출시의 n)의 유사도값이 임계값 이하인 경우에 상기 DB 정보 생성부(21)에 입력으로 들어오는 자연어 질문이 상기 데이터 구축부(10)에서의 자연어 질문과 비교하여 새로운 자연어 질문이어서 갱신이 필요한 것으로 판정하는 것을 특징으로 하는, 다양한 스키마에 대해 언어 모델을 학습시키기 위한 학습 데이터셋 구축 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서초구...</address><code>120230429651</code><country>대한민국</country><engName>NICK syndicate Co., Ltd.</engName><name>주식회사 닉신디케이트</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 관악구...</address><code> </code><country> </country><engName>Yang, Jong-Hyeon</engName><name>양종현</name></inventorInfo><inventorInfo><address>경기도 김포시 김포한강**로 ***,...</address><code> </code><country> </country><engName>Son, Hwa-Min</engName><name>손화민</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 효령로 *** (서초동) 대호빌딩 *층 ***호(파코국제특허법률사무소)</address><code>920050008669</code><country>대한민국</country><engName>Son Tae Won</engName><name>손태원</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.01</receiptDate><receiptNumber>1-1-2023-0848719-51</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.08.11</receiptDate><receiptNumber>1-1-2023-0887618-07</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.06.13</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230100562.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d57a9a8fd3aec1f7761c088c2562f79288314589a2b296d39171380cc58184f7ac4bb9ac88a13a7be73b6f7728322f60999975bd0a4dcbdf</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf85b6521c68bd28322f08e377659caaa2de5f282064a725786b6274f0cf19eb82c9458e41af923af646e54d9119870615f3b9cb887ac77eb7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>