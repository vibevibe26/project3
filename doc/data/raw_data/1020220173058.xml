<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:05.65</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.12</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0173058</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>메타 렌즈를 이용하여 획득한 이미지를 처리하는 전자 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>AN ELECTRONIC DEVICE FOR PROCESSING AN IMAGE OBTAINED  BY META LENS AND A METHOD FOR OPERATING THE SAME</inventionTitleEng><openDate>2024.03.15</openDate><openNumber>10-2024-0035296</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/55</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/54</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G03B 17/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 메타 렌즈를 이용하여 획득된 이미지로부터 객체의 인식 결과를 획득하는 전자 장치 및 그 동작 방법을 제공한다. 본 개시의 일 실시예에 따른 전자 장치는 표면에 서로 다른 형태, 높이, 및 넓이를 갖는 복수의 기둥(pillar) 또는 핀으로 구성된 패턴이 형성된 메타 렌즈, 객체로부터 반사되어 메타 렌즈를 투과한 위상 변조된 광을 수신하고, 수신된 광을 전기적 신호로 변환하여 부호화 이미지(coded image)를 획득하는 이미지 센서, 및 인공지능(Artificial Intelligence) 모델에 부호화 이미지를 입력하고, 인공지능 모델을 이용하는 추론을 통해 객체의 인식 결과를 나타내는 라벨(label)을 획득하는 적어도 하나의 프로세서(130)를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 표면에 서로 다른 형태, 높이, 및 넓이를 갖는 복수의 기둥(pillar) 또는 핀으로 구성된 패턴이 형성되고, 상기 표면의 패턴을 통해 객체로부터 반사된 광의 위상을 변조하는 광학 특성을 갖는 메타 렌즈(metalens)(110); 객체로부터 반사되어 상기 메타 렌즈(110)를 투과한 위상 변조된 광을 수신하고, 수신된 광을 전기적 신호로 변환하여 부호화 이미지(coded image)를 획득하는 이미지 센서(120); 및인공지능(Artificial Intelligence) 모델에 상기 부호화 이미지를 입력하고, 상기 인공지능 모델(200)을 이용하는 추론을 통해 상기 객체의 인식 결과를 나타내는 라벨(label)을 획득하는 적어도 하나의 프로세서(130); 를 포함하고, 상기 인공지능 모델(200)은, RGB 이미지를 상기 메타 렌즈(110)의 광학 특성을 반영한 모델에 입력하여 시뮬레이션 이미지를 획득하고, 상기 획득된 시뮬레이션 이미지의 인식 결과 상기 입력된 RGB 이미지의 정답 값(ground truth)을 나타내는 라벨을 출력하도록 학습된 신경망 모델(neural network model)이고, 상기 인공지능 모델(200)은 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도를 나타내는 정보가 최소화되도록 학습된, 전자 장치(100). </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 메타 렌즈(110)의 표면 패턴을 형성하는 상기 복수의 기둥 또는 핀의 형태, 높이, 및 넓이는 상기 인공지능 모델(200)의 학습 결과에 따른 수학적 모델링 파라미터에 기초하여 형성된, 전자 장치(100). </claim></claimInfo><claimInfo><claim>3. 제1 항 및 제2 항 중 어느 하나의 항에 있어서,상기 인공지능 모델(200)은, 상기 메타 렌즈(110)의 광학 특성을 수학적으로 모델링한 점 퍼짐 함수(point spread function)를 상기 RGB 이미지와 컨볼루션(convolution)하여 상기 RGB 이미지로부터 상기 시뮬레이션 이미지를 출력하도록 학습된 제1 인공지능 모델(210) 및 상기 시뮬레이션 이미지로부터 상기 RGB 이미지의 정답 값을 나타내는 라벨을 출력하도록 학습된 제2 인공지능 모델(220)을 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 제2 인공지능 모델(220)에 상기 부호화 이미지를 입력하고, 상기 제2 인공지능 모델(220)에 의한 추론을 통해 상기 부호화 이미지의 인식 결과에 따른 상기 라벨을 획득하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서, 상기 제1 인공지능 모델(210)은,상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도를 나타내는 상관 관계 정보(mutual information)가 최소화되도록 상기 상관 관계 정보를 손실값(loss)으로 적용하는 역 전파(back propagation)를 통해 가중치들(weights)을 업데이트함으로써 학습된, 전자 장치(100). </claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 제1 인공지능 모델(210)은,상기 RGB 이미지 및 상기 시뮬레이션 이미지 간의 벡터 공간 상의 분포의 상관 관계를 나타내는 KL-divergence를 최소화함으로써, 상기 손실값을 최소화하도록 학습된, 전자 장치(100). </claim></claimInfo><claimInfo><claim>6. 제4 항에 있어서, 상기 인공지능 모델(200)은 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 비유사도(dissimilarity)를 나타내는 손실 값을 연산하는 제3 인공지능 모델(230)을 더 포함하고, 상기 제3 인공지능 모델(230)은,상기 시뮬레이션 이미지에 기초하여 상기 RGB 이미지를 모조한 가짜 이미지(fake image)를 생성하도록 학습된 복원 모델(reconstruction model) 및 입력된 이미지가 상기 RGB 이미지인지 또는 상기 복원 모델에 의해 생성된 가짜 이미지인지 여부를 판별하는 판별 모델(discriminator model)을 포함하는, 전자 장치(100).  </claim></claimInfo><claimInfo><claim>7. 제1 항 내지 제6 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은, 상기 입력된 부호화 이미지로부터 특징 맵(feature map)을 추출하도록 학습된 백본 네트워크(backbone network) 및 상기 특징 맵으로부터 상기 부호화 이미지의 인식 결과를 나타내는 라벨을 출력하도록 학습된 헤드 네트워크(head network)를 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 인공지능 모델(200)을 이용하여 인식하고자 하는 비전 태스크(vision task)의 목적 또는 용도에 기초하여 상기 백본 네트워크 및 상기 헤드 네트워크 중 적어도 하나를 변경하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서, 상기 헤드 네트워크가 상기 비전 태스크의 목적 또는 용도에 따라 변경되는 경우 상기 백본 네트워크의 구조는 상기 변경된 헤드 네트워크에 관계없이 동일하게 적용되는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은,사용자에 의한 상기 메타 렌즈(110)의 교체 또는 변경을 인식하는 메타렌즈 프로파일러 모델(metalens profiler)을 더 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 메타렌즈 프로파일러 모델을 통해 상기 메타 렌즈(110)의 교체 또는 변경이 인식된 경우, 교체 또는 변경된 메타 렌즈(110)에 대응되는 비전 태스크를 식별하고, 상기 인공지능 모델(200)의 백본 네트워크 및 헤드 네트워크를 상기 식별된 비전 태스크에 최적화된 모델로서 미리 결정된 백본 네트워크 및 헤드 네트워크로 변경하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 하나의 항에 있어서, 객체의 깊이 값을 측정하도록 구성된 깊이 센서(depth sensor); 및 상기 객체로부터 음향 신호를 획득하는 오디오 센서(audio sensor);를 더 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 깊이 센서에 의해 측정된 상기 객체의 깊이 값 및 상기 오디오 센서에 의해 획득된 상기 음향 신호를 상기 인공지능 모델(200)에 입력하고, 상기 인공지능 모델(200)을 이용하는 추론을 통해 상기 객체의 인식 결과에 따른 라벨을 획득하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>11. 전자 장치(100)가 메타 렌즈(110)를 통해 획득된 이미지로부터 객체의 인식 결과를 획득하는 방법에 있어서, 객체로부터 반사되어 상기 메타 렌즈(110)를 투과한 위상 변조된 광을 수신하고, 수신된 광을 전기적 신호로 변환하여 부호화 이미지(coded image)를 획득하는 단계(S510); 및인공지능(Artificial Intelligence) 모델에 상기 부호화 이미지를 입력하고, 상기 인공지능 모델(200)을 이용하는 추론을 통해 상기 객체의 인식 결과를 나타내는 라벨(label)을 획득하는 단계(S520);를 포함하고, 상기 인공지능 모델(200)은, RGB 이미지를 상기 메타 렌즈(110)의 광학 특성을 반영한 모델에 입력하여 시뮬레이션 이미지를 획득하고, 상기 획득된 시뮬레이션 이미지의 인식 결과 상기 입력된 RGB 이미지의 정답 값(ground truth)을 나타내는 라벨을 출력하도록 학습된 신경망 모델(neural network model)이고, 상기 인공지능 모델(200)은 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도를 나타내는 정보가 최소화되도록 학습된, 방법. </claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서, 상기 메타 렌즈(110)의 표면에는 서로 다른 형태, 높이, 및 넓이를 갖는 복수의 기둥(pillar) 또는 핀으로 구성된 패턴이 형성되고, 상기 메타 렌즈(110)의 표면의 패턴을 형성하는 상기 복수의 기둥 또는 핀의 형태, 높이, 및 넓이는 상기 인공지능 모델(200)의 학습 결과에 따른 수학적 모델링 파라미터에 기초하여 형성된, 방법. </claim></claimInfo><claimInfo><claim>13. 제11 항 및 제12 항 중 어느 하나의 항에 있어서,상기 인공지능 모델(200)은, 상기 메타 렌즈(110)의 광학 특성을 수학적으로 모델링한 점 퍼짐 함수(point spread function)를 상기 RGB 이미지와 컨볼루션(convolution)하여 상기 RGB 이미지로부터 상기 시뮬레이션 이미지를 출력하도록 학습된 제1 인공지능 모델(210) 및 상기 시뮬레이션 이미지로부터 상기 RGB 이미지의 정답 값을 나타내는 라벨을 출력하도록 학습된 제2 인공지능 모델(220)을 포함하고, 상기 라벨을 획득하는 단계(S520)는, 상기 제2 인공지능 모델(220)에 상기 부호화 이미지를 입력하고, 상기 제2 인공지능 모델(220)에 의한 추론을 통해 상기 부호화 이미지의 인식 결과에 따른 상기 라벨을 획득하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서, 상기 제1 인공지능 모델(210)은,상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도를 나타내는 상관 관계 정보(mutual information)가 최소화되도록 상기 상관 관계 정보를 손실값(loss)으로 적용하는 역 전파(back propagation)를 통해 가중치들(weights)을 업데이트함으로써 학습된, 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서, 상기 제1 인공지능 모델(210)은,상기 RGB 이미지 및 상기 시뮬레이션 이미지 간의 벡터 공간 상의 분포의 상관 관계를 나타내는 KL-divergence를 최소화함으로써, 상기 손실값을 최소화하도록 학습된, 방법. </claim></claimInfo><claimInfo><claim>16. 제14 항에 있어서, 상기 인공지능 모델(200)은 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 비유사도(dissimilarity)를 나타내는 손실 값을 연산하는 제3 인공지능 모델(230)을 더 포함하고, 상기 제3 인공지능 모델(230)은,상기 시뮬레이션 이미지에 기초하여 상기 RGB 이미지를 모조한 가짜 이미지(fake image)를 생성하도록 학습된 복원 모델(reconstruction model) 및 입력된 이미지가 상기 RGB 이미지인지 또는 상기 복원 모델에 의해 생성된 가짜 이미지인지 여부를 판별하는 판별 모델(discriminator model)을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>17. 제11 항 내지 제16 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은, 상기 입력된 부호화 이미지로부터 특징 맵(feature map)을 추출하도록 학습된 백본 네트워크(backbone network) 및 상기 특징 맵으로부터 상기 부호화 이미지의 인식 결과를 나타내는 라벨을 출력하도록 학습된 헤드 네트워크(head network)를 포함하고, 상기 라벨을 획득하는 단계(S520)는,상기 인공지능 모델(200)을 이용하여 인식하고자 하는 비전 태스크(vision task)의 목적 또는 용도에 기초하여 상기 백본 네트워크 및 상기 헤드 네트워크 중 적어도 하나를 변경하는 단계(S910); 및상기 백본 네트워크 및 상기 헤드 네트워크 중 적어도 하나가 변경된 상기 인공지능 모델(200)에 상기 부호화 이미지를 입력하여, 상기 부호화 이미지의 인식 결과를 나타내는 라벨을 출력하는 단계(S920);를 포함하는, 방법,</claim></claimInfo><claimInfo><claim>18. 제11 항 내지 제17 항 중 어느 하나의 항에 있어서, 사용자에 의한 상기 메타 렌즈(110)의 교체 또는 변경을 인식하는 단계(S1210); 상기 교체 또는 변경된 메타 렌즈(110)에 대응되는 비전 태스크를 식별하는 단계(S1220); 및상기 인공지능 모델(200)의 백본 네트워크 및 헤드 네트워크를 상기 식별된 비전 태스크에 최적화된 모델로서 미리 결정된 백본 네트워크 및 헤드 네트워크로 변경하는 단계(S1230);를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제11 항 내지 제18 항 중 어느 하나의 항에 있어서, 깊이 센서로부터 상기 객체의 깊이 값을 획득하는 단계; 및오디오 센서로부터 상기 객체로부터 음향 신호를 획득하는 단계; 를 더 포함하고, 상기 라벨을 획득하는 단계(S520)는,상기 깊이 센서에 의해 측정된 상기 객체의 깊이 값 및 상기 오디오 센서에 의해 획득된 상기 음향 신호를 상기 인공지능 모델(200)에 입력하고, 상기 인공지능 모델(200)을 이용하는 추론을 통해 상기 객체의 인식 결과에 따른 라벨을 획득하는, 방법. </claim></claimInfo><claimInfo><claim>20. 제11 항 내지 제19 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Jung Min</engName><name>이정민</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Young O</engName><name>박영오</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>CHOI, Kwang Pyo</engName><name>최광표</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.09.08</priorityApplicationDate><priorityApplicationNumber>1020220114496</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.12</receiptDate><receiptNumber>1-1-2022-1335560-90</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220173058.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9353750368cfa243cd384728bf8a13fbe6e730e3a1f517924d00e1349810ba3906e28fecaaea80d31bfce1b1fdc5cac9a299454d3a06f6eef6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe6c0a37e5419bd01e5f27e308f5bedd184eef6dea7877214b60ce2dbe0fa9d1e17169290b52dd09bb0fdd2b0b3b727ba99f19dc8e57688aa</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>