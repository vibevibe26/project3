<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:55:49.5549</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.06</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2023-0015515</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>트랜스포머 기반 생성 작업들에 대한 추론 시스템을 위한 선택적 배칭</inventionTitle><inventionTitleEng>SELECTIVE BATCHING FOR INFERENCE SYSTEM FOR  TRANSFORMER-BASED GENERATION TASKS</inventionTitleEng><openDate>2023.06.12</openDate><openNumber>10-2023-0084104</openNumber><originalApplicationDate>2022.08.22</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2022-0104647</originalApplicationNumber><originalExaminationRequestDate>2023.02.06</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/063</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 5/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020220104647</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 추론 시스템은, 트랜스포머 모델에서의 연산들의 서브세트를 선택적으로 배칭하지만 트랜스포머 모델에서의 연산들의 서브세트에 대해 개별적으로 배치 내의 요청들을 처리함으로써, 가변 입력 길이 또는 가변 타겟 길이 또는 가변 내부 상태 길이를 갖는 요청들의 배치에 기계 학습 트랜스포머 모델을 적용한다. 일 실시예에서, 개별적으로 처리될 연산은, 트랜스포머 모델의 인코더 또는 디코더의 주의집중 연산이다. 선택적 배칭에 의해, 추론 시스템은, 요청들의 배치의 데이터를 동일한 길이로 제한하는 차선책들에 대해 발생하는 불필요한 계산들을 방지하면서, 하드웨어 가속기들의 병렬 계산 능력들을 활용하도록, 가변 입력 또는 타겟 길이 또는 내부 상태 길이를 갖는 요청들의 배치에 대해 배칭 연산들이 수행될 수 있게 할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 기계 학습 모델을 적용함으로써 요청들의 배치(batch)를 실행하는 방법으로서,하나 이상의 토큰 시퀀스를 포함하는 배치를 수신하는 단계 - 상기 배치 내의 제1 토큰 시퀀스의 길이는 상기 배치 내의 제2 토큰 시퀀스의 길이와 상이함 -; 기계 학습 모델에 액세스하는 단계;하나 이상의 출력 표현을 생성하는 단계를 포함하고, 상기 생성하는 단계는, 하나 이상의 질의, 하나 이상의 키, 및 하나 이상의 값을 획득하는 단계 - 상기 하나 이상의 질의는 하나 이상의 입력 표현에 질의 가중 텐서를 적용함으로써 생성되고, 적어도 상기 하나 이상의 질의는 배치 연산에 의해 생성됨 -, 상기 하나 이상의 질의로부터 상기 제1 토큰 시퀀스에 대한 제1 질의를, 상기 하나 이상의 키로부터 제1 키를, 그리고 상기 하나 이상의 값으로부터 제1 값을 분할하고, 상기 하나 이상의 질의로부터 상기 제2 토큰 시퀀스에 대한 제2 질의를, 상기 하나 이상의 키로부터 제2 키를, 그리고 상기 하나 이상의 값으로부터 제2 값을 분할하는 단계,적어도, 상기 제1 질의, 상기 제1 키, 및 상기 제1 값을 조합함으로써, 제1 주의집중(attention) 출력을 생성하는 단계,적어도, 상기 제2 질의, 상기 제2 키, 및 상기 제2 값을 조합함으로써, 제2 주의집중 출력을 별개로 생성하는 단계,적어도 상기 제1 주의집중 출력 및 상기 제2 주의집중 출력을 연접된 텐서로 연접시키는 단계, 및 적어도 상기 연접된 텐서에 하나 이상의 가중 텐서를 적용함으로써, 하나 이상의 출력 표현을 생성하는 단계 - 상기 하나 이상의 출력 표현은 배치 연산에 의해 생성됨 -를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 기계 학습 모델은 한 세트의 디코더들을 포함하고, 디코더에 대한 상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하는 단계는,상기 질의 가중 텐서, 키 가중 텐서, 및 값 가중 텐서를 포함하는 QKV 가중 텐서를 상기 하나 이상의 입력 표현에 적용하는 단계를 포함하고, 상기 하나 이상의 입력 표현은 이전 디코더로부터의 하나 이상의 출력 표현 또는 상기 하나 이상의 토큰 시퀀스로부터 생성되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 기계 학습 모델은 한 세트의 인코더들 및 상기 한 세트의 인코더들에 결합된 한 세트의 디코더들을 포함하고, 상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하는 단계는,상기 한 세트의 인코더들 내의 적어도 하나의 인코더로부터 상기 하나 이상의 키 및 상기 하나 이상의 값을 획득하는 단계 - 상기 하나 이상의 키는 상기 키 가중 텐서를 상기 인코더의 하나 이상의 출력 표현에 적용함으로써 생성되고, 상기 하나 이상의 값은 상기 값 가중 텐서를 상기 인코더의 상기 하나 이상의 출력 표현에 적용함으로써 생성됨 -; 및상기 하나 이상의 입력 표현에 상기 질의 가중 텐서를 적용함으로써 디코더에 대한 상기 하나 이상의 질의를 생성하는 단계를 포함하고, 상기 하나 이상의 입력 표현은 이전 디코더로부터의 하나 이상의 출력 표현 또는 상기 하나 이상의 토큰 시퀀스로부터 생성되는, 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하기 전에, 자기-주의집중(self-attention) 계층에 입력하기 위한 하나 이상의 제3 질의, 하나 이상의 제3 키, 및 하나 이상의 제3 값을 획득하는 단계,적어도, 상기 하나 이상의 제3 질의, 상기 하나 이상의 제3 키, 및 상기 하나 이상의 제3 값을 조합함으로써 주의집중 출력들을 생성하는 단계를 더 포함하고, 상기 하나 이상의 질의를 생성하기 위한 상기 하나 이상의 입력 표현은 상기 자기-주의집중 계층으로부터의 상기 주의집중 출력들로부터 생성되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서, 상기 인코더는 상기 한 세트의 인코더들 내의 최종 인코더인, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 기계 학습 모델은 한 세트의 인코더들을 포함하고, 인코더에 대한 상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하는 단계는,상기 질의 가중 텐서, 키 가중 텐서, 및 값 가중 텐서를 포함하는 QKV 가중 텐서를 상기 하나 이상의 입력 표현에 적용하는 단계를 포함하고, 상기 하나 이상의 입력 표현은 이전 인코더로부터의 하나 이상의 출력 표현 또는 상기 하나 이상의 토큰 시퀀스로부터 생성되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 연접된 입력 텐서를 생성하기 위해 상기 배치에 대한 상기 하나 이상의 토큰 시퀀스 내의 토큰들을 단일 차원을 따라 연접시키는 단계를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 적어도 상기 제1 주의집중 출력 및 상기 제2 주의집중 출력을 상기 연접된 텐서로 연접시키는 단계는 상기 연접된 텐서를 생성하기 위해 상기 제1 주의집중 출력 및 상기 제2 주의집중 출력의 요소들을 단일 차원을 따라 연접시키는 단계를 더 포함하는, 방법.  </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 제1 주의집중 출력은 적어도 상기 제1 질의, 상기 제1 키, 및 상기 제1 값에 대해 한 세트의 연산들을 실행함으로써 생성되고, 상기 제2 주의집중 출력은 적어도 상기 제2 질의, 상기 제2 키, 및 상기 제2 값에 대해 제2 세트의 연산들을 실행함으로써 생성되고, 상기 한 세트의 연산들은 실행 엔진의 제1 커널 상에서 실행되고, 상기 제2 세트의 연산들은 상기 실행 엔진의 제2 커널 상에서 또는 제2 실행 엔진 상에서 실행되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 제1 주의집중 출력은 적어도 상기 제1 질의, 상기 제1 키, 및 상기 제1 값에 대해 한 세트의 연산들을 실행함으로써 생성되고, 상기 제2 주의집중 출력은 적어도 상기 제2 질의, 상기 제2 키, 및 상기 제2 값에 대해 제2 세트의 연산들을 실행함으로써 생성되고, 상기 한 세트의 연산들은 실행 엔진의 제1 커널 상에서 실행되고, 상기 제2 세트의 연산들은 상기 실행 엔진의 상기 제1 커널 상에서 실행되는, 방법.</claim></claimInfo><claimInfo><claim>11. 동작들을 수행하도록 실행가능한 컴퓨터 프로그램 명령어들을 저장한 비-일시적인 컴퓨터 판독가능 저장 매체로서, 상기 동작들은,하나 이상의 토큰 시퀀스를 포함하는 배치를 수신하는 것 - 상기 배치 내의 제1 토큰 시퀀스의 길이는 상기 배치 내의 제2 토큰 시퀀스의 길이와 상이함 -; 기계 학습 모델에 액세스하는 것;하나 이상의 출력 표현을 생성하는 것을 포함하고, 상기 생성하는 것은, 하나 이상의 질의, 하나 이상의 키, 및 하나 이상의 값을 획득하는 것 - 상기 하나 이상의 질의는 하나 이상의 입력 표현에 질의 가중 텐서를 적용함으로써 생성되고, 적어도 상기 하나 이상의 질의는 배치 연산에 의해 생성됨 -, 상기 하나 이상의 질의로부터 상기 제1 토큰 시퀀스에 대한 제1 질의를, 상기 하나 이상의 키로부터 제1 키를, 그리고 상기 하나 이상의 값으로부터 제1 값을 분할하고, 상기 하나 이상의 질의로부터 상기 제2 토큰 시퀀스에 대한 제2 질의를, 상기 하나 이상의 키로부터 제2 키를, 그리고 상기 하나 이상의 값으로부터 제2 값을 분할하는 것,적어도, 상기 제1 질의, 상기 제1 키, 및 상기 제1 값을 조합함으로써, 제1 주의집중 출력을 생성하는 것,적어도, 상기 제2 질의, 상기 제2 키, 및 상기 제2 값을 조합함으로써, 제2 주의집중 출력을 별개로 생성하는 것,적어도 상기 제1 주의집중 출력 및 상기 제2 주의집중 출력을 연접된 텐서로 연접시키는 것, 및 적어도 상기 연접된 텐서에 하나 이상의 가중 텐서를 적용함으로써, 하나 이상의 출력 표현을 생성하는 것 - 상기 하나 이상의 출력 표현은 배치 연산에 의해 생성됨 -을 더 포함하는, 비-일시적인 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 기계 학습 모델은 한 세트의 디코더들을 포함하고, 디코더에 대한 상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하는 것은,상기 질의 가중 텐서, 키 가중 텐서, 및 값 가중 텐서를 포함하는 QKV 가중 텐서를 상기 하나 이상의 입력 표현에 적용하는 것을 포함하고, 상기 하나 이상의 입력 표현은 이전 디코더로부터의 하나 이상의 출력 표현 또는 상기 하나 이상의 토큰 시퀀스로부터 생성되는, 비-일시적인 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 기계 학습 모델은 한 세트의 인코더들 및 상기 한 세트의 인코더들에 결합된 한 세트의 디코더들을 포함하고, 상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하는 것은,상기 한 세트의 인코더들 내의 적어도 하나의 인코더로부터 상기 하나 이상의 키 및 상기 하나 이상의 값을 획득하는 것 - 상기 하나 이상의 키는 상기 키 가중 텐서를 상기 인코더의 하나 이상의 출력 표현에 적용함으로써 생성되고, 상기 하나 이상의 값은 상기 값 가중 텐서를 상기 인코더의 상기 하나 이상의 출력 표현에 적용함으로써 생성됨 -; 및상기 하나 이상의 입력 표현에 상기 질의 가중 텐서를 적용함으로써 디코더에 대한 상기 하나 이상의 질의를 생성하는 것을 포함하고, 상기 하나 이상의 입력 표현은 이전 디코더로부터의 하나 이상의 출력 표현 또는 상기 하나 이상의 토큰 시퀀스로부터 생성되는, 비-일시적인 컴퓨터 판독가능 저장 매체. </claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하기 전에, 자기-주의집중(self-attention) 계층에 입력하기 위한 하나 이상의 제3 질의, 하나 이상의 제3 키, 및 하나 이상의 제3 값을 획득하는 것,적어도, 상기 하나 이상의 제3 질의, 상기 하나 이상의 제3 키, 및 상기 하나 이상의 제3 값을 조합함으로써 주의집중 출력들을 생성하는 것을 더 포함하고, 상기 하나 이상의 질의를 생성하기 위한 상기 하나 이상의 입력 표현은 상기 자기-주의집중 계층으로부터의 상기 주의집중 출력들로부터 생성되는, 비-일시적인 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서, 상기 인코더는 상기 한 세트의 인코더들 내의 최종 인코더인, 비-일시적인 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 기계 학습 모델은 한 세트의 인코더들을 포함하고, 인코더에 대한 상기 하나 이상의 질의, 상기 하나 이상의 키, 및 상기 하나 이상의 값을 획득하는 것은,상기 질의 가중 텐서, 키 가중 텐서, 및 값 가중 텐서를 포함하는 QKV 가중 텐서를 상기 하나 이상의 입력 표현에 적용하는 것을 포함하고, 상기 하나 이상의 입력 표현은 이전 인코더로부터의 하나 이상의 출력 표현 또는 상기 하나 이상의 토큰 시퀀스로부터 생성되는, 비-일시적인 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 연접된 입력 텐서를 생성하기 위해 상기 배치에 대한 상기 하나 이상의 토큰 시퀀스 내의 토큰들을 단일 차원을 따라 연접시키는 것을 더 포함하는, 비-일시적인 컴퓨터 판독가능 저장 매체. </claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 적어도 상기 제1 주의집중 출력 및 상기 제2 주의집중 출력을 상기 연접된 텐서로 연접시키는 것은 상기 연접된 텐서를 생성하기 위해 상기 제1 주의집중 출력 및 상기 제2 주의집중 출력의 요소들을 단일 차원을 따라 연접시키는 것을 더 포함하는, 비-일시적인 컴퓨터 판독가능 저장 매체.  </claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 제1 주의집중 출력은 적어도 상기 제1 질의, 상기 제1 키, 및 상기 제1 값에 대해 한 세트의 연산들을 실행함으로써 생성되고, 상기 제2 주의집중 출력은 적어도 상기 제2 질의, 상기 제2 키, 및 상기 제2 값에 대해 제2 세트의 연산들을 실행함으로써 생성되고, 상기 한 세트의 연산들은 실행 엔진의 제1 커널 상에서 실행되고, 상기 제2 세트의 연산들은 상기 실행 엔진의 제2 커널 상에서 또는 제2 실행 엔진 상에서 실행되는, 비-일시적인 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서, 상기 제1 주의집중 출력은 적어도 상기 제1 질의, 상기 제1 키, 및 상기 제1 값에 대해 한 세트의 연산들을 실행함으로써 생성되고, 상기 제2 주의집중 출력은 적어도 상기 제2 질의, 상기 제2 키, 및 상기 제2 값에 대해 제2 세트의 연산들을 실행함으로써 생성되고, 상기 한 세트의 연산들은 실행 엔진의 제1 커널 상에서 실행되고, 상기 제2 세트의 연산들은 상기 실행 엔진의 상기 제1 커널 상에서 실행되는, 비-일시적인 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 ***** 레드우드 시티 트윈 돌핀 디알 *** 유닛 **** 스위트 ***</address><code>520250759430</code><country>미국</country><engName>FriendliAI Corp.</engName><name>프렌들리에이아이 코프.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대한민국 ***** 서울 관악구 ...</address><code> </code><country> </country><engName>YU, Gyeongin</engName><name>유경인</name></inventorInfo><inventorInfo><address>대한민국 ***** 서울 관악구 ...</address><code> </code><country> </country><engName>KIM, Geon-Woo</engName><name>김건우</name></inventorInfo><inventorInfo><address>대한민국 ***** 서울 관악구 ...</address><code> </code><country> </country><engName>JEONG, Joo Seong</engName><name>정주성</name></inventorInfo><inventorInfo><address>대한민국 ***** 서울 관악구 ...</address><code> </code><country> </country><engName>KIM, Soojeong</engName><name>김수정</name></inventorInfo><inventorInfo><address>대한민국 ***** 서울 관악구 ...</address><code> </code><country> </country><engName>CHUN, Byung-Gon</engName><name>전병곤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920030004930</code><country>대한민국</country><engName>Lim KyuBin</engName><name>임규빈</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.03</priorityApplicationDate><priorityApplicationNumber>17/542,189</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2023.02.06</receiptDate><receiptNumber>1-1-2023-0135848-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.01.22</receiptDate><receiptNumber>4-1-2024-0001373-52</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Change of Applicant] Report on Change of Proprietary Status</documentEngName><documentName>[출원인변경]권리관계변경신고서</documentName><receiptDate>2025.11.07</receiptDate><receiptNumber>1-1-2025-1246528-87</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230015515.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9392633e94811cd2ecb69c89e6f60f4fe3414dc272a3526181315547642c222bb4fda7bbb03afa885ea060d121d00d50c19d50f9dbb61d87d5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf02084a239b3c41fd83c6dde2f38c9eb0a2b5367b385cbf8a9f758756c68670dda457a529739fab38936558906ca3d4f022d730ccd6430351</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>