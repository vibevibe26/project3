<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:35.5135</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.07.31</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7019149</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>뇌-컴퓨터 인터페이스</inventionTitle><inventionTitleEng>BRAIN-COMPUTER INTERFACE</inventionTitleEng><openDate>2025.06.19</openDate><openNumber>10-2025-0090382</openNumber><originalApplicationDate>2020.07.31</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2022-7006634</originalApplicationNumber><originalExaminationRequestDate>2025.06.10</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.06.10</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/14</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020227006634</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 뇌-컴퓨터 인터페이스에서의 적응형 교정 방법이 개시된다. 방법은 신경 신호를 객체와 신뢰성 있게 연관시키기 위해 사용되고, 그 객체에 대한 사용자의 주의가 그 신경 신호를 도출하였다. 하나 이상의 객체를 오버레이하는 시각적 자극이 제공되고, 시각적 자극의 적어도 일부는 특성 변조를 갖는다. 뇌 컴퓨터 인터페이스는 사용자가 보게 되는 객체들에 대한 신경 응답을 측정한다. 시각적 자극에 대한 신경 응답은 변조와 상관되고, 이 상관은 시각적 자극에 주의가 집중될 때 더 강하게 된다. 결정된 상관들에 기초하여 사용자에 대한 신경 응답들의 결과적인 모델에 가중치들이 적용된다. 신경 신호 모델 가중과 디스플레이된 객체 디스플레이 변조 둘 모두는 신경 신호들과 그 신호들을 유발한 객체들의 연관의 확실성을 개선하도록 적응된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.02.04</internationOpenDate><internationOpenNumber>WO2021019088</internationOpenNumber><internationalApplicationDate>2020.07.31</internationalApplicationDate><internationalApplicationNumber>PCT/EP2020/071702</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터에 의해 구현되는 방법으로서, 뇌 컴퓨터 인터페이스(Brain Computer Interface)(BCI)의 사용자에 의한 사용 동안 상기 사용자가 감각 자극들에 노출되는 동안 상기 사용자로부터 신경 신호들을 수신하는 단계;신경 응답 모델을 사용하여 상기 감각 자극들에 대한 상기 사용자의 주의 집중을 식별하기 위해 상기 신경 신호들을 디코딩하는 단계;상기 사용자에게 실시간 피드백을 제공하기 위해 상기 주의 집중에 기초하여 상기 감각 자극들을 실시간으로 수정하는 단계;상기 실시간 피드백에 대한 상기 사용자에 의한 응답을 사용하여 상기 신경 응답 모델을 정밀화하는 단계; 및상기 신경 응답 모델을 연속적으로 교정하기 위해 상기 BCI의 사용자에 의한 사용 동안 상기 수신, 디코딩, 수정, 및 정밀화 동작들을 연속적으로 반복하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 감각 자극들은 시각적 자극들을 포함하고, 상기 실시간 피드백은 상기 시각적 자극들의 디스플레이 특성들을 수정하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 감각 자극들은 훈련 시퀀스로부터의 감각 자극들 중 적어도 하나를 포함하는 확인 시퀀스의 일부인, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 감각 자극들은 상기 확인 시퀀스에서의 감각 자극들의 외관을 변경시킴으로써 수정되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 신경 응답 모델은 상기 신경 신호들의 피처들에 적용되는 가중치들을 포함하고, 상기 신경 응답 모델을 정밀화하는 단계는 상기 가중치들을 수정하는 단계를 수반하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 감각 자극들은 각각이 적어도 하나의 미리 결정된 대응하는 특성을 가지는 하나 이상의 감각 자극을 포함하는 훈련 시퀀스의 일부인, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 방법은 감각 자극들에 대한 사용자 신경 응답의 모델을 사용하여 상기 감각 자극들 중 어느 것이 상기 사용자의 집중 객체인지를 추정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 머신으로서,하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하는 명령어들을 저장하는 메모리를 포함하고, 상기 동작들은,뇌 컴퓨터 인터페이스(BCI)의 사용자에 의한 사용 동안 상기 사용자가 감각 자극들에 노출되는 동안 상기 사용자로부터 신경 신호들을 수신하는 동작;신경 응답 모델을 사용하여 상기 감각 자극들에 대한 상기 사용자의 주의 집중을 식별하기 위해 상기 신경 신호들을 디코딩하는 동작;상기 사용자에게 실시간 피드백을 제공하기 위해 상기 주의 집중에 기초하여 상기 감각 자극들을 실시간으로 수정하는 동작;상기 실시간 피드백에 대한 상기 사용자에 의한 응답을 사용하여 상기 신경 응답 모델을 정밀화하는 동작; 및상기 신경 응답 모델을 연속적으로 교정하기 위해 상기 BCI의 사용자에 의한 사용 동안 상기 수신, 디코딩, 수정, 및 정밀화 동작들을 연속적으로 반복하는 동작을 포함하는, 머신.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 감각 자극들은 시각적 자극들을 포함하고, 상기 실시간 피드백은 상기 시각적 자극들의 디스플레이 특성들을 수정하는 것을 포함하는, 머신.</claim></claimInfo><claimInfo><claim>10. 머신에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하는 머신 실행가능 명령어들을 저장하는 머신 저장 매체로서, 상기 동작들은,뇌 컴퓨터 인터페이스(BCI)의 사용자에 의한 사용 동안 상기 사용자가 감각 자극들에 노출되는 동안 상기 사용자로부터 신경 신호들을 수신하는 동작;신경 응답 모델을 사용하여 상기 감각 자극들에 대한 상기 사용자의 주의 집중을 식별하기 위해 상기 신경 신호들을 디코딩하는 동작;상기 사용자에게 실시간 피드백을 제공하기 위해 상기 주의 집중에 기초하여 상기 감각 자극들을 실시간으로 수정하는 동작;상기 실시간 피드백에 대한 상기 사용자에 의한 응답을 사용하여 상기 신경 응답 모델을 정밀화하는 동작; 및상기 신경 응답 모델을 연속적으로 교정하기 위해 상기 BCI의 사용자에 의한 사용 동안 상기 수신, 디코딩, 수정, 및 정밀화 동작들을 연속적으로 반복하는 동작을 포함하는, 머신 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>프랑스 ***** 파리 뤼 드 라 호슈푸꼬 **</address><code>520220129087</code><country>프랑스</country><engName>NEXTMIND SAS</engName><name>넥스트마인드 에스에이에스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>BARASCUD, Nicolas</engName><name>바라스쿠드, 니콜라스</name></inventorInfo><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>ROUJANSKY, Paul</engName><name>로우잔스키, 폴</name></inventorInfo><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>ROYEN, Clement</engName><name>로옌, 클레멘트</name></inventorInfo><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>KOUIDER, Sid</engName><name>쿠이더, 시드</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.07.31</priorityApplicationDate><priorityApplicationNumber>62/880,704</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.06.10</receiptDate><receiptNumber>1-1-2025-0645470-07</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257019149.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9380d278569d775277dfe8417f89a62d925519e5bbaa31cbe9d6685c72dd3102e4dc876cb19a4eb0bf8378b72a6bddefe013a112d5c94f1cff</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf297428012f3eab7e3a441c2739c06703e2c3486b715817c488e6687a78b1c6bbaa42c23858a2a5d434352ccdc12509861597af38a1e41bf5</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>