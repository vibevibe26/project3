<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:31.3331</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7023508</applicationNumber><claimCount>31</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>입력 이미지 데이터로부터의 고속 실시간 장면 재구성</inventionTitle><inventionTitleEng>HIGH-SPEED REAL-TIME SCENE RECONSTRUCTION FROM INPUT IMAGE DATA</inventionTitleEng><openDate>2024.08.19</openDate><openNumber>10-2024-0124969</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.11.06</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.07.12</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/771</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/593</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일련의 입력 이미지에 대한 높이 필드를 출력하는 장면 재구성 모델이 개시된다. 상기 모델은 각 입력 이미지에 대해 깊이 맵을 예측하고 특징 맵을 추출한다. 상기 모델은 상기 예측된 깊이 맵과 이미지에 대한 카메라 포즈를 활용하여 3D 모델을 구축한다. 상기 모델은 3D 모델에 레이 캐스팅(raycast)하여 장면에 대한 원시 높이 필드를 결정한다. 상기 모델은 원시 높이 필드를 활용하여 특징 맵으로부터 높이 필드 상의 위치에 해당하는 특징을 샘플링한다. 상기 모델은 샘플링된 특징을 통합 특징 맵으로 통합한다. 상기 모델은 상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀한다. 상기 모델은 원시 높이 필드와 개선된 높이 필드의 조합을 기반으로 최종 높이 필드를 결정한다. 최종 높이 필드를 이용하여, 클라이언트 장치는 클라이언트 장치에 의해 캡처된 현실 세계 이미지에 증강되는 가상 콘텐츠를 생성할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.06.22</internationOpenDate><internationOpenNumber>WO2023111909</internationOpenNumber><internationalApplicationDate>2022.12.14</internationalApplicationDate><internationalApplicationNumber>PCT/IB2022/062234</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 구현 방법으로서,모바일 장치의 카메라 어셈블리에 의해 캡처된 장면의 실시간 이미지 데이터를 수신하는 단계;상기 장면의 실시간 이미지 데이터를 장면 재구성 모델에 입력하는 단계;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하는 단계 - 상기 장면 재구성 모델은:상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하는 단계,상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하는 단계,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하는 단계,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하는 단계,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하는 단계, 및상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정하는 단계를 통해 상기 최종 높이 필드를 생성함 -;상기 최종 높이 필드를 이용하여 상기 장면의 실시간 이미지 데이터와 함께 표시할 가상 콘텐츠를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 실시간 이미지 데이터는 복수의 이미지와 각 이미지에 대한 카메라 포즈를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 각 이미지에 대한 카메라 포즈는 상기 모바일 장치의 위치 센서에 의해 캡처되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 각 이미지에 대한 카메라 포즈는 상기 이미지를 기반으로 포즈 추정 모델에 의해 추정되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 깊이 맵을 예측하는 단계는 상기 이미지에 깊이 추정 모델을 적용하여 상기 깊이 맵을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 특징 맵을 추출하는 단계는 상기 이미지에 컨볼루션 네트워크를 적용하여 상기 특징 맵을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 특징 맵은 제1 특징 유형에 대한 제1 텐서 및 제2 특징 유형에 대한 제2 텐서를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 특징 맵은 제1 특징 유형에 대한 제1 텐서 및 제2 특징 유형에 대한 제2 텐서를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 원시 높이 필드를 생성하는 단계는:상기 예측된 깊이 맵과 함께 절단 부호화 거리 필드를 이용하여 3D 모델을 생성하는 단계; 및상기 3D 모델에 레이 캐스팅하여 상기 원시 높이 필드를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 3D 모델에 레이 캐스팅하여 상기 원시 높이 필드를 생성하는 단계는, 상기 원시 높이 필드의 각 위치에 대해, 광선을 하향으로 상기 3D 모델의 표면에 투사하여 해당 위치에서 상기 표면의 높이를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 통합 특징 맵을 생성하는 단계는:상기 이미지 데이터의 각 이미지에 대해: 상기 원시 높이 필드를 상기 이미지에 대한 카메라 포즈의 시점으로 트랜스포즈하고,상기 카메라 포즈의 시점에서 상기 원시 높이 필드의 각 위치가 가시적인지 또는 은닉되어 있는지 식별하며,상기 가시적인 위치의 특징을 샘플링하는 단계; 및상기 통합 특징 맵의 각 위치에 대해, 해당 위치에서의 상기 이미지 데이터의 하나 이상의 특징을 평균화하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 개선된 높이 필드를 회귀하는 단계는 상기 통합 특징 맵에 기계 학습 모델을 적용하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 장면 재구성 모델은 각 위치에서 해당 위치에서의 상기 개선된 높이 필드의 신뢰도를 예측하는 블렌드 맵을 추가로 출력함으로써 상기 최종 높이 필드를 생성하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정하는 단계는, 상기 최종 높이 필드의 각 위치에서, 해당 위치에서 상기 개선된 높이 필드의 기여도는 상기 블렌드 맵에서 해당 위치에 대한 신뢰도를 기반으로 하는 것을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 상기 가상 콘텐츠를 생성하는 단계는, 상기 최종 높이 필드의 표면 위에 놓이는 가상 객체를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서, 상기 가상 콘텐츠를 생성하는 단계는, 상기 최종 높이 필드의 두 개 이상의 표면 사이에서 이동할 수 있는 가상 객체를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>17. 명령어가 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 명령어가 컴퓨터 프로세서에 의해 실행될 경우, 상기 프로세서로 하여금:모바일 장치의 카메라 어셈블리에 의해 캡처된 장면의 실시간 이미지 데이터를 수신하고;상기 장면의 실시간 이미지 데이터를 장면 재구성 모델에 입력하고;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하되, 상기 장면 재구성 모델은:상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하고,상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하고,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하고,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하고,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하며, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정함으로써, 상기 최종 높이 필드를 생성하며;상기 최종 높이 필드를 이용하여 상기 장면의 실시간 이미지 데이터와 함께 표시할 가상 콘텐츠를 생성하도록 하는, 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>18. 시스템으로서,컴퓨터 프로세서; 및명령어가 저장된 비일시적 컴퓨터 판독 가능 저장 매체를 포함하되, 상기 명령어가 상기 컴퓨터 프로세서에 의해 실행될 경우, 상기 프로세서로 하여금:모바일 장치의 카메라 어셈블리에 의해 캡처된 장면의 실시간 이미지 데이터를 수신하고;상기 장면의 실시간 이미지 데이터를 장면 재구성 모델에 입력하고;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하되, 상기 장면 재구성 모델은:상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하고,상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하고,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하고,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하고,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하며, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정함으로써, 상기 최종 높이 필드를 생성하며;상기 최종 높이 필드를 이용하여 상기 장면의 실시간 이미지 데이터와 함께 표시할 가상 콘텐츠를 생성하도록 하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 컴퓨터 구현 방법으로서,자율 주행 차량의 카메라 어셈블리에 의해 캡처된 장면의 실시간 이미지 데이터를 수신하는 단계;상기 장면의 실시간 이미지 데이터를 장면 재구성 모델에 입력하는 단계;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하는 단계 - 상기 장면 재구성 모델은:상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하고,상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하고,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하고,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하고,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하며, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정하는 단계를 통해 상기 최종 높이 필드를 생성함 -; 및상기 최종 높이 필드를 이용하여 상기 장면에서 상기 자율 주행 차량을 내비게이팅하기 위한 내비게이션 명령어를 생성하는 단계; 및상기 내비게이션 명령어에 따라 상기 자율 주행 차량을 내비게이팅하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 실시간 이미지 데이터는 복수의 이미지와 각 이미지에 대한 카메라 포즈를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 각 이미지에 대한 카메라 포즈는 모바일 장치의 위치 센서에 의해 캡처되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>22. 제20항에 있어서, 상기 각 이미지에 대한 카메라 포즈는 상기 이미지를 기반으로 포즈 추정 모델에 의해 추정되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>23. 제19항에 있어서, 깊이 맵을 예측하는 단계는, 상기 이미지에 깊이 추정 모델을 적용하여 상기 깊이 맵을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>24. 제19항에 있어서, 특징 맵을 추출하는 단계는, 상기 이미지에 컨볼루션 네트워크를 적용하여 상기 특징 맵을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>25. 제19항에 있어서, 상기 특징 맵은 제1 특징 유형에 대한 제1 텐서 및 제2 특징 유형에 대한 제2 텐서를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>26. 제19항에 있어서, 상기 특징 맵은 제1 특징 유형에 대한 제1 텐서 및 제2 특징 유형에 대한 제2 텐서를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>27. 제19항에 있어서, 상기 원시 높이 필드를 생성하는 단계는:상기 예측된 깊이 맵과 함께 절단 부호화 거리 필드를 이용하여 3D 모델을 생성하는 단계; 및상기 3D 모델에 레이 캐스팅하여 상기 원시 높이 필드를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 3D 모델에 레이 캐스팅하여 상기 원시 높이 필드를 생성하는 단계는, 상기 원시 높이 필드의 각 위치에 대해, 광선을 하향으로 상기 3D 모델의 표면에 투사하여 해당 위치에서 상기 표면의 높이를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>29. 제19항에 있어서, 상기 통합 특징 맵을 생성하는 단계는:상기 이미지 데이터의 각 이미지에 대해: 상기 원시 높이 필드를 상기 이미지에 대한 카메라 포즈의 시점으로 트랜스포즈하고,상기 카메라 포즈의 시점에서 상기 원시 높이 필드의 각 위치가 가시적인지 또는 은닉되어 있는지 식별하며,상기 가시적인 위치의 특징을 샘플링하는 단계; 및상기 통합 특징 맵의 각 위치에 대해, 해당 위치에서의 상기 이미지 데이터의 하나 이상의 특징을 평균화하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>30. 제19항에 있어서, 상기 개선된 높이 필드를 회귀하는 단계는, 상기 통합 특징 맵에 기계 학습 모델을 적용하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서, 상기 장면 재구성 모델은 각 위치에서 해당 위치에서의 상기 개선된 높이 필드의 신뢰도를 예측하는 블렌드 맵을 추가로 출력함으로써 상기 최종 높이 필드를 생성하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정하는 단계는, 상기 최종 높이 필드의 각 위치에서, 해당 위치에서 상기 개선된 높이 필드의 기여도는 상기 블렌드 맵에서 해당 위치에 대한 신뢰도를 기반으로 하는 것을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>33. 제19항에 있어서, 상기 내비게이션 명령어를 생성하는 단계는, 상기 자율 주행 차량을 제1 높이의 제1 표면에서 제2 높이의 제2 표면으로 전환시키기 위한 내비게이션 명령어를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>34. 제19항에 있어서, 상기 내비게이션 명령어를 생성하는 단계는, 제1 높이의 제1 표면과 상이한 제2 높이의 제2 표면 주위의 상기 제1 표면에서 상기 자율 주행 차량을 내비게이팅하기 위한 내비게이션 명령어를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>35. 명령어가 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 명령어가 컴퓨터 프로세서에 의해 실행될 경우, 상기 프로세서로 하여금:자율 주행 차량의 카메라 어셈블리에 의해 캡처된 장면의 실시간 이미지 데이터를 수신하고;상기 장면의 실시간 이미지 데이터를 장면 재구성 모델에 입력하고;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하되, 상기 장면 재구성 모델은:상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하고,상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하고,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하고,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하고,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하며, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정함으로써, 상기 최종 높이 필드를 생성하며;상기 최종 높이 필드를 이용하여 상기 장면에서 상기 자율 주행 차량을 내비게이팅하기 위한 내비게이션 명령어를 생성하며;상기 내비게이션 명령어에 따라 상기 자율 주행 차량을 내비게이팅하도록 하는, 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>36. 시스템으로서,컴퓨터 프로세서; 및명령어가 저장된 비일시적 컴퓨터 판독 가능 저장 매체를 포함하되, 상기 명령어가 상기 컴퓨터 프로세서에 의해 실행될 경우, 상기 프로세서로 하여금:자율 주행 차량의 카메라 어셈블리에 의해 캡처된 장면의 실시간 이미지 데이터를 수신하고;상기 장면의 실시간 이미지 데이터를 장면 재구성 모델에 입력하고;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하되, 상기 장면 재구성 모델은:상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하고,상기 이미지 데이터의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하고,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하고,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하고,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하며,상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정함으로써, 상기 최종 높이 필드를 생성하고;상기 최종 높이 필드를 이용하여 상기 장면에서 상기 자율 주행 차량을 내비게이팅하기 위한 내비게이션 명령어를 생성하며;상기 내비게이션 명령어에 따라 상기 자율 주행 차량을 내비게이팅하도록 하는, 시스템.</claim></claimInfo><claimInfo><claim>37. 컴퓨터 구현 방법으로서,하나 이상의 장면에 대한 하나 이상의 실측 높이 필드를 갖는 하나 이상의 카메라 어셈블리에 의해 캡처된 상기 하나 이상의 장면의 하나 이상의 훈련 이미지 데이터 세트를 수신하는 단계;상기 장면의 각 훈련 이미지 데이터 세트를 장면 재구성 모델에 입력하는 단계;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하는 단계 - 상기 장면 재구성 모델은:상기 훈련 이미지 데이터 세트의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하는 단계,상기 훈련 이미지 데이터 세트의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하는 단계,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하는 단계,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하는 단계,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하는 단계, 및상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정하는 단계를 통해, 상기 최종 높이 필드를 생성함 -; 각 훈련 데이터 세트에 대해, 상기 장면에 대한 상기 최종 높이 필드와 상기 장면에 대한 상기 실측 높이 필드 사이의 손실을 결정하는 단계; 및상기 손실을 최소화하도록 상기 장면 재구성 모델을 훈련하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>38. 제37항에 있어서, 상기 훈련 이미지 데이터는 복수의 이미지와 각 이미지에 대한 카메라 포즈 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>39. 제38항에 있어서, 상기 각 이미지에 대한 카메라 포즈는 모바일 장치의 위치 센서에 의해 캡처되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>40. 제38항에 있어서, 상기 각 이미지에 대한 카메라 포즈는 상기 이미지를 기반으로 포즈 추정 모델에 의해 추정되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>41. 제37항에 있어서, 깊이 맵을 예측하는 단계는, 상기 이미지에 깊이 추정 모델을 적용하여 상기 깊이 맵을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>42. 제37항에 있어서, 특징 맵을 추출하는 단계는, 상기 이미지에 컨볼루션 네트워크를 적용하여 상기 특징 맵을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>43. 제37항에 있어서, 상기 특징 맵은 제1 특징 유형에 대한 제1 텐서 및 제2 특징 유형에 대한 제2 텐서를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>44. 제37항에 있어서, 상기 특징 맵은 제1 특징 유형에 대한 제1 텐서 및 제2 특징 유형에 대한 제2 텐서를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>45. 제37항에 있어서, 상기 원시 높이 필드를 생성하는 단계는:상기 예측된 깊이 맵과 함께 절단 부호화 거리 필드를 이용하여 3D 모델을 생성하는 단계; 및상기 3D 모델에 레이 캐스팅하여 상기 원시 높이 필드를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>46. 제45항에 있어서, 상기 3D 모델에 레이 캐스팅하여 상기 원시 높이 필드를 생성하는 단계는, 상기 원시 높이 필드의 각 위치에 대해, 광선을 하향으로 상기 3D 모델의 표면에 투사하여 해당 위치에서 상기 표면의 높이를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.  </claim></claimInfo><claimInfo><claim>47. 제37항에 있어서, 상기 통합 특징 맵을 생성하는 단계는:상기 이미지 데이터의 각 이미지에 대해: 상기 원시 높이 필드를 상기 이미지에 대한 카메라 포즈의 시점으로 트랜스포즈하고,상기 카메라 포즈의 시점에서 상기 원시 높이 필드의 각 위치가 가시적인지 또는 은닉되어 있는지 식별하며,상기 가시적인 위치의 특징을 샘플링하는 단계; 및상기 통합 특징 맵의 각 위치에 대해, 해당 위치에서의 상기 이미지 데이터의 하나 이상의 특징을 평균화하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>48. 제37항에 있어서, 상기 개선된 높이 필드를 회귀하는 단계는, 상기 통합 특징 맵에 기계 학습 모델을 적용하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>49. 제48항에 있어서, 상기 장면 재구성 모델은 각 위치에서 해당 위치에서의 상기 개선된 높이 필드의 신뢰도를 예측하는 블렌드 맵을 추가로 출력함으로써 상기 최종 높이 필드를 생성하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>50. 제49항에 있어서, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정하는 단계는, 상기 최종 높이 필드의 각 위치에서, 해당 위치에서 상기 개선된 높이 필드의 기여도는 상기 블렌드 맵에서 해당 위치에 대한 신뢰도를 기반으로 하는 것을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>51. 제37항에 있어서, 상기 장면 재구성 모델을 훈련하는 단계는, 상기 장면 재구성 모델의 하나 이상의 컴포넌트를 동기적으로 훈련하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>52. 제37항에 있어서, 상기 장면 재구성 모델을 훈련하는 단계는, 상기 장면 재구성 모델의 하나 이상의 컴포넌트를 비동기적으로 훈련하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>53. 명령어가 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 명령어가 컴퓨터 프로세서에 의해 실행될 경우, 상기 프로세서로 하여금:하나 이상의 장면에 대한 하나 이상의 실측 높이 필드를 갖는 하나 이상의 카메라 어셈블리에 의해 캡처된 상기 하나 이상의 장면의 하나 이상의 훈련 이미지 데이터 세트를 수신하고;상기 장면의 각 훈련 이미지 데이터 세트를 장면 재구성 모델에 입력하고;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하되, 상기 장면 재구성 모델은:상기 훈련 이미지 데이터 세트의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하고,상기 훈련 이미지 데이터 세트의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하고,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하고,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하고,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하며, 상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정함으로써, 상기 최종 높이 필드를 생성하고; 각 훈련 데이터 세트에 대해, 상기 장면에 대한 상기 최종 높이 필드와 상기 장면에 대한 상기 실측 높이 필드 사이의 손실을 결정하며;상기 손실을 최소화하도록 상기 장면 재구성 모델을 훈련하도록 하는, 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>54. 장면 재구성 모델이 저장된 비일시적 컴퓨터 판독 가능 저장 매체를 포함하는 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램 제품은:하나 이상의 장면에 대한 하나 이상의 실측 높이 필드를 갖는 하나 이상의 카메라 어셈블리에 의해 캡처된 상기 하나 이상의 장면의 하나 이상의 훈련 이미지 데이터 세트를 수신하는 단계;상기 장면의 각 훈련 이미지 데이터 세트를 장면 재구성 모델에 입력하는 단계;상기 장면 재구성 모델로부터 상기 장면의 각 2D 위치에서의 높이 값을 포함하는 상기 장면의 최종 높이 필드를 수신하는 단계 - 상기 장면 재구성 모델은:상기 훈련 이미지 데이터 세트의 각 이미지에 대해, 이미지를 기반으로 깊이 맵을 예측하는 단계,상기 훈련 이미지 데이터 세트의 각 이미지에 대해, 이미지를 기반으로 특징 맵을 추출하는 단계,상기 예측한 이미지의 깊이 맵을 기반으로 원시 높이 필드를 생성하는 단계,상기 이미지의 특징 맵을 기반으로 통합 특징 맵을 생성하는 단계,상기 통합 특징 맵을 기반으로 개선된 높이 필드를 회귀하는 단계, 및상기 최종 높이 필드를 상기 원시 높이 필드와 상기 개선된 높이 필드의 조합으로 결정하는 단계를 통해, 상기 최종 높이 필드를 생성함 -; 각 훈련 데이터 세트에 대해, 상기 장면에 대한 상기 최종 높이 필드와 상기 장면에 대한 상기 실측 높이 필드 사이의 손실을 결정하는 단계; 상기 손실을 최소화하도록 상기 장면 재구성 모델을 훈련하는 단계; 및상기 비일시적 컴퓨터 판독 가능 저장 매체에 상기 장면 재구성 모델을 저장하는 단계;를 포함하는 프로세스를 통해 제조되는, 컴퓨터 프로그램 제품.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국, 캘리포니아주 *****, 샌프란시스코, 스위트 ***, 원 페리 빌딩</address><code>520170656780</code><country>미국</country><engName>Niantic, Inc.</engName><name>나이앤틱, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국, 브리스톨 비에스* *엔티, 루인스 미드...</address><code> </code><country> </country><engName>WATSON, James</engName><name>왓슨, 제임스</name></inventorInfo><inventorInfo><address>영국, 브리스톨 비에스* *엔티, 루인스 미드...</address><code> </code><country> </country><engName>VICENTE, Sara Alexandra Gomes</engName><name>비센테, 사라 알렉산드라 고메스</name></inventorInfo><inventorInfo><address>영국, 브리스톨 비에스* *엔티, 루인스 미드...</address><code> </code><country> </country><engName>MAC AODHA, Oisin</engName><name>맥 아오다, 오이신</name></inventorInfo><inventorInfo><address>영국, 브리스톨 비에스* *엔티, 루인스 미드...</address><code> </code><country> </country><engName>GODARD, Clement</engName><name>고다르, 클레망</name></inventorInfo><inventorInfo><address>영국, 브리스톨 비에스* *엔티, 루인스 미드...</address><code> </code><country> </country><engName>BROSTOW, Gabriel J.</engName><name>브로스토우, 가브리엘 제이.</name></inventorInfo><inventorInfo><address>영국, 브리스톨 비에스* *엔티, 루인스 미드...</address><code> </code><country> </country><engName>FIRMAN, Michael David</engName><name>퍼먼, 마이클 데이비드</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 종로구 종로*길 ** (수송동, **, **층)(법무법인케이씨엘)</address><code>919980001311</code><country>대한민국</country><engName>KIM, Sun Young</engName><name>김 순 영</name></agentInfo><agentInfo><address>서울 종로구 종로*길 ** (수송동, **, **층)(법무법인케이씨엘)</address><code>919980000403</code><country>대한민국</country><engName>KIM, Young Chol</engName><name>김영철</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.16</priorityApplicationDate><priorityApplicationNumber>63/290,440</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.07.12</receiptDate><receiptNumber>1-1-2024-0759293-72</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-5-2024-0117208-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.11.06</receiptDate><receiptNumber>1-1-2025-1240961-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.11.06</receiptDate><receiptNumber>1-1-2025-1240964-30</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247023508.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d86c91b045bff3b12678c0319bda785a5bd170e916448147ca175718359d3a3637ca664b42ad4f9308e1915d2d1b94642fd97f0abe7f5a0e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf638e1b12628e93565865dfd620502caf02a27b28c50f96c83ed846496da2af14c6fc8834a23391b27c002f5d611ceb659551b6255bf68924</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>