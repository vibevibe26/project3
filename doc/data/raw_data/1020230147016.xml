<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:30.5130</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0147016</applicationNumber><claimCount>12</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법, 이를 수행하는 장치 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>Adversarial attack method using reinforcement learning  for gait recognition system, apparatus and computer  program for performing the method</inventionTitleEng><openDate>2025.05.08</openDate><openNumber>10-2025-0062260</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/094</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 문서의 일 실시예에 따른 보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법, 이를 수행하는 장치 및 컴퓨터 프로그램은, 서로 다른 복수개의 딥러닝(deep learning) 기반의 보행 인식 시스템(gait recognition system) 중에서 가장 높은 인식 성능을 나타내는 딥러닝 기반의 보행 인식 시스템에 대해, 강화 학습(reinforcement learning)을 이용하여 적대적 공격(adversarial attack)을 수행함으로써, 보행 인식 시스템의 취약성 등을 분석하여 보행 인식 시스템의 안전성을 보다 정확하게 검증할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 동일한 사람에 대한 서로 다른 복수개의 보행 에너지 이미지(gait energy image, GEI)로 구성되는 보행 데이터가 복수의 사람별로 구비된 테스트 데이터 세트를 이용하여, 서로 다른 복수개의 딥러닝(deep learning) 기반의 보행 인식 시스템(gait recognition system) 중에서 가장 높은 인식 성능을 나타내는 딥러닝 기반의 보행 인식 시스템을 분석 대상 보행 인식 시스템으로 획득하는 단계; 및에이전트(agent)가 상호 작용하는 보행 에너지 이미지(GEI)가 환경(environment)이고, 보행 에너지 이미지(GEI)에서의 픽셀 위치(pixel location)가 상태(state)이며, 상기 에이전트가 현재 상태에서 가능한 모든 이동이 액션(action)이고, 상기 분석 대상 보행 인식 시스템으로부터 제공받은 예측 결과를 토대로 결정된 액션 품질 값이 보상(reward)인 강화 학습(reinforcement learning, RL)을 이용하여 블랙 박스 공격(black box attack)인 적대적 공격(adversarial attack)을 상기 분석 대상 보행 인식 시스템에 대해 수행하는 단계;를 포함하며,상기 액션은, 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 미리 설정된 크기의 스텝(step)을 단위로 다른 픽셀로 이동하는 것이고,상기 적대적 공격 수행 단계는, 상기 에이전트가 수행한 상기 액션에 따른 상기 에이전트의 상기 상태인 픽셀 위치를 중심으로 하여 픽셀 값이 랜덤하게 생성된 n×n 크기를 가지는 적대적 패치(adversarial patch)를 생성하고, 상기 적대적 패치의 픽셀 위치를 토대로 상기 보행 에너지 이미지(GEI)에 상기 적대적 패치를 추가하여 픽셀이 교란(perturbation)된 적대적 보행 에너지 이미지(GEI)를 획득하며, 상기 적대적 보행 에너지 이미지(GEI)를 상기 분석 대상 보행 인식 시스템에 제공하는 것으로 이루어지는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에서,상기 액션은,상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 위쪽에 있는 픽셀로 이동, 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 아래쪽에 있는 픽셀로 이동, 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 왼쪽에 있는 픽셀로 이동, 및 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 오른쪽에 있는 픽셀로 이동을 포함하는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에서,상기 적대적 공격 수행 단계는,상기 분석 대상 보행 인식 시스템으로부터 제공받은 상기 적대적 보행 에너지 이미지(GEI)에 대한 예측 결과가 상기 분석 대상 보행 인식 시스템의 신뢰도(confidence)를 낮추는 결과에 해당하면 양의 상기 액션 품질 값을 상기 액션에 대한 상기 보상으로 결정하고, 상기 분석 대상 보행 인식 시스템으로부터 제공받은 상기 적대적 보행 에너지 이미지(GEI)에 대한 예측 결과가 상기 분석 대상 보행 인식 시스템의 신뢰도를 낮추는 결과에 해당하지 않으면 음의 상기 액션 품질 값을 상기 액션에 대한 상기 보상으로 결정하는 것으로 이루어지는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에서,상기 적대적 공격 수행 단계는,Q-러닝(Q-learning)을 기반으로 상기 분석 대상 보행 인식 시스템에 대해 상기 적대적 공격을 수행하는 것으로 이루어지는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에서,상기 Q-러닝은,상기 보행 에너지 이미지(GEI)와 Q-러닝 알고리즘 파라미터가 입력이고, 상기 에이전트가 도달한 목표 상태가 출력이며, 에피소드 수와 에피소드당 반복 수를 포함하는 하이퍼파라미터를 상태 및 액션 크기로 초기화한 후, 각 상기 보행 에너지 이미지(GEI)에 대해, 상기 에피소드당 반복 수와 상기 에피소드 수를 기반으로, 상기 에이전트가 현재 상태에 따른 상기 보행 에너지 이미지(GEI)에서의 픽셀 위치를 기반으로 상기 액션을 수행하는 과정, 상기 에이전트가 수행한 상기 액션을 기반으로 상기 적대적 패치를 생성하고 상기 적대적 패치가 추가된 상기 적대적 보행 에너지 이미지(GEI)를 상기 분석 대상 보행 인식 시스템에 제공하여 상태 전환을 수행하는 과정, 상기 분석 대상 보행 인식 시스템으로부터 제공받은 상기 적대적 보행 에너지 이미지(GEI)에 대한 예측 결과를 토대로 상기 액션에 대한 상기 보상을 결정하는 과정, 및 각 상태-액션 쌍(state-action pair)에 대한 Q-값을 보유하는 Q-테이블(Q-table)을 업데이트하는 과정을, 반복적으로 수행하는 알고리즘인,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에서,상기 보행 인식 시스템은,상기 보행 에너지 이미지(GEI) 기반의 보행 표현(gait representation)을 이용하여 보행 스타일로 개인을 인식하는 심층 합성곱 신경망(deep convolutional neural network, DCNN) 기반의 지능형 모델(intelligent model)인,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 기재된 보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 방법을 컴퓨터에서 실행시키기 위하여 컴퓨터 판독 가능한 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>8. 딥러닝(deep learning) 기반의 보행 인식 시스템(gait recognition system)에 대해, 강화 학습(reinforcement learning, RL)을 이용하여 적대적 공격(adversarial attack)을 수행하기 위한 하나 이상의 프로그램을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 프로그램에 따라 상기 강화 학습을 이용하여 상기 적대적 공격을 상기 보행 인식 시스템에 대해 수행하기 위한 동작을 수행하는 하나 이상의 프로세서;를 포함하며,상기 프로세서는,동일한 사람에 대한 서로 다른 복수개의 보행 에너지 이미지(gait energy image, GEI)로 구성되는 보행 데이터가 복수의 사람별로 구비된 테스트 데이터 세트를 이용하여, 서로 다른 복수개의 딥러닝 기반의 상기 보행 인식 시스템 중에서 가장 높은 인식 성능을 나타내는 딥러닝 기반의 보행 인식 시스템을 분석 대상 보행 인식 시스템으로 획득하고,에이전트(agent)가 상호 작용하는 보행 에너지 이미지(GEI)가 환경(environment)이고, 보행 에너지 이미지(GEI)에서의 픽셀 위치(pixel location)가 상태(state)이며, 상기 에이전트가 현재 상태에서 가능한 모든 이동이 액션(action)이고, 상기 분석 대상 보행 인식 시스템으로부터 제공받은 예측 결과를 토대로 결정된 액션 품질 값이 보상(reward)인 강화 학습(RL)을 이용하여 블랙 박스 공격(black box attack)인 적대적 공격을 상기 분석 대상 보행 인식 시스템에 대해 수행하며,상기 액션은, 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 미리 설정된 크기의 스텝(step)을 단위로 다른 픽셀로 이동하는 것이고,상기 프로세서는, 상기 에이전트가 수행한 상기 액션에 따른 상기 에이전트의 상기 상태인 픽셀 위치를 중심으로 하여 픽셀 값이 랜덤하게 생성된 n×n 크기를 가지는 적대적 패치(adversarial patch)를 생성하고, 상기 적대적 패치의 픽셀 위치를 토대로 상기 보행 에너지 이미지(GEI)에 상기 적대적 패치를 추가하여 픽셀이 교란(perturbation)된 적대적 보행 에너지 이미지(GEI)를 획득하며, 상기 적대적 보행 에너지 이미지(GEI)를 상기 분석 대상 보행 인식 시스템에 제공하는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에서,상기 액션은,상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 위쪽에 있는 픽셀로 이동, 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 아래쪽에 있는 픽셀로 이동, 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 왼쪽에 있는 픽셀로 이동, 및 상기 에이전트가 현재 상태에 따른 픽셀 위치를 기준으로 상기 미리 설정된 크기의 스텝을 단위로 오른쪽에 있는 픽셀로 이동을 포함하는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에서,상기 프로세서는,상기 분석 대상 보행 인식 시스템으로부터 제공받은 상기 적대적 보행 에너지 이미지(GEI)에 대한 예측 결과가 상기 분석 대상 보행 인식 시스템의 신뢰도(confidence)를 낮추는 결과에 해당하면 양의 상기 액션 품질 값을 상기 액션에 대한 상기 보상으로 결정하고, 상기 분석 대상 보행 인식 시스템으로부터 제공받은 상기 적대적 보행 에너지 이미지(GEI)에 대한 예측 결과가 상기 분석 대상 보행 인식 시스템의 신뢰도를 낮추는 결과에 해당하지 않으면 음의 상기 액션 품질 값을 상기 액션에 대한 상기 보상으로 결정하는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에서,상기 프로세서는,Q-러닝(Q-learning)을 기반으로 상기 분석 대상 보행 인식 시스템에 대해 상기 적대적 공격을 수행하는,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에서,상기 Q-러닝은,상기 보행 에너지 이미지(GEI)와 Q-러닝 알고리즘 파라미터가 입력이고, 상기 에이전트가 도달한 목표 상태가 출력이며, 에피소드 수와 에피소드당 반복 수를 포함하는 하이퍼파라미터를 상태 및 액션 크기로 초기화한 후, 각 상기 보행 에너지 이미지(GEI)에 대해, 상기 에피소드당 반복 수와 상기 에피소드 수를 기반으로, 상기 에이전트가 현재 상태에 따른 상기 보행 에너지 이미지(GEI)에서의 픽셀 위치를 기반으로 상기 액션을 수행하는 과정, 상기 에이전트가 수행한 상기 액션을 기반으로 상기 적대적 패치를 생성하고 상기 적대적 패치가 추가된 상기 적대적 보행 에너지 이미지(GEI)를 상기 분석 대상 보행 인식 시스템에 제공하여 상태 전환을 수행하는 과정, 상기 분석 대상 보행 인식 시스템으로부터 제공받은 상기 적대적 보행 에너지 이미지(GEI)에 대한 예측 결과를 토대로 상기 액션에 대한 상기 보상을 결정하는 과정, 및 각 상태-액션 쌍(state-action pair)에 대한 Q-값을 보유하는 Q-테이블(Q-table)을 업데이트하는 과정을, 반복적으로 수행하는 알고리즘인,보행 인식 시스템에 대한 강화 학습을 이용한 적대적 공격 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 동작구...</address><code>220040385305</code><country>대한민국</country><engName>CHUNG ANG University Industry Academic Cooperation Foundation</engName><name>중앙대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>Rho, Seungmin</engName><name>노승민</name></inventorInfo><inventorInfo><address>대전광역시 서구...</address><code> </code><country> </country><engName>Yeo, SangSoo</engName><name>여상수</name></inventorInfo><inventorInfo><address>파키스탄, 이슬라마바드 캐피털 ...</address><code> </code><country> </country><engName>muazzam maqsood</engName><name>무아잠 맥수드</name></inventorInfo><inventorInfo><address>파키스탄, 이슬라마바드 캐피털 ...</address><code> </code><country> </country><engName>sadaf yasmin</engName><name>사다프 야스민</name></inventorInfo><inventorInfo><address>영국 브랫포드, 브...</address><code> </code><country> </country><engName>Irfan Mehmood</engName><name>어판 메흐무드</name></inventorInfo><inventorInfo><address>파키스탄 아톡, 아...</address><code> </code><country> </country><engName>Farhan Aadil</engName><name>파르한 아딜</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서대문구 경기대로 **,  진양빌딩 *층(충정로*가)</address><code>920191001412</code><country>대한민국</country><engName>WeThePeople IP &amp; Law Firm</engName><name>특허법인위더피플</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.30</receiptDate><receiptNumber>1-1-2023-1194274-52</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2023.11.08</receiptDate><receiptNumber>1-5-2023-0179014-61</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.11.22</receiptDate><receiptNumber>1-1-2023-1306941-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.12.27</receiptDate><receiptNumber>1-1-2023-1463418-73</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.08.07</receiptDate><receiptNumber>4-1-2024-5236660-34</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.05.15</receiptDate><receiptNumber>4-1-2025-5130684-12</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230147016.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93036444d076c976119a1e75cee10acf7ee320f94835558c7c4b410954ff71c3d48e3adf6ddbf0a1433cf7baa86fab0cccbf5b54078285608d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf79c7f827b03b71df533052fe73ce8c3cb15717e94649252a0d354e168f03530ab5f1343b2a39af188323fb6c5c35f787bf6cdd0ff5cb09e3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>