<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:27:23.2723</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7029776</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>감정-기반 텍스트 대 스피치</inventionTitle><inventionTitleEng>EMOTION-BASED TEXT TO SPEECH</inventionTitleEng><openDate>2024.09.27</openDate><openNumber>10-2024-0141833</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.04</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.09.04</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 13/033</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 13/047</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0482</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 감정-기반 텍스트 대 스피치를 제공하기 위한 시스템들 및 방법들이 제공된다. 이러한 시스템들 및 방법들은 동작들을 수행하고, 이러한 동작들은 텍스트 문자열에 액세스하는 동작; 복수의 스피커들과 연관된 복수의 임베딩들을 저장하는 동작- 복수의 스피커들 중 제1 스피커에 대한 제1 임베딩은 제1 감정과 연관되고, 제2 스피커에 대한 제2 임베딩은 제2 감정과 연관됨 -; 텍스트 문자열의 하나 이상의 단어를 말하기 위해 제1 스피커를 선택하는 동작; 하나 이상의 단어가 제2 감정과 연관된다고 결정하는 동작; 제1 임베딩 및 제2 임베딩에 기초하여, 제2 감정과 연관된 제1 스피커에 대한 제3 임베딩을 생성하는 동작; 및 제2 감정과 함께 제1 스피커에 의해 말해지는 하나 이상의 단어를 포함하는 오디오 스트림을 생성하기 위해 제3 임베딩 및 텍스트 문자열을 보코더에 적용하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.08.17</internationOpenDate><internationOpenNumber>WO2023154323</internationOpenNumber><internationalApplicationDate>2023.02.08</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/012594</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 하나 이상의 단어를 포함하는 텍스트 문자열에 액세스하는 단계;복수의 스피커들 중 제1 스피커에 대한 제1 임베딩 및 제2 스피커에 대한 제2 임베딩을 저장하는 단계- 상기 제1 임베딩은 제1 감정과 연관되고 상기 제2 임베딩은 제2 감정과 연관됨-;상기 하나 이상의 프로세서에 의해, 상기 텍스트 문자열의 상기 하나 이상의 단어의 가상 스피치에 대해 상기 제1 스피커를 선택하는 단계;상기 텍스트 문자열의 상기 하나 이상의 단어가 상기 제2 감정과 연관된다고 결정하는 단계;상기 제1 스피커의 상기 제1 임베딩 및 상기 제2 스피커의 상기 제2 임베딩에 기초하여, 상기 제2 감정과 연관된 상기 제1 스피커에 대한 제3 임베딩을 생성하는 단계; 및상기 제2 감정과 함께 상기 제1 스피커에 의해 가상으로 말해지는 상기 하나 이상의 단어를 포함하는 오디오 스트림을 생성하기 위해 상기 제1 스피커의 상기 제3 임베딩 및 상기 텍스트 문자열을 보코더에 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 보코더는 Mel 스펙트로그램 포맷의 주어진 스피커의 스피치를 음향 오디오 스트림으로 변환하도록 구성되는 트레이닝된 신경망을 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 추가로,상기 제1 스피커에 대한 상기 제1 임베딩을 제1 음성 컴포넌트와 제1 스타일 컴포넌트로 분할하는 단계; 및상기 제2 스피커에 대한 상기 제2 임베딩을 제2 음성 컴포넌트와 제2 스타일 컴포넌트로 분할하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제3 임베딩을 생성하는 단계는,상기 제2 임베딩으로부터 분할되는 상기 제2 스타일 컴포넌트와 상기 제1 임베딩으로부터 분할되는 상기 제1 음성 컴포넌트를 제3 임베딩으로 조합하는 단계- 상기 제3 임베딩은 상기 제1 음성 컴포넌트 및 상기 제2 스타일 컴포넌트를 포함함 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제3항 또는 제4항에 있어서, 추가로,상기 제1 음성 컴포넌트 및 상기 제1 스타일 컴포넌트를 추정하기 위해 머신 학습 기술에 의해 상기 제1 스피커와 연관된 제1 스피치를 처리하는 단계; 및상기 제2 음성 컴포넌트 및 상기 제2 스타일 컴포넌트를 추정하기 위해 상기 머신 학습 기술에 의해 상기 제2 스피커와 연관된 제2 스피치를 처리하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제3항 내지 제5항 중 어느 한 항에 있어서, 상기 제3 임베딩을 생성하는 단계는,상기 제2 스타일 컴포넌트와 연관된 복수의 스피커들과 연관된 복수의 스피치를 처리하는 것에 의해 상기 제2 스타일 컴포넌트를 일반화하도록 상기 머신 학습 기술을 트레이닝하는 단계; 및상기 일반화된 제2 스타일 컴포넌트를 상기 제3 임베딩으로 조합하는 단계- 상기 제3 임베딩은 상기 제1 음성 컴포넌트 및 상기 일반화된 제2 스타일 컴포넌트를 포함함 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 추가로,상기 복수의 스피커들의 리스트를 디스플레이하는 단계; 및상기 디스플레이된 리스트에서의 상기 복수의 스피커들로부터의 상기 제1 스피커의 선택을 포함하는 입력을 수신하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 제2 감정은, 중립적임, 기쁨, 슬픔, 화남, 졸림, 역겨움, 놀람, 또는 두려움 중 적어도 하나를 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 추가로,상기 하나 이상의 단어의 감정의 레벨을 예측하기 위해 머신 학습 기술을 사용하여 상기 텍스트 문자열에서의 상기 하나 이상의 단어를 처리하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 머신 학습 기술은 랜덤-포레스트(random-forest), 신경망, 또는 지원 벡터 머신을 포함하는- 상기 머신 학습 기술은 언어 모델들에 기초하여 텍스트의 강도를 예측하도록 트레이닝됨 - 방법.</claim></claimInfo><claimInfo><claim>11. 제9항 또는 제10항에 있어서, 추가로,상기 예측된 감정의 레벨에 기초하여 상기 제1 감정과 연관된 제1 계수를 컴퓨팅하는 단계; 및상기 예측된 감정의 레벨에 기초하여 상기 제2 감정과 연관된 제2 계수를 컴퓨팅하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제9항 내지 제11항 중 어느 한 항에 있어서, 상기 제3 임베딩을 생성하는 단계는,상기 제1 계수에 기초하여 상기 제1 임베딩의 제1 스타일 컴포넌트를 스케일링하는 단계;상기 제2 계수에 기초하여 상기 제2 임베딩의 제2 스타일 컴포넌트를 스케일링하는 단계; 및상기 스케일링된 제1 및 제2 스타일 컴포넌트들을 상기 제3 임베딩의 스타일 컴포넌트로 조합하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제9항 내지 제12항 중 어느 한 항에 있어서, 추가로,복수의 트레이닝 텍스트 문자열들을 포함하는 트레이닝 데이터를 수신하는 단계- 상기 복수의 트레이닝 텍스트 문자열들 각각은 스케일링된 스타일 컴포넌트들의 조합을 표현하는 실측 스타일 컴포넌트와 연관됨 -;상이한 스타일들의 세트와 연관된 계수들의 추정된 세트를 생성하기 위해 머신 학습 기술에 의해 제1 트레이닝 텍스트 문자열을 처리하는 단계;추정된 스타일 컴포넌트를 생성하기 위해 상기 계수들의 추정된 세트에 기초하여 상기 상이한 스타일들의 세트를 조합하는 단계;손실을 생성하기 위해 상기 추정된 스타일 컴포넌트를 상기 제1 트레이닝 텍스트 문자열의 상기 실측 스타일 컴포넌트와 비교하는 단계; 및상기 손실에 기초하여 상기 머신 학습 기술의 파라미터들을 업데이트하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제12항 또는 제13항에 있어서, 상기 오디오 스트림은 상기 제1 감정의 일부 및 상기 제2 감정의 일부와 함께 상기 제1 스피커에 의해 말해지는 상기 하나 이상의 단어를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 추가로,비디오를 수신하는 단계;상기 텍스트 문자열을 상기 비디오와 연관시키라는 요청을 수신하는 단계; 및상기 요청을 수신하는 것에 응답하여, 상기 제2 감정과 함께 상기 제1 스피커에 의해 말해지는 상기 하나 이상의 단어를 포함하는 상기 오디오 스트림을 상기 비디오에 추가하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 추가로,오디오 명령어, 추천, 또는 정보와 연관되는 증강 현실 경험을 수신하는 단계; 및상기 오디오 명령어, 상기 추천, 또는 상기 정보를 구두로 제공하기 위해 상기 오디오 스트림을 상기 증강 현실 경험과 연관시키는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 오디오 명령어, 상기 추천, 또는 상기 정보는 메시징 애플리케이션 상에서 상기 증강 현실 경험을 론칭하는 것에 응답하여 상기 텍스트 문자열로서 사용자로부터 수신되는 방법.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제17항 중 어느 한 항에 있어서, 상기 제1 스피커 및 상기 제2 감정에 대한 임베딩이 이용가능하지 않다고 결정하는 단계를 추가로 포함하고, 상기 제3 임베딩은 상기 제1 스피커 및 상기 제2 감정에 대한 임베딩이 이용가능하지 않다고 결정하는 것에 응답하여 생성되는 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서,동작들을 수행하도록 구성되는 프로세서를 포함하고, 상기 동작들은,하나 이상의 단어를 포함하는 텍스트 문자열에 액세스하는 동작;복수의 스피커들 중 제1 스피커에 대한 제1 임베딩 및 제2 스피커에 대한 제2 임베딩을 저장하는 동작- 상기 제1 임베딩은 제1 감정과 연관되고 상기 제2 임베딩은 제2 감정과 연관됨-;상기 하나 이상의 프로세서에 의해, 상기 텍스트 문자열의 상기 하나 이상의 단어의 가상 스피치에 대해 상기 제1 스피커를 선택하는 동작;상기 텍스트 문자열의 상기 하나 이상의 단어가 상기 제2 감정과 연관된다고 결정하는 동작;상기 제1 스피커의 상기 제1 임베딩 및 상기 제2 스피커의 상기 제2 임베딩에 기초하여, 상기 제2 감정과 연관된 상기 제1 스피커에 대한 제3 임베딩을 생성하는 동작; 및상기 제2 감정과 함께 상기 제1 스피커에 의해 가상으로 말해지는 상기 하나 이상의 단어를 포함하는 오디오 스트림을 생성하기 위해 상기 제1 스피커의 상기 제3 임베딩 및 상기 텍스트 문자열을 보코더에 적용하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함하는 비-일시적인 머신-판독가능 저장 매체로서, 상기 명령어들은, 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서로 하여금 동작들을 수행하게 하고, 상기 동작들은,하나 이상의 단어를 포함하는 텍스트 문자열에 액세스하는 동작;복수의 스피커들 중 제1 스피커에 대한 제1 임베딩 및 제2 스피커에 대한 제2 임베딩을 저장하는 동작- 상기 제1 임베딩은 제1 감정과 연관되고 상기 제2 임베딩은 제2 감정과 연관됨-;상기 하나 이상의 프로세서에 의해, 상기 텍스트 문자열의 상기 하나 이상의 단어의 가상 스피치에 대해 상기 제1 스피커를 선택하는 동작;상기 텍스트 문자열의 상기 하나 이상의 단어가 상기 제2 감정과 연관된다고 결정하는 동작;상기 제1 스피커의 상기 제1 임베딩 및 상기 제2 스피커의 상기 제2 임베딩에 기초하여, 상기 제2 감정과 연관된 상기 제1 스피커에 대한 제3 임베딩을 생성하는 동작; 및상기 제2 감정과 함께 상기 제1 스피커에 의해 가상으로 말해지는 상기 하나 이상의 단어를 포함하는 오디오 스트림을 생성하기 위해 상기 제1 스피커의 상기 제3 임베딩 및 상기 텍스트 문자열을 보코더에 적용하는 동작을 포함하는 비-일시적 머신-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>HARAZI, Liron</engName><name>하라지, 리론</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>ASSA, Jackie</engName><name>아싸, 재키</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>BEKKER, Alan</engName><name>베커, 아란</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.02.08</priorityApplicationDate><priorityApplicationNumber>17/667,128</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.09.04</receiptDate><receiptNumber>1-1-2024-0971029-53</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.09.04</receiptDate><receiptNumber>1-1-2024-0971931-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.09</receiptDate><receiptNumber>1-5-2024-0147657-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.24</receiptDate><receiptNumber>9-5-2025-1033193-92</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247029776.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338ed1317dba44d9790ab7d3f6a436f74414dd48c634bc81e39781dde050d1d198f83fd9ddda263e0ac7a80f489348731ea00b0dc1cc750720e9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1ed19c573a05ab9cba5337a840721cb340ebcf65c40f3e6c585e55826d39ac15a97d1a38f7a0aca4a5e435d62076b55c4796fb7f7ce45814</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>