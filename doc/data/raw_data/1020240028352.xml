<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:27.5127</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0028352</applicationNumber><claimCount>11</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비전-언어 기반 제로-샷 행동 인식 장치 및 그 방법</inventionTitle><inventionTitleEng>DEVICE AND METHOD FOR RECOGNIZING ZERO-SHOT BEHAVIORS BASED  ON VISION-LANGUAGE</inventionTitleEng><openDate>2025.09.03</openDate><openNumber>10-2025-0131638</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.02.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 설명 속성 생성 방식과 시공간적 상호작용 접근 방식을 적용하여 입력 비디오 학습의 정밀도를 향상시킬 수 있는 비전-언어 기반 제로-샷 행동 인식 장치 및 그 방법이 개시된다. 비전-언어 기반 제로-샷 행동 인식 장치는, 외부에서 입력되는 입력 비디오 데이터를 패치 단위로 임베딩하여 패치 임베딩을 생성하고, 상기 패치 임베딩의 프레임 단위 임베딩을 기반으로 프레임 사이의 시간적 관계성을 임베딩하여 비디오 임베딩을 생성하는 비디오 데이터 처리모듈; 및 상기 입력 비디오 데이터와 연관된 적어도 하나 이상의 행동 클래스와 상기 행동 클래스와 연관된 추가적 설명 속성을 기반으로 상기 입력 비디오 데이터와의 유사도를 산출하고, 상기 산출된 유사도를 기반으로 상기 입력 비디오 데이터의 행동 클래스를 인식하는 행동 클래스 인식 모듈을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 외부에서 입력되는 입력 비디오 데이터를 패치 단위로 임베딩하여 패치 임베딩을 생성하고, 상기 패치 임베딩의 프레임 단위 임베딩을 기반으로 프레임 사이의 시간적 관계성을 임베딩하여 비디오 임베딩을 생성하는 비디오 데이터 처리모듈; 및 상기 입력 비디오 데이터와 연관된 적어도 하나 이상의 행동 클래스와 상기 행동 클래스와 연관된 추가적 설명 속성을 기반으로 상기 입력 비디오 데이터와의 유사도를 산출하고, 상기 산출된 유사도를 기반으로 상기 입력 비디오 데이터의 행동 클래스를 인식하는 행동 클래스 인식 모듈을 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 장치. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 비디오 데이터 처리 모듈은, 상기 입력 비디오 데이터를 패치 단위로 임베딩하여 프레임 단위의 상기 패치 임베딩을 생성하는 비디오 인코더를 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 비디오 데이터 처리 모듈은, 상기 패치 임베딩의 첫 번째 패치를 추출한 후 프레임 사이 연관성을 학습하여 시간적 정보를 합쳐 상기 비디오 임베딩을 생성하는 시간적 인코더를 더 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 장치. </claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 행동 클래스 인식 모듈은, 상기 행동 클래스와 연관된 추가적 설명 속성을 생성하는 설명 속성 생성부; 상기 행동 클래스와 상기 추가적 설명 속성을 인코딩하여 속성 임베딩과 클래스 임베딩을 생성하는 텍스트 인코더; 상기 패치 임베딩과 상기 속성 임베딩 간의 상호 유사성을 산정하는 공간적 상호작용부; 및 시간적 주목도를 활용하여 상기 속성 임베딩과 상기 프레임 임베딩 간의 세분화된 관련성을 추정하는 시간적 상호작용부를 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 장치. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 공간적 상호작용부는, 상기 패치 임베딩과 상기 속성 임베딩 간의 상호 유사도를 산출하고,　패치 단위별 가장 높은 유사도를 갖는 속성 임베딩과 프레임 단위별 가장 높은 유사도를 갖는 속성 임베딩을 생성하여 공간적 특징을 생성하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 장치. </claim></claimInfo><claimInfo><claim>6. 제4항에 있어서, 상기 시간적 상호작용부는, 상기 공간적 특징과 상기 비디오 임베딩을 곱셈 연산하여 공간적 정보를 주입한 공간적 비디오 임베딩과 상기 속성 임베딩간의 상호 유사도를 산출하고,　상기 산출된 유사도를 기반으로 시간적으로 높은 주목도를 갖는 프레임에 대한 정보를 포함하는 시간적 중요도 벡터를 생성하고,　상기 시간적 중요도 벡터와 상기 비디오 임베딩을 곱셈 연산하여 시공간적 특징을 생성하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 장치. </claim></claimInfo><claimInfo><claim>7. 외부에서 입력되는 입력 비디오 데이터를 패치 단위로 임베딩하여 패치 임베딩을 생성하는 단계; 상기 패치 임베딩의 프레임 단위 임베딩을 기반으로 프레임 사이의 시간적 관계성을 임베딩하여 비디오 임베딩을 생성하는 단계; 상기 입력 비디오 데이터와 연관된 적어도 하나 이상의 행동 클래스와 상기 행동 클래스와 연관된 추가적 설명 속성을 기반으로 상기 입력 비디오 데이터와의 유사도를 산출하는 단계; 및 상기 산출된 유사도를 기반으로 상기 입력 비디오 데이터의 행동 클래스를 인식하는 단계를 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 방법. </claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 유사도를 산출하는 단계는, 상기 행동 클래스와 연관된 추가적 설명 속성을 생성하는 단계; 상기 행동 클래스와 상기 추가적 설명 속성을 인코딩하여 속성 임베딩과 클래스 임베딩을 생성하는 단계; 상기 패치 임베딩과 상기 속성 임베딩 간의 상호 유사성을 산정하는 단계; 및 시간적 주목도를 활용하여 상기 속성 임베딩과 상기 프레임 임베딩 간의 세분화된 관련성을 추정하는 단계를 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 추가적 설명 속성을 생성하는 단계는, 상기 행동 클래스와 연관된 사전 정의 데이터를 웹 크롤링 방식으로 수집하는 단계; 상기 수집된 사전 정의 데이터로부터 주요 키워드를 추출하는 단계; 및 미리 마련된 텍스트 형식에 상기 주요 키워드를 삽입하여 상기 추가적 설명 속성을 생성하는 단계를 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 방법. </claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 상호 유사성을 산정하는 단계는, 상기 패치 임베딩과 상기 속성 임베딩을 행렬로 배열하고 코사인 유사도를 각각 산정하는 단계; 열 방향으로 배열된 벡터들 중 가장 높은 값을 추출하는 1차 맥스 풀링 과정을 수행하는 단계; 및 상기 1차 맥스 풀링 과정을 통해 획득된 값들에 대해 프레임 단위로 2차 맥스 풀링 과정을 수행하여 공간적 특징을 획득하는 단계를 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 방법.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서, 상기 세분화된 관련성을 추정하는 단계는, 상기 비디오 임베딩과 상기 속성 임베딩을 행렬로 배열하고 코사인 유사도를 각각 산정하는 단계; 여러 프레임에 걸쳐 에버리지 풀링 과정을 통해 평균을 집계하여 다양한 단어에 걸쳐 프레임별 시간적 주목도를 측정하는 단계; 및 상기 시간적 주목도와 상기 비디오 임베딩을 행렬 곱 연산 처리하여 시공간적 특징이 모두 적용된 비디오 표현을 도출하는 단계를 포함하는 것을 특징으로 하는 비전-언어 기반 제로-샷 행동 인식 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성북구...</address><code>220040170680</code><country>대한민국</country><engName>Korea University Research and Business Foundation</engName><name>고려대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>Lee, Seong Whan</engName><name>이성환</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>Kim Yehna</engName><name>김예나 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 금천구 디지털로 *** (가산동) 가산퍼블릭 A동 ***,***호(디앤특허법률사무소)</address><code>920100008438</code><country>대한민국</country><engName>YUN KUI SANG</engName><name>윤귀상</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.02.27</receiptDate><receiptNumber>1-1-2024-0226458-52</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240028352.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93df6dbba8cd51b7954fc972d81d27fb67eed8d7f7ef45b0d503572113a06fc373d237c0826ffb34fa47cbdccca84a153208b62c61966ac6af</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf310e7b1f9d7c91f3a86a7c2ca6afddaddb27ec8b6c5a9e9114b3e8e6d9628b68396db64bdd2755fac9dc61ff9a00fab2554cef8f1db43916</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>