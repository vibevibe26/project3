<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:44.3944</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7028666</applicationNumber><claimCount>32</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>효율적인 워핑 기반 뉴럴 비디오 코덱</inventionTitle><inventionTitleEng>EFFICIENT WARPING-BASED NEURAL VIDEO CODEC</inventionTitleEng><openDate>2025.10.29</openDate><openNumber>10-2025-0155015</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.08.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/513</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/124</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/186</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/436</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/587</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/91</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 예시적인 디바이스는 메모리 및 하나 이상의 프로세서들을 포함할 수 있다. 하나 이상의 프로세서들은 엔트로피 디코딩된 데이터를 생성하기 위해 수신된 비트스트림으로부터 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하도록 구성될 수 있다. 하나 이상의 프로세서들은 엔트로피 디코딩된 데이터에 기초하여 모션 벡터를 예측하도록 구성될 수 있다. 하나 이상의 프로세서들은 엔트로피 디코딩된 데이터로부터 모션 벡터 잔차를 디코딩하도록 구성될 수 있다. 하나 이상의 프로세서들은 모션 벡터 잔차 및 모션 벡터를 가산하도록 구성될 수 있다. 하나 이상의 프로세서들은 예측된 현재의 비디오 데이터를 생성하기 위해 모션 벡터를 사용하여 오버랩된 블록 기반 워프 함수로 이전의 재구성된 비디오 데이터를 워핑하도록 구성될 수 있다. 하나 이상의 프로세서들은 현재의 재구성된 비디오 데이터를 생성하기 위해 예측된 현재의 비디오 데이터를 잔차 블록과 합산하도록 구성될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.09.12</internationOpenDate><internationOpenNumber>WO2024186678</internationOpenNumber><internationalApplicationDate>2024.03.01</internationalApplicationDate><internationalApplicationNumber>PCT/US2024/018215</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 데이터를 코딩하기 위한 디바이스로서,상기 비디오 데이터를 저장하기 위한 메모리로서, 상기 비디오 데이터는 이전의 재구성된 비디오 데이터 및 현재의 재구성된 비디오 데이터를 포함하는, 상기 메모리; 및하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은: 엔트로피 디코딩된 데이터를 생성하기 위해 수신된 비트스트림으로부터 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하고; 예측된 모션 벡터를 생성하기 위해 상기 엔트로피 디코딩된 데이터에 기초하여 블록 기반 모션 벡터를 예측하고; 상기 엔트로피 디코딩된 데이터로부터 모션 벡터 잔차를 디코딩하고; 상기 블록 기반 모션 벡터를 생성하기 위해 상기 예측된 모션 벡터에 상기 모션 벡터 잔차를 가산하고; 예측된 현재의 비디오 데이터를 생성하기 위해 상기 블록 기반 모션 벡터를 사용하여 오버랩된 블록 기반 워프 함수로 상기 이전의 재구성된 비디오 데이터를 워핑하고; 상기 현재의 재구성된 비디오 데이터를 생성하기 위해 상기 예측된 현재의 비디오 데이터를 잔차 블록과 합산하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 모션 벡터 잔차를 디코딩하는 것의 일부로서, 상기 하나 이상의 프로세서들은 뉴럴 네트워크 모델을 사용하여 픽셀 기반 모션 벡터 잔차를 디코딩하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 뉴럴 네트워크 모델은 양자화-인식 트레이닝되는, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 오버랩된 블록 기반 워프 함수는,워핑 결과들을 생성하기 위해 각각의 주위 블록의 각각의 모션 벡터를 사용하여 상기 이전의 재구성된 비디오 데이터의 블록을 복수회 워핑하고;감쇠를 사용하여 상기 워핑 결과들을 평균화하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하는 것의 일부로서, 상기 하나 이상의 프로세서들은 적어도 하나의 그래픽스 프로세싱 유닛으로 상기 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 이전의 재구성된 비디오 데이터를 워핑하는 것의 일부로서, 상기 하나 이상의 프로세서들은 상기 이전의 재구성된 비디오 데이터를 블록 기반 프레임 보간(FINT) 워핑하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 이전의 재구성된 비디오 데이터를 블록 기반 FINT 워핑하는 것의 일부로서, 상기 하나 이상의 프로세서들은 FINT 커널을 사용하여 상기 이전의 재구성된 비디오 데이터를 FINT 워핑하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 FINT 커널은 뉴럴 네트워크 신호 프로세서에서 구현되는, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 인코딩된 비디오 데이터는 YUV420 비디오 데이터를 나타내고 상기 현재의 재구성된 비디오 데이터는 YUV420 비디오 데이터를 포함하는, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 하나 이상의 프로세서들은 상기 엔트로피 디코딩된 데이터의 적어도 일부를 양자화하도록 추가로 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 엔트로피 디코딩된 데이터의 상기 적어도 일부를 양자화하는 것의 일부로서, 상기 하나 이상의 프로세서들은 레이턴트, 평균, 또는 스케일 중 적어도 하나를 양자화하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 엔트로피 디코딩된 데이터의 상기 적어도 일부를 양자화하는 것의 일부로서, 상기 하나 이상의 프로세서들은 int8을 사용하여 상기 엔트로피 디코딩된 데이터의 상기 적어도 일부를 양자화하도록 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 하나 이상의 프로세서들은, 외삽된 흐름을 생성하기 위해 흐름 외삽기를 상기 엔트로피 디코딩된 데이터에 적용하도록 추가로 구성되는, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 하나 이상의 프로세서들은, 상기 외삽된 흐름을 사용하여 가산적 흐름 예측을 수행하도록 추가로 구성된, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 상기 인코딩된 비디오 데이터는 루마 데이터를 포함하는, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>16. 비디오 데이터를 디코딩하는 방법으로서,엔트로피 디코딩된 데이터를 생성하기 위해 수신된 비트스트림으로부터 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하는 단계;예측된 모션 벡터를 생성하기 위해 상기 엔트로피 디코딩된 데이터에 기초하여 블록 기반 모션 벡터를 예측하는 단계;상기 엔트로피 디코딩된 데이터로부터 모션 벡터 잔차를 디코딩하는 단계;상기 블록 기반 모션 벡터를 생성하기 위해 상기 모션 벡터 잔차 및 상기 예측된 모션 벡터를 가산하는 단계;예측된 현재의 비디오 데이터를 생성하기 위해 상기 블록 기반 모션 벡터를 사용하여 오버랩된 블록 기반 워프 함수로 이전의 재구성된 비디오 데이터를 워핑하는 단계; 및현재의 재구성된 비디오 데이터를 생성하기 위해 상기 예측된 현재의 비디오 데이터를 잔차 블록과 합산하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 모션 벡터 잔차를 디코딩하는 단계는 뉴럴 네트워크 모델을 사용하여 픽셀 기반 모션 벡터 잔차를 디코딩하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 뉴럴 네트워크 모델은 양자화-인식 트레이닝되는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 오버랩된 블록 기반 워프 함수로 상기 이전의 재구성된 비디오 데이터를 워핑하는 단계는,워핑 결과들을 생성하기 위해 각각의 주위 블록의 각각의 모션 벡터를 사용하여 상기 이전의 재구성된 비디오 데이터의 블록을 복수회 워핑하는 단계; 및감쇠를 사용하여 상기 워핑 결과들을 평균화하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서, 상기 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하는 단계는 적어도 하나의 그래픽스 프로세싱 유닛으로 상기 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>21. 제16항에 있어서, 상기 이전의 재구성된 비디오 데이터를 워핑하는 단계는 상기 이전의 재구성된 비디오 데이터를 블록 기반 프레임 보간(FINT) 워핑하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 이전의 재구성된 비디오 데이터를 블록 기반 FINT 워핑하는 단계는 FINT 커널을 사용하여 상기 이전의 재구성된 비디오 데이터를 FINT 워핑하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 FINT 커널은 뉴럴 네트워크 신호 프로세서에서 구현되는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>24. 제16항에 있어서, 상기 인코딩된 비디오 데이터는 YUV420 비디오 데이터를 나타내고 상기 현재의 재구성된 비디오는 YUV420 비디오 데이터를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>25. 제16항에 있어서, 상기 엔트로피 디코딩된 데이터의 적어도 일부를 양자화하는 단계를 더 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 엔트로피 디코딩된 데이터의 상기 적어도 일부를 양자화하는 단계는 레이턴트, 평균, 또는 스케일 중 적어도 하나를 양자화하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>27. 제25항에 있어서, 상기 엔트로피 디코딩된 데이터의 상기 적어도 일부를 양자화하는 단계는 int8을 사용하여 상기 엔트로피 디코딩된 데이터의 상기 적어도 일부를 양자화하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>28. 제16항에 있어서, 외삽된 흐름을 생성하기 위해 상기 엔트로피 디코딩된 데이터에 흐름 외삽기를 적용하는 단계를 더 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 외삽된 흐름을 사용하여 가산적 흐름 예측을 미리 형성하는 단계를 더 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>30. 제16항에 있어서, 상기 인코딩된 비디오 데이터는 루마 데이터를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>31. 비디오 데이터를 코딩하기 위한 디바이스로서,엔트로피 디코딩된 데이터를 생성하기 위해 수신된 비트스트림으로부터 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하기 위한 수단;예측된 모션 벡터를 생성하기 위해 상기 엔트로피 디코딩된 데이터에 기초하여 블록 기반 모션 벡터를 예측하기 위한 수단;상기 엔트로피 디코딩된 데이터로부터 모션 벡터 잔차를 디코딩하기 위한 수단;상기 블록 기반 모션 벡터를 생성하기 위해 상기 모션 벡터 잔차 및 상기 예측된 모션 벡터를 가산하기 위한 수단;예측된 현재의 비디오 데이터를 생성하기 위해 상기 블록 기반 모션 벡터를 사용하여 오버랩된 블록 기반 워프 함수로 이전의 재구성된 비디오 데이터를 워핑하기 위한 수단; 및현재의 재구성된 비디오 데이터를 생성하기 위해 상기 예측된 현재의 비디오 데이터를 잔차 블록과 합산하기 위한 수단을 포함하는, 비디오 데이터를 코딩하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>32. 명령들을 저장하는 비일시적, 컴퓨터 판독가능 저장 매체로서, 상기 명령들은, 실행될 때, 하나 이상의 프로세서들로 하여금:엔트로피 디코딩된 데이터를 생성하기 위해 수신된 비트스트림으로부터 인코딩된 비디오 데이터를 병렬 엔트로피 디코딩하게 하고;예측된 모션 벡터를 생성하기 위해 상기 엔트로피 디코딩된 데이터에 기초하여 블록 기반 모션 벡터를 예측하게 하고;상기 엔트로피 디코딩된 데이터로부터 모션 벡터 잔차를 디코딩하게 하고;상기 블록 기반 모션 벡터를 생성하기 위해 상기 예측된 모션 벡터에 상기 모션 벡터 잔차를 가산하게 하고;예측된 현재의 비디오 데이터를 생성하기 위해 상기 블록 기반 모션 벡터를 사용하여 오버랩된 블록 기반 워프 함수로 이전의 재구성된 비디오 데이터를 워핑하게 하고;현재의 재구성된 비디오 데이터를 생성하기 위해 상기 예측된 현재의 비디오 데이터를 잔차 블록과 합산하게 하는, 명령들을 저장하는 비일시적, 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>네덜란드</country><engName>VAN ROZENDAAL, TIES JEHAN</engName><name>판 로전달 티스 예한</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>베트남</country><engName>LE, HOANG CONG MINH</engName><name>레 호앙 콩 민</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>인도</country><engName>SINGHAL, TUSHAR</engName><name>싱갈 투샤르</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>SAID, AMIR</engName><name>사이드 아미르</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>BUSKA, KRISHNA</engName><name>부스카 크리쉬나</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>프랑스</country><engName>SAUTIERE, GUILLAUME KONRAD</engName><name>소띠에르 기욤 콘라드</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>RAHA, ANJUMAN</engName><name>라하 안주만</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>네덜란드</country><engName>WIGGERS, AUKE JORIS</engName><name>비허르스 아우커 요리스</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>독일</country><engName>MAYER, FRANK STEVEN</engName><name>마이어 프랑크 슈테펜</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>ZHANG, LIANG</engName><name>장 량</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>KHOBARE, ABHIJIT</engName><name>코바레 아브히지트</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>AKULA, MURALIDHAR REDDY</engName><name>아쿨라 무랄리다르 레디</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.03.09</priorityApplicationDate><priorityApplicationNumber>63/489,306</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.04.20</priorityApplicationDate><priorityApplicationNumber>63/497,411</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.08.28</priorityApplicationDate><priorityApplicationNumber>18/457,079</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.08.27</receiptDate><receiptNumber>1-1-2025-0983475-63</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.10.13</receiptDate><receiptNumber>1-5-2025-0167568-86</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257028666.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9382e2fb3b5c49a2d44a7fcfe94ea688a1ecfe70a26ae5118333bfe62c18daba2ab5d78bb75888e3e9e4e99f82d71607329ec2900f7f477238</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd4d52feee4e6cbabc55ecbe8929caa7512df02298bf7e1e9e927f5b1fa725a8a70e0353fdf0f612f3f7f69b8850bc389d774e8b7024d0f82</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>