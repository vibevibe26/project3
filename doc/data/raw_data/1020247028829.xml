<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:49.3349</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.03.24</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7028829</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>타겟 객체 식별 장치 및 그 장치의 제어 방법</inventionTitle><inventionTitleEng>TARGET AVATAR IDENTIFICATION APPARATUS, AND CONTROL METHOD FOR APPARATUS</inventionTitleEng><openDate>2024.10.11</openDate><openNumber>10-2024-0148361</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04W 4/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06F 3/048</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 차량에 구비된 적어도 하나의 카메라에서 획득된 상기 차량 주변의 이미지를 수신하는 인터페이스부와, 기 저장된 식별정보에 대응하는 타겟 디바이스와 기 설정된 통신 방식에 따라 무선 통신을 시도하고, 무선 통신이 연결되면 타겟 디바이스의 위치를 산출하기 위한 적어도 하나의 메시지를 교환하는 적어도 하나의 앵커 센서 및, 적어도 하나의 앵커 센서와 타겟 디바이스와의 무선 통신 연결 상태에 근거하여 타겟 디바이스의 위치를 산출하고, 인터페이스부를 통해 타겟 디바이스의 방향을 지향하는 카메라에서 센싱된 이미지를 수신 및, 수신된 이미지에 포함된 각 객체의 위치들을 산출하며, 이미지를 통해 산출된 각 객체의 위치들 중, 산출된 타겟 디바이스의 위치로부터 기 설정된 오차 거리 이내에 위치한 어느 하나의 객체를 타겟 디바이스에 대응하는 대상으로 식별하는 프로세서를 포함하는 것을 특징으로 한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.01.04</internationOpenDate><internationOpenNumber>WO2024005303</internationOpenNumber><internationalApplicationDate>2023.03.24</internationalApplicationDate><internationalApplicationNumber>PCT/KR2023/003976</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1.  차량에 구비된 적어도 하나의 카메라에서 획득된 상기 차량 주변의 이미지를 수신하는 인터페이스부;기 저장된 식별정보에 대응하는 타겟 디바이스와 기 설정된 통신 방식에 따라 무선 통신을 시도하고, 무선 통신이 연결되면 상기 타겟 디바이스의 위치를 산출하기 위한 적어도 하나의 메시지를 교환하는 적어도 하나의 앵커(Anchor) 센서; 및,상기 적어도 하나의 앵커 센서와 상기 타겟 디바이스와의 무선 통신 연결 상태에 근거하여 상기 타겟 디바이스의 위치를 산출하고, 상기 인터페이스부를 통해 상기 타겟 디바이스의 방향을 지향하는 카메라에서 센싱된 이미지를 수신 및, 수신된 이미지에 포함된 각 객체의 위치들을 산출하며, 상기 이미지를 통해 산출된 각 객체의 위치들 중, 상기 산출된 타겟 디바이스의 위치로부터 기 설정된 오차 거리 이내에 위치한 어느 하나의 객체를 상기 타겟 디바이스에 대응하는 대상으로 식별하는 프로세서를 포함하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>2.  제1항에 있어서,메타버스(metaverse) 플랫폼을 제공하며, 상기 메타버스 플랫폼을 통해 상기 차량에 메타버스 가상공간에 관련된 서비스를 제공하는 클라우드 서버와 무선 통신을 수행하는 통신부를 더 구비하고,상기 프로세서는,상기 차량 주변의 객체들 중 상기 타겟 디바이스에 대응하는 대상으로 식별된 어느 하나의 위치 정보를 상기 클라우드 서버에 전송하고, 상기 식별된 대상의 위치 정보 전송에 대한 응답으로, 상기 클라우드 서버로부터 상기 식별된 대상에 대응하는 아바타(avatar)가 상기 차량 주변에 표시되는 상기 메타버스 가상공간의 정보를 수신하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>3.  제2항에 있어서, 상기 식별된 대상의 위치 정보는,상기 적어도 하나의 앵커 센서와 상기 타겟 디바이스 사이에서 교환된 메시지의 송수신 시각에 따라 산출되는 상기 타겟 디바이스까지의 거리 및 상기 타겟 디바이스로부터 수신되는 신호의 신호 도래각(Arrival Of Angle, AOA)으로부터 산출되는 타겟 디바이스의 방향에 대응하는 제1 위치, 또는 상기 타겟 디바이스의 방향을 지향하는 카메라에서 센싱된 이미지에 포함된 상기 식별된 대상에 대응하는 객체의 깊이 정보에 따라 산출되는 거리와 상기 센싱된 이미지의 화각 중심에서 상기 식별된 대상에 대응하는 객체의 중심에 이르는 간격에 따라 산출되는 방향에 대응하는 제2 위치 중 어느 하나임을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>4.  제2항에 있어서,상기 클라우드 서버는,상기 식별된 대상의 위치 정보가 수신되면, 상기 차량의 위치 주변에 상기 메타버스 가상공간을 공유하는 것으로 기 설정된 다른 사용자를 더 검출하고, 검출 결과 상기 메타버스 가상공간을 공유하는 적어도 하나의 다른 사용자의 아바타와 위치 정보를 상기 프로세서에 더 전송하며,상기 프로세서는,상기 식별된 대상의 아바타 및 상기 적어도 하나의 다른 사용자의 아바타가 상기 차량에 대응하는 객체 주변에 표시된 상기 메타버스 가상공간의 이미지가, 상기 차량의 디스플레이부 상에 표시되도록 상기 인터페이스부를 제어하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>5.  제2항에 있어서,상기 프로세서는,상기 수신된 메타버스 가상공간의 이미지가 상기 차량의 디스플레이부 상에 표시되도록 상기 인터페이스부를 제어하며,상기 메타버스 가상공간의 이미지는,상기 차량 주변의 객체들 중 상기 타겟 디바이스에 대응하는 식별된 객체를 상기 수신된 아바타로 표시하여, 식별되지 않은 나머지 객체들과 구분되도록 표시한 이미지임을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>6.  제2항에 있어서, 상기 프로세서는,상기 타겟 디바이스의 방향을 지향하는 카메라에서 센싱된 이미지로부터, 상기 타겟 디바이스와의 무선 통신 연결 상태에 따른 상기 타겟 디바이스의 위치를 검출한 결과, 상기 타겟 디바이스에 대응하는 상기 이미지 상의 위치가 벽 또는 장애물인 경우, 상기 벽 또는 장애물에 의해 상기 타겟 디바이스에 대응하는 대상이 가려진 것으로 검출하고,상기 타겟 디바이스의 위치에 대응하는 상기 이미지 상의 벽 또는 장애물, 또는 상기 아바타를 반투명하게 표시하여, 상기 벽 또는 장애물에 의해 가려진 상기 타겟 디바이스에 대응하는 대상의 위치가 표시된 상기 메타버스 가상공간의 이미지가 상기 차량의 디스플레이부 상에 표시되도록 상기 인터페이스부를 제어하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>7.  제2항에 있어서, 상기 타겟 식별정보는,상기 클라우드 서버에서 제공되는 특정 서비스의 가입자가 소지한 타겟 기기의 식별 정보임을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>8.  제7항에 있어서, 상기 타겟 기기는,상기 기 설정된 통신 방식에 따른 무선 통신을 지원하는 통신 기기 또는 상기 기 설정된 통신 방식에 따른 무선 통신을 수행할 수 있는 RF(radio Frequency) 회로를 포함하는 태그(tag)가 부착된 기기임을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>9.  제1항에 있어서, 상기 기 설정된 통신 방식은,UWB(Ultra Wide Band) 대역의 무선 신호를 이용하는 통신 방식임을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>10.  제1항에 있어서, 상기 프로세서는,상기 차량의 일 지점을 기준점으로 설정하고, 각 앵커 센서의 위치를 기준으로 하는 좌표계에서, 상기 설정된 기준점을 기준으로 하는 좌표계로의 좌표 변환을 통해, 상기 적어도 하나의 앵커 센서 각각을 기준으로 산출되는 타겟 디바이스의 위치를 상기 기준점을 기준으로 하는 위치로 보정하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>11.  제10항에 있어서,상기 앵커 센서는 2개 이상이며,상기 프로세서는,상기 복수의 앵커 센서 각각을 기준으로 산출되는 타겟 디바이스의 위치들을, 상기 좌표 변환을 통해 상기 기준점을 기준으로 하는 좌표계에 따른 위치들로 보정하고, 보정된 위치들의 좌표 평균을 산출하여 상기 타겟 디바이스의 위치를 결정하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>12.  제1항에 있어서, 상기 프로세서는,상기 차량의 일 지점을 기준점으로 설정하고, 각 앵커 센서의 위치를 기준으로 하는 좌표계에서, 상기 설정된 기준점을 기준으로 하는 좌표계로의 좌표 변환을 통해, 상기 카메라의 위치를 기준으로 산출되는 타겟 디바이스의 위치를 상기 기준점을 기준으로 하는 위치로 보정하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>13.  제10항 또는 제12항에 있어서, 상기 기준점은,상기 차량의 전면 중심과 상기 차량의 후면 중심을 잇는 중심축과, 상기 차량의 후룬 각각의 중심을 잇는 후차축이 교차하는 지점임을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>14.  제1항에 있어서, 상기 프로세서는,상기 차량에 구비된 복수의 카메라 중, 상기 타겟 디바이스와의 무선 통신 연결 상태에 따라 산출된 상기 타겟 디바이스의 방향을 포함하는 FOV(Field Of View)에 대응하는 이미지를 센싱하는 어느 하나의 카메라를 검출하고, 검출된 카메라에서 센싱된 이미지에 포함된 각 객체의 위치들을 산출하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>15.  제1항에 있어서,상기 차량의 및 상기 타겟 디바이스의 GPS 위치를 산출하는 위치 산출부를 더 포함하고,상기 프로세서는,상기 위치 산출 결과, 상기 차량의 GPS 위치와 상기 타겟 디바이스의 GPS 위치 사이의 거리가 기 설정된 거리를 초과하는 경우 상기 적어도 하나의 앵커 센서를 비활성 상태로 유지하고,상기 차량의 GPS 위치와 상기 타겟 디바이스의 GPS 위치 사이의 거리가 기 설정된 거리 이하인 경우 상기 적어도 하나의 앵커 센서를 비활성 상태에서 활성 상태로 전환하여, 상기 적어도 하나의 앵커 센서와 상기 타겟 디바이스 간의 무선 통신을 연결하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>16.  제2항에 있어서, 상기 프로세서는,상기 산출된 타겟 디바이스로부터 기 설정된 오차 거리 이내에 위치한 객체가 복수인 경우, 상기 이미지로부터 산출되는 상기 객체들의 위치에 근거하여 상기 객체들 중 적어도 일부를 상기 타겟 디바이스에 대응하는 타겟 그룹으로 식별하고 상기 타겟 그룹에 포함된 객체들 각각의 위치 정보를 상기 클라우드 서버에 전송하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>17.  제16항에 있어서, 상기 클라우드 서버는,상기 타겟 그룹에 포함된 객체들 각각의 위치 정보에 대한 응답으로 상기 타겟 그룹에 포함된 객체들 중, 센싱된 이미지로부터 산출된 위치가 상기 타겟 디바이스와의 무선 통신 연결 상태에 따른 상기 타겟 디바이스의 위치에 가장 인접한 어느 하나의 객체에 상기 식별된 대상에 대응하는 아바타를 표시 및, 나머지 타겟 그룹의 객체들이 표시된 상기 메타버스 가상공간의 이미지를, 상기 타겟 그룹의 위치 정보 전송에 대한 응답으로 제공하는 것을 특징으로 하는 객체 식별 장치. </claim></claimInfo><claimInfo><claim>18.  특정 타겟 디바이스의 식별 정보를 수신하는 단계;적어도 하나의 앵커(Anchor) 센서를 통해 상기 기 설정된 통신 방식에 따라 상기 타겟 디바이스와 무선 통신을 시도하고, 상기 타겟 디바이스와의 무선 통신이 연결되면 상기 타겟 디바이스와 페어링(paring)을 수행하는 단계;페어링이 이루어지면, 상기 적어도 하나의 앵커 센서가 상기 타겟 디바이스의 위치를 산출하기 위한 메시지를 교환하고, 상기 메시지 교환을 통해 상기 타겟 디바이스의 위치를 산출하는 단계;차량으로부터, 상기 타겟 디바이스의 위치에 따른 방향의 이미지를 센싱하는 카메라를 검출하는 단계;검출된 카메라에서 센싱된 이미지 내의 객체들 각각에 대하여, 깊이 정보 및 화각 중심에 근거하여 상기 카메라로부터 상기 객체들 각각의 거리 및 방향을 포함하는 객체들의 위치들을 산출하는 단계;상기 산출된 객체들의 위치들 중, 상기 타겟 디바이스로부터 기 설정된 오차 거리 이내에 위치한 객체의 위치를 검출하는 단계; 및,상기 타겟 디바이스로부터 상기 오차 거리 이내에 위치한 이미지 상의 객체를, 상기 타겟 디바이스에 대응하는 대상으로 식별하는 단계를 포함하는 것을 특징으로 하는 객체 식별 장치의 제어 방법. </claim></claimInfo><claimInfo><claim>19.  제18항에 있어서,메타버스 플랫폼을 제공하며, 상기 메타버스 플랫폼을 통해 메타버스 가상공간에 관련된 서비스를 제공하는 클라우드 서버에 상기 타겟 디바이스에 대응하는 식별된 대상의 위치 정보를 전송하는 단계;상기 위치 정보 전송에 대한 응답으로, 상기 식별된 대상에 대응하는 아바타를 포함하는 상기 메타버스 가상공간의 정보를 수신하는 단계; 및,수신된 메타버스 가상공간의 정보에 따라, 상기 식별된 대상의 위치에 상기 아바타가 표시되는 상기 메타버스 가상공간의 이미지를, 상기 차량의 디스플레이부에 표시하는 단계를 더 포함하는 것을 특징으로 하는 객체 식별 장치의 제어 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 영등포구...</address><code>120020128403</code><country>대한민국</country><engName>LG Electronics Inc.</engName><name>엘지전자 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>CHOI Sunghwan</engName><name>최성환</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>KIM Taekyoung</engName><name>김태경</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>LEE Heemin</engName><name>이희민</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>SEO Jungryul</engName><name>서정렬</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>LEE Kihyung</engName><name>이기형</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.06.29</priorityApplicationDate><priorityApplicationNumber>1020220079894</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.27</receiptDate><receiptNumber>1-1-2024-0938660-24</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.09</receiptDate><receiptNumber>1-5-2024-0147987-00</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247028829.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9398493e17c3b8ac69225fecaf97ad45dfca74f57011b72fa8656c47e1100a33192c2b77ae04005279250c40376848ffa1c5209e1435705c11</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1cfe29b956979877fe9edf457a82e5c3b2a45123e06df0dbbf730497faea90fc89d2457ae64b6c1c6f6878d80125036862c6f570b3ab35fe</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>