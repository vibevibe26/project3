<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:23.523</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.04.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0049051</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>빛 추정 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR LIGHT ESTIMATION</inventionTitleEng><openDate>2023.10.27</openDate><openNumber>10-2023-0149615</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 빛 추정 방법 및 장치가 제공된다. 일 실시예에 따르면, 그 방법은 참조 객체의 촬영에 따른 로 영상 데이터 및 제1 ISP 설정에 기초하여 생성된, 참조 영상을 획득하고, 참조 객체가 위치한 현실 배경의 촬영에 따른 로 영상 데이터 및 제2 ISP 설정에 기초하여 생성된, 배경 영상을 획득하고, 빛 추정 모델을 이용하여 배경 영상에 대응하는 빛 정보를 추정하고, 빛 정보 및 참조 객체에 대응하는 가상 객체 영상을 렌더링하고, 참조 영상과 가상 객체 영상 간의 차이에 기초하여 빛 추정 모델을 트레이닝하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 빛 추정을 위한 방법에 있어서,참조 객체의 촬영에 따른 로 영상 데이터 및 제1 ISP 설정에 기초하여 생성된, 참조 영상을 획득하는 단계;상기 참조 객체가 위치한 현실 배경의 촬영에 따른 로 영상 데이터 및 제2 ISP 설정에 기초하여 생성된, 배경 영상을 획득하는 단계;빛 추정 모델을 이용하여 상기 배경 영상에 대응하는 빛 정보를 추정하는 단계;상기 빛 정보 및 상기 참조 객체에 대응하는 가상 객체 영상을 렌더링하는 단계; 및상기 참조 영상과 상기 가상 객체 영상 간의 차이에 기초하여 상기 빛 추정 모델을 트레이닝하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 ISP 설정은 고정 조절 값에 따라 ISP 요소를 제어하고,상기 제2 ISP 설정은 가변 조절 값에 따라 상기 ISP 요소를 제어하는,방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 ISP 요소는자동 화이트밸런스(auto white balance), 자동 노출(auto exposure), 감마 보정(gamma correction), 다이나믹 레인지 컴프레션(dynamic range compression), 및 와이드 다이나믹 레인지(wide dynamic range) 중 적어도 일부를 포함하는,방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 참조 객체는톤 및 재질 중 적어도 일부가 서로 다른 객체들, 및상기 객체들을 지지하는 평면들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 참조 객체의 촬영에 따른 상기 로 영상 데이터에서 상기 객체들은 각각 서로 다른 동적 범위(dynamic range)의 영상 데이터로 표현되고,상기 참조 영상과 상기 가상 객체 영상 간의 차이를 결정하는데 상기 객체들 중 가장 넓은 동적 범위를 가지는 어느 하나의 영상 데이터가 선택적으로 이용되는,방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 참조 객체는상기 참조 영상 및 상기 배경 영상을 생성하는 카메라와 지지부를 통해 연결되는,방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 카메라는상기 제1 ISP 설정을 사용하여 상기 참조 영상을 생성하는 제1 카메라, 및상기 제2 ISP 설정을 사용하여 상기 배경 영상을 생성하는 제2 카메라를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서,상기 가상 객체 영상을 렌더링하는 단계는상기 가상 객체 영상의 그림자를 렌더링하는 단계를 포함하고,상기 빛 추정 모델을 트레이닝하는 단계는상기 참조 영상에 나타난 상기 참조 객체의 그림자와 상기 가상 객체 영상에 렌더링된 상기 그림자 간의 차이를 고려하여 상기 빛 추정 모델을 트레이닝하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 참조 영상 및 상기 배경 영상은 상기 제1 ISP 설정 및 상기 제2 ISP 설정을 번갈아 사용하는 제3 카메라를 통해 생성되는,방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 배경 영상 및 상기 제2 ISP 설정에 대응하는 입력 데이터가 상기 빛 추정 모델의 입력으로 이용되는,방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 참조 영상 및 상기 배경 영상은각각 제1 위치 및 제1 방향에서 획득된 제1 참조 영상 및 제1 배경 영상, 각각 제2 위치 및 제2 방향에서 획득된 제2 참조 영상 및 제2 배경 영상을 포함하고,상기 빛 정보를 추정하는 단계는상기 제1 위치, 상기 제2 위치, 상기 제1 방향, 및 상기 제2 방향에 따른 SLAM 정보에 따른 상기 제1 배경 영상 및 상기 제2 배경 영상의 통합 배경 영상에 대응하는 통합 빛 정보를 추정하는 단계를 포함하고,상기 가상 객체 영상을 렌더링하는 단계는상기 통합 빛 정보에 기초하여 상기 제1 위치 및 상기 제1 방향에 대응하는 제1 가상 객체 영상 및 상기 제2 위치 및 상기 제2 방향에 대응하는 제2 가상 객체 영상을 렌더링하는 단계를 포함하고,상기 빛 추정 모델을 트레이닝하는 단계는상기 제1 참조 영상과 상기 제1 가상 객체 영상 간의 차이, 및 상기 제2 참조 영상과 상기 제2 가상 객체 영상 간의 차이 중 적어도 일부에 기초하여 상기 빛 추정 모델을 트레이닝하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 빛 추정을 위한 방법에 있어서,가상 객체를 표시할 현실 배경의 촬영에 따른 로 영상 데이터 및 제2 ISP 설정에 기초하여 생성된, 배경 영상을 획득하는 단계;빛 추정 모델을 이용하여 상기 배경 영상 및 제1 ISP 설정에 대응하는 빛 정보를 추정하는 단계;상기 빛 정보 및 상기 가상 객체에 대응하는 가상 객체 영상을 렌더링하는 단계; 및상기 가상 객체 영상 및 상기 배경 영상에 따른 AR 영상을 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 AR 영상이 불투명 디스플레이에 표시되는 경우, 상기 제2 ISP 설정에 기초한 상기 가상 객체 영상의 ISP 요소의 제어 결과가 상기 AR 영상의 생성에 이용되고,상기 AR 영상이 반투명 디스플레이에 표시되는 경우, 상기 제2 ISP 설정에 기초한 상기 ISP 요소의 제어 없이 상기 가상 객체 영상이 상기 AR 영상의 생성에 이용되는,방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 빛 추정 모델은참조 객체의 촬영에 따른 로 영상 데이터 및 상기 제1 ISP 설정에 기초하여 생성된, 샘플 참조 영상을 획득하는 단계;상기 참조 객체가 위치한 샘플 현실 배경의 촬영에 따른 로 영상 데이터 및 상기 제2 ISP 설정에 기초하여 생성된, 샘플 배경 영상을 획득하는 단계;상기 빛 추정 모델을 이용하여 상기 샘플 배경 영상에 대응하는 샘플 빛 정보를 추정하는 단계;상기 샘플 빛 정보 및 상기 참조 객체에 대응하는 샘플 가상 객체 영상을 렌더링하는 단계; 및상기 샘플 참조 영상과 상기 샘플 가상 객체 영상 간의 차이에 기초하여 상기 빛 추정 모델을 트레이닝하는 단계를 거쳐 미리 트레이닝되는, 방법.</claim></claimInfo><claimInfo><claim>15. 하드웨어와 결합되어 제1항 내지 제14항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 참조 객체의 촬영에 따른 로 영상 데이터 및 제1 ISP 설정에 기초하여 참조 영상을 생성하고, 상기 참조 객체가 위치한 현실 배경의 촬영에 따른 로 영상 데이터 및 제2 ISP 설정에 기초하여 배경 영상을 생성하는 카메라; 및빛 추정 모델을 이용하여 상기 배경 영상에 대응하는 빛 정보를 추정하고, 상기 빛 정보 및 상기 참조 객체에 대응하는 가상 객체 영상을 렌더링하고, 상기 참조 영상과 상기 가상 객체 영상 간의 차이에 기초하여 상기 빛 추정 모델을 트레이닝하는, 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 제1 ISP 설정은 고정 조절 값에 따라 ISP 요소를 제어하고,상기 제2 ISP 설정은 가변 조절 값에 따라 상기 ISP 요소를 제어하는,전자 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 참조 객체는 톤 및 재질 중 적어도 일부가 서로 다른 객체들, 및 상기 객체들을 지지하는 평면들을 포함하고,상기 참조 객체의 촬영에 따른 상기 로 영상 데이터에서 상기 객체들은 각각 서로 다른 동적 범위(dynamic range)의 영상 데이터로 표현되고,상기 참조 영상과 상기 가상 객체 영상 간의 차이를 결정하는데 상기 객체들 중 가장 넓은 동적 범위를 가지는 어느 하나의 영상 데이터가 선택적으로 이용되는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서,상기 배경 영상 및 상기 제2 ISP 설정에 대응하는 입력 데이터가 상기 빛 추정 모델의 입력으로 이용되는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서,상기 참조 영상 및 상기 배경 영상은각각 제1 위치 및 제1 방향에서 획득된 제1 참조 영상 및 제1 배경 영상, 각각 제2 위치 및 제2 방향에서 획득된 제2 참조 영상 및 제2 배경 영상을 포함하고,상기 프로세서는상기 제1 위치, 상기 제2 위치, 상기 제1 방향, 및 상기 제2 방향에 따른 SLAM 정보에 따른 상기 제1 배경 영상 및 상기 제2 배경 영상의 통합 배경 영상에 대응하는 통합 빛 정보를 추정하고,상기 통합 빛 정보에 기초하여 상기 제1 위치 및 상기 제1 방향에 대응하는 제1 가상 객체 영상 및 상기 제2 위치 및 상기 제2 방향에 대응하는 제2 가상 객체 영상을 렌더링하고,상기 제1 참조 영상과 상기 제1 가상 객체 영상 간의 차이, 및 상기 제2 참조 영상과 상기 제2 가상 객체 영상 간의 차이 중 적어도 일부에 기초하여 상기 빛 추정 모델을 트레이닝하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경상북도 포항시 남구...</address><code>420180163128</code><country>대한민국</country><engName>HA, Inwoo</engName><name>하인우</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code>420220083870</code><country>대한민국</country><engName>Jinwoo Park</engName><name>박진우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.04.20</receiptDate><receiptNumber>1-1-2022-0425438-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.03.19</receiptDate><receiptNumber>1-1-2025-0312846-49</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220049051.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93fc88783a72440b64e819b1344cc11d5e07dcbe4036fc2cf5c7f5b435613c4c49bfa2a4542180404a3f55232ef1b2fd9182c32acb1cfde073</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe7385d00aa2cc98c581b736be912e15a99d6d946ee660251243487053def3a6015e9f1702c9d525cae9f788ff9c5708c60ebae19d4c0c513</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>