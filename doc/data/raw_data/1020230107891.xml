<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:09:09.99</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0107891</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>퓨-샷 학습 방법 및 이를 이용한 영상 처리 시스템</inventionTitle><inventionTitleEng>METHOD FOR FEW-SHOT LEARNING AND IMAGE PROCESSING SYSTEM USING THE METHOD FOR FEW-SHOT LEARNING</inventionTitleEng><openDate>2024.07.04</openDate><openNumber>10-2024-0103956</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.08.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06V 10/10</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명에 따른 퓨-샷 학습 방법은 이미지 및 상기 이미지에 대한 분할 예측값(segmentation prediction)을 획득하는 단계 및 기학습된 모델로 쿼리 이미지가 제공될 때에 상기 쿼리 이미지로부터 특정 영역의 분류 및 분할을 동시에 수행하도록 상기 이미지 및 분할 지표를 기반으로 상기 모델을 학습하는 단계를 포함하고, 상기 모델은 ASNet(Attentive Squeeze Network)을 포함하며, 상기 쿼리 이미지에 관련성이 낮은 물체가 존재할 때에 분류를 수행하지 않고 관련성이 높은 물체가 존재할 때에 분류 및 분할을 수행할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 및 상기 이미지에 대한 분할 예측값(segmentation prediction)을 획득하는 단계; 및기학습된 모델로 쿼리 이미지가 제공될 때에 상기 쿼리 이미지로부터 특정 영역의 분류 및 분할을 동시에 수행하도록 상기 이미지 및 분할 지표를 기반으로 상기 모델을 학습하는 단계를 포함하고,상기 모델은 ASNet(Attentive Squeeze Network)을 포함하며, 상기 쿼리 이미지에 관련성이 낮은 물체가 존재할 때에 분류를 수행하지 않고 관련성이 높은 물체가 존재할 때에 분류 및 분할을 수행하는 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 모델의 학습에서는통합적 퓨-샷 학습(Integrative few-shot learning, iFSL) 방법이 적용되고,상기 통합적 퓨-샷 학습은상기 쿼리 이미지 내 등장하는 하위 집합을 식별하고 클래스에 해당하는 문제 분할 마스크 집합을 예측하도록 상기 모델을 학습하는 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 모델은복수 개의 이미지 사이의 상관 텐서를 계산하고, 상기 상관 텐서를 Strided self-attention layer에 통과시켜 분류 맵을 생성하는 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서상기 ASNet은AS Layer(Attentive Squeeze Layer)를 포함하며, 상기 AS Layer는고차 자기주의(High-order self-attention) 레이어로 마련되어 상기 상관 텐서를 기반으로 다른 수준의 상관 표현을 반환하는 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서,상기 ASNet은상기 쿼리 이미지와 서포트 이미지 사이의 피라미드형 교차 상관관계 텐서인 초상관관계(Hypercorrelation)를 입력으로 하는 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>6. 제2 항에 있어서,상기 통합적 퓨-샷 학습에서는맥스 풀링(Max pooling)을 이용하여 추론을 수행하는 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>7. 제2 항에 있어서,상기 통합적 퓨-샷 학습에서는분류 손실과 분할 손실을 사용하며, 클래스 태그 또는 분할 주석을 사용하여 학습자를 훈련하는 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 분류 손실은  공간적으로 평균 풀링된 클래스 점수와 그 정답 클래스 레이블 사이의 평균 이진 교차 엔트로피인 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>9. 제7 항에 있어서,상기 분할 손실은개별 위치의 클래스 분포와 실제 분할 주석 사이의 평균 교차 엔트로피인 것을 특징으로 하는 퓨-샷 학습 방법.</claim></claimInfo><claimInfo><claim>10. 외부로부터 제공되는 이미지를 기학습된 모델에 입력하여 상기 이미지로부터 특정 영역의 분류 및 분할을 동시에 수행하는 처리모듈을 포함하고,상기 모델의 학습에서는이미지 및 상기 이미지에 대한 분할 예측값(segmentation prediction)을 획득하고,기학습된 모델로 쿼리 이미지가 제공될 때에 상기 쿼리 이미지로부터 특정 영역의 분류 및 분할을 동시에 수행하도록 상기 이미지 및 분할 지표를 기반으로 상기 모델을 학습하며,상기 모델은 ASNet(Attentive Squeeze Network)을 포함하며, 상기 쿼리 이미지에 관련성이 낮은 물체가 존재할 때에 분류를 수행하지 않고 관련성이 높은 물체가 존재할 때에 분류 및 분할을 수행하는 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>11. 제1 항에 있어서,상기 모델의 학습에서는통합적 퓨-샷 학습(Integrative few-shot learning, iFSL) 방법이 적용되고,상기 통합적 퓨-샷 학습은상기 쿼리 이미지 내 등장하는 하위 집합을 식별하고 클래스에 해당하는 문제 분할 마스크 집합을 예측하도록 상기 모델을 학습하는 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>12. 제10 항에 있어서,상기 모델은복수 개의 이미지 사이의 상관 텐서를 계산하고, 상기 상관 텐서를 Strided self-attention layer에 통과시켜 분류 맵을 생성하는 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서상기 ASNet은AS Layer(Attentive Squeeze Layer)를 포함하며, 상기 AS Layer는고차 자기주의(High-order self-attention) 레이어로 마련되어 상기 상관 텐서를 기반으로 다른 수준의 상관 표현을 반환하는 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 ASNet은상기 쿼리 이미지와 서포트 이미지 사이의 피라미드형 교차 상관관계 텐서인 초상관관계(Hypercorrelation)를 입력으로 하는 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>15. 제11 항에 있어서,상기 통합적 퓨-샷 학습에서는맥스 풀링(Max pooling)을 이용하여 추론을 수행하는 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>16. 제11 항에 있어서,상기 통합적 퓨-샷 학습에서는분류 손실과 분할 손실을 사용하며, 클래스 태그 또는 분할 주석을 사용하여 학습자를 훈련하는 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>17. 제16 항에 있어서,상기 분류 손실은  공간적으로 평균 풀링된 클래스 점수와 그 정답 클래스 레이블 사이의 평균 이진 교차 엔트로피인 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo><claimInfo><claim>18. 제16 항에 있어서,상기 분할 손실은개별 위치의 클래스 분포와 실제 분할 주석 사이의 평균 교차 엔트로피인 것을 특징으로 하는 영상 처리 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경상북도 포항시 남구...</address><code>220040433361</code><country>대한민국</country><engName>POSTECH Research and Business Development Foundation</engName><name>포항공과대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경상북도 포항시 남구...</address><code> </code><country> </country><engName>CHO, Min Su</engName><name>조민수</name></inventorInfo><inventorInfo><address>경상북도 포항시 남구...</address><code> </code><country> </country><engName>KANG, Da Hyun</engName><name>강다현</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 송파구  올림픽로  *** ,*층 (신천동, 대한제당)</address><code>920131000018</code><country>대한민국</country><engName>Envision Patent &amp; Law Firm</engName><name>인비전특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.12.27</priorityApplicationDate><priorityApplicationNumber>1020220186054</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.17</receiptDate><receiptNumber>1-1-2023-0907000-61</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.06.13</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230107891.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9325c9011e49e4c1d85d6f596c66c7878c5694535ffbc026a071b5e8573d040e0b359ed5bac24f4e4dfd87176a6d8a4af0bfb58e02ade1e016</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1c6abce026a80c86a0f429e2dd04078635a7c7f5fec9c5f06fa70898662e7d419a19449fa93dec8b84aca48b5648b019b61e3a896858d6a9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>