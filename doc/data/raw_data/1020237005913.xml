<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:51.4051</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.08.24</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7005913</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>시공간 리사이클링 네트워크</inventionTitle><inventionTitleEng>SPATIOTEMPORAL RECYCLING NETWORK</inventionTitleEng><openDate>2023.04.28</openDate><openNumber>10-2023-0057355</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.02.20</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/174</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/136</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/215</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 30/262</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/94</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> (예를 들면, 비디오 세그먼트화를 위한) 시공간 리사이클링 네트워크들을 제공하기 위한 시스템들, 방법들, 및 비일시적 매체들이 제공된다. 예를 들면, 방법은 현재의 프레임 및 하나 이상의 기준 프레임들을 포함하는 비디오 데이터를 획득하는 것을 포함할 수 있다. 방법은, 현재의 프레임 및 하나 이상의 기준 프레임들의 비교에 기초하여, 현재의 프레임과 하나 이상의 기준 프레임들 사이의 차이를 결정하는 것을 포함할 수 있다. 차이가 임계치 미만인 것에 기초하여, 방법은 제1 신경망을 사용하여 현재의 프레임의 의미론적 세그먼트화를 수행하는 것을 포함할 수 있다. 의미론적 세그먼트화는 제1 신경망에 의해 현재의 프레임으로부터 추출되는 더 높은 공간 분해능 피처들 및 제2 신경망에 의해 하나 이상의 기준 프레임들로부터 추출되는 더 낮은 분해능 피처들에 기초하여 수행될 수 있다. 제1 신경망은 제2 신경망보다 더 작은 구조 및/또는 더 낮은 프로세싱 비용을 갖는다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.03.03</internationOpenDate><internationOpenNumber>WO2022046725</internationOpenNumber><internationalApplicationDate>2021.08.24</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/047279</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프레임들을 프로세싱하는 방법으로서,현재의 프레임 및 하나 이상의 기준 프레임들을 포함하는 비디오 데이터를 획득하는 단계;상기 현재의 프레임 및 상기 하나 이상의 기준 프레임들의 비교에 기초하여, 상기 현재의 프레임과 상기 하나 이상의 기준 프레임들 사이의 차이를 결정하는 단계; 및상기 차이가 임계치 미만인 것에 기초하여, 상기 현재의 프레임으로부터 추출되는 더 높은 공간 분해능 피처들 및 제2 신경망에 의해 상기 하나 이상의 기준 프레임들로부터 추출되는 더 낮은 공간 분해능 피처들에 기초하여 제1 신경망을 사용하여 상기 현재의 프레임의 의미론적 세그먼트화(semantic segmentation)를 수행하는 단계를 포함하며, 상기 제1 신경망은 상기 제2 신경망보다 더 작은 구조 및 더 낮은 프로세싱 비용 중 적어도 하나를 갖는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제2 신경망은 세그먼트화 네트워크를 포함하고, 상기 제1 신경망은 상기 세그먼트화 네트워크의 서브네트워크 구조를 포함하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 차이는 상기 현재의 프레임과 연관되는 픽셀 값들과 상기 하나 이상의 기준 프레임들과 연관되는 픽셀 값들 사이의 차이를 포함하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 차이는 상기 현재의 프레임과 상기 하나 이상의 기준 프레임들 사이의 모션의 변화의 양을 포함하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 비교는 분류 네트워크를 사용하여 스코어를 생성하는 것을 포함하고, 상기 스코어는 상기 현재의 프레임과 상기 하나 이상의 기준 프레임들 사이의 상기 차이의 크기를 나타내는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 차이는 상기 현재의 프레임과 연관되는 제1 경계 맵에서의 하나 이상의 경계들과 상기 하나 이상의 기준 프레임들과 연관되는 상기 제2 경계 맵에서의 하나 이상의 경계들 사이의 거리에 기초하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 비교는 이미지 레벨 비교 및 영역 레벨 비교 중 적어도 하나를 포함하고, 상기 차이는 상기 이미지 레벨 비교 및 상기 영역 레벨 비교 중 적어도 하나에 기초하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제2 신경망은 다중 레벨 네트워크 구조를 포함하고, 상기 다중 레벨 네트워크 구조는 상기 제1 신경망과 연관되는 네트워크 구조보다 하나 이상의 더 깊은 레벨들을 포함하고, 상기 더 낮은 공간 분해능 피처들은 상기 다중 레벨 네트워크 구조의 상기 하나 이상의 더 깊은 레벨들에서 추출되는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 의미론적 세그먼트화는 하나 이상의 이전 프레임들에 기초하여 생성되는 하나 이상의 세그먼트화 맵들에 추가로 기초하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 의미론적 세그먼트화에 기초하여, 상기 현재의 프레임과 연관되는 하나 이상의 세그먼트화 맵들을 포함하는 세그먼트화 출력을 생성하는 단계를 더 포함하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 의미론적 세그먼트화를 수행하는 단계는:스토리지로부터 상기 더 낮은 공간 분해능 피처들을 획득하는 단계;상기 더 낮은 공간 분해능 피처들을 풀링하는(pooling) 단계;상기 현재의 프레임과 연관되는 피처들의 세트를 결정하는 단계 — 상기 피처들의 세트는 상기 풀링된 더 낮은 공간 분해능 피처들을 상기 더 높은 공간 분해능 피처들과 결합하는 것에 의해 결정됨 — ; 및상기 현재의 프레임과 연관되는 상기 피처들의 세트에 기초하여 세그먼트화 출력을 생성하는 단계를 포함하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 풀링된 더 낮은 공간 분해능 피처들과 상기 더 높은 공간 분해능 피처들의 컨볼루션 기반의 융합에 기초하여 피처 업데이트를 생성하는 단계; 및상기 피처 업데이트를 상기 스토리지에 저장하는 단계를 더 포함하는, 하나 이상의 프레임들을 프로세싱하는 방법. </claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,추가적인 프레임 및 하나 이상의 추가적인 기준 프레임들의 제2 비교에 기초하여, 상기 추가적인 프레임과 상기 하나 이상의 추가적인 기준 프레임들 사이의 추가적인 차이를 결정하는 단계; 및상기 추가적인 차이가 상기 임계치를 초과하는 것에 기초하여, 상기 제2 신경망을 사용하여, 상기 추가적인 프레임의 의미론적 세그먼트화를 수행하는 단계를 더 포함하는, 하나 이상의 프레임들을 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>14. 하나 이상의 프레임들을 프로세싱하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 통신 가능하게 커플링되는 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은: 현재의 프레임 및 하나 이상의 기준 프레임들을 포함하는 비디오 데이터를 획득하도록; 상기 현재의 프레임 및 상기 하나 이상의 기준 프레임들의 비교에 기초하여, 상기 현재의 프레임과 상기 하나 이상의 기준 프레임들 사이의 차이를 결정하도록; 그리고 상기 차이가 임계치 미만인 것에 기초하여, 상기 현재의 프레임으로부터 추출되는 더 높은 공간 분해능 피처들 및 제2 신경망에 의해 상기 하나 이상의 기준 프레임들로부터 추출되는 더 낮은 공간 분해능 피처들에 기초하여 제1 신경망을 사용하여 상기 현재의 프레임의 의미론적 세그먼트화를 수행하도록 구성되며, 상기 제1 신경망은 상기 제2 신경망보다 더 작은 구조 및 더 낮은 프로세싱 비용 중 적어도 하나를 갖는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 제2 신경망은 세그먼트화 네트워크를 포함하고, 상기 제1 신경망은 상기 세그먼트화 네트워크의 서브네트워크 구조를 포함하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 차이는 상기 현재의 프레임과 연관되는 픽셀 값들과 상기 하나 이상의 기준 프레임들과 연관되는 픽셀 값들 사이의 차이를 포함하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 차이는 상기 현재의 프레임과 상기 하나 이상의 기준 프레임들 사이의 모션의 변화의 양을 포함하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제14항에 있어서,상기 비교는 분류 네트워크를 사용하여 스코어를 생성하는 것을 포함하고, 상기 스코어는 상기 현재의 프레임과 상기 하나 이상의 기준 프레임들 사이의 상기 차이의 크기를 나타내는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>19. 제14항에 있어서,상기 차이는 상기 현재의 프레임과 연관되는 제1 경계 맵에서의 하나 이상의 경계들과 상기 하나 이상의 기준 프레임들과 연관되는 상기 제2 경계 맵에서의 하나 이상의 경계들 사이의 거리에 기초하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>20. 제14항에 있어서,상기 비교는 이미지 레벨 비교 및 영역 레벨 비교 중 적어도 하나를 포함하고, 상기 차이는 상기 이미지 레벨 비교 및 상기 영역 레벨 비교 중 적어도 하나에 기초하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>21. 제14항에 있어서,상기 제2 신경망은 다중 레벨 네트워크 구조를 포함하고, 상기 다중 레벨 네트워크 구조는 상기 제1 신경망과 연관되는 네트워크 구조보다 하나 이상의 더 깊은 레벨들을 포함하고, 상기 더 낮은 공간 분해능 피처들은 상기 다중 레벨 네트워크 구조의 상기 하나 이상의 더 깊은 레벨들에서 추출되는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>22. 제14항에 있어서,상기 의미론적 세그먼트화는 하나 이상의 이전 프레임들에 기초하여 생성되는 하나 이상의 세그먼트화 맵들에 추가로 기초하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>23. 제14항에 있어서,상기 하나 이상의 프로세서들은:상기 의미론적 세그먼트화에 기초하여, 상기 현재의 프레임과 연관되는 하나 이상의 세그먼트화 맵들을 포함하는 세그먼트화 출력을 생성하도록 구성되는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>24. 제14항에 있어서,상기 의미론적 세그먼트화를 수행하는 것은:스토리지로부터 상기 더 낮은 공간 분해능 피처들을 획득하는 것;상기 더 낮은 공간 분해능 피처들을 풀링하는 것;상기 현재의 프레임과 연관되는 피처들의 세트를 결정하는 것 — 상기 피처들의 세트는 상기 풀링된 더 낮은 공간 분해능 피처들을 상기 더 높은 공간 분해능 피처들과 결합하는 것에 의해 결정됨 — ; 및상기 현재의 프레임과 연관되는 상기 피처들의 세트에 기초하여 세그먼트화 출력을 생성하는 것을 포함하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서,상기 하나 이상의 프로세서들은:상기 풀링된 더 낮은 공간 분해능 피처들과 상기 더 높은 공간 분해능 피처들의 컨볼루션 기반의 융합에 기초하여 피처 업데이트를 생성하도록; 그리고상기 피처 업데이트를 상기 스토리지에 저장하도록 구성되는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>26. 제14항에 있어서,상기 하나 이상의 프로세서들은:추가적인 프레임 및 하나 이상의 추가적인 기준 프레임들의 제2 비교에 기초하여, 상기 추가적인 프레임과 상기 하나 이상의 추가적인 기준 프레임들 사이의 추가적인 차이를 결정하도록; 그리고상기 추가적인 차이가 상기 임계치를 초과하는 것에 기초하여, 상기 제2 신경망을 사용하여, 상기 추가적인 프레임의 의미론적 세그먼트화를 수행하도록 구성되는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>27. 제14항에 있어서,상기 장치는 모바일 디바이스인, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>28. 제14항에 있어서,카메라 및 디스플레이 디바이스 중 적어도 하나를 더 포함하는, 하나 이상의 프레임들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>29. 명령어들이 저장된 적어도 하나의 비일시적 컴퓨터 판독 가능 저장 매체로서,상기 명령어들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금:현재의 프레임 및 하나 이상의 기준 프레임들을 포함하는 비디오 데이터를 획득하게 하고;상기 현재의 프레임 및 상기 하나 이상의 기준 프레임들의 비교에 기초하여, 상기 현재의 프레임과 상기 하나 이상의 기준 프레임들 사이의 차이를 결정하게 하고; 그리고상기 차이가 임계치 미만인 것에 기초하여, 상기 현재의 프레임으로부터 추출되는 더 높은 공간 분해능 피처들 및 제2 신경망에 의해 상기 하나 이상의 기준 프레임들로부터 추출되는 더 낮은 공간 분해능 피처들에 기초하여, 제1 신경망을 사용하여, 상기 현재의 프레임의 의미론적 세그먼트화를 수행하게 하며, 상기 제1 신경망은 상기 제2 신경망보다 더 작은 구조 및 더 낮은 프로세싱 비용 중 적어도 하나를 갖는, 명령어들이 저장된 적어도 하나의 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서,상기 제2 신경망은 세그먼트화 네트워크를 포함하고, 상기 제1 신경망은 상기 세그먼트화 네트워크의 서브네트워크 구조를 포함하는, 명령어들이 저장된 적어도 하나의 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980798710</code><country>미국</country><engName>QUALCOMM INCORPORATED</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>ZHANG, Yizhe</engName><name>장, 이제</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>HABIBIAN, Amirhossein</engName><name>하비비안, 아미르호세인</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>PORIKLI, Fatih Murat</engName><name>포리클리, 파티 무라트</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 서소문로**(서소문동, 정안빌딩*층)</address><code>920121001826</code><country>대한민국</country><engName>NAM &amp; NAM</engName><name>특허법인 남앤남</name></agentInfo><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.08.24</priorityApplicationDate><priorityApplicationNumber>63/069,255</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.08.23</priorityApplicationDate><priorityApplicationNumber>17/408,779</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.02.20</receiptDate><receiptNumber>1-1-2023-0195293-64</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.03.28</receiptDate><receiptNumber>1-5-2023-0050309-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.03.22</receiptDate><receiptNumber>1-1-2024-0326858-24</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.08.08</receiptDate><receiptNumber>1-1-2024-0864154-75</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237005913.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bdce5604bdd444242dbc7fc532c3e8e52d24fdadf0c799e84749faf69e247244491a24516eb240f027eb7794ec309823a6b08ece19814800</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf799f31d28ceda74ed1e5f2a6185b1823ebe904ce563686decfe52222208eb12b8262d5d8e8f2d049529b3b2a263ceb9c0720a5c2f40e2603</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>