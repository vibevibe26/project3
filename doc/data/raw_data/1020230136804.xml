<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:00.330</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0136804</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>슬라이스 기반 기계 학습 모델들을 효율적으로 분석하고 비교하기 위한 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEM AND METHOD FOR EFFICIENT ANALYZING AND COMPARING  SLICE-BASED MACHINE LEARN MODELS</inventionTitleEng><openDate>2024.04.23</openDate><openNumber>10-2024-0052913</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 기계 학습 네트워크를 위한 컴퓨터로 구현된 방법은 입력 데이터세트를 수신하는 단계, 입력 데이터세트를 제1 기계 학습 모델로 전송하여 입력 데이터와 연관된 예측들을 출력하는 단계, 제1 반복에서 입력 데이터세트 및 제1 기계 학습 모델과 연관된 하나 이상의 슬라이스를 식별하는 단계 - 하나 이상의 슬라이스 각각은 입력 데이터세트로부터의 입력 데이터 및 각각의 슬라이스와 연관된 공통 속성들을 포함함 -; 입력 데이터세트의 하나 이상의 슬라이스를 선택하면, 모델과 연관된 잔차들을 예측하도록 구성된 얕은 회귀자 모델을 훈련하는 단계, 지상 실측 정보 라벨(ground-truth label)과 연관된 표현 및 하나 이상의 슬라이스 각각과 연관된 각각의 샘플과 연관된 모델 예측과 연관된 제2 표현을 생성하는 단계, 제1 기계 학습 모델의 모든 예측과 연관된 잔차들을 결정하는 단계, 얕은 회귀자를 훈련하여, 선택된 슬라이스들의 하나 이상의 예측 잔차를 계산하는 단계, 예측 잔차들을 이용하여 최적화된 모델을 생성하는 단계, 입력 데이터세트의 하나 이상의 슬라이스 각각에 대한 최적화된 모델로부터의 최적화된 예측들의 수정된 정확도를 결정하는 단계, 수정된 정확도와 제1 기계 학습 모델과 연관된 원래 정확도 간의 차이를 이용하여 하나 이상의 슬라이스 각각의 수정된 효과를 결정하는 단계, 및 수정된 효과를 그래픽 인터페이스에 출력하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 기계 학습 네트워크를 위한 컴퓨터로 구현된 방법(computer-implemented method)으로서,입력 데이터세트를 수신하는 단계 - 상기 입력 데이터세트는 이미지 정보, 표 형식의 정보, 레이더 정보, 소나(sonar) 정보 또는 사운드 정보를 나타냄 -;상기 입력 데이터세트를 제1 기계 학습 모델로 전송하여 입력 데이터와 연관된 예측들을 출력하는 단계;제1 반복에서 상기 입력 데이터세트 및 제1 기계 학습 모델과 연관된 하나 이상의 슬라이스를 식별하는 단계 - 상기 하나 이상의 슬라이스 각각은 상기 입력 데이터세트로부터의 입력 데이터 및 각각의 슬라이스와 연관된 공통 속성들을 포함함 -;상기 입력 데이터세트의 하나 이상의 슬라이스를 선택하면, 상기 제1 기계 학습 모델과 연관된 잔차들을 예측하도록 구성된 얕은 회귀자 모델을 훈련하는 단계;지상 실측 정보 라벨과 연관된 제1 원-핫-인코딩된 표현 및 상기 하나 이상의 슬라이스 각각과 연관된 각각의 샘플과 연관된 모델 예측과 연관된 제2 원-핫-인코딩된 표현을 생성하는 단계;상기 제1 기계 학습 모델의 모든 모델 예측과 연관된 잔차들을 결정하는 단계 - 상기 잔차들은 상기 지상 실측 정보 라벨과 연관된 상기 제1 원-핫-인코딩된 표현과 상기 모델 예측과 연관된 상기 제2 원-핫-인코딩된 표현 사이의 요소별 차이임 -;상기 입력 데이터세트 및 잔차들과 연관된 검증 데이터를 이용하여 상기 선택된 슬라이스들의 하나 이상의 예측 잔차를 계산하도록 상기 얕은 회귀자를 훈련하는 단계;상기 예측 잔차들을 이용하여 상기 제1 기계 학습 모델의 최적화된 예측들을 출력하도록 구성된 최적화된 모델을 생성하는 단계 - 상기 최적화된 모델은 원래의 모델 예측들과 상기 예측 잔차들을 더하여 생성됨 -;상기 입력 데이터세트의 상기 하나 이상의 슬라이스 각각에 대한 상기 최적화된 모델로부터의 최적화된 예측들의 수정된 정확도를 결정하는 단계;상기 수정된 정확도와 상기 제1 기계 학습 모델과 연관된 원래의 정확도 사이의 차이를 이용하여 상기 하나 이상의 슬라이스 각각의 수정된 효과를 결정하는 단계; 및상기 수정된 효과를 그래픽 인터페이스로 출력하는 단계를 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 기계 학습 모델은 상기 최적화된 모델과 상이한 가중치들을 갖는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 제1 기계 학습 모델은 상기 최적화된 모델과 상이한 네트워크인, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 반복과 연관된 상기 잔차는 다음과 같이 로서 정의되고, 은 상기 지상 실측 정보 라벨과 연관된 상기 제1 원-핫-인코딩된 표현이고, 은 상기 모델 예측과 연관된 상기 제2 원-핫-인코딩된 표현인, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 는 정확한 예측을 나타내는 0, 클래스의 누락된 검출을 나타내는 1, 또는 잘못된 클래스를 나타내는 -1인, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 샘플은 상기 하나 이상의 슬라이스와 연관된 이미지 또는 관찰을 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 검증 데이터는 메타데이터 및 지상 실측 정보 라벨을 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 하나 이상의 슬라이스의 식별은 상기 하나 이상의 슬라이스를 식별하기 위해 데이터 슬라이스 발견 알고리즘을 이용하는 것을 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 얕은 회귀자는 기울기 부스팅 프레임워크를 이용하여 훈련되는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>10. 시스템으로서,인터페이스와 통신하는 프로세서를 포함하고, 상기 프로세서는,인터페이스로부터 입력 데이터세트를 수신하고 - 상기 입력 데이터세트는 이미지 정보, 표 형식의 정보, 레이더 정보, 소나 정보 또는 사운드 정보를 나타냄 -;상기 입력 데이터세트를 제1 기계 학습 모델로 전송하여 입력 데이터와 연관된 예측들을 출력하고;제1 반복에서 상기 입력 데이터세트 및 제1 기계 학습 모델과 연관된 하나 이상의 슬라이스를 식별하고 - 상기 하나 이상의 슬라이스 각각은 상기 입력 데이터세트로부터의 입력 데이터 및 각각의 슬라이스와 연관된 공통 속성들을 포함함 -;상기 입력 데이터세트의 하나 이상의 슬라이스를 선택하면, 상기 제1 기계 학습 모델과 연관된 잔차들을 예측하도록 얕은 회귀자 모델을 훈련하고;지상 실측 정보 라벨과 연관된 제1 원-핫-인코딩된 표현 및 상기 하나 이상의 슬라이스 각각과 연관된 각각의 샘플과 연관된 모델 예측과 연관된 제2 원-핫-인코딩된 표현을 생성하고;상기 제1 기계 학습 모델의 모든 모델 예측과 연관된 잔차들을 결정하고 - 상기 잔차들은 상기 지상 실측 정보 라벨과 연관된 상기 제1 원-핫-인코딩된 표현과 상기 모델 예측과 연관된 상기 제2 원-핫-인코딩된 표현 사이의 요소별 차이임 -;상기 입력 데이터세트 및 잔차들과 연관된 검증 데이터를 이용하여 상기 선택된 슬라이스들의 예측 잔차를 계산하도록 상기 얕은 회귀자 모델을 훈련하고;상기 예측 잔차들을 이용하여 상기 제1 기계 학습 모델의 원래의 모델 예측들을 최적화하고 - 상기 최적화는 상기 원래의 모델 예측들과 상기 예측 잔차들을 더하여 수행됨 -;상기 입력 데이터세트의 상기 하나 이상의 슬라이스 각각에 대한 최적화된 모델로부터의 최적화된 예측들의 편집된 정확도를 결정하고;상기 편집된 정확도와 상기 제1 기계 학습 모델과 연관된 원래의 정확도 사이의 차이를 이용하여 상기 하나 이상의 슬라이스 각각의 추정 효과를 결정하고;상기 추정 효과를 그래픽 인터페이스로 출력하도록 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 샘플은 상기 하나 이상의 슬라이스와 연관된 이미지 또는 관찰을 포함하는, 시스템. </claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 하나 이상의 슬라이스의 식별은 상기 하나 이상의 슬라이스를 식별하기 위해 데이터 슬라이스 발견 알고리즘을 이용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 얕은 회귀자는 기울기 부스팅 프레임워크를 이용하여 훈련되는, 시스템.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서, 상기 잔차는 정확한 예측을 나타내는 0, 클래스의 누락된 검출을 나타내는 1, 또는 부정확한 클래스를 나타내는 -1인, 시스템.</claim></claimInfo><claimInfo><claim>15. 기계 학습 네트워크를 위한 컴퓨터로 구현된 방법으로서,입력 데이터세트를 수신하는 단계 - 상기 입력 데이터세트는 이미지 정보, 표 형식의 정보, 레이더 정보, 소나 정보 또는 사운드 정보를 나타냄 -;상기 입력 데이터세트를 제1 기계 학습 모델로 전송하여 입력 데이터와 연관된 예측들을 출력하는 단계;제1 반복에서 상기 입력 데이터세트 및 제1 기계 학습 모델과 연관된 하나 이상의 슬라이스를 식별하는 단계 - 상기 하나 이상의 슬라이스 각각은 상기 입력 데이터세트로부터의 입력 데이터 및 각각의 슬라이스와 연관된 공통 속성들을 포함함 -;상기 입력 데이터세트의 하나 이상의 슬라이스를 선택하면, 상기 제1 기계 학습 모델과 연관된 잔차들을 예측하도록 구성된 얕은 회귀자 모델을 훈련하는 단계;지상 실측 정보 라벨과 연관된 제1 원-핫-인코딩된 표현 및 상기 하나 이상의 슬라이스 각각과 연관된 각각의 샘플과 연관된 모델 예측과 연관된 제2 원-핫-인코딩된 표현을 생성하는 단계;상기 제1 기계 학습 모델의 모든 모델 예측과 연관된 잔차들을 결정하는 단계 - 상기 잔차들은 상기 지상 실측 정보 라벨과 연관된 상기 제1 원-핫-인코딩된 표현과 상기 모델 예측과 연관된 상기 제2 원-핫-인코딩된 표현 사이의 요소별 차이임 -;상기 입력 데이터세트 및 잔차들과 연관된 검증 데이터를 이용하여 상기 선택된 슬라이스들의 예측 잔차를 계산하도록 상기 얕은 회귀자를 훈련하는 단계;상기 예측 잔차들을 이용하여 상기 제1 기계 학습 모델의 원래의 모델 예측들을 최적화하는 단계 - 상기 최적화는 상기 원래의 모델 예측들과 상기 예측 잔차들을 더하여 수행됨 -;상기 입력 데이터세트의 상기 하나 이상의 슬라이스 각각에 대한 최적화된 모델로부터의 최적화된 예측들의 편집된 정확도를 결정하는 단계; 및추정된 효과를 그래픽 인터페이스로 출력하는 단계를 포함하고, 상기 추정된 효과는 상기 편집된 정확도와 상기 제1 기계 학습 모델과 연관된 원래의 정확도 사이의 차이를 이용하여 하나 이상의 슬라이스와 연관되는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 제1 기계 학습 모델은 상기 최적화된 모델과 상이한 가중치들을 갖는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 제1 기계 학습 모델은 상기 최적화된 모델과 상이한 네트워크인, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 상기 그래픽 인터페이스는 상기 편집된 정확도 및 상기 원래의 정확도를 나타내는 정보를 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서, 상기 얕은 회귀자는 기울기 부스팅 프레임워크를 이용하여 훈련되는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 반복과 연관된 상기 잔차는 다음과 같이 로서 정의되는, 컴퓨터로 구현된 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>독일 데-***** 슈투트가르트 포스트파흐 ** ** **</address><code>519980640388</code><country>독일</country><engName>ROBERT BOSCH GMBH</engName><name>로베르트 보쉬 게엠베하</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니...</address><code> </code><country> </country><engName>SONG, Huan</engName><name>쑹, 환</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ONO, Jorge Piazentin</engName><name>오노, 조지 피아젠틴</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니...</address><code> </code><country> </country><engName>GOU, Liang</engName><name>궈, 량</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니...</address><code> </code><country> </country><engName>REN, Liu</engName><name>런, 류</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 데...</address><code> </code><country> </country><engName>ZHANG, Xiaoyu</engName><name>장, 샤오위</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.10.15</priorityApplicationDate><priorityApplicationNumber>17/966,794</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.13</receiptDate><receiptNumber>1-1-2023-1123579-29</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.10.27</receiptDate><receiptNumber>9-1-2023-9011531-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230136804.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9362f1ffd78e713eeea86ed9567238f20c022664357af5f021cb6d453b6b2b5a93fe3a63ca16ff41b4011543d6e136f449a2d6a400d8298dcd</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6cf0dffdc547c5ea1da943c6a641885ddf47bd0953cced056c9947957dcc4574127295e975aaf2232281b47761755af0f3f3e19828c628da</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>