<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:20.520</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0145096</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>대상 영역에 대한 촬영 이미지를 이용하여 공간 맵을 생성하는 방법 및 이를 수행하기 위한 전자 장치</inventionTitle><inventionTitleEng>METHOD FOR GENERATING SPATIAL MAP USING CAPTURED  IMAGE FOR TARGET AREA, AND ELECTRONIC DEVICE FOR  PERFORMING THE SAME</inventionTitleEng><openDate>2025.05.07</openDate><openNumber>10-2025-0060756</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/89</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 7/497</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/593</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/13</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 공간 맵을 생성하는 방법은, 공간(space) 내 대상 영역(target area)에 대한 촬영 이미지(captured image)를 획득하는 단계, 미리 설정된 제1 높이에 대해서 상기 대상 영역의 깊이(depth)를 스캔한 라이다 스캔 데이터(LiDAR scan data)를 획득하는 단계, 상기 촬영 이미지에 대해 객체 검출(object detection)을 수행하는 단계 및 상기 촬영 이미지로부터 객체가 검출되지 않으면, 상기 라이다 스캔 데이터에 기초하여 상기 대상 영역에 대한 공간 맵(spatial map)을 생성하고, 상기 촬영 이미지로부터 객체가 검출되면, 상기 라이다 스캔 데이터 및 상기 촬영 이미지 모두에 기초하여 상기 대상 영역에 대한 공간 맵을 생성하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 공간(space) 내 대상 영역(target area)에 대한 촬영 이미지(captured image)를 획득하는 단계;미리 설정된 제1 높이에 대해서 상기 대상 영역의 깊이(depth)를 스캔한 라이다 스캔 데이터(LiDAR scan data)를 획득하는 단계;상기 촬영 이미지에 대해 객체 검출(object detection)을 수행하는 단계; 및상기 촬영 이미지로부터 객체가 검출되지 않으면, 상기 라이다 스캔 데이터에 기초하여 상기 대상 영역에 대한 공간 맵(spatial map)을 생성하고, 상기 촬영 이미지로부터 객체가 검출되면, 상기 라이다 스캔 데이터 및 상기 촬영 이미지 모두에 기초하여 상기 대상 영역에 대한 공간 맵을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 촬영 이미지로부터 객체가 검출되는 경우,상기 공간 맵을 생성하는 단계는,상기 촬영 이미지를 이용하여, 상기 대상 영역에서 상기 제1 높이와 다른 제2 높이에 위치하는 복수의 지점(spot)들에 대한 깊이 값(depth value)들을 획득하는 단계; 및상기 획득한 깊이 값들에 기초하여 상기 공간 맵을 생성하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 깊이 값들을 획득하는 단계는,상기 촬영 이미지로부터 뎁스 이미지(depth image)를 획득하는 단계;상기 라이다 스캔 데이터와 상기 뎁스 이미지의 스케일(scale)을 일치시키기 위한 뎁스 캘리브레이션(depth calibration)을 수행하는 단계;상기 대상 영역에서 상기 검출된 객체가 존재하지 않는 높이를 상기 제2 높이로 결정하는 단계; 및상기 뎁스 캘리브레이션 결과를 반영하여, 상기 뎁스 이미지로부터 상기 제2 높이에 위치하는 복수의 지점들에 대한 깊이 값을 획득하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 뎁스 캘리브레이션을 수행하는 단계는,상기 라이다 스캔 데이터로부터 상기 제1 높이에 위치하는 복수의 지점들에 대한 절대적인 깊이 값(absolute depth value)들을 획득하는 단계;상기 뎁스 이미지로부터 상기 제1 높이에 위치하는 복수의 지점들에 대한 상대적인 깊이 값(relative depth value)들을 획득하는 단계; 및상기 획득한 절대적인 깊이 값들 및 상대적인 깊이 값들에 기초하여, 상기 뎁스 이미지에 포함된 상대적인 깊이 값을 절대적인 깊이 값으로 변환하기 위한 스케일 팩터(scale factor)를 획득하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 스케일 팩터를 획득하는 단계는,비용함수(cost function)를 이용하여, 상기 제1 높이에 위치하는 복수의 지점들에 대한 절대적인 깊이 값들과, 상기 제1 높이에 위치하는 복수의 지점들에 대한 상대적인 깊이 값들에 상기 스케일 팩터를 곱한 값들 간의 차이가 최소가 되도록, 상기 스케일 팩터의 값을 결정하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>6. 제3항에 있어서,상기 검출된 객체가 존재하지 않는 높이를 상기 제2 높이로 결정하는 단계는,상기 촬영 이미지를 분석함으로써, 상기 대상 영역에서 상기 객체가 존재하지 않는 높이의 범위를 확인하는 단계; 및상기 확인된 범위 중에서 어느 하나의 높이를 상기 제2 높이로 결정하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>7. 제3항에 있어서,상기 검출된 객체가 존재하지 않는 높이를 상기 제2 높이로 결정하는 단계는,상기 뎁스 이미지에 기초하여, 상기 제1 높이와 다른 복수의 높이들에 대해서 상기 대상 영역에 대한 공간 맵의 테두리(border)들을 결정하는 단계; 및상기 결정된 테두리들 중에서 연결점(junction)의 개수가 최소인 테두리에 대응되는 높이를 상기 제2 높이로 결정하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>8. 제3항에 있어서, 상기 검출된 객체가 존재하지 않는 높이를 상기 제2 높이로 결정하는 단계는,상기 뎁스 이미지에 기초하여, 상기 제1 높이와 다른 복수의 높이들에 대해서 상기 대상 영역에 대한 공간 맵의 면적들을 산출하는 단계; 및상기 산출된 면적들 중에서 최대인 면적에 대응되는 높이를 상기 제2 높이로 결정하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>9. 제4항에 있어서,상기 뎁스 이미지로부터 상기 제1 높이에 위치하는 복수의 지점들에 대한 상대적인 깊이 값들을 획득하는 단계는,상기 라이다 스캔 데이터와 상기 촬영 이미지 간 위치 매칭을 위한 변환 행렬(transform matrix)을 획득하는 단계;상기 변환 행렬을 이용하여, 상기 라이다 스캔 데이터에 포함된 깊이 값들에 대응되는 지점들의 위치를, 상기 뎁스 이미지상의 위치로 변환하는 단계; 및상기 뎁스 이미지로부터 상기 변환된 위치의 지점들에 대응되는 상대적인 깊이 값들을 획득하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>10. 제4항에 있어서,상기 뎁스 이미지로부터 상기 제1 높이에 위치하는 복수의 지점들에 대한 상대적인 깊이 값들을 획득하는 단계는,상기 촬영 이미지에 대해서 시맨틱 세그멘테이션(semantic segmentation)을 수행하는 단계;상기 촬영 이미지에서 벽면과 바닥 사이의 경계선(boundary)을 확인하는 단계; 및상기 경계선상에 위치한 복수의 지점들에 대응되는 상대적인 깊이 값들을 획득하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>11. 제4항에 있어서,상기 뎁스 이미지로부터 상기 제1 높이에 위치하는 복수의 지점들에 대한 상대적인 깊이 값들을 획득하는 단계는,상기 뎁스 이미지상에서 복수의 픽셀 열(pixel column)들을 추출하는 단계;상기 픽셀 열들 각각에 대해서 엘보우 포인트(elbow point)를 결정하는 단계; 및상기 결정된 엘보우 포인트들에 위치하는 지점들에 대응되는 상대적인 깊이 값들을 획득하는 단계를 포함하며,상기 엘보우 포인트는, 상기 픽셀 열의 길이 방향으로 깊이 값이 변화하는 정도가 미리 설정된 일정 기준 이하로 변경되는 지점인 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 촬영 이미지로부터 객체가 검출되는 경우,상기 라이다 스캔 데이터에만 기초하여 결정된 상기 공간 맵의 테두리(border)와, 상기 라이다 스캔 데이터 및 상기 촬영 이미지 모두에 기초하여 결정된 상기 공간 맵의 테두리를 비교함으로써 상기 검출된 객체가 위치하는 영역을 결정하는 단계; 및상기 공간 맵상의 상기 결정된 영역에 상기 검출된 객체를 표시하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo><claimInfo><claim>14. 공간 맵(spatial map)을 생성하기 위한 전자 장치에 있어서,공간 맵을 생성하기 위한 프로그램이 저장되는 메모리; 및적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는 상기 프로그램을 실행함으로써,공간(space) 내 대상 영역(target area)에 대한 촬영 이미지(captured image)를 획득하고,미리 설정된 제1 높이에 대해서 상기 대상 영역의 깊이(depth)를 스캔한 라이다 스캔 데이터(LiDAR scan data)를 획득하고,상기 촬영 이미지에 대해 객체 검출(object detection)을 수행한 후,상기 촬영 이미지로부터 객체가 검출되지 않으면, 상기 라이다 스캔 데이터에 기초하여 상기 대상 영역에 대한 공간 맵(spatial map)을 생성하고, 상기 촬영 이미지로부터 객체가 검출되면, 상기 라이다 스캔 데이터 및 상기 촬영 이미지 모두에 기초하여 상기 대상 영역에 대한 공간 맵을 생성하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 촬영 이미지로부터 객체가 검출되는 경우,상기 적어도 하나의 프로세서는 상기 공간 맵을 생성함에 있어서,상기 촬영 이미지를 이용하여, 상기 대상 영역에서 상기 제1 높이와 다른 제2 높이에 위치하는 복수의 지점(spot)들에 대한 깊이 값(depth value)들을 획득한 후,상기 획득한 깊이 값들에 기초하여 상기 공간 맵을 생성하는 것을 특징으로 하는 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 적어도 하나의 프로세서는 상기 깊이 값들을 획득함에 있어서,상기 촬영 이미지로부터 뎁스 이미지(depth image)를 획득하고,상기 라이다 스캔 데이터와 상기 뎁스 이미지의 스케일(scale)을 일치시키기 위한 뎁스 캘리브레이션(depth calibration)을 수행하고,상기 대상 영역에서 상기 검출된 객체가 존재하지 않는 높이를 상기 제2 높이로 결정한 후,상기 뎁스 캘리브레이션 결과를 반영하여, 상기 뎁스 이미지로부터 상기 제2 높이에 위치하는 복수의 지점들에 대한 깊이 값을 획득하는 것을 특징으로 하는 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 적어도 하나의 프로세서는 상기 뎁스 캘리브레이션을 수행함에 있어서,상기 라이다 스캔 데이터로부터 상기 제1 높이에 위치하는 복수의 지점들에 대한 절대적인 깊이 값(absolute depth value)들을 획득하고,상기 뎁스 이미지로부터 상기 제1 높이에 위치하는 복수의 지점들에 대한 상대적인 깊이 값(relative depth value)들을 획득한 후,상기 획득한 절대적인 깊이 값들 및 상대적인 깊이 값들에 기초하여, 상기 뎁스 이미지에 포함된 상대적인 깊이 값을 절대적인 깊이 값으로 변환하기 위한 스케일 팩터(scale factor)를 획득하는 것을 특징으로 하는 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 적어도 하나의 프로세서는 상기 스케일 팩터를 획득함에 있어서,비용함수(cost function)를 이용하여, 상기 제1 높이에 위치하는 복수의 지점들에 대한 절대적인 깊이 값들과, 상기 제1 높이에 위치하는 복수의 지점들에 대한 상대적인 깊이 값들에 상기 스케일 팩터를 곱한 값들 간의 차이가 최소가 되도록, 상기 스케일 팩터의 값을 결정하는 것을 특징으로 하는 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서,상기 적어도 하나의 프로세서는 상기 검출된 객체가 존재하지 않는 높이를 상기 제2 높이로 결정함에 있어서,상기 촬영 이미지를 분석함으로써, 상기 대상 영역에서 상기 객체가 존재하지 않는 높이의 범위를 확인한 후,상기 확인된 범위 중에서 어느 하나의 높이를 상기 제2 높이로 결정하는 것을 특징으로 하는 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서,상기 적어도 하나의 프로세서는 상기 검출된 객체가 존재하지 않는 높이를 상기 제2 높이로 결정함에 있어서,상기 뎁스 이미지에 기초하여, 상기 제1 높이와 다른 복수의 높이들에 대해서 상기 대상 영역에 대한 공간 맵의 테두리(border)들을 결정한 후,상기 결정된 테두리들 중에서 연결점(junction)의 개수가 최소인 테두리에 대응되는 높이를 상기 제2 높이로 결정하는 것을 특징으로 하는 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>CHOI, I Sak</engName><name>최이삭</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>BYUN, Dong Nam</engName><name>변동남</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HWANG, Jin Young</engName><name>황진영</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.26</receiptDate><receiptNumber>1-1-2023-1181801-10</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230145096.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d25b0acb2956c4dd567bcc2b999104767f9e9419d740345f47de2fc094c9acb618977c104434cd54e0525e2bc202bd86f7c6689f497201e4</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf965da9994007687c5746f9f582f46986cfdffa81d4dacdb87d50c88a77732c6518074011f42dcafd7cde5e79b05dc211349df842a7835754</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>