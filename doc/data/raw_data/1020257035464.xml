<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:23.423</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.09.19</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7035464</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사용자 인터랙션들의 고속 및 정확한 추적을 사용하는 인간-컴퓨터 인터페이스</inventionTitle><inventionTitleEng>HUMAN-COMPUTER INTERFACE USING HIGH-SPEED AND ACCURATE  TRACKING OF USER INTERACTIONS</inventionTitleEng><openDate>2025.11.07</openDate><openNumber>10-2025-0159070</openNumber><originalApplicationDate>2019.09.19</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2021-7011793</originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.10.23</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G02B 27/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020217011793</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에 설명된 실시예들은 사용자에게 전략적으로 제시되는 사용자 인터페이스/사용자 경험과의 사용자 인터랙션들의 고속 및 효율적인 추적을 사용하여 인간-컴퓨터 인터페이스의 구현에 사용하기 위한 시스템들, 디바이스들 및 방법들에 관한 것이다. 본 명세서에 설명된 실시예들은 또한 머신들 및 디바이스들의 사용자 조작을 중재하기 위해 신경, 동안(oculomotor) 및/또는 근전도 검사(electromyography) 신호들을 사용하는 하드웨어 불문 인간-컴퓨터 인터페이스의 구현에 관한 것이다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2020.03.26</internationOpenDate><internationOpenNumber>WO2020061358</internationOpenNumber><internationalApplicationDate>2019.09.19</internationalApplicationDate><internationalApplicationNumber>PCT/US2019/051997</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 장치로서,사용자에게 인터랙티브 환경(interactive environment)을 제시하도록 구성되는 디스플레이;상기 디스플레이에 커플링된 눈-추적기(eye-tracker) - 상기 눈-추적기는 적어도 2개의 센서를 포함하고, 상기 적어도 2개의 센서는 상기 사용자의 눈으로부터의 눈-움직임(eye-movement) 신호들을 기록하도록 구성됨 -; 및상기 디스플레이 및 상기 눈-추적기에 동작 가능하게 커플링된 인터페이스 디바이스를 포함하고,상기 인터페이스 디바이스는메모리; 및프로세서를 포함하고,상기 프로세서는 상기 메모리에 동작 가능하게 커플링되고, 상기 눈-추적기의 상기 적어도 2개의 센서로부터 상기 눈-움직임 신호들을 수신하고, 상기 인터랙티브 환경을 통해 그리고 상기 디스플레이를 통해 상기 사용자에게 자극을 생성 및 제시하고, 상기 눈-움직임 신호들에 기초하여 상기 사용자의 초점을 결정하고, 상기 사용자의 초점에 기초하여 상기 사용자에 의해 의도된 액션을 결정하고, 상기 사용자에 의해 의도된 액션을 구현하도록구성되는 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 디스플레이는 상기 사용자에게 상기 인터랙티브 환경을 투영하도록 구성되는 디스플레이 렌즈를 포함하고,상기 눈-추적기의 상기 적어도 2개의 센서는 상기 디스플레이 렌즈 주위에 축들을 따라 위치 결정되는 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 디스플레이는 상기 사용자에게 상기 인터랙티브 환경을 투영하도록 구성되는 디스플레이 렌즈를 포함하고,상기 눈-추적기는 적어도 4개의 센서를 포함하고, 상기 적어도 4개의 센서는 상기 디스플레이 렌즈 주위에 2개의 직교 축을 따라 위치 결정되는 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 눈-추적기는 상기 적어도 2개의 센서 중의 각각의 센서에 의해 기록된 눈-움직임 신호들을 독립적인 방식으로 상기 프로세서에 전송하도록 추가로 구성되는 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 눈-움직임 신호들은 복수의 눈-움직임 신호 세트를 포함하고, 각각의 눈-움직임 신호 세트는 상기 적어도 2개의 센서 중의 각각의 센서에 의해 기록되고, 각각의 눈-움직임 신호 세트는 상기 적어도 2개의 센서 중의 나머지 센서들에 의해 기록된 상기 복수의 눈-움직임 신호 세트와 독립적이고,상기 프로세서는 상기 복수의 눈-움직임 신호 세트로부터의 각각의 눈-움직임 신호 세트에 기초하여, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 응시 벡터(gaze vector)를 컴퓨팅하고 - 각각의 센서와 연관된 상기 응시 벡터는 상기 사용자의 눈의 응시 각도를 나타냄 -, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 각각의 응시 벡터의 경사도를 결정하고 - 상기 경사도는 해당 센서와 연관된 수직각에 상대적임 -, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 각각의 응시 벡터의 경사도에 기초하여, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 가중치를 결정하여 가중치 세트를 생성하고, 캘리브레이션된 눈-움직임 신호 세트를 결정하기 위해 상기 복수의 눈-움직임 신호 세트에 상기 가중치 세트를 적용하도록추가로 구성되는 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 눈-움직임 신호들은 복수의 눈-움직임 신호 세트를 포함하고, 각각의 눈-움직임 신호 세트는 상기 적어도 2개의 센서 중의 각각의 센서에 의해 기록되고, 각각의 눈-움직임 신호 세트는 상기 적어도 2개의 센서 중의 나머지 센서들에 의해 기록된 상기 복수의 눈-움직임 신호 세트와 독립적이고,상기 프로세서는 상기 복수의 눈-움직임 신호 세트로부터의 각각의 눈-움직임 신호 세트에 기초하여, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 응시 벡터를 컴퓨팅하고 - 각각의 센서와 연관된 상기 응시 벡터는 상기 사용자의 눈의 응시 각도를 나타냄 -, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 각각의 응시 벡터의 경사도를 결정하고 - 상기 경사도는 해당 센서와 연관된 수직각에 상대적임 -, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 각각의 응시 벡터의 경사도 및 경험적으로 미리 결정된 가중치 함수에 기초하여, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 가중치를 결정하여 가중치 세트를 생성하고, 캘리브레이션된 눈-움직임 신호 세트를 결정하기 위해 상기 복수의 눈-움직임 신호 세트에 상기 가중치 세트를 적용하도록추가로 구성되는 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 눈-움직임 신호들은 복수의 눈-움직임 신호 세트를 포함하고, 각각의 눈-움직임 신호 세트는 상기 적어도 2개의 센서 중의 각각의 센서에 의해 기록되고, 각각의 눈-움직임 신호 세트는 상기 적어도 2개의 센서 중의 나머지 센서들에 의해 기록된 상기 복수의 눈-움직임 신호 세트와 독립적이고,상기 프로세서는상기 복수의 눈-움직임 신호 세트에서 누락된 데이터 포인트 세트를 식별하고,상기 눈-추적기로부터 상기 적어도 2개의 센서와 관련된 정보를 수신하고,상기 적어도 2개의 센서와 관련된 정보에 기초하여, 시뮬레이션된 사용자의 시뮬레이션된 눈-움직임 세트의 운동학적 모델(kinematics model)을 생성하고,상기 운동학적 모델에 기초하여, 복수의 시뮬레이션된 눈-움직임 신호 세트를 컴퓨팅하고 - 각각의 시뮬레이션된 눈-움직임 신호 세트는 상기 적어도 2개의 센서 중의 각각의 센서와 연관됨 -,상기 복수의 시뮬레이션된 눈-움직임 신호 세트에 기초하여, 상기 적어도 2개의 센서로부터 수신된 상기 눈-움직임 신호들에서 상기 누락된 데이터 포인트 세트를 대체하기 위해 대체 데이터 포인트 세트를 컴퓨팅하고,상기 누락된 데이터 포인트 세트를 대체하고 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 캘리브레이션된 눈-움직임 신호들을 생성하기 위해 상기 대체 데이터 포인트 세트를 통합하도록추가로 구성되고, 상기 사용자의 초점은 상기 캘리브레이션된 눈-움직임 신호들에 기초하여 결정되는 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 눈-추적기는 적어도 4개의 센서를 포함하고, 상기 4개의 센서는 2개의 직교 축을 따라 위치 결정되고, 상기 프로세서는, 상기 눈-움직임 신호들에 기초하여, 상기 2개의 직교 축에 상대적인 대응되는 응시 벡터 세트를 컴퓨팅하도록 추가로 구성되고, 상기 응시 벡터 세트는 상기 사용자의 눈의 응시 각도를 집합적으로 나타내도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 눈-움직임 신호들은 제1 시점에서 상기 사용자의 눈의 응시 각도에 대응하고, 상기 프로세서는, 상기 눈-움직임 신호들에 기초하여, 상기 제1 시점과 상이한 제2 시점에서 상기 사용자의 눈의 응시 각도를 결정하도록 추가로 구성되고, 상기 제2 시점은 상기 제1 시점 이후에 발생하는 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 눈-움직임 신호들은 제1 시점에서 상기 사용자의 눈의 응시 각도에 대응하고 상기 제1 시점에서 운동량의 제1 측정값과 연관되고, 상기 프로세서는, 상기 눈-움직임 신호들, 상기 제1 시점에서의 상기 응시 각도, 및 상기 제1 시점에서의 상기 운동량의 제1 측정값에 기초하여, 상기 제1 시점과 상이한 제2 시점에서 상기 사용자의 눈의 응시 각도를 결정하도록 추가로 구성되고, 상기 제2 시점은 상기 제1 시점 이후에 발생하는 장치.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 사용자에 의해 생성된 신경 신호들을 기록하도록 구성되는 신경 기록 디바이스를 추가로 포함하고, 상기 신경 신호들은 뇌파 검사(electroencephalogram)(EEG) 신호들을 포함하고, 상기 초점은 계산된 초점이고,상기 프로세서는상기 EEG 신호들을 수신하고 - 상기 EEG 신호들은 시각적 유발 전위들(visually evoked potentials)(VEP), 청각적 유발 전위들(auditory evoked potentials)(AEP), 운동 이미지 신호들(motor imagery signals), 이벤트 관련 전위들(Event Related Potentials)(ERP), 및 뇌 상태 의존 신호들(brain state dependent signals) 중 적어도 하나를 포함함 -,상기 EEG 신호들에 기초하여, 상기 사용자의 예상되는 초점을 결정하고,상기 계산된 초점과 상기 예상되는 초점 사이의 비교에 기초하여, 상기 계산된 초점과 연관된 오차 척도(measure of error)를 컴퓨팅하고,상기 오차 척도에 기초하여, 상기 계산된 초점을 정정하여 상기 사용자의 캘리브레이션된 초점을 생성하도록추가로 구성되는 장치.</claim></claimInfo><claimInfo><claim>12. 방법으로서,사용자에게 디스플레이를 통해, 인터랙티브 사용자 인터페이스에 포함된 자극을 제시하는 단계;눈-추적기로부터, 사용자 거동과 연관된 눈-움직임 신호들을 수신하는 단계 - 상기 눈-움직임 신호들은 상기 눈-추적기 상에 위치 결정되는 적어도 2개의 센서에 의해 독립적으로 기록됨 -;상기 제시된 자극과 관련된 정보를 수신하는 단계;상기 눈-움직임 신호들에 기초하여 상기 사용자의 초점을 결정하는 단계;상기 초점 및 상기 자극에 기초하여, 상기 사용자에 의해 의도된 액션을 결정하는 단계; 및상기 인터랙티브 사용자 인터페이스를 통해 상기 액션을 구현하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 자극을 제시하는 단계는 상기 디스플레이와 연관된 디스플레이 렌즈를 통해 상기 자극의 이미지를 투영하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 자극과 관련된 정보를 수신하는 단계는 상기 디스플레이의 속성들과 관련된 정보를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 디스플레이에 상대적인 상기 적어도 2개의 센서 중의 각각의 센서의 위치 결정의 표시 및 상기 사용자의 눈에 상대적인 상기 적어도 2개의 센서 중의 각각의 센서의 위치 결정의 표시를 포함하는, 상기 적어도 2개의 센서와 관련된 정보를 수신하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서, 상기 초점을 결정하는 단계는 상기 적어도 2개의 센서 중의 각각의 센서에 의해 기록된 눈-움직임 신호들과 연관된 응시 벡터를 계산하는 것에 기초하고,상기 방법은상기 눈-움직임 신호들에 기초하여, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 응시 벡터를 컴퓨팅하는 단계 - 상기 응시 벡터는 상기 사용자의 눈의 응시 각도를 나타냄 -;상기 적어도 2개의 센서 중의 각각의 센서와 연관된 응시 벡터의 경사도를 결정하는 단계 - 상기 응시 벡터의 경사도는 상기 적어도 2개의 센서 중의 해당 센서와 연관된 수직각에 상대적임 -;상기 적어도 2개의 센서 중의 각각의 센서와 연관된 응시 벡터의 경사도에 기초하여, 상기 적어도 2개의 센서 중의 각각의 센서와 연관된 가중치들을 정의하여 가중치 세트를 생성하는 단계; 및캘리브레이션된 눈-움직임 신호 세트를 컴퓨팅하기 위해 상기 적어도 2개의 센서 중의 각각의 센서에 의해 독립적으로 기록된 눈-움직임 신호들에 상기 가중치 세트를 적용하는 단계를 추가로 포함하고, 상기 초점을 결정하는 단계는 상기 캘리브레이션된 눈-움직임 신호 세트에 기초하는 방법.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서, 상기 눈-추적기로부터 수신하는 단계는 적어도 4개의 센서에 의해 기록된 눈-움직임 신호들을 수신하는 단계를 포함하고,상기 방법은상기 눈-움직임 신호들에 기초하여 상기 사용자의 눈의 응시 벡터 세트를 컴퓨팅하는 단계 - 상기 응시 벡터 세트로부터의 각각의 응시 벡터는 상기 적어도 4개의 센서 중의 각각의 센서와 연관됨 -;제1 축 및 상기 제1 축에 직교하는 제2 축을 따라 상기 응시 벡터 세트를 분해하는(resolving) 단계;제1 센서 세트와 연관된 응시 벡터들의 제1 가중 평균에 기초하여 제1 평균 응시 벡터를 컴퓨팅하는 단계 - 상기 제1 센서 세트는 상기 제1 축을 따라 그룹화됨 -;제2 센서 세트와 연관된 응시 벡터들의 제2 가중 평균에 기초하여 제2 평균 응시 벡터를 컴퓨팅하는 단계 - 상기 제2 센서 세트는 상기 제2 축을 따라 그룹화됨 -; 및상기 제1 평균 응시 벡터 및 상기 제2 평균 응시 벡터에 기초하여 캘리브레이션된 응시 벡터를 컴퓨팅하는 단계를 추가로 포함하고, 상기 사용자의 초점은 상기 캘리브레이션된 응시 벡터에 기초하여 결정되는 방법.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서,상기 눈-움직임 신호들에 기초하여 양안 응시 벡터 세트(set of binocular gaze vectors)의 교차점을 결정하는 단계 - 상기 교차점은 상기 사용자의 초점을 나타냄 -;헤드-추적기(head-tracker)로부터, 상기 사용자로부터의 헤드-움직임 신호들을 수신하는 단계;상기 헤드-움직임 신호들에 기초하여 상기 사용자의 눈들의 평면을 결정하는 단계;상기 자극의 2차원 투영을 컴퓨팅하는 단계 - 상기 자극은 3차원이고, 상기 2차원 투영은 상기 사용자의 눈들의 평면에 평행한 평면 상에 있음 -;2차원 영역을 정의하는 경계를 생성하는 단계 - 상기 2차원 영역은 상기 자극의 2차원 투영에 포함되고, 상기 자극의 객체와 연관됨 -;상기 사용자의 초점과 상기 객체와 연관된 상기 2차원 영역 사이의 중첩을 계산하는 단계; 및상기 중첩에 기초하여, 상기 사용자의 초점과 상기 객체 사이의 인터랙션(interaction)을 결정하는 단계를 추가로 포함하고, 상기 사용자에 의해 의도된 액션을 결정하는 단계는 상기 사용자의 초점과 상기 객체 사이의 상기 인터랙션에 기초하는 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 자극에 포함된 인터랙티브 객체 세트를 식별하는 단계;상기 인터랙티브 객체 세트의 밀도를 계산하는 단계; 및상기 인터랙티브 객체 세트의 밀도에 기초하여 경계-스케일링 계수(boundary-scaling factor)를 정의하는 단계를 추가로 포함하고, 상기 2차원 영역을 정의하는 경계를 생성하는 단계는 상기 경계-스케일링 계수에 기초하는 방법.</claim></claimInfo><claimInfo><claim>20. 제12항에 있어서,헤드-추적기로부터, 상기 사용자로부터의 헤드-움직임 신호들을 수신하는 단계;상기 헤드-움직임 신호들에 기초하여 상기 사용자의 눈들의 평면을 결정하는 단계;상기 자극의 2차원 투영을 컴퓨팅하는 단계 - 상기 자극은 3차원이고, 상기 2차원 투영은 상기 사용자의 눈들의 평면에 평행한 평면 상에 있음 -;상기 눈-움직임 신호들에 기초하여 양안 응시 벡터 세트의 교차점을 결정하는 단계 - 상기 교차점은 상기 사용자의 초점을 나타냄 -;2차원 영역을 정의하는 경계를 생성하는 단계 - 상기 2차원 영역은 상기 자극의 2차원 투영에 포함되고, 상기 자극에서의 인터랙티브 객체와 연관됨 -;상기 2차원 영역에 매핑된 포인트 세트를 식별하는 단계;상기 포인트 세트에 기초하여, 상기 인터랙티브 객체와 연관된 볼록 껍질(convex hull)을 계산하는 단계;상기 사용자의 초점과 상기 인터랙티브 객체와 연관된 볼록 껍질 사이의 거리의 측정값을 계산하는 단계; 및상기 거리의 측정값에 기초하여, 상기 사용자의 초점과 상기 인터랙티브 객체 사이의 인터랙션을 결정하는 단계를 추가로 포함하고, 상기 사용자에 의해 의도된 액션을 결정하는 단계는 상기 사용자의 초점과 상기 객체 사이의 상기 인터랙션에 기초하는 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매사추세츠주 보스톤 브롬필드 스트리트 ** 스위트 ***</address><code>520190542564</code><country>미국</country><engName>Neurable Inc.</engName><name>뉴레이블 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 매사추세츠...</address><code> </code><country>미국</country><engName>JANTZ, Jay</engName><name>잔츠, 제이</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠...</address><code> </code><country>미국</country><engName>ALCAIDE, Ramses</engName><name>알카이데, 람세스</name></inventorInfo><inventorInfo><address>미국 ***** 매사추...</address><code> </code><country>미국</country><engName>PADDEN, Dereck</engName><name>파덴, 데렉</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠...</address><code> </code><country>미국</country><engName>HAMET, James</engName><name>하멧, 제임스</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠...</address><code> </code><country>미국</country><engName>MORRIS JR., Jeffrey</engName><name>모리스 주니어, 제프리</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠...</address><code> </code><country>미국</country><engName>PEREIRA, Arnaldo</engName><name>페레이라, 아날도</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2018.09.21</priorityApplicationDate><priorityApplicationNumber>16/138,791</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.10.23</receiptDate><receiptNumber>1-1-2025-1182393-20</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257035464.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937ef3a9d836d5388760a78d03bc617b3982fabba5dc474a8cdf9e6107836e47284133184fd49635653f3f56544d0f40f1133ff35f75eed238</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf87ae9397fb997ca7c5ec90ebb6ddba29b5b767f66774599c0770d6dd7c63699c35b9e68dc4e59db8d9eb10f8f04908dcf31242b4fe3a0978</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>