<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:35.5335</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0166589</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인체를 3차원 모델링하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR 3D MODELING OF HUMAN BODY</inventionTitleEng><openDate>2023.06.07</openDate><openNumber>10-2023-0079618</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.07</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시 예에 따르면, 웨어러블 디바이스 착용자의 3차원 모델링을 위해, 웨어러블 디바이스에 장착된 복수의 촬영 장치들로부터 획득한, 착용자에 대한 복수의 영상들 각각에 대해 특징 맵(feature map)을 생성하고, 복수의 영상들 각각에 대해, 특징 맵에 기초하여 착용자의 관절(joint) 위치에 대응하는 조인트 키포인트(joint keypoint) 정보 - 조인트 키포인트 정보는 2차원 픽셀 정보 및 깊이 정보를 포함함 - 및 착용자의 형상(shape)에 대한 초기 형상 계수(shape coefficient) 정보를 획득하고, 조인트 키포인트 정보 및 초기 형상 계수 정보에 기초하여, 착용자를 3차원 모델링하기 위한 타겟 3차원 조인트 각도를 결정하고, 조인트 키포인트 정보 및 초기 형상 계수 정보에 기초하여, 착용자를 3차원 모델링하기 위한 타겟 형상 계수 정보를 결정하고, 및 타겟 3차원 조인트 각도 및 타겟 형상 계수 정보에 기초하여, 착용자에 대한 3차원 메쉬(mesh)를 획득할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 웨어러블 디바이스의 착용자를 3차원 모델링하는 방법에 있어서,상기 웨어러블 디바이스에 장착된 복수의 촬영 장치들로부터 획득한, 상기 착용자에 대한 복수의 영상들 각각에 대해, 특징 맵(feature map)을 생성하는 단계;상기 복수의 영상들 각각에 대해, 상기 특징 맵에 기초하여 상기 착용자의 관절(joint) 위치에 대응하는 조인트 키포인트(joint keypoint) 정보 - 상기 조인트 키포인트 정보는 2차원 픽셀 정보 및 깊이 정보를 포함함 - 및 상기 착용자의 형상(shape)에 대한 초기 형상 계수(shape coefficient) 정보를 획득하는 단계;상기 조인트 키포인트 정보 및 상기 초기 형상 계수 정보에 기초하여, 상기 착용자를 3차원 모델링하기 위한 타겟 3차원 조인트 각도를 결정하는 단계;상기 조인트 키포인트 정보 및 상기 초기 형상 계수 정보에 기초하여, 상기 착용자를 3차원 모델링하기 위한 타겟 형상 계수 정보를 결정하는 단계; 및상기 타겟 3차원 조인트 각도 및 상기 타겟 형상 계수 정보에 기초하여, 상기 착용자에 대한 3차원 메쉬(mesh)를 획득하는 단계를 포함하는,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 특징 맵은,Mobilenet, Googlenet 및 Resnet 중 적어도 어느 하나에 기초하여 생성되는,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 복수의 영상들 각각에 대해 상기 조인트 키포인트 정보 및 상기 초기 형상 계수 정보를 획득하는 단계는,상기 특징 맵 및 제1 컨볼루션 신경망(convolution neural network) 모델에 기초하여 추론되는 상기 2차원 픽셀 정보를 획득하는 단계;상기 특징 맵 및 제2 컨볼루션 신경망 모델에 기초하여 추론되는 상기 깊이 정보를 획득하는 단계; 및상기 특징 맵에 대한 반복적 회귀분석(iterative regression)을 통해 상기 초기 형상 계수 정보를 획득하는 단계를 포함하는,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 타겟 3차원 조인트 각도를 결정하는 단계는,상기 2차원 픽셀 정보에 대한 오차를 계산하는 단계;상기 깊이 정보에 대한 오차를 계산하는 단계;시간에 따른 3차원 조인트 각도의 오차를 계산하는 단계;상기 2차원 픽셀 정보에 대한 오차, 상기 깊이 정보에 대한 오차 및 상기 시간에 따른 3차원 조인트 각도의 오차에 기초하여 3차원 조인트 각도에 대한 전체 오차를 계산하는 단계; 및상기 전체 오차가 최소가 되는 3차원 조인트 각도를 상기 타겟 3차원 조인트 각도로 결정하는 단계를 포함하는,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 복수의 촬영 장치들이 상기 웨어러블 디바이스의 좌측에 장착된 좌측 촬영 장치 및 상기 웨어러블 디바이스의 우측에 장착된 우측 촬영 장치로 구성되는 경우,상기 2차원 픽셀 정보에 대한 오차는,하기 수학식 1에 기초하여 계산되는,3차원 모델링 방법.[수학식 1]여기서, 는 상기 2차원 픽셀 정보에 대한 오차, 는 3차원 조인트 각도, 는 형상 계수 정보, Xi는 와 를 입력으로 vertex를 출력하는 SMPL(Skinned. Multi-person Linear Model)에서 i번째 관절의 3차원 위치 정보, l은 상기 좌측 촬영 장치의 장착 위치로 투영(projection)하는 함수, r은 상기 우측 촬영 장치의 장착 위치로 투영(projection)하는 함수, li는 상기 좌측 촬영 장치로 획득된 영상에서 i번째 관절의 상기 2차원 픽셀 정보, ri는 상기 우측 촬영 장치로 획득된 영상에서 i번째 관절의 상기 2차원 픽셀 정보, vli는 상기 좌측 촬영 장치로 획득된 영상에서 i번째 관절이 관찰되었는지 여부에 대한 정보 - 관찰된 경우 1, 관찰되지 않은 경우 0 -, vri는 상기 우측 촬영 장치로 획득된 영상에서 i번째 관절이 관찰되었는지 여부에 대한 정보 - 관찰된 경우 1, 관찰되지 않은 경우 0 -, 는 L2-놈(norm)의 제곱으로, 각 성분의 제곱합을 의미함.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 형상 계수 정보 의 초기값인 초기 형상 계수 정보 는,상기 좌측 촬영 장치로 획득된 영상으로부터 획득된 초기 형상 계수 정보인 과 상기 우측 촬영 장치로 획득된 영상으로부터 획득된 초기 형상 계수 정보인 의 평균인,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 복수의 촬영 장치들이 상기 웨어러블 디바이스의 좌측에 장착된 좌측 촬영 장치 및 상기 웨어러블 디바이스의 우측에 장착된 우측 촬영 장치로 구성되는 경우,상기 깊이 정보에 대한 오차는 좌측 깊이 정보 오차 및 우측 깊이 정보 오차를 합산함으로써 계산되며, 상기 좌측 깊이 정보 오차는 하기 수학식 2에 기초하여 계산되고, 상기 우측 깊이 정보 오차는 하기 수학식 3에 기초하여 계산되는,3차원 모델링 방법.[수학식 2]여기서, 은 상기 좌측 깊이 정보 오차, 는 3차원 조인트 각도, 는 형상 계수 정보, Xi는 와 를 입력으로 vertex를 출력하는 SMPL에서 i번째 관절의 3차원 위치 정보, 은 상기 좌측 촬영 장치로 획득된 영상에서 상기 SMPL의 관절의 깊이 정보, X0는 상기 SMPL의 기준 관절의 3차원 위치 정보, vli는 상기 좌측 촬영 장치로 획득된 영상에서 i번째 관절이 관찰되었는지 여부에 대한 정보 - 관찰된 경우 1, 관찰되지 않은 경우 0 -, 는 상기 좌측 촬영 장치로 획득된 영상에서 i번째 관절의 상기 깊이 정보, 는 상기 좌측 촬영 장치로 획득된 영상에서 i번째 관절의 깊이 정보의 초기값, 는 L2-놈(norm)의 제곱으로, 각 성분의 제곱합을 의미함.[수학식 3]여기서, 은 상기 우측 깊이 정보 오차, 는 3차원 조인트 각도, 는 상기 형상 계수 정보, Xi는 와 를 입력으로 vertex를 출력하는 SMPL에서 i번째 관절의 3차원 위치 정보, 은 상기 우측 촬영 장치로 획득된 영상에서 상기 SMPL의 관절의 깊이 정보, X0는 상기 SMPL의 기준 관절의 3차원 위치 정보, vri는 상기 우측 촬영 장치로 획득된 영상에서 i번째 관절이 관찰되었는지 여부에 대한 정보 - 관찰된 경우 1, 관찰되지 않은 경우 0 -, 는 상기 우측 촬영 장치로 획득된 영상에서 i번째 관절의 상기 깊이 정보, 는 상기 우측 촬영 장치로 획득된 영상에서 i번째 관절의 깊이 정보의 초기값, 는 L2-놈(norm)의 제곱으로, 각 성분의 제곱합을 의미함.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서,상기 시간에 따른 3차원 조인트 각도의 오차는, 하기 수학식 4에 기초하여 계산되는,3차원 모델링 방법.[수학식 4]여기서, 는 상기 시간에 따른 3차원 조인트 각도의 오차, 는 3차원 조인트 각도, 는 직전 프레임에서의 3차원 조인트 각도, 는 L2-놈(norm)의 제곱으로 각 성분의 제곱합을 의미함.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 타겟 형상 계수 정보를 결정하는 단계는,하기 수학식 5에 기초하여 계산되는,3차원 모델링 방법.[수학식 5]여기서, 은 상기 타겟 형상 계수 정보, 는 상기 2차원 픽셀 정보에 대한 오차, 는 3차원 조인트 각도, 는 형상 계수 정보를 의미함.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 복수의 촬영 장치들 각각은,어안렌즈(fisheye lens)를 포함하는,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 웨어러블 디바이스는,AR글래스 및 HMD(head-mounted display) 중 어느 하나인,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 복수의 촬영 장치들 중 적어도 두 개의 촬영 장치는,상기 웨어러블 디바이스의 좌측 끝 및 우측 끝에, 각각 하단 방향으로 소정의 각도를 이루도록 장착되고,각각 일정 크기의 화각(FoV: field of view)을 갖는,3차원 모델링 방법.</claim></claimInfo><claimInfo><claim>13. 하드웨어와 결합되어 제1항 내지 제12항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>14. 착용자의 3차원 모델링 방법을 수행하는 웨어러블 디바이스에 있어서,상기 착용자에 대한 복수의 영상들을 획득하기 위한 복수의 촬영 장치들;컴퓨터로 실행 가능한 명령어들(computer-executable instructions)이 저장된 메모리; 및상기 메모리에 억세스(access)하여 상기 명령어들을 실행하는 프로세서를 포함하고,상기 명령어들은,상기 복수의 영상들 각각에 대해, 특징 맵(feature map)을 생정하고,상기 복수의 영상들 각각에 대해, 상기 특징 맵에 기초하여 상기 착용자의 관절(joint) 위치에 대응하는 조인트 키포인트(joint keypoint) 정보 - 상기 조인트 키포인트 정보는 2차원 픽셀 정보 및 깊이 정보를 포함함 - 및 상기 착용자의 형상(shape)에 대한 초기 형상 계수(shape coefficient) 정보를 획득하고,상기 조인트 키포인트 정보 및 상기 초기 형상 계수 정보에 기초하여, 상기 착용자를 3차원 모델링하기 위한 타겟 3차원 조인트 각도를 결정하고,상기 조인트 키포인트 정보 및 상기 초기 형상 계수 정보에 기초하여, 상기 착용자를 3차원 모델링하기 위한 타겟 형상 계수 정보를 결정하고, 및상기 타겟 3차원 조인트 각도 및 상기 타겟 형상 계수 정보에 기초하여, 상기 착용자에 대한 3차원 메쉬(mesh)를 획득하도록 구성되는,웨어러블 디바이스.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 명령어들은,상기 특징 맵 및 제1 컨볼루션 신경망(convolution neural network) 모델에 기초하여 추론되는 상기 2차원 픽셀 정보를 획득하고,상기 특징 맵 및 제2 컨볼루션 신경망 모델에 기초하여 추론되는 상기 깊이 정보를 획득하고, 및상기 특징 맵에 대한 반복적 회귀분석(iterative regression)을 통해 상기 초기 형상 계수 정보를 획득하도록 구성되는,웨어러블 디바이스.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 명령어들은,상기 2차원 픽셀 정보에 대한 오차를 계산하고,상기 깊이 정보에 대한 오차를 계산하고,시간에 따른 3차원 조인트 각도의 오차를 계산하고,상기 2차원 픽셀 정보에 대한 오차, 상기 깊이 정보에 대한 오차 및 상기 시간에 따른 3차원 조인트 각도에 기초하여 전체 오차를 계산하고, 및상기 전체 오차가 최소가 되는 3차원 조인트 각도를 상기 타겟 3차원 조인트 각도로 결정하도록 구성되는,웨어러블 디바이스.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 명령어들은,시간에 따라 3차원 조인트 각도를 상기 2차원 픽셀 정보에 대한 오차에 입력함으로써 출력되는 값들을 합산한 값이 최소가 되는 형상 계수 정보를 상기 타겟 형상 계수 정보로 결정하도록 구성되는,웨어러블 디바이스.</claim></claimInfo><claimInfo><claim>18. 제14항에 있어서,상기 복수의 촬영 장치들 각각은,어안렌즈(fisheye lens)를 포함하는,웨어러블 디바이스.</claim></claimInfo><claimInfo><claim>19. 제14항에 있어서,상기 웨어러블 디바이스는,AR글래스 및 HMD(head-mounted display) 중 어느 하나인,웨어러블 디바이스.</claim></claimInfo><claimInfo><claim>20. 제14항에 있어서,상기 복수의 촬영 장치들 중 적어도 두 개의 촬영 장치는,상기 웨어러블 디바이스의 좌측 끝 및 우측 끝에, 각각 하단 방향으로 소정의 각도를 이루도록 장착되고,각각 일정 크기의 화각(FoV: field of view)을 갖는,웨어러블 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 양천구...</address><code>420200351124</code><country>대한민국</country><engName>JEE, Seunghoon</engName><name>지승훈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.11.29</receiptDate><receiptNumber>1-1-2021-1375901-58</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.07</receiptDate><receiptNumber>1-1-2024-1222480-98</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210166589.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e581c55c90ffd26821ede75ead1e70458db701e4de651e4ce8abde1c6246e89a571d09e7ed95ee1d744811e6439a7f3a2a1b0d7a704e9d77</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb4c1e48a651fb0d66780ee443a0d0222c5777fdea60f85907596edcfb8fb6b1d6f4930e628bb00a54927241c85104ab6c52a25aa6b6f7f1c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>