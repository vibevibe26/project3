<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:40.5640</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.03.30</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7034425</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>제스처-기반 공유 AR 세션 생성</inventionTitle><inventionTitleEng>GESTURE-BASED SHARED AR SESSION CREATION</inventionTitleEng><openDate>2025.10.21</openDate><openNumber>10-2025-0151622</openNumber><originalApplicationDate>2021.03.30</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2022-7037572</originalApplicationNumber><originalExaminationRequestDate>2025.10.15</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.10.15</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04815</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 51/046</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 51/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 51/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 67/131</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020227037572</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 제스처에 기초하여 공유 AR 세션을 생성하는 방법은 서버가 관찰된 모션 데이터를 제1 사용자와 연관된 제1 디바이스로부터 수신하는 것으로 시작한다. 제1 디바이스는, 제스처를 수행하는 제2 사용자의 이미지들을 포함하는 데이터 스트림의 분석에 기초하여, 관찰된 모션 데이터를 생성한다. 제2 사용자는 제2 디바이스와 연관된다. 서버는 제스처에 대응하는 캡처된 모션 데이터를 제2 디바이스로부터 수신한다. 캡처된 모션 데이터는 제2 디바이스에 포함되는 센서에 의해 기록된다. 서버는 제1 디바이스로부터의 관찰된 모션 데이터와 제2 디바이스로부터의 캡처된 모션 데이터 사이에 매칭이 존재하는지를 결정한다. 매칭이 존재한다고 결정하는 것에 응답하여, 서버는 제1 디바이스와 제2 디바이스 사이에 공유 AR 세션을 생성하고, 공유 AR 세션으로 하여금 제1 디바이스 및 제2 디바이스에 의해 디스플레이되게 한다. 다른 실시예들이 본 명세서에 설명된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.10.07</internationOpenDate><internationOpenNumber>WO2021203133</internationOpenNumber><internationalApplicationDate>2021.03.30</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/070340</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,관찰된 모션 데이터를 제1 사용자와 연관된 제1 디바이스로부터 수신하는 단계 - 상기 제1 디바이스는 공유 증강 현실(augmented reality: AR) 세션을 공유하는 것을 나타내는 제스처를 수행하는 제2 사용자의 이미지들을 포함하는 데이터 스트림의 분석에 기초하여 상기 관찰된 모션 데이터를 생성하고, 상기 제2 사용자는 제2 디바이스와 연관됨 -;상기 제스처에 대응하는 캡처된 모션 데이터를 상기 제2 디바이스로부터 수신하는 단계 - 상기 캡처된 모션 데이터는 상기 제2 디바이스에 포함된 센서에 의해 기록됨 -;상기 제1 디바이스로부터의 상기 관찰된 모션 데이터와 상기 제2 디바이스로부터의 상기 캡처된 모션 데이터 사이에 매칭이 존재하는지를 결정하는 단계; 및상기 매칭이 존재한다는 결정에 응답하여, AR 세션이 현재 상기 제1 디바이스 또는 상기 제2 디바이스에 존재하는지를 결정하는 단계;AR 세션이 현재 존재하지 않을 경우, 상기 제1 디바이스와 상기 제2 디바이스 사이에 새로운 공유 AR 세션을 개시하는 단계;AR 세션이 현재 존재하는 경우, 새로운 공유 AR 세션을 사이에 생성하기 위해 상기 현재 존재하는 AR 세션에 상기 제1 디바이스 또는 상기 제2 디바이스를 추가하는 단계; 및상기 공유 AR 세션으로 하여금 상기 제1 디바이스에 의해 그리고 상기 제2 디바이스에 의해 디스플레이되게 하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 공유 AR 세션은 실시간 메시징 세션을 포함하는 방법. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 데이터 스트림은 상기 제2 사용자의 비디오인 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 제1 디바이스가 상기 데이터 스트림의 분석에 기초하여 상기 관찰된 모션 데이터를 생성하는 것은상기 제1 디바이스가 상기 제2 사용자의 적어도 하나의 신체 부분의 위치들을 식별하는 것 및 상기 제스처 동안 상기 적어도 하나의 신체 부분의 모션을 분석하는 것을 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 적어도 하나의 신체 부분은 상기 제2 사용자의 팔 또는 손을 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 데이터 스트림은 제3 디바이스와 연관된 제3 사용자의 이미지들을 추가로 포함하고, 상기 제1 디바이스는 상기 데이터 스트림에서의 상기 제2 사용자를 상기 제2 디바이스와 연관되는 것으로서 식별하는 방법.</claim></claimInfo><claimInfo><claim>7. 시스템으로서,프로세서; 및 명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때, 상기 시스템으로 하여금 동작들을 수행하게 하고, 상기 동작들은관찰된 모션 데이터를 제1 사용자와 연관된 제1 디바이스로부터 수신하는 동작 - 상기 제1 디바이스는 공유 증강 현실(augmented reality: AR) 세션을 공유하는 것을 나타내는 제스처를 수행하는 제2 사용자의 이미지들을 포함하는 데이터 스트림의 분석에 기초하여 상기 관찰된 모션 데이터를 생성하고, 상기 제2 사용자는 제2 디바이스와 연관됨 -;상기 제스처에 대응하는 캡처된 모션 데이터를 상기 제2 디바이스로부터 수신하는 동작 - 상기 캡처된 모션 데이터는 상기 제2 디바이스에 포함된 센서에 의해 기록됨 -;상기 제1 디바이스로부터의 상기 관찰된 모션 데이터와 상기 제2 디바이스로부터의 상기 캡처된 모션 데이터 사이에 매칭이 존재하는지를 결정하는 동작; 및상기 매칭이 존재한다는 결정에 응답하여, AR 세션이 현재 상기 제1 디바이스 또는 상기 제2 디바이스에 존재하는지를 결정하는 동작;AR 세션이 현재 존재하지 않을 경우, 상기 제1 디바이스와 상기 제2 디바이스 사이에 새로운 공유 AR 세션을 개시하는 동작;AR 세션이 현재 존재하는 경우, 새로운 공유 AR 세션을 사이에 생성하기 위해 상기 현재 존재하는 AR 세션에 상기 제1 디바이스 또는 상기 제2 디바이스를 추가하는 동작; 및상기 공유 AR 세션으로 하여금 상기 제1 디바이스에 의해 그리고 상기 제2 디바이스에 의해 디스플레이되게 하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 공유 AR 세션은 실시간 메시징 세션을 포함하는 시스템. </claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 데이터 스트림은 상기 제스처를 수행하는 상기 제2 사용자의 비디오이고, 상기 비디오는 상기 제1 디바이스에 포함된 카메라에 의해 캡처되는 시스템.</claim></claimInfo><claimInfo><claim>10. 제7항에 있어서,상기 제1 디바이스가 상기 데이터 스트림의 분석에 기초하여 상기 관찰된 모션 데이터를 생성하는 것은상기 제1 디바이스가 상기 제2 사용자의 적어도 하나의 신체 부분의 위치들을 식별하는 것 및 상기 제스처 동안 상기 적어도 하나의 신체 부분의 모션을 분석하는 것을 추가로 포함하는 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 적어도 하나의 신체 부분은 상기 제2 사용자의 팔 또는 손을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>12. 제7항에 있어서,상기 데이터 스트림은 제3 디바이스와 연관된 제3 사용자의 이미지들을 추가로 포함하고, 상기 제1 디바이스는 상기 데이터 스트림에서의 상기 제2 사용자를 상기 제2 디바이스와 연관되는 것으로서 식별하는 시스템.</claim></claimInfo><claimInfo><claim>13. 명령어들이 저장된 비-일시적 컴퓨터-판독가능 저장 매체로서,상기 명령어들은, 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하고, 상기 동작들은관찰된 모션 데이터를 제1 사용자와 연관된 제1 디바이스로부터 수신하는 동작 - 상기 제1 디바이스는 데이터 스트림의 분석에 기초하여 상기 관찰된 모션 데이터를 생성하고, 상기 제1 디바이스는 제스처를 수행하는 제2 사용자의 이미지들을 포함하는 상기 데이터 스트림을 캡처하는 카메라를 포함하고, 상기 제2 사용자는 제2 디바이스와 연관되고 상기 제2 디바이스에 연결됨 -;상기 제2 디바이스에 포함된 센서에 의해 기록된 캡처된 모션 데이터를 상기 제2 디바이스로부터 수신하는 동작 - 상기 센서는 상기 제2 디바이스의 위치, 움직임, 및 배향을 캡처함 -;상기 제1 디바이스로부터의 상기 관찰된 모션 데이터와 상기 제2 디바이스로부터의 상기 캡처된 모션 데이터 사이에 매칭이 존재하는지를 결정하는 동작 - 상기 매칭이 존재한다고 결정하는 것은, 미리 결정된 에러 임계값 내에서 상기 제2 사용자에 의해 수행되는 동일한 제스처를 설명하는 상기 관찰된 모션 데이터 및 상기 캡처된 모션 데이터에 기초함 -; 및상기 매칭이 존재한다는 결정에 응답하여, 상기 제1 디바이스와 상기 제2 디바이스 사이에 공유 AR 세션을 생성하는 동작; 및상기 공유 AR 세션으로 하여금 상기 제1 디바이스에 의해 그리고 상기 제2 디바이스에 의해 디스플레이되게 하는 동작을 포함하는 비-일시적 컴퓨터-판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>14. 방법으로서,제1 디바이스에 포함된 카메라를 사용하여, 제스처를 수행하는 제2 디바이스의 사용자의 비디오를 캡처하는 단계 - 상기 제2 디바이스의 상기 사용자는 상기 제2 디바이스에 연결됨 -; 상기 제1 디바이스에 포함된 프로세서에 의해, 상기 제2 디바이스의 상기 사용자의 상기 비디오의 분석에 기초하여, 관찰된 모션 데이터를 생성하는 단계; 상기 제스처에 대응하는 캡처된 모션 데이터를 상기 제2 디바이스로부터 수신하는 단계 - 상기 캡처된 모션 데이터는 상기 제2 디바이스에 포함된 센서에 의해 기록됨 -;상기 제1 디바이스로부터의 상기 관찰된 모션 데이터와 상기 제2 디바이스로부터의 상기 캡처된 모션 데이터 사이에 매칭이 존재하는지를 결정하는 단계; 및상기 매칭이 존재한다는 결정에 응답하여, AR 세션이 현재 상기 제1 디바이스 또는 상기 제2 디바이스에 존재하는지를 결정하는 단계;AR 세션이 현재 존재하지 않을 경우, 상기 제1 디바이스와 상기 제2 디바이스 사이에 새로운 공유 AR 세션을 개시하는 단계;AR 세션이 현재 존재하는 경우, 새로운 공유 AR 세션을 사이에 생성하기 위해 상기 현재 존재하는 AR 세션에 상기 제1 디바이스 또는 상기 제2 디바이스를 추가하는 단계; 및상기 공유 AR 세션으로 하여금 상기 제1 디바이스에 의해 그리고 상기 제2 디바이스에 의해 디스플레이되게 하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 매칭이 존재한다는 결정에 응답하여, 상기 공유 AR 세션으로 하여금 상기 제1 디바이스에 의해 그리고 상기 제2 디바이스에 의해 디스플레이되게 하라는 요청을 송신하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 제1 디바이스와 상기 제2 디바이스 사이에 공유 AR 세션이 수립되는 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 매칭이 존재한다는 결정에 응답하여, 상기 제1 디바이스에 의해, 상기 비디오에서의 상기 제2 디바이스의 상기 사용자를 상기 제2 디바이스와 연관되는 것으로서 식별하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 제14항에 있어서,상기 공유 AR 세션은 실시간 메시징 세션을 포함하는 방법. </claim></claimInfo><claimInfo><claim>19. 제14항에 있어서,상기 제1 디바이스에 의해 상기 관찰된 모션 데이터를 생성하는 것은상기 제2 디바이스의 상기 사용자의 적어도 하나의 신체 부분의 위치들을 식별하는 것 및 상기 제스처 동안 상기 적어도 하나의 신체 부분의 모션을 분석하는 것을 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 적어도 하나의 신체 부분은 상기 제2 디바이스의 상기 사용자의 팔 또는 손을 포함하는 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>영국</country><engName>COWBURN, Piers George</engName><name>카우번, 피어스 조지</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>영국</country><engName>LI, David</engName><name>리, 데이비드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>핀란드</country><engName>MUELLER SANDVIK, Isac Andreas</engName><name>뮐러 샌드빅, 아이작 안드레아스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>영국</country><engName>PAN, Qi</engName><name>판, 치</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.03.30</priorityApplicationDate><priorityApplicationNumber>63/002,099</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.08.03</priorityApplicationDate><priorityApplicationNumber>16/983,693</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.10.15</receiptDate><receiptNumber>1-1-2025-1151793-64</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257034425.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937e31a9d38214751603f3d70225fd34178f0df29b3ae8fad459e9d625e60ded968ea08c38764efa1a3f7acabddca182a2c52a6e9d225f16b0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf247b5c78e370b4b94586a638aaef274f5e900e7f13ba01a6e8a015420ed18e2a2c57e9d0f3f82b8b80cdd921cf5e10db860a4c8965f25383</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>