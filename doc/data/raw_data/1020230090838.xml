<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:35.5335</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0090838</applicationNumber><claimCount>9</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체의 상황을 예측하는 장치 및 방법</inventionTitle><inventionTitleEng>APPARATUS AND METHOD FOR PREDICTING THE SITUATION OF AN OBJECT</inventionTitleEng><openDate>2025.01.21</openDate><openNumber>10-2025-0010791</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 객체의 상황을 예측하는 장치 및 방법을 개시한다. 객체의 상황을 예측하는 장치는, 전장에서 객체의 상황을 예측하기 위한 영상 정보 데이터를 획득하는 입출력부; 및 상기 획득된 영상 정보 데이터를 분석하고, 상기 분석된 결과에 기초하여 전장에서 객체의 상황을 예측하는 제어부;를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전장에서 객체의 상황을 예측하기 위한 영상 정보 데이터를 획득하는 입출력부; 및상기 획득된 영상 정보 데이터를 분석하고, 상기 분석된 결과에 기초하여 전장에서 객체의 상황을 예측하는 제어부;를 포함하는 객체의 상황을 예측하는 장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제어부는,상기 획득된 영상 정보 데이터를 기초로 객체 인식 알고리즘을 이용하여 객체를 인식하고, 상기 인식된 객체가 사람이면, 미리 설정된 알고리즘을 기초로 상기 객체의 상황을 예측하는 것을 특징으로 하는 객체의 상황을 예측하는 장치.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 미리 설정된 알고리즘은,객체 트래킹(object tracking) 알고리즘 또는 위상 판정 알고리즘 중 어느 하나인 것을 특징으로 하는 객체의 상황을 예측하는 장치. </claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 제어부는,상기 획득된 영상 정보 데이터를 기초로 객체를 인식하고, 상기 인식된 객체가 사람이면, 위상 판정 알고리즘을 기초로 상기 객체의 상황을 예측하여 사람이 쓰러진 것으로 판단하더라도, 머리가 골반보다 높은 경우에는, 사람이 전투와 관련된 사격 자세 중 어느 하나를 취하고 있다고 판단하는 것을 특징으로 하는 객체의 상황을 예측하는 장치.</claim></claimInfo><claimInfo><claim>5. 객체의 상황을 예측하는 장치에서의 객체의 상황을 예측하는 방법에 있어서,전장에서 객체의 상황을 예측하기 위한 영상 정보 데이터를 획득하는 단계;상기 획득된 영상 정보 데이터를 분석하는 단계; 및상기 분석된 결과에 기초하여, 전장에서 객체의 상황을 예측하는 단계;를 포함하는 객체의 상황을 예측하는 방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,상기 객체의 상황을 예측하는 단계는,상기 획득된 영상 정보 데이터를 기초로 객체 인식 알고리즘을 이용하여 객체를 인식하고, 상기 인식된 객체가 사람인지 판단하는 단계; 및미리 설정된 알고리즘을 기초로 상기 객체의 상황을 예측하는 단계;를 포함하는 것을 특징으로 하는 객체의 상황을 예측하는 방법.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,상기 미리 설정된 알고리즘은,객체 트래킹(object tracking) 알고리즘 또는 위상 판정 알고리즘 중 어느 하나인 것을 특징으로 하는 객체의 상황을 예측하는 방법.</claim></claimInfo><claimInfo><claim>8. 제 5 항에 기재된 방법을 수행하는 프로그램이 기록된 컴퓨터 판독 가능한 기록 매체.</claim></claimInfo><claimInfo><claim>9. 객체의 상황을 예측하는 장치에 의해 수행되며, 제 5 항에 기재된 방법을 수행하기 위해 기록 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 과천시 과천대로*나길 ...</address><code>120130166901</code><country>대한민국</country><engName>Laon People Inc.</engName><name>라온피플 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>KIM, Yeonjung</engName><name>김연중</name></inventorInfo><inventorInfo><address>경기도 수원시 장안구...</address><code> </code><country> </country><engName>OH, Jun Taek</engName><name>오준택</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, *층 ***호(삼성동)</address><code>920121001222</code><country>대한민국</country><engName>iSquare Patent &amp; Trademark Firm</engName><name>특허법인 아이스퀘어</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.07.13</receiptDate><receiptNumber>1-1-2023-0770512-56</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.05.27</receiptDate><receiptNumber>4-1-2024-5163740-09</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230090838.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93082149907f8200244c01a56d30caf47db31f61f7e261d24ecca39ed64cf5b4eb1eb972bb2988fe8c151eb5aba42e3ca6fb444aaee80c980a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1131a4f5d4edd279e3df713894227fcb4f4436fd7b6a26f54d522014d3455427400d98db8ddab0cb9424de3d6a20079989136482356bcbca</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>