<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:26.026</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.05.10</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0060334</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>로봇 장치, 그 제어 방법, 및 프로그램이 기록된 기록매체</inventionTitle><inventionTitleEng>Robot apparatus, controlling method thereof, and  recording medium for recording program</inventionTitleEng><openDate>2022.11.17</openDate><openNumber>10-2022-0152866</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.05.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2009.01.01)</ipcDate><ipcNumber>H04W 16/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 19/02</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 로봇 장치에 있어서, 상기 로봇 장치를 이동시키는 이동 어셈블리; 상기 로봇 장치의 주행 중에 주변을 촬영하여 입력 영상 신호를 생성하는 카메라; 통신 인터페이스; 및 상기 로봇 장치의 주행 영역에서 사람을 검출하고, 상기 주행 영역에 사람이 없다고 판단된 경우, 제1 모드에서, 상기 영상 신호로부터 생성된 입력 영상을 클라우드 기계학습 모델에 입력하고, 상기 클라우드 기계학습 모델의 출력에 기초하여 객체를 인식하고, 상기 주행 영역에 사람이 있다고 판단된 경우, 제2 모드에서, 상기 입력 영상을 온-디바이스 기계학습 모델에 입력하고, 상기 온-디바이스 기계학습 모델의 출력에 기초하여 객체를 인식하고, 상기 객체 인식 결과를 이용하여 상기 이동 어셈블리를 통한 상기 로봇 장치의 주행을 제어하는 적어도 하나의 프로세서를 포함하고, 상기 클라우드 기계학습 모델은 상기 통신 인터페이스를 통해 연결된 클라우드 서버에서 동작하고, 상기 온-디바이스 기계학습 모델은, 상기 로봇 장치 상에서 동작하는, 로봇 장치가 제공된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 로봇 장치에 있어서,상기 로봇 장치를 이동시키는 이동 어셈블리;상기 로봇 장치의 주행 중에 주변을 촬영하여 영상 신호를 생성하는 카메라;통신 인터페이스; 및상기 로봇 장치의 주행 영역에서 사람을 검출하고, 상기 주행 영역에 사람이 없다고 판단된 경우, 제1 모드에서, 상기 영상 신호로부터 생성된 입력 영상을 클라우드 기계학습 모델에 입력하고, 상기 클라우드 기계학습 모델의 출력에 기초하여 객체를 인식하고, 상기 주행 영역에 사람이 있다고 판단된 경우, 제2 모드에서, 상기 입력 영상을 온-디바이스 기계학습 모델에 입력하고, 상기 온-디바이스 기계학습 모델의 출력에 기초하여 객체를 인식하고, 상기 객체를 인식한 결과를 이용하여 상기 이동 어셈블리를 통한 상기 로봇 장치의 주행을 제어하는 적어도 하나의 프로세서를 포함하고,상기 클라우드 기계학습 모델은 상기 통신 인터페이스를 통해 연결된 클라우드 서버에서 동작하고, 상기 온-디바이스 기계학습 모델은, 상기 로봇 장치 상에서 동작하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 로봇 장치는, 출력 인터페이스를 더 포함하고,상기 적어도 하나의 프로세서는, 상기 제1 모드로 동작 중에, 상기 주행 영역에 사람이 있다고 판단된 경우, 상기 출력 인터페이스를 통해 상기 제2 모드로 동작 모드를 변경할 것을 추천하는 알림을 제공하고,상기 제2 모드로 동작 중에, 상기 주행 영역에 사람이 없다고 판단된 경우, 상기 출력 인터페이스를 통해 상기 제1 모드로 동작 모드를 변경할 것을 추천하는 알림을 제공하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 적어도 하나의 프로세서는, 상기 클라우드 기계학습 모델 또는 상기 온-디바이스 기계학습 모델의 객체 인식 결과에 기초하여, 상기 주행 영역에 사람이 있는지 여부를 판단하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 통신 인터페이스는, 상기 주행 영역에서 사람을 검출하는 제1 센서를 포함하는 외부 장치와 통신하고,상기 적어도 하나의 프로세서는, 상기 제1 센서의 센서 검출 값에 기초하여 상기 주행 영역에 사람이 있는지 여부를 판단하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 통신 인터페이스는, 상기 주행 영역을 포함하는 소정의 영역을 관리하는 영역 관리 시스템과 통신하고,상기 적어도 하나의 프로세서는, 상기 영역 관리 시스템이 외출 모드로 설정되었다는 외출 정보를 수신한 것에 기초하여, 상기 주행 영역에 사람이 없다고 판단하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 통신 인터페이스는, 사용자 계정에 등록된 적어도 하나의 전자 장치를 제어하는 장치 관리 서버와 통신하고, 상기 적어도 하나의 프로세서는, 상기 장치 관리 서버의 상기 사용자 계정에 등록된 다른 전자 장치로부터 수신된 사용자 위치 정보 또는 외출 모드 설정 정보에 기초하여, 상기 주행 영역에 사람이 있는지 여부를 판단하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 적어도 하나의 프로세서는, 상기 주행 영역 전체를 스캔하고, 상기 주행 영역 전체의 스캔 결과에 기초하여 상기 주행 영역에 사람이 있는지 여부를 판단하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 주행 영역은 상기 주행 영역을 분할하여 정의되는 적어도 하나의 서브 주행 영역을 포함하고, 상기 적어도 하나의 프로세서는, 상기 적어도 하나의 서브 주행 영역 중에서 사람이 없다고 판단된 서브 주행 영역에 대해서는 상기 제1 모드로 동작하여 객체를 인식하고, 상기 적어도 하나의 서브 주행 영역 중에서 사람이 있다고 판단된 서브 주행 영역에 대해서는 상기 제 2 모드로 동작하면서 객체를 인식하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 온-디바이스 기계학습 모델은, 상기 제2 모드에서 노멀 모드로 동작하고, 상기 제1 모드에서 상기 노멀 모드에 비해 처리량이 적은 상기 라이트 모드로 동작하고,상기 적어도 하나의 프로세서는, 상기 제1 모드에서 동작하는 동안, 상기 온-디바이스 기계학습 모델을 라이트 모드로 설정하고, 상기 입력 영상을 상기 클라우드 기계학습 모델로 입력하기 전에, 상기 입력 영상을 상기 라이트 모드로 설정된 온-디바이스 기계학습 모델에 입력하고, 상기 라이트 모드로 설정된 온-디바이스 기계학습 모델의 출력에 기초하여 사람이 검출되지 않았다고 판단되면, 상기 입력 영상을 상기 클라우드 기계학습 모델로 입력하고, 상기 라이트 모드로 설정된 온-디바이스 기계학습 모델의 출력에 기초하여 사람이 검출되었다고 판단되면, 상기 입력 영상을 상기 클라우드 기계학습 모델로 입력하는 동작을 중단하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 적어도 하나의 프로세서는, 상기 제1 모드로 동작 중에, 상기 주행 영역에 사람이 있다고 판단된 경우, 상기 제2 모드로 동작 모드를 변경할 것을 추천하는 알림을 제공하고, 상기 제2 모드로 동작 중에, 상기 주행 영역에 사람이 없다고 판단된 경우, 상기 제1 모드로 동작 모드를 변경할 것을 추천하는 알림을 제공하고,상기 알림은 상기 통신 인터페이스를 통해 연결된 장치 관리 서버의 사용자 계정에 등록된 적어도 하나의 장치를 통해 출력되는, 로봇 장치.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 적어도 하나의 프로세서는, 상기 주행 영역 중 프라이버시 영역이 설정된 경우, 상기 프라이버시 영역에서는, 사람의 검출 여부에 관계없이, 상기 제2 모드로 동작하는, 로봇 장치.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 로봇 장치는,진공 흡입 또는 걸레 수분 공급 중 적어도 하나의 동작을 수행하는 청소 어셈블리를 더 포함하고,상기 적어도 하나의 프로세서는, 상기 제1 모드 및 상기 제2 모드에서, 상기 주행 영역을 주행하면서, 상기 청소 어셈블리를 동작시키는 로봇 장치.</claim></claimInfo><claimInfo><claim>13. 로봇 장치의 주행 중에 주변을 촬영하여 입력 영상을 획득하는 단계;상기 로봇 장치의 주행 영역에서 사람을 검출하는 단계;상기 주행 영역에 사람이 없다고 판단된 경우, 제1 모드에서, 상기 입력 영상을 클라우드 기계학습 모델에 입력하고, 상기 클라우드 기계학습 모델의 출력에 기초하여 객체를 인식하는 단계;상기 주행 영역에 사람이 있다고 판단된 경우, 제2 모드에서, 상기 입력 영상을 온-디바이스 기계학습 모델에 입력하고, 상기 온-디바이스 기계학습 모델의 출력에 기초하여 객체를 인식하는 단계; 및상기 객체를 인식한 결과를 이용하여 상기 로봇 장치의 주행을 제어하는 단계를 포함하고,상기 클라우드 기계학습 모델은 상기 로봇 장치와 통신하는 클라우드 서버에서 동작하고, 상기 온-디바이스 기계학습 모델은, 상기 로봇 장치 상에서 동작하는, 로봇 장치 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 제1 모드로 동작 중에, 상기 주행 영역에 사람이 있다고 판단된 경우, 상기 제2 모드로 동작 모드를 변경할 것을 추천하는 알림을 제공하는 단계; 및상기 제2 모드로 동작 중에, 상기 주행 영역에 사람이 없다고 판단된 경우, 상기 제1 모드로 동작 모드를 변경할 것을 추천하는 알림을 제공하는 단계를 더 포함하는 로봇 장치 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 사람을 검출하는 단계는, 상기 클라우드 기계학습 모델 또는 상기 온-디바이스 기계학습 모델의 객체 인식 결과에 기초하여, 사람을 검출하는 단계를 포함하는, 로봇 장치 제어 방법.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 사람을 검출하는 단계는, 상기 주행 영역에서 사람을 검출하는 제1 센서를 포함하는 외부 장치로부터 수신된 상기 제1 센서의 센서 검출 값에 기초하여 상기 주행 영역에서 사람을 검출하는 단계를 포함하는, 로봇 장치 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서,상기 주행 영역을 포함하는 소정의 영역을 관리하는 영역 관리 시스템이 외출 모드로 설정되었다는 외출 정보를 수신한 것에 기초하여, 상기 주행 영역에 사람이 없다고 판단하는 단계를 더 포함하는, 로봇 장치 제어 방법.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서,사용자 계정에 등록된 적어도 하나의 전자 장치를 제어하는 장치 관리 서버와 통신하는 단계; 및상기 장치 관리 서버의 상기 사용자 계정에 등록된 다른 전자 장치로부터 수신된 사용자 위치 정보 또는 외출 모드 설정 정보에 기초하여, 상기 주행 영역에 사람이 있는지 여부를 판단하는 단계를 더 포함하는, 로봇 장치 제어 방법.</claim></claimInfo><claimInfo><claim>19. 제13항에 있어서, 상기 주행 영역 전체를 스캔하는 단계; 및상기 주행 영역 전체의 스캔 결과에 기초하여 상기 주행 영역에 사람이 있는지 여부를 판단하는 단계를 더 포함하는, 로봇 장치 제어 방법.</claim></claimInfo><claimInfo><claim>20. 제13항 내지 제19항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 컴퓨터 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Si Hyun</engName><name>박시현</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.05.10</receiptDate><receiptNumber>1-1-2021-0540258-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.05.09</receiptDate><receiptNumber>1-1-2024-0505281-90</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.01</receiptDate><receiptNumber>9-5-2025-0957888-08</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210060334.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930b4b8b70f55dbd80547978abb8d5b5425cca9b91d8c1cd2c1c406e3858a3feb71534c05f5a253a10761ccd5190302cc0901fe814434ceba6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf39f9bb751af12ff42dfea67aab8db312d84d8f3532aef329d317f49e75df5c9b47a31eed3f2a4ad53b12e80b61058558a4f51f5eef34304e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>