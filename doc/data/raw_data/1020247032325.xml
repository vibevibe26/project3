<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:23.123</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.03.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7032325</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>로봇의 자연어 제어</inventionTitle><inventionTitleEng>NATURAL LANGUAGE CONTROL OF A ROBOT</inventionTitleEng><openDate>2024.11.06</openDate><openNumber>10-2024-0159835</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.09.26</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/30</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 구현예는 대규모 언어 모델을 사용하여, LLM 출력을 생성하기 위해 자유형 자연어(NL) 명령어를 프로세싱한다. 이러한 구현예는 LLM 출력과 로봇 스킬의 NL 스킬 설명에 기초하여 LLM 출력의 확률 분포에서 스킬 설명의 확률을 반영하는 작업-그라운딩 측정을 생성한다. 이러한 구현예는 로봇 스킬과 현재 환경 상태 데이터에 기초하여, 현재 환경 상태 데이터에 기초하여 성공할 로봇 스킬의 확률을 반영하는 세계-그라운딩 측정을 추가로 생성한다. 이러한 구현예는 작업-그라운딩 측정과 세계-그라운딩 측정에 기초하여, 로봇 스킬을 구현할지 여부를 추가로 결정한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.10.05</internationOpenDate><internationOpenNumber>WO2023192497</internationOpenNumber><internationalApplicationDate>2023.03.30</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/016932</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프로세서(processor)에 의해 구현되는 방법에 있어서, 상기 방법은:명령어를 식별하는 단계-상기 명령어는 하나 이상의 사용자 인터페이스 입력 디바이스(user interface input device)를 통해 사용자에 의해 제공된 사용자 인터페이스 입력에 기초하여 생성된 자유형 자연어 명령어(free-form natural language instruction)임-; 언어 모델(LM, language model)을 사용하여 상기 명령어에 기초하여 생성된 언어 모델(LM) 프롬프트를 프로세싱하여 상기 LM 프롬프트에 따라 후보 단어 조성에 대한 확률 분포를 모델링하는 LM 출력을 생성하는 단계;로봇에 의해 수행가능한, 로봇 스킬(robot skill)과 상기 로봇 스킬의 자연어 설명인 스킬 설명을 식별하는 단계;상기 LM 출력 및 상기 스킬 설명에 기초하여, 상기 LM 출력의 상기 확률 분포에서 상기 스킬 설명의 확률을 반영하는, 상기 로봇 스킬에 대한, 작업-그라운딩 측정(task-grounding measure)을 생성하는 단계;상기 로봇 스킬과 현재 환경 상태 데이터에 기초하여, 상기 현재 환경 상태 데이터에 기초하여 성공할 상기 로봇 스킬의 확률을 반영하는, 상기 로봇 스킬에 대한, 세계-그라운딩 측정(world-grounding measure)을 생성하는 단계-, 상기 현재 환경 상태 데이터는 상기 로봇의 현재 환경에서 상기 로봇의 하나 이상의 센서 컴포넌트에 의해 캡쳐된 센서 데이터를 포함함-;상기 작업-그라운딩 측정과 상기 세계-그라운딩 측정 둘 모두에 기초하여, 상기 로봇에 의해 각각 수행가능한 추가 로봇 스킬 대신 상기 로봇 스킬을 구현하도록 결정하는 단계; 및상기 로봇 스킬을 구현하도록 결정한 것에 응답하여: 상기 로봇으로 하여금 상기 현재 환경에서 상기 로봇 스킬을 구현하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 추가 로봇 스킬 중 추가 로봇 스킬과 상기 추가 로봇 스킬의 자연어 설명인 추가 스킬 설명을 식별하는 단계;상기 LM 출력과 상기 추가 스킬 설명에 기초하여, 상기 확률 분포에서 상기 추가 스킬 설명의 추가 확률을 반영하는, 상기 추가 로봇 스킬에 대한, 추가-작업 그라운딩 측정을 생성하는 단계;상기 추가 로봇 스킬과 상기 현재 환경 상태 데이터에 기초하여, 상기 현재 환경 상태 데이터에 기초하여 성공할 상기 추가 로봇 스킬의 추가 확률을 반영하는, 상기 추가 로봇 스킬에 대한, 추가 세계-그라운딩 측정을 생성하는 단계를 더 포함하고,상기 작업-그라운딩 측정과 상기 세계-그라운딩 측정에 기초하여, 상기 로봇에 의해 각각 수행가능한 추가 로봇 스킬 대신 상기 로봇 스킬을 구현하기로 결정하는 단계는: 상기 작업-그라운딩 측정과 상기 세계-그라운딩 측정 둘 모두에 기초하는, 상기 로봇 스킬에 대한, 전체 측정을 생성하는 단계; 상기 추가 작업-그라운딩 측정과 추가 상기 세계-그라운딩 측정 둘 모두에 기초하는, 상기 로봇 스킬에 대한, 추가 전체 측정을 생성하는 단계; 및 상기 전체 측정을 상기 추가 전체 측정의 비교에 기초하여 상기 추가 로봇 스킬 대신 상기 로봇 스킬을 구현하기로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 로봇 스킬을 구현하기로 결정하는 것에 응답하여: 상기 LM을 사용하여 상기 명령어와 상기 로봇 스킬의 상기 스킬 설명을 기초로 하는 추가 LM 프롬프트를 프로세싱하여, 상기 추가 LM 프롬프트에 의존하는 상기 후보 단어 조성에 대한 추가 확률 분포를 모델링하는 추가 LM 출력을 생성하는 단계; 상기 추가 로봇 스킬 중 추가 로봇 스킬과 상기 추가 로봇 스킬의 자연어 설명인 추가 스킬 설명을 식별하는 단계;  상기 추가 LM 출력 및 상기 추가 스킬 설명에 기초하여, 상기 추가 확률 분포에서 상기 추가 스킬 설명의 확률을 반영하는, 상기 추가 로봇 스킬에 대한, 상기 추가 작업-그라운딩 측정을 생성하는 단계; 상기 추가 로봇 스킬 및 업데이트된 현재 환경 상태 데이터에 기초하여, 상기 업데이트된 현재 환경 상태 데이터에 기초하여 성공할 상기 추가 로봇 스킬의 확률을 반영하는, 상기 추가 로봇 스킬에 대한, 추가 세계-그라운딩 측정을 생성하는 단계-,  상기 업데이트된 현재 환경 상태 데이터는 상기 로봇 스킬의 구현 후 상기 현재 환경에서 상기 하나 이상의 센서 컴포넌트에 의해 캡쳐된 업데이트된 센서 데이터를 포함함-; 상기 추가 작업-그라운딩 측정과 추가 상기 세계-그라운딩 측정에 기초하여, 상기 로봇 스킬 또는 상기 로봇에 의해 각각 수행가능한 상기 추가 로봇 스킬의 다른 것 대신 상기 추가 로봇 스킬을 구현하기로 결정하는 단계; 및 상기 추가 로봇 스킬을 구현하기로 결정한 것에 응답하여:  상기 로봇으로 하여금 상기 현재 환경에서 상기 추가 로봇 스킬을 구현하게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,로봇 스킬을 구현하기로 결정하는 것에 응답하여: 상기 LM을 사용하여 상기 명령어와 상기 로봇 스킬의 상기 스킬 설명을 기초로 하는 추가 LM 프롬프트를 프로세싱하여, 상기 추가 LM 프롬프트에 의존하는 상기 후보 단어 조성에 대한 추가 확률 분포를 모델링하는 추가 LM 출력을 생성하는 단계; 상기 추가 로봇 스킬의 종료 스킬과 상기 명령어의 수행이 완료되었다는 자연어 설명인 종료 설명을 식별하는 단계; 상기 추가 LM 출력 및 상기 종료 설명을 기초로, 상기 추가 확률 분포에서 종료 스킬 설명의 확률을 반영하는, 상기 종료 스킬에 대한, 종료 작업-그라운딩 측정을 생성하는 단계; 상기 추가 작업-그라운딩 측정을 기초로, 상기 로봇 스킬 또는 상기 로봇에 의해 수행될 수 있는 다른 추가 로봇 스킬 대신 종료 스킬을 구현하기로 결정하는 단계; 및  상기 종료 스킬을 구현하기로 결정하는 것에 응답하여:  상기 로봇으로 하여금 상기 명령어를 더욱 발전시키기 위한 임의의 제어 커맨드의 추가 구현을 중단하게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 로봇 스킬과 상기 현재 환경 상태 데이터에 기초하여, 상기 세계-그라운딩 측정을 생성하는 단계는:상기 세계-그라운딩 측정을 포함하는 가치 함수 출력을 생성하기 위해, 트레이닝된 가치 함수를 사용하여, 상기 로봇 스킬과 상기 현재 환경 상태 데이터를 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 현재 환경 상태 데이터는 상기 센서 데이터의 비전 데이터(vision data)를 포함하고, 상기비전 데이터는 상기 로봇의 상기 하나 이상의 센서 컴포넌트의 하나 이상의 비전 컴포넌트에 의해 캡쳐되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 비전 데이터는 다중-채널(multi-channel) 이미지를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제5항에 있어서, 상기 트레이닝된 가치 함수는 언어-조건 가치 함수(language-conditioned value function)이고 상기 트레이닝된 가치 함수를 사용하여 상기 로봇 스킬을 프로세싱하는 단계는 상기 로봇 스킬의 상기 스킬 설명을 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제5항에 있어서, 상기 트레이닝된 가치 함수는 어포던스 함수(affordance function)에 대응하도록 트레이닝되고, 상기 가치 함수 출력은 상기 현재 환경 상태 데이터에 기초하여 상기 로봇 스킬이 가능한지 여부를 지정하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제5항에 있어서, 상기 가치 함수는 강화 러닝(reinforcement learning)을 사용하여 트레이닝된 머신 러닝 모델인, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 작업-그라운딩 측정과 상기 세계-그라운딩 측정에 기초하여, 상기 추가 로봇 스킬 대신 상기 로봇 스킬을 구현하기로 결정하는 단계는:상기 작업-그라운딩 측정과 상기 세계-그라운딩 측정의 함수로서 전체 측정을 생성하는 단계;상기 전체 측정을 상기 추가 로봇 스킬 중 대응하는 하나에 대한 각각인 대응하는 추가 측정과 비교하는 단계; 및상기 비교에 기초하여 상기 로봇 스킬을 구현하기로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 전체 측정은 상기 작업-그라운딩 측정과 상기 세계-그라운딩 측정의 가중 또는 비가중 조합인, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 작업-그라운딩 측정은 작업-그라운딩 확률이고, 상기 세계-그라운딩 측정은 세계-그라운딩 확률이고, 상기 전체 측정을 생성하는 단계는 상기 작업-그라운딩 확률에 상기 세계-그라운딩 확률을 곱한 것에 기초하여 곱을 생성하는 단계, 및 상기 곱을 상기 전체 측정으로서 사용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항의 어느 한 항에 있어서, 상기 로봇으로 하여금 상기 현재 환경에서 상기 로봇 스킬을 구현하게 하는 단계는:상기 로봇 스킬의 상기 스킬 설명에 따라 조건화된, 언어-조건 로봇 제어 정책의 실행을 야기하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 언어-조건 로봇 제어 정책은 머신 러닝 모델을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 언어-조건 로봇 제어 정책은 강화 러닝 및/또는 모방 러닝을 사용하여 트레이닝되는, 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항의 어느 한 항에 있어서, 상기 LM 프롬프트는 상기 사용자 인터페이스 입력을 통해 상기 사용자에 의해 제공된 자연어 입력을 엄격히 확인하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 LM 프롬프트는 상기 사용자 인터페이스 입력을 통해 상기 사용자에 의해 제공된 자연어 입력을 엄격히 확인하지 않고:상기 자연어 입력이 상기 질문의 형태가 아님을 결정하는 단계; 및상기 자연어 입력이 상기 질문의 형태가 아니라고 결정하는 것에 응답하여, 상기 자연어 입력을 상기 질문의 형태로 수정함으로써 상기 LM 프롬프트를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제1항 내지 제16항 중 어느 한 항의 방법에 있어서, 상기 LM 프롬프트는 상기 사용자 인터페이스 입력을 통해 상기 사용자에 의해 제공된 자연어 입력을 엄격히 확인하지 않고:다음 단계의 생성을 요청하는 콘텐츠를 접미사로, 포함하도록 상기 LM 프롬프트를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 LM 프롬프트는 상기 사용자 인터페이스 입력을 통해 상기 사용자에 의해 제공된 자연어 입력을 엄격히 확인하지 않고:상기 로봇의 현재 환경을 설명하는 하나 이상의 장면 설명자를 포함하기 위해 상기 LM 프롬프트를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제1항 내지 제20항 중 어느 한 항에 있어서, 상기 LM은 대규모 언어 모델(LLM)인, 방법.</claim></claimInfo><claimInfo><claim>22. 하나 이상의 프로세서에 의해 구현되는 방법에 있어서, 상기 방법은:명령어를 식별하는 단계-상기 명령어는 하나 이상의 사용자 인터페이스 입력 디바이스를 통해 사용자에 의해 제공된 사용자 인터페이스 입력에 기초하여 생성된 자유형 자연어 명령어임-;상기 명령어에 기초하여 대규모 언어 모델(LLM) 프롬프트를 생성하는 단계;상기 LLM 프롬프트에 의존하는, 후보 단어 조성에 대해, 확률 분포를 모델링하는 LLM 출력을 생성하기 위해, LLM을 사용하여, LLM 프롬프트를 프로세싱하는 단계;로봇에 의해 각각 수행가능한 복수의 로봇 스킬의 각각에 대해: 상기 LLM 출력 및 상기 로봇 스킬에 대한 스킬 설명에 기초하여, 상기 확률 분포에서 상기 스킬 설명의 확률을 반영하는, 상기 로봇 스킬에 대한, 작업-그라운딩 측정을 생성하는 단계; 상기 로봇 스킬 및 현재 환경 상태 데이터에 기초하여, 상기 현재 환경 상태 데이터에 기초하여 성공할 상기 로봇 스킬의 확률을 반영하는, 상기 로봇 스킬에 대한, 세계-그라운딩 측정을 생성하는 단계-,  상기 현재 환경 상태 데이터는 상기 로봇의 현재 환경에서 상기 로봇의 하나 이상의 센서 컴포넌트에 의해 캡쳐된 센서 데이터를 포함함-; 및 상기 작업-그라운딩 측정 및 상기 세계-그라운딩 측정에 기초하여, 상기 로봇 스킬에 대한, 전체 측정을 생성하는 단계;상기 로봇 스킬에 대한 전체 측정에 기초하여 상기 로봇 스킬 중 주어진 스킬을 선택하는 단계; 및상기 주어진 로봇 스킬을 선택하는 것에 응답하여: 상기 로봇으로 하여금 상기 현재 환경에서 상기 주어진 로봇 스킬을 구현하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 로봇에 있어서,하나 이상의 액추에이터(actuator);엔드 이펙터(end effector);명령어를 저장하는 메모리;제1항 내지 제22항 중 어느 한 항에의 상기 방법을 수행하기 위해 상기 명령어를 실행하도록 동작가능한, 하나 이상의 프로세서를 포함하는, 로봇.</claim></claimInfo><claimInfo><claim>24. 시스템에 있어서, 명령어를 저장하는 메모리 및 제1항 내지 제22항 중 어느 한 항의 상기 방법을 수행하기 위해 상기 명령어를 실행하도록 동작가능한 하나 이상의 프로세스를 포함하는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>HAUSMAN, Karol</engName><name>하우스만 카롤</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>ICHTER, Brian</engName><name>이처 브라이언</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>LEVINE, Sergey</engName><name>레바인 세르게이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>TOSHEV, Alexander</engName><name>토스헤브 알렉산더</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>XIA, Fei</engName><name>시아 페이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>PARADA, Carolina</engName><name>파라다 캐롤리나</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.30</priorityApplicationDate><priorityApplicationNumber>63/325,556</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.31</priorityApplicationDate><priorityApplicationNumber>63/326,080</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.09.26</receiptDate><receiptNumber>1-1-2024-1054304-29</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.10.07</receiptDate><receiptNumber>1-5-2024-0160463-48</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247032325.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930c2dd0f7e6f085518f7599b2203a2c2cccab3fe4e2fbf87a91a73ab27e19895a58dd1d5b7c20574e453964e6dc785dace5bc11aef6aed83a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf788142de74a20a71fdb80f15745a9220026f89746bfb7d909cdf7f540aaa544b60886daa242592475d850e7c2e4078a2deb97d91f5a306f3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>