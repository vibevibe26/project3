<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:29:57.2957</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7004458</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>라디오 스테이션(들)을 통해 생성된 오디오 데이터의 스트림(들)으로부터 오디오 기반 기계 학습 모델(들)의 일시적 학습 및/또는 연합 학습</inventionTitle><inventionTitleEng>EPHEMERAL LEARNING AND/OR FEDERATED LEARNING OF AUDIO-BASED MACHINE LEARNING MODEL(S) FROM STREAM(S) OF AUDIO DATA GENERATED VIA RADIO STATION(S)</inventionTitleEng><openDate>2025.03.17</openDate><openNumber>10-2025-0037507</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.02.11</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 19/018</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에 개시된 구현예는 전 세계의 라디오 스테이션(들)을 통해 생성된 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여 오디오 기반 기계 학습(ML) 모델을 업데이트하기 위해 일시적 학습 기술 및/또는 연합 학습 기술을 활용하는 것에 관한 것이다. 이를 통해 오디오 기반 ML 모델(들)은 오디오 데이터가 없거나/최소한인 테일 언어를 포함하는 전 세계의 표현을 학습하고 및/또는 언어를 이해할 수 있다. 다양한 구현예에서, 하나 이상의 중복제거 기술을 사용하여 오디오 기반 ML 모델(들)을 업데이트하는 데 동일한 오디오 데이터의 스트림이 과도하게 사용되지 않도록 할 수 있다. 다양한 구현예에서, 주어진 클라이언트 디바이스는 원격 시스템과의 연결 상태 등에 기초하여 일시적 학습 기술 또는 연합 학습 기술을 활용할지 여부를 결정할 수 있다. 일반적으로, 오디오 데이터의 스트림은 클라이언트 디바이스에서 수신되지만, 일시적 학습 기술은 클라이언트 디바이스 및/또는 원격 시스템에서 구현될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.02.29</internationOpenDate><internationOpenNumber>WO2024043921</internationOpenNumber><internationalApplicationDate>2022.12.06</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/052013</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 클라이언트 디바이스의 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은:주어진 라디오 스테이션으로부터, 주어진 언어로 된 음성 발화의 스트림을 캡처하는 오디오 데이터의 스트림을 수신하는 단계;상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 오디오 데이터의 스트림에 대한 오디오 지문을 생성하는 단계;상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 오디오 지문의 데이터베이스와 비교하는 것에 기초하여, 상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 글로벌 기계 학습(ML) 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었는지 여부를 결정하는 단계; 및상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되지 않았다고 결정하는 것에 응답하여: 상기 클라이언트 디바이스의 온디바이스 스토리지에 저장되어 있고 상기 글로벌 ML 모델의 온디바이스 대응물인 온디바이스 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하는 단계; 비지도 또는 자기지도 학습 기술을 사용하고, 상기 온디바이스 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하는 단계; 및 상기 그래디언트를 상기 원격 시스템으로 송신하여 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 데 사용되도록 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었다고 결정하는 것에 응답하여:상기 오디오 데이터의 스트림을 삭제하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 원격 시스템으로부터, 상기 오디오 지문의 데이터베이스를 수신하는 단계; 및상기 클라이언트 디바이스의 온디바이스 스토리지에, 상기 오디오 지문의 데이터베이스를 저장하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 원격 시스템은 상기 클라이언트 디바이스와 복수의 추가 클라이언트 디바이스로부터 수신되고 상기 주어진 언어를 포함한 복수의 다른 언어로 된 음성 발화의 대응하는 스트림을 캡처하는 복수의 대응하는 오디오 데이터의 스트림과 복수의 다른 라디오 스테이션으로부터 수신된 복수의 대응하는 오디오 데이터의 스트림을 기초로 상기 오디오 지문의 데이터베이스를 사전에 생성하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 또는 제2항 있어서, 상기 오디오 데이터의 스트림을 프로세싱한 것에 기초하여 상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 생성하는 단계는:로컬 감도 해시를 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하여 오디오 지문으로서 오디오 해시를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 오디오 데이터의 스트림이 상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 상기 오디오 지문의 데이터베이스와 비교하는 것에 기초하여 상기 주어진 언어에 대한 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었는지 여부를 결정하는 단계는:상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여 생성된 상기 오디오 해시를 복수의 이전에 생성된 오디오 해시와 비교하는 단계-상기 복수의 이전에 생성된 오디오 해시는 이전에 오디오 데이터의 대응하는 스트림을 프로세싱하는 것에 기초하여 생성되었으며, 상기 복수의 이전에 생성된 오디오 해시는 상기 오디오 지문의 데이터베이스에 저장됨-; 및상기 비교를 기초로, 상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었는지 여부를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 또는 제2항에 있어서, 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여 상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 생성하는 단계는:인코더-디코더 ML 모델의 인코더 부분을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하여 상기 오디오 지문으로서 임베딩을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 오디오 데이터의 스트림이 상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 상기 오디오 지문의 데이터베이스와 비교하는 것에 기초하여 상기 주어진 언어에 대한 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었는지 여부를 결정하는 단계는:상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여 생성된 상기 임베딩을 상기 복수의 이전에 생성된 임베딩과 비교하는 단계-상기 복수의 이전에 생성된 임베딩은 이전에 오디오 데이터의 대응하는 스트림을 프로세싱하는 것에 기초하여 생성되었으며, 상기 복수의 이전에 생성된 임베딩은 상기 오디오 지문의 데이터베이스에 저장됨-; 및상기 비교를 기초로, 상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었는지 여부를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 클라이언트 디바이스의 상기 온디바이스 스토리지에 저장된 온디바이스 언어 식별 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하여 상기 주어진 언어를 식별하는 단계; 및상기 주어진 언어가 복수의 타겟 언어 중 하나인지 여부를 결정하는 단계를 더 포함하고, 상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 생성하는 단계는 상기 주어진 언어가 상기 복수의 타겟 언어 중 하나임을 결정하는 것에 대한 응답인, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 주어진 언어가 상기 복수의 타겟 언어 중 하나가 아님을 결정하는 것에 응답하여:상기 오디오 데이터의 스트림의 추가 프로세싱을 중단하는 단계; 및상기 오디오 데이터의 스트림을 삭제하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서, 상기 글로벌 ML 모델과 연관된 개발자가 상기 복수의 타겟 언어의 표시를 제공하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 원격 시스템이 상기 그래디언트를 활용하여 상기 글로벌 ML 모델의 하나 이상의 글로벌 가중치를 업데이트하여 업데이트된 글로벌 ML 모델을 생성하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 원격 시스템으로부터, 상기 업데이트된 글로벌 ML 모델의 상기 하나 이상의 글로벌 가중치를 수신하는 단계, 또는상기 원격 시스템으로부터, 상기 업데이트된 글로벌 ML 모델을 수신하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 클라이언트 디바이스의 상기 온디바이스 스토리지에서, 상기 온디바이스 ML 모델의 하나 이상의 온디바이스 가중치를 상기 업데이트된 글로벌 ML 모델의 상기 하나 이상의 글로벌 가중치로 대체하는 단계, 또는상기 클라이언트 디바이스의 상기 온디바이스 스토리지에서, 상기 온디바이스 ML 모델을 상기 업데이트된 글로벌 ML 모델로 대체하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 비지도 또는 자기지도 학습 기술은 교사-학생 기술 또는 마스킹 기술 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 글로벌 ML 모델은 상기 주어진 언어와 관련하여 상기 오디오 데이터의 스트림으로부터 기능을 추출하도록 업데이트된 글로벌 피처 추출기 모델인, 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 글로벌 ML 모델은 상기 주어진 언어와 관련하여 상기 오디오 데이터의 스트림으로부터 텍스트를 인식하도록 업데이트된 다국어 자동 음성 인식(ASR) 모델인, 방법.</claim></claimInfo><claimInfo><claim>18. 클라이언트 디바이스의 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은:주어진 라디오 스테이션으로부터, 주어진 언어로 된 음성 발화의 스트림을 캡처하는 오디오 데이터의 스트림을 수신하는 단계;상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 오디오 데이터의 스트림에 대한 오디오 지문을 생성하는 단계;상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 오디오 지문의 데이터베이스와 비교하는 것에 기초하여, 상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 글로벌 기계 학습(ML) 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었는지 여부를 결정하는 단계; 및상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되지 않았다고 결정하는 것에 응답하여: 상기 오디오 데이터의 스트림을 상기 원격 시스템에 송신하는 단계를 포함하고, 상기 오디오 데이터의 스트림을 상기 원격 시스템에 송신하는 단계는 상기 원격 시스템으로 하여금:  상기 글로벌 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하게 하고;  비지도 또는 자기지도 학습 기술을 사용하고, 상기 글로벌 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여 상기 그래디언트를 생성하게 하고; 및  상기 그래디언트를 기초로, 상기 글로벌 ML 모델을 업데이트하게 하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 원격 시스템에 상기 오디오 데이터의 스트림을 송신하는 단계는 상기 원격 시스템으로 하여금:상기 그래디언트를 생성한 후:상기 오디오 데이터의 스트림을 삭제하게 하는, 방법.</claim></claimInfo><claimInfo><claim>20. 원격 시스템의 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은:주어진 클라이언트 디바이스로부터, 주어진 언어로 된 음성 발화의 스트림을 캡처하는 오디오 데이터의 스트림을 수신하는 단계-상기 오디오 데이터의 스트림은 주어진 라디오 스테이션으로부터 상기 주어진 클라이언트 디바이스에서 초기에 수신됨-;상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 오디오 데이터의 스트림에 대한 오디오 지문을 생성하는 단계;상기 오디오 데이터의 스트림에 대한 상기 오디오 지문을 오디오 지문의 데이터베이스와 비교하는 것에 기초하여, 상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 글로벌 기계 학습(ML) 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되었는지 여부를 결정하는 단계; 및상기 오디오 데이터의 스트림이 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하는 데 이전에 활용되지 않았다고 결정하는 것에 응답하여: 상기 글로벌 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하는 단계; 비지도 또는 자기지도 학습 기술을 사용하고, 상기 글로벌 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여 상기 그래디언트를 생성하는 단계; 및 상기 그래디언트를 기초로, 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 클라이언트 디바이스의 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은:주어진 라디오 스테이션으로부터, 주어진 언어로 된 음성 발화의 스트림을 캡처하는 오디오 데이터의 스트림을 수신하는 단계;상기 클라이언트 디바이스와 상기 원격 시스템 사이의 연결 상태를 기초로, 상기 주어진 언어에 대한 글로벌 기계 학습(ML) 모델을 업데이트하기 위한 그래디언트를 생성하기 위해 연합 학습 또는 일시적 학습을 구현할지 여부를 결정하는 단계;상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용하기 위한 상기 그래디언트를 생성하기 위해 상기 연합 학습을 구현하기로 결정하는 것에 응답하여: 상기 클라이언트 디바이스의 온디바이스 스토리지에 저장되어 있고 상기 글로벌 ML 모델의 온디바이스 대응물인 온디바이스 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하는 단계; 비지도 또는 자기지도 학습 기술을 사용하여, 상기 온디바이스 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하는 단계; 및 상기 그래디언트를 상기 원격 시스템에 비동기식으로 송신하여 상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용되도록 하는 단계; 및 상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용하기 위한 상기 그래디언트를 생성하기 위해 상기 일시적 학습을 구현하기로 결정하는 것에 응답하여: 상기 온디바이스 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하는 단계; 상기 비지도 또는 자기 지도 학습 기술을 사용하여, 상기 온디바이스 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하는 단계; 및 상기 그래디언트를 상기 원격 시스템에 동기식으로 송신하여 상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용되도록 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,상기 클라이언트 디바이스와 상기 원격 시스템 사이의 연결 상태가 상기 클라이언트 디바이스가 상기 원격 시스템에 연결할 수 없음을 나타내는 것을 기초로 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 데 활용하기 위한 상기 그래디언트를 생성하기 위해 연합 학습을 구현하기로 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 그래디언트를 상기 원격 시스템에 비동기식으로 송신하여 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 데 활용되도록 하는 단계는:상기 그래디언트를 생성한 후: 상기 클라이언트 디바이스와 상기 원격 시스템 사이에 연결이 설정되었음을 결정하는 단계; 및 상기 클라이언트 디바이스와 상기 원격 시스템 사이에 상기 연결이 설정되었음을 결정하는 것에 응답하여:  상기 그래디언트를 상기 원격 시스템에 송신하여 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 데 활용되도록 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 제21항 내지 제23항 중 어느 한 항에 있어서, 상기 클라이언트 디바이스와 상기 원격 시스템 사이의 상기 연결 상태가 상기 클라이언트 디바이스가 상기 원격 시스템에 연결되었음을 나타내는 것을 기초로 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 데 활용하기 위한 상기 그래디언트를 생성하기 위해 일시적 학습을 구현하기로 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 그래디언트를 상기 원격 시스템에 동기식으로 송신하여 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 데 활용되도록 하는 단계는: 상기 그래디언트를 상기 원격 시스템에 송신하여 상기 클라이언트 디바이스와 상기 원격 시스템 간에 어떠한 연결도 이후에 설정되지 않고 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하는 데 활용되도록 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 제21항 내지 제25항 중 어느 한 항에 있어서, 상기 주어진 언어에 대한 상기 글로벌 ML 모델을 업데이트하기 위한 그래디언트를 생성하기 위해 연합 학습 또는 일시적 학습을 구현할지를 여부를 결정하는 단계는 상기 클라이언트 디바이스의 위치에 더 기초하는, 방법.</claim></claimInfo><claimInfo><claim>27. 클라이언트 디바이스의 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은:주어진 라디오 스테이션으로부터, 주어진 언어로 된 음성 발화의 스트림을 캡처하는 오디오 데이터의 스트림을 수신하는 단계;상기 클라이언트 디바이스와 상기 원격 시스템 사이의 연결 상태를 기초로, 상기 주어진 언어에 대한 글로벌 기계 학습(ML) 모델을 업데이트하기 위한 그래디언트를 생성하기 위해 연합 학습 또는 일시적 학습을 구현할지 여부를 결정하는 단계;상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용하기 위한 상기 그래디언트를 생성하기 위해 상기 연합 학습을 구현하기로 결정하는 것에 응답하여: 상기 클라이언트 디바이스의 온디바이스 스토리지에 저장되어 있고 상기 글로벌 ML 모델의 온디바이스 대응물인 온디바이스 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하는 단계; 비지도 또는 자기지도 학습 기술을 사용하여, 상기 온디바이스 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하는 단계; 및 상기 그래디언트를 상기 원격 시스템에 비동기식으로 송신하여 상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용되도록 하는 단계; 및 상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용하기 위한 상기 그래디언트를 생성하기 위해 상기 일시적 학습을 구현하기로 결정하는 것에 응답하여: 상기 오디오 데이터의 스트림을 상기 원격 시스템에 동기식으로 송신하는 단계를 포함하고, 상기 원격 시스템에 상기 오디오 데이터의 스트림을 동기식으로 송신하는 단계는 상기 원격 시스템으로 하여금:  상기 글로벌 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하게 하고;  상기 비지도 또는 자기지도 학습 기술을 사용하여, 상기 글로벌 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하게 하고; 및  상기 그래디언트를 기초로, 상기 글로벌 ML 모델을 업데이트하게 하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 오디오 데이터의 스트림을 상기 원격 시스템에 동기식으로 송신하는 단계는 상기 원격 시스템으로 하여금:상기 그래디언트를 생성한 후 상기 오디오 데이터의 스트림을 삭제하게 하는, 방법.</claim></claimInfo><claimInfo><claim>29. 클라이언트 디바이스의 하나 이상의 프로세서에 의해 구현되는 방법으로,서 상기 방법은:상기 클라이언트 디바이스의 사용자가 적극적으로 소비하는 주어진 라디오 스테이션으로부터, 주어진 언어로 된 음성 발화의 스트림을 캡처하는 오디오 데이터의 스트림을 수신하는 단계; 및원격 시스템에서 상기 주어진 언어와 관련하여 글로벌 기계 학습(ML) 모델을 업데이트하기 위해, 그래디언트가 생성되게 하는 단계를 포함하고, 상기 그래디언트가 생성되게 하는 단계는:  상기 클라이언트 디바이스의 온디바이스 스토리지에 저장되어 있고 상기 글로벌 ML 모델의 온디바이스 대응물인 온디바이스 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하는 단계;  비지도 또는 자기지도 학습 기술을 사용하여, 상기 온디바이스 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하는 단계;  상기 오디오 데이터의 스트림을 삭제하는 단계; 및  상기 그래디언트를 상기 원격 시스템에 송신하여 상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 데 활용되게 하는 단계를 포함하고; 또는  상기 그래디언트가 생성되게 하는 단계는:  상기 오디오 데이터의 스트림을 상기 원격 시스템에 송신하는 단계를 포함하고, 상기 오디오 데이터의 스트림을 상기 원격 시스템에 송신하는 단계는 상기 원격 시스템으로 하여금:   상기 글로벌 ML 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하게 하고;   상기 비지도 또는 자기지도 학습 기술을 사용하여, 상기 글로벌 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하게 하고;   상기 오디오 데이터의 스트림을 삭제하게 하고; 및   상기 그래디언트를 기초로, 상기 글로벌 ML 모델을 업데이트하게 하는, 방법.</claim></claimInfo><claimInfo><claim>30. 원격 시스템의 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은:주어진 클라이언트 디바이스로부터, 주어진 언어로 된 음성 발화의 스트림을 캡처하는 오디오 데이터의 스트림을 수신하는 단계-상기 오디오 데이터의 스트림은 상기 주어진 클라이언트 디바이스의 사용자가 적극적으로 소비하는 주어진 라디오 스테이션으로부터 상기 주어진 클라이언트 디바이스에서 초기에 수신됨-;글로벌 기계 학습(ML) 모델을 사용하여, 상기 오디오 데이터의 스트림을 프로세싱하는 단계;비지도 또는 자기 지도 학습 기술을 사용하여, 그리고 상기 글로벌 ML 모델을 사용하여 상기 오디오 데이터의 스트림을 프로세싱하는 것에 기초하여, 상기 그래디언트를 생성하는 단계;상기 오디오 데이터의 스트림을 삭제하는 단계; 및상기 그래디언트를 기초로, 상기 주어진 언어와 관련하여 상기 글로벌 ML 모델을 업데이트하는 단계를 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>미국</country><engName>SCHALKWYK, Johan</engName><name>스칼크익 조한</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>미국</country><engName>AGUERA-ARCAS, Blaise</engName><name>아게라 아르카스 블래이스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>미국</country><engName>CASADO, Diego Melendo</engName><name>카사도 디에고 멜렌도</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>미국</country><engName>LITVIN, Oren</engName><name>리트빈 오렌</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.26</priorityApplicationDate><priorityApplicationNumber>63/401,399</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.12.05</priorityApplicationDate><priorityApplicationNumber>18/074,739</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.02.11</receiptDate><receiptNumber>1-1-2025-0157255-28</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.02.14</receiptDate><receiptNumber>1-5-2025-0027215-35</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257004458.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930b050ef8c0efa352633b99d1f2baa3fe548cd5106976024d1bdc698c42642b259251202566e04bccca8d89d97ff98a6c83748e11d5d018eb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1109d49fde13e180501ce9cc62db2b2d24564fb6d11e1fe629e11f3a0283a71ee4e37584798f10521d7bdbf98489a0fdf458b5193873758b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>