<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:57.4057</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.01.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7029923</applicationNumber><claimCount>64</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>순환-기반 머신 러닝 시스템들을 사용한 비디오 압축</inventionTitle><inventionTitleEng>VIDEO COMPRESSION USING RECURRENT-BASED MACHINE LEARNING SYSTEMS</inventionTitleEng><openDate>2022.11.10</openDate><openNumber>10-2022-0150298</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.08.29</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/436</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/503</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/42</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/137</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/172</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/463</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/85</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 순환-기반 머신 러닝 툴들을 사용하여 비디오 콘텐츠를 코딩하기 위한 기법들이 본 명세서에서 설명된다. 디바이스는 인코더 및 디코더 부분들을 포함하는 뉴럴 네트워크 시스템을 포함할 수 있다. 인코더 부분은 뉴럴 네트워크 시스템의 동작의 현재 시간 스텝에 대한 입력 비디오 프레임, 동작의 이전 시간 스텝으로부터의 재구성된 모션 추정 데이터, 동작의 이전 시간 스텝으로부터의 재구성된 잔차 데이터, 및 동작의 이전 시간 스텝으로부터 뉴럴 네트워크 시스템의 디코더 부분의 적어도 하나의 순환 계층으로부터의 순환 상태 데이터에 가초하여 뉴럴 네트워크 시스템의 동작의 현재 시간 스텝에 대한 출력 데이터를 생성할 수 있다. 뉴럴 네트워크 시스템의 디코더 부분은 출력 데이터 및 동작의 이전 시간 스텝으로부터의 순환 상태 데이터에 기초하여, 동작의 현재 시간 스텝에 대한 재구성된 비디오 프레임을 생성할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.09.10</internationOpenDate><internationOpenNumber>WO2021178050</internationOpenNumber><internationalApplicationDate>2021.01.15</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/013599</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 데이터를 프로세싱하는 방법으로서, 뉴럴 네트워크 시스템의 인코더 부분에 의해, 상기 뉴럴 네트워크 시스템의 동작의 현재 시간 스텝에 대한 입력 비디오 프레임, 상기 뉴럴 네트워크 시스템의 동작의 이전 시간 스텝으로부터의 재구성된 모션 추정 데이터, 상기 뉴럴 네트워크 시스템의 동작의 상기 이전 시간 스텝으로부터의 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터 상기 뉴럴 네트워크 시스템의 디코더 부분의 적어도 하나의 순환 계층으로부터의 순환 상태 데이터를 획득하는 단계;상기 뉴럴 네트워크 시스템의 상기 인코더 부분에 의해, 상기 뉴럴 네트워크 시스템의 동작의 상기 현재 시간 스텝에 대한 출력 데이터를 생성하는 단계로서, 상기 출력 데이터는 상기 입력 비디오 프레임, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 모션 추정 데이터, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터에 적어도 부분적으로 기초하여 생성되는, 상기 출력 데이터를 생성하는 단계;상기 뉴럴 네트워크 시스템의 상기 디코더 부분에 의해, 동작의 상기 현재 시간 스텝에 대한 상기 출력 데이터 및 동작의 상기 이전 시간 스텝으로부터 상기 디코더 부분의 상기 적어도 하나의 순환 계층으로부터의 상기 순환 상태 데이터를 획득하는 단계; 및동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 �상기 출력 데이터에 적어도 부분적으로 기초하여, 동작의 상기 현재 시간 스텝에 대한 재구성된 비디오 프레임을 생성하는 단계로서, 상기 재구성된 비디오 프레임은 상기 입력 비디오 프레임을 나타내는, 상기 재구성된 비디오 프레임을 생성하는 단계를 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 뉴럴 네트워크 시스템의 상기 디코더 부분에 의해, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 모션 추정 데이터를 결정하는 단계;동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임을 획득하는 단계; 및상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 뉴럴 네트워크 시스템의 상기 디코더 부분에 의해, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하는 단계; 및상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터에 상기 워핑된 재구성된 비디오 프레임을 부가함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>4. 제 2 항에 있어서,상기 뉴럴 네트워크 시스템의 상기 디코더 부분에 의해, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하는 단계; 및상기 디코더 부분의 포스트-워핑 네트워크에 의해, 상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임을 프로세싱하는 단계를 더 포함하고, 상기 재구성된 비디오 프레임은 상기 포스트-워핑 네트워크에 의한 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임의 프로세싱에 기초하여 동작의 상기 현재 시간 스텝에 대해 생성되는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 뉴럴 네트워크 시스템의 모션 추정 네트워크에 의해, 상기 입력 비디오 프레임과 동작의 상기 이전 시간 스텝으로부터의 이전에 재구성된 비디오 프레임 또는 동작의 상기 이전 시간 스텝으로부터의 이전 입력 비디오 프레임 중 적어도 하나에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 모션 추정 데이터를 결정하는 단계;상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임 또는 상기 이전 입력 비디오 프레임 중 적어도 하나의 하나 이상의 픽셀을 수정함으로써 적어도 부분적으로 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하는 단계; 및 동작의 상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터 및 상기 워핑된 재구성된 비디오 프레임을 상기 뉴럴 네트워크 시스템의 상기 인코더 부분에 전송하는 단계를 더 포함하고, 동작의 상기 현재 시간 스텝에 대한 생성된 상기 출력 데이터는 동작의 상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터 및 상기 워핑된 재구성된 비디오 프레임에 적어도 부분적으로 기초하여 상기 뉴럴 네트워크 시스템의 상기 인코더 부분에 의해 생성되는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,하나 이상의 훈련 반복에 대해, 제 1 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하는 단계로서, 상기 제 1 손실 함수는 하나 이상의 입력 비디오 프레임과 하나 이상의 워핑된 재구성된 비디오 프레임 사이의 손실을 결정하는, 상기 제 1 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하는 단계;  상기 제 1 손실 함수를 비활성화하는 단계; 및상기 하나 이상의 훈련 반복 후에 수행되는 하나 이상의 후속 훈련 반복에 대해, 제 2 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하는 단계로서, 상기 제 2 손실 함수는 적어도 하나의 입력 비디오 프레임과 적어도 하나의 재구성된 비디오 프레임 사이의 손실을 결정하는, 상기 제 2 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서, 상기 순환 상태 데이터는 상기 적어도 하나의 순환 계층의 노드들의 하나 이상의 값을 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서, 상기 뉴럴 네트워크 시스템의 상기 디코더 부분은 복수의 순환 계층을 포함하고, 상기 복수의 순환 계층의 각각의 순환 계층은 개개의 순환 상태 데이터를 제공하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서,동작의 상기 현재 시간 스텝 또는 동작의 상기 이전 시간 스텝에 대한 결정된 모션 추정 데이터를 사용하여 동작의 상기 이전 시간 스텝으로부터 상기 순환 상태 데이터를 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 순환 상태 데이터를 생성하는 단계를 더 포함하고, 동작의 상기 현재 시간 스텝에 대한 생성된 상기 재구성된 비디오 프레임은 상기 워핑된 순환 상태 데이터에 적어도 부분적으로 기초하여 생성되는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>10. 제 1 항에 있어서,상기 디코더 부분에 의해, 재구성된 마스크를 생성하는 단계로서, 상기 재구성된 마스크는 동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임에서의 데이터의 존재를 표시하는 하나 이상의 값을 포함하는, 상기 재구성된 마스크를 생성하는 단계; 및 상기 재구성된 마스크, 동작의 상기 현재 시간 스텝에 대한 생성된 워핑된 재구성된 비디오 프레임, 및 동작의 상기 현재 시간 스텝에 대한 결정된 재구성된 잔차 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 단계로서, 상기 재구성된 마스크는 상기 워핑된 재구성된 비디오 프레임 및 상기 재구성된 잔차 데이터의 기여들을 가중하는, 상기 재구성된 비디오 프레임을 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서,동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임을 획득하는 단계; 동작의 상기 현재 시간 스텝 동안, 상기 현재 시간 스텝에 대한 결정된 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하는 단계; 동작의 상기 현재 시간 스텝 동안 상기 디코더 부분에 의해, 동작의 상기 현재 시간 스텝에 대한 제 1 재구성된 잔차 데이터를 결정하는 단계; 상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터에 상기 워핑된 재구성된 비디오 프레임을 부가함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 단계; 동작의 상기 현재 시간 스텝 동안 상기 디코더 부분에 의해, 동작의 상기 현재 시간 스텝 동안 상기 인코더 부분에 의해 프로세싱된 이전 입력 비디오 프레임에 적어도 부분적으로 기초하여 동작의 상기 이전 시간 스텝으로부터의 제 2 재구성된 잔차 데이터를 결정하는 단계; 동작의 상기 현재 시간 스텝 동안, 상기 제 2 재구성된 잔차 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임을 수정하는 단계; 및 수정된 상기 이전에 재구성된 비디오 프레임을 동작의 상기 현재 시간 스텝에 대한 최종 출력 비디오 프레임으로서 출력하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>12. 제 1 항에 있어서,상기 뉴럴 네트워크 시스템의 상기 인코더 부분에 의해, 하나 이상의 왜곡 맵을 획득하는 단계; 및상기 뉴럴 네트워크 시스템의 상기 인코더 부분에 의해, 상기 하나 이상의 왜곡 맵에 적어도 부분적으로 기초하여 상기 출력 데이터를 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서, 상기 하나 이상의 왜곡 맵은 동작의 상기 현재 시간 스텝에 대한 상기 입력 비디오 프레임과 동작의 상기 이전 시간 스텝으로부터의 이전에 재구성된 비디오 프레임 사이의 왜곡을 표시하는 제 1 왜곡 맵을 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>14. 제 12 항에 있어서, 상기 하나 이상의 왜곡 맵은 동작의 상기 현재 시간 스텝에 대한 상기 입력 비디오 프레임과 워핑된 재구성된 비디오 프레임 사이의 왜곡을 표시하는 제 2 왜곡 맵을 포함하고, 상기 워핑된 재구성된 비디오 프레임은 동작의 상기 이전 시간 스텝으로부터 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 적어도 부분적으로 생성되는, 비디오 데이터를 프로세싱하는 방법. </claim></claimInfo><claimInfo><claim>15. 제 1 항에 있어서,상기 뉴럴 네트워크 시스템의 상기 인코더 부분의 제 1 계층에 의해, 입력 데이터를 프로세싱하는 단계; 상기 인코더 부분의 상기 제 1 계층에 의해, 상기 인코더 부분의 상기 제 1 계층에 대한 복수의 가중치 값을 결정하는 단계;상기 뉴럴 네트워크 시스템의 상기 인코더 부분의 제 2 계층의 가중치들을 상기 복수의 가중치 값으로 설정하는 단계; 및상기 인코더 부분의 상기 제 2 계층에 의해, 상기 복수의 가중치 값으로 설정된 가중치들을 사용하여 상기 입력 데이터를 프로세싱하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>16. 제 1 항에 있어서,상기 출력 데이터를 저장 매체에 저장하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>17. 제 1 항에 있어서,상기 재구성된 비디오 프레임을 저장 매체에 저장하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>18. 제 1 항에 있어서,상기 재구성된 비디오 프레임을 송신 매체를 통해 적어도 하나의 디바이스에 전송하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>19. 비디오 데이터를 프로세싱하기 위한 장치로서,메모리; 및상기 메모리에 커플링된 프로세서를 포함하고, 상기 프로세서는,  뉴럴 네트워크 시스템의 인코더 부분을 사용하여, 상기 뉴럴 네트워크 시스템의 동작의 현재 시간 스텝에 대한 입력 비디오 프레임, 상기 뉴럴 네트워크 시스템의 동작의 이전 시간 스텝으로부터의 재구성된 모션 추정 데이터, 상기 뉴럴 네트워크 시스템의 동작의 상기 이전 시간 스텝으로부터의 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터 상기 뉴럴 네트워크 시스템의 디코더 부분의 적어도 하나의 순환 계층으로부터의 순환 상태 데이터를 획득하고; 상기 인코더 부분을 사용하여, 상기 뉴럴 네트워크 시스템의 동작의 상기 현재 시간 스텝에 대한 출력 데이터를 생성하는 것으로서, 상기 출력 데이터는 상기 입력 비디오 프레임, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 모션 추정 데이터, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터에 적어도 부분적으로 기초하여 생성되는, 상기 출력 데이터를 생성하고; 뉴럴 네트워크 시스템의 상기 디코더 부분을 사용하여, 동작의 상기 현재 시간 스텝에 대한 상기 출력 데이터 및 동작의 상기 이전 시간 스텝으로부터 상기 디코더 부분의 상기 적어도 하나의 순환 계층으로부터의 상기 순환 상태 데이터를 획득하며; 그리고 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 �상기 출력 데이터에 적어도 부분적으로 기초하여, 동작의 상기 현재 시간 스텝에 대한 재구성된 비디오 프레임을 생성하는 것으로서, 상기 재구성된 비디오 프레임은 상기 입력 비디오 프레임을 나타내는, 상기 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>20. 제 19 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 상기 디코더 부분을 사용하여, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 모션 추정 데이터를 결정하고; 동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임을 획득하며; 그리고상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 상기 디코더 부분을 사용하여, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하고; 그리고상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터에 상기 워핑된 재구성된 비디오 프레임을 부가함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>22. 제 21 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 상기 디코더 부분을 사용하여, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하고; 그리고상기 디코더 부분의 포스트-워핑 네트워크를 사용하여, 상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임을 프로세싱하도록 구성되며,  상기 재구성된 비디오 프레임은 상기 포스트-워핑 네트워크에 의한 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임의 프로세싱에 기초하여 동작의 상기 현재 시간 스텝에 대해 생성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>23. 제 19 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 모션 추정 네트워크를 사용하여, 상기 입력 비디오 프레임과 동작의 상기 이전 시간 스텝으로부터의 이전에 재구성된 비디오 프레임 또는 동작의 상기 이전 시간 스텝으로부터의 이전 입력 비디오 프레임 중 적어도 하나에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 모션 추정 데이터를 결정하고;상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임 또는 상기 이전 입력 비디오 프레임 중 적어도 하나의 하나 이상의 픽셀을 수정함으로써 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하며; 그리고동작의 상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터 및 상기 워핑된 재구성된 비디오 프레임을 상기 뉴럴 네트워크 시스템의 상기 인코더 부분에 전송하도록 구성되고,  동작의 상기 현재 시간 스텝에 대한 생성된 상기 출력 데이터는 동작의 상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터 및 상기 워핑된 재구성된 비디오 프레임에 적어도 부분적으로 기초하여 상기 뉴럴 네트워크 시스템의 상기 인코더 부분을 사용하여 생성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>24. 제 23 항에 있어서, 상기 프로세서는,하나 이상의 훈련 반복에 대해, 제 1 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하는 것으로서, 상기 제 1 손실 함수는 하나 이상의 입력 비디오 프레임과 하나 이상의 워핑된 재구성된 비디오 프레임 사이의 손실을 결정하는, 상기 제 1 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하고; 상기 제 1 손실 함수를 비활성화하며; 그리고상기 하나 이상의 훈련 반복 후에 수행되는 하나 이상의 후속 훈련 반복에 대해, 제 2 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하는 것으로서, 상기 제 2 손실 함수는 적어도 하나의 입력 비디오 프레임과 적어도 하나의 재구성된 비디오 프레임 사이의 손실을 결정하는, 상기 제 2 손실 함수를 사용하여 상기 뉴럴 네트워크 시스템을 훈련하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>25. 제 19 항에 있어서, 상기 순환 상태 데이터는 상기 적어도 하나의 순환 계층의 노드들의 하나 이상의 값을 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>26. 제 19 항에 있어서, 상기 뉴럴 네트워크 시스템의 상기 디코더 부분은 복수의 순환 계층을 포함하고, 상기 복수의 순환 계층의 각각의 순환 계층은 개개의 순환 상태 데이터를 제공하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>27. 제 19 항에 있어서, 상기 프로세서는,동작의 상기 현재 시간 스텝 또는 동작의 상기 이전 시간 스텝에 대한 결정된 모션 추정 데이터를 사용하여 동작의 상기 이전 시간 스텝으로부터 상기 순환 상태 데이터를 수정함으로써 동작의 상기 현재 시간 스텝에 대한 워핑된 순환 상태 데이터를 생성하도록 구성되고,  동작의 상기 현재 시간 스텝에 대한 생성된 상기 재구성된 비디오 프레임은 상기 워핑된 순환 상태 데이터에 적어도 부분적으로 기초하여 생성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>28. 제 19 항에 있어서, 상기 프로세서는,상기 디코더 부분을 사용하여, 재구성된 마스크를 생성하는 것으로서, 상기 재구성된 마스크는 동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임에서의 데이터의 존재를 표시하는 하나 이상의 값을 포함하는, 상기 재구성된 마스크를 생성하고; 그리고 상기 디코더 부분을 사용하여, 상기 재구성된 마스크, 동작의 상기 현재 시간 스텝에 대한 생성된 워핑된 재구성된 비디오 프레임, 및 동작의 상기 현재 시간 스텝에 대한 결정된 재구성된 잔차 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 것으로서, 상기 재구성된 마스크는 상기 워핑된 재구성된 비디오 프레임 및 상기 재구성된 잔차 데이터의 기여들을 가중하는, 상기 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>29. 제 19 항에 있어서, 상기 프로세서는,동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임을 획득하고;동작의 상기 현재 시간 스텝 동안 상기 디코더 부분을 사용하여, 상기 현재 시간 스텝에 대한 결정된 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 동작의 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하고;동작의 상기 현재 시간 스텝 동안 상기 디코더 부분을 사용하여, 동작의 상기 현재 시간 스텝에 대한 제 1 재구성된 잔차 데이터를 결정하고; 상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터에 상기 워핑된 재구성된 비디오 프레임을 부가함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하고;동작의 상기 현재 시간 스텝 동안 상기 디코더 부분을 사용하여, 동작의 상기 현재 시간 스텝 동안 상기 인코더 부분에 의해 프로세싱된 이전 입력 비디오 프레임에 적어도 부분적으로 기초하여 동작의 상기 이전 시간 스텝으로부터의 제 2 재구성된 잔차 데이터를 결정하고; 동작의 상기 현재 시간 스텝 동안 상기 디코더 부분을 사용하여, 상기 제 2 재구성된 잔차 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임을 수정하며; 그리고 수정된 상기 이전에 재구성된 비디오 프레임을 동작의 상기 현재 시간 스텝에 대한 최종 출력 비디오 프레임으로서 출력하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>30. 제 19 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 상기 인코더 부분을 사용하여, 하나 이상의 왜곡 맵을 획득하고; 그리고상기 뉴럴 네트워크 시스템의 상기 인코더 부분을 사용하여, 상기 하나 이상의 왜곡 맵에 적어도 부분적으로 기초하여 상기 출력 데이터를 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>31. 제 30 항에 있어서, 상기 하나 이상의 왜곡 맵은 동작의 상기 현재 시간 스텝에 대한 상기 입력 비디오 프레임과 동작의 상기 이전 시간 스텝으로부터의 이전에 재구성된 비디오 프레임 사이의 왜곡을 표시하는 제 1 왜곡 맵을 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>32. 제 30 항에 있어서, 상기 하나 이상의 왜곡 맵은 동작의 상기 현재 시간 스텝에 대한 상기 입력 비디오 프레임과 워핑된 재구성된 비디오 프레임 사이의 왜곡을 표시하는 제 2 왜곡 맵을 포함하고, 상기 워핑된 재구성된 비디오 프레임은 동작의 상기 이전 시간 스텝으로부터 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 생성되는, 비디오 데이터를 프로세싱하기 위한 장치. </claim></claimInfo><claimInfo><claim>33. 제 19 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 상기 인코더 부분의 제 1 계층을 사용하여, 입력 데이터를 프로세싱하고; 상기 인코더 부분의 상기 제 1 계층을 사용하여, 상기 인코더 부분의 상기 제 1 계층에 대한 복수의 가중치 값을 결정하고;상기 뉴럴 네트워크 시스템의 상기 인코더 부분의 제 2 계층의 가중치들을 상기 복수의 가중치 값으로 설정하며; 그리고상기 인코더 부분의 상기 제 2 계층에 의해, 상기 복수의 가중치 값으로 설정된 가중치들을 사용하여 상기 입력 데이터를 프로세싱하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>34. 제 19 항에 있어서, 상기 프로세서는,상기 출력 데이터가 상기 메모리에 저장되게 하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>35. 제 19 항에 있어서, 상기 프로세서는,상기 재구성된 비디오 프레임이 상기 메모리에 저장되게 하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>36. 제 19 항에 있어서,상기 재구성된 비디오 프레임을 송신 매체를 통해 적어도 하나의 디바이스에 송신하도록 구성된 송신기를 더 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>37. 제 19 항에 있어서, 상기 프로세서는 뉴럴 프로세싱 유닛 (NPU) 를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>38. 제 19 항에 있어서, 상기 장치는 모바일 디바이스를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>39. 제 19 항에 있어서, 상기 장치는 확장 현실 디바이스를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>40. 제 19 항에 있어서,디스플레이를 더 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>41. 제 19 항에 있어서,상기 장치는 텔레비전을 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>42. 제 19 항에 있어서, 상기 장치는 하나 이상의 비디오 프레임을 캡처하도록 구성된 카메라를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>43. 비디오 데이터를 프로세싱하는 방법으로서,뉴럴 네트워크 시스템의 디코더 부분에 의해, 상기 뉴럴 네트워크 시스템의 동작의 현재 시간 스텝에 대한 출력 데이터 및 상기 뉴럴 네트워크 시스템의 동작의 이전 시간 스텝으로부터 상기 디코더 부분의 적어도 하나의 순환 계층으로부터의 순환 상태 데이터를 획득하는 단계;  상기 뉴럴 네트워크 시스템의 상기 디코더 부분에 의해, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 모션 추정 데이터를 결정하는 단계;동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임을 획득하는 단계; 상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하는 단계; 및 상기 워핑된 재구성된 비디오 프레임에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 비디오 프레임을 생성하는 단계를 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>44. 제 43 항에 있어서,상기 뉴럴 네트워크 시스템의 상기 디코더 부분에 의해, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하는 단계; 및상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터에 상기 워핑된 재구성된 비디오 프레임을 부가함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>45. 제 44 항에 있어서,동작의 상기 현재 시간 스텝 동안 상기 디코더 부분에 의해, 동작의 상기 현재 시간 스텝 동안 상기 뉴럴 네트워크 시스템의 인코더 부분에 의해 프로세싱된 이전 입력 비디오 프레임에 적어도 부분적으로 기초하여 동작의 상기 이전 시간 스텝으로부터의 재구성된 잔차 데이터를 결정하는 단계; 동작의 상기 현재 시간 스텝 동안, 동작의 상기 이전 시간 스템으로부터의 상기 재구성된 잔차 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임을 수정하는 단계; 및 수정된 상기 이전에 재구성된 비디오 프레임을 동작의 상기 현재 시간 스텝에 대한 최종 출력 비디오 프레임으로서 출력하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>46. 제 43 항에 있어서,상기 뉴럴 네트워크 시스템의 상기 디코더 부분에 의해, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하는 단계;  상기 디코더 부분의 포스트-워핑 네트워크에 의해, 상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임을 프로세싱하는 단계; 및상기 포스트-워핑 네트워크에 의한 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임의 프로세싱에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>47. 제 43 항에 있어서,동작의 상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터 또는 동작의 상기 이전 시간 스텝에 대한 결정된 모션 추정을 사용하여 동작의 상기 이전 시간 스텝으로부터 상기 순환 상태 데이터를 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 순환 상태 데이터를 생성하는 단계; 및상기 워핑된 순환 상태 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>48. 제 43 항에 있어서,상기 디코더 부분에 의해, 재구성된 마스크를 생성하는 단계로서, 상기 재구성된 마스크는 동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임에서의 데이터의 존재를 표시하는 하나 이상의 값을 포함하는, 상기 재구성된 마스크를 생성하는 단계; 및 상기 재구성된 마스크, 동작의 상기 현재 시간 스텝에 대한 상기 워핑된 재구성된 비디오 프레임, 및 동작의 상기 현재 시간 스텝에 대한 결정된 재구성된 잔차 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 단계로서, 상기 재구성된 마스크는 상기 워핑된 재구성된 비디오 프레임 및 상기 재구성된 잔차 데이터의 기여들을 가중하는, 상기 재구성된 비디오 프레임을 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>49. 제 43 항에 있어서,뉴럴 네트워크 시스템의 인코더 부분에 의해, 동작의 상기 현재 시간 스텝에 대한 입력 비디오 프레임, 상기 뉴럴 네트워크 시스템의 동작의 이전 시간 스텝으로부터의 재구성된 모션 추정 데이터, 상기 뉴럴 네트워크 시스템의 동작의 상기 이전 시간 스텝으로부터의 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터 상기 뉴럴 네트워크 시스템의 상기 디코더 부분의 적어도 하나의 순환 계층으로부터의 순환 상태 데이터를 획득하는 단계; 및상기 뉴럴 네트워크 시스템의 상기 인코더 부분에 의해, 동작의 상기 현재 시간 스텝에 대한 출력 데이터를 생성하는 단계로서, 상기 출력 데이터는 상기 입력 비디오 프레임, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 모션 추정 데이터, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터에 적어도 부분적으로 기초하여 생성되는, 상기 출력 데이터를 생성하는 단계를 더 포함하는, 비디오 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>50. 비디오 데이터를 프로세싱하기 위한 장치로서,메모리; 및상기 메모리에 커플링된 프로세서를 포함하고, 상기 프로세서는,  뉴럴 네트워크 시스템의 디코더 부분을 사용하여, 상기 뉴럴 네트워크 시스템의 동작의 현재 시간 스텝에 대한 출력 데이터 및 상기 뉴럴 네트워크 시스템의 동작의 이전 시간 스텝으로부터 상기 디코더 부분의 적어도 하나의 순환 계층으로부터의 순환 상태 데이터를 획득하고;   상기 뉴럴 네트워크 시스템의 상기 디코더 부분을 사용하여, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 모션 추정 데이터를 결정하고; 동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임을 획득하고;  상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임의 하나 이상의 픽셀을 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 재구성된 비디오 프레임을 생성하며; 그리고 상기 워핑된 재구성된 비디오 프레임에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>51. 제 50 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 상기 디코더 부분을 사용하여, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하고; 그리고상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터에 상기 워핑된 재구성된 비디오 프레임을 부가함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>52. 제 51 항에 있어서, 상기 프로세서는,동작의 상기 현재 시간 스텝 동안 상기 디코더 부분을 사용하여, 동작의 상기 현재 시간 스텝 동안 상기 뉴럴 네트워크 시스템의 인코더 부분에 의해 프로세싱된 이전 입력 비디오 프레임에 적어도 부분적으로 기초하여 동작의 상기 이전 시간 스텝으로부터의 제 2 재구성된 잔차 데이터를 결정하고; 동작의 상기 현재 시간 스텝 동안, 동작의 상기 이전 시간 스템으로부터의 상기 재구성된 잔차 데이터를 사용하여 상기 이전에 재구성된 비디오 프레임을 수정하며; 그리고 수정된 상기 이전에 재구성된 비디오 프레임을 동작의 상기 현재 시간 스텝에 대한 최종 출력 비디오 프레임으로서 출력하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>53. 제 50 항에 있어서, 상기 프로세서는,상기 뉴럴 네트워크 시스템의 상기 디코더 부분을 사용하여, 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터 및 상기 출력 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 재구성된 잔차 데이터를 결정하고; 상기 디코더 부분의 포스트-워핑 네트워크를 사용하여, 상기 현재 시간 스텝에 대한 결정된 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임을 프로세싱하며; 그리고상기 포스트-워핑 네트워크에 의한 상기 재구성된 잔차 데이터 및 상기 워핑된 재구성된 비디오 프레임의 프로세싱에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>54. 제 50 항에 있어서, 상기 프로세서는,동작의 상기 현재 시간 스텝에 대한 결정된 상기 모션 추정 데이터 또는 동작의 상기 이전 시간 스텝에 대한 결정된 모션 추정을 사용하여 동작의 상기 이전 시간 스텝으로부터 상기 순환 상태 데이터를 수정함으로써 적어도 부분적으로 동작의 상기 현재 시간 스텝에 대한 워핑된 순환 상태 데이터를 생성하고; 그리고상기 워핑된 순환 상태 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>55. 제 50 항에 있어서, 상기 프로세서는,상기 디코더 부분을 사용하여, 재구성된 마스크를 생성하는 것으로서, 상기 재구성된 마스크는 동작의 상기 이전 시간 스텝 동안 생성된 이전에 재구성된 비디오 프레임에서의 데이터의 존재를 표시하는 하나 이상의 값을 포함하는, 상기 재구성된 마스크를 생성하고; 그리고 상기 재구성된 마스크, 동작의 상기 현재 시간 스텝에 대한 상기 워핑된 재구성된 비디오 프레임, 및 동작의 상기 현재 시간 스텝에 대한 결정된 재구성된 잔차 데이터에 적어도 부분적으로 기초하여 동작의 상기 현재 시간 스텝에 대한 상기 재구성된 비디오 프레임을 생성하는 것으로서, 상기 재구성된 마스크는 상기 워핑된 재구성된 비디오 프레임 및 상기 재구성된 잔차 데이터의 기여들을 가중하는, 상기 재구성된 비디오 프레임을 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>56. 제 50 항에 있어서, 상기 프로세서는,뉴럴 네트워크 시스템의 인코더 부분을 사용하여, 동작의 상기 현재 시간 스텝에 대한 입력 비디오 프레임, 상기 뉴럴 네트워크 시스템의 동작의 이전 시간 스텝으로부터의 재구성된 모션 추정 데이터, 상기 뉴럴 네트워크 시스템의 동작의 상기 이전 시간 스텝으로부터의 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터 상기 뉴럴 네트워크 시스템의 상기 디코더 부분의 적어도 하나의 순환 계층으로부터의 순환 상태 데이터를 획득하고; 그리고상기 뉴럴 네트워크 시스템의 상기 인코더 부분을 사용하여, 동작의 상기 현재 시간 스텝에 대한 출력 데이터를 생성하는 것으로서, 상기 출력 데이터는 상기 입력 비디오 프레임, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 모션 추정 데이터, 동작의 상기 이전 시간 스텝으로부터의 상기 재구성된 잔차 데이터, 및 동작의 상기 이전 시간 스텝으로부터의 상기 순환 상태 데이터에 적어도 부분적으로 기초하여 생성되는, 상기 출력 데이터를 생성하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>57. 제 50 항에 있어서, 상기 프로세서는,상기 재구성된 비디오 프레임이 상기 메모리에 저장되게 하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>58. 제 50 항에 있어서, 상기 프로세서는,상기 재구성된 비디오 프레임이 디스플레이되게 하도록 구성되는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>59. 제 50 항에 있어서,상기 재구성된 비디오 프레임을 디스플레이하도록 구성된 디스플레이를 더 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>60. 제 50 항에 있어서, 상기 프로세서는 뉴럴 프로세싱 유닛 (NPU) 를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>61. 제 50 항에 있어서, 상기 장치는 모바일 디바이스를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>62. 제 50 항에 있어서, 상기 장치는 확장 현실 디바이스를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>63. 제 50 항에 있어서,상기 장치는 텔레비전을 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>64. 제 50 항에 있어서, 상기 장치는 하나 이상의 비디오 프레임을 캡처하도록 구성된 카메라를 포함하는, 비디오 데이터를 프로세싱하기 위한 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>GOLINSKI, ADAM WALDEMAR</engName><name>골린스키 아담 발데마르</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>YANG, YANG</engName><name>양 양</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>POURREZA, REZA</engName><name>푸레자 레자</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>SAUTIERE, GUILLAUME KONRAD</engName><name>소띠에르 기욤 콘라드</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>VAN ROZENDAAL, TIES JEHAN</engName><name>판 로전달 티스 예한</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>COHEN, TACO SEBASTIAAN</engName><name>코헌 타코 세바스티안</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.03.03</priorityApplicationDate><priorityApplicationNumber>62/984,673</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.11.06</priorityApplicationDate><priorityApplicationNumber>17/091,570</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.08.29</receiptDate><receiptNumber>1-1-2022-0907205-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.10.06</receiptDate><receiptNumber>1-5-2022-0148690-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.12.27</receiptDate><receiptNumber>1-1-2023-1463437-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2023.12.27</receiptDate><receiptNumber>1-1-2023-1463438-86</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227029923.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c932a0d227f5e7edba2b3d0fdb5d9e3a8491c0fffabe31d336fdb92f078447739ccc42320766e35397b015e6d80c3703dcc9b9ac39ad0deed4c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe1fb2e8bea9b57ce488b75bfd457d14ffb7eec8fb11318f6752a123da6eb4dd95882b24444797b874c291287ee89beb89de993858bf81a4e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>