<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:31.131</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.03.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7036263</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>픽셀-정렬된 객체에 대한 표면 법선들</inventionTitle><inventionTitleEng>SURFACE NORMALS FOR PIXEL-ALIGNED OBJECT</inventionTitleEng><openDate>2024.12.09</openDate><openNumber>10-2024-0172197</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.10.30</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/60</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미지에서 묘사되는 사람에 증강 현실 엘리먼트들을 적용하기 위한 동작들을 수행하기 위한 방법들 및 시스템들이 개시된다. 이러한 동작들은, 사람의 묘사를 표현하는 데이터를 포함하는 이미지를 수신하는 동작; 이미지에서 묘사되는 사람을 표현하는 데이터의 세그먼트화를 생성하는 동작; 이미지에서 묘사되는 사람을 표현하는 데이터의 세그먼트화에 대응하는 이미지의 부분을 추출하는 동작; 사람의 묘사를 표현하는 데이터에 대한 표면 법선 텐서를 예측하기 위해 이미지의 부분에 머신 학습 모델을 적용하는 동작- 표면 법선 텐서는 이미지의 부분 내의 각각의 픽셀의 표면 법선들을 표현함 -; 및 표면 법선 텐서에 기초하여 이미지에 하나 이상의 AR(augmented reality) 엘리먼트를 적용하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.10.05</internationOpenDate><internationOpenNumber>WO2023192426</internationOpenNumber><internationalApplicationDate>2023.03.30</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/016813</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,클라이언트 디바이스의 하나 이상의 프로세서에 의해, 사람의 묘사를 표현하는 데이터를 포함하는 이미지를 수신하는 단계;상기 하나 이상의 프로세서에 의해, 상기 사람의 묘사를 표현하는 데이터의 세그먼트화를 생성하는 단계;상기 이미지에서 묘사되는 상기 사람을 표현하는 데이터의 세그먼트화에 대응하는 상기 이미지의 부분을 추출하는 단계;상기 사람의 묘사를 표현하는 데이터에 대한 표면 법선 텐서를 예측하기 위해 상기 이미지의 부분에 머신 학습 모델을 적용하는 단계- 상기 표면 법선 텐서는 상기 이미지의 부분 내의 각각의 픽셀의 표면 법선들을 표현함 -; 및상기 표면 법선 텐서에 기초하여 상기 이미지에 하나 이상의 AR(augmented reality) 엘리먼트를 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는,상기 표면 법선 텐서에 기초하여 제1 방향으로부터 상기 사람의 묘사를 표현하는 데이터에 광이 집중되고 있다고 결정하는 단계; 및제2 방향으로부터 상기 사람의 묘사에 상기 광을 다시 집중하기 위해 상기 사람의 묘사를 표현하는 데이터의 세그먼트화에 대응하는 상기 이미지의 부분의 픽셀 값들을 수정하는 단계- 상기 픽셀 값들은 상기 세그먼트화 외부의 상기 이미지의 부분들의 픽셀 값들을 수정하지 않고 수정됨 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는 상기 사람의 신체의 지오메트리, 상기 사람의 머리카락, 상기 사람의 복장, 및 상기 사람에 의해 착용되는 하나 이상의 액세서리에 기초하여 상기 하나 이상의 AR 엘리먼트를 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는 상기 표면 법선 텐서에 기초하여 상기 이미지에서 묘사되는 상기 사람을 표현하는 데이터에 인공 광을 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 추가로,비디오의 제1 프레임에서 묘사되는 상기 사람을 표현하는 데이터의 제1 부분 상에 상기 하나 이상의 AR 엘리먼트를 디스플레이하는 단계- 상기 사람은 상기 제1 프레임에서의 제1 위치에 위치결정됨 -;상기 사람이 상기 제1 위치로부터 상기 비디오의 제2 프레임에서의 제2 위치로 이동하였다고 결정하는 단계; 및상기 표면 법선 텐서에 기초하여 상기 이미지에서 묘사되는 상기 사람을 표현하는 데이터 상에 상기 하나 이상의 AR 엘리먼트의 디스플레이를 유지하기 위해 상기 제2 프레임에서의 상기 하나 이상의 AR 엘리먼트의 디스플레이 위치를 업데이트하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 표면 법선 텐서는 상기 이미지를 캡처하기 위해 사용되는 카메라의 표면 법선에 관해 컴퓨팅되는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 AR 엘리먼트들은 상기 이미지를 포함하는 실시간 비디오 피드에 적용되는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는 상기 사람의 묘사를 표현하는 데이터를 하나 이상의 시각적 효과로 대체하는 단계를 포함하고, 추가로,상기 표면 법선 텐서에 기초하여 상기 사람에 대한 광 반사 방향들을 결정하는 단계; 및상기 하나 이상의 시각적 효과로 하여금 상기 표면 법선 텐서를 사용하여 상기 광 반사 방향들을 따라 광을 반사하게 하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는 상기 이미지에서 묘사되는 상기 사람의 하나 이상의 부분을 재채색하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는 상기 표면 법선 텐서에 기초하여 상기 이미지에서 묘사되는 상기 사람에 하나 이상의 애니메이션화된 패션 아이템을 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는,사람의 묘사를 표현하는 데이터에 대응하는 제1 픽셀의 제1 방향을 결정하는 단계;사람의 묘사를 표현하는 데이터에 대응하는 제2 픽셀의 제2 방향을 결정하는 단계;디스플레이를 위해, 상기 제1 방향을 따라 상기 제1 픽셀로부터 연장되는 3차원(3D) 그래픽을 포함하는 제1 AR 엘리먼트를 생성하는 단계; 및상기 제1 AR 엘리먼트와 함께 디스플레이하기 위해, 상기 제2 방향을 따라 상기 제2 픽셀로부터 연장되는 3D 그래픽을 포함하는 제2 AR 엘리먼트를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제1 픽셀로부터 연장되는 상기 3D 그래픽은 3D 열을 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 머신 학습 모델은 신경망- 상기 신경망은 인체들의 상이한 배향들을 묘사하는 이미지 부분들과 상기 인체들의 픽셀들의 표면 법선 방향들 사이의 관계를 수립하도록 트레이닝됨 -을 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 동작들을 수행하는 것에 의해 상기 머신 학습 모델을 트레이닝하는 단계를 추가로 포함하고, 상기 동작들은,복수의 트레이닝 데이터 세트들을 수신하는 동작- 상기 복수의 트레이닝 데이터 세트들 각각은 이미지에서 묘사되는 사람을 표현하는 트레이닝 부분 및 대응하는 실측 표면 법선 텐서를 포함함 -;추정된 표면 법선 텐서를 예측하기 위해 제1 트레이닝 데이터 세트의 제1 트레이닝 부분에 상기 머신 학습 모델을 적용하는 동작;상기 제1 트레이닝 부분과 연관된 상기 실측 표면 법선 텐서와 상기 추정된 표면 법선 텐서 사이의 편차를 컴퓨팅하는 동작;상기 컴퓨팅된 편차에 기초하여 상기 머신 학습 모델의 하나 이상의 파라미터를 업데이트하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 추가로,상기 표면 법선 텐서에 기초하여 상기 이미지에서 묘사되는 상기 사람에 의해 착용되는 복장의 하나 이상의 주름을 검출하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는 상기 하나 이상의 주름에 기초하여 상기 복장 상에 하나 이상의 가상 그림자를 렌더링하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 하나 이상의 AR 엘리먼트를 적용하는 단계는 상기 표면 법선 텐서에 기초하여 상기 하나 이상의 주름을 오버레이하는 상기 하나 이상의 AR 엘리먼트의 부분을 구부리는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제17항 중 어느 한 항에 있어서, 상기 머신 학습 모델은 상기 이미지에서의 각각의 픽셀을, 상기 픽셀이 배경에 대응하는지 또는 상기 사람의 묘사를 표현하는 데이터에 대응하는지의 표시와 연관시키는 세그먼트화 벡터를 생성하는- 상기 하나 이상의 AR 엘리먼트는 상기 세그먼트화 벡터에 추가로 기초하여 적용됨 - 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서,클라이언트 디바이스의 프로세서; 및명령어들을 저장한 메모리 컴포넌트를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하고, 상기 동작들은,사람의 묘사를 표현하는 데이터를 포함하는 이미지를 수신하는 동작;상기 이미지에서 묘사되는 상기 사람을 표현하는 데이터의 세그먼트화를 생성하는 동작;상기 이미지에서 묘사되는 상기 사람을 표현하는 데이터의 세그먼트화에 대응하는 상기 이미지의 부분을 추출하는 동작;상기 사람의 묘사를 표현하는 데이터에 대한 표면 법선 텐서를 예측하기 위해 상기 이미지의 부분에 머신 학습 모델을 적용하는 동작- 상기 표면 법선 텐서는 상기 이미지의 부분 내의 각각의 픽셀의 표면 법선들을 표현함 -; 및상기 표면 법선 텐서에 기초하여 상기 이미지에 하나 이상의 AR(augmented reality) 엘리먼트를 적용하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 저장한 비-일시적 컴퓨터-판독가능 저장 매체로서, 상기 명령어들은, 클라이언트 디바이스의 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하고, 상기 동작들은,사람의 묘사를 표현하는 데이터를 포함하는 이미지를 수신하는 동작;상기 이미지에서 묘사되는 상기 사람을 표현하는 데이터의 세그먼트화를 생성하는 동작;상기 이미지에서 묘사되는 상기 사람을 표현하는 데이터의 세그먼트화에 대응하는 상기 이미지의 부분을 추출하는 동작;상기 사람의 묘사를 표현하는 데이터에 대한 표면 법선 텐서를 예측하기 위해 상기 이미지의 부분에 머신 학습 모델을 적용하는 동작- 상기 표면 법선 텐서는 상기 이미지의 부분 내의 각각의 픽셀의 표면 법선들을 표현함 -; 및상기 표면 법선 텐서에 기초하여 상기 이미지에 하나 이상의 AR(augmented reality) 엘리먼트를 적용하는 동작을 포함하는 비-일시적 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>AITBAYEV, Madiyar</engName><name>아이트바예프, 마디야르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>FULKERSON, Brian</engName><name>풀커슨, 브라이언</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>GULER, Riza Alp</engName><name>굴러, 리자 알프</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>PAPANDREOU, Georgios</engName><name>파판드레우, 게오르기오스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>TAM, Himmy</engName><name>탐, 히미</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.06.16</priorityApplicationDate><priorityApplicationNumber>17/841,994</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>그리스</priorityApplicationCountry><priorityApplicationDate>2022.03.30</priorityApplicationDate><priorityApplicationNumber>20220100284</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.10.30</receiptDate><receiptNumber>1-1-2024-1186473-33</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.10.30</receiptDate><receiptNumber>1-1-2024-1187726-68</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.11.04</receiptDate><receiptNumber>1-5-2024-0177041-82</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247036263.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937b4f32412194f3d24009eca2ac4766ccf63c3a2787d199bc711826c70a219e4aa9e5a353d468b73f5a1758bd3870e949fa11878b9e56528a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4547f2ee98594573e025cd3cab287298b1f84475563bf68261bf8528245890fa7e679a546f865d5842d60e09dce9f63c93e688117c32e387</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>