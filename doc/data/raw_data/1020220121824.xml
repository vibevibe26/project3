<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:06.76</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.09.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0121824</applicationNumber><claimCount>40</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>차원 축소 모델 및 그 훈련 방법</inventionTitle><inventionTitleEng>DIMENSIONALITY REDUCTION MODEL AND METHOD FOR  TRAINING SAME</inventionTitleEng><openDate>2023.04.12</openDate><openNumber>10-2023-0049025</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.09.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/088</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 차원 축소(dimensionality reduction) 모델을 훈련시키기 위한 방법들 및 시스템들이 제공된다. 더 높은 차원 공간에서 근접하게 위치된 훈련 벡터들의 쌍들이 생성된다. 저차원 벡터 쌍들은 차원 축소 모델을 사용하여 제1 및 제2 훈련 벡터들을 인코딩함으로써 생성되고, 증강 차원 벡터 쌍들은 더 많은 차원들을 갖는 증강 차원 표현 공간에 투영함으로써 생성된다. 유사성 보존 손실 및 중복 감소 손실이 계산되고 차원 축소 모델의 파라미터들을 최적화하는 데 사용된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 차원 축소(dimensionality reduction) 모델을 훈련시키기 위해 프로세서 및 메모리에 의해 수행되는 방법으로서, 상기 차원 축소 모델은 -차원 표현 공간에서 입력 벡터를 수신하고, -차원 표현 공간에서 출력 벡터를 생성하고, 는 보다 더 크고, 상기 차원 축소 모델은 하나 이상의 파라미터들에 의해 정의되며, 상기 방법은,상기 -차원 공간에서  포지티브 쌍들의 훈련 벡터들의 배치를 생성하는 단계 - 각각의 포지티브 쌍은 제1 훈련 벡터 및 제2 훈련 벡터를 포함하고, 상기 생성하는 단계는 각각의 포지티브 쌍에 대해,상기 -차원 표현 공간에서 훈련 벡터들의 세트로부터 상기 제1 훈련 벡터를 선택하는 단계, 및상기 제1 훈련 벡터에 근접한 상기 -차원 공간에서 제2 훈련 벡터를 식별하는 단계를 포함함 -;각각 제1 및 제2 저차원 벡터들을 제공하기 위해 상기 차원 축소 모델을 사용하여 상기  포지티브 쌍들의 배치의 각각의 상기 제1 및 제2 훈련 벡터들을 상기 -차원 표현 공간으로 인코딩함으로써  저차원 벡터 쌍들의 배치를 생성하는 단계;각각 제1 및 제2 증강 차원 벡터들을 제공하기 위해 차원()을 갖는 증강 차원 표현 공간에 상기  저차원 벡터 쌍들의 배치의 각각의 상기 제1 및 제2 저차원 벡터들을 투영함으로써  증강 차원 벡터 쌍들의 배치를 생성하는 단계 - 는 보다 더 큼 -;상기  증강 차원 벡터 쌍들의 배치에 대해 상기 제1 및 제2 증강 차원 벡터들 사이의 유사성 보존 손실 및 중복 감소 손실을 계산하는 단계; 및상기 계산된 유사성 보존 손실 및 상기 계산된 중복 감소 손실에 기초하여 총 손실을 최소화하도록 상기 차원 축소 모델의 상기 파라미터들을 최적화하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기  포지티브 쌍들의 배치의 각각에서 상기 제2 훈련 벡터를 식별하는 단계는,상기 제1 훈련 벡터에 잡음을 추가함으로써 합성 훈련 벡터를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기  포지티브 쌍들의 배치의 각각에서 상기 제2 훈련 벡터를 식별하는 단계는,상기 훈련 벡터들의 세트로부터 상기 제1 훈련 벡터에 근접한 훈련 벡터를 선택하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기  포지티브 쌍들의 배치의 각각에서 상기 제2 훈련 벡터를 식별하는 단계는,상기 선택된 훈련 벡터의 이웃을 제공하기 위해 메트릭과 관련하여 상기 제1 훈련 벡터에 대한  최근접 이웃들의 세트를 결정하는 단계; 및상기 결정된  최근접 이웃들의 세트로부터 상기 제2 훈련 벡터를 선택하는 단계를 포함하며,상기 는 선택 가능한 파라미터인, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제2 훈련 벡터를 선택하는 단계는,상기 결정된  최근접 이웃들의 세트를 샘플링하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 메트릭은 훈련 벡터들 사이의 유클리드 거리를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 메트릭은 훈련 벡터들 사이의 비-유클리드 거리를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서,상기 메트릭은 상기 훈련 벡터들의 각각의 주위의 반경을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 유사성 보존 손실을 계산하는 단계는,공통 차원들에 대한 상기  증강 차원 벡터 쌍들의 배치에 대해 상기 제1 및 제2 증강 차원 벡터들 사이의 상호 상관을 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 중복 감소 손실을 계산하는 단계는,상기  증강 차원 벡터 쌍들의 배치에 대해 상기 제1 및 제2 증강 차원 벡터들의 차원들 사이의 상관관계를 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 중복 감소 손실을 계산하는 단계는,상기 공통 차원들 이외의 차원들에 대한 상기  증강 차원 벡터 쌍들의 배치에 대해 상기 제1 및 제2 증강 벡터들 사이의 상호 상관을 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 유사성 보존 손실을 계산하는 단계 및 상기 중복 감소 손실을 계산하는 단계는,상기  증강 차원 벡터 쌍들의 배치에 대해 상기 제1 및 제2 증강 벡터들 사이의  상호-상관 행렬을 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,상기 총 손실은 오프셋 파라미터에 의해 가중된 유사성 보존 손실 및 중복 감소 손실을 계산하는 것에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,상기 차원 축소 모델은 파라미터화된 신경망에서 구현되는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서,상기 차원 축소 모델은 선형 함수를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서,상기 차원 축소 모델은 비선형 함수를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서,상기 차원 축소 모델은 인수분해된 선형 함수를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제1항에 있어서,상기 차원 축소 모델은 선형 및 비선형 함수들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제1항에 있어서,상기 차원 축소 모델은 파라미터화된 신경망에서 구현되고,상기 차원 축소 모델은 은닉 유닛들 및 선형 투영 유닛을 갖는 다층 퍼셉트론(multilayer perceptron)을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 파라미터화된 신경망은 배치 정규화를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제1항에 있어서,상기 투영하는 단계는, 다층 퍼셉트론, 선형 투영기, 또는 비선형 투영기 중 하나 이상을 사용하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제1항에 있어서,상기 파라미터들을 최적화하는 단계는, 확률적 경사 하강법을 사용하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제1항에 있어서,상기 방법은 비지도 방식인, 방법.</claim></claimInfo><claimInfo><claim>24. 제1항에 있어서,상기 방법은 자기 지도 방식인, 방법.</claim></claimInfo><claimInfo><claim>25. 제1항에 있어서,상기 훈련 벡터들의 세트의 각각의 훈련 벡터는 토큰, 문서, 문장, 단락, 문서, 이미지, 이미지의 패치 또는 임의의 영역, 비디오, 파형, 3D 모델, 3D 포인트 클라우드 또는 테이블 형식 데이터의 임베딩들 중 하나 이상을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>26. 1항에 있어서,상기 -차원 공간의 상기 훈련 벡터들의 세트의 각각의 훈련 벡터는 특징 세트의 핵심 표현을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서,상기 핵심 표현은 오프라인으로 생성되는, 방법.</claim></claimInfo><claimInfo><claim>28. 제1항에 있어서,상기 방법은 상기 최적화된 파라미터들을 저장하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>29. 프로세서 및 메모리를 사용하여 입력 벡터를 인코딩하기 위한 방법으로서, -차원 표현 공간에서 상기 입력 벡터를 수신하고 -차원 표현 공간에서 출력 벡터를 생성하도록 훈련된 차원 축소 모델에 상기 입력 벡터를 입력하는 단계 - 는 보다 더 크고, 상기 차원 축소 모델은 하나 이상의 훈련 가능한 파라미터들에 의해 정의됨 -;상기 -차원 공간에서 인코딩된 출력 벡터를 생성하기 위해 상기 훈련된 차원 축소 모델을 사용하여 상기 입력 벡터를 인코딩하는 단계; 및상기 인코딩된 출력 벡터를 출력하는 단계를 포함하며,상기 차원 축소 모델은,상기 -차원 공간에서  포지티브 쌍들의 훈련 벡터들의 배치를 생성하는 단계 - 각각의 포지티브 쌍은 제1 훈련 벡터 및 제2 훈련 벡터를 포함하고, 상기 생성하는 단계는 각각의 포지티브 쌍에 대해,상기 -차원 표현 공간에서 훈련 벡터들의 세트로부터 상기 제1 훈련 벡터를 선택하는 단계; 및상기 제1 훈련 벡터에 근접한 상기 -차원 공간에서 제2 훈련 벡터를 식별하는 단계를 포함함 -;각각 제1 및 제2 저차원 벡터들을 제공하기 위해 상기 차원 축소 모델을 사용하여 상기  포지티브 쌍들의 배치의 각각의 상기 제1 및 제2 훈련 벡터들을 상기 -차원 표현 공간으로 인코딩함으로써  저차원 벡터 쌍들의 배치를 생성하는 단계;각각 제1 및 제2 증강 차원 벡터들을 제공하기 위해 차원()을 갖는 증강 차원 표현 공간에 상기  저차원 벡터 쌍들의 배치의 각각의 상기 제1 및 제2 저차원 벡터들을 투영함으로써  증강 차원 벡터 쌍들의 배치를 생성하는 단계 - 는 보다 더 큼 -;상기  증강 차원 벡터 쌍들의 배치에 대해 상기 제1 및 제2 증강 차원 벡터들 사이의 유사성 보존 손실 및 중복 감소 손실을 계산하는 단계; 및상기 계산된 유사성 보존 손실 및 상기 계산된 중복 감소 손실에 기초하여 총 손실을 최소화하도록 상기 차원 축소 모델의 상기 파라미터들을 최적화하는 단계를 포함하는 방법에 의해 훈련되는, 방법.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서,상기 차원 축소 모델은 파라미터화된 신경망을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>31. 제29항에 있어서, 상기 방법은,상기 -차원 공간에서 입력의 핵심 표현을 생성하는 단계; 및상기 입력의 상기 핵심 표현을 정규화하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>32. 제29항에 있어서,상기 입력은 토큰, 문서, 문장, 단락, 이미지, 비디오, 파형, 3D 모델, 3D 포인트 클라우드, 또는 테이블 형식 데이터의 임베딩들 중 하나 이상을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>33. 제29항에 있어서,상기 방법은,작업을 수행하기 위해 상기 차원 축소 모델의 다운스트림의 상기 인코딩된 출력 벡터를 처리하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서,상기 작업은 데이터 검색 작업을 포함하고, 상기 데이터 검색 작업은 고차원 벡터 공간에 대한 것이고,상기 데이터 검색 작업은 유클리드 메트릭들 및/또는 비-유클리드 메트릭들을 사용하는, 방법.</claim></claimInfo><claimInfo><claim>35. 제29항에 있어서,상기  증강 차원 벡터 쌍들의 배치를 생성하는 단계는 투영기를 사용하고,훈련된 이후의 상기 훈련된 차원 축소 모델은 상기 투영기를 포함하지 않는, 방법.</claim></claimInfo><claimInfo><claim>36. 제29항에 있어서,훈련 중인 상기 차원 축소 모델은 선형 인코더 및 비선형 인코더를 사용하고,훈련된 이후의 상기 훈련된 차원 축소 모델은 비선형 인코더를 사용하지 않는, 방법.</claim></claimInfo><claimInfo><claim>37. 신경망 모델을 훈련시키기 위해 프로세서 및 메모리에 의해 수행되는 방법으로서, 상기 신경망 모델은 인코더 및 상기 인코더의 다운스트림의 작업 수행 모델을 포함하며, 상기 방법은,입력 벡터들 및 연관된 레이블들의 훈련 세트를 제공하는 단계;상기 입력 벡터들을 상기 인코더에 입력하는 단계 - 상기 인코더는 -차원 표현 공간에서 입력 벡터를 수신하고, -차원 표현 공간에서 출력 벡터를 생성하는 차원 축소 모델을 포함하고, 는 보다 더 크고, 상기 차원 축소 모델은 하나 이상의 훈련 가능한 파라미터들에 의해 정의되고, 상기 차원 축소 모델은,상기 -차원 공간에서  포지티브 쌍들의 훈련 벡터들의 배치를 생성하는 단계 - 각각의 포지티브 쌍은 제1 훈련 벡터 및 제2 훈련 벡터를 포함하고, 상기 생성하는 단계는 각각의 포지티브 쌍에 대해,상기 -차원 표현 공간에서 훈련 벡터들의 세트로부터 상기 제1 훈련 벡터를 선택하는 단계, 및상기 제1 훈련 벡터에 근접하고 상기 제1 훈련 벡터와 레이블을 공유하는 제2 훈련 벡터를 -차원 공간에서 식별하는 단계를 포함함 -;각각 제1 및 제2 저차원 벡터들을 제공하기 위해 상기 차원 축소 모델을 사용하여 상기  포지티브 쌍들의 배치의 각각의 상기 제1 및 제2 훈련 벡터들을 상기 -차원 표현 공간으로 인코딩함으로써  저차원 벡터 쌍들의 배치를 생성하는 단계;각각 제1 및 제2 증강 차원 벡터들을 제공하기 위해 차원()을 갖는 증강 차원 표현 공간에 상기  저차원 벡터 쌍들의 배치의 각각의 상기 제1 및 제2 저차원 벡터들을 투영함으로써  증강 차원 벡터 쌍들의 배치를 생성하는 단계 - 는 보다 더 큼 -;상기  증강 차원 벡터 쌍들의 배치에 대해 상기 제1 및 제2 증강 차원 벡터들 사이의 유사성 보존 손실 및 중복 감소 손실을 계산하는 단계; 및상기 계산된 유사성 보존 손실 및 상기 계산된 중복 감소 손실에 기초하여 총 손실을 최소화하도록 상기 차원 축소 모델의 상기 파라미터들을 최적화하는 단계를 포함하는 방법에 의해 훈련됨 -;인코딩된 출력 벡터들을 생성하기 위해 상기 훈련된 차원 축소 모델을 사용하여 상기 입력 벡터들을 인코딩하는 단계; 및상기 인코딩된 출력 벡터들과 상기 레이블들을 사용하여 상기 작업 수행 모델을 훈련시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>38. 제37항에 있어서,상기 방법은,상기 -차원 공간에서 상기 입력 벡터들의 훈련 세트의 각각에 대한 입력의 핵심 표현을 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>39. 제38항에 있어서,상기 방법은,상기 입력의 상기 핵심 표현을 정규화하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>40. 제37항에 있어서,상기 훈련 세트의 상기 훈련 벡터들은 토큰, 문서, 이미지, 이미지의 일부, 비디오, 파형, 3D 모델, 3D 포인트 클라우드, 또는 테이블 형식 데이터의 임베딩들 중 하나 이상을 나타내는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>119990373888</code><country>대한민국</country><engName>NAVER Corporation</engName><name>네이버 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>프랑스 ***** ...</address><code> </code><country> </country><engName>Ioannis Kalantidis</engName><name>요안니스 칼란티디스</name></inventorInfo><inventorInfo><address>프랑스 ***** ...</address><code> </code><country> </country><engName>Diane Larlus</engName><name>다이앤 랄러스</name></inventorInfo><inventorInfo><address>프랑스 ***** ...</address><code> </code><country> </country><engName>Jon Almazan</engName><name>존 알마잔</name></inventorInfo><inventorInfo><address>프랑스 ***** ...</address><code> </code><country> </country><engName>Carlos Lassance</engName><name>카를로스 라상스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 역삼로***,*층(역삼동,성보역삼빌딩)</address><code>920041000211</code><country>대한민국</country><engName>HMP IP GROUP</engName><name>특허법인충정</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.05</priorityApplicationDate><priorityApplicationNumber>63/252,380</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.02</priorityApplicationDate><priorityApplicationNumber>17/929,502</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.09.26</receiptDate><receiptNumber>1-1-2022-1012356-40</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.09.28</receiptDate><receiptNumber>9-1-2022-9011215-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.01.05</receiptDate><receiptNumber>9-1-2023-9000251-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>불수리 (Non-acceptance) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.02.11</receiptDate><receiptNumber>1-1-2025-0153894-90</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Reason for Return of Document</documentEngName><documentName>서류반려이유통지서</documentName><receiptDate>2025.02.17</receiptDate><receiptNumber>1-5-2025-0028252-93</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[반려요청]서류 반려요청서·반환신청서</documentName><receiptDate>2025.02.25</receiptDate><receiptNumber>1-1-2025-0218580-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.02.25</receiptDate><receiptNumber>1-1-2025-0218586-90</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice for Return of Document</documentEngName><documentName>서류반려통지서</documentName><receiptDate>2025.02.27</receiptDate><receiptNumber>1-5-2025-0035695-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.09.05</receiptDate><receiptNumber>9-5-2025-0860146-08</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName> </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.10.21</receiptDate><receiptNumber>1-1-2025-1176121-33</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.10.21</receiptDate><receiptNumber>1-1-2025-1176120-98</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220121824.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93399e125397d943c854fd878409c25f0302dc4b7738330cbe7dfda49d8d2ba38b6f1599487dec3e4707d6476423e362be79b5feed2b8bf933</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0255e35434a322a62c37e204c9133ac08785a2355a77545bff12172ac55fed236ace0562bf20cdc3bbe29b435e09fc51f8333eddfcddacb3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>