<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:03:28.328</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.08.12</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0101583</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>깊이 정보를 획득하는 증강 현실 디바이스 및 그 동작 방법</inventionTitle><inventionTitleEng>AN AUGMENTED REALITY DEVICE FOR OBTAINING DEPTH  INFORMATION AND A METHOD FOR OPERATING THE SAME</inventionTitleEng><openDate>2023.11.27</openDate><openNumber>10-2023-0161309</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.08.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/271</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/239</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/257</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/128</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 추가 하드웨어 모듈없이 높은 정확도를 갖는 깊이 맵을 획득하기 위하여 IMU 센서에 의해 측정된 중력 방향에 기초하여 깊이 값을 보정하는 증강 현실 디바이스 및 그 동작 방법을 제공한다. 본 개시의 일 실시예에 따른 증강 현실 디바이스는 카메라를 이용하여 획득한 이미지로부터 깊이 맵(depth map)을 획득하고, 깊이 맵으로부터 적어도 하나의 픽셀의 법선 벡터(normal vector)를 획득하고, IMU 센서(Inertial Measurement Unit)에 의해 측정된 중력 방향에 기초하여 적어도 하나의 픽셀의 법선 벡터의 방향을 보정하고, 보정된 법선 벡터의 방향에 기초하여 깊이 맵의 깊이 값을 보정할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 카메라(110);중력 방향을 측정하도록 구성되는 IMU 센서(Inertial Measurement Unit)(120); 적어도 하나의 명령어들(instructions)를 저장하는 메모리(140); 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(130); 를 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 카메라(110)를 이용하여 획득한 이미지로부터 깊이 맵(depth map)을 획득하고, 상기 깊이 맵에 포함된 적어도 하나의 픽셀의 법선 벡터(normal vector)를 획득하고,상기 IMU 센서(120)에 의해 측정된 중력 방향에 기초하여 상기 적어도 하나의 픽셀의 법선 벡터의 방향을 보정하고, 상기 보정된 법선 벡터의 방향에 기초하여 상기 적어도 하나의 픽셀의 깊이 값을 보정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 적어도 하나의 프로세서(130)는, 상기 깊이 맵에 포함된 적어도 하나의 픽셀의 방향 벡터 및 상기 적어도 하나의 픽셀의 깊이 값에 기초하여 상기 적어도 하나의 픽셀을 3차원 좌표값으로 변환하고, 상하좌우 방향으로 인접한 복수의 인접 픽셀들의 3차원 좌표값의 외적(cross-product)을 계산함으로써, 상기 법선 벡터를 획득하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>3. 제1 항 및 제2 항 중 어느 하나의 항에 있어서,상기 카메라(110)는 좌안 이미지를 획득하는 좌안 카메라 및 우안 이미지를 획득하는 우안 카메라를 포함하고, 상기 적어도 하나의 프로세서(130)는,상기 좌안 이미지 및 상기 우안 이미지를 인공지능 모델에 입력으로 적용하고, 상기 인공지능 모델을 이용하여 상기 좌안 이미지와 상기 우안 이미지의 픽셀 휘도값 유사도에 따른 시차(disparity)를 계산함으로써, 상기 깊이 맵을 획득하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,상기 적어도 하나의 프로세서(130)는,상기 보정된 법선 벡터에 의해 정의되는 평면 상의 픽셀 및 상기 픽셀과 위치 상으로 인접한 복수의 인접 픽셀들의 깊이 값에 기초하여, 상기 인공지능 모델에 의해 획득된 깊이 맵의 손실값(loss)을 산출하고,  상기 산출된 손실값을 상기 인공지능 모델에 적용하는 트레이닝(training)을 수행함으로써, 상기 적어도 하나의 픽셀의 깊이 값을 보정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서,상기 적어도 하나의 프로세서(130)는,상기 보정된 법선 벡터를 갖는 픽셀 및 상기 픽셀에 위치적으로 인접한 상기 복수의 인접 픽셀들로 구성된 평면을 정의하고, 상기 정의된 평면과 상기 카메라(110)의 광선 벡터(ray vector)가 만나는 복수의 포인트에 기초하여 상기 복수의 인접 픽셀들의 깊이 값을 획득하고, 상기 획득된 픽셀의 깊이 값과 상기 복수의 인접 픽셀들의 깊이 값 간의 차이값을 각각 산출하고, 상기 복수의 인접 픽셀들 별로 산출된 차이값에 가중치를 적용하는 가중합(weighted sum) 연산을 수행함으로써, 상기 손실값을 획득하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 가중치는, 상기 깊이 맵에서의 복수의 인접 픽셀들 각각의 상기 카메라(110)와의 거리에 기초하여 결정되는 제1 가중치 및 상기 깊이 맵에서의 상기 픽셀과 상기 복수의 인접 픽셀들 간의 휘도값 차이에 기초하여 결정되는 제2 가중치를 포함하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>7. 제3 항 내지 제6 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(130)는,상기 트레이닝된 인공지능 모델에 상기 좌안 이미지 및 상기 우안 이미지를 입력하는 추론을 수행함으로써, 보정된 깊이 맵을 획득하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서, 상기 카메라(110)는 좌안 이미지를 획득하는 좌안 카메라 및 우안 이미지를 획득하는 우안 카메라를 포함하고, 상기 적어도 하나의 프로세서(130)는,상기 중력 방향 또는 중력 방향에 수직한 방향에 따라 상기 좌안 이미지 및 상기 우안 이미지의 법선 벡터의 방향을 보정하고, 상기 보정된 법선 벡터의 방향 또는 상기 보정된 법선 벡터의 방향에 수직하는 방향을 따라 평면 가정(plane hypothesis)을 수행하고, 상기 평면 가정에 의해 정의된 평면을 따라 플레인 스윕(plane sweep)을 수행함으로써, 상기 적어도 하나의 픽셀의 깊이 값을 획득하고,상기 획득된 깊이 값을 이용하여 상기 적어도 하나의 픽셀의 깊이 값을 보정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,상기 카메라(110)는 ToF 카메라(Time-of-Flight camera)로 구성되고, 상기 적어도 하나의 프로세서(130)는,상기 ToF 카메라를 이용하여 상기 깊이 맵을 획득하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,상기 적어도 하나의 프로세서(130)는,상기 보정된 법선 벡터에 기초하여 픽셀 별 평면을 정의하고, RGB 이미지의 색상 정보에 따라 분할된 영역에 기초하여 상기 깊이 맵에서 정의된 평면의 평면 영역을 식별하고, 상기 식별된 평면 영역 내의 인접 픽셀들의 깊이 값에 기초하여 상기 깊이 값을 보정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>11. 증강 현실 디바이스(100)가 깊이 값을 보정하는 방법에 있어서, 카메라(110)를 이용하여 획득한 이미지로부터 깊이 맵(depth map)을 획득하는 단계(S310); 상기 깊이 맵에 포함된 적어도 하나의 픽셀의 법선 벡터(normal vector)를 획득하는 단계(S320);IMU 센서(120)에 의해 측정된 중력 방향에 기초하여 상기 적어도 하나의 픽셀의 법선 벡터의 방향을 보정하는 단계(S330); 및상기 보정된 법선 벡터의 방향에 기초하여 상기 적어도 하나의 픽셀의 깊이 값을 보정하는 단계(S340);를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 깊이 맵을 획득하는 단계(S310)는,좌안 카메라를 이용하여 획득된 좌안 이미지 및 우안 카메라를 이용하여 획득된 우안 이미지를 인공지능 모델에 입력하는 단계; 및 상기 인공지능 모델을 이용하여 상기 좌안 이미지와 상기 우안 이미지의 픽셀 휘도값 유사도에 따른 시차(disparity)를 계산함으로써, 상기 깊이 맵을 획득하는 단계;를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 깊이 맵의 픽셀 별 깊이 값을 보정하는 단계(S340)는, 상기 보정된 법선 벡터에 의해 정의되는 평면 상의 픽셀 및 상기 픽셀과 위치 상으로 인접한 복수의 인접 픽셀들의 깊이 값에 기초하여, 상기 인공지능 모델에 의해 획득된 깊이 맵의 손실값(loss)을 산출하는 단계(S810); 및 상기 산출된 손실값을 상기 인공지능 모델에 적용하는 트레이닝(training)을 수행함으로써, 상기 적어도 하나의 픽셀의 깊이 값을 보정하는 단계(S820);를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 손실값을 산출하는 단계(S810)는,상기 보정된 법선 벡터를 갖는 픽셀 및 상기 픽셀에 위치적으로 인접한 상기 복수의 인접 픽셀들로 구성된 평면을 정의하는 단계(S910);상기 정의된 평면과 상기 카메라(110)의 광선 벡터(ray vector)가 만나는 복수의 포인트에 기초하여 상기 복수의 인접 픽셀들의 깊이 값을 획득하는 단계(S920); 상기 획득된 픽셀의 깊이 값과 상기 복수의 인접 픽셀들의 깊이 값 간의 차이값을 각각 산출하는 단계(S930); 및상기 복수의 인접 픽셀들 별로 산출된 차이값에 가중치를 적용하는 가중합(weighted sum) 연산을 수행함으로써, 상기 손실값을 획득하는 단계(S940); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,상기 가중치는, 상기 깊이 맵에서의 복수의 인접 픽셀들 각각의 상기 카메라(110)와의 거리에 기초하여 결정되는 제1 가중치 및 상기 깊이 맵에서의 상기 픽셀과 상기 복수의 인접 픽셀들 간의 휘도값 차이에 기초하여 결정되는 제2 가중치를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>16. 제12 항 내지 제15 항 중 어느 하나의 항에 있어서,상기 트레이닝된 인공지능 모델에 상기 좌안 이미지 및 상기 우안 이미지를 입력하는 추론을 수행함으로써, 보정된 깊이 맵을 획득하는 단계;를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>17. 제11 항에 있어서, 상기 픽셀 별 법선 벡터의 방향을 보정하는 단계(S330)는, 상기 중력 방향 또는 중력 방향에 수직한 방향에 따라 좌안 카메라를 이용하여 획득된 좌안 이미지 및 우안 카메라를 이용하여 획득된 우안 이미지의 법선 벡터의 방향을 보정하는 단계;를 포함하고, 상기 적어도 하나의 픽셀의 깊이 값을 보정하는 단계(S340)는, 상기 보정된 법선 벡터의 방향 또는 상기 보정된 법선 벡터의 방향에 수직하는 방향을 따라 평면 가정(plane hypothesis)을 수행하는 단계(S1220); 및 상기 평면 가정에 의해 정의된 평면을 따라 플레인 스윕(plane sweep)을 수행함으로써, 상기 깊이 값을 획득하는 단계(S1230); 및상기 획득된 깊이 값을 이용하여 상기 적어도 하나의 픽셀의 깊이 값을 보정하는 단계(S1240); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>18. 제11 항에 있어서,상기 깊이 맵을 획득하는 단계(S310)는, ToF 카메라(Time-of-Flight camera)를 이용하여 상기 깊이 맵을 획득하는, 방법. </claim></claimInfo><claimInfo><claim>19. 제18 항에 있어서,상기 적어도 하나의 픽셀의 깊이 값을 보정하는 단계(S340)는, 상기 보정된 법선 벡터에 기초하여 픽셀의 평면을 정의하는 단계(S1410); RGB 이미지의 색상 정보에 따라 분할된 영역에 기초하여 상기 깊이 맵에서 정의된 평면의 평면 영역을 식별하는 단계(S1420); 및상기 식별된 평면 영역 내의 인접 픽셀들의 깊이 값에 기초하여 적어도 하나의 픽셀의 깊이 값을 보정하는 단계(S1430);를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>20. 제11 항 내지 제19 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체.  </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SHIN, Seung Hak</engName><name>신승학</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEONG, Jae Yun</engName><name>정재윤</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Song Hyeon</engName><name>김송현</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Hyo Kak</engName><name>김효각</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>WON, Seung Jae</engName><name>원승재</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JI, Seo Won</engName><name>지서원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.05.18</priorityApplicationDate><priorityApplicationNumber>1020220061033</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.08.12</receiptDate><receiptNumber>1-1-2022-0848705-88</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.08.12</receiptDate><receiptNumber>1-1-2025-0919124-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220101583.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93acb7082d5f501cfe3518355e1e9e61a9366ba9e6164c8620296d17df86b32fd5a5dd01909230b4fb882d527663fbf3378242b3c557f6b306</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf13f9a72592fab4f8110c99aeea397232aeb38f3002c6f428147f7155177f5b2131f97a3d659451cf2cca844e28188f9b352961291ece9211</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>