<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:21.621</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.11.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0164821</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전자 장치 및 전자 장치의 제어 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE AND CONTROLLING METHOD OF  ELECTRONIC DEVICE</inventionTitleEng><openDate>2022.06.08</openDate><openNumber>10-2022-0076048</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/292</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/55</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 1/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치 및 전자 장치의 제어 방법이 개시된다. 본 개시에 따른 전자 장치는 제1 카메라 및 제2 카메라를 포함하며, 전자 장치의 제어 방법은 제1 구간에 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제1 이미지 프레임이 획득되면, 한 쌍의 제1 이미지 프레임 각각에 포함된 제1 타겟 오브젝트에 대한 한 쌍의 제1 이미지 데이터를 포즈 측정 모듈에 입력하여, 제1 구간의 제1 타겟 오브젝트에 대한 제1 포즈 정보를 획득하는 단계, 제1 구간 이후의 제2 구간에 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제2 이미지 프레임이 획득되면, 제1 포즈 정보를 포즈 트래킹 모듈에 입력하여, 제2 구간의 제1 타겟 오브젝트에 대한 제2 포즈 정보를 획득하는 단계 및 제2 포즈 정보가 획득되는 동안, 한 쌍의 제2 이미지 프레임 각각에 포함된 제2 타겟 오브젝트에 대한 한 쌍의 제2 이미지 데이터를 포즈 측정 모듈에 입력하여, 제2 구간의 제2 타겟 오브젝트에 대한 제3 포즈 정보를 획득하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 있어서,제1 카메라;제2 카메라;이미지에 포함된 타겟 오브젝트의 포즈에 대한 포즈 정보를 획득하기 위한 복수의 모듈을 저장하는 메모리; 및상기 제1 카메라 및 상기 제2 카메라 각각을 통해 획득된 이미지 프레임들을 바탕으로 상기 이미지 프레임들에 포함된 복수의 타겟 오브젝트 각각의 포즈에 대한 포즈 정보를 획득하는 프로세서; 를 포함하고, 상기 프로세서는, 제1 구간에 상기 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제1 이미지 프레임이 획득되면, 상기 한 쌍의 제1 이미지 프레임 각각에 포함된 제1 타겟 오브젝트에 대한 한 쌍의 제1 이미지 데이터를 포즈 측정 모듈에 입력하여, 상기 제1 구간의 상기 제1 타겟 오브젝트에 대한 제1 포즈 정보를 획득하고, 제1 구간 이후의 제2 구간에 상기 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제2 이미지 프레임이 획득되면, 상기 제1 포즈 정보를 포즈 트래킹 모듈에 입력하여, 상기 제2 구간의 상기 제1 타겟 오브젝트에 대한 제2 포즈 정보를 획득하며, 상기 제2 포즈 정보가 획득되는 동안, 상기 한 쌍의 제2 이미지 프레임 각각에 포함된 제2 타겟 오브젝트에 대한 한 쌍의 제2 이미지 데이터를 상기 포즈 측정 모듈에 입력하여, 상기 제2 구간의 제2 타겟 오브젝트에 대한 제3 포즈 정보를 획득하는 전자 장치. </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 상기 포즈 측정 모듈은, 적어도 하나의 신경망을 포함하며, 상기 제1 카메라 및 상기 제2 카메라 각각을 통해 획득된 이미지 프레임들을 바탕으로 상기 복수의 타겟 오브젝트 각각에 대한 2 차원의 포즈 정보 및 디스패리티(disparity) 정보를 획득하고, 상기 2 차원의 포즈 정보 및 상기 디스패리티 정보를 바탕으로 상기 복수의 타겟 오브젝트 각각의 스켈레톤(skeleton) 정보에 대한 측정 값을 포함하는 포즈 정보를 획득하는 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서, 상기 포즈 트래킹 모듈은,칼만 필터(kalman filter)를 바탕으로, 입력된 이미지 프레임의 다음 프레임에 포함된 복수의 타겟 오브젝트 각각의 스켈레톤 정보에 대한 추정 값을 포함하는 포즈 정보를 획득하는 전자 장치. </claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서, 상기 프로세서는, 상기 제2 포즈 정보가 획득되면, 상기 제2 포즈 정보에 대응되는 바운딩 박스에 대한 정보 및 상기 한 쌍의 제2 이미지 프레임 각각에 포함된 상기 제1 타겟 오브젝트에 대응되는 바운딩 박스에 대한 정보를 비교하여 상기 제2 포즈 정보의 신뢰도에 대한 스코어를 획득하고, 상기 제2 구간 이후의 제3 구간에 상기 제1 카메라 및 상기 제2 카메라 각각을 통해 한 쌍의 제3 이미지 프레임을 획득하며, 상기 스코어가 기 설정된 임계 값 미만이면, 상기 한 쌍의 제3 이미지 프레임 각각에 포함된 상기 제1 타겟 오브젝트에 대한 한 쌍의 제3 이미지 데이터를 상기 포즈 측정 모듈에 입력하여, 상기 제3 구간의 상기 제1 타겟 오브젝트에 대한 제4 포즈 정보를 획득하는 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 프로세서는,상기 제2 포즈 정보가 획득되면, 상기 제2 포즈 정보를 변환하여 상기 제2 포즈 정보에 대응되는 디스패리티 정보를 획득하고, 상기 제2 포즈 정보에 대응되는 디스패리티 정보를 바탕으로 상기 제3 이미지 프레임에 포함된 상기 제1 타겟 오브젝트에 대응되는 영역을 검출하여, 상기 제3 이미지 프레임에 포함된 상기 제1 타겟 오브젝트에 대한 상기 제3 이미지 데이터를 획득하는 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서, 상기 프로세서는, 상기 제1 포즈 정보가 획득되는 동안, 상기 한 쌍의 제1 이미지 프레임 각각에 포함된 상기 제2 타겟 오브젝트에 대한 한 쌍의 제4 이미지 데이터를 상기 포즈 트래킹 모듈에 입력하여, 상기 제1 구간의 상기 제2 타겟 오브젝트에 대한 제5 포즈 정보를 획득하는 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서, 제3 카메라; 를 더 포함하고, 상기 프로세서는, 상기 한 쌍의 제1 이미지 프레임이 획득되는 동안, 상기 제3 카메라를 통해 상기 한 쌍의 제1 이미지 프레임에 대응되는 제4 이미지 프레임을 획득하고, 상기 제1 포즈 정보가 획득되는 동안, 상기 제4 이미지 프레임에 포함된 상기 제1 타겟 오브젝트에 대한 제5 이미지 데이터를 상기 포즈 트래킹 모듈에 입력하여, 상기 제1 구간의 상기 제1 타겟 오브젝트에 대한 2 차원의 포즈 정보인 제6 포즈 정보를 획득하는 전자 장치. </claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서, 상기 포즈 측정 모듈은 상기 프로세서에 포함된 GPU를 이용하여 동작하며, 상기 포즈 트래킹 모듈은 상기 프로세서에 포함된 CPU를 이용하여 동작하는 전자 장치. </claim></claimInfo><claimInfo><claim>9. 제1 카메라 및 제2 카메라를 포함하는 전자 장치의 제어 방법에 있어서,제1 구간에 상기 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제1 이미지 프레임이 획득되면, 상기 한 쌍의 제1 이미지 프레임 각각에 포함된 제1 타겟 오브젝트에 대한 한 쌍의 제1 이미지 데이터를 포즈 측정 모듈에 입력하여, 상기 제1 구간의 상기 제1 타겟 오브젝트에 대한 제1 포즈 정보를 획득하는 단계;제1 구간 이후의 제2 구간에 상기 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제2 이미지 프레임이 획득되면, 상기 제1 포즈 정보를 포즈 트래킹 모듈에 입력하여, 상기 제2 구간의 상기 제1 타겟 오브젝트에 대한 제2 포즈 정보를 획득하는 단계; 및상기 제2 포즈 정보가 획득되는 동안, 상기 한 쌍의 제2 이미지 프레임 각각에 포함된 제2 타겟 오브젝트에 대한 한 쌍의 제2 이미지 데이터를 상기 포즈 측정 모듈에 입력하여, 상기 제2 구간의 제2 타겟 오브젝트에 대한 제3 포즈 정보를 획득하는 단계; 를 포함하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서, 상기 포즈 측정 모듈은, 적어도 하나의 신경망을 포함하며, 상기 제1 카메라 및 상기 제2 카메라 각각을 통해 획득된 이미지 프레임들을 바탕으로 상기 복수의 타겟 오브젝트 각각에 대한 2 차원의 포즈 정보 및 디스패리티(disparity) 정보를 획득하고, 상기 2 차원의 포즈 정보 및 상기 디스패리티 정보를 바탕으로 상기 복수의 타겟 오브젝트 각각의 스켈레톤(skeleton) 정보에 대한 측정 값을 포함하는 포즈 정보를 획득하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>11. 제9 항에 있어서, 상기 포즈 트래킹 모듈은,칼만 필터(kalman filter)를 바탕으로, 입력된 이미지 프레임의 다음 프레임에 포함된 복수의 타겟 오브젝트 각각의 스켈레톤 정보에 대한 추정 값을 포함하는 포즈 정보를 획득하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>12. 제9 항에 있어서, 상기 제2 포즈 정보가 획득되면, 상기 제2 포즈 정보에 대응되는 바운딩 박스에 대한 정보 및 상기 한 쌍의 제2 이미지 프레임 각각에 포함된 상기 제1 타겟 오브젝트에 대응되는 바운딩 박스에 대한 정보를 비교하여 상기 제2 포즈 정보의 신뢰도에 대한 스코어를 획득하는 단계;상기 제2 구간 이후의 제3 구간에 상기 제1 카메라 및 상기 제2 카메라 각각을 통해 한 쌍의 제3 이미지 프레임을 획득하는 단계; 및상기 스코어가 기 설정된 임계 값 미만이면, 상기 한 쌍의 제3 이미지 프레임 각각에 포함된 상기 제1 타겟 오브젝트에 대한 한 쌍의 제3 이미지 데이터를 상기 포즈 측정 모듈에 입력하여, 상기 제3 구간의 상기 제1 타겟 오브젝트에 대한 제4 포즈 정보를 획득하는 단계; 를 더 포함하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서, 상기 제2 포즈 정보가 획득되면, 상기 제2 포즈 정보를 변환하여 상기 제2 포즈 정보에 대응되는 디스패리티 정보를 획득하는 단계; 및상기 제2 포즈 정보에 대응되는 디스패리티 정보를 바탕으로 상기 제3 이미지 프레임에 포함된 상기 제1 타겟 오브젝트에 대응되는 영역을 검출하여, 상기 제3 이미지 프레임에 포함된 상기 제1 타겟 오브젝트에 대한 상기 제3 이미지 데이터를 획득하는 단계; 를 더 포함하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제9 항에 있어서, 상기 제1 포즈 정보가 획득되는 동안, 상기 한 쌍의 제1 이미지 프레임 각각에 포함된 상기 제2 타겟 오브젝트에 대한 한 쌍의 제4 이미지 데이터를 상기 포즈 트래킹 모듈에 입력하여, 상기 제1 구간의 상기 제2 타겟 오브젝트에 대한 제5 포즈 정보를 획득하는 단계; 를 더 포함하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제9 항에 있어서, 상기 전자 장치는 제3 카메라; 를 더 포함하고, 상기 전자 장치의 제어 방법은,상기 한 쌍의 제1 이미지 프레임이 획득되는 동안, 상기 제3 카메라를 통해 상기 한 쌍의 제1 이미지 프레임에 대응되는 제4 이미지 프레임을 획득하는 단계; 및 상기 제1 포즈 정보가 획득되는 동안, 상기 제4 이미지 프레임에 포함된 상기 제1 타겟 오브젝트에 대한 제5 이미지 데이터를 상기 포즈 트래킹 모듈에 입력하여, 상기 제1 구간의 상기 제1 타겟 오브젝트에 대한 2 차원의 포즈 정보인 제6 포즈 정보를 획득하는 단계; 를 더 포함하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>16. 제1 항에 있어서, 상기 포즈 측정 모듈은 상기 전자 장치의 프로세서에 포함된 GPU를 이용하여 동작하며, 상기 포즈 트래킹 모듈은 상기 전자 장치의 프로세서에 포함된 CPU를 이용하여 동작하는 전자 장치의 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제1 카메라 및 제2 카메라를 포함하는 전자 장치의 제어 방법을 실행하는 프로그램을 포함하는 비일시적 컴퓨터 판독 가능 기록매체에 있어서,상기 전자 장치의 제어 방법은,제1 구간에 상기 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제1 이미지 프레임이 획득되면, 상기 한 쌍의 제1 이미지 프레임 각각에 포함된 제1 타겟 오브젝트에 대한 한 쌍의 제1 이미지 데이터를 포즈 측정 모듈에 입력하여, 상기 제1 구간의 상기 제1 타겟 오브젝트에 대한 제1 포즈 정보를 획득하는 단계;제1 구간 이후의 제2 구간에 상기 제1 카메라 및 제2 카메라 각각을 통해 한 쌍의 제2 이미지 프레임이 획득되면, 상기 제1 포즈 정보를 포즈 트래킹 모듈에 입력하여, 상기 제2 구간의 상기 제1 타겟 오브젝트에 대한 제2 포즈 정보를 획득하는 단계; 및상기 제2 포즈 정보가 획득되는 동안, 상기 한 쌍의 제2 이미지 프레임 각각에 포함된 제2 타겟 오브젝트에 대한 한 쌍의 제2 이미지 데이터를 상기 포즈 측정 모듈에 입력하여, 상기 제2 구간의 제2 타겟 오브젝트에 대한 제3 포즈 정보를 획득하는 단계; 를 포함하는 컴퓨터 판독 가능 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JU, Jae Yong</engName><name>주재용</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Yong Sung</engName><name>김용성</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SEO, Chan Won</engName><name>서찬원</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Hong Pyo</engName><name>이홍표</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>ZHANG, Lei</engName><name>장 레이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.11.30</receiptDate><receiptNumber>1-1-2020-1293641-46</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.11.30</receiptDate><receiptNumber>1-1-2023-1343513-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.11.30</receiptDate><receiptNumber>1-1-2023-1343527-60</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200164821.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d4cb1330a7dcd9e1ade0a23b157abc1e83cb7e543713b9884cea7fd4b080edf21029363d64aa2d408bafbf3736aeaaabb7bbcc5130106907</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1a660f5942a03457222e800ae90ad9fd30bd57c502269787c83b1f32989034e31010c72a38bf9e50743ec7943ecb1e3aa32c83d5d9bdebed</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>