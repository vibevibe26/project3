<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:32.3932</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.03.02</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0027689</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전자 장치 및 그 제어 방법</inventionTitle><inventionTitleEng>ELECTRONIC APPARATUS AND METHOD FOR CONTROLLING  THEREOF</inventionTitleEng><openDate>2022.09.13</openDate><openNumber>10-2022-0124022</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.02.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/372</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/291</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치가 개시된다. 본 개시에 따른 전자 장치는, 디스플레이, 사용자의 머리에 부착 가능한 복수의 센서 및 사용자의 컨텍스트 정보 또는 디스플레이를 통해 제공되는 컨텐츠에 대한 정보 중 적어도 하나를 신경망 모델에 입력하여 복수의 센서 중 적어도 하나의 센서를 식별하고, 식별된 적어도 하나의 센서로부터 센싱된 뇌파 신호에 기초하여 사용자 명령을 식별하고, 식별된 사용자 명령에 기초하여 컨텐츠를 제어하는 프로세서를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디스플레이;사용자의 머리에 부착 가능한 복수의 센서;상기 사용자의 컨텍스트 정보 또는 상기 디스플레이를 통해 제공되는 컨텐츠에 대한 정보 중 적어도 하나를 신경망 모델에 입력하여 상기 복수의 센서 중 적어도 하나의 센서를 식별하고,상기 식별된 적어도 하나의 센서로부터 센싱된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하고,상기 식별된 사용자 명령에 기초하여 상기 컨텐츠를 제어하는 프로세서;를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 복수의 센서 각각은, 상기 사용자의 머리에 대응되는 상이한 복수의 영역 각각에 부착되며,상기 복수의 영역은,전두엽에 대응되는 영역, 두정엽에 대응되는 영역, 후두엽에 대응되는 영역 또는 측두엽에 대응되는 영역을 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 컨텐츠에 대한 정보는,상기 컨텐츠가 시각 자극 컨텐츠인지 또는 청각 자극 컨텐츠인지에 대한 정보를 포함하며,상기 사용자의 컨텍스트 정보는,상기 사용자의 주변 소음 정보를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 프로세서는,상기 컨텐츠에 대한 정보에 기초하여 상기 컨텐츠가 상기 시각 자극 컨텐츠로 식별되면, 상기 복수의 센서 중 상기 신경망 모델에 의해 식별된 제1 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하며,상기 제1 센서는,상기 사용자의 머리에 대응되는 복수의 영역 중 후두엽에 대응되는 영역에 부착된, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 프로세서는,상기 컨텐츠에 대한 정보에 기초하여 상기 컨텐츠가 상기 청각 자극 컨텐츠로 식별되면, 상기 복수의 센서 중 상기 신경망 모델에 의해 식별된 제2 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하며,상기 제2 센서는,상기 사용자의 머리에 대응되는 복수의 영역 중 측두엽에 대응되는 영역에 부착된, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제3항에 있어서,상기 프로세서는,상기 사용자의 주변 소음 정보에 기초하여 상기 복수의 센서로부터 수신된 뇌파 신호 중 상기 측두엽에 대응되는 영역에 부착된 센서로부터 수신된 뇌파 신호를 제외한 나머지 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 프로세서는,사용자의 시각을 자극하는 가이드 컨텐츠를 출력하도록 상기 디스플레이를 제어하고,상기 가이드 컨텐츠가 출력되는 동안, 상기 복수의 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자의 머리에 대응되는 복수의 영역 중 임계 전극 이상의 뇌파 신호가 감지된 적어도 하나의 제1 영역을 식별하고,상기 컨텐츠에 대한 정보에 기초하여 상기 디스플레이를 통해 제공되는 컨텐츠가 시각 자극 컨텐츠로 식별되면, 상기 적어도 하나의 제1 영역에 부착된 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,스피커;를 더 포함하며,상기 프로세서는,사용자의 청각을 자극하는 가이드 컨텐츠를 출력하도록 상기 스피커를 제어하고,상기 가이드 컨텐츠가 출력되는 동안, 상기 복수의 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자의 머리에 대응되는 복수의 영역 중 임계 전극 이상의 뇌파 신호가 감지된 적어도 하나의 제2 영역을 식별하고,상기 컨텐츠에 대한 정보에 기초하여 상기 디스플레이를 통해 제공되는 컨텐츠가 청각 자극 컨텐츠로 식별되면, 상기 적어도 하나의 제2 영역에 부착된 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 사용자 명령은,상기 컨텐츠에 포함된 복수의 오브젝트 중 특정 오브젝트에 대한 선택 명령, 이동 명령, 입력될 문자 키 또는 상기 전자 장치에 대한 제어 명령 중 적어도 하나를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 프로세서는,상기 식별된 적어도 하나의 센서로부터 수신된 뇌파 신호의 파형을 식별하고,상기 식별된 파형에 기초하여 상기 사용자 명령을 식별하는, 전자 장치.</claim></claimInfo><claimInfo><claim>11. 사용자의 머리에 부착 가능한 복수의 센서를 포함하는 전자 장치의 제어 방법에 있어서,상기 사용자의 컨텍스트 정보 또는 상기 전자 장치를 통해 제공되는 컨텐츠에 대한 정보 중 적어도 하나를 신경망 모델에 입력하여 상기 복수의 센서 중 적어도 하나의 센서를 식별하는 단계;상기 식별된 적어도 하나의 센서로부터 센싱된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는 단계; 및상기 식별된 사용자 명령에 기초하여 상기 컨텐츠를 제어하는 단계;를 포함하는 제어 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 복수의 센서 각각은,상기 사용자의 머리에 대응되는 상이한 복수의 영역 각각에 부착되며,상기 복수의 영역은,전두엽에 대응되는 영역, 두정엽에 대응되는 영역, 후두엽에 대응되는 영역 또는 측두엽에 대응되는 영역을 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 컨텐츠에 대한 정보는,상기 컨텐츠가 시각 자극 컨텐츠인지 또는 청각 자극 컨텐츠인지에 대한 정보를 포함하며,상기 사용자의 컨텍스트 정보는,상기 사용자의 주변 소음 정보를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 사용자 명령을 식별하는 단계는,상기 컨텐츠에 대한 정보에 기초하여 상기 컨텐츠가 상기 시각 자극 컨텐츠로 식별되면, 상기 복수의 센서 중 상기 신경망 모델에 의해 식별된 제1 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는 단계;를 포함하며,상기 제1 센서는,상기 사용자의 머리에 대응되는 복수의 영역 중 후두엽에 대응되는 영역에 부착된, 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 사용자 명령을 식별하는 단계는,상기 컨텐츠에 대한 정보에 기초하여 상기 컨텐츠가 상기 청각 자극 컨텐츠로 식별되면, 상기 복수의 센서 중 상기 신경망 모델에 의해 식별된 제2 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는 단계;를 포함하며,상기 제2 센서는,상기 사용자의 머리에 대응되는 복수의 영역 중 측두엽에 대응되는 영역에 부착된, 제어 방법.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 사용자 명령을 식별하는 단계는,상기 사용자의 주변 소음 정보에 기초하여 상기 복수의 센서로부터 수신된 뇌파 신호 중 상기 측두엽에 대응되는 영역에 부착된 센서로부터 수신된 뇌파 신호를 제외한 나머지 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서,사용자의 시각을 자극하는 가이드 컨텐츠를 출력하는 단계; 및상기 가이드 컨텐츠가 출력되는 동안, 상기 복수의 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자의 머리에 대응되는 복수의 영역 중 임계 전극 이상의 뇌파 신호가 감지된 적어도 하나의 제1 영역을 식별하는 단계;를 더 포함하며,상기 사용자 명령을 식별하는 단계는,상기 컨텐츠에 대한 정보에 기초하여 상기 전자 장치를 통해 제공되는 컨텐츠가 시각 자극 컨텐츠로 식별되면, 상기 적어도 하나의 제1 영역에 부착된 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는 단계;를 포함하는, 제어 방법. </claim></claimInfo><claimInfo><claim>18. 제11항에 있어서,사용자의 청각을 자극하는 가이드 컨텐츠를 출력하는 단계; 및상기 가이드 컨텐츠가 출력되는 동안, 상기 복수의 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자의 머리에 대응되는 복수의 영역 중 임계 전극 이상의 뇌파 신호가 감지된 적어도 하나의 제2 영역을 식별하는 단계;를 더 포함하며,상기 사용자 명령을 식별하는 단계는,상기 컨텐츠에 대한 정보에 기초하여 상기 전자 장치를 통해 제공되는 컨텐츠가 청각 자극 컨텐츠로 식별되면, 상기 적어도 하나의 제2 영역에 부착된 센서로부터 수신된 뇌파 신호에 기초하여 상기 사용자 명령을 식별하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서,상기 사용자 명령은,상기 컨텐츠에 포함된 복수의 오브젝트 중 특정 오브젝트에 대한 선택 명령, 이동 명령, 입력된 문자 키 또는 상기 전자 장치에 대한 제어 명령 중 적어도 하나를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서,상기 사용자 명령을 식별하는 단계는,상기 식별된 적어도 하나의 센서로부터 수신된 뇌파 신호의 파형을 식별하는 단계; 및상기 식별된 파형에 기초하여 상기 사용자 명령을 식별하는 단계;를 포함하는, 제어 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>CHO, Keun Seok</engName><name>조근석</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Dong Seop</engName><name>이동섭</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Hyo Muk</engName><name>김효묵</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SON, Yu Sun</engName><name>손유선</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YANG, Do Jun</engName><name>양도준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HYUNG, Ji Won</engName><name>형지원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.03.02</receiptDate><receiptNumber>1-1-2021-0246662-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.02.29</receiptDate><receiptNumber>1-1-2024-0236603-66</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.02.29</receiptDate><receiptNumber>1-1-2024-0236645-73</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210027689.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93097abff9d43694e98ad2fff55ee526d31ea4e902e04b49f7168215c2c4159ab33348a0de8af6636cb362a3e43b29845b3ed42ba5cf73660a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf31c9e5a028c5f04ef2b7e5ad2cbf49c1c27456e38ebbcacaf7ffd5c5c043b31f0f862b0794577aca9d117a5293248ff4b1a026c5a425902b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>