<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:17.417</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.09.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0120169</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 생성 방법 및 장치 및 컴퓨터 판독 가능 저장 매체</inventionTitle><inventionTitleEng>IMAGE GENERATION METHOD AND DEVICE AND COMPUTER-READABLE  STORAGE MEDIUM</inventionTitleEng><openDate>2025.04.16</openDate><openNumber>10-2025-0051039</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/90</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4015</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 이미지 생성 방법 및 장치 및 컴퓨터 판독 가능 저장 매체에 관한 것으로, 이미지 생성 방법은, 제1 이미지를 획득하는 단계, 상기 제1 이미지를 기반으로, 텍스처 예측 모델을 통해 상기 제1 이미지에 대응하는 타겟 이미지의 텍스처 예측 정보를 획득하는 단계, 상기 제1 이미지를 기반으로, 색상 예측 모델을 통해 상기 타겟 이미지의 색상 예측 정보를 획득하는 단계 및 상기 텍스처 예측 정보 및 상기 색상 예측 정보에 따라, 상기 제1 이미지에 기초하여 상기 타겟 이미지를 생성하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 생성 방법에 있어서,제1 이미지를 획득하는 단계;상기 제1 이미지를 기반으로, 텍스처 예측 모델을 통해 상기 제1 이미지에 대응하는 타겟 이미지의 텍스처 예측 정보를 획득하는 단계;상기 제1 이미지를 기반으로, 색상 예측 모델을 통해 상기 타겟 이미지의 색상 예측 정보를 획득하는 단계; 및상기 텍스처 예측 정보 및 상기 색상 예측 정보에 따라, 상기 제1 이미지에 기초하여 상기 타겟 이미지를 생성하는 단계를 포함하고,상기 타겟 이미지의 형식은 상기 제1 이미지의 형식과 다른 것을 특징으로 하는이미지 생성 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 이미지를 기반으로, 상기 텍스처 예측 모델을 통해 상기 제1 이미지에 대응하는 상기 타겟 이미지의 텍스처 예측 정보를 획득하는 단계는,상기 텍스처 예측 모델의 제1 인코더를 통해 상기 제1 이미지를 인코딩하여 상기 제1 이미지의 이미지 인코딩 특징을 획득하는 단계;상기 텍스처 예측 모델의 제1 디코더를 통해 상기 제1 이미지의 이미지 인코딩 특징을 디코딩하여 제1 예측 이미지를 획득하는 단계; 및텍스처 추출 모듈을 통해, 상기 제1 예측 이미지에 대해 텍스처 추출 작업을 수행하여 상기 타겟 이미지의 텍스처 예측 정보를 획득하는 단계를 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 텍스처 예측 모델은, 상기 제1 인코더에 훈련 데이터를 입력하여 상기 훈련 데이터를 인코딩하여 상기 훈련 데이터의 이미지 인코딩 특징을 획득하는 단계;상기 이미지 인코딩 특징을 상기 텍스처 예측 모델의 상기 제1 디코더 및 상기 텍스처 예측 모델의 제2 디코더에 각각 입력하고, 상기 제1 디코더를 통해 상기 훈련 데이터에 대응하는 텍스처 예측 정보를 획득하고, 상기 제2 디코더를 통해 깊이 예측 정보를 획득하는 단계; 및상기 훈련 데이터에 대응하는 텍스처 예측 정보 및 상기 훈련 데이터에 대응하는 참조 이미지를 통해 상기 제1 인코더 및 상기 제1 디코더를 훈련하고, 획득된 상기 깊이 예측 정보 및 깊이 모델을 통해 획득된 깊이 맵을 기반으로 상기 제1 인코더 및 상기 제2 디코더를 훈련하는 단계를 통해서 훈련되고,상기 훈련 데이터는,상기 제1 이미지의 형식과 동일하고,상기 훈련 데이터 및 상기 참조 이미지는,서로 다른 이미지 센서에 의해서 획득되는이미지 생성 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 깊이 맵은, 상기 깊이 모델을 통해 상기 훈련 데이터에 대응하는 전체 장면에서 상대적 깊이 추정을 수행하여 상기 훈련 데이터에 대응하는 깊이 맵을 획득하는 단계를 통해서 획득되는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 제1 이미지를 기반으로, 상기 색상 예측 모델을 통해 상기 타겟 이미지의 색상 예측 정보를 획득하는 단계는,상기 제1 이미지를 기반으로 상기 색상 예측 모델의 제2 인코더를 통해 상기 제1 이미지의 특징을 추출하는 단계;상기 색상 예측 모델을 통해, 참조 이미지의 선험적 정보를 포함하는 이산 코드 테이블과 상기 제1 이미지의 특징을 일치시키는 단계;상기 색상 예측 모델의 제3 디코더를 통해 일치된 특징을 재구성하여 제2 예측 이미지를 생성하는 단계; 및상기 제2 예측 이미지에 대해 색 공간 변환을 수행하고, 상기 색 공간 변환으로 얻어진 결과 중 색상 성분을 상기 색상 예측 정보로 결정하는 단계를 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 색상 예측 모델은,상기 참조 이미지를 기반으로 상기 제3 디코더와 상기 이산 코드 테이블을 훈련하는 단계; 및훈련 데이터를 기반으로, 훈련된 상기 이산 코드 테이블과 상기 제3 디코더를 통해 상기 제2 인코더를 훈련하는 단계를 통해 훈련되어 얻어지고,상기 참조 이미지와 상기 훈련 데이터는,서로 다른 이미지 센서에 의해서 획득되는이미지 생성 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 참조 이미지를 기반으로 상기 제3 디코더와 상기 이산 코드 테이블을 훈련하는 단계는,상기 참조 이미지를 상기 제2 인코더에 입력하여 상기 참조 이미지의 특징을 추출하는 단계;상기 참조 이미지의 특징을 이전 이산 코드 테이블과 일치시키는 단계; 및상기 제3 디코더를 사용하여 일치된 특징을 재구성하고, 상기 참조 이미지 및 재구성 후 얻은 이미지에 따라 상기 이산 코드 테이블 및 상기 제3 디코더를 훈련하는 단계를 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 훈련 데이터를 기반으로, 훈련된 상기 이산 코드 테이블과 상기 제3 디코더를 통해 상기 제2 인코더를 훈련하는 단계는,상기 훈련 데이터를 상기 제2 인코더에 입력하여 상기 훈련 데이터의 특징을 추출하는 단계;상기 훈련 데이터의 특징을 훈련을 통해 얻은 상기 이산 코드 테이블과 일치시키는 단계; 및훈련하여 얻은 상기 제3 디코더를 사용하여 일치된 특징을 재구성하고, 상기 훈련 데이터에 대응하는 참조 이미지와 재구성 후 얻은 이미지에 따라 상기 제3 디코더를 훈련하는 단계를 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서, 상기 참조 이미지의 의미론적 정보를 획득하는 단계; 및상기 참조 이미지의 특징 중 이전 이산 코드 테이블과 일치하는 특징과 상기 의미론적 정보를 의미론적으로 일치시키는 단계를 더 포함하고,상기 제3 디코더를 사용하여 일치된 특징을 재구성하는 것은,상기 제3 디코더를 사용하여 의미론적 일치 후의 특징을 재구성하는 것을 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 텍스처 예측 정보 및 상기 색상 예측 정보에 따라, 상기 제1 이미지에 기초하여 상기 타겟 이미지를 생성하는 단계는,상기 텍스처 예측 정보 및 상기 색상 예측 정보에 대해 융합 처리를 진행하여 제1 융합 이미지를 획득하는 단계;상기 제1 융합 이미지에 따라 노출 추정 모델을 통해 제1 노출 파라미터를 획득하는 단계; 및상기 제1 노출 파라미터에 기초하여, 상기 제1 융합 이미지에 대해 노출 조정을 수행하여 상기 타겟 이미지를 획득하는 단계를 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 텍스처 예측 정보를 획득하는 단계 및 상기 색상 예측 정보를 획득하는 단계를 수행하기 전,각 색상 채널에 대해 상기 제1 이미지에 노출 정규화 처리를 수행하여 노출 정규화된 제1 이미지를 획득하는 단계를 더 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,노출 추정 모델을 통해 상기 제1 이미지에서 제2 노출 파라미터를 추정하는 단계를 더 포함하고,상기 텍스처 예측 정보 및 상기 색상 예측 정보에 따라, 상기 제1 이미지에 기초하여 상기 타겟 이미지를 생성하는 단계는,상기 텍스처 예측 정보 및 상기 색상 예측 정보에 기초하여, 상기 노출 정규화된 제1 이미지에 따라 노출 정규화된 제3 이미지를 생성하는 단계; 및상기 제2 노출 파라미터를 사용하여, 상기 노출 정규화된 제3 이미지에 대해 노출 조정을 수행하여 상기 타겟 이미지를 획득하는 단계를 포함하는 이미지 생성 방법.</claim></claimInfo><claimInfo><claim>13. 컴퓨터 판독가능 기록매체에 있어서,명령들을 저장하고,상기 명령들은, 하나 이상의 프로세서에 의하여 실행되는 경우, 제1항 내지 제12항의 방법을 수행하도록 하는컴퓨터 판독가능 기록매체.</claim></claimInfo><claimInfo><claim>14. 전자 장치에 있어서,하나 이상의 프로세서; 및명령들을 저장하는 메모리를 포함하고, 상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 전자 장치로 하여금,제1 이미지를 획득하는 단계;상기 제1 이미지를 기반으로, 텍스처 예측 모델을 통해 상기 제1 이미지에 대응하는 상기 제1 이미지의 형식과 다른 형식을 가진 타겟 이미지의 텍스처 예측 정보를 획득하는 단계;상기 제1 이미지를 기반으로, 색상 예측 모델을 통해 상기 타겟 이미지의 색상 예측 정보를 획득하는 단계; 및상기 텍스처 예측 정보 및 상기 색상 예측 정보에 따라, 상기 제1 이미지에 기초하여 상기 타겟 이미지를 생성하는 단계를 수행하도록 하는 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 전자 장치로 하여금,상기 제1 이미지를 기반으로, 상기 텍스처 예측 모델을 통해 상기 제1 이미지에 대응하는 상기 타겟 이미지의 텍스처 예측 정보를 획득하는 단계에서,상기 텍스처 예측 모델의 제1 인코더를 통해 상기 제1 이미지를 인코딩하여 상기 제1 이미지의 이미지 인코딩 특징을 획득하는 단계;상기 텍스처 예측 모델의 제1 디코더를 통해 상기 제1 이미지의 이미지 인코딩 특징을 디코딩하여 제1 예측 이미지를 획득하는 단계; 및텍스처 추출 모듈을 통해, 상기 제1 예측 이미지에 대해 텍스처 추출 작업을 수행하여 상기 타겟 이미지의 텍스처 예측 정보를 획득하는 단계를 수행하도록 하는 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 전자 장치로 하여금,상기 제1 이미지를 기반으로, 상기 색상 예측 모델을 통해 상기 타겟 이미지의 색상 예측 정보를 획득하는 단계에서,상기 제1 이미지를 기반으로 상기 색상 예측 모델의 제2 인코더를 통해 상기 제1 이미지의 특징을 추출하는 단계;상기 색상 예측 모델을 통해, 참조 이미지의 선험적 정보를 포함하는 이산 코드 테이블과 상기 제1 이미지의 특징을 일치시키는 단계;상기 색상 예측 모델의 제3 디코더를 통해 일치된 특징을 재구성하여 제2 예측 이미지를 생성하는 단계; 및상기 제2 예측 이미지에 대해 색 공간 변환을 수행하고, 상기 색 공간 변환으로 얻어진 결과 중 색상 성분을 상기 색상 예측 정보로 결정하는 단계를 수행하도록 하는 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 전자 장치로 하여금,상기 텍스처 예측 정보 및 상기 색상 예측 정보에 따라, 상기 제1 이미지에 기초하여 상기 타겟 이미지를 생성하는 단계에서,상기 텍스처 예측 정보 및 상기 색상 예측 정보에 대해 융합 처리를 진행하여 제1 융합 이미지를 획득하는 단계;상기 제1 융합 이미지에 따라 노출 추정 모델을 통해 제1 노출 파라미터를 획득하는 단계; 및상기 제1 노출 파라미터에 기초하여, 상기 제1 융합 이미지에 대해 노출 조정을 수행하여 상기 타겟 이미지를 획득하는 단계를 수행하도록 하는 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제14항에 있어서,상기 명령들은, 상기 하나 이상의 프로세서에 의하여 실행되는 경우, 상기 전자 장치로 하여금,상기 텍스처 예측 정보를 획득하는 단계 및 상기 색상 예측 정보를 획득하는 단계를 수행하기 전,각 색상 채널에 대해 상기 제1 이미지에 노출 정규화 처리를 수행하여 노출 정규화된 제1 이미지를 획득하는 단계를 수행하도록 하는 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중화인민공화국 ****** 베이징 차오양...</address><code> </code><country> </country><engName>lu xu</engName><name>루 쉬</name></inventorInfo><inventorInfo><address>중화인민공화국 ****** 베이징 차오양...</address><code> </code><country> </country><engName>Chao Zhang</engName><name>차오 장</name></inventorInfo><inventorInfo><address>중화인민공화국 ****** 베이징 차오양...</address><code> </code><country> </country><engName>yasi wang</engName><name>야시 왕</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420180786048</code><country>대한민국</country><engName>LEE, Hyong Euk</engName><name>이형욱</name></inventorInfo><inventorInfo><address>중화인민공화국 ****** 베이징 차오양...</address><code> </code><country> </country><engName>Qiang Wang</engName><name>창 왕</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2023.10.09</priorityApplicationDate><priorityApplicationNumber>202311303919.3</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.09.04</receiptDate><receiptNumber>1-1-2024-0972901-20</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.09.26</receiptDate><receiptNumber>9-1-2024-9010389-42</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.09.27</receiptDate><receiptNumber>9-1-2024-9010537-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.09.27</receiptDate><receiptNumber>9-1-2024-9010538-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.10.10</receiptDate><receiptNumber>9-1-2024-9011003-13</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240120169.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93401a2e7adddf7d04cb86196b1ac3238f815e1de500ea04fd7b8b5e1316b305a53869ee734190193e275481f3096945c199b247b6d360d1f8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6fcfb3fce306d9c6324f64e4718e045d7c2388c4592fc689ef07aa531ad98995b8a0c69aed68ab3cdece167f01b841aca110e53e7102623d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>