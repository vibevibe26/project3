<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:22.4022</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.03.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7035724</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신경망 제어 변량들</inventionTitle><inventionTitleEng>NEURAL NETWORK CONTROL VARIATES</inventionTitleEng><openDate>2024.11.29</openDate><openNumber>10-2024-0168402</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.25</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.10.25</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 장면의 3D 모델을 생성하기 위한 동작들을 수행하기 위한 방법들 및 시스템들이 개시된다. 동작들은: 실세계 환경의 제1 뷰를 표현하는 2차원(2D) 이미지들의 세트를 수신하는 것; 실세계 환경의 제2 뷰를 표현하는 타겟 이미지의 픽셀 값들을 예측하기 위해 2D 이미지들의 세트에 신경 광 필드 네트워크를 포함하는 머신러닝 모델을 적용하는 것 - 머신러닝 모델은 광선 원점 및 방향을 주어진 픽셀 값에 직접 매핑하도록 훈련됨 -; 및 2D 이미지들의 세트 및 예측된 타겟 이미지에 기초하여 실세계 환경의 3차원(3D) 모델을 생성하는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.10.05</internationOpenDate><internationOpenNumber>WO2023192231</internationOpenNumber><internationalApplicationDate>2023.03.28</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/016507</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 실세계 환경의 제1 뷰를 표현하는 2차원(2D) 이미지들의 세트를 수신하는 단계;상기 하나 이상의 프로세서에 의해, 상기 실세계 환경의 제2 뷰를 표현하는 타겟 이미지의 픽셀 값들을 예측하기 위해 신경 광 필드 네트워크(neural light field network)를 포함하는 머신러닝 모델을 상기 2D 이미지들의 세트에 적용하는 단계 - 상기 머신러닝 모델은 광선(ray) 원점 및 방향을 주어진 픽셀 값에 직접 매핑하도록 훈련됨 -; 및상기 하나 이상의 프로세서에 의해, 상기 2D 이미지들의 세트 및 예측된 타겟 이미지에 기초하여 상기 실세계 환경의 3차원(3D) 모델을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 머신러닝 모델은 심층 잔차(deep residual) 다층 퍼셉트론(Multi-Layer Perceptron)(MLP) 네트워크를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 실세계 환경의 상기 제2 뷰와 연관된 광선 원점 및 방향을 선택하는 단계;상기 실세계 환경의 상기 제1 뷰를 표현하는 상기 2D 이미지들의 세트의 주어진 2D 이미지를 사용하여, 상기 실세계 환경의 상기 제2 뷰에 대응하는 광선 원점 및 방향에 기초하여 광선을 생성하는 단계; 및상기 광선을 따른 복수의 포인트를 샘플링하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 복수의 포인트들은 상기 광선을 따라 균일하게 이격되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제3항 또는 제4항에 있어서, 상기 복수의 포인트들은 상기 머신러닝 모델의 훈련 동안 계층화된 샘플링(stratified sampling)에 기초하여 랜덤하게 샘플링되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제3항 내지 제5항 중 어느 한 항에 있어서,상기 복수의 포인트를 연결하여 입력 데이터를 생성하는 단계; 및상기 2D 타겟 이미지의 픽셀 값들 중 하나를 예측하기 위해 상기 머신러닝 모델로 상기 입력 데이터를 처리하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,훈련 이미지들 및 연관된 카메라 포즈들을 포함하는 훈련 데이터를 수신하는 단계 - 상기 훈련 이미지들 및 연관된 카메라 포즈들은 복수의 훈련 광선 원점들 및 정규화된 광선 방향들 및 대응하는 실측(ground-truth) 픽셀 값들과 연관됨 -;상기 훈련 이미지들 및 연관된 카메라 포즈의 제1 훈련 이미지의 상기 훈련 광선 원점 및 정규화된 광선 방향을 획득하는 단계;훈련 픽셀 값을 예측하기 위해 상기 훈련 광선 원점 및 정규화된 광선 방향에 의해 형성된 훈련 광선을 따른 포인트들의 세트에 상기 머신러닝 모델을 적용하는 단계;상기 제1 훈련 이미지와 연관된 상기 실측 픽셀 값을 검색(retrieve)하는 단계;예측된 훈련 픽셀 값과 상기 실측 픽셀 값 사이의 편차를 계산하는 단계; 및상기 편차에 기초하여 상기 머신러닝 모델의 하나 이상의 파라미터를 업데이트하는 단계를 포함하는, 동작들을 수행함으로써 상기 머신러닝 모델을 훈련하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 머신러닝 모델은 제1 머신러닝 모델을 포함하고, 상기 훈련 데이터를 생성하기 위해 2D 이미지들의 컬렉션에 제2 머신러닝 모델을 적용하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 제2 머신러닝 모델은 훈련된 신경 방사휘도 필드 네트워크(neural radiance field network)를 포함하고, 상기 신경 방사휘도 필드 네트워크는 특정 광선에 대응하는 샘플링된 포인트의 방사휘도를 표현하는 출력을 생성하도록 구성되고, 상기 특정 광선의 픽셀 값은 각각의 방사휘도 값들에 대응하는 상기 특정 광선을 따른 샘플링된 포인트를 포함하는 복수의 포인트의 알파-컴포지션을 통해 생성되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 2D 이미지들의 컬렉션의 제1 2D 이미지를 수신하는 단계;상기 제1 2D 이미지에 기초하여, 상기 제1 2D 이미지와 상이한 카메라 포즈와 연관된 제2 2D 이미지와 연관된 카메라 포즈의 광선 원점 및 정규화된 방향을 선택하는 단계;상기 제2 머신 러닝 모델을 상기 제2 2D 이미지와 연관된 카메라 포즈의 광선 원점 및 정규화된 방향에 적용하여 상기 제2 2D 이미지에 대한 픽셀 값을 예측하는 단계를 추가로 포함하고, 상기 제2 머신 러닝 모델을 적용하는 단계는:상기 제2 2D 이미지와 연관된 상기 카메라 포즈의 상기 광선 원점 및 정규화된 방향에 의해 형성된 광선을 따른 복수의 포인트 각각에 상기 제2 머신 러닝 모델을 적용하여 복수의 방사휘도 값을 생성하는 단계; 및상기 제2 2D 이미지에 대한 픽셀 값을 예측하기 위해 상기 복수의 방사휘도 값들의 알파-컴포지션을 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 카메라 포즈의 상기 광선 원점 및 정규화된 방향은 균일한 분포에 기초하여 랜덤하게 선택되는, 방법.</claim></claimInfo><claimInfo><claim>12. 제10항 또는 제11항에 있어서, 상기 훈련 데이터는 상기 2D 이미지들의 컬렉션을 배제하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서,상기 훈련 데이터에 대해 복수의 손실들을 생성하는 단계;상기 복수의 손실들을 오름차순으로 정렬하는 단계; 및지정된 임계치를 초과하는 정렬된 복수의 손실들에서의 샘플들의 수를 식별하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 샘플들의 수에 대응하는 추가적인 훈련 데이터로 상기 훈련 데이터를 증강시키는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 실세계 환경의 상기 3D 모델에 기초하여 상기 2D 이미지들의 세트를 포함하는 비디오 내에 클라이언트 디바이스 상에서 증강 현실 또는 가상 현실 경험과 연관된 가상 요소를 디스플레이하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 시스템으로서,클라이언트 디바이스의 프로세서; 및상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하는 명령어들을 저장하고 있는 메모리 컴포넌트를 포함하고, 상기 동작들은:실세계 환경의 제1 뷰를 표현하는 2차원(2D) 이미지들의 세트를 수신하는 단계;상기 실세계 환경의 제2 뷰를 표현하는 타겟 이미지의 픽셀 값들을 예측하기 위해 신경 광 필드 네트워크를 포함하는 머신러닝 모델을 상기 2D 이미지들의 세트에 적용하는 단계 - 상기 머신러닝 모델은 광선 원점 및 방향을 주어진 픽셀 값에 직접 매핑하도록 훈련됨 -; 및상기 2D 이미지들의 세트 및 예측된 타겟 이미지에 기초하여 상기 실세계 환경의 3차원(3D) 모델을 생성하는 단계를 포함하는, 시스템. </claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 동작들은:상기 실세계 환경의 상기 제2 뷰와 연관된 광선 원점 및 방향을 선택하는 단계;상기 실세계 환경의 상기 제1 뷰를 표현하는 상기 2D 이미지들의 세트의 주어진 2D 이미지를 사용하여, 상기 실세계 환경의 상기 제2 뷰에 대응하는 광선 원점 및 방향에 기초하여 광선을 생성하는 단계; 및상기 광선을 따른 복수의 포인트를 샘플링하는 단계를 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제16항 또는 제17항에 있어서, 상기 복수의 포인트는 상기 광선을 따라 균등하게 이격되는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제16항 내지 제18항 중 어느 한 항에 있어서, 상기 복수의 포인트들은 상기 머신러닝 모델의 훈련 동안 계층화된 샘플링에 기초하여 랜덤하게 샘플링되는, 시스템.</claim></claimInfo><claimInfo><claim>20. 클라이언트 디바이스의 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하는 명령어들을 저장한 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 동작들은:실세계 환경의 제1 뷰를 표현하는 2차원(2D) 이미지들의 세트를 수신하는 단계;상기 실세계 환경의 제2 뷰를 표현하는 타겟 이미지의 픽셀 값들을 예측하기 위해 신경 광 필드 네트워크를 포함하는 머신러닝 모델을 상기 2D 이미지들의 세트에 적용하는 단계 - 상기 머신러닝 모델은 광선 원점 및 방향을 주어진 픽셀 값에 직접 매핑하도록 훈련됨 -; 및상기 2D 이미지들의 세트 및 상기 예측된 타겟 이미지에 기초하여 상기 실세계 환경의 3차원(3D) 모델을 생성하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>HUANG, Zeng</engName><name>황, 젱</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>REN, Jian</engName><name>렌, 지안</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>TULYAKOV, Sergey</engName><name>툴리아코브, 세르게이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>CHAI, Menglei</engName><name>차이, 멘글레이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>OLSZEWSKI, Kyle</engName><name>올제브스키, 카일</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>WANG, Huan</engName><name>왕, 후안</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.28</priorityApplicationDate><priorityApplicationNumber>17/656,778</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.10.25</receiptDate><receiptNumber>1-1-2024-1167070-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.10.25</receiptDate><receiptNumber>1-1-2024-1168149-33</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.10.30</receiptDate><receiptNumber>1-5-2024-0175265-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.07.10</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247035724.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c939efac6067b2e79e0ae386cd30542c53a17887e7bb14ff9565b4293cc8e2e68ba362d51d7f4d6b61e0ff5003d0efbe816eaca84cf47afa448</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfddbfe5338543550f0f47fdfe9d73b8188d69e6e44777f61a501fc759881e12c3c9f530944b924448540c8a46b155f8db82de0fddcaa524a0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>