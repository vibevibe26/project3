<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:08:23.823</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.03.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7033483</applicationNumber><claimCount>26</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>얼굴 표정, 신체 자세 형상 및 의류 퍼포먼스 캡처를 위해 암시적 구별가능 렌더러를 사용하는 멀티뷰 신경 사람 예측</inventionTitle><inventionTitleEng>MULTIVIEW NEURAL HUMAN PREDICTION USING IMPLICIT DIFFERENTIABLE RENDERER FOR FACIAL EXPRESSION, BODY POSE SHAPE AND CLOTHES PERFORMANCE CAPTURE</inventionTitleEng><openDate>2023.10.31</openDate><openNumber>10-2023-0150867</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.09.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.09.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/766</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/422</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/55</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 신경 사람 활동 캡처 프레임워크(MVS-PERF)는 교정된 멀티뷰 이미지들의 세트로부터 골격, 신체 형상 및 의류 변위, 및 사람의 외관을 캡처한다. 이것은 단안(monocular) 사람 메쉬 복구에서 절대 위치를 예측하는 모호성을 해결하고, NeRF로부터의 볼륨 표현과 애니메이션-친화적 퍼포먼스 캡처에 가교 역할을 한다. MVS-PERF는 멀티뷰 이미지들로부터 피쳐 맵들을 추출하고 이들을 피쳐 볼륨에 융합하고, 피쳐 볼륨을 벌거벗은 사람 파라미터 벡터로 회귀시켜, 골격 자세, 신체 형상, 및 표정을 갖는 SMPL-X 피부 밀착 신체 메쉬를 생성하며, 신경 래디언스 필드 및 변형 필드를 활용하여, 구별 가능한 렌더링을 사용함으로써 벌거벗은 신체 상의 변위로서 의류를 추론하기 위한 3개의 모듈을 포함한다. SMPL-X 피부 밀착 신체 메쉬 정점들에 보간된 변위 벡터들을 추가함으로써 의류를 입은 신체 메쉬가 취득된다. 획득된 래디언스 필드는 입력 피사체의 프리-뷰(free-view) 볼륨 렌더링을 위해 사용된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.10.06</internationOpenDate><internationOpenNumber>WO2022208440</internationOpenNumber><internationalApplicationDate>2022.03.31</internationalApplicationDate><internationalApplicationNumber>PCT/IB2022/053034</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디바이스의 비일시적으로 프로그래밍되는 방법으로서,이미지들의 세트를 입력으로서 취득하는 단계; 및신경 네트워크를 이용하여 상기 이미지들의 세트를 처리하는 단계를 포함하고, 상기 처리하는 단계는: 상기 이미지들의 세트를 하나 이상의 피쳐(feature)로 인코딩하는 단계; 상기 피쳐들을 사람 파라미터들로 회귀(regressing)시키는 단계; 상기 신경 네트워크를 미세 조정하는 단계; 및  쿼리(query) 3D 광선을 RGB 색상 및 의류-대-신체 변위(clothes-to-body displacement)로 디코딩하는 단계 - 상기 RGB 색상은 상기 이미지들의 세트에 기초함 -를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 이미지들의 세트는 크기 의 4D 텐서(tensor)를 포함하고, N은 뷰들의 수이고, w는 이미지의 폭이고, h는 상기 이미지의 높이이고, c는 상기 이미지의 채널인, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 신경 네트워크는 상기 이미지들의 세트로부터 기준 뷰로서 정면 뷰를 선택하고 피쳐 볼륨을 추출하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 신경 네트워크는 모든 피쳐 볼륨들을 사람의 자세, 형상, 얼굴 표정 파라미터들로 회귀시키는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 신경 네트워크는 상기 파라미터들에 따라 사람의 벌거벗은 신체 메쉬(human naked body mesh)를 생성하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 벌거벗은 신체 메쉬는 바운딩 박스(bounding box)에서 점유 필드(occupancy field)로 변환되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 신경 네트워크는 각각의 뷰 중심으로부터의 광선 방향들과 연관된, 상기 신체 메쉬 근처의 임의의 3D 포인트에 대해 벌거벗은 신체의 표면을 가리키는 3D 변위 벡터 및 RGB 색상을 생성하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 의류를 입은 사람 신체(clothed human body)의 외관(appearance)은 카메라 뷰의 모든 픽셀들로부터 방사(shooting)한 모든 광선을 쿼리함으로써 RGB 이미지로서 렌더링되고, 상기 의류를 입은 신체 메쉬는 샘플링된 포인트들로부터 상기 3D 변위 벡터들을 이용하여 상기 벌거벗은 신체를 변형시킴으로써 획득되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 신경 네트워크는 감독 모드(supervision mode) 또는 자체-감독 모드(self-supervision mode)로 구현되는, 방법.</claim></claimInfo><claimInfo><claim>10. 장치로서,애플리케이션을 저장하도록 구성된 비일시적인 메모리; 및 상기 애플리케이션을 처리하도록 구성된 프로세서를 포함하고, 상기 어플리케이션은:이미지들의 세트를 입력으로서 취득하고;신경 네트워크를 이용하여 상기 이미지들의 세트를 처리하도록 구성되고, 상기 처리는:  상기 이미지들의 세트를 하나 이상의 피쳐로 인코딩하는 단계;  상기 피쳐들을 사람 파라미터들로 회귀시키는 단계;  상기 신경 네트워크를 미세 조정하는 단계; 및   쿼리 3D 광선을 RGB 색상 및 의류-대-신체 변위로 디코딩하는 단계 - 상기 RGB 색상은 상기 이미지들의 세트에 기초함 - 를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 이미지들의 세트는 크기 의 4D 텐서를 포함하고, N은 뷰들의 수고, w는 이미지의 폭이고, h는 상기 이미지의 높이이고, c는 상기 이미지의 채널인, 장치.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 신경 네트워크는 상기 이미지들의 세트로부터 기준 뷰로서 정면 뷰를 선택하고 피쳐 볼륨을 추출하는, 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 신경 네트워크는 모든 피쳐 볼륨들을 사람의 자세, 형상, 얼굴 표정 파라미터들로 회귀시키는, 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 신경 네트워크는 상기 파라미터들에 따라 사람의 벌거벗은 신체 메쉬를 생성하는, 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 벌거벗은 신체 메쉬는 바운딩 박스에서 점유 필드로 변환되는, 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 신경 네트워크는 각각의 뷰 중심으로부터의 광선 방향들과 연관된, 상기 신체 메쉬 근처의 임의의 3D 포인트에 대해 벌거벗은 신체의 표면을 가리키는 3D 변위 벡터 및 RGB 색상을 생성하는, 장치.  </claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 의류를 입은 사람 신체의 외관은 카메라 뷰의 모든 픽셀로부터 방사한 모든 광선을 쿼리함으로써 RGB 이미지로서 렌더링되고, 상기 의류를 입은 신체 메쉬는 샘플링된 포인트들로부터 상기 3D 변위 벡터들을 이용하여 상기 벌거벗은 신체를 변형시킴으로써 획득되는, 장치.</claim></claimInfo><claimInfo><claim>18. 제10항에 있어서, 상기 신경 네트워크는 감독 모드 또는 자체-감독 모드로 구현되는, 장치.</claim></claimInfo><claimInfo><claim>19. 장치로서,애플리케이션을 저장하도록 구성된 비일시적인 메모리; 및 상기 애플리케이션을 처리하도록 구성된 프로세서를 포함하고, 상기 어플리케이션은:입력 이미지 세트를 피쳐들로 인코딩하도록 구성된 멀티뷰 스테레오 3D 컨볼루셔널 신경 네트워크(multiview stereo 3D convolutional neural network) (MVS-3DCNN);상기 피쳐들을 사람 파라미터들로 회귀시키도록 구성된 사람 메쉬 복구 다층 퍼셉트론(human mesh recovery multilayer perceptron)(HMR MLP); 및 상기 MVS-3DCNN을 미세-조정하도록 구성되고 쿼리 3D 광선(3D 위치 및 방향)을 RGB 색상 및 의류-대-신체 변위로 디코딩하는 신경 래디언스 필드 다층 퍼셉트론(neural radiance field multilayer perceptron)(NeRF MLP); 을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 이미지들의 세트는 크기 의 4D 텐서를 포함하고, N은 뷰들의 수고, w는 이미지의 폭이고, h는 상기 이미지의 높이이고, c는 상기 이미지의 채널인, 장치.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 MVS-3DCNN은 상기 이미지들의 세트로부터 기준 뷰로서 정면 뷰를 선택하고 피쳐 볼륨을 추출하는, 장치.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 HMR MLP는 모든 피쳐 볼륨들을 사람의 자세, 형상, 얼굴 표정 파라미터들로 회귀시키는, 장치.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 파라미터들에 따라 사람의 벌거벗은 신체 메쉬를 생성하도록 구성된 모델을 더 포함하는, 장치.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 벌거벗은 신체 메쉬는 바운딩 박스에서 점유 필드로 변환되는, 장치.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 NeRF MLP는 각각의 뷰 중심으로부터의 광선 방향들과 연관된, 상기 신체 메쉬 근처의 임의의 3D 포인트에 대해 벌거벗은 신체의 표면을 가리키는 3D 변위 벡터 및 RGB 색상을 생성하는, 장치.  </claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 의류를 입은 사람 신체의 외관은 카메라 뷰의 모든 픽셀로부터 방사한 모든 광선을 쿼리함으로써 RGB 이미지로서 렌더링되고, 상기 의류를 입은 신체 메쉬는 샘플링된 포인트들로부터 상기 3D 변위 벡터들을 이용하여 상기 벌거벗은 신체를 변형시킴으로써 획득되는, 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>일본국 도쿄도 미나토쿠 코난 *-*-*</address><code>519980961547</code><country>일본</country><engName>Sony Group Corporation</engName><name>소니그룹주식회사</name></applicantInfo><applicantInfo><address>미국 ***** 뉴욕주 뉴욕 매디슨 애비뉴 **</address><code>519980693859</code><country>미국</country><engName>Sony Corporation of America</engName><name>소니 코포레이션 오브 아메리카</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아주 산호...</address><code> </code><country> </country><engName>ZHANG, Qing</engName><name>장 칭</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 로스 앤젤레...</address><code> </code><country> </country><engName>XIAO, Hanyuan</engName><name>샤오 한위안</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990002028</code><country>대한민국</country><engName>LEE, JUNG HEE</engName><name>이중희</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.03.31</priorityApplicationDate><priorityApplicationNumber>63/168,467</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.11.16</priorityApplicationDate><priorityApplicationNumber>63/279,916</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.23</priorityApplicationDate><priorityApplicationNumber>17/701,991</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.09.27</receiptDate><receiptNumber>1-1-2023-1075296-43</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.10.05</receiptDate><receiptNumber>1-5-2023-0157321-68</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237033483.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93fb127dce8357bc7773c3d7260f00b7a649241e74e5dadc1209067c35c8ee2cb2d3537c641223fb77a934611f76be0c2a5507c35722e1c96b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf16782a4fbaa0b5cdd4a7a768275d70ff4b1167481b26e6ba846d5e323f03e9e6dcf8e62fbfbe4523859e90c6c3d39acd23534ea961614ff9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>