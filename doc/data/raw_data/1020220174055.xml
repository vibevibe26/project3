<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:14.614</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0174055</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>화면을 투사하는 동안 외부 객체를 식별하기 위한 전자 장치 및 그 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE FOR IDENTIFYING EXTERNAL OBJECT  WHILE PROJECTING SCREEN AND METHOD THEREOF</inventionTitleEng><openDate>2024.06.20</openDate><openNumber>10-2024-0088393</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04845</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04842</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0481</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06V 10/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/327</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시 예에 따른, 전자 장치의 프로세서는, 프로젝션 어셈블리를 제어하여, 인터페이스를 통해 획득된 화면을 투사할 수 있다. 상기 프로세서는, 프로젝션 어셈블리에 의해 표시 영역이 형성되는 일 면 상의 접촉 점의 식별이 요구되는 상기 화면이 투사되는 상태 내에서, 상기 프로젝션 어셈블리의 제1 방향과 상이한 제2 방향을 향하여 배치된 카메라를 활성화할 수 있다. 상기 프로세서는, 상기 활성화된 카메라를 이용하여 획득된 정보로부터 외부 객체를 식별하는 것에 응답하여, 상기 화면의 사이즈를, 상기 일 면에 대한 상기 외부 객체의 위치에 기반하여 변경할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치(101)(electronic device)에 있어서,  인터페이스;  카메라(220);  프로젝션 어셈블리(120)(projection assembly); 및  하나 이상의 프로세서들(210)을 포함하고,  상기 하나 이상의 프로세서들(210)은,  상기 프로젝션 어셈블리(120)를 제어하여, 상기 인터페이스를 통해 획득된 화면을 투사하고;  상기 프로젝션 어셈블리(120)에 의해 표시 영역이 형성되는 일(one) 면 상의 접촉 점(contact point)의 식별이 요구되는 상기 화면이 투사되는 상태 내에서, 상기 프로젝션 어셈블리(120)의 제1 방향과 상이한 제2 방향을 향하여 배치된 상기 카메라(220)를 활성화하고; 및  상기 활성화된 카메라(220)를 이용하여 획득된 정보로부터 외부 객체(105)를 식별하는 것에 응답하여, 상기 화면의 사이즈를, 상기 일 면(310)에 대한 상기 외부 객체(105)의 위치에 기반하여 변경하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,  상기 하나 이상의 프로세서들(210)은,  상기 카메라(220)에 기반하여, 상기 화면에 대한 상기 외부 객체(105)의 입력을 식별하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,  상기 하나 이상의 프로세서들(210)은,  상기 카메라(220)를 이용하여 상기 외부 객체(105)의 일부 및 상기 일 면(310) 사이의 거리를 식별하고; 및  상기 거리를 식별한 것에 기반하여, 상기 접촉 점을 식별하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,  자이로 센서(231)를 더 포함하고,  상기 하나 이상의 프로세서들(210)은,  상기 자이로 센서(231)에 기반하여, 상기 접촉 점의 식별이 요구되는 상기 화면이 투사되는 상기 상태를 식별하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,  상기 하나 이상의 프로세서들(210)은,  상기 외부 객체(105)의 지정된 모션을 식별한 것에 기반하여, 상기 화면을 투사하기 위한 제1 소프트웨어 어플리케이션과 상이한 제2 소프트웨어 어플리케이션을 실행하고; 및  상기 제1 소프트웨어 어플리케이션과 관련된 제1 화면 및 상기 제2 소프트웨어 어플리케이션과 관련된 제2 화면을 투사하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,  상기 하나 이상의 프로세서들(210)은,  상기 제1 화면 및 상기 제2 화면을 투사한 상태 내에서, 상기 외부 객체(105) 및 상기 일 면(310) 사이의 지정된 임계치 미만의 거리를 식별한 것에 기반하여, 상기 제1 소프트웨어 어플리케이션 및 상기 제2 소프트웨어 어플리케이션의 종료와 관련된 시각적 객체들을 투사하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서,  상기 하나 이상의 프로세서들(210)은,  상기 외부 객체(105) 및 상기 일 면(310) 사이의 지정된 임계치 이상의 거리를 식별한 것에 기반하여, 상기 종료와 관련된 시각적 객체들의 투사를 중단하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>8. 제5 항에 있어서,  상기 하나 이상의 프로세서들(210)은,  상기 제1 화면 및 상기 제2 화면 사이에 형성된 경계 선(border line)에 기반하여, 상기 제1 화면 및 상기 제2 화면의 사이즈를 조절하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,  자이로 센서(231); 및  ToF(time-of-flight) 센서를 더 포함하고,  상기 하나 이상의 프로세서들(210)은,  제1 상태인 상기 상태와 상이한 제2 상태 내에서, 상기 자이로 센서(231)에 기반하여 식별된 상기 프로젝션 어셈블리(120)의 제1 방향에 기반하여, 상기 ToF 센서를 이용하여 상기 외부 객체(105)를 식별하도록, 구성된,  전자 장치(101).  </claim></claimInfo><claimInfo><claim>10. 전자 장치(101)(electronic device)의 방법에 있어서,  프로젝션 어셈블리(120)를 제어하여, 인터페이스를 통해 획득된 화면을 투사하는 동작;  상기 프로젝션 어셈블리(120)에 의해 표시 영역이 형성되는 일(one) 면 상의 접촉 점(contact point)의 식별이 요구되는 상기 화면이 투사되는 상태 내에서, 상기 프로젝션 어셈블리(120)의 제1 방향과 상이한 제2 방향을 향하여 배치된 카메라(220)를 활성화하는 동작; 및  상기 활성화된 카메라(220)를 이용하여 획득된 정보로부터 외부 객체(105)를 식별하는 것에 응답하여, 상기 화면의 사이즈를, 상기 일 면(310)에 대한 상기 외부 객체(105)의 위치에 기반하여 변경하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  상기 카메라(220)에 기반하여, 상기 화면에 대한 상기 외부 객체(105)의 입력을 식별하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  상기 카메라(220)를 이용하여 상기 외부 객체(105)의 일부 및 상기 일 면(310) 사이의 거리를 식별하는 동작; 및  상기 거리를 식별한 것에 기반하여, 상기 접촉 점을 식별하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>13. 제10 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  자이로 센서(231)에 기반하여, 상기 접촉 점의 식별이 요구되는 상기 화면이 투사되는 상기 상태를 식별하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>14. 제10 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  상기 외부 객체(105)의 지정된 모션을 식별한 것에 기반하여, 상기 화면을 투사하기 위한 제1 소프트웨어 어플리케이션과 상이한 제2 소프트웨어 어플리케이션을 실행하고; 및  상기 제1 소프트웨어 어플리케이션과 관련된 제1 화면 및 상기 제2 소프트웨어 어플리케이션과 관련된 제2 화면을 투사하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  상기 제1 화면 및 상기 제2 화면을 투사한 상태 내에서, 상기 외부 객체(105) 및 상기 일 면(310) 사이의 지정된 임계치 미만의 거리를 식별한 것에 기반하여, 상기 제1 소프트웨어 어플리케이션 및 상기 제2 소프트웨어 어플리케이션의 종료와 관련된 시각적 객체를 투사하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  상기 외부 객체(105) 및 상기 일 면(310) 사이의 지정된 임계치 이상의 거리를 식별한 것에 기반하여, 상기 종료와 관련된 시각적 객체의 투사를 중단하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>17. 제14 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  상기 제1 화면 및 상기 제2 화면 사이에 형성된 경계 선(border line)에 기반하여, 상기 제1 화면 및 상기 제2 화면의 사이즈를 조절하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>18. 제10 항에 있어서,  상기 전자 장치(101)의 상기 방법은,  제1 상태인 상기 상태와 상이한 제2 상태 내에서, 자이로 센서(231)에 기반하여 식별된 상기 프로젝션 어셈블리(120)의 제1 방향에 기반하여, ToF 센서를 이용하여 상기 외부 객체(105)를 식별하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>19. 하나 이상의 프로그램들이 저장된 컴퓨터 판독가능 저장 매체에 있어서,  상기 하나 이상의 프로그램들은, 전자 장치(101)(electronic device)의 프로세서(210)에 의해 실행될 때에,  프로젝션 어셈블리(120)를 제어하여, 인터페이스를 통해 획득된 화면을 투사하고;  상기 프로젝션 어셈블리(120)에 의해 표시 영역이 형성되는 일(one) 면 상의 접촉 점(contact point)의 식별이 요구되는 상기 화면이 투사되는 상태 내에서, 상기 프로젝션 어셈블리(120)의 제1 방향과 상이한 제2 방향을 향하여 배치된 카메라(220)를 활성화하고; 및  상기 활성화된 카메라(220)를 이용하여 획득된 정보로부터 외부 객체(105)를 식별하는 것에 응답하여, 상기 화면의 사이즈를 상기 일 면(310)에 대한 상기 외부 객체(105)의 위치에 기반하여 변경하도록, 상기 전자 장치(101)의 상기 프로세서(210)를 야기하는,  컴퓨터 판독가능 저장 매체.  </claim></claimInfo><claimInfo><claim>20. 제19 항에 있어서,  상기 하나 이상의 프로그램들은, 상기 전자 장치(101)의 상기 프로세서(210)에 의해 실행될 때에,  상기 카메라(220)에 기반하여, 상기 화면에 대한 상기 외부 객체(105)의 입력을 식별하도록, 상기 전자 장치(101)의 상기 프로세서(210)를 야기하는,  컴퓨터 판독가능 저장 매체.  </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Kihyoung SON</engName><name>손기형</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Jiyeon MA</engName><name>마지연</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Jingun JUNG</engName><name>정진근</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Sungjun HWANG</engName><name>황성준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Youngah LEE</engName><name>이영아</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구  논현로**길  **, *층, *층 (도곡동, 덕영빌딩)</address><code>920191001617</code><country>대한민국</country><engName>KWANG AND JANG PATENT LAW FIRM</engName><name>특허법인광앤장</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.13</receiptDate><receiptNumber>1-1-2022-1341316-52</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220174055.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936925b075a6e23cc97c1f71136394ad0587fc0923e0b102acbd246c510bcc9d0bb981f8aab7fb061c3f0f156c5e16438b0b37b7c0a585550b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf28dccbef02564c51e41ada19de52b6958dcb0440f96df304ccdeecdbc6dc0c76ef5372a2d6aa0829b2326f420ad7c72c324f2c91e28eaca3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>