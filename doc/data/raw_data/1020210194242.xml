<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:54.554</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0194242</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>AR 처리 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR PROCESSING AUGMENTED REALITY</inventionTitleEng><openDate>2023.07.07</openDate><openNumber>10-2023-0103379</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.28</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> AR 처리 방법 및 장치가 개시됨. 일 실시예에 따르면, 그 방법은 현실 세계의 타겟 장면에 대응하는 시각 정보가 AR 디바이스의 디스플레이 영역을 거쳐 사용자에게 제공됨에 따라 디스플레이 영역에 의해 발생하는 시각 정보의 빛 감쇠를 보상하는 보상 파라미터를 결정하고, AR 디바이스의 카메라를 이용하여 현실 세계의 타겟 장면을 촬영하여 빛 감쇠가 없는 배경 영상을 생성하고, 보상 파라미터를 이용하여 배경 영상의 밝기를 감소시켜서 빛 감쇠를 보상하는 보상 영상을 생성하고, 타겟 장면에 오버레이할 가상 객체 영상을 생성하고, 보상 영상 및 가상 객체 영상을 합성하여 디스플레이 영상을 생성하고, 디스플레이 영상을 디스플레이 영역에 표시하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 현실 세계의 타겟 장면에 대응하는 시각 정보가 AR 디바이스의 디스플레이 영역을 거쳐 사용자에게 제공됨에 따라 상기 디스플레이 영역에 의해 발생하는 상기 시각 정보의 빛 감쇠(light attenuation)를 보상하는 보상 파라미터를 결정하는 단계;상기 AR 디바이스의 카메라를 이용하여 상기 현실 세계의 상기 타겟 장면을 촬영하여 상기 빛 감쇠가 없는 배경 영상을 생성하는 단계;상기 보상 파라미터를 이용하여 상기 배경 영상의 밝기를 감소시켜서 상기 빛 감쇠를 보상하는 보상 영상을 생성하는 단계;상기 타겟 장면에 오버레이할 가상 객체 영상을 생성하는 단계;상기 보상 영상 및 상기 가상 객체 영상을 합성하여 디스플레이 영상을 생성하는 단계; 및상기 디스플레이 영상을 상기 디스플레이 영역에 표시하는 단계를 포함하는 AR 처리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 가상 객체 영상은상기 빛 감쇠를 이용하여 어두운 색을 표현하는 감쇠 영역을 포함하는,AR 처리 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 가상 객체 영상의 상기 감쇠 영역은상기 디스플레이 영역에 의한 상기 빛 감쇠의 적어도 일부가 유지된 상태로 표현되는,AR 처리 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 가상 객체 영상의 상기 감쇠 영역은상기 가상 객체 영상의 그림자, 검은 눈동자, 및 검은 머리카락 중 적어도 일부를 포함하는,AR 처리 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 디스플레이 영상을 생성하는 단계는상기 보상 영상에서 상기 가상 객체 영상의 상기 감쇠 영역의 대응 영역을 결정하는 단계; 및상기 감쇠 영역의 픽셀 값에 기초하여 상기 대응 영역의 픽셀 값을 차감하여 상기 대응 영역을 표현하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 대응 영역을 표현하는 단계는상기 대응 영역의 보상 값을 0으로 감소시켜서 상기 어두운 색 중 가장 어두운 색을 표현하는 단계를 포함하는,AR 처리 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 가상 객체 영상은 객체 요소 및 그림자 요소를 포함하고,상기 가상 객체 영상을 생성하는 단계는상기 배경 영상과 초기 가상 객체 요소를 융합하여 상기 객체 요소를 생성하는 단계;상기 배경 영상과 상기 중간 결과 영상 간의 차이에 기초하여 상기 그림자 요소를 생성하는 단계; 및상기 객체 요소 및 상기 그림자 요소를 결합하여 상기 가상 객체 영상을 생성하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 가상 객체 영상을 생성하는 단계는상기 초기 가상 객체 요소에 대응하는 마스크를 포함하는 마스크 영상을 생성하는 단계를 더 포함하고,상기 객체 요소를 생성하는 단계는상기 배경 영상과 초기 가상 객체 요소를 융합하여 상기 객체 요소를 포함하는 중간 결과 영상을 생성하는 단계; 및상기 마스크 영상 중 상기 마스크의 내부 영역을 이용하여 상기 중간 결과 영상으로부터 상기 객체 요소를 추출하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 가상 객체 영상을 생성하는 단계는상기 초기 가상 객체 요소에 대응하는 마스크를 포함하는 마스크 영상을 생성하는 단계를 더 포함하고,상기 그림자 요소를 생성하는 단계는상기 배경 영상과 상기 중간 결과 영상 간의 차이에 해당하는 차이 영상을 생성하는 단계; 및상기 마스크 영상 중 상기 마스크의 외부 영역을 이용하여 상기 차이 영상으로부터 상기 그림자 요소를 추출하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 보상 영상과 상기 타겟 장면이 정합된 상태로 상기 사용자에 의해 관측되도록 상기 보상 영상을 조정하는 단계를 더 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 보상 영상을 조정하는 단계는상기 AR 디바이스로부터 상기 보상 영상의 타겟 영역까지의 타겟 깊이를 결정하는 단계;상기 카메라의 촬영 시점과 상기 사용자의 관측 시점 간의 차이에 기초하여 캘리브레이션 정보를 결정하는 단계;상기 타겟 깊이 및 상기 캘리브레이션 정보에 기초하여, 상기 타겟 영역에 관한 상기 촬영 시점의 영상을 상기 관측 시점의 영상으로 변환하는 변환 정보를 결정하는 단계; 및상기 변환 정보를 이용하여 상기 보상 영상을 조정하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 타겟 깊이를 결정하는 단계는상기 타겟 장면에서 상기 가상 객체 영상을 표시하려는 객체 위치 정보를 획득하는 단계; 및상기 객체 위치 정보에 기초하여 상기 타겟 깊이를 결정하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 타겟 깊이를 결정하는 단계는상기 타겟 영역에 대응하는 타겟 평면을 추정하여 타겟 평면 정보를 결정하는 단계; 및상기 타겟 평면 정보에 기초하여 상기 타겟 깊이를 결정하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,상기 타겟 깊이를 결정하는 단계는상기 타겟 영역에 대응하는 공간 정보를 추정하여 타겟 공간 정보를 결정하는 단계; 및상기 타겟 공간 정보에 기초하여 상기 타겟 깊이를 결정하는 단계를 포함하는, AR 처리 방법.</claim></claimInfo><claimInfo><claim>15. 하드웨어와 결합되어 제1항 내지 제14항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 프로세서; 및상기 프로세서에서 실행가능한 명령어들을 포함하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에서 실행되면, 상기 프로세서는현실 세계의 타겟 장면에 대응하는 시각 정보가 AR 디바이스의 디스플레이 영역을 거쳐 사용자에게 제공됨에 따라 상기 디스플레이 영역에 의해 발생하는 상기 시각 정보의 빛 감쇠를 보상하는 보상 파라미터를 결정하고,상기 AR 디바이스의 카메라를 이용하여 상기 현실 세계의 상기 타겟 장면을 촬영하여 상기 빛 감쇠가 없는 배경 영상을 생성하고,상기 보상 파라미터를 이용하여 상기 배경 영상의 밝기를 감소시켜서 상기 빛 감쇠를 보상하는 보상 영상을 생성하고,상기 타겟 장면에 오버레이할 가상 객체 영상을 생성하고,상기 보상 영상 및 상기 가상 객체 영상을 합성하여 디스플레이 영상을 생성하고,상기 디스플레이 영상을 상기 디스플레이 영역에 표시하는,AR 처리 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 가상 객체 영상은상기 빛 감쇠를 이용하여 어두운 색을 표현하는 감쇠 영역을 포함하는,상기 디스플레이 영역에 의한 상기 빛 감쇠의 적어도 일부가 유지된 상태로 표현되는,AR 처리 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서는상기 보상 영상에서 상기 가상 객체 영상의 상기 감쇠 영역의 대응 영역을 결정하고,상기 감쇠 영역의 픽셀 값에 기초하여 상기 대응 영역의 픽셀 값을 차감하여 상기 대응 영역을 표현하는,AR 처리 장치.</claim></claimInfo><claimInfo><claim>19. 현실 세계의 타겟 장면을 촬영하는 카메라;디스플레이 영역에 디스플레이 영상을 표시하는 디스플레이; 및상기 타겟 장면에 대응하는 시각 정보가 상기 디스플레이 영역을 거쳐 사용자에게 제공됨에 따라 상기 디스플레이 영역에 의해 발생하는 상기 시각 정보의 빛 감쇠를 보상하는 보상 파라미터를 결정하고,상기 카메라를 이용하여 상기 타겟 장면을 촬영하여 상기 빛 감쇠가 없는 배경 영상을 생성하고,상기 보상 파라미터를 이용하여 상기 배경 영상의 밝기를 감소시켜서 상기 빛 감쇠를 보상하는 보상 영상을 생성하고,상기 타겟 장면에 오버레이할 가상 객체 영상을 생성하고,상기 보상 영상 및 상기 가상 객체 영상을 합성하여 상기 디스플레이 영상을 생성하는, 프로세서를 포함하는, AR 디바이스.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 가상 객체 영상은상기 빛 감쇠를 이용하여 어두운 색을 표현하는 감쇠 영역을 포함하고,상기 프로세서는상기 보상 영상에서 상기 가상 객체 영상의 상기 감쇠 영역의 대응 영역을 결정하고,상기 감쇠 영역의 픽셀 값에 기초하여 상기 대응 영역의 픽셀 값을 차감하여 상기 대응 영역을 표현하는,AR 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경상북도 포항시 남구...</address><code>420180163128</code><country>대한민국</country><engName>HA, Inwoo</engName><name>하인우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.12.31</receiptDate><receiptNumber>1-1-2021-1534194-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.28</receiptDate><receiptNumber>1-1-2024-1316142-08</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210194242.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a2debee5e8f2b965d040e5e2ff9daa8aa1832e517dc3420598e8740c873fe9cedebd806b20f2b218d7bfdf1a0ef1091e060341b1f7f2e2ac</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf08875553779b8c112d56d6e3be6a0ed89350fc57c8ba70ac907aafc56cbbf0fe3172004f6ef37f31368ae41cee6490cf92b28995e79fe22c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>