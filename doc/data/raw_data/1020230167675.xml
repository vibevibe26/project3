<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:26:20.2620</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0167675</applicationNumber><claimCount>14</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전통적 의료영상을 초다시점 입체 디스플레이 영상으로 자동 변환하기 위한 장치 및 방법</inventionTitle><inventionTitleEng>DEVICE AND METHOD FOR AUTOMATICALLY CONVERTING CONVENTIONAL  MEDICAL IMAGES INTO SUPER-MULTIVIEW DISPLAY IMAGES</inventionTitleEng><openDate>2025.03.31</openDate><openNumber>10-2025-0044068</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.28</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G03H 1/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/388</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시 내용에 따르면, 전통적 의료영상을 초다시점 입체디스플레이 영상으로 자동 변환하기 위한 장치 및 방법이 제시된다. 상기 장치는, 영상 촬영 장비로부터 의료 영상을 획득하도록 구성되는 입력부; 상기 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN 기반 알고리즘을 이용하여 분할된 관심 영역들을 학습시키도록 구성되는 학습부; 상기 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하도록 구성되는 추론부; 상기 검출된 관심 영역들에 대응하는 오브젝트를 생성하도록 구성되는 저장부; 및 상기 오브젝트를 초다시점 디스플레이 영상으로 변환하도록 구성되는 출력부를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 장치로서,영상 촬영 장비로부터 의료 영상을 획득하도록 구성되는 입력부;상기 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN(Convolutional Neural Network) 기반 알고리즘을 이용하여 분할된 관심 영역들을 학습시키도록 구성되는 학습부;상기 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하도록 구성되는 추론부;상기 검출된 관심 영역들에 대응하는 오브젝트를 생성하여 저장하도록 구성되는 저장부; 및상기 오브젝트를 초다시점 디스플레이 영상으로 변환하도록 구성되는 출력부를 포함하는,장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 학습부는 리전 그로잉(Region Growing) 알고리즘 및 스레스홀드(Threshold) 알고리즘을 이용하여 상기 관심 영역들의 주석처리 및 분할을 수행하고, 분할된 관심 영역들을 레이블링하도록 추가적으로 구성되는,장치.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 제 1 CNN 기반 알고리즘은 SegResNet 알고리즘을 포함하고,상기 학습부는 상기 레이블링된 분할된 관심 영역들을 상기 SegResNet 알고리즘을 이용하여 학습시키도록 추가적으로 구성되는,장치.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 SegResNet 알고리즘을 이용한 학습은 상기 레이블링된 분할된 관심 영역들에 대한 특징 추출(Feature Extraction) 및 분류(Classification)를 포함하는,장치.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 제 2 CNN 기반 알고리즘은 3D-Unet 모델을 포함하며,상기 추론부는 상기 3D-Unet 모델을 이용한 자동 분할(Automated Segmentation)을 통해 3차원적으로 추론된 관심 영역들을 검출하도록 추가적으로 구성되는,장치.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,상기 저장부는 상기 3차원적으로 추론된 관심 영역들을 병합하여 하나의 3D 오브젝트로 저장하도록 추가적으로 구성되는,장치.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,상기 출력부는 상기 3D 오브젝트를 이용하여 초다시점 홀로그램 디스플레이 영상을 출력하도록 추가적으로 구성되는,장치.</claim></claimInfo><claimInfo><claim>8. 인공지능 기반으로 의료 영상으로부터 관심 영역을 예측하여 초다시점 디스플레이 영상으로 변환하기 위한 방법으로서,영상 촬영 장비로부터 의료 영상을 획득하는 단계;상기 의료 영상으로부터 종양 및 종양 주변 조직에 대응하는 관심 영역들을 분할하고 제 1 CNN 기반 알고리즘을 이용하여 분할된 관심 영역들을 학습시키는 단계;상기 학습된 관심 영역들에 기초하여 제 2 CNN 기반 알고리즘을 이용하여 추론된 관심 영역들을 검출하는 단계;상기 검출된 관심 영역들에 대응하는 오브젝트를 생성하는 단계; 및상기 오브젝트를 초다시점 디스플레이 영상으로 변환하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 관심 영역들을 분할하는 단계는,리전 그로잉 알고리즘 및 스레스홀드 알고리즘을 이용하여 상기 관심 영역들의 주석처리 및 분할을 수행하는 단계; 및분할된 관심 영역들을 레이블링하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 제 1 CNN 기반 알고리즘은 SegResNet 알고리즘을 포함하고,상기 분할된 관심 영역들을 학습시키는 단계는, 상기 레이블링된 분할된 관심 영역들을 상기 SegResNet 알고리즘을 이용하여 학습시키는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서,상기 SegResNet 알고리즘을 이용한 학습은 상기 레이블링된 분할된 관심 영역들에 대한 특징 추출 및 분류를 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 제 8 항에 있어서,상기 제 2 CNN 기반 알고리즘은 3D-Unet 모델을 포함하며,상기 추론된 관심 영역들을 검출하는 단계는, 상기 3D-Unet 모델을 이용한 자동 분할을 통해 3차원적으로 추론된 관심 영역들을 검출하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서,상기 오브젝트를 생성하는 단계는,상기 3차원적으로 추론된 관심 영역들을 병합하여 하나의 3D 오브젝트를 생성하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 변환하는 단계는,상기 3D 오브젝트를 이용하여 초다시점 홀로그램 디스플레이 영상을 출력하는 단계를 포함하는,방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성북구...</address><code>319980077518</code><country>대한민국</country><engName>KOREA INSTITUTE OF SCIENCE AND TECHNOLOGY</engName><name>한국과학기술연구원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>Hyung-Seop Han</engName><name>한형섭</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM KYU RI</engName><name>김규리</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>Kang Min Koo</engName><name>강민구</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구  테헤란로**길  ** ,*층 (대치동, 노벨빌딩)</address><code>920211000219</code><country>대한민국</country><engName>PADO IP Law PLLC</engName><name>파도특허법인유한회사</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.09.22</priorityApplicationDate><priorityApplicationNumber>1020230126869</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.28</receiptDate><receiptNumber>1-1-2023-1328621-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.03.22</receiptDate><receiptNumber>4-1-2024-5102250-75</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.11.05</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230167675.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a06d687861d51fe6b23feb850c31ef5af0a788e5fd095d36a49d2d264d9d3f66a5d516868b08a6a7e02dd9c2a1b1b11cbe56fe6ccfdf16ac</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6d9d47c16d25cfe8e89b52ab42762b20ea73648ebe0df32032f9064b0621c43ef612ec9b006bd775d34ff330083ddde2f43bdd91b4c71462</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>