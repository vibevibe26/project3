<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:25.125</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.12</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7023978</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>실시간 모션 및 외관 전달</inventionTitle><inventionTitleEng>REAL-TIME MOTION AND APPEARANCE TRANSFER</inventionTitleEng><openDate>2024.08.19</openDate><openNumber>10-2024-0125621</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.07.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.07.17</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/215</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 어느 한 현실 세계 객체로부터 또 다른 현실 세계 객체로 실시간으로 모션을 전달하기 위한 동작들을 수행하기 위한 방법들 및 시스템들이 개시된다. 동작들은 제1 현실 세계 객체의 묘사를 포함하는 제1 비디오를 수신하는 동작 및 비디오로부터 제1 현실 세계 객체의 외관을 추출하는 동작을 포함한다. 동작들은 제2 현실 세계 객체의 묘사를 포함하는 제2 비디오를 획득하는 동작 및 제2 비디오로부터 제2 현실 세계 객체의 모션을 추출하는 동작을 포함한다. 동작들은 제2 비디오로부터 추출된 제2 현실 세계 객체의 모션을 제1 비디오로부터 추출된 제1 현실 세계 객체의 외관에 적용하는 동작을 포함한다. 동작들은 제1 현실 세계 객체의 외관 및 제2 현실 세계 객체의 모션을 갖는 제1 현실 세계 객체의 묘사를 포함하는 제3 비디오를 생성하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.06.29</internationOpenDate><internationOpenNumber>WO2023121896</internationOpenNumber><internationalApplicationDate>2022.12.12</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/052520</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서:하나 이상의 프로세서에 의해, 제1 현실 세계 객체의 묘사를 포함하는 제1 비디오를 수신하는 단계;상기 제1 비디오로부터 상기 제1 현실 세계 객체의 외관을 표현하는 외관 데이터를 추출하는 단계;제2 현실 세계 객체의 묘사를 포함하는 제2 비디오를 획득하는 단계;상기 제2 비디오로부터 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터를 추출하는 단계;상기 제2 비디오로부터 추출된 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터를 상기 제1 비디오로부터 추출된 상기 제1 현실 세계 객체의 외관에 적용하는 단계; 및상기 제1 현실 세계 객체의 외관을 표현하는 외관 데이터 및 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터에 기초하여 상기 제1 현실 세계 객체의 묘사를 포함하는 제3 비디오를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 현실 세계 객체는 제1 사람을 포함하고, 상기 제2 현실 세계 객체는 제2 사람을 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 제1 현실 세계 객체의 외관을 표현하는 외관 데이터는 상기 제1 현실 세계 객체의 3차원(3D) 자세 데이터, 상기 제1 현실 세계 객체의 전체 신체 세그먼테이션 데이터, 상기 제1 현실 세계 객체의 조밀한 키포인트 세트, 및 상기 제1 현실 세계 객체의 의복 세그먼테이션 데이터를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 외관 데이터를 추출하는 단계는 상기 제1 비디오에 제1 머신 러닝 기법을 적용하는 단계를 포함하고, 상기 제1 머신 러닝 기법은 입력 비디오에 대한 상기 외관 및 모션 데이터를 추정하도록 훈련되고, 상기 외관 데이터는 상기 제1 현실 세계 객체에 대한 텍스처 및 컬러 데이터를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 모션 데이터를 추출하는 단계는 상기 제1 머신 러닝 기법을 상기 제2 비디오에 적용하는 단계를 포함하고, 상기 모션 데이터는 상기 제2 현실 세계 객체의 자세를 표현하는 자세 데이터를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 제1 머신 러닝 기법은 상기 입력 비디오에 묘사된 주어진 현실 세계 객체의 3차원(3D) 자세, 상기 주어진 현실 세계 객체의 전체 신체 세그먼테이션 데이터, 상기 주어진 현실 세계 객체의 조밀한 키포인트 세트, 및 상기 주어진 현실 세계 객체의 의복 세그먼테이션 데이터를 동시에 생성하도록 훈련되는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 제2 비디오로부터 추출된 모션 데이터 및 상기 제1 비디오로부터 추출된 외관 데이터를 제2 머신 러닝 기법에 적용하는 단계 - 상기 제2 머신 러닝 기법은 어느 한 현실 세계 객체의 모션 데이터를 또 다른 현실 세계 객체의 외관 데이터에 적용하는 새로운 비디오를 생성하도록 훈련됨 - 를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 제1 및 제2 머신 러닝 기법들은 제1 훈련 비디오에 묘사된 제1 모션을 표현하는 제1 모션 데이터를 갖는 훈련 현실 세계 객체의 외관 데이터와 제2 훈련 비디오에 묘사된 제2 모션을 갖는 훈련 현실 세계 객체의 외관을 표현하는 외관 데이터 사이의 관계를 확립하도록 엔드-투-엔드(end-to end)로 훈련되는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 외관 데이터 및 상기 제1 모션 데이터를 갖는 상기 훈련 현실 세계 객체를 묘사하는 상기 제1 훈련 비디오를 수신하는 동작;상기 외관 데이터 및 상기 제2 모션 데이터를 갖는 상기 훈련 현실 세계 객체를 묘사하는 상기 제2 훈련 비디오를 수신하는 동작;상기 제1 훈련 비디오에 상기 제1 머신 러닝 기법을 적용하여 상기 훈련 현실 세계 객체의 추정된 외관 데이터를 생성하는 동작;상기 제2 훈련 비디오에 상기 제1 머신 러닝 기법을 적용하여 상기 훈련 현실 세계 객체의 추정된 모션 데이터를 생성하는 동작; 및상기 훈련 현실 세계 객체의 추정된 외관 데이터 및 상기 훈련 현실 세계 객체의 추정된 모션 데이터를 상기 제2 머신 러닝 기법에 적용하여 상기 추정된 외관 데이터 및 상기 추정된 모션 데이터를 갖는 상기 훈련 현실 세계 객체의 묘사를 생성하는 동작을 포함하는 동작들의 시퀀스를 통해 반복함으로써 상기 제1 및 제2 머신 러닝 기법들을 훈련하는 단계를 추가로 포함하는 방법.  </claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 추정된 외관 데이터 및 상기 추정된 모션 데이터를 갖는 상기 훈련 현실 세계 객체의 묘사와 상기 외관 데이터 및 상기 제2 모션 데이터를 갖는 상기 훈련 현실 세계 객체를 묘사하는 상기 제2 훈련 비디오 사이의 편차를 계산하는 단계; 및상기 계산된 편차에 기초하여 상기 제1 및 제2 머신 러닝 기법들의 하나 이상의 파라미터를 갱신하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 제1 및 제2 훈련 비디오들에 묘사된 상기 현실 세계 객체는 특정 의류 물품을 착용한 사람을 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 머신 러닝 기법은 외관 및 모션 데이터 추출 모듈을 포함하고, 상기 제2 머신 러닝 기법은 이미지 생성기 모듈을 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 제1 현실 세계 객체는 제1 사용자를 포함하고, 상기 제2 현실 세계 객체는 제2 사용자를 포함하며, 상기 방법은:상기 제1 사용자의 클라이언트 디바이스의 이미지 캡처 디바이스를 이용하여 상기 제2 사용자를 묘사하는 상기 제2 비디오를 캡처하는 단계; 및상기 제2 비디오를 캡처한 후에, 상기 이미지 캡처 디바이스를 사용하여 상기 제1 사용자를 묘사하는 제1 비디오를 캡처하는 단계 - 상기 제3 비디오는 상기 제2 비디오를 캡처한 후에 상기 제1 비디오를 캡처한 것에 응답하여 생성됨 - 를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 제2 비디오는 상기 클라이언트 디바이스의 후방 카메라를 이용하여 캡처되고, 상기 제1 비디오는 상기 클라이언트 디바이스의 전방 카메라를 이용하여 캡처되는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 제1 및 제2 비디오들은 클라이언트 디바이스의 상이한 카메라들을 사용하여 동시에 캡처되는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 제3 비디오는 상기 제1 및 제2 비디오들이 캡처되고 있음에 따라 실시간으로 생성되는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 제1 비디오는 상기 제1 현실 세계 객체를 제1 자세에 있고 제1 의류 물품을 착용하는 것으로 묘사하고, 상기 제2 비디오는 상기 제2 현실 세계 객체를 제2 자세에 있고 제2 의류 물품을 착용하는 것으로 묘사하고, 상기 제3 비디오는 상기 제1 현실 세계 객체를 상기 제2 현실 세계 객체의 제2 자세에 있고 상기 제1 의류 물품을 착용하는 것으로 묘사하는 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 제1 현실 세계 객체를 상기 제2 현실 세계 객체의 제2 자세에 있고 상기 제1 의류 물품을 착용하는 것으로 묘사하기 위해 상기 제1 의류 물품 상의 새로운 픽셀 세트를 시뮬레이션하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서:프로세서; 및상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 야기하는 명령어들이 저장된 메모리 컴포넌트를 포함하고, 상기 동작들은: 제1 현실 세계 객체의 묘사를 포함하는 제1 비디오를 수신하는 동작; 상기 제1 비디오로부터 상기 제1 현실 세계 객체의 외관을 표현하는 외관 데이터를 추출하는 동작; 제2 현실 세계 객체의 묘사를 포함하는 제2 비디오를 획득하는 동작; 상기 제2 비디오로부터 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터를 추출하는 동작; 상기 제2 비디오로부터 추출된 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터를 상기 제1 비디오로부터 추출된 상기 제1 현실 세계 객체의 외관에 적용하는 동작; 및 상기 제1 현실 세계 객체의 외관을 표현하는 외관 데이터 및 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터에 기초하여 상기 제1 현실 세계 객체의 묘사를 포함하는 제3 비디오를 생성하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 야기하는 명령어들이 저장된 컴퓨터 판독가능 저장 매체로서, 상기 동작들은:제1 현실 세계 객체의 묘사를 포함하는 제1 비디오를 수신하는 동작;상기 제1 비디오로부터 상기 제1 현실 세계 객체의 외관을 표현하는 외관 데이터를 추출하는 동작;제2 현실 세계 객체의 묘사를 포함하는 제2 비디오를 획득하는 동작;상기 제2 비디오로부터 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터를 추출하는 동작;상기 제2 비디오로부터 추출된 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터를 상기 제1 비디오로부터 추출된 상기 제1 현실 세계 객체의 외관에 적용하는 동작; 및상기 제1 현실 세계 객체의 외관을 표현하는 외관 데이터 및 상기 제2 현실 세계 객체의 모션을 표현하는 모션 데이터에 기초하여 상기 제1 현실 세계 객체의 묘사를 포함하는 제3 비디오를 생성하는 동작을 포함하는 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>ASSOULINE, Avihay</engName><name>아술린, 아비하이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>BERGER, Itamar</engName><name>버거, 이타마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>MALBIN, Nir</engName><name>말빈, 니르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>SASSON, Gal</engName><name>사슨, 갈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.21</priorityApplicationDate><priorityApplicationNumber>17/645,366</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-1-2024-0774364-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-1-2024-0776578-22</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.07.19</receiptDate><receiptNumber>1-5-2024-0118880-44</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247023978.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d86c91b045bff3b12678c0319bda785a5bd170e91644814780af5a9adb1552bc975f15c7ae8e2782b961e86478800ca818bda56dbd81e08c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf638e1b12628e93565865dfd620502caf02a27b28c50f96c880e54f1c00cdf875c71a486082af84f395a36dd5f0585c74586838fe330478da</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>