<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:08.58</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0167559</applicationNumber><claimCount>22</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>군중 계수의 추정 방법, 군중 계수의 추정을 위한 모델의 학습 방법, 및 이를 수행하기 위한 전자 장치</inventionTitle><inventionTitleEng>A METHOD FOR ESTIMATING A CROWD COEFFICIENT, A METHOD  FOR TRAINING A MODEL FOR ESTIMATION OF THE CROWD  COEFFICIENT, AND AN ELECTRONIC DEVICE FOR PERFORMING  THE SAME</inventionTitleEng><openDate>2025.06.09</openDate><openNumber>10-2025-0081970</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.28</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/30</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 출원의 일 실시예에 따른 군중 계수의 추론을 위한 인공지능 모델의 준지도 학습 방법은, 정답 주석과 매칭되지 않은 제1 이미지 및 정답 주석과 매칭된 제2 이미지를 포함하는 제1 학습 데이터 세트에 기초하여 학습된 다중 교사 모델-상기 다중 교사 모델은 세그멘테이션 맵을 예측하기 위한 제1 교사 모델을 포함함-을 이용하여, 상기 제1 학습 데이터 세트의 상기 제1 이미지로부터 유사 주석(Pseudo Annotation)을 생성하는 단계; 상기 제1 교사 모델의 출력을 기준으로 상기 다중 교사 모델에 포함된 적어도 하나의 상기 제1 교사 모델과는 다른 교사 모델의 출력과 상기 제1 교사 모델의 출력을 앙상블하여 상기 유사 주석의 노이즈를 제거하는 단계; 상기 노이즈가 제거된 유사 주석에 기초하여, 상기 제1 학습 데이터 세트의 상기 제1 이미지 및 상기 제1 이미지와 매칭된 상기 노이즈가 제거된 유사 주석을 포함하는 제2 학습 데이터 세트를 생성하는 단계; 상기 제2 학습 데이터 세트에 기초하여 상기 다중 교사 모델에 대응되는 다중 학생 모델을 학습시키는 단계; 및 상기 다중 학생 모델의 학습이 완료된 경우, 상기 다중 학생 모델 중 적어도 하나를 군중계수 추론을 위한 상기 인공지능 모델로서 출력하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치가, 군중계수 추론을 위한 인공지능 모델을 다중모델 기반으로 준지도 학습시키는 방법에 있어서정답 주석과 매칭되지 않은 제1 이미지 및 정답 주석과 매칭된 제2 이미지를 포함하는 제1 학습 데이터 세트에 기초하여 학습된 다중 교사 모델 -상기 다중 교사 모델은 세그멘테이션 맵을 예측하기 위한 제1 교사 모델을 포함함-을 이용하여, 상기 제1 학습 데이터 세트의 상기 제1 이미지로부터 유사 주석(Pseudo Annotation)을 생성하는 단계; 상기 제1 교사 모델의 출력을 기준으로 상기 다중 교사 모델에 포함된 적어도 하나의 상기 제1 교사 모델과는 다른 교사 모델의 출력과 상기 제1 교사 모델의 출력을 앙상블하여 상기 유사 주석의 노이즈를 제거하는 단계;상기 노이즈가 제거된 유사 주석에 기초하여, 상기 제1 학습 데이터 세트의 상기 제1 이미지 및 상기 제1 이미지와 매칭된 상기 노이즈가 제거된 유사 주석을 포함하는 제2 학습 데이터 세트를 생성하는 단계;상기 제2 학습 데이터 세트에 기초하여 상기 다중 교사 모델에 대응되는 다중 학생 모델을 학습시키는 단계; 및상기 다중 학생 모델의 학습이 완료된 경우, 상기 다중 학생 모델 중 적어도 하나를 군중계수 추론을 위한 상기 인공지능 모델로서 출력하는 단계를 포함하는, 준지도 학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 상기 유사 주석의 노이즈를 제거하는 단계는, 상기 다중 교사 모델에 포함된 상기 다른 교사 모델의 출력으로부터 변환된 세그멘테이션 맵과 상기 제1 교사 모델의 세그멘테이션 맵 형태의 출력을 앙상블하여 앙상블된 세그멘테이션 맵을 생성하는 단계; 및상기 앙상블된 세그멘테이션 맵을 이용하여 상기 다른 교사 모델에 포함된 상기 유사 주석과 관련된 포인트 맵을 예측하기 위한 제2 교사 모델의 출력에 포함된 노이즈를 제거하는 단계를 더 포함하는, 준지도 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서, 상기 다중 교사 모델에 포함된 적어도 하나의 다른 교사 모델은, 상기 유사 주석과 관련된 포인트 맵을 예측하기 위한 제2 교사 모델, 및 상기 유사 주석과 관련된 밀도 맵을 예측하기 위한 제3 교사 모델을 더 포함하되,상기 유사 주석을 생성하는 단계는, 상기 제1 교사 모델을 통해 상기 제1 학습 데이터 세트의 상기 제1 이미지로부터 유사 세그멘테이션 맵을 생성하는 단계; 상기 제2 교사 모델을 통해 상기 제1 학습 데이터 세트의 상기 제1 이미지로부터 상기 유사 주석의 좌표와 관련된 유사 포인트 맵을 생성하는 단계; 및상기 제3 교사 모델을 통해 상기 제1 학습 데이터 세트의 상기 제1 이미지로부터 유사 밀도 맵을 생성하는 단계를 더 포함하는, 준지도 학습 방법.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서, 상기 유사 주석의 노이즈를 제거하는 단계는, 상기 유사 포인트 맵으로부터 변환된 제1 세그멘테이션 맵을 획득하는 단계;상기 유사 밀도 맵으로부터 변환된 제2 세그멘테이션 맵을 획득하는 단계; 상기 제1 세그멘테이션 맵, 상기 제2 세그멘테이션 맵, 및 상기 유사 세그멘테이션 맵을 앙상블하여 앙상블된 세그멘테이션 맵을 생성하는 단계; 상기 앙상블된 세그멘테이션 맵과 상기 유사 포인트 맵을 비교하여 상기 유사 포인트 맵의 적어도 하나 이상의 픽셀 값을 보정하여 상기 유사 포인트 맵의 노이즈가 제거된 디노이즈된 포인트 맵을 생성하는 단계; 및상기 디노이즈된 포인트 맵으로부터 디노이즈된 밀도 맵과 디노이즈된 세그멘테이션 맵을 각각 생성하는 단계를 더 포함하는, 준지도 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 앙상블된 세그멘테이션 맵을 생성하는 단계는, 상기 제1 세그멘테이션 맵의 상기 제2 세그멘테이션 맵에 대한 유사도와 상기 제1 세그멘테이션 맵의 상기 유사 세그멘테이션 맵에 대한 유사도에 기초하여 상기 제1 세그멘테이션 맵에 대한 제1 유사도 점수를 연산하는 단계; 상기 제2 세그멘테이션 맵의 상기 유사 세그멘테이션 맵에 대한 유사도와 상기 제2 세그멘테이션 맵의 상기 제1 세그멘테이션 맵의 유사도에 기초하여 상기 제2 세그멘테이션 맵에 대한 제2 유사도 점수를 연산하는 단계; 상기 유사 세그멘테이션 맵의 상기 제1 세그멘테이션 맵에 대한 유사도와 상기 유사 세그멘테이션 맵의 상기 제2 세그멘테이션 맵의 유사도에 기초하여 상기 유사 세그멘테이션 맵에 대한 제3유사도 점수를 연산하는 단계; 상기 제1 유사도 점수 내지 상기 제3 유사도 점수에 기초하여 상기 제1 세그멘테이션 맵에 대한 제1 가중치, 상기 제2 세그멘테이션 맵에 대한 제2 가중치, 및 상기 유사 세그멘테이션 맵에 대한 제3 가중치를 연산하는 단계; 및상기 제1 가중치 내지 상기 제3 가중치를 이용하여 상기 앙상블된 세그멘테이션 맵을 생성하는 단계를 더 포함하는, 준지도 학습 방법.</claim></claimInfo><claimInfo><claim>6. 제4 항에 있어서, 상기 디노이즈된 포인트 맵을 생성하는 단계는, 상기 앙상블된 세그멘테이션 맵에 포함된 제1 픽셀 값이 미리 정해진 임계값보다 작은 경우, 상기 제1 픽셀 값에 대응되는 상기 유사 포인트 맵의 대응되는 픽셀 값을 노이즈로 결정하는 단계; 및상기 노이즈에 대응되는 픽셀 값을 제거하여 상기 유사 포인트 맵으로부터 상기 디노이즈된 포인트 맵을 생성하는 단계를 더 포함하는,준지도 학습 방법.</claim></claimInfo><claimInfo><claim>7. 제4 항에 있어서, 상기 디노이즈된 포인트 맵을 생성하는 단계는, 상기 앙상블된 세그멘테이션 맵에 포함된 제2 픽셀이 로컬 최대 값을 가지는 경우, 상기 제2 픽셀에 대응되는 상기 유사 포인트 맵의 픽셀 값을 노이즈로 결정하는 단계; 및상기 제2 픽셀의 값에 기초하여 상기 제2 픽셀에 대응되는 상기 유사 포인트 맵의 픽셀에 값을 추가하여 상기 유사 포인트 맵으로부터 상기 디노이즈된 포인트 맵을 생성하는 단계를 더 포함하는,  준지도 학습 방법.</claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서, 상기 준지도 학습 방법은, 상기 다중 학생 모델의 학습에 따라 갱신된 상기 다중 학생 모델의 가중치에 기초하여, 상기 다중 교사 모델에 포함된 상기 제1 교사 모델 또는 상기 다른 교사 모델의 파라미터를 갱신하는 단계를 더 포함하는, 준지도 학습 방법.  </claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서, 상기 다중 교사 모델에 포함된 적어도 하나의 모델의 초기 모델은, 1차적으로 학습된 상기 다중 학생 모델에 포함된 학생 모델이고, 상기 학생 모델은, 상기 제1 학습 데이터 세트의 상기 제2 이미지에 기초하여 1차적으로 학습되는 것을 특징으로 하는,준지도 학습 방법.     </claim></claimInfo><claimInfo><claim>10. 제1 항에 있어서, 상기 다중 교사 모델에 포함된 세그멘테이션 맵을 예측하기 위한 상기 제1 교사 모델의 초기 모델은,  상기 다중 학생 모델에 포함되고, 상기 제1 학습 데이터 세트의 상기 제2 이미지에 기초하여 세그멘테이션 맵을 예측하도록 1차적으로 학습된 제1 학생 모델이고, 상기 제1 학생 모델은, 상기 제2 이미지에 기초하여, 상기 제2 이미지와 매칭된 상기 정답 주석으로부터 변환된 세그멘테이션 맵을 예측하도록 1차적으로 학습되는 것을 특징으로 하는,준지도 학습 방법. </claim></claimInfo><claimInfo><claim>11. 제1 항에 있어서, 상기 다중 교사 모델에 포함된 포인트 맵을 예측하기 위한 제2 교사 모델의 초기 모델은,  상기 다중 학생 모델에 포함되고, 상기 제1 학습 데이터 세트의 상기 제2 이미지에 기초하여 포인트 맵을 예측하도록 1차적으로 학습된 제2 학생 모델이고, 상기 제2 학생 모델은, 상기 제2 이미지에 기초하여, 상기 제2 이미지와 매칭된 상기 정답 주석에 대응되는 픽셀의 좌표 정보를 포함하는 포인트 맵을 예측하도록 1차적으로 학습되는 것을 특징으로 하는,준지도 학습 방법. </claim></claimInfo><claimInfo><claim>12. 제1 항에 있어서, 상기 다중 교사 모델에 포함된 밀도 맵을 예측하기 위한 제3 교사 모델의 초기 모델은,  상기 다중 학생 모델에 포함되고, 상기 제1 학습 데이터 세트의 상기 제2 이미지에 기초하여 밀도 맵을 예측하도록 1차적으로 학습된 제3 학생 모델이고, 상기 제3 학생 모델은, 상기 제2 이미지에 기초하여, 상기 제2 이미지에 포함된 픽셀이 주석에 대응될 확률에 대한 상기 제2 이미지와 매칭된 상기 정답 주석으로부터 변환된 밀도 맵을 예측하도록 1차적으로 학습되는 것을 특징으로 하는,준지도 학습 방법. </claim></claimInfo><claimInfo><claim>13. 제4 항에 있어서, 상기 다중 학생 모델을 학습시키는 단계는,상기 제2 학습 데이터 세트의 상기 제1 이미지를 상기 다중 학생 모델에 포함된 세그멘테이션 맵을 예측하는 제1 학생 모델에 입력하고, 상기 제1 학생 모델을 통하여 출력되는 제1 예측 맵을 획득하는 단계; 및상기 제1 예측 맵과 상기 디노이즈된 세그멘테이션 맵의 차이에 기초하여 상기 제1 학생 모델의 파라미터를 갱신하는 단계를 더 포함하는, 준지도 학습 방법. </claim></claimInfo><claimInfo><claim>14. 4 항에 있어서, 상기 다중 학생 모델을 학습시키는 단계는,상기 제2 학습 데이터 세트의 상기 제1 이미지를 상기 다중 학생 모델에 포함된 포인트 맵을 예측하는 제2 학생 모델에 입력하고, 상기 제2 학생 모델을 통하여 출력되는 제2 예측 맵을 획득하는 단계; 및상기 제2 예측 맵과 상기 디노이즈된 포인트 맵의 차이에 기초하여 상기 제2 학생 모델의 파라미터를 갱신하는 단계를 더 포함하는, 준지도 학습 방법. </claim></claimInfo><claimInfo><claim>15. 제4 항에 있어서, 상기 다중 학생 모델을 학습시키는 단계는,상기 제2 학습 데이터 세트의 상기 제1 이미지를 상기 다중 학생 모델에 포함된 밀도 맵을 예측하는 제3 학생 모델에 입력하고, 상기 제3 학생 모델을 통하여 출력되는 제3 예측 맵을 획득하는 단계; 및상기 제3 예측 맵과 상기 디노이즈된 포인트 맵의 차이에 기초하여 상기 제3 학생 모델의 파라미터를 갱신하는 단계를 더 포함하는, 준지도 학습 방법. </claim></claimInfo><claimInfo><claim>16. 제1 항에 있어서, 상기 다중 학생 모델은, 인코더(Encoder)와 디코더(Decoder)로 구성되되, 상기 다중 학생 모델의 인코더는 사전에 학습된 비전 파운데이션 모델의 인코더에 기반하며, 상기 다중 학생 모델의 인코더는 학습 과정에서 상기 비전 파운데이션 모델의 가중치에 기초하여 고정된 가중치를 포함하며, 상기 다중 학생 모델의 디코더는 상기 고정된 가중치에 기초하여 상기 다중 학생 모델의 인코더를 통해 출력된 값에 기초하여, 상기 군중 계수 추론을 위한 주석과 관련된 포인트 맵, 밀도 맵, 및 세그멘테이션 맵 중 적어도 하나를 출력하도록 구성되는,    준지도 학습 방법. </claim></claimInfo><claimInfo><claim>17. 전자 장치가, 준지도 학습을 통해 학습이 완료된 인공지능 모델을 이용하여 군중 계수를 추정하는 방법에 있어서, 학습이 완료된 인공지능 모델을 획득하는 단계; 분석 대상의 대상 이미지를 획득하는 단계; 상기 학습이 완료된 인공지능 모델을 통해, 상기 대상 이미지로부터 상기 대상 이미지 상의 사람 객체에 대응되는 위치 정보 또는 사람 객체의 수를 획득하는 단계를 포함하되,상기 학습이 완료된 인공지능 모델은, 정답 주석과 매칭되지 않은 제1 이미지 및 정답 주석과 매칭된 제2 이미지를 포함하는 학습 데이터 세트로부터 세그멘테이션 맵을 예측하기 위한 제1 교사 모델을 포함하는 다중 교사 모델을 이용하여 준지도 학습된 다중 학생 모델 중 적어도 하나를 포함하는 인공지능 모델이고,상기 다중 학생 모델은.상기 학습 데이터 세트의 상기 제1 이미지에 대해 상기 다중 교사 모델이 예측한 유사 주석의 노이즈를 제거하여 생성된 디노이즈된 유사 주석을 기초로 학습된 것을 특징으로 하는, 군중 계수의 추정 방법.</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서, 상기 유사 주석의 노이즈는,상기 다중 교사 모델에 포함된 적어도 하나의 상기 제1 교사 모델과는 다른 교사 모델의 출력을, 상기 제1 교사 모델이 출력을 기준으로 앙상블한 결과에 기초하여 제거된 것을 특징으로 하는, 군중 계수의 추정 방법.</claim></claimInfo><claimInfo><claim>19. 제17 항에 있어서, 상기 군중계수의 추론을 위한 학습이 완료된 인공지능 모델은, 상기 다중 학생 모델에 포함되고, 상기 대상 이미지 상의 사람 객체에 대응되는 주석의 좌표에 대한 포인트 맵을 예측하기 위한 제1 학생 모델, 및 상기 다중 학생 모델에 포함되고, 상기 대상 이미지 상의 픽셀이 상기 주석에 대응될 확률 정보에 대한 밀도 맵을 예측하기 위한 제2 학생 모델 중 적어도 어느 하나인, 군중 계수의 추정 방법,</claim></claimInfo><claimInfo><claim>20. 제19 항에 있어서, 상기 학습이 완료된 인공지능 모델을 통해, 상기 대상 이미지로부터 상기 이미지 상의 사람 객체에 대응되는 위치 정보 또는 사람 객체의 수를 획득하는 단계는, 학습이 완료된 상기 제1 학생 모델을 통해, 상기 대상 이미지로부터 포인트 맵과 관련된 제1 출력 맵을 획득하는 단계;상기 제1 출력 맵의 주석에 대응되는 좌표에 기초하여 상기 사람 객체의 위치 정보를 연산하는 단계; 및 상기 연산된 위치 정보에 대한 상기 제1 출력 맵의 주석에 대응되는 좌표의 수에 기초하여 상기 사람 객체의 수를 연산하는 단계를 더 포함하는, 군중 계수의 추정 방법,</claim></claimInfo><claimInfo><claim>21. 제19 항에 있어서, 상기 학습이 완료된 인공지능 모델을 통해, 상기 대상 이미지로부터 상기 이미지 상의 사람 객체에 대응되는 위치 정보 또는 사람 객체의 수를 획득하는 단계는, 학습이 완료된 상기 제2 학생 모델을 통해, 상기 대상 이미지로부터 밀도 맵과 관련된 제2 출력 맵을 획득하는 단계; 및상기 제2 출력 맵의 픽셀들 각각에 할당된 확률 값의 합에 기초하여 상기 사람 객체의 수를 연산하는 단계를 더 포함하는, 군중 계수의 추정 방법,</claim></claimInfo><claimInfo><claim>22. 제17 항에 있어서, 상기 학습이 완료된 인공지능 모델은, 상기 다중 교사 모델의 출력으로부터 변환된 세그멘테이션 맵과 상기 제1 교사 모델의 세그멘테이션 맵 형태의 출력을 앙상블하여 앙상블된 세그멘테이션 맵을 생성하고, 상기 앙상블된 세그멘테이션 맵을 이용하여, 상기 다중 교사 모델에 포함된 상기 유사 주석과 관련된 포인트 맵을 예측하기 위한 제2 교사 모델의 출력에 노이즈를 제거하여 생성된 디노이즈된 유사 주석을 기초로 학습된 것을 특징으로 하는, 군중 계수의 추정 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>120150372683</code><country>대한민국</country><engName>NOTA, INC.</engName><name>주식회사 노타</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 구리시 ...</address><code> </code><country> </country><engName>Jeongho Kim</engName><name>김정호</name></inventorInfo><inventorInfo><address>경기도 수원시 권선구...</address><code> </code><country> </country><engName>Hancheol Park</engName><name>박한철</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서초구 서초중앙로**길 ** (서초동) *층(인트로특허법률사무소)</address><code>920140003863</code><country>대한민국</country><engName>KANG DAEHWAN</engName><name>강대환</name></agentInfo><agentInfo><address>서울 서초구 서초중앙로**길 ** (서초동) *층(인트로특허법률사무소)</address><code>920120009857</code><country>대한민국</country><engName>BAEK JONG UNG</engName><name>백종웅</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.28</receiptDate><receiptNumber>1-1-2023-1328112-29</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.04.25</receiptDate><receiptNumber>4-1-2025-5112974-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230167559.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93357df36c037ec8d4dc312644adc4a49649f0765642062a3c4dd022064f1674e511b43f7202c3ea17dc10b7dc9abb91e73964c3f01dbf6b0a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfda11d02ae0cb211b0303b869a79073e727c244f7cb72b9c3a9764303e3058f3af9f97cd1e2c3a0baea99de9eb707d5a27ea2e168d9495d66</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>