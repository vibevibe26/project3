<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:18.518</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0103531</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 기반의 재활 훈련 제공 장치, 서버, 방법 및 프로그램</inventionTitle><inventionTitleEng>Apparatus, server, method and program for providing  rehabilitation training based on augmented reality</inventionTitleEng><openDate>2025.02.18</openDate><openNumber>10-2025-0022943</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.08.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 20/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 10/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A63B 21/055</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/69</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 증강 현실 기반의 재활 훈련 제공 장치에 관한 것으로, 사용자의 재활 부위, 재활 부위의 상태 정보 및 사용자의 재활 훈련 스케줄을 기반으로 사용자의 재활 훈련을 위한 제1 목표 모션을 선택하고, 선택된 제1 목표 모션을 나타내는 영상을 가상현실 장치를 통해 출력하고, 단말을 통해 촬영된 영상에서 사용자의 제1 목표 모션에 대한 수행된 수행 모션을 인식하고, 인식된 수행 모션을 평가할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 단말 및 가상현실 장치와 통신하는 통신부;하나 이상의 인스트럭션이 저장된 저장부;상기 인스트럭션을 실행하며, 상기 통신부를 통해 상기 단말을 통해 촬영된 영상을 수신하고 상기 수신된 영상을 기반으로 사용자의 모션을 인식하는 하나 이상의 프로세서를 포함하며,상기 프로세서는,상기 사용자의 재활 부위, 상기 재활 부위의 상태 정보 및 상기 사용자의 재활 훈련 스케줄을 기반으로 상기 사용자의 재활 훈련을 위한 제1 목표 모션을 선택하고,상기 선택된 제1 목표 모션을 나타내는 영상을 상기 가상현실 장치를 통해 출력하고,상기 단말을 통해 촬영된 영상에서 상기 사용자의 상기 제1 목표 모션에 대한 수행된 수행 모션을 인식하고,상기 인식된 수행 모션을 평가하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 프로세서는,상기 재활 부위와 관련된 적어도 하나의 신체 부위에 대한 평가 점수를 기반으로 상기 상태 정보를 생성하고,상기 평가 점수는 상기 재활 부위와 관련된 적어도 하나의 신체 부위에 대하여 근력, 가동 범위, 근지구력, 균형성, 유연성, 순발력, 민첩성 및 협응력 중 적어도 하나의 항목에 평가된 것인,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 프로세서는,상기 사용자의 이전 재활 훈련에 대한 결과 데이터를 기반으로 상기 평가 점수를 산출하고,상기 사용자가 이전 재활 훈련에서 수행을 성공했던 제2 목표 모션을 기반으로 상기 제1 목표 모션을 선택하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 프로세서는,상기 제2 목표 모션의 가동 범위 및 상기 제2 목표 모션의 수행에 필요한 근력을 기반으로 상기 제1 목표 모션의 가동 범위를 상기 사용자의 재활 훈련을 위해 보정하고,상기 보정된 제1 목표 모션을 상기 가상현실 장치를 통해 출력하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 프로세서는,상기 인식된 수행 모션이 상기 보정된 제1 목표 모션의 수행에 실패한 것으로 판단되는 경우,상기 인식된 수행 모션을 기반으로 상기 보정된 제1 목표 모션을 재보정하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 프로세서는,상기 사용자의 초기 자세로부터 상기 보정된 제1 목표 모션의 목표 자세까지 상기 사용자의 모션 경로, 상기 목표 자세의 도달 여부 및 모션의 속도를 기반으로 상기 인식된 수행 모션을 평가하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 프로세서는,상기 수행 모션의 반복에 따른 상기 사용자의 상기 목표 자세의 도달 여부 및 모션의 속도를 기반으로 상기 적어도 하나의 신체 부위에 대한 근지구력을 평가하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 프로세서는,상기 사용자의 재활 훈련 진행에 따라 수행되는 수행 모션의 누적에 따라 목표 자세의 도달 여부, 모션 경로의 일치율 및 모션의 속도에 대한 변화값을 산출하고,상기 산출된 변화값을 기반으로 상기 사용자의 근피로도를 산출하고,상기 산출된 근피로도가 기 설정된 임계치에 도달하면 상기 재활 훈련을 종료시키는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>9. 제2항에 있어서,상기 저장부는 운동 기구별로 무게 및 저항 강도 중 적어도 하나가 저장되어 있고,상기 프로세서는,상기 단말을 통해 촬영된 영상 내에서 상기 사용자가 운동 기구를 사용하는 것으로 판단된 경우, 상기 촬영된 영상 내 운동 기구의 이미지를 기반으로 상기 운동 기구의 종류를 판단하고,상기 판단된 운동 기구의 종류를 기반으로 상기 인식된 수행 모션을 평가하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 운동 기구는 서로 다른 색상에 따라 서로 다른 저항 강도를 갖는 세라밴드를 포함하고,상기 저장부는 상기 세라밴드의 색상에 따른 저항 강도와 늘어나는 길이에 따른 저항력이 저장되어 있고,상기 프로세서는,상기 단말을 통해 촬영된 영상에서 상기 사용자가 사용하는 세라밴드의 색상을 판단하고, 상기 사용자의 수행 모션에 의해 상기 세라밴드가 늘어난 길이를 산출하고,상기 판단된 색상 및 상기 산출된 길이를 기반으로 상기 인식된 수행 모션을 평가하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 프로세서는,상기 판단된 세라밴드의 색상을 기반으로 상기 제1 목표 모션을 보정하거나 새로운 목표 모션을 생성하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 프로세서는,상기 단말을 통해 촬영된 영상 내에서 상기 재활 부위의 영상이 차지하는 비율을 산출하고,상기 비율이 기 설정된 비율이 되기 위한 상기 단말과 상기 사용자의 거리를 산출하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 프로세서는,상기 비율이 기 설정된 비율이 되도록 상기 단말의 카메라 배율을 제어하는 제어 신호를 생성하여 상기 단말로 전송하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,상기 저장부는 복수의 제스쳐에 대한 제어신호가 저장되어 있으며,상기 프로세서는,상기 단말을 통해 촬영된 영상에서 상기 복수의 제스쳐 중 특정 제스쳐가 인식되는 경우, 상기 인식된 특정 제스쳐에 해당하는 제어신호를 발생시키는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서,상기 프로세서는,상기 인식된 수행 모션에 대한 평가 결과를 기반으로 상기 사용자 단말로 피드백을 제공하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 프로세서는,상기 사용자의 재활 훈련 내역 및 상기 평가 결과를 저장하고, 병원 서버에 제공하고,상기 사용자의 재활 훈련 스케쥴에 따라 상기 단말로 알림을 제공하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 장치.</claim></claimInfo><claimInfo><claim>17. 카메라;가상현실 장치와 통신하는 통신부;하나 이상의 인스트럭션이 저장된 저장부;상기 인스트럭션을 실행하며, 상기 카메라를 통해 촬영된 영상을 기반으로 사용자의 모션을 인식하는 하나 이상의 프로세서를 포함하며,상기 프로세서는,상기 사용자의 재활 부위, 상기 재활 부위의 상태 정보 및 상기 사용자의 재활 훈련 스케줄을 기반으로 상기 사용자의 재활 훈련을 위한 제1 목표 모션을 선택하고,상기 선택된 제1 목표 모션을 나타내는 영상을 상기 가상현실 장치를 통해 출력하고,상기 촬영된 영상에서 상기 사용자의 상기 제1 목표 모션에 대한 수행된 수행 모션을 인식하고,상기 인식된 수행 모션을 평가하는 것을 특징으로 하는,증강 현실 기반의 재활 훈련 제공 단말.</claim></claimInfo><claimInfo><claim>18. 장치에 의해 수행되는 방법으로,사용자의 재활 부위, 상기 재활 부위의 상태 정보 및 상기 사용자의 재활 훈련 스케줄을 기반으로 상기 사용자의 재활 훈련을 위한 제1 목표 모션을 선택하는 단계;상기 선택된 제1 목표 모션을 나타내는 영상을 가상현실 장치를 통해 출력하는 단계;단말을 통해 촬영된 영상에서 상기 사용자의 상기 제1 목표 모션에 대한 수행된 수행 모션을 인식하는 단계; 및상기 인식된 수행 모션을 평가하는 단계를 포함하는,증강 현실 기반의 재활 훈련 제공 방법.</claim></claimInfo><claimInfo><claim>19. 하드웨어인 컴퓨터와 결합되어, 제18항의 방법을 실행시키기 위한 프로그램이 저장된 컴퓨터 판독 가능한 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서초구...</address><code>220050224041</code><country>대한민국</country><engName>THE CATHOLIC UNIVERSITY OF KOREA INDUSTRY-ACADEMIC COOPERATION FOUNDATION</engName><name>가톨릭대학교 산학협력단</name></applicantInfo><applicantInfo><address>서울특별시 마포구...</address><code>220060514623</code><country>대한민국</country><engName>Hongik University Industry-Academia Cooperation Foundation</engName><name>홍익대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울시 강남구...</address><code> </code><country> </country><engName>Jong-Ho Kim</engName><name>김종호</name></inventorInfo><inventorInfo><address>서울시 성동구...</address><code> </code><country> </country><engName>Youn Kyu Lee</engName><name>이윤규</name></inventorInfo><inventorInfo><address>서울시 마포구...</address><code> </code><country> </country><engName>Youn Hea Jung</engName><name>정윤혜</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구  법원로*길  **, *층 (서초동, 태흥빌딩)</address><code>920201001264</code><country>대한민국</country><engName>BLT Patent &amp; Law Firm</engName><name>특허법인비엘티</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.08</receiptDate><receiptNumber>1-1-2023-0872276-34</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.05.12</receiptDate><receiptNumber>4-1-2025-5125726-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.05.12</receiptDate><receiptNumber>4-1-2025-5125730-07</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230103531.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9362e78244abb2bb059e90fbff4df53a08d51e7d338b9bf3d94e6f99832c4f1a3930fde310bbede819ec0d7f9c59c0709d08b96734e459ff53</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb0ea328bd3a499852fa661e389d09166a5bdb85caf6d9c280373c2969a2c21f0558adaf6f0685a709fc432fe32ae9daac59858626dc03ee0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>