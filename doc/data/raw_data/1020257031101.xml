<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:50.3950</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7031101</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>공동 굽힘 추정</inventionTitle><inventionTitleEng>JOINT BENDING ESTIMATION</inventionTitleEng><openDate>2025.10.21</openDate><openNumber>10-2025-0151480</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.09.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.09.17</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01B 7/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01L 1/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 증강 현실 시스템의 프레임 굽힘을 정정하기 위한 시스템이 제공된다. 변형 게이지들과 시각적 관성 주행 거리 측정의 조합이 프레임의 변형을 결정하는 데 사용된다. 변형 게이지 측정들과 실제 프레임 공간 관계들 사이의 초기 모델은 유한 요소 분석 또는 교정에 기초한다. 초기 시각적 관성 주행 거리 측정 데이터 계산 단계 동안, 증강 현실 시스템은 프레임에 장착된 변형 게이지들로부터의 변형 데이터를 사용하여 프레임의 굽힘 또는 변형들을 계산한다. 후속하는 시각적 관성 주행 거리 측정 데이터 계산들은 프레임의 정정된 프레임 모델을 생성하기 위해 사용된다. 정정된 프레임 모델은 증강 현실 시스템에 의해 제공되는 AR 경험에서 사용되는 가상 오버레이들을 생성하기 위해 사용되는 정정된 추적 데이터 및 정정된 가상 오버레이들을 계산하기 위해 사용된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.08.29</internationOpenDate><internationOpenNumber>WO2024177930</internationOpenNumber><internationalApplicationDate>2024.02.19</internationalApplicationDate><internationalApplicationNumber>PCT/US2024/016369</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터에 의해 구현되는 방법으로서,하나 이상의 프로세서에 의해, 증강 현실(AR) 시스템의 하나 이상의 이미징 디바이스를 사용하여, 현실 세계 장면의 추적 비디오 프레임 데이터를 캡처하는 단계;상기 하나 이상의 프로세서에 의해, 상기 AR 시스템의 하나 이상의 변형 게이지(strain gauge)를 사용하여, 상기 추적 비디오 프레임 데이터가 캡처될 때 상기 AR 시스템의 프레임의 변형들의 변형 데이터를 측정하는 단계;상기 하나 이상의 프로세서에 의해, 상기 변형 데이터, 상기 추적 비디오 프레임 데이터, 및 상기 프레임의 프레임 모델에 기초하여 상기 프레임의 정정된 프레임 모델을 생성하는 단계; 및상기 하나 이상의 프로세서에 의해, 상기 정정된 프레임 모델 및 상기 추적 비디오 프레임 데이터에 기초하여 정정된 추적 데이터를 생성하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 프로세서에 의해, 상기 정정된 추적 데이터에 기초하여 가상 오버레이 데이터를 생성하는 단계;상기 하나 이상의 프로세서에 의해, 상기 정정된 프레임 모델 및 상기 가상 오버레이 데이터에 기초하여 정정된 가상 오버레이 비디오 프레임 데이터를 생성하는 단계; 및상기 하나 이상의 프로세서에 의해, 상기 AR 시스템의 광학 엔진을 사용하여, 상기 정정된 가상 오버레이 비디오 프레임 데이터에 기초하여 상기 AR 시스템의 사용자에게 가상 오버레이를 제공하는 단계를 더 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 프레임의 상기 정정된 프레임 모델을 생성하는 동작은:상기 추적 비디오 프레임 데이터, 상기 변형 데이터, 및 상기 프레임 모델에 기초하여 시각적 관성 주행 거리 측정 데이터(visual inertial odometry data)를 생성하는 단계; 및상기 시각적 관성 주행 거리 측정 데이터 및 상기 프레임 모델에 기초하여 상기 정정된 프레임 모델을 생성하는 단계를 더 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 동작은:상기 변형 데이터에 기초하여 상기 프레임의 요 굽힘 데이터(yaw bending data)를 생성하는 단계; 및상기 추적 비디오 프레임 데이터, 상기 요 굽힘 데이터, 및 상기 프레임 모델에 기초하여 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 단계를 더 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서, 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 동작은:상기 하나 이상의 프로세서에 의해, 상기 프레임의 관성 측정 유닛을 사용하여, 상기 추적 비디오 프레임 데이터가 캡처될 때 상기 프레임의 관성 이동 데이터를 측정하는 단계;상기 관성 이동 데이터에 기초하여 초기 관성 주행 거리 측정 데이터를 생성하는 단계; 및상기 초기 관성 주행 거리 측정 데이터, 상기 추적 비디오 프레임 데이터, 상기 변형 데이터, 및 상기 프레임의 상기 프레임 모델에 기초하여 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 단계를 더 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 하나 이상의 변형 게이지 중 적어도 하나는 상기 프레임의 브리지 부분 상에 장착되는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 AR 시스템은 머리 착용형 AR 장치를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>8. AR 시스템으로서,프레임;상기 프레임의 변형들을 측정하도록 동작 가능한 하나 이상의 변형 게이지;상기 프레임에 장착된 하나 이상의 이미징 디바이스;하나 이상의 프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 AR 시스템으로 하여금:상기 하나 이상의 이미징 디바이스를 사용하여, 현실 세계 장면의 추적 비디오 프레임 데이터를 캡처하는 단계;상기 하나 이상의 프로세서에 의해, 상기 AR 시스템의 상기 하나 이상의 변형 게이지를 사용하여, 상기 추적 비디오 프레임 데이터가 캡처될 때 상기 AR 시스템의 상기 프레임의 상기 변형들의 변형 데이터를 측정하는 단계;상기 하나 이상의 프로세서에 의해, 상기 변형 데이터, 상기 추적 비디오 프레임 데이터, 및 상기 프레임의 프레임 모델에 기초하여 상기 프레임의 정정된 프레임 모델을 생성하는 단계; 및상기 하나 이상의 프로세서에 의해, 상기 정정된 프레임 모델 및 상기 추적 비디오 프레임 데이터에 기초하여 정정된 추적 데이터를 생성하는 단계를 포함하는 동작들을 수행하게 하는, AR 시스템.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 AR 시스템은 상기 프레임에 장착된 광학 엔진을 더 포함하고,상기 명령어들은, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 AR 시스템으로 하여금:상기 정정된 추적 데이터에 기초하여 가상 오버레이 데이터를 생성하는 단계;상기 정정된 프레임 모델 및 상기 가상 오버레이 데이터에 기초하여 정정된 가상 오버레이 비디오 프레임 데이터를 생성하는 단계; 및상기 광학 엔진을 사용하여, 상기 정정된 가상 오버레이 비디오 프레임 데이터에 기초하여 상기 AR 시스템의 사용자에게 가상 오버레이를 제공하는 단계를 포함하는 동작들을 더 수행하게 하는, AR 시스템.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 AR 시스템으로 하여금 상기 프레임의 상기 정정된 프레임 모델을 생성하는 동작들을 수행하게 하는 명령어들은, 상기 AR 시스템으로 하여금:상기 추적 비디오 프레임 데이터, 상기 변형 데이터, 및 상기 프레임 모델에 기초하여 시각적 관성 주행 거리 측정 데이터를 생성하는 단계; 및상기 시각적 관성 주행 거리 측정 데이터 및 상기 프레임 모델에 기초하여 상기 정정된 프레임 모델을 생성하는 단계를 포함하는 동작들을 더 수행하게 하는, AR 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 AR 시스템으로 하여금 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 동작들을 수행하게 하는 명령어들은, 상기 AR 시스템으로 하여금:상기 변형 데이터에 기초하여 상기 프레임의 요 굽힘 데이터를 생성하는 단계; 및상기 추적 비디오 프레임 데이터, 상기 요 굽힘 데이터, 및 상기 프레임 모델에 기초하여 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 단계를 포함하는 동작들을 더 수행하게 하는, AR 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 AR 시스템으로 하여금, 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는 명령어들은, 상기 AR 시스템으로 하여금:상기 하나 이상의 프로세서에 의해, 상기 프레임의 관성 측정 유닛을 사용하여, 상기 추적 비디오 프레임 데이터가 캡처될 때 상기 프레임의 관성 이동 데이터를 결정하는 단계;상기 관성 이동 데이터에 기초하여 초기 관성 주행 거리 측정 데이터를 생성하는 단계; 및상기 초기 관성 주행 거리 측정 데이터, 상기 추적 비디오 프레임 데이터, 상기 변형 데이터, 및 상기 프레임의 상기 프레임 모델에 기초하여 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 단계를 포함하는 동작들을 더 수행하게 하는, AR 시스템.</claim></claimInfo><claimInfo><claim>13. 제8항에 있어서, 상기 하나 이상의 변형 게이지 중 적어도 하나는 상기 프레임의 브리지 부분 상에 장착되는, AR 시스템.</claim></claimInfo><claimInfo><claim>14. 제8항에 있어서, 상기 AR 시스템은 머리 착용형 AR 장치를 포함하는, AR 시스템.</claim></claimInfo><claimInfo><claim>15. 명령어들을 포함하는 비일시적 컴퓨터 판독가능 저장 매체로서,상기 명령어들은 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금: AR 시스템의 하나 이상의 이미징 디바이스를 사용하여, 현실 세계 장면의 추적 비디오 프레임 데이터를 캡처하는 단계;하나 이상의 프로세서에 의해, 상기 AR 시스템의 하나 이상의 변형 게이지를 사용하여, 상기 추적 비디오 프레임 데이터가 캡처될 때 상기 AR 시스템의 프레임의 변형들의 변형 데이터를 측정하는 단계;상기 하나 이상의 프로세서에 의해, 상기 변형 데이터, 상기 추적 비디오 프레임 데이터, 및 상기 프레임의 프레임 모델에 기초하여 상기 프레임의 정정된 프레임 모델을 생성하는 단계; 및상기 하나 이상의 프로세서에 의해, 상기 정정된 프레임 모델 및 상기 추적 비디오 프레임 데이터에 기초하여 정정된 추적 데이터를 생성하는 단계를 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 명령어들은, 상기 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금:상기 정정된 추적 데이터에 기초하여 가상 오버레이 데이터를 생성하는 단계;상기 정정된 프레임 모델 및 상기 가상 오버레이 데이터에 기초하여 정정된 가상 오버레이 비디오 프레임 데이터를 생성하는 단계; 및상기 AR 시스템의 광학 엔진을 사용하여, 상기 정정된 가상 오버레이 비디오 프레임 데이터에 기초하여 상기 AR 시스템의 사용자에게 가상 오버레이를 제공하는 단계를 포함하는 동작들을 더 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금, 상기 프레임의 상기 정정된 프레임 모델을 생성하는 동작들을 수행하게 하는 명령어들은, 상기 컴퓨터로 하여금:상기 추적 비디오 프레임 데이터, 상기 변형 데이터, 및 상기 프레임 모델에 기초하여 시각적 관성 주행 거리 측정 데이터를 생성하는 단계; 및상기 시각적 관성 주행 거리 측정 데이터 및 상기 프레임 모델에 기초하여 상기 정정된 프레임 모델을 생성하는 단계를 포함하는 동작들을 더 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금, 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 동작들을 수행하게 하는 명령어들은, 상기 컴퓨터로 하여금:상기 변형 데이터에 기초하여 상기 프레임의 요 굽힘 데이터를 생성하는 단계; 및상기 추적 비디오 프레임 데이터, 상기 요 굽힘 데이터, 및 상기 프레임 모델에 기초하여 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 단계를 포함하는 동작들을 더 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금, 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 단계를 포함하는 동작들을 수행하게 하는 명령어들은, 상기 컴퓨터로 하여금:상기 프레임의 관성 측정 유닛을 사용하여, 상기 추적 비디오 프레임 데이터가 캡처될 때 상기 프레임의 관성 이동 데이터를 결정하는 단계;상기 관성 이동 데이터에 기초하여 초기 관성 주행 거리 측정 데이터를 생성하는 단계; 및상기 초기 관성 주행 거리 측정 데이터, 상기 추적 비디오 프레임 데이터, 상기 변형 데이터, 및 상기 프레임의 상기 프레임 모델에 기초하여 상기 시각적 관성 주행 거리 측정 데이터를 생성하는 단계를 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 AR 시스템은 머리 착용형 AR 장치를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>오스트리아</country><engName>KALKGRUBER, Matthias</engName><name>칼크그루버, 마티아스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>포르투칼</country><engName>PEREIRA TORRES, Tiago Miguel</engName><name>페레이라 토레스, 티아고 미겔</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>캐나다</country><engName>CHEN, Chao</engName><name>첸, 차오</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>HEGER, Jason</engName><name>헤거, 제이슨</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>RECCHIO, John</engName><name>레키오, 존</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>KRAZ, Mark</engName><name>크라즈, 마크</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>RYNER, Michael</engName><name>라이너, 마이클</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.02.22</priorityApplicationDate><priorityApplicationNumber>18/172,874</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.09.17</receiptDate><receiptNumber>1-1-2025-1066598-95</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.09.23</receiptDate><receiptNumber>1-5-2025-0162269-78</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257031101.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937e31a9d38214751603f3d70225fd34172cb255458028c415604ac9f757a5633b8eb0d4db0f834fc6cde5bdb672b6fb558f258fb56cd8750f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf247b5c78e370b4b94586a638aaef274fd57d0c7595530ebeb5abeadaa324faf5e0d99519e4ad1c7fe4ab92d41beba13328197a106d0c1d74</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>