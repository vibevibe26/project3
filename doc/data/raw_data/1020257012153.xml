<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:22.5122</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7012153</applicationNumber><claimCount>13</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>가상 객체 애니메이션 생성 방법 및 장치, 전자 디바이스, 컴퓨터 판독가능 저장 매체, 및 컴퓨터 프로그램 제품</inventionTitle><inventionTitleEng>VIRTUAL OBJECT ANIMATION GENERATION METHOD AND APPARATUS, ELECTRONIC DEVICE, COMPUTER-READABLE STORAGE MEDIUM, AND COMPUTER PROGRAM PRODUCT</inventionTitleEng><openDate>2025.05.16</openDate><openNumber>10-2025-0068720</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.04.14</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.14</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 출원은 가상 객체 애니메이션 생성 방법 및 장치, 디바이스, 및 컴퓨터 판독가능 저장 매체를 제공한다. 방법은: 처리될 비디오를 취득하고, 상기 비디오 내의 타깃 객체의 초기 3차원 포즈 정보, 2차원 포즈 정보, 및 발 그라운딩 정보를 결정하는 단계; 타깃 객체의 초기 3차원 포즈 정보에 기초하여 인접한 비디오 프레임들 사이의 포즈 변화 정보를 결정하는 단계; 타깃 객체의 초기 3차원 포즈 정보 및 포즈 변화 정보에 기초하여 타깃 객체의 정정될 포즈 정보를 결정하는 단계; 및 타깃 객체의 2차원 포즈 정보 및 발 그라운딩 정보에 기초하여 타깃 객체의 정정될 포즈 정보를 정정하여 타깃 객체의 정정된 포즈 정보를 획득하고, 상기 비디오에 대응하는 가상 객체 애니메이션 비디오를 생성하기 위해 정정된 포즈 정보의 액션을 가상 객체에 리다이렉트하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.09.12</internationOpenDate><internationOpenNumber>WO2024183454</internationOpenNumber><internationalApplicationDate>2024.01.09</internationalApplicationDate><internationalApplicationNumber>PCT/CN2024/071344</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 가상 객체 애니메이션 생성 방법으로서,처리될 비디오를 획득하고, 상기 처리될 비디오에서의 타깃 객체의 초기 3차원(3D) 포즈 정보, 2차원(2D) 포즈 정보, 및 발 지면 접촉 정보를 결정하는 단계;상기 타깃 객체의 초기 3D 포즈 정보에 기초하여 상기 처리될 비디오에서의 2개의 인접한 비디오 프레임들 사이의 포즈 변화 정보를 결정하는 단계;상기 타깃 객체의 초기 3D 포즈 정보 및 상기 포즈 변화 정보에 기초하여 상기 타깃 객체의 정정될 포즈 정보를 결정하는 단계;상기 타깃 객체의 2D 포즈 정보 및 상기 발 지면 접촉 정보에 기초하여 상기 타깃 객체의 정정될 포즈 정보에 대해 정정 처리를 수행하여, 상기 타깃 객체의 정정된 포즈 정보를 획득하는 단계; 및상기 정정된 포즈 정보를 모션 리타깃팅에 의해 가상 객체에 리타깃팅하여, 상기 처리될 비디오에 대응하는 가상 객체 애니메이션 비디오를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 초기 3D 포즈 정보는 초기 포즈 파라미터 및 초기 형상 파라미터를 포함하고, 상기 타깃 객체의 초기 3D 포즈 정보에 기초하여 상기 처리될 비디오에서의 2개의 인접한 비디오 프레임들 사이의 포즈 변화 정보를 결정하는 단계는,훈련된 모션 프라이어 모델을 획득하는 단계; 및상기 훈련된 모션 프라이어 모델을 이용하여 상기 타깃 객체의 초기 포즈 파라미터에 대해 예측 처리를 수행하여, 상기 처리될 비디오에서의 상기 2개의 인접한 비디오 프레임들 사이의 상기 포즈 변화 정보를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 타깃 객체의 초기 3D 포즈 정보 및 상기 포즈 변화 정보에 기초하여 상기 타깃 객체의 정정될 포즈 정보를 결정하는 단계는,상기 처리될 비디오를 복수의 비디오 클립들로 분할하는 단계;i번째 비디오 프레임이 상기 비디오 클립들에서의 제1 프레임인 것으로 결정될 때, 상기 타깃 객체의 초기 3D 포즈 정보를 상기 타깃 객체의 정정될 포즈 정보로서 결정하는 단계 - i = 1, 2, ..., 또는 N이고, N은 상기 처리될 비디오에서의 비디오 프레임들의 총 수량이고, 상기 i번째 비디오 프레임은 상기 타깃 객체가 위치되는 현재 비디오 프레임임 -;상기 i번째 비디오 프레임이 상기 비디오 클립들에서의 제1 프레임이 아니라고 결정될 때, (i-1)번째 비디오 프레임에서 상기 타깃 객체의 정정된 포즈 정보를 획득하는 단계 - 상기 정정된 포즈 정보는 정정된 포즈 파라미터 및 정정된 형상 파라미터를 포함함 -;상기 (i-1)번째 비디오 프레임으로부터 상기 i번째 비디오 프레임으로의 상기 타깃 객체의 포즈 변화 정보 및 상기 (i-1)번째 비디오 프레임에서의 상기 타깃 객체의 정정된 포즈 파라미터에 기초하여 상기 타깃 객체의 정정될 포즈 파라미터를 결정하는 단계; 및상기 타깃 객체에 대응하는 상기 초기 형상 파라미터 및 상기 타깃 객체의 정정될 포즈 파라미터를 상기 타깃 객체의 정정될 포즈 정보로서 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 타깃 객체의 2D 포즈 정보 및 상기 발 지면 접촉 정보에 기초하여 상기 타깃 객체의 정정될 포즈 정보에 대해 정정 처리를 수행하여, 상기 타깃 객체의 정정된 포즈 정보를 획득하는 단계는,상기 타깃 객체의 정정될 포즈 정보, 상기 2D 포즈 정보, 및 카메라 파라미터들에 기초하여 상기 타깃 객체의 재투영 오차를 결정하는 단계;상기 타깃 객체의 정정될 포즈 정보에 기초하여 상기 타깃 객체의 프라이어 정보를 결정하는 단계;(i-1)번째 비디오 프레임에서의 상기 타깃 객체의 발 지면 접촉 정보 및 정정된 포즈 정보, 및 i번째 비디오 프레임에서의 상기 타깃 객체의 발 지면 접촉 정보 및 정정될 포즈 정보에 기초하여 상기 타깃 객체의 정규 항 오차를 결정하는 단계;상기 타깃 객체의 재투영 오차, 상기 프라이어 정보, 및 상기 정규 항 오차에 기초하여 상기 타깃 객체의 총 오차를 결정하는 단계; 및상기 타깃 객체의 총 오차가 최소 값에 도달할 때까지 그래디언트 하강 알고리즘을 이용하여 상기 타깃 객체의 정정될 포즈 정보에 대해 반복적 최적화를 수행하여, 상기 타깃 객체의 정정된 포즈 정보를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 2D 포즈 정보는 상기 타깃 객체의 각각의 관절 포인트의 기준 좌표 정보 및 상기 관절 포인트의 신뢰도를 포함하고, 상기 타깃 객체의 정정될 포즈 정보, 상기 2D 포즈 정보, 및 카메라 파라미터들에 기초하여 상기 타깃 객체의 재투영 오차를 결정하는 단계는,상기 타깃 객체의 정정될 포즈 정보 및 상기 2D 포즈 정보에 기초하여 상기 타깃 객체의 관절 포인트의 카메라 좌표 정보를 결정하는 단계;상기 카메라 파라미터들 및 상기 타깃 객체의 관절 포인트의 상기 카메라 좌표 정보에 기초하여 상기 관절 포인트의 이미지 좌표 정보를 결정하는 단계;상기 관절 포인트의 이미지 좌표 정보 및 상기 관절 포인트의 기준 좌표 정보에 기초하여 상기 관절 포인트의 좌표 오차를 결정하는 단계; 및상기 관절 포인트의 좌표 오차 및 상기 관절 포인트의 신뢰도에 기초하여 상기 타깃 객체의 재투영 오차를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 정정될 포즈 정보는 정정될 포즈 파라미터 및 정정될 형상 파라미터를 포함하고, 상기 프라이어 정보는 포즈 프라이어 정보 및 형상 프라이어 정보를 포함하고, 상기 타깃 객체의 정정될 포즈 정보에 기초하여 상기 타깃 객체의 프라이어 정보를 결정하는 단계는,상기 타깃 객체의 정정될 형상 파라미터에 기초하여 상기 타깃 객체의 형상 프라이어 정보를 결정하는 단계;상기 타깃 객체의 정정될 포즈 파라미터에 대해 인코딩 처리를 수행하여, 잠재 공간에서의 상기 정정될 포즈 파라미터의 인코딩 결과를 획득하는 단계;상기 잠재 공간에서의 상기 정정될 포즈 파라미터의 인코딩 결과에 기초하여 상기 타깃 객체의 포즈 프라이어 정보를 결정하는 단계; 및상기 타깃 객체의 형상 프라이어 정보 및 상기 타깃 객체의 포즈 프라이어 정보에 기초하여 상기 타깃 객체의 프라이어 정보를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,(i-1)번째 비디오 프레임에서의 상기 타깃 객체의 발 지면 접촉 정보 및 정정된 포즈 정보, 및 i번째 비디오 프레임에서의 상기 타깃 객체의 발 지면 접촉 정보 및 정정될 포즈 정보에 기초하여 상기 타깃 객체의 정규 항 오차를 결정하는 단계는,상기 (i-1)번째 비디오 프레임에서의 상기 타깃 객체의 정정된 포즈 정보 및 상기 i번째 비디오 프레임에서의 상기 타깃 객체의 정정될 포즈 정보에 기초하여 상기 타깃 객체의 각각의 관절 포인트의 위치 차이 및 상기 타깃 객체의 각각의 뼈의 길이 차이를 결정하는 단계;상기 (i-1)번째 비디오 프레임에서의 상기 타깃 객체의 발 지면 접촉 정보 및 상기 i번째 비디오 프레임에서의 상기 타깃 객체의 발 지면 접촉 정보에 기초하여 상기 타깃 객체의 발 속도 오차를 결정하는 단계;상기 타깃 객체의 발 관절 포인트와 지면 사이의 높이 차이를 결정하는 단계; 및상기 타깃 객체의 각각의 관절 포인트의 위치 차이, 상기 타깃 객체의 각각의 뼈의 길이 차이, 상기 타깃 객체의 발 속도 오차, 및 상기 발 관절 포인트와 상기 지면 사이의 높이 차이에 기초하여 상기 타깃 객체의 정규 항 오차를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제2항 내지 제7항 중 어느 한 항에 있어서,훈련 비디오 및 미리 설정된 모션 프라이어 모델을 획득하는 단계 - 상기 훈련 비디오는 복수의 훈련 비디오 프레임들을 포함함 -;k번째 훈련 비디오 프레임 및 (k+1)번째 훈련 비디오 프레임을 k번째 훈련 데이터 쌍으로서 결정하는 단계 - k=1, 2, ..., 또는 M-1이고, M은 상기 훈련 비디오의 비디오 프레임들의 총 수량임 -;상기 k번째 훈련 데이터 쌍에서의 상기 2개의 훈련 비디오 프레임들에 대해 인코딩 처리를 수행하여, 상기 잠재 공간에서의 상기 k번째 훈련 데이터 쌍에서의 상기 2개의 훈련 비디오 프레임들의 인코딩 결과들을 획득하는 단계;상기 잠재 공간에서의 상기 k번째 훈련 데이터 쌍에서의 상기 2개의 훈련 비디오 프레임들의 인코딩 결과들에 기초하여 상기 k번째 훈련 데이터 쌍에서의 상기 2개의 훈련 비디오 프레임들의 예측된 변화 정보를 결정하는 단계; 및각각의 훈련 데이터 쌍에서의 2개의 비디오 프레임들의 포즈 변화 정보에 기초하여 상기 미리 설정된 모션 프라이어 모델의 파라미터를 조절하여, 상기 훈련된 모션 프라이어 모델을 획득하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 처리될 비디오에서의 타깃 객체의 초기 3D 포즈 정보, 2D 포즈 정보, 및 발 지면 접촉 정보를 결정하는 단계는,훈련된 3D 포즈 추정 모델, 훈련된 2D 포즈 추정 모델, 및 훈련된 발 지면 접촉 검출 모델을 획득하는 단계;상기 훈련된 3D 포즈 추정 모델을 이용하여 상기 처리될 비디오에 대해 포즈 추정을 수행하여, 상기 처리될 비디오에서의 상기 타깃 객체의 초기 3D 포즈 정보를 획득하는 단계;상기 훈련된 2D 포즈 추정 모델을 이용하여 상기 처리될 비디오에 대해 포즈 추정을 수행하여, 상기 타깃 객체의 2D 포즈 정보를 획득하는 단계; 및상기 훈련된 발 지면 접촉 검출 모델을 이용하여 상기 타깃 객체의 2D 포즈 정보에 대해 예측 처리를 수행하여, 상기 타깃 객체의 발 지면 접촉 정보를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 정정된 포즈 정보를 모션 리타깃팅에 의해 가상 객체에 리타깃팅하여, 상기 처리될 비디오에 대응하는 가상 객체 애니메이션 비디오를 생성하는 단계는,구동될 가상 객체의 신체 메시 정보를 획득하는 단계;상기 가상 객체의 신체 메시 정보에 기초한 모션 리타깃팅에 의해 상기 가상 객체에 상기 정정된 포즈 정보를 적응시켜, 상기 정정된 포즈 정보에 대응하는 액션을 수행하도록 상기 가상 객체를 구동하여, 상기 처리될 비디오에 대응하는 상기 가상 객체 애니메이션 비디오를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 가상 객체 애니메이션 생성 장치로서,처리될 비디오를 획득하고, 상기 처리될 비디오에서의 타깃 객체의 초기 3차원(3D) 포즈 정보, 2차원(2D) 포즈 정보, 및 발 지면 접촉 정보를 결정하도록 구성된 제1 획득 모듈;상기 타깃 객체의 초기 3D 포즈 정보에 기초하여 상기 처리될 비디오에서의 2개의 인접한 비디오 프레임들 사이의 포즈 변화 정보를 결정하도록 구성된 제1 결정 모듈;상기 타깃 객체의 초기 3D 포즈 정보 및 상기 포즈 변화 정보에 기초하여 상기 타깃 객체의 정정될 포즈 정보를 결정하도록 구성된 제2 결정 모듈;상기 타깃 객체의 2D 포즈 정보 및 상기 발 지면 접촉 정보에 기초하여 상기 타깃 객체의 정정될 포즈 정보에 대해 정정 처리를 수행하여, 상기 타깃 객체의 정정된 포즈 정보를 획득하도록 구성된 제1 처리 모듈; 및상기 정정된 포즈 정보를 모션 리타깃팅에 의해 가상 객체에 리타깃팅하여, 상기 처리될 비디오에 대응하는 가상 객체 애니메이션 비디오를 생성하도록 구성된 모션 리타깃팅 모듈을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>12. 전자 디바이스로서,컴퓨터 실행가능 명령어를 저장하도록 구성된 메모리; 및상기 메모리에 저장된 상기 컴퓨터 실행가능 명령어를 실행하여 제1항 내지 제10항 중 어느 한 항에 따른 방법을 구현하도록 구성된 프로세서를 포함하는, 전자 디바이스.</claim></claimInfo><claimInfo><claim>13. 컴퓨터 실행가능 명령어를 저장한 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 실행가능 명령어는, 프로세서에 의해 실행될 때, 제1항 내지 제10항 중 어느 한 항에 따른 방법을 구현하는, 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>14. 컴퓨터 프로그램 또는 컴퓨터 실행가능 명령어를 포함하는 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 프로그램 또는 상기 컴퓨터 실행가능 명령어는, 프로세서에 의해 실행될 때, 제1항 내지 제10항 중 어느 한 항에 따른 방법을 구현하는, 컴퓨터 프로그램 제품.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 ****** 광동 센젠 난산 디스트릭트 미드웨스트 디스트릭트 오브 하이-테크 파크 커지중이 로드 텐센트 빌딩 **층</address><code>520050388561</code><country>중국</country><engName>TENCENT TECHNOLOGY(SHENZHEN) COMPANY LIMITED</engName><name>텐센트 테크놀로지(센젠) 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>ZHANG, Baocheng</engName><name>장, 바오청</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>FU, Xinghui</engName><name>푸, 싱후이</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>CHENG, Qingrong</engName><name>청, 칭룽</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>LI, Zhuo</engName><name>리, 저우</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>GE, Wenhao</engName><name>거, 원하오</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>SUN, Zhongqian</engName><name>쑨, 중첸</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2023.03.06</priorityApplicationDate><priorityApplicationNumber>202310244258.5</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.14</receiptDate><receiptNumber>1-1-2025-0418696-49</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.04.14</receiptDate><receiptNumber>1-1-2025-0419505-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.14</receiptDate><receiptNumber>1-1-2025-0419527-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.04.17</receiptDate><receiptNumber>1-5-2025-0064168-99</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257012153.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936ce5295df05c78c1e60dd2660798340e77eb765290be836135fb6be9e1e3c4deb83b50afcb700ee9736677fbd8e7e0b977ddda0fb42a576e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9df4b14edc179f05bc67e42b4cb925dedd1eba1f068345fc8969934ba63b728898e15d5cd9af5984f6062219c97e63bb2bdade5cd52816eb</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>