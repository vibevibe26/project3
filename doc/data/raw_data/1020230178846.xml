<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:09:09.99</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0178846</applicationNumber><claimCount>21</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>설명력 제공 인공지능 진단 보조 방법 및 그 시스템</inventionTitle><inventionTitleEng>ARTIFICIAL INTELLIGENCE DIAGNOSTIC ASSISTANCE METHOD AND  SYSTEM THAT PROVIDES EXPLAINING-ABILITY</inventionTitleEng><openDate>2024.08.28</openDate><openNumber>10-2024-0130002</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 10/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 실시 예들은 실제 임상의의 판단에 도움이 되는 설명력을 정확하게 제시해줄 수 있고, 실제 임상 진단에도 적용할 수 있는 임상 진단 기준에 기반한 설명력 제공 인공지능 진단 보조 방법 및 그 시스템에 관한 것이다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 미리 정의된 임상적 판단 기준에 근거한 특성 별 등급 점수 정보가 저장된 데이터베이스; 및 상기 데이터베이스에 저장된 상기 임상적 판단 기준에 근거한 특성 별 등급 점수 정보에 기초하여, 미리 훈련된 분류 모델과 설명 가능 인공지능 모듈을 통해, 타깃 의료 데이터에 대한 진단 특성 정보 및 설명력 특성 정보를 추출하여 표시하는 테스트 부를 포함하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 테스트 부는, 상기 타깃 의료 데이터를 입력 받는 제1 의료 데이터 입력 부; 상기 타깃 의료 데이터에 대응되는 전처리를 실행하는 제1 전처리부; 및 상기 미리 훈련된 분류 모델과 상기 설명 가능 인공지능 모듈을 통해, 상기 타깃 의료 데이터에 대한 상기 진단 특성 정보 및 상기 설명력 특성 정보를 추출하여 표시하는 제1 정보 추출 표시부를 포함하는 설명력 제공 인공지능 진단 보조 시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 분류 모델을 훈련시키고 상기 분류 모델과 대응되는 설명력 특성을 선별하기 위한 트레이닝 부를 더 포함하고, 상기 트레이닝 부는, 상기 타깃 의료 데이터의 학습용 영상을 입력 받는 제2 의료 데이터 입력부; 상기 타깃 의료 데이터에 대응되는 전처리를 실행하는 제2 전처리부; 상기 전처리 된 이미지 데이터베이스를 대상으로 분류 모델을 훈련시키는 분류 모델 훈련부; 및 상기 데이터베이스를 통해, 상기 분류 모델과 대응되는 설명력 특성을 선별하는 설명력 특성 선별부를 포함하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제2 전처리부는 상기 타깃 의료 데이터의 영상 별로 고유한 전처리를 실행하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>5. 제3항에 있어서, 상기 제2 전처리부는 상기 영상에 대한 방향 정렬을 수행한 이후 얻어진 영상을 상기 분류 모델 훈련부에 대입하기 위한 통일된 크기로 출력하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>6. 제3항에 있어서, 상기 제2 전처리부는 상하좌우 패딩 방식을 통해 상기 영상 내 특정 부위가 왜곡되지 않는 상태로 이미지 사이즈를 통일시키는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>7. 제3항에 있어서, 상기 분류 모델은 딥러닝 분류 모델이고 블랙박스로 제공되고, 상기 설명력 특성 선별부는, 상기 데이터베이스를 통해, 딥러닝 분류 모델의 블랙박스 내 적격한 설명력 특성을 선별하는 설명력 제공 인공지능 진단 보조 시스템.</claim></claimInfo><claimInfo><claim>8. 제3항에 있어서, 상기 트레이닝 부의 전처리는 상기 테스트 부의 전처리와 동일한 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>9. 제3항에 있어서, 상기 분류 모델 훈련부는 통일된 이미지 사이즈로 전처리 된 이미지 데이터베이스를 활용하여 분류 모델을 훈련시키는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>10. 제3항에 있어서, 상기 분류 모델을 학습시키는 플랫폼은 텐서블로우(Tensorflow) 및 파이토치(PyTorch) 중 하나이고, 상기 분류 모델은 CNN(Convolutional Neural Network) 기반의 알고리즘과 트랜스포머 기반의 알고리즘 중 하나 이상을 포함하는 설명력 제공 인공지능 진단 보조 시스템.                                                                        </claim></claimInfo><claimInfo><claim>11. 제3항에 있어서, 상기 분류 모델은 복수의 레이어 각각에 대한 특성을 추출하며, 로우-레벨 특성인 앞 단에서 하이-레벨 특성인 뒤 단으로 갈수록 특성의 복잡도가 높아지는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 로우-레벨 특성은 작은 픽셀 공간 내의 정보이고, 상기 하이-레벨 특성은 전체적인 윤곽 정보에 해당하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 복수의 레이어는, 상기 복수의 레이어에 대응되는 복수의 특성 중 임상적 특성에 따라 확인이 가능한 특정 레이어를 포함하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 설명력 특성 선별부는, 영상 처리 기반 특성 추출과 딥러닝 기반 특성 추출 간의 상관 관계를 기반으로, 상기 설명력 특성을 선별하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 설명력 특성 선별부는, 상기 복수의 레이어 각각의 대푯값으로서, 평균값, 중앙값 및 최대값 중 하나 이상을 추출하여 임상의의 평가 기준과의 상관 분석을 수행하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>16. 제3항에 있어서, 상기 분류 모델은 상기 트레이닝 부에서 학습한 분류 모델이고, 상기 설명 가능 인공지능 모듈은, 상기 트레이닝 부에서 학습한 분류 모델을 통과시킨 이후, 각 레이어 별 대표 값을 추출하고, 이전 선별한 레이어와 진단 임계점을 고려하여 각 설명력 특성 별 수치를 제시하는 설명력 제공 인공지능 진단 보조 시스템.</claim></claimInfo><claimInfo><claim>17. 제3항에 있어서, 상기 트레이닝 부는 상기 설명력 특성을 추출하는 설명력 특성 추출부 및 설명력을 제시하기 위한 설명력 제시부를 더 포함하고, 상기 설명력 특성 추출부는 라디오믹스(radiomics) 및 색상 특성을 토대로 영상 처리 기반 정량적 특성을 추출하고, 상기 설명력 제시부는 상기 설명력 특성의 선별 과정에서의 결과를 최종적으로 제시하며, 딥러닝이 판단한 임상지표에의 출력과 함께, 딥러닝의 결과값을 영상 처리 특성으로 대체하는 작업을 수행하는 설명력 제공 인공지능 진단 보조 시스템.  </claim></claimInfo><claimInfo><claim>18. 제1항에 있어서, 상기 임상적 판단 기준에 근거한 특성 별 등급 점수 정보를 상기 데이터베이스에 저장시키는 데이터베이스 구축부를 더 포함하고, 상기 데이터베이스 구축부는, 의료 영상 이미지를 통해 진단에 적격한 특성을 선별한 이후, 상기 데이터베이스를 구축하되, 각 특성 별 주관적 지표에 대한 수집 데이터를 입력 받아 상기 데이터베이스를 구축하거나, 영상 처리 기반으로 해당 특성에 대응되는 영상 특징을 추출하여 상기 데이터베이스를 구축하는 설명력 제공 인공지능 진단 보조 시스템. </claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 데이터베이스 구축부는, 의료 영상 이미지를 통해 진단에 적격한 특성을 선별한 이후, 상기 데이터베이스를 구축하되, 각 특성 별 주관적 지표에 대한 수집 데이터를 입력 받지 못하는 경우, 미리 정의된 질감 선별 방식에 따라 질감 정보를 선별하거나, 미리 정의된 혈관 선별 방식에 따라 혈관 정보를 선별하거나,  미리 정의된 색상 선별 방식에 따라 색상 정보를 선별하거나, 미리 정의된 형태 선별 방식에 따라 형태 정보를 선별하거나, 미리 정의된 공간 선별 방식에 따라 공간 정보를 선별하는 설명력 제공 인공지능 진단 보조 시스템.</claim></claimInfo><claimInfo><claim>20. 미리 정의된 임상적 판단 기준에 근거한 특성 별 등급 점수 정보가 저장된 데이터베이스를 구축하는 데이터베이스 구축 단계; 및 상기 데이터베이스에 저장된 상기 임상적 판단 기준에 근거한 특성 별 등급 점수 정보에 기초하여, 미리 훈련된 분류 모델과 설명 가능 인공지능 모듈을 통해, 타깃 의료 데이터에 대한 진단 특성 정보 및 설명력 특성 정보를 추출하여 표시하는 테스트 단계를 포함하는 설명력 제공 인공지능 진단 보조 방법. </claim></claimInfo><claimInfo><claim>21. 제19항에 있어서, 상기 데이터베이스 구축 단계와 상기 테스트 단계 사이에, 분류 모델을 훈련시키고 상기 분류 모델과 대응되는 설명력 특성을 선별하기 위한 트레이닝 단계를 더 포함하는 설명력 제공 인공지능 진단 보조 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 종로구...</address><code>219987005545</code><country>대한민국</country><engName>SEOUL NATIONAL UNIVERSITY HOSPITAL</engName><name>서울대학교병원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM, Young Gon</engName><name>김영곤</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>BAE, Jung Ho</engName><name>배정호</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>KIM, Jung</engName><name>김정</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>SHIN, You Min</engName><name>신유민</name></inventorInfo><inventorInfo><address>경기도 안산시 상록구...</address><code> </code><country> </country><engName>LEE, Chang Woo</engName><name>이창우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로**길**, *층</address><code>920181002416</code><country>대한민국</country><engName>LEECHAE Intellectual Property</engName><name>특허법인리채</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.02.21</priorityApplicationDate><priorityApplicationNumber>1020230022703</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.11</receiptDate><receiptNumber>1-1-2023-1386548-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.12.12</receiptDate><receiptNumber>1-1-2023-1389909-64</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.08.29</receiptDate><receiptNumber>9-5-2025-0830982-03</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230178846.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93ea189098f038aa62ae0eb271bb7ebc837d854395121f1c248a65811b77d3fbf2b8f34cf1e1b5fa691ffe578c7ee79c5ba476fffca1eabbd9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf389b62649a0cdb8e27009ae353bb97de2d936b41f193c8ac1b6c519c878b1fe2427792d1935b12039326519ebb432d0bc44647ab9dc593ca</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>