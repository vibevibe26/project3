<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:00.100</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0180738</applicationNumber><claimCount>48</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>차량 실내의 객체를 검출하기 위한 전자 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE FOR DETECTING AN OBJECT IN A BEHICLE  INDOOR AND OPERATING METHOD THEREOF</inventionTitleEng><openDate>2025.06.20</openDate><openNumber>10-2025-0090748</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B60R 21/015</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B60W 40/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/59</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G08B 21/22</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 차량 실내의 객체를 검출하기 위한 전자 장치의 동작 방법은, 상기 차량 실내에 대한 적어도 하나의 실내 이미지를 획득하는 단계, 상기 적어도 하나의 실내 이미지를 이용하여 기준 이미지를 생성하는 단계, 및 상기 생성된 기준 이미지의 적어도 하나의 분할 영역과, 상기 기준 이미지가 생성된 이후 획득된 상기 차량의 실내 이미지인 타겟 이미지의 적어도 하나의 분할 영역에 기반하여, 상기 차량 내의 객체를 검출하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 차량 실내의 객체를 검출하기 위한 전자 장치의 동작 방법에 있어서,상기 차량 실내에 대한 적어도 하나의 실내 이미지를 획득하는 단계; 상기 적어도 하나의 실내 이미지를 이용하여 기준 이미지를 생성하는 단계; 및상기 생성된 기준 이미지의 적어도 하나의 분할 영역과, 상기 기준 이미지가 생성된 이후 획득된 상기 차량의 실내 이미지인 타겟 이미지의 적어도 하나의 분할 영역에 기반하여, 상기 차량 내의 객체를 검출하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 적어도 하나의 실내 이미지를 획득하는 단계는,상기 차량의 주차 모드에서, 상기 차량의 실내를 일정 시간 동안 소정 프레임 비율로 촬영하는 단계를 포함하며,상기 차량의 주차 모드는 상기 차량의 시동 상태를 감지하여 확인되는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 기준 이미지를 생성하는 단계는,상기 적어도 하나의 실내 이미지 각각에 대해 관심 영역을 설정하는 단계; 및상기 관심 영역이 설정된 각 실내 이미지를 합성하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 관심 영역을 설정하는 단계는,상기 차량의 창문 영역이 최소화되도록 미리 설정된 방식으로 설정하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 미리 설정된 방식은,상기 기준 이미지의 하단 중심점을 기준으로 좌우로부터 각각 제1 비율의 이미지를 제외하고, 상기 기준 이미지의 상단으로부터 제2 비율의 이미지를 제외하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 객체를 검출하는 단계는,상기 타겟 이미지를 복수 개의 영역으로 분할하고, 상기 분할된 복수 개의 영역들 별로 상기 객체를 검출하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 객체를 검출하는 단계는,복수 개의 그리드 컨테이너들을, 상기 그리드 컨테이너들의 분할 사이즈에 따라 오름차순으로 상기 기준 이미지와 상기 타겟 이미지에 순차로 적용하여 상기 객체를 검출하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 복수 개의 그리드 컨테이너들은, 분할 사이즈가 동일한 복수 개의 그리드 컨테이너들을 포함하며, 상기 분할 사이즈가 동일한 복수 개의 그리드 컨테이너들은, 그리드 컨테이너에 포함되는 그리드 셀의 시작 위치가 서로 다르게 설정되고,상기 그리드 셀의 시작 위치가 서로 다르게 설정된, 상기 분할 사이즈가 동일한 복수 개의 그리드 컨테이너들은, 상기 실내 이미지에 함께 적용되는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서, 상기 객체를 검출하는 단계는,상기 순차로 적용된 그리드 컨테이너를 이용하여 상기 객체가 검출되면, 다음 순차의 그리드 컨테이너를 이용하여 상기 객체를 검출하지 않는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 제7항에 있어서, 상기 객체를 검출하는 단계는,상기 순차로 적용된 그리드 컨테이너를 이용하여 상기 객체가 검출된 경우, 상기 객체가 검출된 다음 순차의 그리드 컨테이너를 이용하여 상기 객체를 검출하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 객체의 검출에 대한 알림 정보를 상기 차량 사용자의 단말에게 송신하는 단계를 더 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 검출된 객체의 정보를 획득하는 단계; 및상기 획득한 객체의 정보를 상기 차량 사용자의 단말에게 송신하는 단계를 더 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 객체의 정보를 획득하는 단계는,머신 러닝에 기초하여 상기 객체를 분류하는 단계; 및상기 분류 결과에 기초하여 상기 객체의 클래스 정보를 획득하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 객체를 분류하는 단계는,상기 객체가 사람이면, 상기 기준 이미지에서 사물의 크기와, 상기 사람 간의 비율에 기초하여 상기 사람이 성인, 아동 또는 유아인지 여부로 분류하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>15. 차량 실내의 객체를 검출하기 위한 전자 장치에 있어서,상기 차량 실내에 대한 적어도 하나의 실내 이미지를 획득하는 카메라; 및상기 적어도 하나의 실내 이미지를 이용하여 기준 이미지를 생성하고, 상기 생성된 기준 이미지의 적어도 하나의 분할 영역과, 상기 기준 이미지가 생성된 이후 획득된 상기 차량의 실내 이미지인 타겟 이미지의 적어도 하나의 분할 영역에 기반하여, 상기 차량 내의 객체를 검출하는 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 카메라는, 상기 차량의 주차 모드에서, 상기 차량의 실내를 일정 시간 동안 소정 프레임 비율로 촬영하고, 상기 프로세서는, 상기 차량의 주차 모드를 상기 차량의 시동 상태를 감지하여 확인하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 프로세서는,상기 적어도 하나의 실내 이미지 각각에 대해 관심 영역을 설정하고, 상기 관심 영역이 설정된 각 실내 이미지를 합성하여, 상기 기준 이미지를 생성하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 프로세서는,상기 차량의 창문 영역이 최소화되도록 미리 설정된 방식으로 상기 관심 영역을 설정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 미리 설정된 방식은,상기 기준 이미지의 하단 중심점을 기준으로 좌우로부터 각각 제1 비율의 이미지를 제외하고, 상기 기준 이미지의 상단으로부터 제2 비율의 이미지를 제외하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 프로세서는,상기 타겟 이미지를 복수 개의 영역으로 분할하고, 상기 분할된 복수 개의 영역들 별로 상기 객체를 검출하는, 전자 장치.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 프로세서는,복수 개의 그리드 컨테이너들을, 상기 그리드 컨테이너들의 분할 사이즈에 따라 오름차순으로 상기 기준 이미지와 상기 타겟 이미지에 순차로 적용하여 상기 객체를 검출하는, 전자 장치.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 복수 개의 그리드 컨테이너들은, 분할 사이즈가 동일한 복수 개의 그리드 컨테이너들을 포함하며, 상기 분할 사이즈가 동일한 복수 개의 그리드 컨테이너들은, 그리드 컨테이너에 포함되는 그리드 셀의 시작 위치가 서로 다르게 설정되고,상기 그리드 셀의 시작 위치가 서로 다르게 설정된, 상기 분할 사이즈가 동일한 복수 개의 그리드 컨테이너들은, 상기 실내 이미지에 함께 적용되는, 전자 장치.</claim></claimInfo><claimInfo><claim>23. 제21항에 있어서, 상기 프로세서는, 상기 순차로 적용된 그리드 컨테이너를 이용하여 상기 객체가 검출되면, 다음 순차의 그리드 컨테이너를 이용하여 상기 객체를 검출하지 않는, 전자 장치.</claim></claimInfo><claimInfo><claim>24. 제21항에 있어서, 상기 프로세서는,상기 순차로 적용된 그리드 컨테이너를 이용하여 상기 객체가 검출된 경우, 상기 객체가 검출된 다음 순차의 그리드 컨테이너를 이용하여 상기 객체를 검출하는, 전자 장치.</claim></claimInfo><claimInfo><claim>25. 제15항에 있어서, 상기 객체의 검출에 대한 알림 정보를 상기 차량 사용자의 단말에게 송신하는 통신 회로를 더 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>26. 제15항에 있어서, 상기 프로세서는, 상기 검출된 객체의 정보를 획득하고,상기 전자 장치는, 상기 획득한 객체의 정보를 상기 차량 사용자의 단말에게 송신하는 통신 회로부를 더 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 프로세서는, 머신 러닝에 기초하여 상기 객체를 분류하고, 상기 분류 결과에 기초하여 상기 객체의 클래스 정보를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 프로세서는,상기 객체가 사람이면, 상기 기준 이미지에서 사물의 크기와, 상기 사람 간의 비율에 기초하여 상기 사람이 성인, 아동 또는 유아인지 여부로 분류하는, 전자 장치.</claim></claimInfo><claimInfo><claim>29. 운전자의 상태를 모니터링하는 전자 장치의 동작 방법에 있어서,상기 전자 장치에 구비된 실내 카메라에서 촬영된 차량의 실내 이미지에서 운전자 얼굴의 특징점들을 검출하는 단계;상기 검출된 특징점들의 좌표를 정면 좌표계 상의 좌표로 변환하는 단계; 및적어도 두 개의 상기 변환된 특징점들의 좌표 간의 거리를 이용하여 상기 운전자의 상태를 결정하는 단계를 포함하며,상기 정면 좌표계는, 상기 실내 카메라가 상기 운전자 얼굴을 정면에서 촬영한 이미지 상의 좌표계인, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서, 상기 정면 좌표계 상의 좌표로 변환하는 단계는,상기 실내 카메라의 장착 각도를 획득하는 단계; 및상기 실내 카메라의 장착 각도를 이용하여 상기 특징점들의 좌표를 상기 정면 좌표계 상의 좌표로 변환하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서, 상기 실내 카메라의 장착 각도를 획득하는 단계는,상기 전자 장치에 구비된 전방 카메라가 촬영한 전방 이미지에서 직선 차선을 검출하는 단계;상기 검출된 직선 차선의 소실점을 검출하는 단계;상기 검출된 소실점과 상기 전방 이미지의 중심점을 비교하여, 상기 전방 카메라의 장착 각도를 획득하는 단계; 및상기 전방 카메라의 장착 각도로부터 상기 실내 카메라의 장착 각도를 획득하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서, 상기 실내 카메라의 장착 각도를 획득하는 단계는,자이로(gyro) 센서를 이용하여 상기 실내 카메라의 장착 각도를 획득하는 단계; 및상기 전방 카메라의 장착 각도로부터 획득한 상기 실내 카메라의 장착 각도와, 상기 자이로 센서를 이용하여 획득한 실내 카메라의 장착 각도를 각각 가중합하는 단계; 및상기 가중합된 값을 최종적인 상기 실내 카메라의 장착 각도로 결정하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>33. 제29항에 있어서, 상기 운전자 얼굴의 특징점들을 검출하는 단계는, 상기 운전자 얼굴에서 왼쪽 눈의 중심점을 제1 특징점으로 하고, 오른쪽 눈의 중심점을 제2 중심점으로 하고, 코의 중심점을 제3 특징점으로 검출하는 단계를 포함하고,상기 운전자의 상태를 결정하는 단계는, 상기 제1 특징점의 좌표와 상기 제3 특징점의 좌표 간의 거리와, 상기 제2 특징점의 좌표와 상기 제3 특징점의 좌표 간의 거리의 비율에 기초하여 결정하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서, 상기 운전자의 상태를 결정하는 단계는,상기 거리의 비율이 제1 기준값 이상이거나, 또는 제2 기준값 미만이면, 상기 운전자의 상태를 전방 미응시로 결정하고, 상기 거리의 비율이 상기 제2 기준값 이상이고 상기 제1 기준값 미만이면, 상기 운전자의 상태를 전방 응시 상태로 결정하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>35. 제29항에 있어서, 상기 검출된 운전자 얼굴의 특징점들 중 적어도 복수의 특징점들은, 상기 운전자 얼굴의 특징부 중 하나의 특징부로부터 검출된 것이고,상기 운전자 얼굴의 특징부는, 눈, 코, 입, 눈썹 및 얼굴 윤곽선 중 적어도 하나를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>36. 제35항에 있어서, 상기 운전자의 상태를 결정하는 단계는, 상기 운전자의 왼쪽 눈 및 오른쪽 눈 중 적어도 하나의 눈 각각에 대해서, 상기 하나의 눈에서 검출된 복수 개의 눈 특징점들 중, 상기 하나의 눈의 양단 눈 특징점들 간의 거리와, 상기 하나의 눈의 적어도 하나의 상측의 눈 특징점과 그에 대응하는 하측의 눈 특징점 간의 거리들의 합의 비율(C)에 기초하여 결정하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서, 상기 운전자의 상태를 결정하는 단계는,상기 비율(C)이 제3 기준값 이하로 일정 시간 이상 지속되면, 상기 운전자의 상태를 졸음 상태로 결정하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>38. 제35항에 있어서, 상기 운전자의 상태를 결정하는 단계는,상기 검출된 운전자 얼굴의 특징점들 중 적어도 일부를 학습한 머신 러닝 모델에 의하여, 상기 운전자의 졸음 여부 및/또는 상기 운전자의 전방 주시 여부를 결정하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>39. 운전자의 상태를 모니터링하는 전자 장치에 있어서,차량의 실내를 촬영하는 실내 카메라; 및상기 실내 카메라에서 촬영된 차량의 실내 이미지에서 운전자 얼굴의 특징점들을 검출하고, 상기 검출된 특징점들의 좌표를 정면 좌표계 상의 좌표로 변환하고, 적어도 두 개의 상기 변환된 특징점들의 좌표 간의 거리를 이용하여 상기 운전자의 상태를 결정하는 프로세서를 포함하며,상기 정면 좌표계는, 상기 실내 카메라가 상기 운전자 얼굴을 정면에서 촬영한 이미지 상의 좌표계인, 전자 장치.</claim></claimInfo><claimInfo><claim>40. 제39항에 있어서, 상기 프로세서는,상기 실내 카메라의 장착 각도를 획득하고, 상기 실내 카메라의 장착 각도를 이용하여 상기 특징점들의 좌표를 상기 정면 좌표계 상의 좌표로 변환하는, 전자 장치.</claim></claimInfo><claimInfo><claim>41. 제40항에 있어서, 상기 프로세서는,상기 전자 장치에 구비된 전방 카메라가 촬영한 전방 이미지에서 직선 차선을 검출하고, 상기 검출된 직선 차선의 소실점을 검출하고, 상기 검출된 소실점과 상기 전방 이미지의 중심점을 비교하여, 상기 전방 카메라의 장착 각도를 획득하고, 상기 전방 카메라의 장착 각도로부터 상기 실내 카메라의 장착 각도를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>42. 제41항에 있어서, 상기 프로세서는,자이로(gyro) 센서를 이용하여 상기 실내 카메라의 장착 각도를 획득하고, 상기 전방 카메라의 장착 각도로부터 획득한 상기 실내 카메라의 장착 각도와, 상기 자이로 센서를 이용하여 획득한 실내 카메라의 장착 각도를 각각 가중합하고, 상기 가중합된 값을 최종적인 상기 실내 카메라의 장착 각도로 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>43. 제39항에 있어서, 상기 프로세서는,상기 운전자 얼굴에서 왼쪽 눈의 중심점을 제1 특징점으로 하고, 오른쪽 눈의 중심점을 제2 중심점으로 하고, 코의 중심점을 제3 특징점으로 검출하여, 상기 운전자 얼굴의 특징점들을 검출하고,상기 제1 특징점의 좌표와 상기 제3 특징점의 좌표 간의 거리와, 상기 제2 특징점의 좌표와 상기 제3 특징점의 좌표 간의 거리의 비율에 기초하여, 상기 운전자의 상태를 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>44. 제43항에 있어서, 상기 프로세서는,상기 거리의 비율이 제1 기준값 이상이거나, 또는 제2 기준값 미만이면, 상기 운전자의 상태를 전방 미응시로 결정하고, 상기 거리의 비율이 상기 제2 기준값 이상이고 상기 제1 기준값 미만이면, 상기 운전자의 상태를 전방 응시 상태로 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>45. 제39항에 있어서,상기 검출된 운전자 얼굴의 특징점들 중 적어도 복수의 특징점들은, 상기 운전자 얼굴의 특징부 중 하나의 특징부로부터 검출된 것이고,상기 운전자 얼굴의 특징부는, 눈, 코, 입, 눈썹 및 얼굴 윤곽선 중 적어도 하나를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>46. 제45항에 있어서, 상기 프로세서는,상기 운전자의 왼쪽 눈 및 오른쪽 눈 중 적어도 하나의 눈 각각에 대해서, 상기 하나의 눈에서 검출된 복수 개의 눈 특징점들 중, 상기 하나의 눈의 양단 눈 특징점들 간의 거리와, 상기 하나의 눈의 적어도 하나의 상측의 눈 특징점과 그에 대응하는 하측의 눈 특징점 간의 거리들의 합의 비율(C)에 기초하여, 상기 운전자의 상태를 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>47. 제46항에 있어서, 상기 프로세서는,상기 비율(C)이 제3 기준값 이하로 일정 시간 이상 지속되면, 상기 운전자의 상태를 졸음 상태로 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>48. 제45항에 있어서, 상기 프로세서는,상기 검출된 운전자 얼굴의 특징점들 중 적어도 일부를 학습한 머신 러닝 모델에 의하여, 상기 운전자의 졸음 여부 및/또는 상기 운전자의 전방 주시 여부를 결정하는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>119990173084</code><country>대한민국</country><engName>THINKWARE CORPORATION</engName><name>팅크웨어(주)</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>PARK, Yo Sep</engName><name>박요셉</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>CHOI, Ye Chan</engName><name>최예찬</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>HAN, Tae Kyu</engName><name>한태규</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로**길 * (역삼동) *층(콕스특허법률사무소)</address><code>920090001219</code><country>대한민국</country><engName>Oh, Jae Eon</engName><name>오재언</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.13</receiptDate><receiptNumber>1-1-2023-1397724-57</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230180738.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93dd5ee96a5f8c0740985058c69ffb590eef85f6973acc7fed875bf01ed4dfc9bfac4df89b1505192effd20f1587a6abc3cd03206e030cbf8b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf94c730609b01706b4b64ef2018531c241a201caf444465deb7491642d38a37742998a4613bcbf85e360d123e30af43bc1cec2dc2a4d4ac64</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>