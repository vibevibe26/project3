<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:56.156</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.04.12</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7038708</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>의복 세그먼트화</inventionTitle><inventionTitleEng>GARMENT SEGMENTATION</inventionTitleEng><openDate>2023.12.19</openDate><openNumber>10-2023-0170722</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.11.09</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/214</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/174</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 동작들을 수행하기 위한 방법들 및 시스템들이 개시되며, 이러한 동작들은, 의복을 착용하고 있는 사용자의 묘사를 포함하는 단안 이미지를 수신하는 동작; 단안 이미지에서 사용자에 의해 착용된 의복의 세그먼트화를 생성하는 동작; 단안 이미지 이전에 수신된 복수의 단안 이미지들을 포함하는 비디오 피드에 액세스하는 동작; 사용자에 의해 착용된 의복의 평활화된 세그먼트화를 제공하도록, 비디오 피드를 사용하여, 사용자에 의해 착용된 의복의 세그먼트화를 평활화하는 동작; 및 사용자에 의해 착용된 평활화된 세그먼트화 의복에 기초하여 단안 이미지에 하나 이상의 시각적 효과를 적용하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.10.20</internationOpenDate><internationOpenNumber>WO2022221243</internationOpenNumber><internationalApplicationDate>2022.04.12</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/024364</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 의복을 착용하고 있는 사용자의 묘사를 포함하는 단안 이미지를 수신하는 단계;상기 하나 이상의 프로세서에 의해, 상기 단안 이미지에서 상기 사용자에 의해 착용된 상기 의복의 세그먼트화를 생성하는 단계;상기 단안 이미지 이전에 수신된 복수의 단안 이미지들을 포함하는 비디오 피드에 액세스하는 단계;상기 사용자에 의해 착용된 상기 의복의 평활화된 세그먼트화를 제공하도록, 상기 비디오 피드를 사용하여, 상기 사용자에 의해 착용된 상기 의복의 상기 세그먼트화를 평활화하는 단계; 및상기 사용자에 의해 착용된 상기 평활화된 세그먼트화 의복에 기초하여 상기 단안 이미지에 하나 이상의 시각적 효과를 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 사용자에 의해 착용된 상기 의복은 신체의 상부 영역에서 나타나는 의류들을 포함하는 상부 의복을 포함하고, 상기 단안 이미지는 각각의 의복들을 착용하고 있는 복수의 사용자들의 묘사를 포함하고- 상기 복수의 사용자들은 상기 사용자를 포함함 -, 상기 복수의 사용자들의 상기 각각의 의복들의 복수의 세그먼트화들을 생성하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 단안 이미지는 비디오의 제1 프레임이고, 추가로,제1 머신 학습 기술을 사용하여 상기 세그먼트화를 생성하는 단계- 상기 사용자에 의해 착용된 상기 의복의 세그먼트화를 평활화하는 단계는 상기 생성된 세그먼트화를 상기 복수의 단안 이미지들로부터 상기 제1 머신 학습 기술에 의해 생성되는 이전 세그먼트화와 비교하는 단계를 포함함 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제1 머신 학습 기술은 제1 심층 신경망을 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제3항 또는 제4항에 있어서, 동작들을 수행하는 것에 의해 상기 제1 심층 신경망을 트레이닝하는 단계를 추가로 포함하고, 상기 동작들은,복수의 트레이닝 단안 이미지들 및 상기 복수의 트레이닝 단안 이미지들 각각에 대한 실측 세그먼트화들을 포함하는 트레이닝 데이터를 수신하는 동작;상기 복수의 트레이닝 단안 이미지들 중 제1 트레이닝 단안 이미지에 상기 제1 심층 신경망을 적용하여, 상기 제1 트레이닝 단안 이미지에서 묘사되는 주어진 사용자에 의해 착용된 의복의 세그먼트화를 추정하는 동작;상기 제1 트레이닝 단안 이미지와 연관된 상기 추정된 세그먼트화와 상기 실측 세그먼트화 사이의 편차를 컴퓨팅하는 동작;상기 컴퓨팅된 편차에 기초하여 상기 제1 심층 신경망의 파라미터들을 업데이트하는 동작; 및상기 복수의 트레이닝 단안 이미지들 각각에 대해 상기 적용, 상기 컴퓨팅 및 상기 업데이트 단계들을 반복하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제3항 내지 제5항 중 어느 한 항에 있어서, 상기 트레이닝 데이터는 트레이닝 사용자들에 의해 착용된 상부 의복들의 묘사들을 포함하고, 상기 복수의 트레이닝 단안 이미지들은 상기 각각의 트레이닝 단안 이미지들에서 묘사되는 상기 트레이닝 사용자들의 하나 이상의 신체의 실측 골격 핵심 포인트들을 포함하고, 추가로,상기 제1 단안 이미지에서 묘사되는 상기 주어진 사용자의 상기 실측 골격 핵심 포인트들에 기초하여, 상기 주어진 사용자에 의해 착용된 상기 의복의 소매들을 식별하는 단계; 및상기 소매들을 식별하는 것에 응답하여, 상기 제1 심층 신경망의 파라미터들을 업데이트하기 위해 사용되는 손실 함수의 파라미터와 연관된 가중치를 조정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제3항 내지 제6항 중 어느 한 항에 있어서, 상기 복수의 트레이닝 단안 이미지들은 복수의 이미지 해상도들을 포함하고, 상기 제1 심층 신경망에 기초하여 복수의 세그먼트화 모델들을 생성하는 단계- 상기 복수의 세그먼트화 모델들 중 제1 세그먼트화 모델은 상기 복수의 이미지 해상도들 중 제1 이미지 해상도를 갖는 트레이닝 단안 이미지들에 기초하여 트레이닝되고, 상기 복수의 세그먼트화 모델들 중 제2 세그먼트화 모델은 상기 복수의 이미지 해상도들 중 제2 이미지 해상도를 갖는 트레이닝 단안 이미지들에 기초하여 트레이닝됨 -를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제3항 내지 제7항 중 어느 한 항에 있어서, 상기 복수의 트레이닝 단안 이미지들은 복수의 라벨링된 및 라벨링되지 않은 이미지 및 비디오 데이터를 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제3항 내지 제8항 중 어느 한 항에 있어서, 상기 복수의 트레이닝 단안 이미지들은 특정 사용자의 전체 신체의 묘사, 임의의 사용자의 묘사가 없는 이미지, 복수의 사용자들의 묘사, 및 이미지 캡처 디바이스로부터 상이한 거리들에 있는 사용자들의 묘사들을 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 세그먼트화를 평활화하는 단계는 상기 비디오 피드를 제2 머신 학습 기술에 적용하여 상기 복수의 단안 이미지들에서 각각 의복들의 묘사들에 기초하여 상기 의복의 하나 이상의 세그먼트화를 예측하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 제2 머신 학습 기술은 제2 심층 신경망을 포함하고, 상기 세그먼트화를 평활화하는 단계는 상기 제2 심층 신경망에 의해 제공되는 상기 의복들의 상기 예측된 하나 이상의 세그먼트화를, 제1 머신 학습 기술에 의해 생성되는, 상기 수신된 단안 이미지에서의, 상기 의복의 세그먼트화와 비교하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제10항 또는 제11항에 있어서, 동작들을 수행하는 것에 의해 상기 제2 심층 신경망을 트레이닝하는 단계를 추가로 포함하고, 상기 동작들은,복수의 트레이닝 비디오들 및 상기 복수의 트레이닝 비디오들 각각에서 묘사되는 의복들에 대한 실측 세그먼트화를 포함하는 트레이닝 데이터를 수신하는 동작;상기 복수의 트레이닝 비디오들 중 제1 트레이닝 비디오에 상기 제2 심층 신경망을 적용하여, 상기 제1 트레이닝 비디오에 후속하는 프레임에서 상기 의복의 세그먼트화를 예측하는 동작;상기 제1 트레이닝 비디오에 후속하는 상기 프레임에서의 상기 의복의 상기 예측된 세그먼트화와 상기 제1 트레이닝 비디오에 후속하는 상기 프레임에서 묘사되는 상기 의복의 상기 실측 세그먼트화 사이의 편차를 컴퓨팅하는 동작;상기 컴퓨팅된 편차에 기초하여 상기 제2 심층 신경망의 파라미터들을 업데이트하는 동작; 및상기 복수의 트레이닝 비디오들 각각에 대해 상기 적용, 상기 컴퓨팅 및 상기 업데이트 단계들을 반복하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 복수의 단안 이미지들은 상기 단안 이미지를 수신하기 임계 수의 초들 이전에 수신된 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 추가로,상기 단안 이미지를 캡처하기 위해 사용되는 클라이언트 디바이스의 하나 이상의 디바이스 능력을 결정하는 단계; 및상기 하나 이상의 디바이스 능력에 기초하여 세그먼트화를 생성하기 위해 세그먼트화 모델을 선택하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 하나 이상의 시각적 효과를 적용하는 단계는,상기 사용자에 의해 착용된 상기 의복을 가상 의복으로 대체하는 단계; 및상기 평활화된 세그먼트화 내에 있는 상기 의복의 픽셀들을 타겟 픽셀 값들로 대체하는 것에 의해 상기 사용자에 의해 착용된 상기 의복을 재채색하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 타겟 픽셀 값들은 텍스처 또는 컬러를 표현하는 애니메이션 또는 타겟 이미지의 픽셀들에 대응하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 하나 이상의 시각적 효과를 적용하는 단계는,상기 사용자의 3차원 전체-신체 위치 정보를 표현하는 데이터에 기초하여 상기 이미지에서 묘사되는 상기 사용자의 전체-신체 포즈를 결정하는 단계;상기 사용자에 의해 착용된 상기 의복의 상기 세그먼트화가 상체 의복에 대응한다고 결정하는 단계;상기 사용자에 의해 착용된 상기 의복의 상기 세그먼트화가 상기 상체 의복에 대응한다고 결정하는 것에 응답하여 가상 하체 의복에 액세스하는 단계;상기 사용자의 전체 신체 포즈에 기초하여 상기 가상 하체 의복의 포즈를 조정하는 단계;상기 이미지에서 묘사되는 상기 사용자의 전체-신체 세그먼트화를 수신하는 단계;상기 이미지에서 묘사되는 상기 사용자의 상기 전체-신체 세그먼트화에 기초하여 상기 가상 하체 의복의 픽셀들을 상기 이미지의 배경의 픽셀들과 혼합하는 단계; 및상기 사용자에 의해 착용된 상기 의복과 상기 가상 하체 의복 사이의 폐색 패턴을 선택하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 추가로,상기 사용자에 의해 착용된 상기 의복의 상기 세그먼트화의 일부가 상기 가상 하체 의복의 상기 픽셀들의 제1 부분과 중첩된다고 결정하는 단계; 및상기 사용자에 의해 착용된 상기 의복의 상기 세그먼트화의 상기 부분이 상기 가상 하체 의복의 상기 픽셀들의 상기 부분과 중첩된다고 결정하는 것에 응답하여, 상기 가상 하체 의복의 상기 픽셀들의 상기 제1 부분을 상기 세그먼트화의 상기 부분에 대응하는 상기 사용자에 의해 착용된 상기 의복의 픽셀들의 제2 부분으로 대체하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서,프로세서; 및상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하는 명령어들을 저장한 메모리 컴포넌트를 포함하고, 상기 동작들은, 의복을 착용하고 있는 사용자의 묘사를 포함하는 단안 이미지를 수신하는 동작; 상기 단안 이미지에서 상기 사용자에 의해 착용된 상기 의복의 세그먼트화를 생성하는 동작; 상기 단안 이미지 이전에 수신된 복수의 단안 이미지들을 포함하는 비디오 피드에 액세스하는 동작; 상기 사용자에 의해 착용된 상기 의복의 평활화된 세그먼트화를 제공하도록, 상기 비디오 피드를 사용하여, 상기 사용자에 의해 착용된 상기 의복의 상기 세그먼트화를 평활화하는 동작; 및 상기 사용자에 의해 착용된 상기 평활화된 세그먼트화 의복에 기초하여 상기 단안 이미지에 하나 이상의 시각적 효과를 적용하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 비-일시적 컴퓨터-판독가능 저장 매체로서, 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하는 명령어들을 저장하고, 상기 동작들은,의복을 착용하고 있는 사용자의 묘사를 포함하는 단안 이미지를 수신하는 동작;상기 단안 이미지에서 상기 사용자에 의해 착용된 상기 의복의 세그먼트화를 생성하는 동작;상기 단안 이미지 이전에 수신된 복수의 단안 이미지들을 포함하는 비디오 피드에 액세스하는 동작;상기 사용자에 의해 착용된 상기 의복의 평활화된 세그먼트화를 제공하도록, 상기 비디오 피드를 사용하여, 상기 사용자에 의해 착용된 상기 의복의 상기 세그먼트화를 평활화하는 동작; 및상기 사용자에 의해 착용된 상기 평활화된 세그먼트화 의복에 기초하여 상기 단안 이미지에 하나 이상의 시각적 효과를 적용하는 동작을 포함하는 비-일시적 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>DUDOVITCH, Gal</engName><name>두도비치, 갤</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>HAREL, Peleg</engName><name>하렐, 펠레그</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>MALBIN, Nir</engName><name>말빈, 니르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>SHUVI, Ma'ayan</engName><name>슈비, 마아얀</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>ZOHAR, Matan</engName><name>조하르, 마탄</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.04.12</priorityApplicationDate><priorityApplicationNumber>17/301,690</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.11.09</receiptDate><receiptNumber>1-1-2023-1239281-61</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.11.09</receiptDate><receiptNumber>1-1-2023-1240800-93</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.11.15</receiptDate><receiptNumber>1-5-2023-0183473-43</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237038708.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e70ee2d6491437971a45f3fcfb7c4fb553adff90129cfdecacd59a80caf5161e2c2b11fdf7178998ecb5b4b7411eab11a44735ef29d6859a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa0c19fcc94713e7e912a13648dd29a0b488660163c5aeeececaaabcc0118d452eaf6f13cae31136b0a16b909241afab0cdef4028caf7561a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>