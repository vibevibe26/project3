<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:35.1035</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0084060</applicationNumber><claimCount>8</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>모션 정보를 이용한 시각-언어 멀티모달 사전 학습 방법 및 비디오 텍스트 리트리벌을 수행하는 데이터 처리 장치</inventionTitle><inventionTitleEng>PRE-TRAINING METHOD FOR VISION-LANGUAGE MULTIMODALITY  USING MOTION OF VIDEO AND DATA PROCESSING APPARATUS  FOR VIDEO-TEXT RETRIEVAL</inventionTitleEng><openDate>2025.01.08</openDate><openNumber>10-2025-0004415</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.06.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0499</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/783</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/732</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 모션 정보를 이용한 시각-언어 멀티모달 사전 학습 방법은 데이터 처리 장치가 비디오-텍스트 쌍을 입력받는 단계, 상기 데이터 처리 장치가 상기 비디오를 비디오 트랜스포머에 입력하여 비디오 토큰을 생성하는 단계, 상기 데이터 처리 장치가 상기 비디오에서 추출한 모션 정보를 모션 트랜스포머에 입력하여 모션 토큰을 생성하는 단계, 상기 데이터 처리 장치가 특정 단어가 마스킹된 상기 텍스트를 텍스트 트랜스포머에 입력하여 텍스트 토큰을 생성하는 단계, 상기 데이터 처리 장치가 상기 모션 정보에서 연산한 모션 가중치를 기준으로 상기 비디오 토큰과 상기 모션 토큰을 융합한 융합 특징을 생성하는 단계 및 상기 데이터 처리 장치가 상기 융합 특징 및 상기 텍스트 토큰을 정답 트랜스포머에 입력하여 상기 정답 트랜스포머가 상기 특정 단어를 예측하도록 학습하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 데이터 처리 장치가 비디오-텍스트 쌍을 입력받는 단계;상기 데이터 처리 장치가 상기 비디오를 비디오 트랜스포머에 입력하여 비디오 토큰을 생성하는 단계;상기 데이터 처리 장치가 상기 비디오에서 추출한 모션 정보를 모션 트랜스포머에 입력하여 모션 토큰을 생성하는 단계;상기 데이터 처리 장치가 특정 단어가 마스킹된 상기 텍스트를 텍스트 트랜스포머에 입력하여 텍스트 토큰을 생성하는 단계;상기 데이터 처리 장치가 상기 모션 정보에서 연산한 모션 가중치를 기준으로 상기 비디오 토큰과 상기 모션 토큰을 융합한 융합 특징을 생성하는 단계; 및상기 데이터 처리 장치가 상기 융합 특징 및 상기 텍스트 토큰을 정답 트랜스포머에 입력하여 상기 정답 트랜스포머가 상기 특정 단어를 예측하도록 학습하는 단계를 포함하는 모션 정보를 이용한 시각-언어 멀티모달 사전 학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 데이터 처리 장치는 상기 비디오를 옵티컬 플로우 모델에 입력하여 상기 모션 정보를 생성하는 모션 정보를 이용한 시각-언어 멀티모달 사전 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 데이터 처리 장치는 상기 모션 정보의 수직방향 벡터값과 수평방향 벡터값 각각에 소벨 필터를 적용하여 상기 모션 가중치를 생성하는 모션 정보를 이용한 시각-언어 멀티모달 사전 학습 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 데이터 처리 장치는 상기 모션 가중치 기준으로 가중된 상기 모션 토큰과 상기 비디오 토큰을 결합(concatenation)한 값을 FFN(Feed-Forward Network)에 입력하여 상기 융합 특징을 생성하는 모션 정보를 이용한 시각-언어 멀티모달 사전 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 데이터 처리 장치는 상기 텍스트에서 질문의 유형을 기준으로 마스킹되는 상기 특정 단어를 결정하되,상기 데이터 처리 장치는 상기 질문의 유형이 What 질의인 경우 상기 텍스트 중 명사를 상기 특정 단어로 결정하고, 상기 질문의 유형이 Who 질의인 경우 상기 텍스트 중 동사를 상기 특정 단어로 결정하는 모션 정보를 이용한 시각-언어 멀티모달 사전 학습 방법.</claim></claimInfo><claimInfo><claim>6. 텍스트 쿼리 또는 비디오 쿼리를 입력받는 입력장치;비디오 데이터베이스 또는 텍스트 데이터베이스를 저장하고, 상기 제1항 내지 상기 제5항 중 어느 한 항에 따른 시각-언어 멀티모달 사전 학습 방법으로 학습된 모델을 이용하여 구축된 비디오 텍스트 리트리벌 모델을 저장하는 저장장치; 및 (i) 상기 입력장치가 상기 텍스트 쿼리를 입력받는 경우 상기 텍스트 쿼리를 상기 비디오 텍스트 리트리벌 모델의 텍스트 트랜스포머에 입력하여 텍스트 토큰을 생성하고, 상기 비디오 데이터베이스에 저장된 비디오들에 대한 융합 특징을 생성하고, 상기 비디오들 중 융합 특징이 상기 텍스트 쿼리의 텍스트 토큰과 가장 유사한 비디오를 결정하고, (ii) 상기 입력장치가 상기 비디오 쿼리를 입력받는 경우 상기 비디오 쿼리에 대한 융합 특징을 생성하고, 상기 텍스트 데이터베이스에 저장된 텍스트들 각각에 대한 텍스트 토큰을 생성하고, 상기 텍스트들 중 텍스트 토큰이 상기 비디오 쿼리의 융합 특징과 가장 유사한 텍스트를 결정하는 연산장치를 포함하는 비디오 텍스트 리트리벌을 수행하는 데이터 처리 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 비디오 텍스트 리트리벌 모델은 대조 학습 과정에서 (i) 비디오-텍스트 쌍을 입력받고, (ii) 상기 비디오-텍스트 쌍 중 상기 비디오를 입력데이터로 삼고, 상기 사전 학습 방법에서 구축된 상기 비디오 트랜스포머 및 상기 모션 트랜스포머를 이용하여 생성되는 융합 특징과 (iii) 상기 비디오-텍스트 쌍 중 상기 텍스트를 상기 사전 학습 방법에서 구축된 상기 텍스트 트랜스포머에 입력하여 생성되는 텍스트 토큰이 임베딩 공간에서 일정 정도로근접하도록 대조 학습이 수행된 모델인 비디오 텍스트 리트리벌을 수행하는 데이터 처리 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 비디오 텍스트 리트리벌 모델은 상기 대조 학습 과정에서 생성되는 비디오 토큰이 비디오 메모리뱅크에 저장되고, 모션 토큰이 모션 메모리뱅크에 저장되고, 텍스트 토큰이 텍스트 메모리뱅크에 저장되고,상기 비디오 메모리뱅크, 상기 모션 메모리뱅크 및 상기 텍스트 메모리뱅크에 저장된 벡터들을 대조 샘플로 삼아 상기 대조 학습을 수행한 모델인 비디오 텍스트 리트리벌을 수행하는 데이터 처리 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220040083301</code><country>대한민국</country><engName>Ewha University - Industry Collaboration Foundation</engName><name>이화여자대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 마포구...</address><code> </code><country> </country><engName>KANG, Je Won</engName><name>강제원</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>KIM, Hyeon Ji</engName><name>김현지</name></inventorInfo><inventorInfo><address>인천광역시 부평구...</address><code> </code><country> </country><engName>LEE, Ju Hee</engName><name>이주희</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로**길**, **층, **층(코아렌빌딩)</address><code>920161001214</code><country>대한민국</country><engName>ISIS IP Law LLC</engName><name>특허법인(유한)아이시스</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.06.29</receiptDate><receiptNumber>1-1-2023-0716725-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230084060.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93ff120271c201a7d4c787599d0e8d2b6e3cc83eeaeffc676716fab8595cee58e337099321d370d844b847b8d9a150dd4a6d0ef2170333ba2a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb707501544d3d98cee84d7f435124eb2aedf623c0932d5b8350bcbe04883f133d90b5d3f0cdbb7552c34e320f1f0eb5ea265a9eff9d77ece</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>