<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:03:15.315</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2025.02.03</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-0013240</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다중 에이전트 강화 학습의 안정화 시스템 및 그 방법</inventionTitle><inventionTitleEng>SYSTEMS AND METHODS FOR STABILIZATION OF MULTI-AGENT  REINFORCEMENT LEARNING</inventionTitleEng><openDate>2025.09.17</openDate><openNumber>10-2025-0137068</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/092</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/098</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 5/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 의한 제조 시스템은 프로세서, 및 상기 프로세서가 실행될 때 상기 프로세서가 다음을 수행하도록 하는 명령을 저장하는 메모리: 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작, 상기 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 과거 데이터를 사용하여 상기 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하여 두번째 에이전트 그룹을 형성하는 동작, 상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작, 상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 휴리스틱 규칙 기반 정책에 의해 수집된 과거 데이터를 기반으로 상기 두번째 에이전트 그룹 중 하나 이상의 비수렴 에이전트의 정책을 업데이트하여 세번째 에이전트 그룹을 형성하는 동작 및 상기 첫번째 그룹의 에이전트, 상기 두번째 에이전트 그룹 및 상기 세번째 에이전트 그룹을 기반으로 한 정책을 배포하는 동작을 수행하며, 상기 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하는 동작은 강화 학습 훈련을 수행하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 프로세서; 및 상기 프로세서가 실행될 때 상기 프로세서가 다음을 수행하도록 하는 명령을 저장하는 메모리: 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작, 상기 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 과거 데이터를 사용하여 상기 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하여 두번째 에이전트 그룹을 형성하는 동작, 상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작,상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 휴리스틱 규칙 기반 정책에 의해 수집된 과거 데이터를 기반으로 상기 두번째 에이전트 그룹 중 하나 이상의 비수렴 에이전트의 정책을 업데이트하여 세번째 에이전트 그룹을 형성하는 동작 및 상기 첫번째 그룹의 에이전트, 상기 두번째 에이전트 그룹 및 상기 세번째 에이전트 그룹을 기반으로 한 정책을 배포하는 동작을 수행하며,상기 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하는 동작은 강화 학습 훈련을 수행하는 동작을 포함하는제조 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에서, 상기 강화 학습 훈련을 수행하는 동작은 오프라인으로 수행되고 최소 제곱 시간 차이를 결정하는 동작을 포함하며, 상기 과거 데이터는 다중 에이전트 환경에서 수집되는 제조 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에서,상기 명령은 상기 프로세서가 상기 첫번째 에이전트 그룹 및 상기 두번째 에이전트 그룹에서 식별된 하나 이상의 수렴 에이전트의 신경망 가중치를 고정하는 동작을 더 수행하며, 상기 휴리스틱 기반 정책은 알려진 보상 함수에 해당하고, 상기 두번째 에이전트 그룹 중 하나 이상의 비수렴 에이전트의 정책을 업데이트하는 동작은 상기 정책과 상기 휴리스틱 규칙 기반 정책 간의 최소 제곱 시차를 설정하는 동작을 포함하는 제조 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에서,상기 프로세서가 다음을 수행하도록 하는 명령은:상기 세번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작,상기 세번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 상기 세번째 에이전트 그룹에서 하나 이상의 비수렴 에이전트에 상기 휴리스틱 규칙 기반 정책을 할당하는 동작 및상기 첫번째 에이전트 그룹, 상기 두번째 에이전트 그룹 및 상기 세번째 에이전트 그룹의 수렴 에이전트를 할당된 상기 휴리스틱 규칙 기반 정책과 결합하는 동작을 더 포함하는 제조 시스템.</claim></claimInfo><claimInfo><claim>5. 프로세서에 의해 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 단계;상기 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 과거 데이터를 사용하여 상기 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하여 두번째 에이전트 그룹을 형성하는 단계;상기 프로세서에 의해 상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 단계;상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 상기 프로세서가 휴리스틱 규칙 기반 정책에 의해 수집된 과거 데이터를 기반으로 상기 두번째 에이전트 그룹 중 하나 이상의 비수렴 에이전트의 정책을 업데이트하여 세번째 에이전트 그룹을 형성하는 단계; 및프로세서에 의해 상기 첫번째 에이전트 그룹, 상기 두번째 에이전트 그룹 및 상기 세번째 에이전트 그룹을 기반으로 한 정책을 배포하는 단계를 포함하고,상기 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하는 단계는 강화 학습 훈련 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에서,상기 강화 학습 훈련 단계는 오프라인으로 수행되며 최소 제곱 시간 차이를 결정하는 단계를 포함하고, 상기 과거 데이터는 다중 에이전트 환경에서 수집되는 단계인 방법. </claim></claimInfo><claimInfo><claim>7. 제5항에서,상기 첫번째 에이전트 그룹 및 상기 두번째 에이전트 그룹에서 식별된 하나 이상의 수렴 에이전트의 신경망 가중치를 고정하는 단계를 더 포함하며, 상기 휴리스틱 규칙 기반 정책은 알려진 보상 함수에 해당하고, 상기 두번째 에이전트 그룹 중 하나 이상의 비수렴 에이전트의 정책을 업데이트하는 동작은 상기 정책과 상기 휴리스틱 규칙 기반 정책 간의 최소 제곱 시차를 설정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제5항에서,상기 세번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 단계,상기 세번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 상기 세번째 에이전트 그룹에서 하나 이상의 비수렴 에이전트에 상기 휴리스틱 규칙 기반 정책을 할당하는 단계 및상기 첫번째 에이전트 그룹, 상기 두번째 에이전트 그룹 및 상기 세번째 에이전트 그룹의 수렴 에이전트를 할당된 상기 휴리스틱 규칙 기반 정책과 결합하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서가 다음 동작을 수행하도록 하는 명령을 저장하는 컴퓨터 판독 가능 매체로서,상기 프로세서에 의해 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작;상기 첫번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 과거 데이터를 사용하여 상기 프로세서에 의해 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하여 두번째 에이전트 그룹을 형성하는 동작;프로세서에 의해 상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작; 상기 두번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라, 휴리스틱 규칙 기반 정책에 의해 수집된 과거 데이터를 기반으로 상기 두번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 정책을 상기 프로세서에 의해 업데이트하여 세번째 에이전트 그룹을 형성하는 동작; 및상기 프로세서에 의해 상기 첫번째 에이전트 그룹, 상기 두번째 에이전트 그룹 및 상기 세번째 에이전트 그룹을 기반으로 한 정책을 배포하는 동작을 수행하고,상기 첫번째 에이전트 그룹의 하나 이상의 비수렴 에이전트의 학습을 실시하는 동작은 강화 학습 훈련을 수행하는 동작을 포함하며,상기 강화 학습 훈련을 수행하는 동작은 오프라인으로 수행되고, 상기 과거 데이터는 다중 에이전트 환경에서 수집되는 동작인 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>10. 제9항에서,상기 하나 이상의 프로세서는 상기 첫번째 에이전트 그룹과 상기 두번째 에이전트 그룹에서 식별된 하나 이상의 수렴 에이전트의 신경망 가중치를 고정하는 동작을 포함하고, 상기 세번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별하는 동작, 상기 세번째 에이전트 그룹에서 하나 이상의 수렴 에이전트를 식별함에 따라 상기 세번째 에이전트 그룹에서 하나 이상의 비수렴 에이전트에 상기 휴리스틱 규칙 기반 정책을 할당하는 동작 및 상기 첫번째 에이전트 그룹, 상기 두번째 에이전트 그룹 및 상기 세번째 에이전트 그룹의 수렴 에이전트를 할당된 상기 휴리스틱 규칙 기반 정책과 결합하는 동작을 포함하는 컴퓨터 판독 가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기 용인시 기흥구...</address><code>120120164552</code><country>대한민국</country><engName>Samsung Display Co., Ltd.</engName><name>삼성디스플레이 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>SHUHUI QU</engName><name>쿠 수후이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>LEE, JANGHWAN</engName><name>이장환</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 강남대로 ***, 산학협동재단빌딩 **층(서초동)</address><code>920071000819</code><country>대한민국</country><engName>PanKorea Patent &amp; Law Firm</engName><name>팬코리아특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2024.03.08</priorityApplicationDate><priorityApplicationNumber>63/563,161</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2024.05.02</priorityApplicationDate><priorityApplicationNumber>18/653,901</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2025.02.03</receiptDate><receiptNumber>1-1-2025-0120067-96</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2025.02.10</receiptDate><receiptNumber>9-1-2025-9001459-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2025.02.11</receiptDate><receiptNumber>9-1-2025-9001484-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020250013240.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930cb50a342a061aa426b7c788dfda5a359557e1bd954ba6799bb62517d4d89d15a0eb261889ae5fbb0919d2d70c06cd086bdd8b04c350e3f6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfdfa8a4b3774c34727d6abb93f4eb1afff1b9cbff6711a00ff9fe7f199312acbdcff76b5f67c88530e9b7aacee960aab2b25e5cc3a3125d2d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>