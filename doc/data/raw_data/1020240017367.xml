<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:13:08.138</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0017367</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 추적 시스템 및 3D 위치 보고 방법</inventionTitle><inventionTitleEng>OBJECT TRACKING SYSTEM AND 3D LOCATION REPORTING METHOD</inventionTitleEng><openDate>2025.02.11</openDate><openNumber>10-2025-0021060</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.02.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/593</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 3D 위치 보고 방법은 센서 프레임 레이트를 가지는 복수의 2D 이미지 프레임 및 센서 프레임 레이트를 가지는 복수의 3D 심도 이미지 프레임을 캡처하는 단계 - 복수의 2D 이미지 프레임 및 복수의 3D 심도 이미지 프레임은 인터리빙되고, 복수의 2D 이미지 프레임 중 제1 2D 이미지 프레임은 복수의 3D 심도 이미지 프레임 중 제1 3D 심도 이미지 프레임보다 이전에 캡처됨 -; 복수의 2D 이미지 프레임 중 N 번째 2D 이미지 프레임 및 복수의 3D 심도 이미지 프레임 중 N 번째 3D 심도 이미지 프레임에 따라 제1 3D 위치를 계산하는 단계; 및 N 번째 3D 심도 이미지 프레임 및 복수의 2D 이미지 프레임 중 (N+1) 번째 2D 이미지 프레임에 따라 제2 3D 위치를 계산하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 객체 추적 시스템으로서,센서 프레임 레이트(sensor frame rate)를 가지는 복수의 2D 이미지 프레임(image frame) 및 상기 센서 프레임 레이트를 가지는 복수의 3D 심도 이미지 프레임(depth image frame)을 캡처하도록 구성되는 센서 - 상기 복수의 2D 이미지 프레임 및 상기 복수의 3D 심도 이미지 프레임은 인터리빙(interleave)되고, 상기 복수의 2D 이미지 프레임 중 제1 2D 이미지 프레임은 상기 복수의 3D 심도 이미지 프레임 중 제1 3D 심도 이미지 프레임보다 이전에 캡처됨 -;상기 센서에 결합되는 프로세서; 및상기 프로세서에 결합되고, 3D 위치 보고 방법을 실행하도록 상기 프로세서에 명령하기 위한 프로그램 코드를 저장하도록 구성되는 메모리 - 상기 3D 위치 보고 방법은, 상기 복수의 2D 이미지 프레임 중 N 번째 2D 이미지 프레임 및 상기 복수의 3D 심도 이미지 프레임 중 N 번째 3D 심도 이미지 프레임에 따라 제1 3D 위치를 계산하는 단계; 및 상기 N 번째 3D 심도 이미지 프레임 및 상기 복수의 2D 이미지 프레임 중 (N+1) 번째 2D 이미지 프레임에 따라 제2 3D 위치를 계산하는 단계를 포함함 -를 포함하는 객체 추적 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 복수의 2D 이미지 프레임은 근적외선(NIR : near infrared) 이미지 프레임 또는 RGB 이미지 프레임인, 객체 추적 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제1 3D 위치를 계산하는 단계는,상기 복수의 2D 이미지 프레임에 각각 대응하는 복수의 2D 위치를 계산하는 단계; 및상기 복수의 2D 이미지 프레임 중 상기 N 번째 2D 이미지 프레임에 대응하는 N 번째 2D 위치 및 상기 복수의 3D 심도 이미지 프레임 중 상기 N 번째 3D 심도 이미지 프레임에 따라 상기 제1 3D 위치를 계산하는 단계를 포함하는, 객체 추적 시스템.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 제2 3D 위치를 계산하는 단계는,상기 N 번째 3D 심도 이미지 프레임, 및 상기 복수의 2D 이미지 프레임 중 상기 (N+1) 번째 2D 이미지 프레임에 대응하는 (N+1) 번째 2D 위치에 따라 상기 제2 3D 위치를 계산하는 단계를 더 포함하는, 객체 추적 시스템.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 제2 3D 위치를 계산하는 단계는,상기 N 번째 3D 심도 이미지 프레임 내의 객체의 영역에 대응하는 타깃 3D 심도 이미지 프레임을 계산하는 단계; 및상기 타깃 3D 심도 이미지 프레임, 및 상기 복수의 2D 이미지 프레임 중 상기 (N+1) 번째 2D 이미지 프레임에 대응하는 (N+1) 번째 2D 위치에 따라 상기 제2 3D 위치를 계산하는 단계를 더 포함하는, 객체 추적 시스템.</claim></claimInfo><claimInfo><claim>6. 3D 위치 보고 방법으로서,센서 프레임 레이트를 가지는 복수의 2D 이미지 프레임 및 상기 센서 프레임 레이트를 가지는 복수의 3D 심도 이미지 프레임을 캡처하는 단계 - 상기 복수의 2D 이미지 프레임 및 상기 복수의 3D 심도 이미지 프레임은 인터리빙되고, 상기 복수의 2D 이미지 프레임 중 제1 2D 이미지 프레임은 상기 복수의 3D 심도 이미지 프레임 중 제1 3D 심도 이미지 프레임보다 이전에 캡처됨 -;상기 복수의 2D 이미지 프레임 중 N 번째 2D 이미지 프레임 및 상기 복수의 3D 심도 이미지 프레임 중 N 번째 3D 심도 이미지 프레임에 따라 제1 3D 위치를 계산하는 단계; 및상기 N 번째 3D 심도 이미지 프레임 및 상기 복수의 2D 이미지 프레임 중 (N+1) 번째 2D 이미지 프레임에 따라 제2 3D 위치를 계산하는 단계를 포함하는 3D 위치 보고 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 복수의 2D 이미지 프레임은 근적외선(NIR) 이미지 프레임 또는 RGB 이미지 프레임인, 3D 위치 보고 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 제1 3D 위치를 계산하는 단계는,상기 복수의 2D 이미지 프레임에 각각 대응하는 복수의 2D 위치를 계산하는 단계; 및상기 복수의 2D 이미지 프레임 중 상기 N 번째 2D 이미지 프레임에 대응하는 N 번째 2D 위치 및 상기 복수의 3D 심도 이미지 프레임 중 상기 N 번째 3D 심도 이미지 프레임에 따라 상기 제1 3D 위치를 계산하는 단계를 포함하는, 3D 위치 보고 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 제2 3D 위치를 계산하는 단계는,상기 N 번째 3D 심도 이미지 프레임, 및 상기 복수의 2D 이미지 프레임 중 상기 (N+1) 번째 2D 이미지 프레임에 대응하는 (N+1) 번째 2D 위치에 따라 상기 제2 3D 위치를 계산하는 단계를 더 포함하는, 3D 위치 보고 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 제2 3D 위치를 계산하는 단계는,상기 N 번째 3D 심도 이미지 프레임 내의 객체의 영역에 대응하는 타깃 3D 심도 이미지 프레임을 계산하는 단계; 및상기 타깃 3D 심도 이미지 프레임, 및 상기 복수의 2D 이미지 프레임 중 상기 (N+1) 번째 2D 이미지 프레임에 대응하는 (N+1) 번째 2D 위치에 따라 상기 제2 3D 위치를 계산하는 단계를 더 포함하는, 3D 위치 보고 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대만, 타이난 카운티 *****, 신시 타운쉽, 풍화 빌리지,  지 리안 로드, 넘버.**</address><code>520020212210</code><country>대만</country><engName>HIMAX TECHNOLOGIES LIMITED</engName><name>하이맥스 테크놀로지스 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대만 ***** 타이난 시티 신시...</address><code> </code><country> </country><engName>LIANG, Kuei-Hsin</engName><name>량 쿠에이-신</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, 서림빌딩 **층 (역삼동)</address><code>920011000036</code><country>대한민국</country><engName>YOU ME PATENT &amp; LAW FIRM</engName><name>유미특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.08.04</priorityApplicationDate><priorityApplicationNumber>18/230,172</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.02.05</receiptDate><receiptNumber>1-1-2024-0140090-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2024.02.08</receiptDate><receiptNumber>9-1-2024-9001718-60</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240017367.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d57a9a8fd3aec1f7180cef21e21034e74723b9dc882c7477beb9557ec503feb7769df4311abed748e9eceb0a67202a79acceed29542077f5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf85b6521c68bd283233501b98c59c05cd6cfff1bb3e2607c80b05582350920776ba04374dd18890f441cbebe3bb66408d8a4ac9956c381990</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>