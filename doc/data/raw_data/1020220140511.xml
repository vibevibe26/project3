<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:40.5340</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0140511</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>음성 신호 비식별화 처리 방법 및 그 전자 장치</inventionTitle><inventionTitleEng>METHOD AND ELECTRONIC DEVICE FOR PROCESSING VOICE  SIGNAL DE-IDENTIFICATION</inventionTitleEng><openDate>2024.05.07</openDate><openNumber>10-2024-0059350</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.10.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/48</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 21/0208</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 19/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/15</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 입력 음성 신호를 획득하는 단계, 상기 입력 음성 신호를 인공지능 모델에 입력함으로써, 상기 입력 음성 신호의 개인 특성이 필터링된 출력 음성 신호를 생성하는 단계, 상기 출력 음성 신호를 부호함으로써, 부호화된 음성 정보를 생성하는 단계, 상기 부호화된 음성 정보를 외부 전자장치로 전송하는 단계를 포함하는 음성 신호 처리 방법이 제공된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 음성 신호 처리 방법에 있어서,입력 음성 신호를 획득하는 단계(510);상기 입력 음성 신호를 인공지능 모델에 입력함으로써, 상기 입력 음성 신호의 개인 특성이 필터링된 출력 음성 신호를 생성하는 단계(520); 상기 출력 음성 신호를 부호함으로써, 부호화된 음성 정보를 생성하는 단계(530);상기 부호화된 음성 정보를 외부 전자장치로 전송하는 단계(540)를 포함하고,상기 인공지능 모델은 상기 부호화된 음성 정보에 기초하여 생성된 복원 음성 신호가 개인 특성을 포함하지 않도록 학습된 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 인공지능 모델은 상기 복원된 음성 신호와 입력 음성 신호 사이의 차이에 관한 제1 손실 함수와 상기 복원된 음성 신호와 타겟 음성 신호 사이의 차이에 관한 제2 손실 함수의 합에 해당하는 제3 손실 함수가 최소화 되도록 학습된 것이고,상기 타겟 음성 신호는 복수의 사용자로부터 획득된 음성 신호들에 기초하여 생성된 평균 음성 신호인 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 입력 음성 신호와 상기 타겟 음성 신호의 유사도에 관한 정보를 획득하는 단계를 더 포함하고, 상기 인공지능 모델은 복수의 인공지능 모델 중에서 상기 유사도에 대응되는 인공지능 모델인 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 입력 음성 신호에 포함된 사용자의 대화 내용을 식별하는 단계;상기 사용자의 대화 내용에 개인 정보가 포함되어 있는지 여부를 식별하는 단계; 및상기 입력 음성 신호에 포함된 상기 개인 정보가 제거되도록 상기 입력 음성 신호를 수정하는 단계를 더 포함하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 복수의 감정 상태들 중에서 하나를 선택하는 사용자 입력을 획득하는 단계를 더 포함하고,상기 인공지능 모델은 복수의 감정 상태에 대한 인공지능 모델들 중에서 상기 선택된 감정 상태에 대응되는 인공지능 모델인 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 부호화된 음성 정보가 전달되는 채널을 식별하는 단계; 및상기 채널의 타입에 기초하여, 상기 부호화된 음성 신호를 수정하는 단계를 더 포함하는 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 음성 신호의 상기 개인 특성을 제거하는지 여부에 관한 사용자 입력을 획득하는 단계를 더 포함하고,상기 출력 음성 신호를 생성하는 단계는,상기 개인 특성을 제거하는 사용자 입력에 기초하여, 상기 입력 음성 신호를 상기 인공지능 모델에 입력함으로써, 상기 출력 음성 신호를 생성하는 단계를 포함하는 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 부호화된 음성 정보를 생성하는 단계는,상기 출력 음성 신호의 음성 특징(speech feature)을 추출하는 단계; 및상기 음성 특징을 부호화함으로써 상기 부호화된 음성 정보를 생성하는 단계를 포함하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 부호화된 음성 정보가 개인 특성이 필터링된 것임을 나타내는 정보를 상기 외부 전자장치로 전송하는 단계를 더 포함하는 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 개인 특성은 사용자의 억양, 사용자의 발음 또는 사용자의 톤 중에서 적어도 하나를 포함하는 것을 특징으로 하는, 음성 신호 처리 방법.</claim></claimInfo><claimInfo><claim>11. 음성 신호를 처리하기 위한 전자 장치에 있어서,적어도 하나의 인스트럭션을 저장하는 메모리(1510, 1610); 및상기 적어도 하나의 인스트럭션에 따라 동작하는 적어도 하나의 프로세서(1520, 1620)를 포함하고,상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,입력 음성 신호를 획득하고,상기 입력 음성 신호를 인공지능 모델에 입력함으로써, 상기 입력 음성 신호의 개인 특성이 필터링된 출력 음성 신호를 생성하고, 상기 출력 음성 신호를 부호함으로써, 부호화된 음성 정보를 생성하고,상기 부호화된 음성 정보를 외부 전자장치로 전송하고,상기 인공지능 모델은 상기 부호화된 음성 정보에 기초하여 생성된 복원 음성 신호가 개인 특성을 포함하지 않도록 학습된 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 인공지능 모델은 상기 복원된 음성 신호와 입력 음성 신호 사이의 차이에 관한 제1 손실 함수와 상기 복원된 음성 신호와 타겟 음성 신호 사이의 차이에 관한 제2 손실 함수의 합에 해당하는 제3 손실 함수가 최소화 되도록 학습된 것이고,상기 타겟 음성 신호는 복수의 사용자로부터 획득된 음성 신호들에 기초하여 생성된 평균 음성 신호인 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 입력 음성 신호와 상기 타겟 음성 신호의 유사도에 관한 정보를 획득하고,상기 인공지능 모델은 복수의 인공지능 모델 중에서 상기 유사도에 대응되는 인공지능 모델인 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 입력 음성 신호에 포함된 사용자의 대화 내용을 식별하고,상기 사용자의 대화 내용에 개인 정보가 포함되어 있는지 여부를 식별하고,상기 입력 음성 신호에 포함된 상기 개인 정보가 제거되도록 상기 입력 음성 신호를 수정하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제11항 내지 제14항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,복수의 감정 상태들 중에서 하나를 선택하는 사용자 입력을 획득하고,상기 인공지능 모델은 복수의 감정 상태에 대한 인공지능 모델들 중에서 상기 선택된 감정 상태에 대응되는 인공지능 모델인 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제11항 내지 제15항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 부호화된 음성 정보가 전달되는 채널을 식별하고,상기 채널의 타입에 기초하여, 상기 부호화된 음성 신호를 필터링하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제11항 내지 제16항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 적어도 하나의 프로세서는 상기 음성 신호의 상기 개인 특성을 제거하는지 여부에 관한 사용자 입력을 획득하고,상기 개인 특성을 제거하는 사용자 입력에 기초하여, 상기 입력 음성 신호를 상기 인공지능 모델에 입력함으로써, 상기 출력 음성 신호를 생성하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제11항 내지 제17항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 출력 음성 신호의 음성 특징(speech feature)을 추출하고,상기 음성 특징을 부호화함으로써 상기 부호화된 음성 정보를 생성하는 단계를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제11항 내지 제18항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(1520, 1620)는 상기 적어도 하나의 인스트럭션을 실행함으로써,상기 부호화된 음성 정보가 개인 특성이 필터링된 것임을 나타내는 정보를 상기 외부 전자장치로 전송하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제 10항 중 어느 한 항의 방법을 컴퓨터가 수행하기 위한 인스트럭션들이 기록된, 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>우크라이나 키이우 ***** 르바 톨스토고 ...</address><code> </code><country> </country><engName>PROGONOV, Dmytro</engName><name>프로고노프 드미트로</name></inventorInfo><inventorInfo><address>우크라이나 키이우 ***** 르바 톨스토고 ...</address><code> </code><country> </country><engName>SOKOL, Oleksandra</engName><name>소콜 올렉산드라</name></inventorInfo><inventorInfo><address>우크라이나 키이우 ***** 르바 톨스토고 ...</address><code> </code><country> </country><engName>NAUMENKO, Heorhii</engName><name>나우멘코 헤오르히</name></inventorInfo><inventorInfo><address>우크라이나 키이우 ***** 르바 톨스토고 ...</address><code> </code><country> </country><engName>DERKACH, Viacheslav</engName><name>데르카흐 비아체슬라프</name></inventorInfo><inventorInfo><address>우크라이나 키이우 ***** 르바 톨스토고 ...</address><code> </code><country> </country><engName>VOLOBUIEV, Kostiantyn</engName><name>볼로비에프 코스티안틴</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.10.27</receiptDate><receiptNumber>1-1-2022-1139686-91</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.27</receiptDate><receiptNumber>1-1-2025-1197154-76</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220140511.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931199face00b2ed4759dcbf3c903a5ab36ec97fd31a4e4c401639dcfb1702ded7506fc102f28af9285573c590af3b246f9cc0bbaae22c8534</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9a75f9ca8ec3335e6915a066ebab41bd01e4d97e49c8feefa94e4abb4763e5399eb42baa16523c4a0bd3149f7198da17a67a0f8a5cd73d7a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>