<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:15.5115</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2025.03.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-0035537</applicationNumber><claimCount>31</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>정보 예측 방법 및 자율주행 모델의 훈련 방법, 장치, 컴퓨터 프로그램</inventionTitle><inventionTitleEng>Information prediction method and training method for  autonomous driving model, apparatus, computer program</inventionTitleEng><openDate>2025.04.07</openDate><openNumber>10-2025-0047938</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>B60W 60/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 정보 예측 방법, 자율주행 모델의 훈련 방법, 장치, 기기, 매체, 프로그램, 및 자율주행 차량을 제공하고, 인공 지능 기술 분야에 관한 것으로서, 특히 컴퓨터 비전 및 딥러닝 등 기술 분야에 관한 것이며, 자율주행 등 장면에 적용 가능하다. 정보 예측 방법의 구체적인 실현 방안은, 차량 내의 센서가 수집한 영상 데이터 및 차량의 운전 데이터를 포함하는 감지 데이터를 취득하며; 영상 데이터를 부호화하여, 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 운전 데이터를 부호화하여, 운전 데이터에 대응하는 운전 특징을 얻으며; 운전 특징 및 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 제어 정보를 생성한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 정보 예측 방법으로서, 차량 내의 센서가 수집한 영상 데이터 및 상기 차량의 운전 데이터를 포함하는 감지 데이터를 취득하며; 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻으며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것을 포함하는 정보 예측 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 영상 토큰 시퀀스는 상기 영상 데이터의 이산적인 특징이며; 상기 정보 예측 방법은, 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻는 것을 또한 포함하며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 제어 정보를 생성하는 것을 포함하는, 정보 예측 방법. </claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 운전 데이터는 상기 차량의 주행 파라미터 및 상기 차량의 네비게이션 데이터를 포함하며; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻는 것은, 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻으며; 다층 퍼셉트론을 이용하여 상기 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻는 것을 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 정보 예측 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함하며; 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻는 것은, 상기 적어도 2개의 목표 지점의 위치에 기초하여, 상기 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스크 영상을 생성하며; 상기 제2 컨볼루션 네트워크를 이용하여 상기 마스크 영상을 부호화하여, 상기 제2 특징 벡터를 얻는 것을 포함하는, 정보 예측 방법. </claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻는 것은, 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻으며; 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻는 것을 포함하는 정보 예측 방법. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하는 것은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻으며; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻으며; 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 제어 정보를 얻는 것을, 포함하는 정보 예측 방법. </claim></claimInfo><claimInfo><claim>7. 자율주행 모델의 훈련 방법으로서, 상기 자율주행 모델은 부호화 층 및 생성 모델을 포함하며; 상기 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함하며; 상기 자율주행 모델의 훈련 방법은, 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻으며; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻으며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하며; 상기 예측 토큰 시퀀스와 상기 영상 토큰 시퀀스에 따라, 상기 자율주행 모델을 훈련하는 것을 포함하는 자율주행 모델의 훈련 방법. </claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 샘플 감지 데이터는 실제 제어 정보를 또한 포함하며; 상기 자율주행 모델의 훈련 방법은 상기 실제 제어 정보와 상기 예측 제어 정보 사이의 차이에 따라, 상기 자율주행 모델을 훈련하는 것을 또한 포함하는 자율주행 모델의 훈련 방법. </claim></claimInfo><claimInfo><claim>9. 제7항 또는 제8항에 있어서,상기 자율주행 모델을 훈련하는 것은, 상기 자율주행 모델 중 상기 시퀀스 부호화 네트워크 이외의 기타 모델 구조를 훈련하는 것을, 포함하는 자율주행 모델의 훈련 방법. </claim></claimInfo><claimInfo><claim>10. 제7항에 있어서, 상기 부호화 층은 제1 컨볼루션 네트워크를 또한 포함하며; 상기 자율주행 모델의 훈련 방법은, 상기 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻는 것을 또한 포함하며; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하는 것은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 생성하는 것을, 포함하는 자율주행 모델의 훈련 방법. </claim></claimInfo><claimInfo><claim>11. 제7항 또는 제10항에 있어서, 상기 운전 데이터는 차량의 과거 주행 파라미터 및 상기 차량의 과거 네비게이션 데이터를 포함하며; 상기 운전 데이터 부호화 네트워크는 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포함하며; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻는 것은, 상기 제2 컨볼루션 네트워크를 이용하여 상기 과거 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻으며; 상기 다층 퍼셉트론을 이용하여 상기 과거 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻는 것을, 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 자율주행 모델의 훈련 방법. </claim></claimInfo><claimInfo><claim>12. 제7항에 있어서, 상기 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함하며; 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻는 것은 상기 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻으며; 상기 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻는 것을, 포함하며,상기 시퀀스 부호화 네트워크는 벡터 양자화의 압축 기술에 기초하여 상기 영상 데이터를 처리하는, 자율주행 모델의 훈련 방법. </claim></claimInfo><claimInfo><claim>13. 제7항에 있어서, 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하는 것은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻으며; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻으며; 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 얻는 것을, 포함하며, 상기 생성 모델은 자기 회귀 모델을 포함하는, 자율주행 모델의 훈련 방법. </claim></claimInfo><claimInfo><claim>14. 정보 예측 장치로서, 차량 내의 센서가 수집한 영상 데이터 및 상기 차량의 운전 데이터를 포함하는 감지 데이터를 취득하기 위해 사용되는 데이터 취득 모듈; 상기 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용되는 제1 부호화 모듈; 상기 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용되는 제2 부호화 모듈; 및 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 상기 차량에 대한 제어 정보를 생성하기 위해 사용되는 생성 모듈, 을 포함하는 정보 예측 장치. </claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 영상 토큰 시퀀스는 상기 영상 데이터의 이산적인 특징이며; 상기 정보 예측 장치는, 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻기 위해 사용되는 특징 추출 모듈을 또한 포함하며; 상기 생성 모듈은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 제어 정보를 생성하기 위해 사용되는 정보 예측 장치. </claim></claimInfo><claimInfo><claim>16. 제14항 또는 제15항에 있어서, 상기 운전 데이터는 상기 차량의 주행 파라미터 및 상기 차량의 네비게이션 데이터를 포함하며; 상기 제2 부호화 모듈은, 제2 컨볼루션 네트워크를 이용하여 상기 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻기 위해 사용되는 제1 부호화 서브 모듈; 및 다층 퍼셉트론을 이용하여 상기 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻기 위해 사용되는 제2 부호화 서브 모듈을, 포함하며, 상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 정보 예측 장치. </claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 네비게이션 데이터는 네비게이션 경로 상의 적어도 2개의 목표 지점의 위치를 포함하며; 상기 제1 부호화 서브 모듈은, 상기 적어도 2개의 목표 지점의 위치에 기초하여, 상기 적어도 2개의 목표 지점이 구성한 경로를 표현하는 마스크 영상을 생성하기 위해 사용되는 영상 생성 유닛; 및 상기 제2 컨볼루션 네트워크를 이용하여 상기 마스크 영상을 부호화하여, 상기 제2 특징 벡터를 얻기 위해 사용되는 영상 부호화 유닛을, 포함하는 정보 예측 장치. </claim></claimInfo><claimInfo><claim>18. 제14항에 있어서, 상기 제1 부호화 모듈은, 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻기 위해 사용되는 제3 부호화 서브 모듈; 및 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻기 위해 사용되는 양자화 서브 모듈을, 포함하는, 정보 예측 장치. </claim></claimInfo><claimInfo><claim>19. 제14항에 있어서, 상기 생성 모듈은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용되는 태그 추가 서브 모듈; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻기 위해 사용되는 시퀀스 획득 서브 모듈; 및 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 제어 정보를 얻기 위해 사용되는 생성 서브 모듈을, 포함하는 정보 예측 장치. </claim></claimInfo><claimInfo><claim>20. 자율주행 모델의 훈련 장치로서, 상기 자율주행 모델은 부호화 층 및 생성 모델을 포함하며; 상기 부호화 층은 시퀀스 부호화 네트워크 및 운전 데이터 부호화 네트워크를 포함하며; 상기 자율주행 모델의 훈련 장치는, 상기 시퀀스 부호화 네트워크를 이용하여 샘플 감지 데이터 중의 영상 데이터를 부호화하여, 상기 영상 데이터에 대응하는 영상 토큰 시퀀스를 얻기 위해 사용되는 제1 부호화 모듈; 상기 운전 데이터 부호화 네트워크를 이용하여 상기 샘플 감지 데이터 중의 운전 데이터를 부호화하여, 상기 운전 데이터에 대응하는 운전 특징을 얻기 위해 사용되는 제2 부호화 모듈; 상기 운전 특징 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 영상 토큰 시퀀스에 대응하는 예측 토큰 시퀀스 및 차량에 대한 예측 제어 정보를 생성하기 위해 사용되는 생성 모듈; 및 상기 예측 토큰 시퀀스와 상기 영상 토큰 시퀀스에 따라, 상기 자율주행 모델을 훈련하기 위해 사용되는 훈련 모듈을 포함하는 자율주행 모델의 훈련 장치. </claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 샘플 감지 데이터는 실제 제어 정보를 또한 포함하며; 상기 훈련 모듈은 또한 상기 실제 제어 정보와 상기 예측 제어 정보 사이의 차이에 따라, 상기 자율주행 모델을 훈련하기 위해 사용되는, 자율주행 모델의 훈련 장치. </claim></claimInfo><claimInfo><claim>22. 제20항 또는 제21항에 있어서, 상기 훈련 모듈은, 상기 자율주행 모델 중 상기 시퀀스 부호화 네트워크 이외의 기타 모델 구조를 훈련하기 위해 사용되는, 자율주행 모델의 훈련 장치. </claim></claimInfo><claimInfo><claim>23. 제20항에 있어서, 상기 부호화 층은 제1 컨볼루션 네트워크를 또한 포함하며; 상기 자율주행 모델의 훈련 장치는, 상기 제1 컨볼루션 네트워크를 이용하여 상기 영상 데이터의 영상 특징을 추출하여, 상기 영상 특징을 표현하는 제1 특징 벡터를 얻기 위해 사용되는 특징 추출 모듈을 또한 포함하며; 상기 생성 모듈은, 상기 운전 특징, 상기 제1 특징 벡터 및 상기 영상 토큰 시퀀스에 기초하여, 상기 생성 모델을 이용하여 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 생성하기 위해 사용되는, 자율주행 모델의 훈련 장치. </claim></claimInfo><claimInfo><claim>24. 제20항 또는 제21항에 있어서, 상기 운전 데이터는 차량의 과거 주행 파라미터 및 상기 차량의 과거 네비게이션 데이터를 포함하며; 상기 운전 데이터 부호화 네트워크는 제2 컨볼루션 네트워크 및 다층 퍼셉트론을 포함하며; 상기 제2 부호화 모듈은, 상기 제2 컨볼루션 네트워크를 이용하여 상기 과거 네비게이션 데이터를 부호화하여, 상기 네비게이션 데이터를 표현하는 제2 특징 벡터를 얻기 위해 사용되는 제1 부호화 서브 모듈; 및 상기 다층 퍼셉트론을 이용하여 상기 과거 주행 파라미터를 부호화하여, 상기 주행 파라미터를 표현하는 제3 특징 벡터를 얻기 위해 사용되는 제2 부호화 서브 모듈을, 포함하며,상기 운전 특징은 상기 제2 특징 벡터 및 상기 제3 특징 벡터를 포함하는, 자율주행 모델의 훈련 장치. </claim></claimInfo><claimInfo><claim>25. 제20항에 있어서, 상기 시퀀스 부호화 네트워크는 부호기 및 양자화기를 포함하며; 상기 제1 부호화 모듈은, 상기 부호기를 이용하여 상기 영상 데이터를 부호화하여, 부호화 특징 시퀀스를 얻기 위해 사용되는 제3 부호화 서브 모듈; 및 상기 양자화기를 이용하여 상기 부호화 특징 시퀀스를 양자화 처리하여, 상기 영상 토큰 시퀀스를 얻기 위해 사용되는 양자화 서브 모듈을 포함하며, 상기 시퀀스 부호화 네트워크는 벡터 양자화의 압축 기술에 기초하여 상기 영상 데이터를 처리하는, 자율주행 모델의 훈련 장치. </claim></claimInfo><claimInfo><claim>26. 제20항에 있어서, 상기 생성 모듈은, 상기 영상 토큰 시퀀스의 헤드 위치에 시작 태그를 추가하고, 상기 영상 토큰 시퀀스의 꼬리 위치에 쿼리 태그를 추가하여, 태그된 토큰 시퀀스를 얻기 위해 사용되는 태그 추가 서브 모듈; 상기 운전 특징 및 상기 태그된 토큰 시퀀스에 기초하여, 상기 생성 모델의 입력 시퀀스를 얻기 위해 사용되는 시퀀스 획득 서브 모듈; 및 상기 입력 시퀀스를 상기 생성 모델에 입력하여, 상기 생성 모델이 생성하는 상기 예측 토큰 시퀀스 및 상기 예측 제어 정보를 얻기 위해 사용되는 생성 서브 모듈을 포함하며,상기 생성 모델은 자기 회귀 모델을 포함하는, 자율주행 모델의 훈련 장치. </claim></claimInfo><claimInfo><claim>27. 전자 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통시 연결된 메모리를 포함하며, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 상기 명령어가 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서를 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방법을 실행 가능하게 하는 전자 기기. </claim></claimInfo><claimInfo><claim>28. 전자 기기로서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서와 통시 연결된 메모리를 포함하며, 상기 메모리는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령어를 저항하고, 상기 명령어가 상기 적어도 하나의 프로세서에 의해 실행되어, 상기 적어도 하나의 프로세서를 제7항, 제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 실행 가능하게 하는 전자 기기. </claim></claimInfo><claimInfo><claim>29. 컴퓨터 명령어가 저장되어 있는 비순간 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령어는 상기 컴퓨터로 하여금 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방법 또는 제7항, 제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 실행하기 위해 사용되는 비순간 컴퓨터 판독 가능 저장 매체. </claim></claimInfo><claimInfo><claim>30. 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램이 판독 가능 저장 매체 및 전자 기기 중 적어도 하나에 저장되며, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 때 제1항, 제2항, 및 제4항 내지 제6항 중 어느 하나의 정보 예측 방법 또는 제7항, 제8항, 제10항, 제12항 및 제13항 중 어느 하나의 자율주행 모델의 훈련 방법을 구현하는 컴퓨터 프로그램. </claim></claimInfo><claimInfo><claim>31. 제27항의 전자 기기를 포함하는 자율주행 차량.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국, 베이징 ******, 하이디안 ...</address><code> </code><country>중국</country><engName>GONG, Shi</engName><name>공, 시</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이디안 ...</address><code> </code><country>중국</country><engName>YE, Xiaoqing</engName><name>예, 샤오칭</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이디안 ...</address><code> </code><country>중국</country><engName>TAN, Xiao</engName><name>탄, 샤오</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이디안 ...</address><code> </code><country>중국</country><engName>DING, Errui</engName><name>딩, 에루이</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이디안 ...</address><code> </code><country>중국</country><engName>WANG, Jingdong</engName><name>왕, 징동</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이디안 ...</address><code> </code><country>중국</country><engName>WU, Tian</engName><name>우, 티안</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이디안 ...</address><code> </code><country>중국</country><engName>WANG, Haifeng</engName><name>왕, 하이펑</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서초구 남부순환로 ****, *층(서초동, 한원빌딩)</address><code>920071001019</code><country>대한민국</country><engName>KASAN IP &amp; LAW FIRM</engName><name>특허법인가산</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2024.06.19</priorityApplicationDate><priorityApplicationNumber>202410796725.X</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2025.03.19</receiptDate><receiptNumber>1-1-2025-0313623-43</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>9-1-2025-9003607-82</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020250035537.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934d82fb28e9a9b5ebf366dcb8f7f918098b3c003f9b6edcf21fc5f787065ff9a470a641c06054ecd831beede703d8181e54c94ca2ea65c9e5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf17f0920d8fbb6609f07ea8ac92c95235112500195fb459458841f6dc63a1ea1c2cea69a49a5166a0cafc8d4960075167e37c652cff8e1dff</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>