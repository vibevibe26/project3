<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:13:48.1348</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0157566</applicationNumber><claimCount>17</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>깊이 지도 추정 방법 및 상기 방법을 수행하는 컴퓨팅 장치 및 이를 위한 컴퓨터 판독 가능한 기록 매체</inventionTitle><inventionTitleEng>Depth Map Estimation Method, Computing Device for  Performing the Method and a Computer-readable Recording  Medium therefor</inventionTitleEng><openDate>2025.05.21</openDate><openNumber>10-2025-0071030</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.14</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 깊이 지도 추정 방법이 개시된다. 보다 구체적으로 본 발명은 다운스트림 테스크를 위한 인코더 모델과 디코더 모델 사이의 갭 차이를 감소시킬 수 있는 새로운 자기 주도 학습 모델의 프레임 워크를 제공할 수 있으며, 이러한 새로운 자기 주도 학습 모델의 프레임 워크를 통해 두 개의 양안 이미지로부터 보다 정확한 깊이 지도를 추정할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 깊이 지도를 추정하고자 하는 원본 좌안 이미지 및 원본 우안 이미지를 획득하는 단계;상기 원본 좌안 이미지 및 원본 우안 이미지 각각에 대해 임의의 패치(Patch)를 마스킹(Masking)함으로써 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 각각 생성하는 단계;제1 인코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 제1 CLS(Special Classification token) 값 및 상기 마스킹된 패치에 대한 제1 패치 값을 예측하고, 제2 인코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 제2 CLS 값 및 상기 마스킹된 패치에 대한 제2 패치 값을 예측하는 단계;상기 제1 인코더의 출력 값 및 제2 인코더의 출력 값에 기초하여 결정된 손실 값(loss value)에 기초하여 상기 제1 인코더와 제2 인코더를 학습하는 단계;상기 학습된 제1 인코더에 연결되는 제1 디코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 제1 깊이 지도를 예측하고, 상기 학습된 제2 인코더에 연결되는 제2 디코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 제2 깊이 지도를 예측하는 단계; 및상기 제1 디코더의 출력 값 및 제2 디코더의 출력 값에 기초하여 결정된 손실 값에 기초하여 상기 제1 디코더와 제2 디코더를 학습하는 단계를 포함하는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 인코더와 제2 인코더를 학습하는 단계는,상기 제1 인코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 제1 CLS 값과 상기 제2 인코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 예측된 제2 CLS 값에 기초하여 제1 손실 값을 결정하는 단계;상기 결정된 제1 손실 값에 기초하여 상기 제2 인코더를 학습하는 단계; 및상기 학습된 제2 인코더의 파라미터들에 대한 지수 이동 평균(Exponential Moving Average, EMA)을 제1 인코더에 적용함으로써 상기 제1 인코더를 학습하는 단계를 포함하는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제1 손실 값은,상기 제1 CLS 값과 제2 CLS 값 사이의 교차 엔트로피 오차(Cross Entropy Error, CEE)를 이용하여 결정되는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제1 인코더와 제2 인코더를 학습하는 단계는,상기 제1 인코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 상기 마스킹된 패치에 대한 제1 패치 값과 상기 제2 인코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 예측된 상기 마스킹된 패치에 대한 제2 패치 값에 기초하여 결정된 제2 손실　 값을 결정하는 단계;상기 결정된 제2 손실 값에 기초하여 상기 제2 인코더를 학습하는 단계; 및상기 학습된 제2 인코더의 파라미터들에 대한 지수 이동 평균(Exponential Moving Average, EMA)을 제1 인코더에 적용함으로써 상기 제1 인코더의 파라미터들을 학습하는 단계를 포함하는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제2 손실 값은,상기 제1 패치 값과 제2 패치 값 사이의 평균 제곱 오차(Mean Square Error, MSE)를 이용하여 결정되는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제1 디코더와 제2 디코더를 학습하는 단계는,상기 원본 좌안 이미지 및 원본 우안 이미지에 대한 원본 깊이 지도와 상기 제1 디코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 제1 깊이 지도에 기초하여 제3 손실 값을 결정하는 단계; 및상기 결정된 제3 손실 값에 기초하여 상기 제1 디코더를 학습하는 단계를 포함하는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 제1 디코더와 제2 디코더를 학습하는 단계는,상기 제1 디코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 제1 깊이 지도와 상기 제2 디코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 예측된 제2 깊이 지도에 기초하여 제4 손실 값을 결정하는 단계; 및상기 결정된 제4 손실 값에 기초하여 상기 제2 디코더를 학습하는 단계를 포함하는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 제3 손실 값 및 제4 손실 값은,상기 원본 깊이 지도와 제1 깊이 지도 사이의 평균 절대 오차(Mean Absolute Error, MAE) 및 상기 제1 깊이 지도와 제2 깊이 지도 사이의 평균 절대 오차를 이용하여 각각 결정되는 깊이 지도 추정 방법.</claim></claimInfo><claimInfo><claim>9. 하드웨어와 결합되어 제1항 내지 제8항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>10. 컴퓨팅 장치에 있어서,하나 이상의 프로세서; 및상기 프로세서에 의해 실행되는 프로그램을 로드(load)하거나 저장하는 메모리를 포함하되,상기 프로그램은,깊이 지도를 추정하고자 하는 원본 좌안 이미지 및 원본 우안 이미지를 획득하는 단계; 상기 원본 좌안 이미지 및 원본 우안 이미지 각각에 대해 임의의 패치(Patch)를 마스킹(Masking)함으로써 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 각각 생성하는 단계; 제1 인코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 제1 CLS(Special Classification token) 값 및 상기 마스킹된 패치에 대한 제1 패치 값을 예측하고, 제2 인코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 제2 CLS 값 및 상기 마스킹된 패치에 대한 제2 패치 값을 예측하는 단계; 상기 제1 인코더의 출력 값 및 제2 인코더의 출력 값에 기초하여 결정된 손실 값(loss value)에 기초하여 상기 제1 인코더와 제2 인코더를 학습하는 단계; 상기 학습된 제1 인코더에 연결되는 제1 디코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 제1 깊이 지도를 예측하고, 상기 학습된 제2 인코더에 연결되는 제2 디코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 제2 깊이 지도를 예측하는 단계; 및 상기 제1 디코더의 출력 값 및 제2 디코더의 출력 값에 기초하여 결정된 손실 값에 기초하여 상기 제1 디코더와 제2 디코더를 학습하는 단계를 포함하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 프로세서는,상기 제1 인코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 제1 CLS 값과 상기 제2 인코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 예측된 제2 CLS 값에 기초하여 제1 손실 값을 결정하고, 상기 결정된 제1 손실 값에 기초하여 상기 제2 인코더를 학습하며, 상기 학습된 제2 인코더의 파라미터들에 대한 지수 이동 평균(Exponential Moving Average, EMA)을 제1 인코더에 적용함으로써 상기 제1 인코더를 학습하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 제1 손실 값은,상기 제1 CLS 값과 제2 CLS 값 사이의 교차 엔트로피 오차(Cross Entropy Error, CEE)를 이용하여 결정되는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,상기 프로세서는,상기 제1 인코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 상기 마스킹된 패치에 대한 제1 패치 값과 상기 제2 인코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 예측된 상기 마스킹된 패치에 대한 제2 패치 값에 기초하여 제2 손실　 값을 결정하고, 상기 결정된 제2 손실 값에 기초하여 상기 제2 인코더를 학습하며, 상기 학습된 제2 인코더의 파라미터들에 대한 지수 이동 평균(Exponential Moving Average, EMA)을 제1 인코더에 적용함으로써 상기 제1 인코더의 파라미터들을 학습하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 제2 손실 값은,상기 제1 패치 값과 제2 패치 값 사이의 평균 제곱 오차(Mean Square Error, MSE)를 이용하여 결정되는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서,상기 프로세서는,상기 원본 좌안 이미지 및 원본 우안 이미지에 대한 원본 깊이 지도와 상기 제1 디코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 제1 깊이 지도에 기초하여 제3 손실 값을 결정하고, 상기 결정된 제3 손실 값에 기초하여 상기 제1 디코더를 학습하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 프로세서는,상기 제1 디코더에 상기 원본 좌안 이미지 및 원본 우안 이미지를 입력하여 예측된 제1 깊이 지도와 상기 제2 디코더에 상기 마스킹된 좌안 이미지 및 마스킹된 우안 이미지를 입력하여 예측된 제2 깊이 지도에 기초하여 제4 손실 값을 결정하고, 상기 결정된 제4 손실 값에 기초하여 상기 제2 디코더를 학습하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 제3 손실 값 및 제4 손실 값은,상기 원본 깊이 지도와 제1 깊이 지도 사이의 평균 절대 오차(Mean Absolute Error, MAE) 및 상기 제1 깊이 지도와 제2 깊이 지도 사이의 평균 절대 오차를 이용하여 각각 결정되는 컴퓨팅 장치.　　</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220040083301</code><country>대한민국</country><engName>Ewha University - Industry Collaboration Foundation</engName><name>이화여자대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>MIN Dong Bo</engName><name>민동보</name></inventorInfo><inventorInfo><address>서울특별시 마포구...</address><code> </code><country> </country><engName>AHN Ji Hye</engName><name>안지혜</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.14</receiptDate><receiptNumber>1-1-2023-1260248-57</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230157566.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93191078e9070af38d272b6f7fc6c1c0992fa008c741a4642227e2a49f9a14274f7e167ec688b0b67c939e023d269fcea2b0643ac09e13e88c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf85c8c7fe549487099838d35d6d4bc1830d0338b06bc909dbea978f0402ce32bbc36309d2e0e2dda0966c06f031a68d0461bc36cf2f1b7a76</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>