<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:25.125</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.12</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7024068</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>실시간 의복 교환</inventionTitle><inventionTitleEng>REAL-TIME GARMENT EXCHANGE</inventionTitleEng><openDate>2024.08.23</openDate><openNumber>10-2024-0128015</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.07.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.07.17</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/54</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/56</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 비디오에서의 의복을 어느 한 현실 세계 객체로부터 또 다른 것으로 실시간으로 전달하기 위한 동작들을 수행하기 위한 방법들 및 시스템들이 개시된다. 동작들은 제1 자세로 제1 의복을 착용한 제1 사람의 묘사를 포함하는 제1 비디오를 수신하는 동작 및 제2 자세로 제2 의복을 착용한 제2 사람의 묘사를 포함하는 제2 비디오를 획득하는 동작을 포함한다. 동작들은 제1 비디오에 묘사된 제1 사람의 제1 자세와 매칭되도록 제2 사람의 자세를 수정하는 동작을 포함한다. 동작들은 제2 사람이 제2 비디오에서 착용하고 있는 제2 의복의 전신 세그먼테이션을 생성하는 동작 및 제2 사람이 제2 비디오에서 착용하고 있는 제2 의복의 전신 세그먼테이션에 기초하여 제1 사람의 외관을 제1 의복을 착용한 것으로부터 제2 의복을 착용한 것으로 변경하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.06.29</internationOpenDate><internationOpenNumber>WO2023121897</internationOpenNumber><internationalApplicationDate>2022.12.12</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/052528</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서:하나 이상의 프로세서에 의해, 제1 자세로 제1 의복을 착용한 제1 사람의 묘사를 포함하는 제1 비디오를 수신하는 단계;제2 자세로 제2 의복을 착용한 제2 사람의 묘사를 포함하는 제2 비디오를 획득하는 단계;상기 제1 비디오에 묘사된 상기 제1 사람의 상기 제1 자세와 매칭되도록 상기 제2 비디오에 묘사된 상기 제2 사람의 상기 제2 자세를 상기 제2 자세로부터 상기 제1 자세로 수정하는 단계;상기 제1 사람의 상기 제1 자세와 매칭되도록 상기 제2 사람의 상기 제2 자세를 수정한 후에, 상기 제2 사람이 상기 제2 비디오에서 착용하고 있는 상기 제2 의복의 전신 세그먼테이션을 생성하는 단계; 및상기 제2 사람이 상기 제2 비디오에서 착용하고 있는 상기 제2 의복의 전신 세그먼테이션에 기초하여 상기 제1 사람의 외관을 표현하는 외관 데이터를 상기 제1 의복을 착용한 것으로부터 상기 제2 의복을 착용한 것으로 변경하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 사람과 연관된 상기 외관 데이터를 변경하는 단계는:상기 제1 비디오로부터 상기 제1 사람과 연관된 외관 및 모션 데이터를 추출하는 단계;상기 제2 비디오로부터 상기 제2 사람과 연관된 외관 및 모션 데이터를 추출하는 단계;상기 제1 사람과 연관된 모션 데이터와 매칭되도록 상기 제2 사람과 연관된 모션 데이터를 수정하는 단계;상기 제2 사람과 연관된 모션 데이터를 수정하여 상기 제2 의복에 대응하는 픽셀들을 획득한 후에, 상기 전신 세그먼테이션에 기초하여, 상기 제2 사람과 연관된 외관 데이터에 마스크를 적용하는 단계; 상기 제2 사람과 연관된 외관 데이터에 적용된 상기 마스크 내의 픽셀들에 기초하여 상기 제1 사람과 연관된 외관 데이터의 일부분을 대체하는 단계; 및상기 제1 사람과 연관된 외관 데이터의 일부분을 대체한 것에 기초하여, 상기 제1 의복 대신에 상기 제2 의복을 착용한 상기 제1 사람의 묘사를 포함하는 제3 비디오를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 제1 사람과 연관된 외관 데이터에 상기 마스크를 적용하여 타깃 픽셀들의 세트를 식별하는 단계; 및상기 제2 의복에 대응하는 픽셀들을 상기 타깃 픽셀들의 세트에 복사하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제2 사람의 자세를 수정하는 단계는:상기 제2 비디오로부터 상기 제2 사람과 연관된 외관 데이터를 추출하는 단계;상기 제1 비디오로부터 상기 제1 사람의 모션을 추출하는 단계; 및상기 제2 사람과 연관된 외관 데이터 및 상기 제1 사람과 연관된 모션 데이터를 갖는 상기 제2 사람의 묘사를 포함하는 제3 비디오를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제3 비디오에 마스크를 적용하여 상기 제2 의복에 대응하는 픽셀들의 세트를 획득하는 단계; 및상기 마스크 내의 픽셀들을 상기 제1 비디오에서의 대응하는 픽셀 위치들에 복사하여 상기 제1 의복 대신에 상기 제2 의복을 착용한 상기 제1 사람의 묘사를 포함하는 제4 비디오를 생성하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 제2 사람과 연관된 외관 데이터는 3차원(3D) 자세, 전체 신체 세그먼테이션, 조밀한 키포인트 세트, 텍스처, 컬러, 및 의복 세그먼테이션을 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 제1 및 제2 사람들과 연관된 외관 및 모션 데이터를 추출하는 단계는 상기 제1 및 제2 비디오들에 제1 머신 러닝 기법을 적용하는 단계를 포함하고, 상기 제1 머신 러닝 기법은 입력 비디오와 연관된 외관 및 모션 데이터를 추정하도록 훈련되는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 제1 머신 러닝 기법은 상기 입력 비디오에 묘사된 주어진 현실 세계 객체의 3차원(3D) 자세, 상기 주어진 현실 세계 객체의 전체 신체 세그먼테이션, 상기 주어진 현실 세계 객체의 조밀한 키포인트 세트, 텍스처, 컬러, 및 상기 주어진 현실 세계 객체의 의복 세그먼테이션을 동시에 생성하도록 훈련되는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 제1 비디오로부터 추출된 상기 제1 사람과 연관된 모션 데이터 및 상기 제2 비디오로부터 추출된 상기 제2 사람과 연관된 외관 데이터를 제2 머신 러닝 기법에 적용하는 단계 - 상기 제2 머신 러닝 기법은 제3 사람과 연관된 모션 데이터를 제4 사람과 연관된 외관 데이터에 적용하고 또한 상기 제3 사람이 상기 제4 사람의 의복을 착용한 것을 묘사하는 새로운 비디오를 렌더링하도록 훈련됨 - 를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 동작들의 시퀀스를 통해 반복함으로써 상기 제1 및 제2 머신 러닝 기법들을 훈련하는 단계를 추가로 포함하고, 상기 동작들의 시퀀스는:제1 훈련 자세에 있고 제1 훈련 의복을 착용한 훈련자를 묘사하는 제1 훈련 비디오를 수신하는 동작;제2 훈련 자세에 있고 제2 훈련 의복을 착용한 상기 훈련자를 묘사하는 제2 훈련 비디오를 수신하는 동작;상기 제1 머신 러닝 기법을 상기 제1 및 제2 훈련 비디오들에 적용하여, 상기 훈련자와 연관된 추정된 외관 및 모션 데이터의 제1 및 제2 세트들을 생성하는 동작; 및상기 훈련자와 연관된 추정된 외관 및 모션 데이터의 제1 및 제2 세트들을 상기 제2 머신 러닝 기법에 적용하여 상기 제2 훈련 의복을 착용한 상기 훈련자의 묘사를 생성하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서,상기 제2 훈련 의복을 착용한 상기 훈련자의 생성된 묘사와 상기 제2 훈련 의복을 착용한 상기 훈련자를 묘사하는 상기 제2 훈련 비디오 간의 편차를 계산하는 단계; 및상기 계산된 편차에 기초하여 상기 제1 및 제2 머신 러닝 기법들의 하나 이상의 파라미터를 갱신하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 제1 머신 러닝 기법은 외관 및 모션 데이터 추출 모듈을 포함하고, 상기 제2 머신 러닝 기법은 이미지 생성기 모듈을 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서,상기 제1 사람의 클라이언트 디바이스의 이미지 캡처 디바이스를 이용하여 상기 제2 사람을 묘사하는 상기 제2 비디오를 캡처하는 단계; 및상기 제2 비디오를 캡처한 후에, 상기 이미지 캡처 디바이스를 이용하여 상기 제1 사람을 묘사하는 상기 제1 비디오를 캡처하는 단계 - 상기 제2 비디오를 캡처한 후에 상기 제1 비디오를 캡처한 것에 응답하여 제3 비디오가 생성되고, 상기 제3 비디오는 상기 제2 사람에 의해 착용되고 있는 상기 제2 의복을 착용한 상기 제1 사람을 묘사함 - 를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 제2 비디오는 상기 클라이언트 디바이스의 후방 카메라를 이용하여 캡처되고, 상기 제1 비디오는 상기 클라이언트 디바이스의 전방 카메라를 이용하여 캡처되는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 제1 및 제2 비디오들은 클라이언트 디바이스의 상이한 카메라들을 사용하여 동시에 캡처되는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 제1 사람의 외관의 변경을 묘사하는 제3 비디오는 상기 제1 및 제2 비디오들이 캡처됨에 따라 실시간으로 생성되는 방법.</claim></claimInfo><claimInfo><claim>17. 시스템으로서:프로세서; 및상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 야기하는 명령어들이 저장된 메모리 컴포넌트를 포함하고, 상기 동작들은: 제1 자세로 제1 의복을 착용한 제1 사람의 묘사를 포함하는 제1 비디오를 수신하는 동작; 제2 자세로 제2 의복을 착용한 제2 사람의 묘사를 포함하는 제2 비디오를 획득하는 동작; 상기 제1 비디오에 묘사된 상기 제1 사람의 상기 제1 자세와 매칭되도록 상기 제2 비디오에 묘사된 상기 제2 사람의 상기 제2 자세를 상기 제2 자세로부터 상기 제1 자세로 수정하는 동작; 상기 제1 사람의 상기 제1 자세와 매칭되도록 상기 제2 사람의 상기 제2 자세를 수정한 후에, 상기 제2 사람이 상기 제2 비디오에서 착용하고 있는 상기 제2 의복의 전신 세그먼테이션을 생성하는 동작; 및 상기 제2 사람이 상기 제2 비디오에서 착용하고 있는 상기 제2 의복의 전신 세그먼테이션에 기초하여 상기 제1 사람의 외관을 표현하는 외관 데이터를 상기 제1 의복을 착용한 것으로부터 상기 제2 의복을 착용한 것으로 변경하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 제1 사람과 연관된 외관 데이터를 변경하는 동작은:상기 제1 비디오로부터 상기 제1 사람과 연관된 외관 및 모션 데이터를 추출하는 동작;상기 제2 비디오로부터 상기 제2 사람과 연관된 외관 및 모션 데이터를 추출하는 동작;상기 제1 사람과 연관된 모션 데이터와 매칭되도록 상기 제2 사람과 연관된 모션 데이터를 수정하는 동작상기 제2 사람과 연관된 모션 데이터를 수정하여 상기 제2 의복에 대응하는 픽셀들을 획득한 후에, 상기 전신 세그먼테이션에 기초하여, 상기 제2 사람과 연관된 상기 외관 데이터에 마스크를 적용하는 동작; 상기 제2 사람과 연관된 외관 데이터에 적용된 상기 마스크 내의 픽셀들에 기초하여 상기 제1 사람과 연관된 외관 데이터의 일부분을 대체하는 동작; 및상기 제1 사람과 연관된 외관 데이터의 일부분을 대체한 것에 기초하여, 상기 제1 의복 대신에 상기 제2 의복을 착용한 상기 제1 사람의 묘사를 포함하는 제3 비디오를 생성하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>19. 제17항 또는 제18항에 있어서, 상기 동작들은:상기 제1 사람과 연관된 외관 데이터에 상기 마스크를 적용하여 타깃 픽셀들의 세트를 식별하는 동작; 및상기 제2 의복에 대응하는 픽셀들을 상기 타깃 픽셀들의 세트에 복사하는 동작을 추가로 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 야기하는 명령어들이 저장된 컴퓨터 판독가능 저장 매체로서, 상기 동작들은:제1 자세로 제1 의복을 착용한 제1 사람의 묘사를 포함하는 제1 비디오를 수신하는 동작;제2 자세로 제2 의복을 착용한 제2 사람의 묘사를 포함하는 제2 비디오를 획득하는 동작;상기 제1 비디오에 묘사된 상기 제1 사람의 상기 제1 자세와 매칭되도록 상기 제2 비디오에 묘사된 상기 제2 사람의 상기 제2 자세를 상기 제2 자세로부터 상기 제1 자세로 수정하는 동작;상기 제1 사람의 상기 제1 자세와 매칭되도록 상기 제2 사람의 상기 제2 자세를 수정한 후에, 상기 제2 사람이 상기 제2 비디오에서 착용하고 있는 상기 제2 의복의 전신 세그먼테이션을 생성하는 동작; 및상기 제2 사람이 상기 제2 비디오에서 착용하고 있는 상기 제2 의복의 전신 세그먼테이션에 기초하여 상기 제1 사람의 외관을 표현하는 외관 데이터를 상기 제1 의복을 착용한 것으로부터 상기 제2 의복을 착용한 것으로 변경하는 동작을 포함하는 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ASSOULINE, Avihay</engName><name>아술린, 아비하이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BERGER, Itamar</engName><name>베르거, 이타마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MALBIN, Nir</engName><name>말빈, 니르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>SASSON, Gal</engName><name>사슨, 갈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.21</priorityApplicationDate><priorityApplicationNumber>17/557,652</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-1-2024-0776383-26</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-1-2024-0776742-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.07.23</receiptDate><receiptNumber>1-5-2024-0120749-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247024068.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338ece507675fafed69f309f643bdda0a3200903fc76090f4335ed1e796cf5207e289f8ad5dbc720a52d381b86057878455522434237139060e1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff99a314763d727d7d00f7d22b4f1ebfcafb9f1ea8c47d7e39b2633f11c0a878bad69490ac3bdcf5ededd6871decec306bb8a660f1bd83f8f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>