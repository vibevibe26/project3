<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:48.4148</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.05.03</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0057771</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>공간 맵을 획득하는 방법 및 전자 장치</inventionTitle><inventionTitleEng>METHOD AND ELECTRONIC DEVICE FOR OBTAINING SPATIAL  MAP</inventionTitleEng><openDate>2024.07.24</openDate><openNumber>10-2024-0114673</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 17/05</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/28</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/29</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 공간에 대한 공간 스캔 정보로부터 공간에 속하는 객체를 인식하고, 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득하고, 획득된 특징 정보에 기초한 쿼리를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 데이터베이스에 기초하여 객체를 식별하고, 공간 스캔 정보 및 공간에 속하는 객체에 대한 객체 정보에 기초하여, 공간에 대한 공간 맵을 생성하는 전자 장치 및 방법이 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 센서를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하는 단계(S610);상기 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는(unrecognizable) 객체와 관련된 특징 정보를 획득하는 단계(S620);상기 획득된 특징 정보에 기초한 쿼리(query)를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된(personalized) 데이터베이스에 기초하여 식별하는 단계(S630); 및상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 공간에 대한 공간 맵을 생성하는 단계(S640);를 포함하는, 공간 맵을 획득하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 식별하는 단계(S630)는,상기 쿼리에 대한 응답으로, 상기 개인화된 데이터베이스로부터 객체 후보군에 대한 정보를 획득하는 단계; 및상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 상기 객체 후보군에 포함된 객체들 각각의 이미지 정보를 비교하여, 상기 비교 결과에 기초하여 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항 또는 제2 항에 있어서,상기 객체 후보군에 대한 정보를 획득하는 단계는,상기 쿼리에 포함된 상기 특징 정보와 상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 상기 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1 항 내지 제3 항 중 어느 한 항에 있어서,상기 쿼리는,상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보가 상기 획득된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청하는 것인, 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항 내지 제4 항 중 어느 한 항에 있어서,상기 비교 결과에 기초하여 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는 단계는,상기 적어도 하나의 센서를 포함하는 전자 장치(100)의 위치를 소정의 시점으로 이동시키는 단계; 및상기 이동된 위치에서 상기 적어도 하나의 센서를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1 항 내지 제5 항 중 어느 한 항에 있어서,상기 객체 후보군에 대한 정보를 획득하는 단계는,상기 개인화된 데이터베이스를 포함하는 클라우드 서버(200)에 상기 쿼리를 전송한 것에 대한 응답으로, 상기 클라우드 서버(200)로부터 객체 후보군에 대한 정보를 수신하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1 항 내지 제6 항 중 어느 한 항에 있어서,상기 공간에 속하는 객체를 인식하는 단계(S610)는,상기 객체 인식 모델을 이용하여, 상기 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하고,상기 특징 정보를 획득하는 단계(S620)는,특징 분석 모델을 이용하여, 상기 객체 인식 결과에 따라 레이블링된 상기 공간 스캔 정보로부터 상기 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 추출하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1 항 내지 제7 항 중 어느 한 항에 있어서,상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 개인화된 데이터베이스를 업데이트하는 단계를 더 포함하고,상기 공간에 대한 공간 맵을 생성하는 단계(S640)는,상기 업데이트된 개인화된 데이터베이스에 기초하여, 상기 공간에 대한 공간 맵을 생성하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 한 항에 있어서,상기 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것이고,상기 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 상기 사용자의 사용 과정에서 결정되는 사용 속성 정보를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 한 항의 방법을 실행시키기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo><claimInfo><claim>11. 하나 이상의 인스트럭션을 저장하는 메모리(110);상기 메모리(110)에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서(120); 및적어도 하나의 센서를 포함하는 센싱부(130)를 포함하고,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 센싱부(130)를 이용하여 획득된 공간에 대한 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하고, 상기 공간 스캔 정보로부터 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 획득하고, 상기 획득된 특징 정보에 기초한 쿼리를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 개인화된 테이터베이스에 기초하여 식별하고, 상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 공간에 대한 공간 맵을 생성하는, 전자 장치(100).</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 쿼리에 대한 응답으로, 상기 개인화된 데이터베이스로부터 객체 후보군에 대한 정보를 획득하고, 상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보와 상기 객체 후보군에 포함된 객체들 각각의 이미지 정보를 비교하여, 상기 비교 결과에 기초하여 상기 객체 인식 모델을 통해 인식할 수 없는 객체를 식별하는, 전자 장치(100).</claim></claimInfo><claimInfo><claim>13. 제11 항 또는 제12 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 쿼리에 포함된 상기 특징 정보와 상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보를 비교하여, 상기 특징 정보에 대응되는 속성 정보를 가지는 객체 후보군에 대한 정보를 획득하는, 전자 장치(100).</claim></claimInfo><claimInfo><claim>14. 제11 항 내지 제13 항 중 어느 한 항에 있어서,상기 쿼리는,상기 개인화된 데이터베이스에 저장된 객체 별 속성 정보가 상기 획득된 특징 정보와 일정한 수준 이상으로 매칭되는 적어도 하나의 객체에 대한 객체 정보의 수집을 요청하는 것인, 전자 장치(100).</claim></claimInfo><claimInfo><claim>15. 제11 항 내지 제14 항 중 어느 한 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 전자 장치(100)의 위치를 소정의 시점으로 이동시키고, 상기 이동된 위치에서 상기 센싱부(130)를 이용하여, 상기 객체 인식 모델을 통해 인식할 수 없는 객체의 추정된 이미지 정보를 생성하는, 전자 장치(100).</claim></claimInfo><claimInfo><claim>16. 제11 항 내지 제15 항 중 어느 한 항에 있어서,통신부(140)를 더 포함하고,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 통신부(140)를 통해, 상기 개인화된 데이터베이스를 포함하는 클라우드 서버(200)에 상기 쿼리를 전송한 것에 대한 응답으로, 상기 클라우드 서버(200)로부터 객체 후보군에 대한 정보를 수신하는, 전자 장치(100).</claim></claimInfo><claimInfo><claim>17. 제11 항 내지 제16 항 중 어느 한 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 객체 인식 모델을 이용하여, 상기 공간 스캔 정보로부터 상기 공간에 속하는 객체를 인식하고, 특징 분석 모델을 이용하여, 상기 객체 인식 결과에 따라 레이블링된 상기 공간 스캔 정보로부터 상기 객체 인식 모델을 통해 인식할 수 없는 객체와 관련된 특징 정보를 추출하는, 전자 장치(100).</claim></claimInfo><claimInfo><claim>18. 제11 항 내지 제17 항 중 어느 한 항에 있어서,상기 프로세서(120)는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 공간 스캔 정보 및 상기 공간에 속하는 객체에 대한 객체 정보에 기초하여, 상기 개인화된 데이터베이스를 업데이트하고, 상기 업데이트된 개인화된 데이터베이스에 기초하여, 상기 공간에 대한 공간 맵을 생성하는, 전자 장치(100).</claim></claimInfo><claimInfo><claim>19. 제11 항 내지 제18 항 중 어느 한 항에 있어서,상기 개인화된 데이터베이스는 사용자의 자산에 속하는 객체들 각각의 속성 정보를 객체별로 등록한 것이고,상기 속성 정보는 객체의 생산 과정에서 결정되는 모델 속성 정보 및 상기 사용자의 사용 과정에서 결정되는 사용 속성 정보를 포함하는, 전자 장치(100).</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Yong Seok</engName><name>이용석</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KWAK, Se Jin</engName><name>곽세진</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Geun Ho</engName><name>이근호</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.01.17</priorityApplicationDate><priorityApplicationNumber>1020230006998</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.05.03</receiptDate><receiptNumber>1-1-2023-0495407-31</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230057771.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bb648c03e716f8032cd13039bab7181668b14c59490c57dea0e75d4615117da43f8052ed8513465e31af8ee5020db843fe8d1e612d33a5db</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf63515af1b15477cea800482abda80f3a67a02c9b22f6012f2a824fb2939b8c43fe2349ed032ca0d155b99ea827e4513f109cd218e4cefeb1</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>