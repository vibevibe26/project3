<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:54.3954</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.04.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0046794</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자동화된 상자 인식을 위한 인공 신경망 네트워크와, 상자 인식 방법 및 연산 장치, 그리고 이의 기록매체</inventionTitle><inventionTitleEng>Artificial neural network for automated box recognition, box  recognition method and computing device, and recording  medium thereof</inventionTitleEng><openDate>2025.10.15</openDate><openNumber>10-2025-0148791</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/62</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 인공 신경망 네트워크는, Box와 No Box라는 2가지 클래스를 갖는 제1 학습 데이터를 통해 학습되어 상자가 보관된 영역의 빈 위치를 식별하는 제1 인공 신경망 모델, 동일 클래스에 속한 상자들이 층층이 적재된 상자 스택과 상기 스택을 설명하는 인스턴스를 라벨링으로 갖는 제2 학습 데이터를 통해 학습되어 상기 상자 스택에 속한 상자의 클래스와 개수를 식별하는 제2 인공 신경망 모델을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. Box와 No Box라는 2가지 클래스를 갖는 제1 학습 데이터를 통해 학습되어 상자가 보관된 영역의 빈 위치를 식별하는 제1 인공 신경망 모델;동일 클래스에 속한 상자들이 층층이 적재된 상자 스택과 상기 스택을 설명하는 인스턴스를 라벨링으로 갖는 제2 학습 데이터를 통해 학습되어 상기 상자 스택에 속한 상자의 클래스와 개수를 식별하는 제2 인공 신경망 모델;을 포함하는 인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 인공 신경망 모델은, MobileNet에 기반해 구현된, 인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제1 학습 데이터는 ROI가 적용된 비디오의 프레임에서 추출된, 인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제2 인공 신경망 모델은, EGC-YOLO에 기반해 구현된, 인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 EGC-YOLO는, 백본, 넥, 헤드를 갖는 네트워크 구조로,상기 백본은 Conv, ECGNet 및 MP 레이어를 포함되고,상기 넥은 Conv, Upsample, MP, 연결 및 다중 스케일 특징 융합 모드(multi-scale feature fusion mode)가 있는 ECGNet을 포함하는,인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제2 인공 신경망 모델은, GhostConv Module, Conv-GhostConv Stack (CGStack) Module, ELAN-GhostConv Network 중 적어도 하나를 포함하는, 인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 제2 학습 데이터의 인스턴스는, 클래스, 경계 상자 중심(x), 경계 상자 중심(y), 정규화된 너비 및 정규화된 높이를 포함하는, 인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 제2 인공 신경망 모델은, 아래 알고리즘 1에 따라 상자 개수를 카운팅하는, 인공 신경망 네트워크.</claim></claimInfo><claimInfo><claim>9. 상자가 보관된 영역의 빈 위치를 식별하는 제1 인공 신경망 모델과 상자 스택에 속한 상자의 클래스와 개수를 식별하는 제2 인공 신경망 모델을 포함하는 인공 신경망 네트워크를 통해 상자 스택에서 상자를 인식하는 방법에 관한 것으로,Box와 No Box라는 2가지 클래스를 갖는 제1 학습 데이터를 통해 상기 제1 인공 신경망 모델이 학습하는 제1 단계와,동일 클래스에 속한 상자들이 층층이 적재된 상자 스택과 상기 스택을 설명하는 인스턴스를 라벨링으로 갖는 제2 학습 데이터를 통해 상기 제2 인공 신경망 모델이 학습하는 제2 단계와,상기 상자 스택으로부터 이미지를 획득해서 학습된 바에 따라서 획득된 이미지속 상자 스택에서 상자의 클래스와 개수를 추론하는 제3 단계,를 포함하는, 상자 인식 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제1 인공 신경망 모델은, MobileNet에 기반해 구현된, 상자 인식 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 제1 학습 데이터는 ROI가 적용된 비디오의 프레임에서 추출된, 상자 인식 방법.</claim></claimInfo><claimInfo><claim>12. 제9항에 있어서,상기 제2 인공 신경망 모델은, EGC-YOLO에 기반해 구현된, 상자 인식 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 EGC-YOLO는, 백본, 넥, 헤드를 갖는 네트워크 구조로,상기 백본은 Conv, ECGNet 및 MP 레이어를 포함되고,상기 넥은 Conv, Upsample, MP, 연결 및 다중 스케일 특징 융합 모드(multi-scale feature fusion mode)가 있는 ECGNet을 포함하는,상자 인식 방법.</claim></claimInfo><claimInfo><claim>14. 제9항에 있어서,상기 제2 인공 신경망 모델은, GhostConv Module, Conv-GhostConv Stack (CGStack) Module, ELAN-GhostConv Network 중 적어도 하나를 포함하는, 상자 인식 방법.</claim></claimInfo><claimInfo><claim>15. 제9항에 있어서,상기 제2 학습 데이터의 인스턴스는, 클래스, 경계 상자 중심(x), 경계 상자 중심(y), 정규화된 너비 및 정규화된 높이를 포함하는, 상자 인식 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 제3 단계에서, 상기 제2 인공 신경망 모델은 아래 알고리즘 1에 따라 상자 개수를 카운팅하는, 상자 인식 방법.</claim></claimInfo><claimInfo><claim>17. 제1 항 내지 제9항 중 어느 한 항에 기재된 인공 신경망 네크워크를 저장한 기록 매체.</claim></claimInfo><claimInfo><claim>18. 상자가 보관된 영역의 빈 위치를 식별하는 제1 인공 신경망 모델과 상자 스택에 속한 상자의 클래스와 개수를 식별하는 제2 인공 신경망 모델을 포함하는 인공 신경망 네트워크와, 상자 인식 방법을 컴퓨터가 읽을 수 있도록 코딩된 프로그램을 저장하는 메모리; 및상기 프로그램을 실행하는 프로세서;를 포함하고,상기 상자 인식 방법은,Box와 No Box라는 2가지 클래스를 갖는 제1 학습 데이터를 통해 상기 제1 인공 신경망 모델을 학습시키는 제1 단계와,동일 클래스에 속한 상자들이 층층이 적재된 상자 스택과 상기 스택을 설명하는 인스턴스를 라벨링으로 갖는 제2 학습 데이터를 통해 상기 제2 인공 신경망 모델을 학습시키는 제2 단계와,작업장에 놓여진 상자 스택으로부터 이미지를 획득해서 학습된 바에 따라서 획득된 이미지속 상자 스택에서 상자의 클래스와 개수를 추론하는 제3 단계;를 포함하는, 연산 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경상북도 경산시...</address><code>220040363026</code><country>대한민국</country><engName>Industry Academic Cooperation Foundation of Yeungnam University</engName><name>영남대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대구광역시 수성구...</address><code> </code><country> </country><engName>Kim, Sungho</engName><name>김성호</name></inventorInfo><inventorInfo><address>경상북도 경산...</address><code> </code><country> </country><engName>FIRDIANTIKA INDAH MONISA</engName><name>피르디안티카인다모니사</name></inventorInfo><inventorInfo><address>경상북도 경산시 조...</address><code> </code><country> </country><engName>Seongryeong Lee</engName><name>이성령</name></inventorInfo><inventorInfo><address>경상북도 경산시 대...</address><code> </code><country> </country><engName>BHATTACHARYYA CHAITALI</engName><name>밭타차리야쪼이탈리</name></inventorInfo><inventorInfo><address>대구광역시 남구...</address><code> </code><country> </country><engName>Yewon Jang</engName><name>장예원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로***길**, *층(대치동, 삼호빌딩)</address><code>920071001220</code><country>대한민국</country><engName>ROYAL Patent &amp; Law Office</engName><name>특허법인로얄</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.04.05</receiptDate><receiptNumber>1-1-2024-0383008-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.07.03</receiptDate><receiptNumber>4-1-2025-5182004-48</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240046794.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b1533be7776e569a96d7af6f2b18c520210c2ab5b7d0681851c7d3841e7855024a4d3d986ad85baef7c633559c6aea0c2cdbfdf5dd077e94</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbc9f22dbc6a44697d64d64e4efb2bdd539614327fcaf3005626461a02ae828f3d79a8abb8ed9089439dbf9de994a2002bb707d4c78805d4e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>