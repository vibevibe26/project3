<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:11.511</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.09.05</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7016368</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>2차원 입력 선택을 활용한 3차원 깊이 이미지들의 깊이 스컬퍼링</inventionTitle><inventionTitleEng>DEPTH SCULPTURING OF THREE-DIMENSIONAL DEPTH IMAGE UTILIZING  TWO-DIMENSIONAL INPUT SELECTION</inventionTitleEng><openDate>2025.05.28</openDate><openNumber>10-2025-0075740</openNumber><originalApplicationDate>2019.09.05</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2021-7011716</originalApplicationNumber><originalExaminationRequestDate>2025.05.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.05.19</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/128</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/122</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/239</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/271</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/383</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/388</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020217011716</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 깊이 스컬퍼링 시스템은 프레임, 프레임의 측방향 측면에 연결된 템플, 및 깊이-캡처 카메라를 포함하는 아이웨어 디바이스를 포함한다. 깊이 스컬퍼링 시스템은 사용자 입력 디바이스를 더 포함한다. 프로세서에 의한 프로그래밍의 실행은, 사용자 입력 디바이스를 통해, 초기 터치 포인트로부터 최종 터치 포인트까지 2차원 입력 선택의 모션을 추적하는 것을 위한 기능들을 수행하도록 깊이 스컬퍼링 시스템을 구성한다. 깊이 스컬퍼링 시스템은, 대응적으로, 초기 터치 포인트 및 최종 터치 포인트에 투영되는 초기 광선과 최종 광선 사이의 회전 매트릭스를 결정한다. 깊이 스컬퍼링 시스템은 초기 깊이 이미지의 정점들에 회전 매트릭스를 적용함으로써 깊이 스컬퍼링된 이미지를 생성한다. 깊이 스컬퍼링 시스템은 이미지 디스플레이를 통해 깊이 스컬퍼링된 이미지를 제시한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2020.04.02</internationOpenDate><internationOpenNumber>WO2020068388</internationOpenNumber><internationalApplicationDate>2019.09.05</internationalApplicationDate><internationalApplicationNumber>PCT/US2019/049637</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 깊이 스컬퍼링(sculpturing) 시스템으로서,아이웨어 디바이스 — 상기 아이웨어 디바이스는, 브릿지를 포함하는 프레임; 상기 프레임의 측방향 측면에 연결된 템플(temple); 및 깊이-캡처 카메라를 포함하고, 상기 깊이-캡처 카메라에서, (i) 중첩하는 시야들을 갖는 적어도 2개의 가시광 카메라들; 또는 (ii) 적어도 하나의 가시광 카메라 및 깊이 센서를 포함함 —;초기 이미지들을 제시하기 위한 이미지 디스플레이 — 상기 초기 이미지는 원시 이미지 또는 2차원인 프로세싱된 원시 이미지임 —;상기 초기 이미지를 제시하도록 상기 이미지 디스플레이를 제어하기 위해 상기 이미지 디스플레이에 커플링된 이미지 디스플레이 드라이버;사용자로부터 2차원 입력 선택을 수신하기 위한 사용자 입력 디바이스;메모리;상기 깊이-캡처 카메라, 상기 이미지 디스플레이 드라이버, 상기 사용자 입력 디바이스 및 상기 메모리에 커플링된 프로세서; 및상기 메모리 내의 프로그래밍을 포함하고, 상기 프로세서에 의한 상기 프로그래밍의 실행은 기능들을 수행하도록 상기 깊이 스컬퍼링 시스템을 구성하고, 상기 기능들은,상기 깊이-캡처 카메라를 통해, 상기 초기 이미지에 대응하는 초기 깊이 이미지를 생성하는 기능 — 상기 초기 깊이 이미지는 정점들의 매트릭스로 형성되고, 각각의 정점은 3차원 장면에서 픽셀을 표현하고; 각각의 정점은 위치 속성을 갖고; 각각의 정점의 상기 위치 속성은 3차원 위치 좌표계에 기초하고, 수평 위치에 대한 X 축 상의 X 위치 좌표, 수직 위치에 대한 Y 축 상의 Y 위치 좌표, 및 깊이에 대한 Z 축 상의 Z 위치 좌표를 포함함 —;상기 이미지 디스플레이를 통해, 상기 초기 이미지를 제시하는 기능;상기 사용자 입력 디바이스를 통해, 상기 사용자로부터 상기 제시된 초기 이미지의 상기 2차원 입력 선택을 수신하는 기능;상기 사용자 입력 디바이스를 통해, 상기 제시된 초기 이미지의 초기 터치 포인트로부터 최종 터치 포인트까지 상기 2차원 입력 선택의 모션을 추적하는 기능;상기 3차원 위치 좌표계의 원점 정점으로부터 상기 제시된 초기 이미지의 상기 초기 터치 포인트에 대응하는 초기 정점까지의 투영인 초기 광선을 컴퓨팅하는 기능 — 상기 원점 정점은 상기 깊이-캡처 카메라에 대응함 —;상기 원점 정점으로부터 상기 제시된 초기 이미지의 최종 터치 포인트에 대응하는 최종 정점까지의 투영인 최종 광선을 컴퓨팅하는 기능;깊이 스컬퍼링 영역을 유도하기 위해 상기 초기 광선으로부터 상기 최종 광선으로의 회전을 설명하는 상기 초기 광선과 상기 최종 광선 사이의 회전 매트릭스를 결정하는 기능;상기 깊이 스컬퍼링 영역에서 상기 초기 깊이 이미지의 정점들의 상기 위치 속성에 상기 회전 매트릭스를 적용함으로써 깊이 스컬퍼링된 이미지를 생성하는 기능; 및상기 이미지 디스플레이를 통해, 상기 깊이 스컬퍼링된 이미지를 제시하는 기능을 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,각각의 정점은 컬러 속성, 텍스처 속성 또는 반사 속성 중 하나 이상을 더 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 프로세서에 의한 상기 프로그래밍의 실행은 상기 정점들 각각에 대한 상기 회전 매트릭스의 영향 가중치를 결정하는, 상기 초기 정점 및 상기 최종 정점 주위의 상기 초기 깊이 이미지의 상기 정점들에 대한 관련성 매트릭스를 컴퓨팅하도록 상기 깊이 스컬퍼링 시스템을 추가로 구성하고;상기 깊이 스컬퍼링 영역에서 상기 초기 깊이 이미지의 정점들의 상기 위치 속성에 상기 회전 매트릭스를 적용함으로써 상기 깊이 스컬퍼링된 이미지를 생성하는 기능은 상기 컴퓨팅된 관련성 매트릭스에 기초하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,상기 깊이-캡처 카메라는 좌측 시야를 갖는 좌측 가시광 카메라 및 우측 시야를 갖는 우측 가시광 카메라를 포함하는 적어도 2개의 가시광 카메라들을 포함하고;상기 좌측 시야 및 상기 우측 시야는 중첩하고;상기 깊이-캡처 카메라를 통해, 상기 초기 깊이 이미지를 생성하는 기능은,상기 좌측 가시광 카메라를 통해, 픽셀들의 좌측 매트릭스를 포함하는 좌측 원시 이미지를 캡처하는 것;상기 우측 가시광 카메라를 통해, 픽셀들의 우측 매트릭스를 포함하는 우측 원시 이미지를 캡처하는 것;상기 좌측 및 우측 원시 이미지들을 정렬하고 상기 좌측 및 우측 가시광 카메라들 각각의 개개의 렌즈로부터 왜곡을 제거하는, 상기 좌측 원시 이미지로부터의 좌측 정류된 이미지 및 상기 우측 원시 이미지로부터의 우측 정류된 이미지를 생성하는 것;상관된 픽셀들 각각에 대한 불일치를 계산하기 위해 상기 좌측 정류된 이미지의 픽셀들을 상기 우측 정류된 이미지와 상관시킴으로써 이미지 불일치를 추출하는 것; 및적어도 상기 상관된 픽셀들 각각에 대해 추출된 이미지 불일치에 기초하여 상기 초기 깊이 이미지의 정점들의 상기 Z 위치 좌표를 계산하는 것을 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,상기 깊이-캡처 카메라는 상기 적어도 하나의 가시광 카메라 및 상기 깊이 센서를 포함하고;상기 적어도 하나의 가시광 카메라 및 상기 깊이 센서는 실질적으로 중첩하는 시야를 갖고;상기 깊이 센서는 적외선 방출기 및 적외선 카메라를 포함하고, 상기 적외선 방출기는 상기 프레임 또는 상기 템플에 연결되어 적외선 광 패턴을 방출하고; 상기 적외선 카메라는 상기 프레임 또는 상기 템플에 연결되어 상기 방출된 적외선 광 패턴의 반사 변형들을 캡처하고;상기 깊이-캡처 카메라를 통해, 상기 초기 깊이 이미지를 생성하는 기능은,상기 적어도 하나의 가시광 카메라를 통해 원시 이미지를 캡처하는 것;상기 적외선 방출기를 통해, 상기 방출된 적외선 광에 의해 도달되는 장면에 위치된 복수의 물체들 또는 물체 특징부들 상에 적외선 광 패턴을 방출하는 것;상기 적외선 카메라를 통해, 상기 복수의 물체들 또는 물체 특징부들 상에서 상기 방출된 적외선 광 패턴의 반사 변형들의 적외선 이미지를 캡처하는 것;반사 변형들의 상기 적외선 이미지에 기초하여 상기 깊이-캡처 카메라로부터 상기 복수의 물체들 또는 물체 특징부들까지의 개개의 깊이를 컴퓨팅하는 것;반사 변형들의 상기 적외선 이미지 내의 물체들 또는 물체 특징부들을 상기 원시 이미지와 상관시키는 것; 및적어도 상기 컴퓨팅된 개개의 깊이에 기초하여, 상기 초기 깊이 이미지의 정점들의 상기 Z 위치 좌표를 계산하는 것을 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,상기 초기 깊이 이미지의 정점들의 상기 위치 속성에 상기 회전 매트릭스를 적용함으로써 상기 깊이 스컬퍼링된 이미지를 생성하는 기능은,상기 3차원 위치 좌표계에서 새로운 X 위치 좌표, 새로운 Y 위치 좌표 및 새로운 Z 위치 좌표를 획득하기 위해 상기 초기 깊이 이미지의 각각의 정점에 상기 회전 매트릭스를 곱하는 것을 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 깊이 스컬퍼링된 이미지는 연속적으로 반복적으로 생성되는 깊이 스컬퍼링된 이미지들의 시퀀스 중 하나이고;상기 프로세서에 의한 상기 프로그래밍의 실행은 깊이 스컬퍼링된 이미지들의 상기 시퀀스 각각을 생성하기 위해 기능들을 반복적으로 수행하도록 상기 깊이 스컬퍼링 시스템을 추가로 구성하고, 상기 기능들은,상기 이미지 디스플레이를 통해, 상기 깊이 스컬퍼링된 이미지를 제시하는 것에 대한 응답으로;상기 사용자 입력 디바이스를 통해, 상기 사용자로부터 상기 깊이 스컬퍼링된 이미지의 다음 2차원 입력 선택을 수신하는 기능;상기 사용자 입력 디바이스를 통해, 상기 제시된 깊이 스컬퍼링된 이미지의 다음 초기 터치 포인트로부터 다음 최종 터치 포인트까지 상기 다음 2차원 입력 선택의 모션을 추적하는 기능;상기 3차원 위치 좌표계의 상기 원점 정점으로부터 상기 깊이 스컬퍼링된 이미지 상의 상기 다음 초기 터치 포인트에 대응하는 다음 초기 정점까지의 투영인 다음 초기 광선을 컴퓨팅하는 기능;상기 원점 정점으로부터 상기 제시된 깊이 스컬퍼링된 이미지의 상기 다음 최종 터치 포인트에 대응하는 상기 다음 최종 정점까지의 투영인 다음 최종 광선을 컴퓨팅하는 기능;다음 깊이 스컬퍼링 영역을 유도하기 위해 상기 다음 초기 광선으로부터 상기 제시된 깊이 스컬퍼링된 이미지의 상기 다음 최종 광선으로의 회전을 설명하는 상기 다음 초기 광선과 상기 다음 최종 광선 사이의 다음 회전 매트릭스를 결정하는 기능;상기 다음 깊이 스컬퍼링 영역에서 상기 깊이 스컬퍼링된 이미지의 정점들의 상기 위치 속성에 상기 다음 회전 매트릭스를 적용함으로써 다음 깊이 스컬퍼링된 이미지를 생성하는 기능; 및상기 이미지 디스플레이를 통해, 상기 다음 깊이 스컬퍼링된 이미지를 제시하는 기능을 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서,상기 프로세서는 제1 프로세서 및 제2 프로세서를 포함하고;상기 메모리는 제1 메모리 및 제2 메모리를 포함하고;상기 아이웨어 디바이스는, 네트워크를 통한 통신을 위한 제1 네트워크 통신 인터페이스; 상기 제1 네트워크 통신 인터페이스에 커플링된 상기 제1 프로세서; 상기 제1 프로세서에 액세스가능한 상기 제1 메모리; 및 상기 제1 메모리 내의 프로그래밍을 포함하고, 상기 제1 프로세서에 의한 상기 프로그래밍의 실행은 상기 깊이-캡처 카메라를 통해, 상기 초기 이미지에 대응하는 상기 초기 깊이 이미지를 생성하는 것을 위한 기능을 수행하도록 상기 아이웨어 디바이스를 구성하고;상기 깊이 스컬퍼링 시스템은 상기 네트워크를 통해 상기 아이웨어 디바이스에 커플링된 호스트 컴퓨터를 더 포함하고, 상기 호스트 컴퓨터는,상기 네트워크를 통한 통신을 위한 제2 네트워크 통신 인터페이스;상기 제2 네트워크 통신 인터페이스에 커플링된 상기 제2 프로세서;상기 제2 프로세서에 액세스가능한 상기 제2 메모리; 및상기 제2 메모리 내의 프로그래밍을 포함하고, 상기 제2 프로세서에 의한 상기 프로그래밍의 실행은 기능들을 수행하도록 상기 호스트 컴퓨터를 구성하고, 상기 기능들은,상기 제2 네트워크 통신 인터페이스를 통해, 상기 초기 깊이 이미지를 상기 아이웨어 디바이스로부터 상기 네트워크를 통해 수신하는 기능;상기 이미지 디스플레이를 통해, 상기 초기 이미지를 제시하는 기능;상기 사용자 입력 디바이스를 통해, 상기 사용자로부터 상기 2차원 입력 선택을 수신하는 기능;상기 사용자 입력 디바이스를 통해, 상기 초기 터치 포인트로부터 상기 최종 터치 포인트까지 상기 2차원 입력 선택의 모션을 추적하는 기능;상기 초기 광선을 컴퓨팅하는 기능;상기 최종 광선을 컴퓨팅하는 기능;상기 초기 광선과 상기 최종 광선 사이의 회전을 설명하는 상기 초기 광선과 상기 최종 광선 사이의 상기 회전 매트릭스를 결정하는 기능;상기 초기 깊이 이미지의 정점들의 상기 위치 속성에 상기 회전 매트릭스를 적용함으로써 상기 깊이 스컬퍼링된 이미지를 생성하는 기능; 및상기 이미지 디스플레이를 통해, 상기 깊이 스컬퍼링된 이미지를 제시하는 기능을 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서,상기 호스트 컴퓨터는 모바일 디바이스이고;상기 네트워크는 무선 단거리 네트워크 또는 무선 로컬 영역 네트워크이고;상기 사용자 입력 디바이스는 터치 스크린 또는 컴퓨터 마우스를 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>10. 제1 항에 있어서,상기 사용자 입력 디바이스는,사용자로부터 입력된 적어도 하나의 손가락 접촉을 수신하기 위해 상기 입력 표면에 커플링되는 센서 어레이 및 입력 표면을 포함하는 터치 센서; 및상기 터치 센서에 통합되거나 연결되고 상기 프로세서에 연결되는 감지 회로를 포함하고, 상기 감지 회로는 상기 입력 표면 상에서 상기 적어도 하나의 손가락 접촉을 추적하기 위해 전압을 측정하도록 구성되고;상기 사용자 입력 디바이스를 통해 상기 사용자로부터 상기 2차원 입력 선택을 수신하는 기능은 상기 터치 센서의 상기 입력 표면 상에서 상기 사용자로부터 입력된 상기 적어도 하나의 손가락 접촉을 수신하는 것을 포함하고;상기 사용자 입력 디바이스를 통해, 상기 초기 터치 포인트로부터 상기 최종 터치 포인트까지 상기 2차원 입력 선택의 모션을 추적하는 기능은 상기 감지 회로를 통해, 상기 터치 센서의 상기 입력 표면 상에서 상기 초기 터치 포인트로부터 상기 최종 터치 포인트까지 상기 입력 표면 상의 상기 적어도 하나의 손가락 접촉으로부터의 드래그를 추적하는 것을 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서,상기 아이웨어 디바이스의 상기 측방향 측면 상이 상기 프레임에 통합되거나 연결되는 청크를 더 포함하고;상기 프레임, 상기 템플 또는 상기 청크는 상기 터치 센서를 포함하는 회로 보드를 포함하고;상기 회로 보드는 가요성 인쇄 회로 보드를 포함하고;상기 터치 센서는 상기 가요성 인쇄 회로 보드 상에 배치되고;상기 센서 어레이는 용량성 어레이 또는 저항성 어레이이고;상기 용량성 어레이 또는 상기 저항성 어레이는 X 및 Y 축 위치 좌표들을 추적하기 위해 2차원 직사각형 좌표계를 형성하는 그리드를 포함하는, 깊이 스컬퍼링 시스템.</claim></claimInfo><claimInfo><claim>12. 방법으로서,깊이-캡처 카메라를 통해, 초기 이미지에 대응하는 초기 깊이 이미지를 생성하는 단계 — 상기 초기 깊이 이미지는 정점들의 매트릭스로 형성되고, 각각의 정점은 3차원 장면에서 픽셀을 표현하고; 각각의 정점은 위치 속성을 갖고; 각각의 정점의 상기 위치 속성은 3차원 위치 좌표계에 기초하고, 수평 위치에 대한 X 축 상의 X 위치 좌표, 수직 위치에 대한 Y 축 상의 Y 위치 좌표, 및 깊이에 대한 Z 축 상의 Z 위치 좌표를 포함함 —;사용자 입력 디바이스를 통해, 사용자로부터 상기 초기 이미지의 2차원 입력 선택을 수신하는 단계;상기 사용자 입력 디바이스를 통해, 상기 초기 이미지의 초기 터치 포인트로부터 최종 터치 포인트까지 상기 2차원 입력 선택의 모션을 추적하는 단계;상기 3차원 위치 좌표계의 원점 정점으로부터 상기 초기 이미지의 상기 초기 터치 포인트에 대응하는 초기 정점까지의 투영인 초기 광선을 컴퓨팅하는 단계 — 상기 원점 정점은 상기 깊이-캡처 카메라에 대응함 —;상기 원점 정점으로부터 상기 초기 이미지의 최종 터치 포인트에 대응하는 최종 정점까지의 투영인 최종 광선을 컴퓨팅하는 단계;깊이 스컬퍼링 영역을 유도하기 위해 상기 초기 광선으로부터 상기 최종 광선으로의 회전을 설명하는 상기 초기 광선과 상기 최종 광선 사이의 회전 매트릭스를 결정하는 단계;상기 깊이 스컬퍼링 영역에서 상기 초기 깊이 이미지의 정점들의 상기 위치 속성에 상기 회전 매트릭스를 적용함으로써 깊이 스컬퍼링된 이미지를 생성하는 단계; 및상기 이미지 디스플레이를 통해, 상기 깊이 스컬퍼링된 이미지를 제시하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,각각의 정점은 컬러 속성, 텍스처 속성 또는 반사 속성 중 하나 이상을 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제12 항에 있어서,상기 정점들 각각에 대한 상기 회전 매트릭스의 영향 가중치를 결정하는, 상기 초기 포인트 터치 포인트 및 상기 최종 터치 포인트 주위의 상기 초기 깊이 이미지의 정점들에 대한 관련성 매트릭스를 컴퓨팅하는 단계를 더 포함하고;상기 깊이 스컬퍼링 영역에서 상기 초기 깊이 이미지의 정점들의 상기 위치 속성에 상기 회전 매트릭스를 적용함으로써 상기 깊이 스컬퍼링된 이미지를 생성하는 단계는 상기 컴퓨팅된 관련성 매트릭스에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제12 항에 있어서,상기 깊이-캡처 카메라를 통해, 상기 초기 깊이 이미지를 생성하는 단계는,좌측 가시광 카메라를 통해 좌측 원시 이미지를 캡처하는 단계;우측 가시광 카메라를 통해 우측 원시 이미지를 캡처하는 단계;상기 좌측 및 우측 원시 이미지들을 정렬하고 상기 좌측 및 우측 가시광 카메라들 각각의 개개의 렌즈로부터 왜곡을 제거하는, 상기 좌측 원시 이미지로부터의 좌측 정류된 이미지 및 상기 우측 원시 이미지로부터의 우측 정류된 이미지를 생성하는 단계;상기 좌측 정류된 이미지의 픽셀들을 상기 우측 정류된 이미지와 상관시킴으로써 이미지 불일치를 추출하는 단계; 및적어도 상기 추출된 이미지 불일치에 기초하여, 상기 초기 깊이 이미지의 정점들의 상기 Z 위치 좌표를 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 깊이-캡처 카메라를 통해, 초기 깊이 이미지를 생성하는 단계는,적어도 하나의 가시광 카메라를 통해 원시 이미지를 캡처하는 단계;적외선 방출기를 통해, 상기 방출된 적외선 광에 의해 도달되는 장면에 위치된 복수의 물체들 또는 물체 특징부들 상에 적외선 광 패턴을 방출하는 단계;상기 적외선 카메라를 통해, 상기 복수의 물체들 또는 물체 특징부들 상에서 상기 방출된 적외선 광 패턴의 반사 변형들의 적외선 이미지를 캡처하는 단계;상기 반사 변형들에 기초하여 상기 깊이-캡처 카메라로부터 상기 복수의 물체들 또는 물체 특징부들까지의 개개의 깊이를 컴퓨팅하는 단계;반사 변형들의 상기 이미지 내의 물체를 상기 원시 이미지와 상관시키는 단계; 및적어도 상기 컴퓨팅된 개개의 깊이에 기초하여, 상기 초기 깊이 이미지의 정점들의 상기 Z 위치 좌표를 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제12 항에 있어서,상기 초기 깊이 이미지의 정점들의 상기 위치 속성에 상기 회전 매트릭스를 적용함으로써 깊이 스컬퍼링된 이미지를 생성하는 단계는,상기 3차원 위치 좌표계에서 새로운 X 위치 좌표, 새로운 Y 위치 좌표 및 새로운 Z 위치 좌표를 획득하기 위해 상기 초기 깊이 이미지의 각각의 정점에 상기 회전 매트릭스를 곱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제12 항에 있어서,상기 깊이-캡처 카메라를 통해, 상기 초기 깊이 이미지를 생성하는 단계는 아이웨어 디바이스 상에서 구현되고;상기 이미지 디스플레이를 통해, 상기 초기 이미지를 제시하는 단계; 상기 사용자 입력 디바이스를 통해, 상기 사용자로부터 상기 2차원 입력 선택을 수신하는 단계; 상기 사용자 입력 디바이스를 통해, 초기 터치 포인트로부터 최종 터치 포인트까지 상기 2차원 입력 선택의 모션을 추적하는 단계; 상기 초기 광선을 컴퓨팅하는 단계; 상기 최종 광선을 컴퓨팅하는 단계; 상기 회전 매트릭스를 결정하는 단계; 상기 깊이 스컬퍼링된 이미지를 생성하는 단계; 및 상기 이미지 디스플레이를 통해, 상기 깊이 스컬퍼링된 이미지를 제시하는 단계는 호스트 컴퓨터 상에서 구현되는, 방법.</claim></claimInfo><claimInfo><claim>19. 제12 항에 있어서,호스트 컴퓨터는 모바일 디바이스, 태블릿 컴퓨터, 또는 랩톱 컴퓨터이고;상기 사용자 입력 디바이스는 터치 스크린 또는 컴퓨터 마우스를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제12 항에 있어서,상기 사용자 입력 디바이스를 통해 상기 사용자로부터 상기 2차원 입력 선택을 수신하는 단계는 터치 센서의 입력 표면 상에서 상기 사용자로부터 입력된 적어도 하나의 손가락 접촉을 수신하는 단계를 포함하고;상기 사용자 입력 디바이스를 통해, 상기 초기 터치 포인트로부터 상기 최종 터치 포인트까지 상기 2차원 입력 선택의 모션을 추적하는 단계는 감지 회로를 통해, 상기 터치 센서의 상기 입력 표면 상에서 상기 초기 터치 포인트로부터 상기 최종 터치 포인트까지 상기 입력 표면 상의 상기 적어도 하나의 손가락 접촉으로부터의 드래그를 추적하는 단계를 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>이스라엘</country><engName>KATZ, Sagi</engName><name>카츠, 사기</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2018.09.26</priorityApplicationDate><priorityApplicationNumber>62/736,658</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.05.19</receiptDate><receiptNumber>1-1-2025-0556092-86</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.05.19</receiptDate><receiptNumber>1-1-2025-0556385-58</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257016368.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9385f595290fd0a5ae6646a14bf33109f468be2a22bc171c0d286cbed150fb46a278e8838fff7ae0db9f76906315aeac100e8c0911699ff158</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfc17d465d221df212d8bae14594d0561c705ba2dab4792e52227325e90c5d3a869d5e47bb5427a27fda7140c727c116660999237f3fbcc3d3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>