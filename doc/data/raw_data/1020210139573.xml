<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:45.4145</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.10.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0139573</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 포즈 추정 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR OBJECT POSE ESTIMATION</inventionTitleEng><openDate>2022.06.15</openDate><openNumber>10-2022-0081261</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/90</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 객체 포즈 추정 방법 및 장치가 개시된다. 일 실시예에 따르면, 객체 포즈 추정 방법은 입력 이미지의 포인트 클라우드에 대응하는 이미지 특징을 획득하고, 이미지 특징에 기초하여, 객체의 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보를 결정하고, 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보에 기초하여 객체 포즈를 추정하는 단계들을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 이미지의 포인트 클라우드에 대응하는 이미지 특징을 획득하는 단계;상기 이미지 특징에 기초하여, 객체의 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보를 결정하는 단계; 및상기 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보에 기초하여 객체 포즈를 추정하는 단계를 포함하는 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 입력 이미지는 깊이 이미지를 포함하고,상기 이미지 특징을 획득하는 단계는상기 깊이 이미지에 기초하여 포인트 클라우드 특징을 추출하는 단계; 및상기 포인트 클라우드 특징을 상기 이미지 특징으로 결정하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 포인트 클라우드 특징을 추출하는 단계는상기 깊이 이미지에 대응하는 포인트 클라우드 정보를 획득하는 단계; 및상기 포인트 클라우드 정보, 컬러 특징, 및 노멀 특징 중 적어도 하나에 기초하여 상기 포인트 클라우드 특징을 추출하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 입력 이미지는 컬러 이미지 및 회색조 이미지 중 적어도 하나를 더 포함하고,상기 이미지 특징을 획득하는 단계는상기 컬러 이미지 및 상기 회색조 이미지 중 적어도 하나에 기초하여 제1 이미지 특징을 추출하는 단계; 및상기 포인트 클라우드 특징과 상기 제1 이미지 특징을 융합하여 상기 이미지 특징을 획득하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제1 이미지 특징과 상기 포인트 클라우드 특징을 융합하여 상기 이미지 특징을 획득하는 단계는상기 제1 이미지 특징과 상기 포인트 클라우드 특징을 픽셀 단위로 융합하여 상기 이미지 특징을 획득하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 이미지 특징에 기초하여, 상기 시맨틱 분할 정보, 상기 인스턴스 마스크 정보, 및 상기 키 포인트 정보를 결정하는 단계는상기 이미지 특징에 기초하여 상기 포인트 클라우드에 대응하는 상기 시맨틱 분할 정보를 결정하는 단계;상기 입력 이미지에 대응하는 포인트 클라우드 정보에 기초하여 3차원 그리드를 생성하고, 상기 3차원 그리드에 기초하여 상기 인스턴스 마스크 정보를 결정하는 단계; 및상기 인스턴스 마스크 정보를 이용하거나, 또는 상기 시맨틱 분할 정보 및 상기 인스턴스 마스크 정보를 이용하여 상기 키 포인트 정보를 결정하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 인스턴스 마스크 정보는 상기 3차원 그리드에서 상기 포인트 클라우드에 대응하는 그리드 정보를 나타내고,상기 객체의 중심의 포인트 클라우드에 대응하는 그리드 정보에 기초하여 상기 객체의 각 포인트 클라우드에 대응하는 네트워크 정보가 결정되는,객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 포인트 클라우드 정보에 기초하여 상기 3차원 그리드를 생성하는 단계는상기 포인트 클라우드 정보에 대응하는 3차원 공간을 동일한 간격으로 분할하여 3차원 그리드를 획득하는 단계;상기 포인트 클라우드 정보에 대응하는 3차원 공간을 다른 간격들로 분할하여 다중 3차원 그리드를 획득하는 단계; 및다른 간격들의 동일한 분할 시작점들에 기초하여, 상기 포인트 클라우드 정보에 대응하는 3차원 공간을 분할하여 다중 3차원 그리드를 획득하는 단계중 적어도 하나를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,상기 인스턴스 마스크 정보를 이용하여 상기 키 포인트 정보를 결정하는 단계는상기 이미지 특징에 기초하여 각 포인트 클라우드에 대응하는 키 포인트의 제1 오프셋을 추정하고, 상기 제1 오프셋 및 상기 인스턴스 마스크 정보에 기초한 회귀를 통해 상기 키 포인트 정보를 결정하는 단계; 및상기 이미지 특징 및 상기 인스턴스 마스크 정보에 기초하여 상기 3차원 그리드의 각 셀에서 각 포인트 클라우드에 대응하는 키 포인트의 제2 오프셋을 추정하고, 상기 제2 오프셋에 기초한 회귀를 통해 상기 키 포인트 정보를 결정하는 단계중 적어도 하나를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제2 오프셋에 기초한 상기 회귀를 통해 상기 키 포인트 정보를 결정하는 단계는상기 제2 오프셋 및 포인트 클라우드 정보에 기초하여 포인트 클라우드를 기준으로 예측된 *?*키 포인트의 타겟 예측 값을 결정하고, 상기 타겟 예측 값에 기초한 회귀를 통해 상기 키 포인트 정보를 결정하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 타겟 예측 값에 기초한 회귀를 통해 상기 키 포인트 정보를 결정하는 단계는상기 객체의 각 키 포인트에 대해, 키 포인트 및 각 포인트 클라우드에 대응하는 타겟 예측 값의 평균 값을 키 포인트 정보로 결정하는 단계;상기 객체의 각 키 포인트에 대해, 키 포인트 및 각 포인트 클라우드에 대응하는 타겟 예측 값, 및 상기 인스턴스 마스크 정보 중 각 포인트 클라우드에 대응하는 확률 값의 가중 평균 값을 키 포인트 정보로 결정하는 단계;상기 객체의 각 키 포인트에 대해, 키 포인트 및 객체 중심점에 가장 가까운 미리 설정된 값의 포인트 클라우드에 대응하는 타겟 예측 값, 및 상기 인스턴스 마스크 정보 중 상기 미리 설정된 값의 포인트 클라우드에 대응하는 확률 값의 가중 평균 값을 키 포인트 정보로 결정하는 단계; 및상기 객체의 각 키 포인트에 대해, 키 포인트 및 각 포인트 클라우드에 대응하는 거리 근사 값, 키 포인트 및 각 포인트 클라우드에 대응하는 타겟 예측 값, 및 상기 인스턴스 마스크 정보 중 각 포인트 클라우드에 대응하는 확률 값의 가중 평균 값을 키 포인트 정보로 결정하는 단계중 적어도 하나를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>12. 제6항에 있어서,상기 시맨틱 분할 정보 및 상기 인스턴스 마스크 정보를 이용하여 상기 키 포인트 정보를 결정하는 단계는상기 시맨틱 분할 정보 및 상기 인스턴스 마스크 정보에 기초하여 인스턴스 분할 정보를 결정하는 단계;상기 이미지 특징에 기초하여 각 포인트 클라우드에 대응하는 키 포인트의 제1 오프셋을 추정하는 단계; 및상기 제1 오프셋과 상기 인스턴스 분할 정보에 기초한 회귀를 통해 상기 키 포인트 정보를 결정하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 제1 오프셋과 상기 인스턴스 분할 정보에 기초한 상기 회귀를 통해 상기 키 포인트 정보를 결정하는 단계는상기 제1 오프셋 및 포인트 클라우드 정보에 기초하여, 포인트 클라우드를 기준으로 예측된 *?*키 포인트의 초기 예측 값을 결정하는 단계;상기 초기 예측 값 및 인스턴스 마스크 정보에 기초하여 상기 3차원 그리드에서 키 포인트의 타겟 예측 값을 결정하는 단계; 및상기 타겟 예측 값에 기초한 회귀를 통해 상기 키 포인트 정보를 결정하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 제1 오프셋과 상기 인스턴스 분할 정보에 기초한 상기 회귀를 통해 상기 키 포인트 정보를 결정하는 단계는상기 제1 오프셋 및 포인트 클라우드 정보에 기초하여, 포인트 클라우드를 기준으로 예측된 *?*키 포인트의 초기 예측 값을 결정하는 단계;상기 초기 예측 값 및 인스턴스 분할 정보에 기초하여 상기 3차원 그리드에서 키 포인트의 타겟 예측 값을 결정하는 단계; 및상기 타겟 예측 값을 기반으로 회귀 방법을 통해 객체의 키 포인트 정보를 결정하는 단계를 포함하는, 객체 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>15. 하드웨어와 결합되어 제1항 내지 제10항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 프로세서; 및상기 프로세서에서 실행가능한 명령어들을 포함하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에서 실행되면, 상기 프로세서는입력 이미지의 포인트 클라우드에 대응하는 이미지 특징을 획득하고,상기 이미지 특징에 기초하여, 객체의 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보를 결정하고,상기 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보에 기초하여 객체 포즈를 추정하는,객체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 프로세서는상기 이미지 특징에 기초하여 상기 포인트 클라우드에 대응하는 상기 시맨틱 분할 정보를 결정하고,상기 입력 이미지에 대응하는 포인트 클라우드 정보에 기초하여 3차원 그리드를 생성하고, 상기 3차원 그리드에 기초하여 상기 인스턴스 마스크 정보를 결정하고,상기 인스턴스 마스크 정보를 이용하거나, 또는 상기 시맨틱 분할 정보 및 상기 인스턴스 마스크 정보를 이용하여 상기 키 포인트 정보를 결정하고,상기 인스턴스 마스크 정보는 상기 3차원 그리드에서 상기 포인트 클라우드에 대응하는 그리드 정보를 나타내고,상기 객체의 중심의 포인트 클라우드에 대응하는 그리드 정보에 기초하여 상기 객체의 각 포인트 클라우드에 대응하는 네트워크 정보가 결정되는,객체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서는상기 이미지 특징에 기초하여 각 포인트 클라우드에 대응하는 키 포인트의 제1 오프셋을 추정하고,상기 이미지 특징 및 상기 인스턴스 마스크 정보에 기초하여 상기 3차원 그리드의 각 셀에서 각 포인트 클라우드에 대응하는 키 포인트의 제2 오프셋을 추정하고,상기 제1 오프셋 및 상기 인스턴스 마스크 정보에 기초한 회귀 및 상기 제2 오프셋에 기초한 회귀 중 적어도 하나를 통해 상기 키 포인트 정보를 결정하는,객체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>19. 입력 이미지를 생성하는 카메라; 및상기 입력 이미지의 포인트 클라우드에 대응하는 이미지 특징을 획득하고,상기 이미지 특징에 기초하여, 객체의 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보를 결정하고,상기 시맨틱 분할 정보, 인스턴스 마스크 정보, 및 키 포인트 정보에 기초하여 객체 포즈를 추정하는, 프로세서를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 프로세서는상기 이미지 특징에 기초하여 상기 포인트 클라우드에 대응하는 상기 시맨틱 분할 정보를 결정하고,상기 입력 이미지에 대응하는 포인트 클라우드 정보에 기초하여 3차원 그리드를 생성하고, 상기 3차원 그리드에 기초하여 상기 인스턴스 마스크 정보를 결정하고,상기 인스턴스 마스크 정보를 이용하거나, 또는 상기 시맨틱 분할 정보 및 상기 인스턴스 마스크 정보를 이용하여 상기 키 포인트 정보를 결정하고,상기 인스턴스 마스크 정보는 상기 3차원 그리드에서 상기 포인트 클라우드에 대응하는 그리드 정보를 나타내고,상기 객체의 중심의 포인트 클라우드에 대응하는 그리드 정보에 기초하여 상기 객체의 각 포인트 클라우드에 대응하는 네트워크 정보가 결정되는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>Weiming, LI</engName><name>웨이밍, 리</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170747602</code><country>대한민국</country><engName>KIM, Jiyeon</engName><name>김지연</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code>420170474303</code><country>대한민국</country><engName>CHANG, Hyun Sung</engName><name>장현성</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>Qiang, WANG</engName><name>창, 왕</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HONG Sung Hoon</engName><name>홍성훈</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>Yang, LIU</engName><name>양, 류</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>Hao, WANG</engName><name>하오, 왕</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>Yueying, KAO</engName><name>웨잉, 카오</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2020.12.08</priorityApplicationDate><priorityApplicationNumber>202011446331.X</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.10.19</receiptDate><receiptNumber>1-1-2021-1197353-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2021.10.21</receiptDate><receiptNumber>9-1-2021-9011704-07</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.10.21</receiptDate><receiptNumber>1-1-2024-1144349-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210139573.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c939f69f585f11228db98bdb65401da7b77c45b15dd1d9a1f9c16a7cc6a52551811b16d290499d626ad32b00ef3d031e7c9bd15f3d9a33623c2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd938a3fb8d36745d2181fffe49fe1644535b7711bb9e2c875ab9dc8927a038a121cc1edda895fa79553e5f101648f1f0d9e694f034c9dca2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>