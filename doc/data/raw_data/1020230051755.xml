<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:46.4146</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.04.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0051755</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 세그먼테이션 방법 및 그 시스템</inventionTitle><inventionTitleEng>METHOD FOR IMAGE SEGMENTATION AND SYSTEM THEREOF</inventionTitleEng><openDate>2024.10.29</openDate><openNumber>10-2024-0155462</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/215</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미지 세그먼테이션 방법 및 그 시스템이 제공된다. 본 개시의 몇몇 실시예들에 따른 이미지 세그먼테이션 방법은, 이미지 세그먼테이션 태스크를 통해 학습된 딥러닝 모델을 획득하는 단계, 주어진 영상의 현재 프레임과 연관된 모션 정보를 추출하는 단계 및 모션 정보를 딥러닝 모델의 클래스별 특징맵에 반영하여 현재 프레임에 대한 이미지 세그먼테이션을 수행하는 단계를 포함할 수 있다. 이러한 방법에 따르면, 딥러닝 모델에 대한 추가적인 학습 없이도 영상에 대한 세그먼테이션 정확도가 크게 향상될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 컴퓨팅 장치에 의해 수행되는 방법에 있어서,이미지 세그먼테이션 태스크를 통해 학습된 딥러닝 모델을 획득하는 단계;주어진 영상의 현재 프레임과 연관된 모션 정보를 추출하는 단계; 및상기 모션 정보를 상기 딥러닝 모델의 클래스별 특징맵에 반영하여 상기 현재 프레임에 대한 이미지 세그먼테이션을 수행하는 단계를 포함하는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 딥러닝 모델의 학습 과정에서는 모션 정보가 이용되지 않는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 이미지 세그먼테이션을 수행하는 단계는,상기 모션 정보를 기초로 상기 현재 프레임과 연관된 모션의 양이 기준치 이상이라는 판단에 기초하여 상기 이미지 세그먼테이션을 수행하는 단계를 포함하고,상기 모션의 양이 기준치 미만인 경우에는 이전 프레임의 이미지 세그먼테이션 결과가 상기 현재 프레임의 이미지 세그먼테이션 결과로 이용되는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 모션 정보를 추출하는 단계는,상기 영상에 포함된 복수의 프레임들 중에서 레퍼런스 프레임을 결정하는 단계; 및상기 현재 프레임과 상기 레퍼런스 프레임의 차이(difference)에 기초하여 상기 모션 정보를 추출하는 단계를 포함하는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 현재 프레임과 상기 레퍼런스 프레임 간의 번호 차이는 상기 영상을 촬영한 장치의 프레임 속도가 높을수록 더 큰 값으로 결정되는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 현재 프레임과 상기 레퍼런스 프레임 간의 번호 차이는 상기 영상이 출력되는 디스플레이의 해상도가 높을수록 더 작은 값으로 결정되는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 현재 프레임과 상기 레퍼런스 프레임 간의 번호 차이는 상기 현재 프레임에 포함된 객체의 중요도가 높을수록 더 작은 값으로 결정되는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 객체는 화상 회의에 참여한 사용자에 해당하는 사람 객체이고,상기 객체의 중요도는 상기 사용자의 발화량 또는 상기 화상 회의 내에서의 상기 사용자의 역할에 기초하여 결정되는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 추출된 모션 정보는 상기 현재 프레임에 존재하는 제1 객체와 제2 객체의 모션 정보를 포함하고,상기 이미지 세그먼테이션을 수행하는 단계는,상기 제1 객체의 모션 정보를 상기 제1 객체에 대응되는 제1 클래스의 특징맵에 반영하는 단계; 및상기 제2 객체의 모션 정보를 상기 제2 객체에 대응되는 제2 클래스의 특징맵에 반영하는 단계를 포함하는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 추출된 모션 정보는 2차원 데이터이고,상기 제1 클래스의 특징맵에 반영하는 단계는,상기 제1 클래스의 특징맵에서 기준치 이상의 특징값을 갖는 활성화(activated) 영역을 결정하는 단계;상기 2차원 데이터에서 상기 활성화 영역에 위치적으로 대응되는 객체 모션 영역을 검출하는 단계; 및상기 객체 모션 영역의 값을 상기 제1 클래스의 특징맵에 반영하는 단계를 포함하는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 추출된 모션 정보는 2차원 데이터이고,상기 제1 클래스의 특징맵에 반영하는 단계는,상기 제1 객체의 속성(attribute) 정보를 이용하여 상기 2차원 데이터에서 상기 제1 객체의 모션 영역을 검출하는 단계; 및상기 모션 영역의 값을 상기 제1 클래스의 특징맵에 반영하는 단계를 포함하는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 이미지 세그먼테이션을 수행하는 단계는,기 설정된 가중치에 기반하여 상기 모션 정보의 값을 상기 클래스별 특징맵에 반영하는 단계를 포함하고,상기 가중치는 상기 딥러닝 모델의 성능이 낮을수록 더 높은 값으로 설정되는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,상기 영상은 화상 회의에 참여한 사용자를 촬영한 것이고,상기 현재 프레임에 대한 상기 이미지 세그먼테이션의 결과를 이용하여 상기 현재 프레임에 상기 사용자가 설정한 가상 배경을 적용하는 단계를 더 포함하는,이미지 세그먼테이션 방법.</claim></claimInfo><claimInfo><claim>14. 하나 이상의 프로세서; 및인스트럭션들을 저장하는 메모리를 포함하고,상기 하나 이상의 프로세서는,상기 저장된 인스트럭션들을 실행시킴으로써,이미지 세그먼테이션 태스크를 통해 학습된 딥러닝 모델을 획득하는 동작,주어진 영상의 현재 프레임과 연관된 모션 정보를 추출하는 동작 및상기 모션 정보를 상기 딥러닝 모델의 클래스별 특징맵에 반영하여 상기 현재 프레임에 대한 이미지 세그먼테이션을 수행하는 동작을 수행하는,이미지 세그먼테이션 시스템.</claim></claimInfo><claimInfo><claim>15. 컴퓨팅 장치와 결합되어,이미지 세그먼테이션 태스크를 통해 학습된 딥러닝 모델을 획득하는 단계;주어진 영상의 현재 프레임과 연관된 모션 정보를 추출하는 단계; 및상기 모션 정보를 상기 딥러닝 모델의 클래스별 특징맵에 반영하여 상기 현재 프레임에 대한 이미지 세그먼테이션을 수행하는 단계를 실행시키기 위하여 컴퓨터로 판독가능한 기록매체에 저장된,컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 송파구...</address><code>119980017903</code><country>대한민국</country><engName>SAMSUNG SDS Co.,Ltd.</engName><name>삼성에스디에스 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>YANG, Hee Sung</engName><name>양희성</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>KANG, Jun Ho</engName><name>강준호</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>IM, Do Hyung</engName><name>임도형</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서초구 남부순환로 ****, *층(서초동, 한원빌딩)</address><code>920071001019</code><country>대한민국</country><engName>KASAN IP &amp; LAW FIRM</engName><name>특허법인가산</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.04.20</receiptDate><receiptNumber>1-1-2023-0444279-09</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230051755.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c935ebedc9bd714f0589fa14465d49e5cf1b7a6b41870825caaa696d2fd49533b3cd11121f49ee174bd713d58574368d6f38905c03c750020be</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff483aee9dfebe0859dea09471167bd7c7b2bb9f67da5eebf40193fd8ec9ec36081d51c2693a119bc381c20c9d96dcb271b27295780190009</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>