<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:28:01.281</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.12.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0197918</applicationNumber><claimCount>16</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법 및 영상처리장치</inventionTitle><inventionTitleEng>PREDICTION METHOD FOR LOCATION OF OBJECT AROUND VEHICLE  USING MULTI-MODAL DATA AND IMAGE PROCESSING APPARATUS</inventionTitleEng><openDate>2025.07.04</openDate><openNumber>10-2025-0101947</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/049</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 차량 주변 객체 위치를 예측하는 영상처리장치는 현재 시간 t 및 과거 시간에서의 RGB 영상 및 라이더 데이터를 입력받는 인터페이스 장치, 의미론적 분할을 수행하는 세그멘테이션 모델 및 객체 미래 위치를 예측하는 객체 위치 예측 네트워크를 저장하는 저장장치 및 상기 세그멘테이션 모델을 이용하여 상기 RGB 영상에 대한 의미론적 분할을 수행하여 마스크를 생성하고, 상기 객체 위치 예측 네트워크를 이용하여 상기 의미론적 분할한 영상, 상기 마스크 및 상기 라이더 데이터를 기준으로 상기 RGB 영상에 포함된 객체의 미래 시간의 위치를 예측하는 연산장치를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 영상처리장치가 현재 시간 t 및 과거 시간에서의 RGB 영상 및 라이더 데이터를 입력받는 단계;상기 영상처리장치가 세그멘테이션 모델을 이용하여 상기 RGB 영상에 대한 의미론적 분할을 수행하여 마스크를 생성하는 단계;상기 영상처리장치가 상기 RGB 영상 및 상기 라이더 데이터를 융합하여 범위 영상(range view)을 생성하는 단계;상기 영상처리장치가 상기 RGB 영상에 대한 의미론적 분할한 영상, 상기 마스크 및 상기 범위 영상을 결합하여 시계열 데이터를 처리하는 특징 추출하는 신경망 계층에 입력하는 단계;상기 영상처리장치가 차량의 에고 모션 정보에 대한 벡터 및 상기 신경망 계층이 출력하는 벡터를 결합하여 전연결 계층에 입력하는 단계; 및상기 영상처리장치가 상기 전열결 계층이 출력하는 바운딩 박스를 기준으로 상기 RGB 영상에 포함된 객체의 미래 시간의 위치를 예측하는 단계를 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 영상처리장치는 NeRF를 이용하여 상기 차량에서 수집한 영상 및 상기 차량의 주변 차량에서 수집한 영상을 기준으로 새로운 시점의 영상인 상기 RGB 영상을 생성하는 단계를 더 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 영상처리장치는 일 방향에 대한 시점이 다른 영상들을 결합(stitching)하여 넓은 시야각 영상인 상기 RGB 영상을 생성하는 단계를 더 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 신경망 계층 및 상기 전열결 계층은 학습과정에서 현재 시간 프레임 및 2개의 과거 프레임들을 사용하여 학습을 진행하되, 상기 2개의 과거 프레임들은 과거 프레임들 중 다변량 가우시안 분포를 기준으로 객체의 미래 위치 예측 정확도가 가장 높은 프레임들로 선별되는, 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>5. 영상처리장치가 현재 시간 t 및 과거 시간에서의 RGB 영상 및 라이더 데이터를 입력받는 단계;상기 영상처리장치가 세그멘테이션 모델을 이용하여 상기 RGB 영상에 대한 의미론적 분할을 수행하여 마스크를 생성하는 단계;상기 영상처리장치가 상기 RGB 영상에 대한 의미론적 분할한 영상 및 상기 마스크를 결합하여 시계열 데이터를 처리하는 특징 추출하는 신경망 계층에 입력하는 단계;상기 영상처리장치가 상기 라이더 데이터를 필터 특징 네트(Pillar Feature Net)에 입력하여 수도 영상을 생성하고, 상기 수도 영상을 컨볼루션 계층에 입력하여 라이더 데이터에 대한 벡터를 생성하는 단계;상기 영상처리장치가 차량의 에고 모션 정보에 대한 벡터, 상기 신경망 계층이 출력하는 벡터 및 상기 라이더 데이터에 대한 벡터를 결합하여 전연결 계층에 입력하는 단계; 및상기 영상처리장치가 상기 전열결 계층이 출력하는 바운딩 박스를 기준으로 상기 RGB 영상에 포함된 객체의 미래 시간의 위치를 예측하는 단계를 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 영상처리장치는 NeRF를 이용하여 상기 차량에서 수집한 영상 및 상기 차량의 주변 차량에서 수집한 영상을 기준으로 새로운 시점의 영상인 상기 RGB 영상을 생성하는 단계를 더 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 영상처리장치는 일 방향에 대한 시점이 다른 영상들을 결합(stitching)하여 넓은 시야각 영상인 상기 RGB 영상을 생성하는 단계를 더 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>8. 제5항에 있어서,상기 신경망 계층 및 상기 전열결 계층은 학습과정에서 현재 시간 프레임 및 2개의 과거 프레임들을 사용하여 학습을 진행하되, 상기 2개의 과거 프레임들은 과거 프레임들 중 다변량 가우시안 분포를 기준으로 객체의 미래 위치 예측 정확도가 가장 높은 프레임들로 선별되는, 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>9. 영상처리장치가 현재 시간 t 및 과거 시간에서의 RGB 영상 및 라이더 데이터를 입력받는 단계;상기 영상처리장치가 세그멘테이션 모델을 이용하여 상기 RGB 영상에 대한 의미론적 분할을 수행하여 마스크를 생성하는 단계;상기 영상처리장치가 상기 RGB 영상에 대한 의미론적 분할한 영상 및 상기 마스크를 결합하여 시계열 데이터를 처리하는 특징 추출하는 신경망 계층에 입력하는 단계;상기 영상처리장치가 상기 라이더 데이터를 필터 특징 네트(Pillar Feature Net)에 입력하여 수도 영상을 생성하고, 상기 수도 영상을 컨볼루션 계층에 입력하여 라이더 데이터에 대한 벡터를 생성하는 단계;상기 영상처리장치가 상기 신경망 계층에서 출력하는 벡터와 상기 라이더 데이터에 대한 벡터를 기준으로 어텐션을 수행하는 단계;상기 영상처리장치가 차량의 에고 모션 정보에 대한 벡터 및 상기 어텐션하여 출력되는 벡터를 결합하여 전연결 계층에 입력하는 단계; 및상기 영상처리장치가 상기 전열결 계층이 출력하는 바운딩 박스를 기준으로 상기 RGB 영상에 포함된 객체의 미래 시간의 위치를 예측하는 단계를 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 영상처리장치는 NeRF를 이용하여 상기 차량에서 수집한 영상 및 상기 차량의 주변 차량에서 수집한 영상을 기준으로 새로운 시점의 영상인 상기 RGB 영상을 생성하는 단계를 더 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 영상처리장치는 일 방향에 대한 시점이 다른 영상들을 결합(stitching)하여 넓은 시야각 영상인 상기 RGB 영상을 생성하는 단계를 더 포함하는 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>12. 제9항에 있어서,상기 신경망 계층 및 상기 전열결 계층은 학습과정에서 현재 시간 프레임 및 2개의 과거 프레임들을 사용하여 학습을 진행하되, 상기 2개의 과거 프레임들은 과거 프레임들 중 다변량 가우시안 분포를 기준으로 객체의 미래 위치 예측 정확도가 가장 높은 프레임들로 선별되는, 멀티모달 데이터를 이용한 차량 주변 객체 위치 예측 방법.</claim></claimInfo><claimInfo><claim>13. 현재 시간 t 및 과거 시간에서의 RGB 영상 및 라이더 데이터를 입력받는 인터페이스 장치;의미론적 분할을 수행하는 세그멘테이션 모델 및 객체 미래 위치를 예측하는 객체 위치 예측 네트워크를 저장하는 저장장치; 및상기 세그멘테이션 모델을 이용하여 상기 RGB 영상에 대한 의미론적 분할을 수행하여 마스크를 생성하고, 상기 객체 위치 예측 네트워크를 이용하여 상기 의미론적 분할한 영상, 상기 마스크 및 상기 라이더 데이터를 기준으로 상기 RGB 영상에 포함된 객체의 미래 시간의 위치를 예측하는 연산장치를 포함하되,상기 RGB 영상은 NeRF를 이용하여 차량에서 수집한 영상 및 상기 차량의 주변 차량에서 수집한 영상을 기준으로 생성한 새로운 시점의 영상인, 차량 주변 객체 위치를 예측하는 영상처리장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 연산장치는 상기 RGB 영상 및 상기 라이더 데이터를 융합하여 범위 영상(range view)을 생성하고, 상기 객체 위치 예측 네트워크는 상기 RGB 영상에 대한 의미론적 분할한 영상, 상기 마스크 및 상기 범위 영상을 결합한 데이터를 입력받는 신경망 계층; 및 상기 차량의 에고 모션 정보에 대한 벡터 및 상기 신경망 계층이 출력하는 벡터를 결합한 벡터를 입력받아 상기 객체에 대한 바운딩 박스를 출력하는 전연결 계층을 포함하는, 차량 주변 객체 위치를 예측하는 영상처리장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 객체 위치 예측 네트워크는 상기 RGB 영상에 대한 의미론적 분할한 영상 및 상기 마스크를 결합한 데이터를 입력받는 제1 신경망 계층;상기 라이더 데이터를 입력받아 수도 영상을 생성하고, 상기 수도 영상에 대한 벡터를 산출하는 제2 신경망 계층; 및차량의 에고 모션 정보에 대한 벡터, 상기 제1 신경망 계층이 출력하는 벡터 및 상기 제2 신경망 계층이 출력하는 벡터를 결합한 벡터를 입력받아 상기 객체에 대한 바운딩 박스를 출력하는 전연결 계층을 포함하는, 차량 주변 객체 위치를 예측하는 영상처리장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 객체 위치 예측 네트워크는 상기 RGB 영상에 대한 의미론적 분할한 영상 및 상기 마스크를 결합한 데이터를 입력받는 제1 신경망 계층;상기 라이더 데이터를 입력받아 수도 영상을 생성하고, 상기 수도 영상에 대한 벡터를 산출하는 제2 신경망 계층; 및상기 제1 신경망 계층에서 출력하는 벡터와 상기 제2 신경망 계층에서 출력하는 벡터를 기준으로 어텐션을 수행한 벡터 및 차량의 에고 모션 정보에 대한 벡터를 결합한 벡터를 입력받아 상기 객체에 대한 바운딩 박스를 출력하는 전연결 계층을 포함하는, 차량 주변 객체 위치를 예측하는 영상처리장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220040083301</code><country>대한민국</country><engName>Ewha University - Industry Collaboration Foundation</engName><name>이화여자대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 마포구...</address><code> </code><country>대한민국</country><engName>KANG, Je Won</engName><name>강제원</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country>대한민국</country><engName>YOON, Jee Ye</engName><name>윤지예</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로**길**, **층, **층(코아렌빌딩)</address><code>920161001214</code><country>대한민국</country><engName>ISIS IP Law LLC</engName><name>특허법인(유한)아이시스</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.12.27</priorityApplicationDate><priorityApplicationNumber>1020230192671</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.12.27</receiptDate><receiptNumber>1-1-2024-1446932-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.04.25</receiptDate><receiptNumber>1-1-2025-0472543-28</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240197918.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93662e3a8b4644c13ecbe027a4d9b368a882a2431f7cf85d2a264d8aef59cac744d4020858825107a11a2003361478aa26e606cd91efd1620d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4d2c3b86128be8909321a3b0e74189ab26f59a41d41bcde7fd1b32ed36aff13864083eaf37f01a992331baa4694479afa550d5c421b3d39d</path></imagePathInfo><rndInfoArray><rndInfo><rndDepartmentName>과학기술정보통신부</rndDepartmentName><rndDuration>2023.03.01 ~ 2024.02.29</rndDuration><rndManagingInstituteName>이화여자대학교</rndManagingInstituteName><rndProjectName>개인기초연구(과기정통부)</rndProjectName><rndSpecialInstituteName>한국연구재단</rndSpecialInstituteName><rndTaskContribution> </rndTaskContribution><rndTaskName>거대 공간을 표현하는 대용량 몰입형 비디오의 압축 도메인 학습 방법과 입체 공간 피처 레벨 신호처리에 관한 핵심 기술 개발</rndTaskName><rndTaskNumber>1711190368</rndTaskNumber></rndInfo><rndInfo><rndDepartmentName>과학기술정보통신부</rndDepartmentName><rndDuration>2023.01.01 ~ 2023.12.31</rndDuration><rndManagingInstituteName>이화여자대학교</rndManagingInstituteName><rndProjectName>정보통신방송기술국제공동연구</rndProjectName><rndSpecialInstituteName>정보통신기획평가원</rndSpecialInstituteName><rndTaskContribution> </rndTaskContribution><rndTaskName>이동형 로봇 기반 실사 메타버스 실감형 비디오의 획득 및 처리 기술 개발</rndTaskName><rndTaskNumber>1711179355</rndTaskNumber></rndInfo></rndInfoArray></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>