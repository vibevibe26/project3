<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:29:22.2922</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0027652</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>텍스트-비디오 검색을 위한 학습 장치 및 방법</inventionTitle><inventionTitleEng>Learning Device and Method for Text-to-Video Retrieval</inventionTitleEng><openDate>2025.09.03</openDate><openNumber>10-2025-0131332</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.02.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 텍스트 데이터와 비디오 데이터 쌍으로 구성되는 다수의 학습 데이터를 학습 대상인 텍스트-비디오 검색 모델의 텍스트 인코더와 비디오 인코더 각각에 인가하여 인코딩하여 가상의 공통 임베딩 공간에 표현되는 텍스트 표현자와 대표 비디오 표현자 및 비디오 데이터에서 샘플링된 다수의 프레임에 각각에 대한 다수의 프레임 표현자를 인가받고, 다수의 프레임 표현자 중 텍스트 표현자와 높은 유사도를 갖는 상위 K개의 프레임 표현자를 이용하여 획득되는 키 표현자 및 나머지 프레임 표현자를 이용하여 획득되는 노이즈 표현자 각각과 대표 비디오 표현자 사이의 유사도를 계산하여 노이즈 억제 대조 손실을 계산하여 텍스트-비디오 검색 모델에 대한 학습을 수행하므로, 사전 학습된 텍스트-이미지 모델에 대해 추가 학습을 수행하여 텍스트와 비디오 사이의 교차 표현력이 향상되도록 함으로써, 텍스트-비디오 검색 성능을 향상시킬 수 있는 텍스트-비디오 검색을 위한 학습 장치 및 방법을 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 메모리; 및 상기 메모리에 저장된 프로그램에 따른 동작의 적어도 일부를 실행하는 프로세서를 포함하는 장치로서, 상기 프로세서는 텍스트 데이터와 비디오 데이터 쌍으로 구성되는 다수의 학습 데이터를 학습 대상인 텍스트-비디오 검색 모델의 텍스트 인코더와 비디오 인코더 각각에 인가하여 인코딩하여 가상의 공통 임베딩 공간에 표현되는 텍스트 표현자와 대표 비디오 표현자 및 상기 비디오 데이터에서 샘플링된 다수의 프레임에 각각에 대한 다수의 프레임 표현자를 인가받고, 상기 다수의 프레임 표현자 중 상기 텍스트 표현자와 높은 유사도를 갖는 상위 K개의 프레임 표현자를 이용하여 획득되는 키 표현자 및 나머지 프레임 표현자를 이용하여 획득되는 노이즈 표현자 각각과 상기 대표 비디오 표현자 사이의 유사도를 계산하여 노이즈 억제 대조 손실을 계산하여 상기 텍스트-비디오 검색 모델에 대한 학습을 수행하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 프로세서는 상기 다수의 프레임 표현자 각각과 상기 텍스트 표현자 사이의 유사도를 계산하고, 계산된 유사도가 높은 상위 K개의 프레임 표현자에 대해 평균값 풀링하여 상기 키 표현자를 획득하며, 선택되지 않은 나머지 프레임에 대해 평균값 풀링하여 상기 노이즈 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 프로세서는 상기 임베딩 공간에서 상기 키 표현자는 상기 대표 비디오 표현자에 가까워지는 반면 상기 노이즈 표현자는 상기 대표 비디오 표현자에서 멀어지도록 노이즈 억제 대조 손실을 계산하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 프로세서는 상기 키 표현자(zitopk)와 상기 노이즈 표현자(zinoisy) 및 상기 대표 비디오 표현자(zi0)에 따른 상기 노이즈 억제 대조 손실(Lsup)을 수학식 (여기서 B와 N은 각각 네거티브 백의 배치 크기와 카디널리티, τ는 하이퍼 파라미터, zn0은 네거티브 비디오 표현자(i ≠ n))에 따라 계산하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 프로세서는 상기 텍스트 표현자와의 유사도에 따라 상기 다수의 프레임 표현자를 가중합하여, 상기 텍스트 표현자와의 연관성이 강조된 비디오 표현자인 텍스트 가이드 비디오 표현자를 획득하고, 상기 대표 비디오 표현자를 신경망 연산으로 투영 변환한 투영 대표 비디오 표현자와 상기 텍스트 가이드 비디오 표현자 사이의 유사도를 기반으로 텍스트 가이드 비디오 토큰 손실을 계산하여 학습을 수행하는 학습 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 프로세서는 상기 텍스트 표현자와 상기 다수의 프레임 표현자 각각을 내적하고, 소프트맥스 연산하여 주의 벡터를 획득하고, 상기 주의 벡터를 상기 다수의 프레임 표현자에 가중합하여 상기 텍스트 가이드 비디오 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 프로세서는 상기 학습 데이터에서 서로 쌍을 이루는 텍스트 데이터와 비디오 데이터에서 획득된 텍스트 표현자와 비디오 표현자 쌍은 서로 유사해지도록 하는 한편, 상을 이루지 않는 텍스트 데이터와 비디오 데이터에서 획득된 텍스트 표현자와 비디오 표현자 쌍은 서로 상이해지도록 하는 대조 손실을 계산하여 학습을 수행하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 텍스트 인코더는 상기 텍스트 데이터를 토큰화하여 다수의 텍스트 토큰으로 변환하고, 변환된 텍스트 토큰에 클래스 토큰을 추가하여 인코딩함으로써, 상기 텍스트 데이터를 대표하는 상기 텍스트 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 비디오 인코더는 상기 비디오 데이터의 다수의 프레임 중에서 샘플링된 프레임 각각에 대해 신경망 연산으로 특징을 추출하여 클래스 토큰과 다수의 프레임 토큰을 획득하고, 상기 클래스 토큰과 상기 다수의 프레임 토큰 각각을 인코딩하여, 상기 대표 비디오 표현자와 상기 다수의 프레임 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 텍스트 인코더와 비디오 인코더는 사전 학습된 텍스트-이미지 검색 모델의 텍스트 인코더와 이미지 인코더로부터 획득되는 텍스트-비디오 검색을 위한 학습 장치.</claim></claimInfo><claimInfo><claim>11. 프로세서에 의해 수행되는 방법으로서, 텍스트 데이터와 비디오 데이터 쌍으로 구성되는 다수의 학습 데이터를 학습 대상인 텍스트-비디오 검색 모델의 텍스트 인코더와 비디오 인코더 각각에 인가하여 인코딩하여 가상의 공통 임베딩 공간에 표현되는 텍스트 표현자와 대표 비디오 표현자 및 상기 비디오 데이터에서 샘플링된 다수의 프레임에 각각에 대한 다수의 프레임 표현자를 인가받는 단계; 및 상기 다수의 프레임 표현자 중 상기 텍스트 표현자와 높은 유사도를 갖는 상위 K개의 프레임 표현자를 이용하여 획득되는 키 표현자 및 나머지 프레임 표현자를 이용하여 획득되는 노이즈 표현자 각각과 상기 대표 비디오 표현자 사이의 유사도를 계산하여 노이즈 억제 대조 손실을 계산하여 상기 텍스트-비디오 검색 모델에 대한 학습을 수행하는 단계를 포함하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 학습을 수행하는 단계는 상기 다수의 프레임 표현자 각각과 상기 텍스트 표현자 사이의 유사도를 계산하고, 계산된 유사도가 높은 상위 K개의 프레임 표현자에 대해 평균값 풀링하여 상기 키 표현자를 획득하며, 선택되지 않은 나머지 프레임에 대해 평균값 풀링하여 상기 노이즈 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 학습을 수행하는 단계는 상기 임베딩 공간에서 상기 키 표현자는 상기 대표 비디오 표현자에 가까워지는 반면 상기 노이즈 표현자는 상기 대표 비디오 표현자에서 멀어지도록 노이즈 억제 대조 손실을 계산하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 학습을 수행하는 단계는 상기 키 표현자(zitopk)와 상기 노이즈 표현자(zinoisy) 및 상기 대표 비디오 표현자(zi0)에 따른 상기 노이즈 억제 대조 손실(Lsup)을 수학식 (여기서 B와 N은 각각 네거티브 백의 배치 크기와 카디널리티, τ는 하이퍼 파라미터, zn0은 네거티브 비디오 표현자(i ≠ n))에 따라 계산하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 학습을 수행하는 단계는 상기 텍스트 표현자와의 유사도에 따라 상기 다수의 프레임 표현자를 가중합하여, 상기 텍스트 표현자와의 연관성이 강조된 비디오 표현자인 텍스트 가이드 비디오 표현자를 획득하고, 상기 대표 비디오 표현자를 신경망 연산으로 투영 변환한 투영 대표 비디오 표현자와 상기 텍스트 가이드 비디오 표현자 사이의 유사도를 기반으로 텍스트 가이드 비디오 토큰 손실을 계산하여 학습을 수행하는 학습 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 학습을 수행하는 단계는 상기 텍스트 표현자와 상기 다수의 프레임 표현자 각각을 내적하고, 소프트맥스 연산하여 주의 벡터를 획득하고, 상기 주의 벡터를 상기 다수의 프레임 표현자에 가중합하여 상기 텍스트 가이드 비디오 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 학습을 수행하는 단계는 상기 학습 데이터에서 서로 쌍을 이루는 텍스트 데이터와 비디오 데이터에서 획득된 텍스트 표현자와 비디오 표현자 쌍은 서로 유사해지도록 하는 한편, 상을 이루지 않는 텍스트 데이터와 비디오 데이터에서 획득된 텍스트 표현자와 비디오 표현자 쌍은 서로 상이해지도록 하는 대조 손실을 계산하여 학습을 수행하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 다수의 프레임 표현자를 인가받는 단계는 상기 텍스트 인코더가 상기 텍스트 데이터를 토큰화하여 다수의 텍스트 토큰으로 변환하고, 변환된 텍스트 토큰에 클래스 토큰을 추가하여 인코딩함으로써, 상기 텍스트 데이터를 대표하는 상기 텍스트 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 다수의 프레임 표현자를 인가받는 단계는 상기 비디오 인코더가 상기 비디오 데이터의 다수의 프레임 중에서 샘플링된 프레임 각각에 대해 신경망 연산으로 특징을 추출하여 클래스 토큰과 다수의 프레임 토큰을 획득하고, 상기 클래스 토큰과 상기 다수의 프레임 토큰 각각을 인코딩하여, 상기 대표 비디오 표현자와 상기 다수의 프레임 표현자를 획득하는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서, 상기 텍스트 인코더와 비디오 인코더는 사전 학습된 텍스트-이미지 검색 모델의 텍스트 인코더와 이미지 인코더로부터 획득되는 텍스트-비디오 검색을 위한 학습 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220050095099</code><country>대한민국</country><engName>UIF (University Industry Foundation), Yonsei University</engName><name>연세대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>BYUN, Hyeran</engName><name>변혜란</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>LEE, Jewook</engName><name>이제욱</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>LEE, Pilhyeon</engName><name>이필현</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>JEON, Seogkyu</engName><name>전석규</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 남부순환로 **** (도곡동, 차우빌딩) *층(맥스국제특허법률사무소)</address><code>920010001018</code><country>대한민국</country><engName>MIN YOUNG JOON</engName><name>민영준</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.02.27</receiptDate><receiptNumber>1-1-2024-0221732-07</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240027652.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93df6dbba8cd51b7954fc972d81d27fb67c7478b89ac4c065d55548e321e030038ca06bb4f10dbcb616d96f775229710db017dc149c29ad96e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf310e7b1f9d7c91f3a86a7c2ca6afddade094d4892b1b559eab45796eafaaee784674f186f727e56655e00f04d7a0c7b05c5b0bb4136ee87f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>