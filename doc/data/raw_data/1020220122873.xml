<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:00.400</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.09.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0122873</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 영역과 배경 영역을 분류하기 위한 전자 장치 및 전자 장치의 동작 방법</inventionTitle><inventionTitleEng>ELECTRONIC APPARATUS FOR CLASSIFYING OBJECT REGION  AND BACKGROUND REGION AND OPERATING METHOD FOR THE  SAME</inventionTitleEng><openDate>2024.04.03</openDate><openNumber>10-2024-0043594</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.09.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/155</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 적어도 하나의 명령어(instruction)를 저장하는 메모리(400) 및 메모리(400)에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서(500)를 포함하고, 적어도 하나의 프로세서(500)는 카메라(300)를 통하여, 객체 및 객체의 배경을 촬영한 입력 영상(1000)을 획득하고, 획득한 입력 영상(1000)을 객체에 대응되는 객체 영역(2100)과 객체의 배경에 대응되는 배경 영역(2200)으로 분류하여 제1 분류 맵(2000)을 획득하고, 제1 분류 맵(2000)을 전처리하여 제1 분류 맵(2000)에 포함된 노이즈(Noise) 영역(2300)을 제거한 제2 분류 맵(3000)을 획득하고, 카메라(300)로부터 객체까지의 거리 정보 및 노이즈 영역(2300)을 이용하여, 제1 분류 맵(2000) 및 제2 분류 맵(3000)에 기초하여 객체에 대응되는 객체 영상(5000)을 획득하는 전자 장치(100) 및 전자 장치(100)의 동작 방법을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 명령어(instruction)를 저장하는 메모리(400); 및상기 메모리(400)에 저장된 상기 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서(500)를 포함하고,상기 적어도 하나의 프로세서(500)는,카메라(300)를 통하여 객체 및 상기 객체의 배경을 촬영한 입력 영상(1000)을 획득하고,상기 획득한 입력 영상(1000)을 상기 객체에 대응되는 객체 영역(2100)과 상기 객체의 배경에 대응되는 배경 영역(2200)으로 분류하여 제1 분류 맵(2000)을 획득하고,상기 제1 분류 맵(2000)을 전처리하여, 상기 제1 분류 맵(2000)에 포함된 노이즈(Noise) 영역(2300)을 제거한 제2 분류 맵(3000)을 획득하고,상기 카메라로부터 상기 객체까지의 거리 정보 및 상기 노이즈 영역(2300)을 이용하여, 상기 제1 분류 맵(2000) 및 상기 제2 분류 맵(3000)에 기초하여 상기 객체에 대응되는 객체 영상(5000)을 획득하는 전자 장치(100).</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 적어도 하나의 프로세서(500)는,상기 카메라로부터 상기 객체까지의 거리 정보 및 상기 노이즈 영역(2300)을 이용하여, 상기 제1 분류 맵(2000) 및 상기 제2 분류 맵(3000)에 기초하여 최종 분류 맵(4000)을 획득하고,상기 최종 분류 맵(4000)을 상기 입력 영상(1000)에 적용하여 상기 객체 영상(5000)을 획득하는 전자 장치(100).</claim></claimInfo><claimInfo><claim>3. 제1 또는 제2 항 중 어느 하나의 항에 있어서,상기 제2 분류 맵(3000)은, 상기 제1 분류 맵(2000)을 모폴로지(Morphology) 연산하여 획득한 분류 맵인 전자 장치(100).</claim></claimInfo><claimInfo><claim>4. 제1 내지 제3 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(500)는,상기 카메라로부터 상기 객체까지의 거리 정보에 기초하여 제1 보정 계수를 계산하고,상기 제1 보정 계수는, 상기 객체 영상을 획득함에 있어, 상기 제1 분류 맵(2000)에 곱해지는 제1 서브 보정 계수 및 상기 제2 분류 맵(3000)에 곱해지는 제2 서브 보정 계수를 포함하고,상기 카메라로부터 상기 객체까지의 길이가 길어질수록 상기 제1 서브 보정 계수의 크기는 작아지고, 상기 카메라로부터 상기 객체까지의 길이가 길어질수록 상기 제2 서브 보정 계수의 크기는 커지며,상기 적어도 하나의 프로세서(500)는,상기 제1 서브 보정 계수와 곱해진 제1 분류 맵(2000)과 상기 제2 서브 보정 계수와 곱해진 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100).</claim></claimInfo><claimInfo><claim>5. 제1 내지 제4 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(500)는,상기 노이즈 영역(2300)에 기초하여 제2 보정 계수를 계산하고,상기 제1 분류 맵(2000)에 포함된 상기 객체 영역(2100) 대비 상기 노이즈 영역(2300)의 비율이 커질수록 상기 제2 보정 계수의 크기는 커지며,상기 적어도 하나의 프로세서(500)는,상기 제2 보정 계수가 곱해진 상기 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100).</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 제2 보정 계수는,상기 객체 영역(2100) 대비 상기 노이즈 영역(2300)의 비율, 상기 노이즈 영역(2300)의 개수 및 상기 노이즈 영역(2300)의 면적 중 적어도 하나에 기초하여 계산되는 전자 장치(100).</claim></claimInfo><claimInfo><claim>7. 제1 내지 6 항 중 어느 하나의 항에 있어서,상기 입력 영상(1000)은, 복수의 화소 영상들을 포함하고, 상기 적어도 하나의 프로세서(500)는,상기 입력 영상(1000)에 기초하여, 상기 복수의 화소 영상들 각각이 상기 객체에 대응될 확률 값을 계산하고,상기 복수의 화소 영상들의 배치 및 기 설정된 제1 기준 확률 값과 상기 계산된 확률을 비교한 결과에 기초하여 상기 복수의 화소 영상들을 상기 객체 영역(2100)과 상기 배경 영역(2200)으로 분류하여 상기 제1 분류 맵(2000)을 획득하는 전자 장치(100).</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 적어도 하나의 프로세서(500)는,상기 제1 분류 맵(2000)을 획득한 후, 기 설정된 제2 기준 확률 값과 상기 복수의 화소 영상들 중 상기 분류된 객체 영역(2100)에 포함된 적어도 하나의 화소 영상이 상기 객체에 대응될 확률 값을 비교한 결과에 기초하여 상기 객체 영역(2100)에 포함된 상기 노이즈 영역(2300)을 분류하고,상기 제2 기준 확률 값은, 상기 제1 기준 확률 값과 상이한 확률 값인 전자 장치(100).</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서,상기 적어도 하나의 프로세서(500)는,상기 제1 보정 계수, 상기 제2 보정 계수 및 상기 노이즈 영역(2300)에 포함된 적어도 하나의 화소 영상이 상기 객체에 대응될 확률 값에 기초하여 계산되는 제3 보정 계수를 이용하여, 상기 제1 분류 맵(2000) 및 상기 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100).</claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,상기 제3 보정 계수는,상기 노이즈 영역(2300)에 포함된 적어도 하나의 화소 영상이 상기 객체에 대응될 확률 값과 반비례하며,상기 적어도 하나의 프로세서(500)는,상기 제3 보정 계수가 곱해진 상기 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100).</claim></claimInfo><claimInfo><claim>11. 전자 장치(100)의 동작 방법에 있어서,카메라(300)를 통하여, 객체 및 상기 객체의 배경을 촬영한 입력 영상(1000)을 획득하는 단계(S100);상기 획득한 입력 영상(1000)을 상기 객체에 대응되는 객체 영역(2100)과 상기 객체의 배경에 대응되는 배경 영역(2200)으로 분류하여 제1 분류 맵(2000)을 획득하는 단계(S200);상기 제1 분류 맵(2000)을 전처리하여, 상기 제1 분류 맵(2000)에 포함된 노이즈(Noise) 영역(2300)을 제거한 제2 분류 맵(3000)을 획득하는 단계(S300);상기 카메라(300)로부터 상기 객체까지의 거리 정보 및 상기 노이즈 영역(2300)을 이용하여, 상기 제1 분류 맵(2000) 및 상기 제2 분류 맵(3000)에 기초하여 상기 객체에 대응되는 객체 영상(5000)을 획득하는 단계(S500)를 포함하는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 전자 장치(100)의 동작 방법은,상기 카메라로부터 상기 객체까지의 거리 정보 및 상기 노이즈 영역(2300)을 이용하여, 상기 제1 분류 맵(2000) 및 상기 제2 분류 맵(3000)에 기초하여 최종 분류 맵(4000)을 획득하는 단계를 더 포함하고,상기 객체 영상(5000)을 획득하는 단계(S500)에서는, 상기 최종 분류 맵(4000)을 상기 입력 영상(1000)에 적용하여 상기 객체 영상(5000)을 획득하는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>13. 제11 또는 제12 항 중 어느 하나의 항에 있어서,상기 카메라로부터 상기 객체까지의 거리 정보에 기초하여 계산된 제1 보정 계수는, 상기 객체 영상(5000)을 획득함에 있어, 상기 제1 분류 맵(2000)에 곱해지는 제1 서브 보정 계수 및 상기 제2 분류 맵(3000)에 곱해지는 제2 서브 보정 계수를 포함하고,상기 카메라로부터 상기 객체까지의 길이가 길어질수록 상기 제1 서브 보정 계수의 크기는 작아지고, 상기 카메라로부터 상기 객체까지의 길이가 길어질수록 상기 제2 서브 보정 계수의 크기는 커지며,상기 객체 영상(5000)을 획득하는 단계(S500)에서,상기 제1 서브 보정 계수가 곱해진 제1 분류 맵(2000)과 상기 제2 서브 보정 계수가 곱해진 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>14. 제11 내지 제13 항 중 어느 하나의 항에 있어서,상기 제1 분류 맵(2000)에 포함된 상기 객체 영역(2100) 대비 상기 노이즈 영역(2300)의 비율이 커질수록, 상기 노이즈 영역(2300)에 기초하여 계산되는 제2 보정 계수의 크기는 커지며,상기 객체 영상(5000)을 획득하는 단계(S500)에서,상기 제2 보정 계수가 곱해진 상기 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,상기 제2 보정 계수는,상기 객체 영역(2100) 대비 상기 노이즈 영역(2300)의 비율, 상기 노이즈 영역(2300)의 개수 및 상기 노이즈 영역(2300)의 면적 중 적어도 하나에 기초하여 계산되는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>16. 제11 내지 제15 항 중 어느 하나의 항에 있어서,상기 입력 영상(1000)은, 복수의 화소 영상들을 포함하고, 상기 전자 장치(100)의 동작 방법은,상기 입력 영상(1000)에 기초하여, 상기 복수의 화소 영상들 각각이 상기 객체에 대응될 확률 값을 계산하는 단계를 더 포함하고,상기 제1 분류 맵을 획득하는 단계(S200)에서,상기 복수의 화소 영상들의 배치 및 기 설정된 제1 기준 확률 값과 상기 계산된 확률을 비교한 결과에 기초하여 상기 복수의 화소 영상들을 상기 객체 영역(2100)과 상기 배경 영역(2200)으로 분류하여 상기 제1 분류 맵(2000)을 획득하는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>17. 제16 항에 있어서,상기 전자 장치(100)의 동작 방법은,상기 제1 분류 맵(2000)을 획득하는 단계 이후에,기 설정된 제2 기준 확률 값과 상기 복수의 화소 영상들 중 상기 분류된 객체 영역(2100)에 포함된 적어도 하나의 화소 영상이 상기 객체에 대응될 확률 값을 비교한 결과에 기초하여 상기 객체 영역(2100)에 포함된 상기 노이즈 영역(2300)을 분류하는 단계를 더 포함하고,상기 제1 기준 확률 값과 상기 제2 기준 확률 값은 상이한 확률 값인 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서,상기 객체 영상(5000)을 획득하는 단계(S500)에서,상기 제1 보정 계수, 상기 제2 보정 계수 및 상기 노이즈 영역(2300)에 포함된 적어도 하나의 화소 영상이 상기 객체에 대응될 확률 값에 기초하여 계산되는 제3 보정 계수를 이용하여, 상기 제1 분류 맵(2000) 및 상기 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>19. 제18 항에 있어서,상기 제3 보정 계수는, 상기 노이즈 영역(2300)에 포함된 적어도 하나의 복수 영상이 상기 객체에 대응될 확률 값과 반비례하며,상기 객체 영상(5000)을 획득하는 단계(S500)에서,상기 제3 보정 계수가 곱해진 상기 제2 분류 맵(3000)에 기초하여 상기 객체 영상(5000)을 획득하는 전자 장치(100)의 동작 방법.</claim></claimInfo><claimInfo><claim>20. 제11 항 내지 제19항 중 어느 하나의 항에 기재된 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEONG, Soon Mook</engName><name>정순묵</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.09.27</receiptDate><receiptNumber>1-1-2022-1019532-98</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.09.26</receiptDate><receiptNumber>1-1-2025-1105000-75</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220122873.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d9390fc1cb849a046c36bfc031cb93148274c638b36f3b9c4d87110a988716a54f624c147d61339a3ae666ab1a467b59ed7dcc4f1a16a140</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf855d0303a897ae5e1043fa7a7d51896db6803d1dce65463bfdc467cba2d1b6af5eb5e7209537a59a80856357b5bdb08a076f6979a1b6c49c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>