<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:32.532</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0124697</applicationNumber><claimCount>13</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이중 어텐션을 이용한 이미지 세그멘테이션 방법 및 이를 이용한 장치</inventionTitle><inventionTitleEng>IMAGE SEGMENTATION METHOD USING DUAL ATTENTION AND  DEVICE USING THE SAME</inventionTitleEng><openDate>2025.03.26</openDate><openNumber>10-2025-0041823</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.09.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본원 발명의 이미지 세그멘테이션 방법은 입력 데이터로부터 공간 어텐션을 추출하는 단계; 상기 입력 데이터로부터 채널 어텐션을 추출하는 단계; 상기 공간 어텐션 및 상기 채널 어텐션에 기초하여 머징 데이터를 생성하는 단계; 및 상기 머징 데이터에 기초하여 구성 요소별 인덱스를 포함하는 결과 데이터를 획득하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나 이상의 프로세서에 의해 수행되는 이미지 세그멘테이션 방법에 있어서,입력 데이터로부터 공간 어텐션을 추출하는 단계;상기 입력 데이터로부터 채널 어텐션을 추출하는 단계;상기 공간 어텐션 및 상기 채널 어텐션에 기초하여 머징 데이터를 생성하는 단계; 및상기 머징 데이터에 기초하여 구성 요소별 인덱스를 포함하는 결과 데이터를 획득하는 단계를 포함하는이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 공간 어텐션은 구성 요소와 관련된 형태 정보를 포함하고,상기 채널 어텐션은 구성 요소와 관련된 문맥 정보를 포함하는이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 공간 어텐션을 추출하는 단계는 스윈 트랜스포머(swin transformer)를 이용하는 단계인이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 공간 어텐션을 추출하는 단계는,상기 입력 데이터에 의해 생성된 제1 크기의 패치 및 제1 값의 채널 개수에 기초하여 제1 공간 어텐션을 추출하는 단계; 및상기 입력 데이터에 의해 생성된 제2 크기의 패치 및 제2 값의 채널 개수에 기초하여 제2 공간 어텐션을 추출하는 단계를 포함하고,상기 제2 크기는 상기 제1 크기보다 크고, 상기 제1 값은 상기 제2 값보다 작은이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 채널 어텐션을 추출하는 단계는,제1 크기의 패치 및 제1 값의 채널 개수에 기초하여 제1 채널 어텐션을 추출하는 단계; 및제2 크기의 패치 및 제2 값의 채널 개수에 기초하여 제2 채널 어텐션을 추출하는 단계를 포함하는이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 머징 데이터를 생성하는 단계는,제1 공간 어텐션, 제1 채널 어텐션, 제2 공간 어텐션 및 제2 채널 어텐션에 기초하여 제1 바텀업 데이터를 생성하는 단계; 및상기 제1 바텀업 데이터, 제3 공간 어텐션 및 제3 채널 어텐션에 기초하여 제2 바텀업 데이터를 생성하는 단계를 포함하는이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 머징 데이터를 생성하는 단계는,상기 제1 바텀업 데이터 상기 제2 바텀업 데이터, 상기 제2 공간 어텐션 및 상기 제2 채널 어텐션에 기초하여 제1 탑다운 데이터를 생성하는 단계; 및상기 제1 탑다운 데이터, 상기 제1 공간 어텐션 및 상기 제1 채널 어텐션에 기초하여 제2 탑다운 데이터를 생성하는 단계를 포함하는이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 결과 데이터를 획득하는 단계는,상기 머징 데이터에 의해 생성된 제3 크기의 패치 및 제3 값의 채널 개수에 기초하여 제1 디코딩 데이터를 생성하는 단계; 및상기 머징 데이터에 의해 생성된 제4 크기의 패치 및 제4 값의 채널 개수에 기초하여 제2 디코딩 데이터를 생성하는 단계를 포함하고,상기 제4 크기는 상기 제3 크기보다 작고, 상기 제3 값은 상기 제4 값보다 큰이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 결과 데이터를 획득하는 단계는,상기 제1 디코딩 데이터 및 상기 제2 디코딩 데이터에 기초하여 제1 픽셀에 제1 구성 요소에 대응되는 제1 인덱스를 설정하는 단계;상기 제1 디코딩 데이터 및 상기 제2 디코딩 데이터에 기초하여 제2 픽셀에 제2 구성 요소에 대응되는 제2 인덱스를 설정하는 단계; 및상기 제1 인덱스가 설정된 픽셀을 포함하는 제1 영역과 상기 제2 인덱스가 설정된 픽셀을 포함하는 제2 영역을 설정하는 단계를 포함하는이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 제1 디코딩 데이터를 생성하는 단계 및 상기 제2 디코딩 데이터를 생성하는 단계는 스윈 트랜스포머(swin transformer)를 이용하는 단계인이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제5항 중 어느 한 항에 기재된 이미지 세그멘테이션 방법을 실행시키도록 컴퓨터로 판독 가능한 기록 매체에 기록된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 전자 장치에 있어서,메모리; 및적어도 하나 이상의 프로세서를 포함하고,상기 메모리는, 상기 적어도 하나 이상의 프로세서에 의해 실행 시, 상기 전자 장치가,입력 데이터로부터 추출된 공간 어텐션을 저장하고,상기 입력 데이터로부터 추출된 채널 어텐션을 저장하고,상기 공간 어텐션 및 상기 채널 어텐션에 기초하여 생성된 머징 데이터를 저장하고,상기 머징 데이터에 기초하여 획득된 구성 요소별 인덱스를 포함하는 결과 데이터를 저장하는전자 장치.</claim></claimInfo><claimInfo><claim>13. 입력 데이터로부터 공간 어텐션 및 채널 어텐션을 추출하는 인코딩부;상기 공간 어텐션 및 상기 채널 어텐션에 기초하여 머징 데이터를 생성하는 머징부; 및상기 머징 데이터에 기초하여 구성 요소별 인덱스를 포함하는 결과 데이터를 생성하는 디코딩부를 포함하는이미지 세그멘테이션 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220050095099</code><country>대한민국</country><engName>UIF (University Industry Foundation), Yonsei University</engName><name>연세대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 양천구...</address><code> </code><country> </country><engName>SANGHYUN PARK</engName><name>박상현</name></inventorInfo><inventorInfo><address>서울특별시 양천구...</address><code> </code><country> </country><engName>SEUNGKYUN HONG</engName><name>홍승균</name></inventorInfo><inventorInfo><address>인천광역시 부평구...</address><code> </code><country> </country><engName>SUNGHYUN AHN</engName><name>안성현</name></inventorInfo><inventorInfo><address>광주광역시 북구...</address><code> </code><country> </country><engName>YOUNGWAN JO</engName><name>조영완</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 강남대로 *** 강남메인타워 *층</address><code>920231000412</code><country>대한민국</country><engName>SIGONG IP&amp;Law Firm</engName><name>특허법인시공</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.09.19</receiptDate><receiptNumber>1-1-2023-1036410-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2023.10.20</receiptDate><receiptNumber>1-1-2023-1151915-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.10.20</receiptDate><receiptNumber>1-1-2023-1152005-14</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230124697.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bccf965a46962de1ef5a292d00e98f4c0674005e1032b5bde5063a11e7ede3a2610ae2437697c480db7d8a342abf340c5716d5ec8f66d077</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cffd25916476482613e75e99cad2a3535038f379edb96ffc55dd9e2cd36c4ee32b4566171b2aee6fb85ff02ce5e49c0e2857f9397fecf0621b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>