<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:38.4038</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.01.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7023991</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>멀티-뷰 정세화를 사용한 3차원 모델들의 향상</inventionTitle><inventionTitleEng>ENHANCING THREE-DIMENSIONAL MODELS USING MULTI-VIEW REFINEMENT</inventionTitleEng><openDate>2023.09.19</openDate><openNumber>10-2023-0133293</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.01.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.07.13</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 멀티-뷰 이미지 데이터를 사용하여 3차원 (3D) 메쉬들을 모델링하기 위한 시스템들 및 기법들이 제공된다. 예시적인 방법은, 타겟의 제 1 이미지에 기초하여, 제 1 좌표 프레임에 대응하는 타겟에 대한 제 1 3D 메쉬 파라미터들을 결정하는 단계; 타겟의 제 2 이미지에 기초하여, 제 2 좌표 프레임에 대응하는 타겟에 대한 제 2 3D 메쉬 파라미터들을 결정하는 단계; 제 3 좌표 프레임에서 타겟에 대한 제 3 3D 메쉬 파라미터들을 결정하는 단계로서, 제 3 3D 메쉬 파라미터들은 제 1 및 제 2 3D 메쉬 파라미터들 및 제 1 및 제 2 이미지들을 캡처한 이미지 센서들의 상대적 회전 및 병진 파라미터들에 기초하는, 상기 제 3 3D 메쉬 파라미터들을 결정하는 단계; 제 3 3D 메쉬 파라미터들과 연관된 손실을 결정하는 단계로서, 그 손실은 제 1 및 제 2 3D 메쉬 파라미터들 및 상대적 회전 및 병진 파라미터들에 기초하는, 상기 손실을 결정하는 단계; 및 손실 및 제 3 3D 메쉬 파라미터들에 기초하여 3D 메쉬 파라미터들을 결정하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.07.28</internationOpenDate><internationOpenNumber>WO2022159942</internationOpenNumber><internationalApplicationDate>2022.01.18</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/070237</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 장치로서,메모리; 및상기 메모리에 커플링된 하나 이상의 프로세서들을 포함하고,상기 하나 이상의 프로세서들은,타겟의 제 1 이미지에 기초하여, 상기 타겟에 대한 제 1 3차원 (3D) 메쉬 파라미터들을 결정하는 것으로서, 상기 제 1 3D 메쉬 파라미터들은 상기 제 1 이미지와 연관된 제 1 좌표 레퍼런스 프레임에 대응하는, 상기 제 1 3D 메쉬 파라미터들을 결정하고;상기 타겟의 제 2 이미지에 기초하여, 상기 타겟에 대한 제 2 3D 메쉬 파라미터들을 결정하는 것으로서, 상기 제 2 3D 메쉬 파라미터들은 상기 제 2 이미지와 연관된 제 2 좌표 레퍼런스 프레임에 대응하는, 상기 제 2 3D 메쉬 파라미터들을 결정하고;제 3 좌표 레퍼런스 프레임에서 상기 타겟에 대한 제 3 3D 메쉬 파라미터들을 결정하는 것으로서, 상기 제 3 3D 메쉬 파라미터들은 상기 제 1 3D 메쉬 파라미터들, 상기 제 2 3D 메쉬 파라미터들, 및 상기 제 1 이미지를 캡처한 제 1 이미지 센서 및 상기 제 2 이미지를 캡처한 제 2 이미지 센서의 상대적 회전 및 병진 파라미터들에 기초하는, 상기 제 3 3D 메쉬 파라미터들을 결정하고; 그리고상기 제 3 3D 메쉬 파라미터들 및 상기 제 3 3D 메쉬 파라미터들과 연관된 하나 이상의 손실들에 기초하여 조정된 3D 메쉬 파라미터들을 생성하는 것으로서, 상기 조정된 3D 메쉬 파라미터들은 상기 제 3 3D 메쉬 파라미터들에 대한 하나 이상의 조정들을 포함하는, 상기 조정된 3D 메쉬 파라미터들을 생성하도록구성되는, 장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제 1 좌표 레퍼런스 프레임은 제 1 루트-상대적 프레임을 포함하고, 상기 제 2 좌표 레퍼런스 프레임은 제 2 루트-상대적 프레임을 포함하고, 상기 제 3 좌표 레퍼런스 프레임은 상기 제 1 이미지 및 상기 제 2 이미지와 연관된 장면에서 실세계 좌표 프레임을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 제 3 3D 메쉬 파라미터들을 결정하기 위해, 상기 하나 이상의 프로세서들은,상기 제 1 루트-상대적 프레임 및 상기 제 2 루트-상대적 프레임에서의 3D 좌표들을 상기 실세계 좌표 프레임에서의 3D 좌표들로 컨버팅하고; 그리고상기 실세계 좌표 프레임에서의 3D 좌표들에 기초하여 상기 제 3 3D 메쉬 파라미터들을 결정하도록구성되고, 상기 제 3 3D 메쉬 파라미터들은 상기 실세계 좌표 프레임에서 상기 타겟을 모델링하는, 장치.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 제 1 루트-상대적 프레임 및 상기 제 2 루트-상대적 프레임에서의 3D 좌표들은 상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들과 연관된 심도 정보 및 상기 상대적 회전 및 병진 파라미터들에 기초하여 상기 실세계 좌표 프레임에서의 3D 좌표들로 컨버팅되는, 장치.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들을 결정하기 위해, 상기 하나 이상의 프로세서들은,상기 제 1 이미지에서의 상기 타겟의 제 1 루트-상대적 포즈 및 상기 제 2 이미지에서의 상기 타겟의 제 2 루트-상대적 포즈를 결정하도록 구성되고,상기 제 1 3D 메쉬 파라미터들은 상기 제 1 루트-상대적 포즈를 포함하고, 상기 제 2 3D 메쉬 파라미터들은 상기 제 2 루트-상대적 포즈를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>6. 제 1 항에 있어서,상기 하나 이상의 프로세서들은,상기 제 3 3D 메쉬 파라미터들을 상기 제 1 좌표 레퍼런스 프레임 및 상기 제 2 좌표 레퍼런스 프레임으로 변환하고; 그리고상기 제 3 3D 메쉬 파라미터들을, 상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들과 연관된 루트-상대적 좌표들과 정렬시키도록구성되는, 장치.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,상기 제 3 3D 메쉬 파라미터들은, 상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들과 연관된 루트-상대적 추정치들과 연관된 루트의 심도를 감산함으로써 상기 루트-상대적 좌표들과 정렬되는, 장치.</claim></claimInfo><claimInfo><claim>8. 제 6 항에 있어서,상기 하나 이상의 프로세서들은,제 2 3D 메쉬 및 제 3 3D 메쉬에 기초하여 상기 하나 이상의 손실들을 결정하도록 구성되고,상기 하나 이상의 손실들은 상기 제 2 3D 메쉬와 상기 제 3 3D 메쉬 사이의 손실을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서,상기 하나 이상의 손실들은 최소 제곱 에러 함수에 기초하여 계산되고,상기 조정된 3D 메쉬 파라미터들을 결정하기 위해, 상기 하나 이상의 프로세서들은 상기 최소 제곱 에러 함수에 기초하여 상기 제 3 3D 메쉬 파라미터들에서의 에러를 최소화하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>10. 제 1 항에 있어서,상기 하나 이상의 손실들을 결정하기 위해, 상기 하나 이상의 프로세서들은,상기 제 3 3D 메쉬 파라미터들 및 상기 상대적 회전 및 병진 파라미터들에 기초하여, 상기 제 1 좌표 레퍼런스 프레임에서의 제 1 3D 메쉬 및 상기 제 2 좌표 레퍼런스 프레임에서의 제 2 3D 메쉬를 생성하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서,상기 하나 이상의 프로세서들은 상기 조정된 3D 메쉬 파라미터들에 기초하여 3D 메쉬 모델을 생성하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 타겟은 관절형 오브젝트를 포함하고, 상기 3D 메쉬 모델은 스킨형 모델을 포함하며, 상기 제 1 이미지 및 상기 제 2 이미지는 단안 이미지들을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>13. 제 1 항에 있어서,상기 장치는 카메라 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>14. 제 1 항에 있어서,상기 장치는 모바일 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>15. 제 1 항에 있어서,상기 제 3 3D 메쉬 파라미터들과 연관된 상기 하나 이상의 손실들은 상기 제 1 3D 메쉬 파라미터들, 상기 제 2 3D 메쉬 파라미터들, 및 상기 상대적 회전 및 병진 파라미터들에 기초하여 결정되는, 장치.</claim></claimInfo><claimInfo><claim>16. 방법으로서,타겟의 제 1 이미지에 기초하여, 상기 타겟에 대한 제 1 3차원 (3D) 메쉬 파라미터들을 결정하는 단계로서, 상기 제 1 3D 메쉬 파라미터들은 상기 제 1 이미지와 연관된 제 1 좌표 레퍼런스 프레임에 대응하는, 상기 제 1 3D 메쉬 파라미터들을 결정하는 단계;상기 타겟의 제 2 이미지에 기초하여, 상기 타겟에 대한 제 2 3D 메쉬 파라미터들을 결정하는 단계로서, 상기 제 2 3D 메쉬 파라미터들은 상기 제 2 이미지와 연관된 제 2 좌표 레퍼런스 프레임에 대응하는, 상기 제 2 3D 메쉬 파라미터들을 결정하는 단계;제 3 좌표 레퍼런스 프레임에서 상기 타겟에 대한 제 3 3D 메쉬 파라미터들을 결정하는 단계로서, 상기 제 3 3D 메쉬 파라미터들은 상기 제 1 3D 메쉬 파라미터들, 상기 제 2 3D 메쉬 파라미터들, 및 상기 제 1 이미지를 캡처한 제 1 이미지 센서 및 상기 제 2 이미지를 캡처한 제 2 이미지 센서의 상대적 회전 및 병진 파라미터들에 기초하는, 상기 제 3 3D 메쉬 파라미터들을 결정하는 단계;상기 제 3 3D 메쉬 파라미터들과 연관된 하나 이상의 손실들을 결정하는 단계로서, 상기 하나 이상의 손실들은 상기 제 1 3D 메쉬 파라미터들, 상기 제 2 3D 메쉬 파라미터들, 및 상기 상대적 회전 및 병진 파라미터들에 기초하는, 상기 하나 이상의 손실들을 결정하는 단계; 및상기 제 3 3D 메쉬 파라미터들 및 상기 제 3 3D 메쉬 파라미터들과 연관된 하나 이상의 손실들에 기초하여 조정된 3D 메쉬 파라미터들을 생성하는 단계로서, 상기 조정된 3D 메쉬 파라미터들은 상기 제 3 3D 메쉬 파라미터들에 대한 하나 이상의 조정들을 포함하는, 상기 조정된 3D 메쉬 파라미터들을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서,상기 제 1 좌표 레퍼런스 프레임은 제 1 루트-상대적 프레임을 포함하고, 상기 제 2 좌표 레퍼런스 프레임은 제 2 루트-상대적 프레임을 포함하고, 상기 제 3 좌표 레퍼런스 프레임은 상기 제 1 이미지 및 상기 제 2 이미지와 연관된 장면에서 실세계 좌표 프레임을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,상기 제 3 3D 메쉬 파라미터들을 결정하기 위해, 하나 이상의 프로세서들은,상기 제 1 루트-상대적 프레임 및 상기 제 2 루트-상대적 프레임에서의 3D 좌표들을 상기 실세계 좌표 프레임에서의 3D 좌표들로 컨버팅하고; 그리고상기 실세계 좌표 프레임에서의 3D 좌표들에 기초하여 상기 제 3 3D 메쉬 파라미터들을 결정하도록구성되고, 상기 제 3 3D 메쉬 파라미터들은 상기 실세계 좌표 프레임에서 상기 타겟을 모델링하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서,상기 제 1 루트-상대적 프레임 및 상기 제 2 루트-상대적 프레임에서의 3D 좌표들은 상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들과 연관된 심도 정보 및 상기 상대적 회전 및 병진 파라미터들에 기초하여 상기 실세계 좌표 프레임에서의 3D 좌표들로 컨버팅되는, 방법.</claim></claimInfo><claimInfo><claim>20. 제 16 항에 있어서,상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들을 결정하기 위해, 하나 이상의 프로세서들은,상기 제 1 이미지에서의 상기 타겟의 제 1 루트-상대적 포즈 및 상기 제 2 이미지에서의 상기 타겟의 제 2 루트-상대적 포즈를 결정하도록 구성되고,상기 제 1 3D 메쉬 파라미터들은 상기 제 1 루트-상대적 포즈를 포함하고, 상기 제 2 3D 메쉬 파라미터들은 상기 제 2 루트-상대적 포즈를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제 16 항에 있어서,하나 이상의 프로세서들은,상기 제 3 3D 메쉬 파라미터들을 상기 제 1 좌표 레퍼런스 프레임 및 상기 제 2 좌표 레퍼런스 프레임으로 변환하고; 그리고상기 제 3 3D 메쉬 파라미터들을, 상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들과 연관된 루트-상대적 좌표들과 정렬시키도록구성되는, 방법.</claim></claimInfo><claimInfo><claim>22. 제 21 항에 있어서,상기 제 3 3D 메쉬 파라미터들은, 상기 제 1 3D 메쉬 파라미터들 및 상기 제 2 3D 메쉬 파라미터들과 연관된 루트-상대적 추정치들과 연관된 루트의 심도를 감산함으로써 상기 루트-상대적 좌표들과 정렬되는, 방법.</claim></claimInfo><claimInfo><claim>23. 제 21 항에 있어서,하나 이상의 프로세서들은,제 2 3D 메쉬 및 제 3 3D 메쉬에 기초하여 상기 하나 이상의 손실들을 결정하도록 구성되고,상기 하나 이상의 손실들은 상기 제 2 3D 메쉬와 상기 제 3 3D 메쉬 사이의 손실을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 제 16 항에 있어서,상기 하나 이상의 손실들은 최소 제곱 에러 함수에 기초하여 계산되고,상기 조정된 3D 메쉬 파라미터들을 결정하기 위해, 하나 이상의 프로세서들은 상기 최소 제곱 에러 함수에 기초하여 상기 제 3 3D 메쉬 파라미터들에서의 에러를 최소화하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>25. 제 16 항에 있어서,상기 하나 이상의 손실들을 결정하기 위해, 하나 이상의 프로세서들은,상기 제 3 3D 메쉬 파라미터들 및 상기 상대적 회전 및 병진 파라미터들에 기초하여, 상기 제 1 좌표 레퍼런스 프레임에서의 제 1 3D 메쉬 및 상기 제 2 좌표 레퍼런스 프레임에서의 제 2 3D 메쉬를 생성하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>26. 제 16 항에 있어서,하나 이상의 프로세서들은 상기 조정된 3D 메쉬 파라미터들에 기초하여 3D 메쉬 모델을 생성하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>27. 제 26 항에 있어서,상기 타겟은 관절형 오브젝트를 포함하고, 상기 3D 메쉬 모델은 스킨형 모델을 포함하며, 상기 제 1 이미지 및 상기 제 2 이미지는 단안 이미지들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제 16 항에 있어서,상기 제 3 3D 메쉬 파라미터들과 연관된 상기 하나 이상의 손실들은 상기 제 1 3D 메쉬 파라미터들, 상기 제 2 3D 메쉬 파라미터들, 및 상기 상대적 회전 및 병진 파라미터들에 기초하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>29. 명령들이 저장된 비일시적 컴퓨터 판독가능 저장 매체로서,상기 명령들은, 하나 이상의 프로세서들에 의해 실행될 경우, 상기 하나 이상의 프로세서들로 하여금:타겟의 제 1 이미지에 기초하여, 상기 타겟에 대한 제 1 3차원 (3D) 메쉬 파라미터들을 결정하게 하는 것으로서, 상기 제 1 3D 메쉬 파라미터들은 상기 제 1 이미지와 연관된 제 1 좌표 레퍼런스 프레임에 대응하는, 상기 제 1 3D 메쉬 파라미터들을 결정하게 하고;상기 타겟의 제 2 이미지에 기초하여, 상기 타겟에 대한 제 2 3D 메쉬 파라미터들을 결정하게 하는 것으로서, 상기 제 2 3D 메쉬 파라미터들은 상기 제 2 이미지와 연관된 제 2 좌표 레퍼런스 프레임에 대응하는, 상기 제 2 3D 메쉬 파라미터들을 결정하게 하고;제 3 좌표 레퍼런스 프레임에서 상기 타겟에 대한 제 3 3D 메쉬 파라미터들을 결정하게 하는 것으로서, 상기 제 3 3D 메쉬 파라미터들은 상기 제 1 3D 메쉬 파라미터들, 상기 제 2 3D 메쉬 파라미터들, 및 상기 제 1 이미지를 캡처한 제 1 이미지 센서 및 상기 제 2 이미지를 캡처한 제 2 이미지 센서의 상대적 회전 및 병진 파라미터들에 기초하는, 상기 제 3 3D 메쉬 파라미터들을 결정하게 하고; 그리고상기 제 3 3D 메쉬 파라미터들 및 상기 제 3 3D 메쉬 파라미터들과 연관된 하나 이상의 손실들에 기초하여 조정된 3D 메쉬 파라미터들을 생성하게 하는 것으로서, 상기 조정된 3D 메쉬 파라미터들은 상기 제 3 3D 메쉬 파라미터들에 대한 하나 이상의 조정들을 포함하는, 상기 조정된 3D 메쉬 파라미터들을 생성하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>30. 제 29 항에 있어서,상기 제 1 좌표 레퍼런스 프레임은 제 1 루트-상대적 프레임을 포함하고, 상기 제 2 좌표 레퍼런스 프레임은 제 2 루트-상대적 프레임을 포함하고, 상기 제 3 좌표 레퍼런스 프레임은 상기 제 1 이미지 및 상기 제 2 이미지와 연관된 장면에서 실세계 좌표 프레임을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ALI, ASHAR</engName><name>알리 아샤르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>DANE, GOKCE</engName><name>데인 고케</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>REITMAYR, GERHARD</engName><name>라이트마이어 게르하르트</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.01.20</priorityApplicationDate><priorityApplicationNumber>17/153,773</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.07.13</receiptDate><receiptNumber>1-1-2023-0773719-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.08.22</receiptDate><receiptNumber>1-5-2023-0134183-70</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.01.02</receiptDate><receiptNumber>1-1-2025-0000855-76</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.01.02</receiptDate><receiptNumber>1-1-2025-0000856-11</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237023991.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9385a8eb56bf292fb664d27a24734d157caba692c84186fcff3a9d00896633db04785e7978c09293f82a744c358244841584be0c707e2765f8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf837aba7ed4929e88dc6b2a7ea1b07c6252857ac948c13011d9c7a4b6a402226ef0da0a963390c8ffe43a737a7dce5df63a1f140ba7d1e9b2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>