<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:54:44.5444</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.06.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0069397</applicationNumber><claimCount>8</claimCount><examinerName> </examinerName><finalDisposal>거절결정 후 재심사중</finalDisposal><inventionTitle>딥러닝 기반의 행동 인식 시스템 및 그 방법</inventionTitle><inventionTitleEng>ACTION RECOGNITION SYSTEM BASED ON DEEP LEARNING AND  THE METHOD THEREOF</inventionTitleEng><openDate>2023.02.03</openDate><openNumber>10-2023-0017126</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.06.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 일 실시예에 따른 딥러닝 기반의 행동 인식 시스템은, 비디오 영상의 데이터 세트에서 중첩 동작 클래스를 그룹화하고, 각 비디오 영상에서 프레임을 추출하여 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에 맞는 프레임 사이즈로 조정하여 사전 학습하는 데이터 전처리부; 상기 데이터 전처리부에서 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에 추가적인 데이터 세트를 적용하여 학습 및 미세 조정하는 전이 학습부; 상기 전이 학습부에서 미세 조정된 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 학습 모델을 적용하여 시각적 데이터 스트림에서 프레임 수준 공간 정보를 학습하여 고차원 심층 특징을 추출하는 심층 특징 추출부; 상기 심층 특징 추출부에서 추출된 고차원 심층 특징을 저차원 특징 맵으로 압축하는 인코더부; 및 상기 인코더부에서 압축된 특징 맵에서 시간 정보를 학습하고 이전 학습된 모델에 새로운 비디오 영상 데이터의 변경 부분을 적용하여 반복적으로 미세 조정하여 학습하는 조정 모듈부를 포함하는 점에 그 특징이 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 영상의 데이터 세트에서 중첩 동작 클래스를 그룹화하고, 각 비디오 영상에서 프레임을 추출하여 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에 맞는 프레임 사이즈로 조정하여 사전 학습하는 데이터 전처리부; 상기 데이터 전처리부에서 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에 추가적인 데이터 세트를 적용하여 학습 및 미세 조정하는 전이 학습부; 상기 전이 학습부에서 미세 조정된 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 학습 모델을 적용하여 시각적 데이터 스트림에서 프레임 수준 공간 정보를 학습하여 고차원 심층 특징을 추출하는 심층 특징 추출부;상기 심층 특징 추출부에서 추출된 고차원 심층 특징을 저차원 특징 맵으로 압축하는 인코더부; 및상기 인코더부에서 압축된 특징 맵에서 시간 정보를 학습하고 이전 학습된 모델에 새로운 비디오 영상 데이터의 변경 부분을 적용하여 반복적으로 미세 조정하여 학습하는 조정 모듈부를 포함하는 딥러닝 기반의 행동 인식 시스템. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 딥 러닝 파이프 라인(DLPL) CNN 학습 모델은 DenseNet201, InceptionV3, ResNet101V2, ResNet152V2, VGG16, VGG19 및 Xception를 포함하고, 이들 중 어느 하나의 사전 훈련된 CNN 학습 모델을 이용하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 전이 학습부는 상기 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 모델의 마지막 분류 계층을 제거하고 새 데이터 세트에 대해 새로운 계층을 추가하여 학습 및 미세 조정하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 심층 특징 추출부는 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에서 마지막 완전 연결 계층(FCL)을 제거하고 일부 추가 계층을 추가하여 데이터 세트에 대해 시각적 데이터 스트림에서 공간 패턴과 관계를 학습하고, 마지막으로 완전히 연결된 SoftMax 계층 이전의 출력을 다음 네트워크에 제공하여 심층 특징을 추출하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 인코더부는 오토 인코더(Deep Autoencoder)를 이용하여 입력 데이터에 대한 최소 표현을 학습하고, 원래 입력 데이터에 가장 가까운 출력으로 재구성하여 저차원 특징 맵으로 출력하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 시스템. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 조정 모듈부는 장기 시간적 맥락을 학습하기 위해 LSTM(Long Short-Term Memory) 및 RNN(Recurrent Neural Network)을 이용하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 시스템. </claim></claimInfo><claimInfo><claim>7. 비디오 영상의 데이터 세트에서 중첩 동작 클래스를 그룹화하고, 각 비디오 영상에서 프레임을 추출하여 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에 맞는 프레임 사이즈로 조정하여 사전 학습하는 단계; 상기 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에 추가적인 데이터 세트를 적용하여 전이 학습 및 미세 조정하는 단계; 상기 미세 조정된 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 학습 모델을 적용하여 시각적 데이터 스트림에서 프레임 수준 공간 정보를 학습하여 고차원 심층 특징을 추출하는 단계;상기 심층 특징 추출부에서 추출된 고차원 심층 특징을 저차원 특징 맵으로 압축하는 단계; 및상기 압축된 특징 맵에서 시간 정보를 학습하고 이전 학습된 모델에 새로운 비디오 영상 데이터의 변경 부분을 적용하여 반복적으로 미세 조정하여 학습하는 단계를 포함하는 딥러닝 기반의 행동 인식 방법. </claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 딥 러닝 파이프 라인(DLPL) CNN 학습 모델은 DenseNet201, InceptionV3, ResNet101V2, ResNet152V2, VGG16, VGG19 및 Xception를 포함하고, 이들 중 어느 하나의 사전 훈련된 CNN 학습 모델을 이용하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 전이 학습 및 미세 조정하는 단계에서 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 모델의 마지막 분류 계층을 제거하고 새 데이터 세트에 대해 새로운 계층을 추가하여 학습 및 미세 조정하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 방법.</claim></claimInfo><claimInfo><claim>10. 제7항에 있어서,상기 심층 특징을 추출하는 단계 상기 사전 학습된 딥 러닝 파이프 라인(DLPL) CNN 학습 모델에서 마지막 완전 연결 계층(FCL)을 제거하고 일부 추가 계층을 추가하여 데이터 세트에 대해 시각적 데이터 스트림에서 공간 패턴과 관계를 학습하고, 마지막으로 완전히 연결된 SoftMax 계층 이전의 출력을 다음 네트워크에 제공하여 심층 특징을 추출하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 방법.</claim></claimInfo><claimInfo><claim>11. 제7항에 있어서,상기 저차원 특징 맵으로 압축하는 단계에서 오토 인코더(Deep Autoencoder)를 이용하여 입력 데이터에 대한 최소 표현을 학습하고, 원래 입력 데이터에 가장 가까운 출력으로 재구성하여 저차원 특징 맵으로 출력하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 방법. </claim></claimInfo><claimInfo><claim>12. 제7항에 있어서, 상기 미세 조정하여 학습하는 단계에서 장기 시간적 맥락을 학습하기 위해 LSTM(Long Short-Term Memory) 및 RNN(Recurrent Neural Network)을 이용하는 것을 특징으로 하는 딥러닝 기반의 행동 인식 방법. </claim></claimInfo><claimInfo><claim>13. 제 7 항 내지 제 12 항 중 어느 한 항에 기재된 방법을 컴퓨터 상에서 수행하기 위한 프로그램을 기록한 컴퓨터 판독 가능한 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 동작구...</address><code>220040385305</code><country>대한민국</country><engName>CHUNG ANG University Industry Academic Cooperation Foundation</engName><name>중앙대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>RHO, SEUNGMIN</engName><name>노승민</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>muhammad bilal</engName><name>무하마드 빌랄</name></inventorInfo><inventorInfo><address>파키스탄 이슬라마바드 수도 ...</address><code> </code><country> </country><engName>muazzam maqsood</engName><name>무아잠 맥수드</name></inventorInfo><inventorInfo><address>파키스탄 이슬라마바드 수도 ...</address><code> </code><country> </country><engName>sadaf yasmin</engName><name>사다프 야스민</name></inventorInfo><inventorInfo><address>오만...</address><code> </code><country> </country><engName>najam ui hasan</engName><name>나잠 하산</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서대문구 경기대로 **,  진양빌딩 *층(충정로*가)</address><code>920191001412</code><country>대한민국</country><engName>WeThePeople IP &amp; Law Firm</engName><name>특허법인위더피플</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2021.07.26</priorityApplicationDate><priorityApplicationNumber>1020210097999</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.06.08</receiptDate><receiptNumber>1-1-2022-0596908-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.05.31</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2024.06.27</receiptDate><receiptNumber>9-6-2024-0142876-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.08.07</receiptDate><receiptNumber>4-1-2024-5236660-34</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2024.08.30</receiptDate><receiptNumber>9-5-2024-0733745-56</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2024.10.30</receiptDate><receiptNumber>1-1-2024-1185073-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.10.30</receiptDate><receiptNumber>1-1-2024-1185074-51</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.05.15</receiptDate><receiptNumber>4-1-2025-5130684-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Decision to Refuse a Patent</documentEngName><documentName>거절결정서</documentName><receiptDate>2025.05.29</receiptDate><receiptNumber>9-5-2025-0514252-68</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.08.12</receiptDate><receiptNumber>1-1-2025-0916583-36</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Amendment to Description, etc(Reexamination)</documentEngName><documentName>[명세서등 보정]보정서(재심사)</documentName><receiptDate>2025.08.12</receiptDate><receiptNumber>1-1-2025-0916584-82</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220069397.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9333ee2bfa2b447a72059cb307a85db80ba7a1f2150fca86f2e78c1ff5086877b7fd4dbc89287417656c797e685e9086641764511e7972c112</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4457c72566b40b7cea240780d068a8325aaea17985134e2bdff071cd632d5ef7065161bcc5ac46e97a33a74ea6ce9d6fa8b07012e3d97f54</path></imagePathInfo><rndInfoArray><rndInfo><rndDepartmentName>과학기술정보통신부</rndDepartmentName><rndDuration>2018.07.01 ~ 2023.12.31</rndDuration><rndManagingInstituteName>중앙대학교 산학협력단</rndManagingInstituteName><rndProjectName>대학ICT연구센터지원사업</rndProjectName><rndSpecialInstituteName>정보통신기획평가원</rndSpecialInstituteName><rndTaskContribution>1/1</rndTaskContribution><rndTaskName>2-2차)블록체인 비즈니스 서비스 기술 개발 및 인력양성</rndTaskName><rndTaskNumber>20210023</rndTaskNumber></rndInfo></rndInfoArray></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>