<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:09.409</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7022118</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>3D 손목 추적</inventionTitle><inventionTitleEng>3D WRIST TRACKING</inventionTitleEng><openDate>2025.07.24</openDate><openNumber>10-2025-0112911</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.07.02</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> AR(Augmented Reality) 애플리케이션들에서 사용하기 위한 손목 추적 프로세스가 제공된다. 컴퓨팅 시스템이 사용자의 손목의 비디오 프레임 추적 데이터를 캡처하고 이러한 비디오 프레임 추적 데이터에 기초하여 사용자의 손목의 3D 파라미터 데이터를 생성한다. 컴퓨팅 시스템은 사용자의 손목의 3D 파라미터 데이터에 기초하여 가상 아이템의 3D 렌더링 데이터를 그리고 가상 아이템에 의해 표현되는 물리적 아이템의 3D 모델 데이터를 생성한다. 컴퓨팅 시스템은 3D 렌더링 데이터 및 비디오 프레임 추적 데이터에 기초하여 비디오 프레임 AR 데이터를 생성한다. 컴퓨팅 시스템은 비디오 프레임 AR 데이터에 기초하여 사용자에게 AR 사용자 인터페이스를 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.06.13</internationOpenDate><internationOpenNumber>WO2024123684</internationOpenNumber><internationalApplicationDate>2023.12.04</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/082313</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 시스템으로서,하나 이상의 프로세서;하나 이상의 카메라; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 컴퓨팅 시스템으로 하여금 동작들을 수행하게 하고, 상기 동작들은,상기 하나 이상의 카메라를 사용하여, 사용자의 손목의 비디오 프레임 추적 데이터를 캡처하는 동작;상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 3D 파라미터 데이터를 생성하는 동작;상기 사용자의 손목의 상기 3D 파라미터 데이터에 기초하여 가상 아이템의 3D 렌더링 데이터를 그리고 상기 가상 아이템에 의해 표현되는 물리적 아이템의 3D 모델 데이터를 생성하는 동작;상기 3D 렌더링 데이터 및 상기 비디오 프레임 추적 데이터에 기초하여 AR(Augmented Reality) 사용자 인터페이스 비디오 프레임 데이터를 생성하는 동작; 및상기 비디오 프레임 AR 사용자 인터페이스 데이터에 기초하여 AR 사용자 인터페이스를 제공하는 동작을 포함하는 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 컴퓨팅 시스템은 거리 센서를 추가로 포함하고, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 컴퓨팅 시스템의 하나 이상의 거리 센서를 사용하여, 상기 사용자의 손목의 거리 데이터를 캡처하는 동작; 및상기 비디오 프레임 추적 데이터 및 상기 거리 데이터에 기초하여 상기 3D 파라미터 데이터를 생성하는 동작을 포함하는 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 시각적 특징들의 3D 좌표 데이터를 포함하는 특징 맵 데이터를 생성하는 동작; 및상기 특징 맵 데이터에 기초하여 중간 3D 파라미터 벡터 데이터를 생성하는 동작을 포함하는 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 컴퓨팅 시스템의 하나 이상의 거리 센서를 사용하여, 상기 사용자의 손목의 거리 데이터를 캡처하는 동작;상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 시각적 특징들의 2D 좌표 데이터를 포함하는 특징 맵 데이터를 생성하는 동작; 및상기 특징 맵 데이터 및 상기 거리 데이터에 기초하여 중간 3D 파라미터 벡터 데이터를 생성하는 동작을 포함하는 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 3D 파라미터 데이터에 기초하여 2D 투영 데이터를 생성하는 동작;상기 2D 투영 데이터 및 상기 사용자의 손목의 이미지에 기초하여 2D 손실 데이터를 생성하는 동작; 및상기 2D 손실 데이터에 기초하여 상기 3D 파라미터 데이터를 정정하는 동작을 포함하는 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 비디오 프레임 추적 데이터 및 합성 비디오 프레임 추적 데이터와 실제 비디오 프레임 추적 데이터의 조합을 사용하여 생성되는 3D 파라미터 모델에 기초하여 상기 사용자의 손목의 상기 3D 파라미터 데이터를 생성하는 동작을 포함하는 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 3D 파라미터 모델의 생성 동안 사용되는 손실 함수는 상기 합성 비디오 프레임 추적 데이터가 아니라 상기 실제 비디오 프레임 추적 데이터에 적용되는 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>8. 컴퓨터-구현 방법으로서,컴퓨팅 시스템의 하나 이상의 카메라를 사용하여, 사용자의 손목의 비디오 프레임 추적 데이터를 캡처하는 단계;하나 이상의 프로세서에 의해, 상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 3D 파라미터 데이터를 생성하는 단계;상기 하나 이상의 프로세서에 의해, 상기 사용자의 손목의 상기 3D 파라미터 데이터에 기초하여 가상 아이템의 3D 렌더링 데이터를 그리고 상기 가상 아이템에 의해 표현되는 물리적 아이템의 3D 모델 데이터를 생성하는 단계;상기 하나 이상의 프로세서에 의해, 상기 3D 렌더링 데이터 및 상기 비디오 프레임 추적 데이터에 기초하여 AR 사용자 인터페이스 비디오 프레임 데이터를 생성하는 단계; 및상기 하나 이상의 프로세서에 의해, 상기 컴퓨팅 시스템의 디스플레이를 사용하여, 상기 비디오 프레임 AR 사용자 인터페이스 데이터에 기초하여 상기 사용자에게 AR 사용자 인터페이스를 제공하는 단계를 포함하는 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 3D 파라미터 데이터를 생성하는 단계는 추가로,상기 컴퓨팅 시스템의 하나 이상의 거리 센서를 사용하여, 상기 사용자의 손목의 거리 데이터를 캡처하는 단계; 및상기 비디오 프레임 추적 데이터 및 상기 거리 데이터에 기초하여 상기 3D 파라미터 데이터를 생성하는 단계를 포함하는 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 3D 파라미터 데이터를 생성하는 단계는 추가로,상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 시각적 특징들의 3D 좌표 데이터를 포함하는 특징 맵 데이터를 생성하는 단계; 및상기 특징 맵 데이터에 기초하여 중간 3D 파라미터 벡터 데이터를 생성하는 단계를 포함하는 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서, 상기 3D 파라미터 데이터를 생성하는 단계는 추가로,상기 컴퓨팅 시스템의 하나 이상의 거리 센서를 사용하여, 상기 사용자의 손목의 거리 데이터를 캡처하는 단계;상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 시각적 특징들의 2D 좌표 데이터를 포함하는 특징 맵 데이터를 생성하는 단계; 및상기 특징 맵 데이터 및 상기 거리 데이터에 기초하여 중간 3D 파라미터 벡터 데이터를 생성하는 단계를 포함하는 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>12. 제8항에 있어서, 상기 3D 파라미터 데이터를 생성하는 단계는 추가로,상기 3D 파라미터 데이터에 기초하여 2D 투영 데이터를 생성하는 단계;상기 2D 투영 데이터 및 상기 사용자의 손목의 이미지에 기초하여 2D 손실 데이터를 생성하는 단계; 및상기 2D 손실 데이터에 기초하여 상기 3D 파라미터 데이터를 정정하는 단계를 포함하는 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>13. 제8항에 있어서, 상기 3D 파라미터 데이터를 생성하는 단계는 추가로,상기 비디오 프레임 추적 데이터 및 합성 비디오 프레임 추적 데이터와 실제 비디오 프레임 추적 데이터의 조합을 사용하여 생성되는 3D 파라미터 모델에 기초하여 상기 사용자의 손목의 상기 3D 파라미터 데이터를 생성하는 단계를 포함하는 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 3D 파라미터 모델의 생성 동안 사용되는 손실 함수는 상기 합성 비디오 프레임 추적 데이터가 아니라 상기 실제 비디오 프레임 추적 데이터에 적용되는 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>15. 비-일시적 컴퓨터-판독가능 저장 매체로서, 상기 컴퓨터-판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금 동작들을 수행하게 하고, 상기 동작들은,하나 이상의 카메라를 사용하여, 사용자의 손목의 비디오 프레임 추적 데이터를 캡처하는 동작;상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 3D 파라미터 데이터를 생성하는 동작;상기 사용자의 손목의 상기 3D 파라미터 데이터에 기초하여 가상 아이템의 3D 렌더링 데이터를 그리고 상기 가상 아이템에 의해 표현되는 물리적 아이템의 3D 모델 데이터를 생성하는 동작;상기 3D 렌더링 데이터 및 상기 비디오 프레임 추적 데이터에 기초하여 AR 사용자 인터페이스 비디오 프레임 데이터를 생성하는 동작; 및컴퓨팅 시스템의 디스플레이를 사용하여, 상기 비디오 프레임 AR 사용자 인터페이스 데이터에 기초하여 상기 사용자에게 AR 사용자 인터페이스를 제공하는 동작을 포함하는 컴퓨터-판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 컴퓨팅 시스템의 하나 이상의 거리 센서를 사용하여, 상기 사용자의 손목의 거리 데이터를 캡처하는 동작; 및상기 비디오 프레임 추적 데이터 및 상기 거리 데이터에 기초하여 상기 3D 파라미터 데이터를 생성하는 동작을 포함하는 컴퓨터-판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 시각적 특징들의 3D 좌표 데이터를 포함하는 특징 맵 데이터를 생성하는 동작; 및상기 특징 맵 데이터에 기초하여 중간 3D 파라미터 벡터 데이터를 생성하는 동작을 포함하는 컴퓨터-판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 컴퓨팅 시스템의 하나 이상의 거리 센서를 사용하여, 상기 사용자의 손목의 거리 데이터를 캡처하는 동작;상기 비디오 프레임 추적 데이터에 기초하여 상기 사용자의 손목의 시각적 특징들의 2D 좌표 데이터를 포함하는 특징 맵 데이터를 생성하는 동작; 및상기 특징 맵 데이터 및 상기 거리 데이터에 기초하여 중간 3D 파라미터 벡터 데이터를 생성하는 동작을 포함하는 컴퓨터-판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 3D 파라미터 데이터에 기초하여 2D 투영 데이터를 생성하는 동작;상기 2D 투영 데이터 및 상기 사용자의 손목의 이미지에 기초하여 2D 손실 데이터를 생성하는 동작; 및상기 2D 손실 데이터에 기초하여 상기 3D 파라미터 데이터를 정정하는 동작을 포함하는 컴퓨터-판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 3D 파라미터 데이터를 생성하는 동작은 추가로,상기 비디오 프레임 추적 데이터 및 합성 비디오 프레임 추적 데이터와 실제 비디오 프레임 추적 데이터의 조합을 사용하여 생성되는 3D 파라미터 모델에 기초하여 상기 사용자의 손목의 상기 3D 파라미터 데이터를 생성하는 동작을 포함하는 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>우크라이나</country><engName>FURKO, Roman</engName><name>푸르코, 로만</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>우크라이나</country><engName>HORBATIUK, Vladyslav</engName><name>호르바튜크, 블라디슬라프</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>러시아</country><engName>IAGUDIN, Amir</engName><name>이아구딘, 아미르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>미국</country><engName>SUPANCIC, James</engName><name>수판시크, 제임스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.12.05</priorityApplicationDate><priorityApplicationNumber>18/061,752</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.07.02</receiptDate><receiptNumber>1-1-2025-0744081-94</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.07.04</receiptDate><receiptNumber>1-5-2025-0112080-30</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257022118.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93dedaf8bbe799cae190f20f6fd4526b3da7205d6f788265d24957b9456a5551fb3f8cddee6061dbe4346f8b4585e1e919b81bf6285613158a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa7dc0766d6ef9add9e37f00c044df535e12f550f061f16e066685b572a9374e4bcae01923c75cc903817016c5e7d8b7d5ddbce8838019b60</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>