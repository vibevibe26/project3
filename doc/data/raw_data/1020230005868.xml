<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:09:54.954</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0005868</applicationNumber><claimCount>12</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체간 거리를 이용한 무질서 예측 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEM AND METHOD FOR PREDICTING DISORDER USING  DISTANCE BETWEEN OBJECTS</inventionTitleEng><openDate>2024.07.24</openDate><openNumber>10-2024-0114308</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.01.16</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/56</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 객체간 거리를 이용하여 무질서를 예측하는 시스템으로, 입력되는 영상 데이터를 설정된 프레임 간격으로 맥락화하여 동영상 맥락화 데이터를 생성하고, 생성된 동영상 맥락화 데이터로부터 프레임별 관심 객체에 대한 객체 정보를 추출하여 관심 객체들간의 거리에 기반하여 무질서 정도를 예측하는 시스템이다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력되는 영상 데이터에 대하여 설정된 프레임 간격으로 객체들을 검출하고, 프레임 별로 검출된 객체의 종류와 수, 객체 속성 정보, 객체의 위치 정보를 포함하는 프레임 맥락화 데이터를 생성하고, 프레임 맥락화 데이터를 결합하여 영상 데이터에 대한 동영상 맥락화 데이터를 생성하여 텍스트 파일 형태로 저장하는 동영상 맥락화부; 및동영상 맥락화 데이터로부터 프레임별 관심 객체에 대한 객체 정보를 추출하여 관심 객체들간의 거리를 계산하고, 관심 객체를 정점(vertex)으로 하고 관심 객체간 거리를 간선(edge)의 가중치로 하는 그래프를 구성한 후 최소 신장 트리를 구하고, 최소 신장 트리를 이용하여 관심 객체간 최단 거리의 표준편차를 구하고 표준편차로부터 무질서 레벨을 산출하여 무질서를 예측하는 무질서 예측부;를 포함하는, 객체간 거리를 이용한 무질서 예측 시스템.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 연속적으로 프레임별로 구한 관심 객체간 최단 거리의 표준편차를 무질서 레벨에 따라 시각화하여 표시하는 무질서 표시부를 포함하는 사용자 인터페이스부;를 더 포함하는, 객체간 거리를 이용한 무질서 예측 시스템.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 사용자 인터페이스부는 무질서 표시부가 표시한 화면에서 선택된 프레임 또는 프레임 구간의 영상을 표시 또는 재생하는 프레임 재생부;를 더 포함하는, 객체간 거리를 이용한 무질서 예측 시스템.</claim></claimInfo><claimInfo><claim>4. 제 2 항에 있어서, 사용자 인터페이스부는 무질서 표시부가 표시한 화면에서 선택된 프레임의 관심 객체를 정점으로 하는 그래프의 최소 신장 트리를 이용하여 관심 객체간 최단 거리를 표시하는 객체간 거리 표시부;를 더 포함하는, 객체간 거리를 이용한 무질서 예측 시스템.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,무질서 예측부는 관심 객체간 거리를 객체의 위치 정보로부터 구성되는 객체의 경계 상자(bounding box)의 중심 위치간 거리로 산출하는, 객체간 거리를 이용한 무질서 예측 시스템.</claim></claimInfo><claimInfo><claim>6. 제 1 항에 있어서,무질서 예측부는 관심 객체간 거리를 객체의 위치 정보로부터 구성되는 객체의 경계 상자(bounding box)간 최소 거리로 산출하는, 객체간 거리를 이용한 무질서 예측 시스템.</claim></claimInfo><claimInfo><claim>7. 하나 이상의 프로세서와, 상기 프로세서에 의해 실행 가능한 프로그램 명령어들을 저장하는 메모리를 포함하는 컴퓨팅 장치에서 수행되는 방법으로,입력되는 영상 데이터에 대하여 설정된 프레임 간격으로 객체들을 검출하는 단계;프레임 별로 검출된 객체의 종류와 수, 객체 속성 정보, 객체의 위치 정보를 포함하는 프레임 맥락화 데이터를 생성하는 단계;프레임 맥락화 데이터를 결합하여 영상 데이터에 대한 동영상 맥락화 데이터를 생성하여 텍스트 파일 형태로 저장하는 단계;프레임 맥락화 데이터로부터 프레임별 관심 객체에 대한 객체 정보를 추출하여 관심 객체들간의 거리를 계산하는 단계;관심 객체를 정점(vertex)으로 하고 관심 객체간 거리를 간선(edge)의 가중치로 하는 그래프를 구성한 후 최소 신장 트리를 구하는 단계; 및최소 신장 트리를 이용하여 관심 객체간 최단 거리의 표준편차를 구하고 표준편차로부터 무질서 레벨을 산출하여 무질서를 예측하는 단계;를 포함하는, 객체간 거리를 이용한 무질서 예측 방법.</claim></claimInfo><claimInfo><claim>8. 제 7 항에 있어서, 연속적으로 프레임별로 구한 관심 객체간 최단 거리의 표준편차를 무질서 레벨에 따라 시각화하여 무질서를 표시하는 단계;를 더 포함하는, 객체간 거리를 이용한 무질서 예측 방법.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서, 무질서를 표시하는 단계에서 표시된 화면에서 선택된 프레임 또는 프레임 구간의 영상을 표시 또는 재생하는 단계;를 더 포함하는, 객체간 거리를 이용한 무질서 예측 방법.</claim></claimInfo><claimInfo><claim>10. 제 8 항에 있어서, 무질서를 표시하는 단계에서 표시된 화면에서 선택된 프레임의 관심 객체를 정점으로 하는 그래프의 최소 신장 트리를 이용하여 관심 객체간 최단 거리를 표시하는 단계;를 더 포함하는, 객체간 거리를 이용한 무질서 예측 방법.</claim></claimInfo><claimInfo><claim>11. 제 7 항에 있어서,관심 객체들간의 거리를 계산하는 단계에서 계산하는 관심 객체간 거리는 객체의 위치 정보로부터 구성되는 객체의 경계 상자의 중심 위치간 거리로부터 산출되는, 객체간 거리를 이용한 무질서 예측 방법.</claim></claimInfo><claimInfo><claim>12. 제 7 항에 있어서,관심 객체들간의 거리를 계산하는 단계에서 계산하는 관심 객체간 거리는 객체의 위치 정보로부터 구성되는 객체의 경계 상자간 최소 거리로부터 산출되는, 객체간 거리를 이용한 무질서 예측 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>220050169907</code><country>대한민국</country><engName>Kyonggi University Industry &amp; Academia Cooperation Foundation</engName><name>경기대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JANG, Jeong Hyeon</engName><name>장정현</name></inventorInfo><inventorInfo><address>경기도 화성시 영통로**번길 **...</address><code> </code><country> </country><engName>KIM, Kwang Hoon</engName><name>김광훈</name></inventorInfo><inventorInfo><address>경기도 안산시 상록구...</address><code> </code><country> </country><engName>SUN, Kyung Hee</engName><name>선경희</name></inventorInfo><inventorInfo><address>경기도 수원시 장안구...</address><code> </code><country> </country><engName>Nguyen Thanh Hai</engName><name>응웬탄하이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로*길 **, *층 ***호실(역삼동, 청원빌딩)</address><code>920101000618</code><country>대한민국</country><engName>SINJI PATENT FIRM</engName><name>특허법인 신지</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.01.16</receiptDate><receiptNumber>1-1-2023-0054108-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230005868.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bb648c03e716f8032cd13039bab71816d22121cc3e373549979e447555402135d5550f1da5d8bb8639f8cdf6a80929d7e225f3a958a46f2b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf63515af1b15477cea800482abda80f3a982b666f892a774443edba337264156cbc92873fafd7b0b6c96125e2b3ade0a807f3de5e3f8a6a1c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>