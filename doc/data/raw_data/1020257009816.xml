<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:23:40.2340</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.06.11</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7009816</applicationNumber><claimCount>22</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>의료영상 장치로부터의 실시간 비디오 처리 및 그 비디오로부터 오브젝트를 검출하기 위한 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEMS AND METHODS FOR PROCESSING REAL-TIME VIDEO FROM A  MEDICAL IMAGE DEVICE AND DETECTING OBJECTS IN THE VIDEO</inventionTitleEng><openDate>2025.04.10</openDate><openNumber>10-2025-0048802</openNumber><originalApplicationDate>2019.06.11</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2021-7000809</originalApplicationNumber><originalExaminationRequestDate>2025.04.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.25</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2025.01.01)</ipcDate><ipcNumber>A61B 1/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A61B 1/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A61B 1/31</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A61B 1/273</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020217000809</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 실시간 비디오 처리를 위한 컴퓨터-구현 시스템에 관한 것이다. 본 발명에 따른 시스템은, 복수의 프레임을 포함하는 실시간 비디오를 캡처하는 의료영상 장치, 훈련된 객체 감지기 및 훈련된 분류기를 포함하는 하나 이상의 신경망, 오버레이 결과를 실시간으로 표시하는 디스플레이 장치, 및 감도 설정에 따른 명령을 수신하는 입력장치를 포함한다. 상기 훈련된 객체 감지기는 실시간으로 입력되는 비디오 프레임을 분석하여 관심-피처를 탐지하고, 훈련된 분류기는 탐지된 관심-피처에 대하여 하나 이상의 범주에 따라 분류를 수행한다. 또한, 상기 명령에 따라 가중치 또는 임계값을 조정하기 위한 프로세서를 포함함으로써, 사용자의 개입에 따른 실시간 최적화가 가능하다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2019.12.19</internationOpenDate><internationOpenNumber>WO2019238714</internationOpenNumber><internationalApplicationDate>2019.06.11</internationalApplicationDate><internationalApplicationNumber>PCT/EP2019/065258</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 실시간 비디오 처리를 위한 컴퓨터-구현 시스템으로서,의료 시술 중 실시간 비디오를 캡처하도록 구성된 의료영상 장치로서, 상기 실시간 비디오는 복수의 프레임을 포함하며;다음을 구현하는 하나 이상의 신경망을 포함하고, 상기 하나 이상의 신경망은상기 의료영상 장치에 의해 캡처된 복수의 이미지를 직접 입력으로 수신하고, 상기 복수의 프레임들 내의 관심-피처(feature-of-interest)에 대한 적어도 하나의 검출(detection)을 출력하도록 구성된 훈련된 객체 감지기(object detector); 및상기 객체 감지기로부터 수신한 상기 관심-피처의 적어도 하나의 검출을 입력으로 하여, 적어도 하나의 범주(category)에 기초하여 상기 관심-피처를 분류(classification)하도록 구성된 훈련된 분류기(classifier);실시간으로 상기 복수의 프레임들과 함께, 상기 관심-피처의 검출 및 분류에 기반한 오버레이(overlay)를 상기 의료영상 장치의 작업자에게 표시하기 위한 디스플레이 장치;상기 검출 및 상기 분류 중 적어도 하나에 대응하는 명령을 상기 작업자로부터 수신하기 위한 입력장치로서, 상기 명령은 감도 설정(sensitivity setting)과 관련되며;상기 명령에 따라, 상기 훈련된 객체 감지기 또는 상기 훈련된 분류기 중 적어도 하나에 관련된 가중치 또는 임계값 중 적어도 하나를 조정하도록 구성된 적어도 하나의 프로세서를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 의료 시술은 내시경, 위내시경, 대장내시경 및 소장내시경 중 적어도 하나인, 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 관심-피처는 비정상(abnormality)으로서, 인체 조직 상 또는 조직 내의 형성, 한 유형의 세포에서 다른 유형의 세포로의 조직 변화, 인체 조직이 존재해야 하는 위치에서의 조직 부재, 또는 병변 중 적어도 하나를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 프로세서는, 상기 명령에 응답하여, 상기 훈련된 객체 감지기 또는 훈련된 분류기 중 적어도 하나의 하나 이상의 노드에 대한 하나 이상의 가중치를 조정하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 프로세서는, 상기 명령에 응답하여, 상기 훈련된 객체 감지기 또는 훈련된 분류기 중 적어도 하나의 출력층에 관련된 하나 이상의 임계값을 조정하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 오버레이는 상기 복수의 프레임들 내에서 상기 관심-피처의 적어도 하나의 검출 위치를 지시하는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 오버레이는 경계 박스(bounding box)를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 오버레이의 디스플레이는, 상기 훈련된 분류기에 의해 생성된 분류 결과에 따라 변경되는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 훈련된 분류기가 상기 관심-피처를 제1 범주로 분류한 경우 상기 오버레이는 제1 색상으로 변경되고, 제2 범주로 분류한 경우 제2 색상으로 변경되는, 시스템.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 분류는 조직학적 분류(histological classification), 형태학적 분류(morphological classification) 또는 구조적 분류(structural classification) 중 적어도 하나에 기반하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 입력장치는 노브(knob), 버튼(button), 키보드(keyboard), 마우스(mouse), 터치스크린(touch screen) 중 적어도 하나를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>12. 실시간 비디오 처리를 위한 방법으로서,의료 시술 중에 의료영상 장치를 통해 실시간 비디오를 캡처하는 단계로서, 상기 실시간 비디오는 복수의 프레임들을 포함하며;상기 복수의 프레임들을 훈련된 객체 감지기에 직접 제공하는 단계로서, 상기 훈련된 객체 감지기는 하나 이상의 신경망을 포함하며;상기 훈련된 객체 감지기를 상기 복수의 프레임들에 적용하여 관심-피처(feature-of-interest)의 적어도 하나의 검출을 생성하는 단계;훈련된 분류기를 상기 적어도 하나의 검출에 적용하여, 적어도 하나의 범주에 기초하여 상기 관심-피처에 대한 분류(classification)를 생성하는 단계로서, 상기 분류기는 하나 이상의 신경망을 포함하고;디스플레이 장치를 통해 상기 의료영상 장치의 작업자에게, 상기 복수의 프레임들과 함께 상기 관심-피처의 검출 및 분류에 기초한 오버레이를 표시하는 단계;입력 장치를 통해 상기 작업자로부터, 상기 검출 또는 상기 분류 중 적어도 하나와 관련된 감도 설정(sensitivity setting)에 대응하는 명령을 수신하는 단계;상기 명령에 기초하여, 상기 훈련된 객체 감지기 또는 상기 훈련된 분류기 중 적어도 하나에 관련된 가중치 또는 임계값 중 적어도 하나를 조정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 의료 시술은 내시경, 위내시경, 대장내시경 또는 소장내시경 중 적어도 하나인, 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 관심-피처는 비정상(abnormality)으로서, 인체 조직 상 또는 조직 내의 형성, 인체 조직이 한 유형의 세포에서 다른 유형의 세포로 변화된 것, 인체 조직이 존재해야 할 위치에서의 조직 부재 또는 병변 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 명령에 응답하여, 상기 훈련된 객체 감지기 또는 훈련된 분류기 중 적어도 하나의 하나 이상의 노드에 대한 하나 이상의 가중치를 조정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 명령에 응답하여, 상기 훈련된 객체 감지기 또는 훈련된 분류기 중 적어도 하나의 출력층과 관련된 하나 이상의 임계값을 조정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서,상기 오버레이는 상기 복수의 프레임들 내에서 상기 관심-피처의 적어도 하나의 검출 위치를 지시하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 오버레이는 경계 박스(bounding box)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서,상기 훈련된 분류기에 의해 생성된 분류 결과에 기초하여 상기 오버레이의 디스플레이를 변경하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 훈련된 분류기가 상기 관심-피처를 제1 범주로 분류한 경우 상기 오버레이를 제1 색상으로 변경하고, 제2 범주로 분류한 경우 제2 색상으로 변경하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제12항에 있어서,상기 분류는 조직학적 분류(histological classification), 형태학적 분류(morphological classification) 또는 구조적 분류(structural classification) 중 적어도 하나에 기반하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제12항에 있어서,상기 입력 장치는 노브(knob), 버튼(button), 키보드(keyboard), 마우스(mouse), 또는 터치스크린(touch screen) 중 적어도 하나를 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>아일랜드 더블린 * 더블린 써 존 로건슨스 키 리버사이드 투</address><code>520210008902</code><country>아일랜드</country><engName>COSMO ARTIFICIAL INTELLIGENCE - AI LIMITED</engName><name>코스모 아티피셜 인텔리전스 - 에이아이 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>이탈리아 로마 ***** ***...</address><code> </code><country>이탈리아</country><engName>NGO DINH, Nhan</engName><name>고 딘 냔</name></inventorInfo><inventorInfo><address>이탈리아 로마 ***** ***...</address><code> </code><country>이탈리아</country><engName>EVANGELISTI, Giulio</engName><name>에반젤리스티 줄리오</name></inventorInfo><inventorInfo><address>이탈리아 로마 ***** ***...</address><code> </code><country>이탈리아</country><engName>NAVARI, Flavio</engName><name>나바리 플라비오</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>대전광역시 서구 한밭대로 ***번지 (둔산동, 사학연금회관) **층</address><code>920151000017</code><country>대한민국</country><engName>PLUS IP Law Firm</engName><name>특허법인플러스</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2018.06.13</priorityApplicationDate><priorityApplicationNumber>16/008,015</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2018.06.28</priorityApplicationDate><priorityApplicationNumber>18180572.2</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.03.25</receiptDate><receiptNumber>1-1-2025-0338601-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.04.17</receiptDate><receiptNumber>1-1-2025-0433734-94</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257009816.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93970cb4f41a1cbd7295c2a53de241bf3e978056422421c2b1a36955b194a9f61cb47090c7913dee631894a59a4d2953fa95dfe5a21d7982ff</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe9dbfa0d3c9af05f6105a1b74e0b425acaa9f769f04eda7c8118a604475429a3dd0948e12a98a3338a60ecf0352669b189622e655abc351d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>