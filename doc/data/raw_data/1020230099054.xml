<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:53.553</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0099054</applicationNumber><claimCount>22</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사용자의 시선 정보를 이용하여 결제를 수행하는 증강 현실 디바이스 및 그 동작 방법</inventionTitle><inventionTitleEng>AN AUGMENTED REALITY DEVICE FOR PERFORMING A PAYMENT  USING GAZE INFORMATION AND A METHOD FOR OPERATING  THE SAME</inventionTitleEng><openDate>2024.12.10</openDate><openNumber>10-2024-0172632</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06K 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06K 7/14</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2012.01.01)</ipcDate><ipcNumber>G06Q 20/32</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/57</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 사용자의 시선 정보를 이용하여 결제 코드를 인식함으로써 결제를 수행하는 증강 현실 디바이스 및 그 동작 방법을 제공한다. 본 개시의 일 실시예에 따른 증강 현실 디바이스는 적어도 하나의 시선 추적 센서를 통해 획득된 사용자의 양안의 시선 정보에 기초하여, 사용자의 양안의 시선 방향이 수렴하는 응시점(gaze point)을 획득하고, 카메라를 통해 획득된 이미지 상에서 응시점에 대응되는 관심 영역을 결정하고, 관심 영역을 확대하여 결제 코드를 인식하고, 인식된 결제 코드에 기초하여 결제를 수행할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 증강 현실 디바이스(100)가 사용자의 시선 정보를 이용하여 결제를 수행하는 방법에 있어서, 적어도 하나의 시선 추적 센서(110)를 이용하여 획득된 상기 사용자의 양안의 시선 정보에 기초하여, 상기 사용자의 양안의 시선 방향이 수렴하는 응시점(gaze point)을 획득하는 단계(S210); 카메라(120)를 통해 획득된 이미지 상에서 상기 응시점에 대응되는 관심 영역을 결정하는 단계(S220); 상기 결정된 관심 영역을 확대하는 단계(S230); 상기 확대된 관심 영역에 포함된 결제 코드를 인식하는 단계(S240); 및상기 인식된 결제 코드를 이용하여 결제를 수행하는 단계; 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 카메라(120)는 서로 다른 배율을 갖는 복수의 카메라를 포함하고, 상기 응시점과 상기 사용자 간의 거리에 기초하여 상기 복수의 카메라 중 상기 결제 코드의 인식을 위한 최적의 배율을 갖는 카메라를 선택하는 단계(S510); 를 더 포함하고, 상기 관심 영역을 결정하는 단계(S220)는, 상기 선택된 카메라를 이용하여 상기 결제 코드를 촬영함으로써 획득된 상기 이미지로부터 상기 관심 영역을 결정하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,상기 카메라(120)를 선택하는 단계(S510)는, 상기 응시점과 상기 사용자 간의 거리에 비례하여 상기 복수의 카메라 중 고배율을 갖는 카메라를 선택하는, 방법.  </claim></claimInfo><claimInfo><claim>4. 제2 항에 있어서, 상기 결제 코드의 크기에 관한 정보가 미리 획득되어 상기 증강 현실 디바이스의 메모리 내에 저장되어 있고, 상기 카메라(120)를 선택하는 단계(S510)는, 상기 결제 코드의 크기에 관한 정보에 기초하여, 상기 복수의 카메라를 통해 획득된 복수의 이미지 상에 상기 결제 코드를 각각 투영함으로써 상기 결제 코드를 둘러싸는 영역의 크기를 산출하는 단계(S710); 및상기 복수의 카메라 중 상기 산출된 영역의 크기가 최대인 이미지를 획득하는 카메라를 선택하는 단계(S720); 를 포함하는, 방법.  </claim></claimInfo><claimInfo><claim>5. 제2 항에 있어서, 상기 카메라(120)를 선택하는 단계(S510)는, 상기 복수의 카메라를 통해 획득된 복수의 이미지에서 상기 응시점에 대응되는 2차원 위치 좌표 정보를 획득하는 단계(S910); 결제 코드 검출(detection)을 수행하여, 상기 응시점의 2차원 위치 좌표 정보를 기준으로 하여 설정된 영역으로부터 상기 결제 코드의 존재 여부 및 상기 결제 코드가 점유하는 영역의 크기를 인식하는 단계(S920); 및인식 결과, 상기 결제 코드가 존재하는 경우 상기 복수의 카메라 중 상기 결제 코드가 점유하는 영역의 크기가 최대인 이미지를 획득하는 카메라를 선택하는 단계(S930);를 포함하는, 방법.  </claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서, 상기 카메라(120)는 복수의 카메라를 포함하고, 상기 관심 영역을 결정하는 단계(S220)는, 상기 복수의 카메라를 이용하여 상기 응시점에 대응되는 영역을 촬영함으로써 복수의 이미지를 획득하는 단계(S1110); 상기 획득된 복수의 이미지 각각으로부터 상기 응시점에 대응되는 2차원 위치 좌표 정보를 획득하는 단계(S1120); 및 상기 복수의 이미지 중 상기 획득된 2차원 위치 좌표 정보를 기준으로 하여 설정된 영역을 복수의 관심 영역으로 결정하는 단계(S1130); 를 포함하고, 상기 관심 영역을 확대하는 단계(S230)는, 상기 복수의 관심 영역 각각을 기 설정된 줌 배율로 확대하고(S1140), 상기 결제 코드를 인식하는 단계(S240)는, 확대된 상기 복수의 관심 영역으로부터 상기 결제 코드를 인식하는(S1150), 방법. </claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 복수의 관심 영역으로부터 상기 결제 코드의 인식이 실패한 경우, 상기 복수의 카메라 외의 다른 카메라를 이용하여 촬영된 이미지로부터 상기 관심 영역을 결정하는 단계(S220), 상기 관심 영역을 기 설정된 줌 배율로 확대하는 단계(S230), 및 확대된 이미지 영역으로부터 상기 결제 코드를 인식하는 단계(S240)를 다시 수행하는, 방법. </claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서, 상기 카메라(120)는 복수의 카메라를 포함하고, 상기 관심 영역을 결정하는 단계(S220)는,상기 복수의 카메라를 이용하여 상기 응시점에 대응되는 영역을 촬영함으로써 복수의 이미지를 획득하는 단계(S1310); 상기 획득된 복수의 이미지를 이용하는 이미지 프로세싱(image processing)을 수행하여, 해상도, 명암비, 및 노이즈 중 적어도 하나를 포함하는 이미지 품질 파라미터가 향상된 고품질 이미지를 획득하는 단계(S1320); 및 상기 획득된 고품질 이미지 상에서 상기 응시점에 대응되는 2차원 위치 좌표 정보에 기초하여 상기 관심 영역을 결정하는 단계(S1330);를 포함하는, 방법.  </claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 하나의 항에 있어서, 상기 관심 영역을 확대하는 단계(S230)는, 기 설정된 줌(zoom) 배율로 상기 관심 영역을 확대하는, 방법. </claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 하나의 항에 있어서, 상기 결제 코드 인식이 실패한 경우, 상기 관심 영역에 대한 줌 배율을 증가시키고, 상기 증가된 줌 배율을 이용하여 상기 관심 영역을 확대하는 단계;를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서, 상기 증가된 줌 배율이 상기 카메라(120)의 최대 확대 배율에 도달하였는지 여부를 판단하는 단계; 및판단 결과에 따라 상기 증가된 줌 배율이 최대 확대 배율에 도달한 경우, 결제 코드 인식 실패를 나타내는 사용자 인터페이스(User Interface)를 출력하는 단계;를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>12. 사용자의 시선 정보를 이용하여 결제를 수행하는 증강 현실 디바이스(100)에 있어서, 사용자의 양안의 시선 정보를 획득하는 적어도 하나의 시선 추적 센서(110); 이미지를 획득하는 카메라(120); 적어도 하나의 명령어들(instructions)를 저장하는 메모리(140); 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(130); 를 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 적어도 하나의 시선 추적 센서(110)를 통해 획득된  상기 사용자의 양안의 시선 정보에 기초하여, 상기 사용자의 양안의 시선 방향이 수렴하는 응시점(gaze point)을 획득하고, 상기 카메라(120)를 통해 획득된 이미지 상에서 상기 응시점에 대응되는 관심 영역을 결정하고, 상기 결정된 관심 영역을 확대하고,확대된 상기 관심 영역에 포함된 결제 코드를 인식하며, 상기 인식된 결제 코드를 이용하여 결제를 수행하는, 증강 현실 디바이스(100).  </claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 카메라(120)는 서로 다른 배율을 갖는 복수의 카메라를 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 응시점과 상기 사용자 간의 거리에 기초하여 상기 복수의 카메라 중 상기 결제 코드의 인식을 위한 최적의 배율을 갖는 카메라를 선택하고, 상기 선택된 카메라를 이용하여 상기 결제 코드를 촬영함으로써 획득된 상기 이미지로부터 상기 관심 영역을 결정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 적어도 하나의 프로세서(130)는, 상기 응시점과 상기 사용자 간의 거리에 비례하여 상기 복수의 카메라 중 고배율을 갖는 카메라를 선택하는, 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>15. 제13 항에 있어서, 상기 결제 코드의 크기에 관한 정보가 미리 획득되어 상기 메모리(140) 내에 저장되어 있고, 상기 적어도 하나의 프로세서(130)는, 상기 결제 코드의 크기에 관한 정보에 기초하여, 상기 복수의 카메라를 통해 획득된 복수의 이미지 상에 상기 결제 코드를 각각 투영함으로써 상기 결제 코드를 둘러싸는 영역의 크기를 산출하고, 상기 복수의 카메라 중 상기 산출된 영역의 크기가 최대인 이미지를 획득하는 카메라를 선택하는, 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>16. 제13 항에 있어서, 상기 적어도 하나의 프로세서(130)는, 상기 복수의 카메라를 통해 획득된 복수의 이미지에서 상기 응시점에 대응되는 2차원 위치 좌표 정보를 획득하고, 결제 코드 검출(detection)을 수행하여, 상기 응시점의 2차원 위치 좌표 정보를 기준으로 하여 설정된 영역으로부터 상기 결제 코드의 존재 여부 및 상기 결제 코드가 점유하는 영역의 크기를 인식하고, 인식 결과, 상기 결제 코드가 존재하는 경우 상기 복수의 카메라 중 상기 결제 코드가 점유하는 영역의 크기가 최대인 이미지를 획득하는 카메라를 선택하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>17. 제12 항에 있어서, 상기 카메라(120)는 복수의 카메라를 포함하고, 상기 복수의 카메라는 응시점에 대응되는 영역을 촬영하여 복수의 이미지를 획득하고, 상기 적어도 하나의 프로세서(130)는, 상기 복수의 카메라를 통해 획득된 복수의 이미지 각각으로부터 상기 응시점에 대응되는 2차원 위치 좌표 정보를 획득하고, 상기 복수의 이미지 중 상기 획득된 2차원 위치 좌표 정보를 기준으로 하여 설정된 영역을 복수의 관심 영역으로 결정하고, 상기 복수의 관심 영역 각각을 기 설정된 줌 배율로 확대하고, 확대된 상기 복수의 관심 영역으로부터 상기 결제 코드를 인식하는, 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>18. 제12 항에 있어서, 상기 카메라(120)는 복수의 카메라를 포함하고, 상기 복수의 카메라는 상기 응시점에 대응되는 영역을 촬영함으로써 복수의 이미지를 획득하고, 상기 적어도 하나의 프로세서(130)는, 상기 복수의 카메라를 통해 획득된 복수의 이미지를 이용하는 이미지 프로세싱(image processing)을 수행하여, 해상도, 명암비, 및 노이즈 중 적어도 하나를 포함하는 이미지 품질 파라미터가 향상된 고품질 이미지를 획득하고, 상기 획득된 고품질 이미지 상에서 상기 응시점에 대응되는 2차원 위치 좌표 정보에 기초하여 상기 관심 영역을 결정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>19. 제12 항 내지 제18 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 프로세서(130)는, 기 설정된 줌(zoom) 배율로 상기 관심 영역을 확대하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>20. 제12 항 내지 제19 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 프로세서(130)는, 상기 결제 코드 인식이 실패한 경우, 상기 관심 영역에 대한 줌 배율을 증가시키고, 상기 증가된 줌 배율을 이용하여 상기 관심 영역을 확대하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>21. 제20 항에 있어서, 디스플레이부(150); 를 더 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 증가된 줌 배율이 상기 카메라(120)의 최대 확대 배율에 도달하였는지 여부를 판단하고, 판단 결과에 따라 상기 증가된 줌 배율이 최대 확대 배율에 도달한 경우, 결제 코드 인식 실패를 나타내는 사용자 인터페이스(User Interface)를 출력하도록 상기 디스플레이부(150)를 제어하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>22. 제1 항 내지 제11 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Won Woo</engName><name>이원우</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, In Jung</engName><name>이인정</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Jeong Pyo</engName><name>이정표</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.06.01</priorityApplicationDate><priorityApplicationNumber>1020230071180</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.07.28</receiptDate><receiptNumber>1-1-2023-0837016-15</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230099054.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c77104924888ba895126d1ad8b7485f8c023cbcb096d816f0439657732cf1b7a84c791c11a236a569e9ffbc42be2b0fc93525f1395adea75</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf5d2dd6f4b82256526c53857249964e1cb3cb6e9741ce29ae529e164ab3527730c57f9fef911866be58f19a9e9ff122062ad282bcb425adf3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>