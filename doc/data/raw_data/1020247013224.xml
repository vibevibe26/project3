<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:29.4029</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7013224</applicationNumber><claimCount>50</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>가변 보조 입력을 이용하는 트랜스포머 기반 신경망</inventionTitle><inventionTitleEng>TRANSFORMER BASED NEURAL NETWORK USING VARIABLE AUXILIARY INPUT</inventionTitleEng><openDate>2024.05.22</openDate><openNumber>10-2024-0071400</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.04.19</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/088</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 19/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용은 트랜스포머 기반 신경망에 관한 것이다. 현재 객체를 프로세싱하는 방법이 제공되고, 방법은, 현재 객체를 나타내는 입력 데이터 텐서의 세트를 트랜스포머 기반 신경망의 신경 계층 내로 입력하는 단계, 적어도 하나의 보조 데이터 텐서를 트랜스포머 기반 신경망의 신경 계층 내로 입력하는 단계 - 적어도 하나의 보조 데이터 텐서는 입력 데이터 텐서의 세트의 입력 데이터 텐서 각각과는 상이하고, 적어도 하나의 보조 입력을 나타냄 -, 및 출력 데이터 텐서의 세트를 획득하기 위하여 적어도 하나의 보조 데이터 텐서를 이용하여 트랜스포머 기반 신경망에 의해 입력 데이터 텐서의 세트를 프로세싱하는 단계를 포함한다. 입력된 적어도 하나의 보조 데이터 텐서는 현재 객체를 프로세싱하는 것에 대한 정보에 종속된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.06.22</internationOpenDate><internationOpenNumber>WO2023113635</internationOpenNumber><internationalApplicationDate>2021.12.15</internationalApplicationDate><internationalApplicationNumber>PCT/RU2021/000569</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 현재 객체를 프로세싱하는 방법으로서,상기 현재 객체를 나타내는 입력 데이터 텐서(tensor)의 세트를 트랜스포머 기반 신경망(transformer based neural network)의 신경 계층(neural layer) 내로 입력하는 단계(S152);적어도 하나의 보조 데이터 텐서를 상기 트랜스포머 기반 신경망의 신경 계층 내로 입력하는 단계(S154) - 상기 적어도 하나의 보조 데이터 텐서는 상기 입력 데이터 텐서의 세트의 상기 입력 데이터 텐서 각각과는 상이하고 적어도 하나의 보조 입력을 나타냄 -; 및출력 데이터 텐서의 세트를 획득하기 위하여 상기 적어도 하나의 보조 데이터 텐서를 이용하여 상기 트랜스포머 기반 신경망에 의해 상기 입력 데이터 텐서의 세트를 프로세싱하는 단계(S156)를 포함하고,상기 입력된 적어도 하나의 보조 데이터 텐서는 상기 현재 객체를 프로세싱하는 것에 대한 정보에 종속되는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 현재 객체는 신경망 추론 동안에 프로세싱되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 현재 객체는 신경망 훈련 동안에 프로세싱되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 입력 데이터 텐서의 세트는 상기 적어도 하나의 보조 데이터 텐서(S154)와는 별도로 입력되는(S152), 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 입력 데이터 텐서의 세트는 상기 트랜스포머 기반 신경망의 제1 신경 계층 내로 입력되고(S152), 상기 적어도 하나의 보조 데이터 텐서는 제1 계층과는 상이한, 상기 트랜스포머 기반 신경망의 제2 신경 계층 내로 입력되는(S154), 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 입력 데이터 텐서의 세트(S152) 및 상기 적어도 하나의 보조 데이터 텐서(S154)를 입력하는 것은,상이한 혼합된 입력 텐서의 세트를 생성하는 것 - 상기 상이한 혼합된 입력 텐서의 세트의 각각의 혼합된 입력 텐서는 상기 적어도 하나의 보조 데이터 텐서, 및 상기 입력 데이터 텐서의 세트의 하나의 입력 데이터 텐서 중의 적어도 하나를 포함함 -; 및상기 혼합된 입력 텐서의 세트를 상기 트랜스포머 기반 신경망의 상기 신경 계층 내로 입력하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 적어도 하나의 보조 입력을 상기 적어도 하나의 보조 데이터 텐서로 선형적으로 변환하는 것;상기 적어도 하나의 보조 입력을 상기 적어도 하나의 보조 데이터 텐서로 비-선형적으로 변환하는 것; 및또 다른 신경망에 의해 상기 적어도 하나의 보조 입력을 상기 적어도 하나의 보조 데이터 텐서로 변환하는 것중의 하나에 의해 상기 적어도 하나의 보조 데이터 텐서를 생성하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 현재 객체를 프로세싱하는 것에 대한 상기 정보는, 연속적 파라미터 범위 상에서 상기 현재 객체를 프로세싱하는 것에 대한 정보인, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,객체에 대하여 생성되는 비트스트림으로부터, 상기 현재 객체를 프로세싱하는 것에 대한 상기 정보를 획득하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 현재 객체는 이미지 또는 이미지의 일부 중의 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 이미지는 비디오 시퀀스(video sequence)의 프레임인, 방법.</claim></claimInfo><claimInfo><claim>12. 제10항 또는 제11항에 있어서,상기 적어도 하나의 보조 입력은,품질 지시 파라미터;신호 공간 내의 채널별 왜곡 메트릭;잠재 공간 내의 채널별 왜곡 메트릭;밝기(brightness), 콘트라스트(contrast), 블러링(blurring), 웜니스(warmness), 샤프니스(sharpness), 포화(saturation), 컬러 히스토그램(color Histogram), 케이드(cade);섀도잉(shadowing), 휘도(luminance), 비네트 제어(vignette control), 페인팅 스타일(painting style);불연속적으로 가변적인 필터 강도, 연속적으로 가변적인 필터 강도;인트라 예측 또는 인터 예측의 지시; 및객체 대체 애플리케이션(object replacement application)을 위한 변환 레이트를 포함하는 그룹으로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>13. 제10항 내지 제12항 중 어느 한 항의 상기 방법의 단계를 포함하는, 이미지를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>14. 제10항 내지 제12항 중 어느 한 항의 상기 방법의 단계를 포함하는, 인코딩된 이미지를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>15. 제13항 또는 제14항의 상기 방법의 단계를 포함하는 비디오 코딩 방법으로서,상기 트랜스포머 기반 신경망은 인루프 필터 내에 포함되는, 비디오 코딩 방법.</claim></claimInfo><claimInfo><claim>16. 제10항 내지 제15항 중 어느 한 항의 상기 방법의 단계를 포함하는, 이미지 강화 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 현재 객체는 하나 이상의 문장을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 적어도 하나의 보조 입력은 온도, 언어, 및 어펙션(affection)을 포함하는 그룹으로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>19. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 현재 객체는 오디오 신호를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 적어도 하나의 보조 입력은,품질 지시 파라미터;신호 공간 내의 채널별 왜곡 메트릭;임의의 잠재 공간 내의 채널별 왜곡 메트릭;등화기 설정(equalizer setting);음량(volume); 및변환 레이트를 포함하는 그룹으로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>21. 제19항 또는 제20항의 상기 방법의 단계를 포함하는, 음향 신호를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>22. 제19항 또는 제20항의 상기 방법의 단계를 포함하는, 인코딩된 음향 신호를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>23. 신경망 추론에 의해 현재 객체를 프로세싱하는 방법으로서,상기 현재 객체를 나타내는 입력 데이터 텐서의 세트를 훈련된 트랜스포머 기반 신경망의 신경 계층 내로 입력하는 단계(S162);적어도 하나의 보조 데이터 텐서를 상기 훈련된 트랜스포머 기반 신경망의 신경 계층 내로 입력하는 단계(S164) - 상기 적어도 하나의 보조 데이터 텐서는 상기 입력 데이터 텐서의 세트의 상기 입력 데이터 텐서 각각과는 상이하고 적어도 하나의 보조 입력을 나타냄 -; 및출력 데이터 텐서의 세트를 획득하기 위하여 상기 적어도 하나의 보조 데이터 텐서를 이용하여 상기 훈련된 트랜스포머 기반 신경망에 의해 상기 입력 데이터 텐서의 세트를 프로세싱하는 단계(S166)를 포함하고,상기 입력된 적어도 하나의 보조 데이터 텐서는 상기 현재 객체의 성질에 대한 정보, 및 상기 현재 객체를 프로세싱하는 것에 대한 정보 중의 적어도 하나에 종속되는, 방법.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 입력 데이터 텐서의 세트는 상기 적어도 하나의 보조 데이터 텐서(S164)와는 별도로 입력되는(S162), 방법.</claim></claimInfo><claimInfo><claim>25. 제23항 또는 제24항에 있어서,상기 입력 데이터 텐서의 세트는 상기 훈련된 트랜스포머 기반 신경망의 제1 신경 계층 내로 입력되고(S162), 상기 적어도 하나의 보조 데이터 텐서는 제1 계층과는 상이한, 상기 훈련된 트랜스포머 기반 신경망의 제2 신경 계층 내로 입력되는(S162), 방법.</claim></claimInfo><claimInfo><claim>26. 제23항 내지 제25항 중 어느 한 항에 있어서,상기 입력 데이터 텐서의 세트(S162) 및 상기 적어도 하나의 보조 데이터 텐서(S164)를 입력하는 것은,상이한 혼합된 입력 텐서의 세트를 생성하는 것 - 상기 상이한 혼합된 입력 텐서의 세트의 각각의 혼합된 입력 텐서는 상기 적어도 하나의 보조 데이터 텐서, 및 상기 입력 데이터 텐서의 세트의 하나의 입력 데이터 텐서 중의 적어도 하나를 포함함 -; 및상기 혼합된 입력 텐서의 세트를 상기 훈련된 트랜스포머 기반 신경망의 상기 신경 계층 내로 입력하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>27. 제23항 내지 제26항 중 어느 한 항에 있어서,상기 적어도 하나의 보조 입력을 상기 적어도 하나의 보조 데이터 텐서로 선형적으로 변환하는 것;상기 적어도 하나의 보조 입력을 상기 적어도 하나의 보조 데이터 텐서로 비-선형적으로 변환하는 것; 및또 다른 신경망에 의해 상기 적어도 하나의 보조 입력을 상기 적어도 하나의 보조 데이터 텐서로 변환하는 것중의 하나에 의해 상기 적어도 하나의 보조 데이터 텐서를 생성하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>28. 제23항 내지 제27항 중 어느 한 항에 있어서,상기 현재 객체의 성질에 대한 정보, 및 상기 현재 객체를 프로세싱하는 것에 정보 중의 적어도 하나는, 연속적인 파라미터 범위 상에서 상기 현재 객체를 프로세싱하는 것에 대한 정보인, 방법.</claim></claimInfo><claimInfo><claim>29. 제23항 내지 제28항 중 어느 한 항에 있어서,객체에 대하여 생성되는 비트스트림으로부터, 상기 현재 객체의 성질에 대한 정보, 및 상기 현재 객체를 프로세싱하는 것에 대한 정보 중의 적어도 하나를 획득하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>30. 제23항 내지 제29항 중 어느 한 항에 있어서,상기 현재 객체는 이미지 또는 이미지의 일부 중의 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서,상기 이미지는 비디오 시퀀스의 프레임인, 방법.</claim></claimInfo><claimInfo><claim>32. 제30항 또는 제31항에 있어서,상기 적어도 하나의 보조 입력은,컨텐츠, 컨텐츠의 유형;품질 지시 파라미터;신호 공간 내의 채널별 왜곡 메트릭;잠재 공간 내의 채널별 왜곡 메트릭;밝기, 콘트라스트, 블러링, 웜니스, 샤프니스, 포화, 컬러 히스토그램, 케이드;섀도잉, 휘도, 비네트 제어, 페인팅 스타일;불연속적으로 가변적인 필터 강도, 연속적으로 가변적인 필터 강도;인트라 예측 또는 인터 예측의 지시; 및객체 대체 애플리케이션을 위한 변환 레이트를 포함하는 그룹으로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>33. 제30항 내지 제32항 중 어느 한 항의 상기 방법의 단계를 포함하는, 이미지를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>34. 제30항 내지 제32항 중 어느 한 항의 상기 방법의 단계를 포함하는, 인코딩된 이미지를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>35. 제30항 내지 제34항 중 어느 한 항의 상기 방법의 단계를 포함하는, 이미지 압축 방법.</claim></claimInfo><claimInfo><claim>36. 제30항 내지 제34항 중 어느 한 항의 상기 방법의 단계를 포함하는, 비디오 압축 방법.</claim></claimInfo><claimInfo><claim>37. 제33항 및 제34항의 상기 방법의 단계를 포함하는, 이미지를 오토-인코딩하는 방법.</claim></claimInfo><claimInfo><claim>38. 비디오 코딩 방법으로서,제30항 내지 제37항 중 어느 한 항의 상기 방법의 단계를 포함하고,상기 훈련된 트랜스포머 기반 신경망은 인루프 필터 내에 포함되는, 비디오 코딩 방법.</claim></claimInfo><claimInfo><claim>39. 제30항 내지 제38항 중 어느 한 항의 상기 방법의 단계를 포함하는, 이미지 강화 방법.</claim></claimInfo><claimInfo><claim>40. 제23항 내지 제29항 중 어느 한 항에 있어서,상기 현재 객체는 하나 이상의 문장을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>41. 제40항에 있어서,상기 적어도 하나의 보조 입력은 컨텐츠, 컨텐츠의 유형, 온도, 언어, 및 어펙션을 포함하는 그룹으로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>42. 제23항 내지 제29항 중 어느 한 항에 있어서,상기 현재 객체는 오디오 신호를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>43. 제42항에 있어서,상기 적어도 하나의 보조 입력은,컨텐츠, 컨텐츠의 유형;품질 지시 파라미터;신호 공간 내의 채널별 왜곡 메트릭;임의의 잠재 공간 내의 채널별 왜곡 메트릭;등화기 설정;음량; 및변환 레이트를 포함하는 그룹으로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>44. 제42항 또는 제43항의 상기 방법의 단계를 포함하는, 음향 신호를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>45. 제42항 또는 제43항의 상기 방법의 단계를 포함하는, 인코딩된 음향 신호를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>46. 코드를 포함하는 비-일시적 매체 상에 저장되는 컴퓨터 프로그램으로서,상기 코드는, 하나 이상의 프로세서에 의해 실행될 때, 제1항 내지 제45항 중 어느 한 항에 따른 상기 방법의 단계를 수행하는, 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>47. 프로세싱 장치(170)로서,하나 이상의 프로세서(176); 및상기 하나 이상의 프로세서(176)에 결합되고, 상기 하나 이상의 프로세서(176)에 의한 실행을 위한 프로그래밍을 저장하는 비-일시적 컴퓨터-판독가능 저장 매체(177) - 상기 프로그래밍은, 상기 하나 이상의 프로세서(176)에 의해 실행될 때, 제1항 내지 제45항 중 어느 한 항에 다른 상기 방법을 수행하도록 상기 프로세싱 장치(170)를 구성함 -를 포함하는 프로세싱 장치(170).</claim></claimInfo><claimInfo><claim>48. 인코딩된 이미지를 디코딩하도록 구성되고, 제47항의 상기 프로세싱 장치(170)를 포함하는 디코딩 디바이스.</claim></claimInfo><claimInfo><claim>49. 이미지를 인코딩하도록 구성되고, 제47항의 상기 프로세싱 장치(170)를 포함하는 인코딩 디바이스.</claim></claimInfo><claimInfo><claim>50. 이미지를 코딩하도록 구성되고, 제48항 및 제49항의 상기 프로세싱 장치(170)를 포함하는 오토-인코딩 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 ****** 광동성 셴젠 롱강 디스트릭트 반티안 후아웨이 어드미니스트레이션 빌딩</address><code>520000572466</code><country>중국</country><engName>HUAWEI TECHNOLOGIES CO., LTD.</engName><name>후아웨이 테크놀러지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ******...</address><code> </code><country> </country><engName>GAIKOV, Georgii Petrovich</engName><name>가이코프 게오르기 페트로비치</name></inventorInfo><inventorInfo><address>중국 ******...</address><code> </code><country> </country><engName>IKONIN, Sergey Yurievich</engName><name>아이코닌 세르게이 유리에비치</name></inventorInfo><inventorInfo><address>중국 ******...</address><code> </code><country> </country><engName>KOYUNCU, Ahmet Burakhan</engName><name>코윤쿠 아흐메트 부라칸</name></inventorInfo><inventorInfo><address>중국 ******...</address><code> </code><country> </country><engName>KARABUTOV, Alexander Alexandrovich</engName><name>카라부토브 알렉산더 알렉산드로비치</name></inventorInfo><inventorInfo><address>중국 ******...</address><code> </code><country> </country><engName>SOLOVYEV, Timofey Mikhailovich</engName><name>솔로비예프 티모페이 미카일로비치</name></inventorInfo><inventorInfo><address>중국 ******...</address><code> </code><country> </country><engName>ALSHINA, Elena Alexandrovna</engName><name>알시나 엘레나 알렉산드로브나</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, 서림빌딩 **층 (역삼동)</address><code>920011000036</code><country>대한민국</country><engName>YOU ME PATENT &amp; LAW FIRM</engName><name>유미특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.04.19</receiptDate><receiptNumber>1-1-2024-0435505-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.04.22</receiptDate><receiptNumber>1-5-2024-0067433-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247013224.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a22c639832dc47dc45db051000cbf183f8df6aceacd5db7c41be2e2c1b644310b6c19bb30ff138614ee1e05aa04758a6f67c787fc7f508d7</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cffb1d27542dd67aa6a9903ed566d88022d824477c3b85e144244e478bd45e5a535e99d03603099f62972110bad875cbe210ca89d79642d16e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>