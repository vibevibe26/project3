<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:14.514</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0156519</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>3차원 객체 인식 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR 3-DIMENSIONAL OBJECT PERCEPTION</inventionTitleEng><openDate>2025.05.21</openDate><openNumber>10-2025-0070672</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 30/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/894</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/931</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 3차원 객체 인식 방법 및 장치가 제공된다. 그 방법은 3차원 공간에 관한 입력 영상, 3차원 공간에 관한 입력 포인트 클라우드, 및 3차원 공간 내 타겟 객체에 관한 입력 언어를 수신하고, 인코딩 모델을 이용하여 입력 영상의 부분 영역들의 후보 영상 특징들, 입력 포인트 클라우드의 포인트 클라우드 특징, 및 입력 언어의 언어 특징을 생성하고, 후보 영상 특징들과 언어 특징 간의 유사도 스코어들에 기초하여 후보 영상 특징들 중 언어 특징에 대응하는 타겟 영상 특징을 선택하고, 타겟 영상 특징 및 포인트 클라우드 특징에 기초하여 멀티 모달 디코딩 모델을 실행하여 디코딩 출력을 생성하고, 디코딩 출력에 기초하여 객체 검출 모델을 실행하여 타겟 객체에 대응하는 3차원 바운딩 박스를 검출하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 3차원 공간에 관한 입력 영상, 3차원 공간에 관한 입력 포인트 클라우드, 및 3차원 공간 내 타겟 객체에 관한 입력 언어를 수신하는 단계;인코딩 모델을 이용하여 상기 입력 영상의 부분 영역들의 후보 영상 특징들, 상기 입력 포인트 클라우드의 포인트 클라우드 특징, 및 상기 입력 언어의 언어 특징을 생성하는 단계;상기 후보 영상 특징들과 상기 언어 특징 간의 유사도 스코어들에 기초하여 상기 후보 영상 특징들 중 상기 언어 특징에 대응하는 타겟 영상 특징을 선택하는 단계;상기 타겟 영상 특징 및 상기 포인트 클라우드 특징에 기초하여 멀티 모달 디코딩 모델을 실행하여 디코딩 출력을 생성하는 단계; 및상기 디코딩 출력에 기초하여 객체 검출 모델을 실행하여 상기 타겟 객체에 대응하는 3차원 바운딩 박스를 검출하는 단계를 포함하는 3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 후보 영상 특징들, 상기 포인트 클라우드 특징, 및 상기 언어 특징을 생성하는 단계는상기 입력 언어에 기초하여 언어 인코딩 모델을 실행하여 상기 입력 언어에 대응하는 언어 특징을 생성하는 단계;상기 입력 영상에 기초하여 영상 인코딩 모델 및 영역 제안 모델을 실행하여 상기 입력 영상의 부분 영역들에 대응하는 후보 영상 특징들을 생성하는 단계; 및상기 입력 포인트 클라우드에 기초하여 포인트 클라우드 인코딩 모델을 실행하여 상기 입력 포인트 클라우드에 대응하는 포인트 클라우드 특징을 생성하는 단계를 포함하는, 3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 입력 언어에 기초하여 상기 타겟 객체의 기하학적 특성을 나타내는 위치 필드, 및 상기 타겟 객체의 클래스를 나타내는 클래스 필드를 각각 포함하는 확장된 표현들이 생성되고,상기 확장된 표현들에 기초하여 상기 언어 특징이 생성되는,3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 위치 필드에 기초하여 다른 기하학적 특성들의 동일 클래스의 객체들이 구분되는,3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 위치 필드는학습 가능한 특성을 갖는,3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 디코딩 출력을 생성하는 단계는상기 타겟 영상 특징을 분할하여 영상 토큰들을 생성하는 단계;상기 포인트 클라우드 특징을 분할하여 포인트 클라우드 토큰들을 생성하는 단계;상기 영상 토큰들의 상대적인 위치를 나타내는 제1 위치 정보를 생성하는 단계;상기 포인트 클라우드 토큰들의 상대적인 위치를 나타내는 제2 위치 정보를 생성하는 단계; 및상기 영상 토큰들, 상기 포인트 클라우드 토큰들, 상기 제1 위치 정보, 및 상기 제2 위치 정보에 기초한 키 데이터 및 밸류 데이터로 상기 멀티 모달 디코딩 모델을 실행하는 단계를 포함하는, 3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 디코딩 출력을 생성하는 단계는상기 3차원 공간에서 상기 타겟 객체가 검출될 가능성이 있는 검출 위치 후보들을 나타내는 검출 가이드 정보에 기초한 쿼리 데이터로 상기 멀티 모달 디코딩 모델을 실행하는 단계를 포함하는,3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 검출 위치 후보들은비균일한(non-uniform) 위치들을 나타내는,3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 멀티 모달 디코딩 모델은상기 타겟 영상 특징, 상기 포인트 클라우드 특징, 및 상기 검출 가이드 정보로부터 연관성을 추출하여 상기 디코딩 출력을 생성하는,3차원 객체 인식 방법.</claim></claimInfo><claimInfo><claim>10. 하드웨어와 결합되어 제1항 내지 제9항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>11. 전자 장치에 있어서,프로세서; 및명령어들을 저장하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에 의해 실행될 때, 상기 전자 장치로 하여금,3차원 공간에 관한 입력 영상, 3차원 공간에 관한 입력 포인트 클라우드, 및 3차원 공간 내 타겟 객체에 관한 입력 언어를 수신하고,인코딩 모델을 이용하여 상기 입력 영상의 부분 영역들의 후보 영상 특징들, 상기 입력 포인트 클라우드의 포인트 클라우드 특징, 및 상기 입력 언어의 언어 특징을 생성하고,상기 후보 영상 특징들과 상기 언어 특징 간의 유사도 스코어들에 기초하여 상기 후보 영상 특징들 중 상기 언어 특징에 대응하는 타겟 영상 특징을 선택하고,상기 타겟 영상 특징 및 상기 포인트 클라우드 특징에 기초하여 멀티 모달 디코딩 모델을 실행하여 디코딩 출력을 생성하고,상기 디코딩 출력에 기초하여 객체 검출 모델을 실행하여 상기 타겟 객체에 대응하는 3차원 바운딩 박스를 검출하도록 하는,전자 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 명령어들이 상기 프로세서에 의해 실행될 때, 상기 전자 장치로 하여금,상기 입력 언어에 기초하여 언어 인코딩 모델을 실행하여 상기 입력 언어에 대응하는 언어 특징을 생성하고,상기 입력 영상에 기초하여 영상 인코딩 모델 및 영역 제안 모델을 실행하여 상기 입력 영상의 부분 영역들에 대응하는 후보 영상 특징들을 생성하고,상기 입력 포인트 클라우드에 기초하여 포인트 클라우드 인코딩 모델을 실행하여 상기 입력 포인트 클라우드에 대응하는 포인트 클라우드 특징을 생성하도록 하는,전자 장치.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 입력 언어에 기초하여 상기 타겟 객체의 기하학적 특성을 나타내는 위치 필드, 및 상기 타겟 객체의 클래스를 나타내는 클래스 필드를 각각 포함하는 확장된 표현들이 생성되고,상기 확장된 표현들에 기초하여 상기 언어 특징이 생성되는,전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 위치 필드에 기초하여 다른 기하학적 특성들의 동일 클래스의 객체들이 구분되는,전자 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 위치 필드는학습 가능한 특성을 갖는,전자 장치.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서,상기 명령어들이 상기 프로세서에 의해 실행될 때, 상기 전자 장치로 하여금,상기 타겟 영상 특징을 분할하여 영상 토큰들을 생성하고,상기 포인트 클라우드 특징을 분할하여 포인트 클라우드 토큰들을 생성하고,상기 영상 토큰들의 상대적인 위치를 나타내는 제1 위치 정보를 생성하고,상기 포인트 클라우드 토큰들의 상대적인 위치를 나타내는 제2 위치 정보를 생성하고,상기 영상 토큰들, 상기 포인트 클라우드 토큰들, 상기 제1 위치 정보, 및 상기 제2 위치 정보에 기초한 키 데이터 및 밸류 데이터로 상기 멀티 모달 디코딩 모델을 실행하도록 하는,전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 명령어들이 상기 프로세서에 의해 실행될 때, 상기 전자 장치로 하여금,상기 3차원 공간에서 상기 타겟 객체가 검출될 가능성이 있는 검출 위치 후보들을 나타내는 검출 가이드 정보에 기초한 쿼리 데이터로 상기 멀티 모달 디코딩 모델을 실행하도록 하는,전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 검출 위치 후보들은비균일한(non-uniform) 위치들을 나타내는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서,상기 멀티 모달 디코딩 모델은상기 타겟 영상 특징, 상기 포인트 클라우드 특징, 및 상기 검출 가이드 정보로부터 연관성을 추출하여 상기 디코딩 출력을 생성하는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 차량에 있어서,3차원 공간에 관한 입력 영상을 생성하는 카메라;상기 3차원 공간에 관한 입력 포인트 클라우드를 생성하는 라이다 센서;상기 3차원 공간에 관한 상기 입력 영상, 상기 3차원 공간에 관한 상기 입력 포인트 클라우드, 및 상기 3차원 공간 내 타겟 객체에 관한 입력 언어를 수신하고,인코딩 모델을 이용하여 상기 입력 영상의 부분 영역들의 후보 영상 특징들, 상기 입력 포인트 클라우드의 포인트 클라우드 특징, 및 상기 입력 언어의 언어 특징을 생성하고,상기 후보 영상 특징들과 상기 언어 특징 간의 유사도 스코어들에 기초하여 상기 후보 영상 특징들 중 상기 언어 특징에 대응하는 타겟 영상 특징을 선택하고,상기 타겟 영상 특징 및 상기 포인트 클라우드 특징에 기초하여 멀티 모달 디코딩 모델을 실행하여 디코딩 출력을 생성하고,상기 디코딩 출력에 기초하여 객체 검출 모델을 실행하여 상기 타겟 객체에 대응하는 3차원 바운딩 박스를 검출하는, 프로세서; 및상기 3차원 바운딩 박스에 기초하여 상기 차량을 제어하는 제어 계통을 포함하는, 차량.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 권선구...</address><code>420190482041</code><country>대한민국</country><engName>LEE, Dong Wook</engName><name>이동욱</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>EOM Chan Ho</engName><name>엄찬호</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code>420170743681</code><country>대한민국</country><engName>YOO BYUNG IN</engName><name>유병인</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code>420190717755</code><country>대한민국</country><engName>LEE, HYUNJEONG</engName><name>이현정</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.13</receiptDate><receiptNumber>1-1-2023-1252821-77</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230156519.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93191078e9070af38d272b6f7fc6c1c0999b8edb33fae7f61aeb0feeb8a7c1f18ce17577fc7f19fe27e2ef1ee312fe8701a474a9c3b09a15ba</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf85c8c7fe549487099838d35d6d4bc183869acb74f229c5553f42c6dce6d83c0b869bea5565291a08c3dac4d346be7dd7182e9440a5739127</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>