<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:40.3940</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.04.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0055202</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자가-증류를 이용한 그래프 기반 신경망 모델에 대한 양자화 인식 재학습 방법 및 저장매체</inventionTitle><inventionTitleEng>METHOD AND STORAGE MEDIUM FOR QUANTIZATION AWARE RETRAINING  FOR GRAPH-BASED NEURAL NETWORK MODEL USING SELF-DISTILLATION</inventionTitleEng><openDate>2025.11.03</openDate><openNumber>10-2025-0156339</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.25</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/042</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 17/15</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 7/483</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 예시는 방법을 제시한다. 상기 방법은: 일방향적 비 순환 그래프(DAG) 형태의 제1 신경망모델에 포함된 복수의 그래프 모듈들에 복수의 마커를 추가하는 단계와; 상기 복수의 그래프 모듈들 각각의 입력 값과 출력 값을 상기 복수의 마커를 이용하여 수집함으로써, 교정 데이터를 생성하는 단계와; 상기 교정 데이터에 기초하여 상기 제1 신경망모델에 적용가능한 스케일 값과 오프셋 값을 결정하는 단계와; 상기 스케일 값과 상기 오프셋 값에 기초하여, 정수 포맷의 양자화된 가중치 파라미터를 포함하는 제2 신경망모델을 상기 제1 신경망모델에 기초하여 생성하는 단계와; 제1 재학습 데이터에 대한 상기 제1 신경망모델의 출력 값을 획득하는 단계와; 상기 제1 신경망모델의 출력 값을 기준으로, 상기 제1 신경망모델로부터 양자화를 수행한 제2 신경망모델에 대한 양자화 인식 재학습(quantization aware retraining)을 수행하여, 상기 제2 신경망모델에 포함된 적어도 하나의 가중치 파라미터를 업데이트하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 일방향적 비 순환 그래프(DAG) 형태의 제1 신경망모델에 포함된 복수의 그래프 모듈들에 복수의 마커를 추가하는 단계와;상기 복수의 그래프 모듈들 각각의 입력 값과 출력 값을 상기 복수의 마커를 이용하여 수집함으로써, 교정 데이터를 생성하는 단계와;상기 교정 데이터에 기초하여 상기 제1 신경망모델에 적용가능한 스케일 값과 오프셋 값을 결정하는 단계와;상기 스케일 값과 상기 오프셋 값에 기초하여, 정수 포맷의 양자화된 가중치 파라미터를 포함하는 제2 신경망모델을 상기 제1 신경망모델에 기초하여 생성하는 단계와;제1 재학습 데이터에 대한 상기 제1 신경망모델의 출력 값을 획득하는 단계와;상기 제1 신경망모델의 출력 값을 기준으로, 상기 제2 신경망모델에 대한 양자화 인식 재학습(quantization aware retraining)을 수행하여 상기 제2 신경망모델에 포함된 적어도 하나의 가중치 파라미터를 업데이트하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제2 신경망모델에 포함된 적어도 하나의 가중치 파라미터를 업데이트하는 단계는,상기 제2 신경망모델에 포함된 복수의 그래프 모듈들 각각에 대하여 경사 하강법(Gradient Descent)를 이용하여 파라미터 변화에 따른 손실(loss)이 최소가 되도록 상기 복수의 그래프 모듈들 각각의 파라미터를 업데이트하고,상기 손실은 상기 제2 신경망모델의 그래프 모듈에 대응되는 상기 제1 신경망모델의 그래프 모듈의 출력 값과 상기 제2 신경망모델의 그래프 모듈의 출력 값의 차이를 나타내는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제2 신경망모델에 대한 양자화 인식 재학습을 수행하는 각 단계에서, 현재 파라미터의 변화에 따른 손실 차이를 차감하여 상기 현재 파라미터를 업데이트하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제2 신경망모델에 대한 양자화 인식 재학습의 각 단계에서, 현재 파라미터의 변화 정도는 사용자 옵션 또는 재학습 수행 시간에 따라 결정되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 제2 신경망모델에 대한 양자화 인식 재학습은 상기 손실이 미리 정해진 임계값 내에 도달하거나, 미리 정해진 실행시간을 초과하는 경우 종료되도록 하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제2 신경망모델에 대한 양자화 인식 재학습을 수행하여, 상기 제2 신경망모델에 포함된 적어도 하나의 가중치 파라미터를 업데이트하는 단계는,상기 제2 신경망모델에 포함된 복수의 그래프 모듈들 각각에 추가된 양자화 모듈에 대응하여, 상기 복수의 그래프 모듈들 각각의 순방향 계산에 손실 변화 계산 함수를 추가하는 단계와;상기 복수의 그래프 모듈들 각각의 역방향 계산에서 각 파라미터의 변화에 따른 각 그래프 모듈의 출력 값을 확인하도록 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 손실 변화 계산 함수는 순방향 계산의 계산 결과에 영향을 미치지 않고, 역방향 계산에서 양자화 모듈에 포함된 라운드 및 클립 연산에 의해 제거된 원래 수식을 보존하도록 하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 손실 변화 계산 함수는 아래 입력 특징맵 파라미터에 대한 detach 함수와 가중치 파라미터에 대한 detach 함수로 표현되고,, 여기서,  는 그래프 모듈의 입력 특징맵 파라미터, 는 입력 특징맵 파라미터에 대한 스케일 값,  는 입력 특징맵 파라미터에 대한 오프셋 값,  는 그래프 모듈의 가중치 파라미터, 는 가중치 파라미터에 대한 스케일 값을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 제2 신경망모델에 대하여 양자화 인식 재학습을 수행하여, 상기 제2 신경망모델에 포함된 적어도 하나의 파라미터를 업데이트 하는 단계는,양자화 모듈이 추가된 그래프 모듈의 을 상기 손실 변화 계산 함수를 이용하여 로 치환하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 스케일 값과 상기 오프셋 값은 아래의 수학식에 의해서 구해지고, 여기서 max는 상기 교정 데이터로 수집된 상기 입력 값들과 출력 값들 중에서 최대 값을 의미하고, min은 상기 교정 데이터로 수집된 상기 입력 값들과 출력 값들 중에서 최소 값을 의미하고, bitwidth는 목표 양자화 비트폭을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 제1 신경망모델 내에 포함되는 합성곱 연산은 아래의 수학식으로 표현되고,여기서 feature_infp는 입력 특징맵 파라미터를 나타내고, weightfp는 가중치 파라미터를 나타내며, of는 입력 특징맵에 대한 오프셋 값을 나타내고, sf는 입력 특징맵에 대한 스케일 값을 나타내고, sw는 가중치에 대한 스케일 값을 나타내고, 는 라운드(Round) 및 클립(Clip) 연산을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 제2 신경망모델 내에 포함되는 합성곱 연산은 아래 수학식으로 표현되고,여기서 feature_outint는 출력 특징맵 파라미터를 나타내고, feature_inint는 입력 특징맵 파라미터를 나타내고, weightint는 가중치 파라미터를 나타내는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,상기 제1 신경망모델의 가중치 파라미터와 입력 특징맵 파라미터는 16비트 내지 32비트 길이를 갖는 부동소수점(floating point) 형태인, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,상기 제2 신경망모델은 2비트 내지 8비트 길이의 정수(INT) 포맷을 갖는 가중치 파라미터와 입력 특징맵 파라미터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 부동소수점 형태의 파라미터를 포함하는 제1 신경망모델을 기초로, 양자화를 수행하여 정수 형태의 파라미터를 포함하는 제2 신경망모델을 생성하는 단계와;재학습 데이터의 레이블 값을 기준으로, 상기 제1 신경망모델에 대한 재학습을 수행하는 단계와;상기 재학습 데이터에 대한 상기 제1 신경망모델의 출력 값을 기준으로, 상기 재학습 데이터를 이용하여 상기 제2 신경망모델에 대한 양자화 인식 재학습을 수행하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 제2 신경망모델에 대한 양자화 인식 재학습을 수행하는 단계는,상기 제2 신경망모델에 포함된 복수 개의 그래프 모듈 각각에 대하여, 상기 제2 신경망모델의 그래프 모듈에 대응되는 상기 제1 신경망모델의 그래프 모듈의 출력 값과 상기 제2 신경망모델의 그래프 모듈의 출력 값의 차이가 최소인 경우, 해당 그래프 모듈의 가중치 파라미터를 현재 가중치 파라미터로 업데이트하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 제1 신경망모델의 가중치 파라미터와 입력 특징맵 파라미터는 16비트 내지 32비트 길이를 갖는 부동소수점(floating point) 형태이고,상기 제2 신경망모델은 2비트 내지 8비트 길이의 정수(INT) 포맷을 갖는 가중치 파라미터와 입력 특징맵 파라미터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 제2 신경망모델에 대한 양자화 인식 재학습을 수행하여, 상기 제2 신경망모델에 포함된 적어도 하나의 가중치 파라미터를 업데이트하는 단계는,상기 제2 신경망모델에 포함된 복수의 그래프 모듈들 각각에 추가된 양자화 모듈에 대응하여, 상기 복수의 그래프 모듈들 각각의 순방향 계산에 손실 변화 계산 함수를 추가하는 단계와;상기 복수의 그래프 모듈들 각각의 역방향 계산에서 각 파라미터의 변화에 따른 각 그래프 모듈의 출력 값을 확인하도록 하는 단계를 포함하고,상기 손실 변화 계산 함수는 순방향 계산의 계산 결과에 영향을 미치지 않고, 역방향 계산에서 양자화 모듈에 포함된 라운드 및 클립 연산에 의해 제거된 원래 수식을 보존하도록 하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 손실 변화 계산 함수는 아래 입력 특징맵 파라미터에 대한 detach 함수와 가중치 파라미터에 대한 detach 함수로 표현되고,, 여기서,  는 그래프 모듈의 입력 특징맵 파라미터, 는 입력 특징맵 파라미터에 대한 스케일 값,  는 입력 특징맵 파라미터에 대한 오프셋 값,  는 그래프 모듈의 가중치 파라미터, 는 가중치 파라미터에 대한 스케일 값을 나타내며,양자화 모듈이 추가된 그래프 모듈의 을 상기 손실 변화 계산 함수를 이용하여 로 치환하는, 방법.</claim></claimInfo><claimInfo><claim>20. 명령어들을 기록하고 있는 비휘발성(non-volatile) 컴퓨터 판독가능 저장 매체로서, 상기 명령어들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금:일방향적 비 순환 그래프(DAG) 형태의 제1 신경망모델에 포함된 복수의 그래프 모듈들에 복수의 마커를 추가하는 단계와;상기 복수의 그래프 모듈들 각각의 입력 값과 출력 값을 상기 복수의 마커를 이용하여 수집함으로써, 교정 데이터를 생성하는 단계와;상기 교정 데이터에 기초하여 상기 제1 신경망모델에 적용가능한 스케일 값과 오프셋 값을 결정하는 단계와;상기 스케일 값과 상기 오프셋 값에 기초하여, 정수 포맷의 양자화된 가중치 파라미터를 포함하는 제2 신경망모델을 상기 제1 신경망모델에 기초하여 생성하는 단계와;제1 재학습 데이터에 대한 상기 제1 신경망모델의 출력 값을 획득하는 단계와;상기 제1 신경망모델의 출력 값을 기준으로, 상기 제1 신경망모델로부터 양자화를 수행한 제2 신경망모델에 대한 양자화 인식 재학습(quantization aware retraining)을 수행하여, 상기 제2 신경망모델에 포함된 적어도 하나의 가중치 파라미터를 업데이트하는 단계를 수행하도록 하는,비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>120180468784</code><country>대한민국</country><engName>DEEPX CO., LTD.</engName><name>주식회사 딥엑스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, You Jun</engName><name>김유준</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>KIM, Lok Won</engName><name>김녹원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 봉은사로 ***, *층(삼성동, 몽베르빌딩)</address><code>920251000411</code><country>대한민국</country><engName>Intellent IP Law Firm</engName><name>인텔런트특허법인</name></agentInfo><agentInfo><address>서울특별시 강남구 봉은사로 ***, *층(삼성동, 몽베르빌딩)(인텔런트특허법인)</address><code>920060016721</code><country>대한민국</country><engName>Yu, Sang-Geun</engName><name>유상근</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.04.25</receiptDate><receiptNumber>1-1-2024-0454765-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2024.04.25</receiptDate><receiptNumber>1-1-2024-0456041-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.02.26</receiptDate><receiptNumber>1-1-2025-0219345-72</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.03.25</receiptDate><receiptNumber>1-1-2025-0340132-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.07.23</receiptDate><receiptNumber>4-1-2025-5202493-10</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240055202.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9324f0ab33db7d39ad8d13b11164c03c376b4c88317aedeece5f92de9cdc2186ab3b595b5c426403cc4a06519bfe9867fad6e8ec8af5086bcd</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff0b851ef961ec9a7043fbec0edde55956418e9ad6ea660c4c5e8f5c9bd84cd7caa1cc4864ab30e7c47aa5296b663821174b500199f2ef2ff</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>