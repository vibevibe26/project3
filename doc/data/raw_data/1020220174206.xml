<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:27:57.2757</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0174206</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>합성 음성을 식별하는 전자 장치 및 그 제어 방법</inventionTitle><inventionTitleEng>A ELECTRONIC DEVICE FOR IDENTIFYING A  SYNTHETIC VOICE AND A CONTROL METHOD THEREOF</inventionTitleEng><openDate>2024.06.20</openDate><openNumber>10-2024-0088457</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 13/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/18</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치가 개시된다. 전자 장치는, 마이크 및 마이크를 통해 음성 데이터가 수신되면, 음성 데이터를 비의미적 특징 추출(Non-semantic feature extract) 모델에 입력하여 음성 데이터에 포함된 비의미적 특징을 획득하고, 비의미적 특징을 합성(Synthetic) 음성 분류 모델에 입력하여 음성 데이터를 합성 음성 또는 사용자 음성 중 어느 하나로 분류하며, 분류 결과를 제공하는 하나 이상의 프로세서를 포함하며, 합성 음성 분류 모델은, 비의미적 특징 추출 모델에 기초하여 전이 학습된(Transfer learned) 모델이다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 마이크; 및상기 마이크를 통해 음성 데이터가 수신되면,상기 음성 데이터를 비의미적 특징 추출(Non-semantic feature extract) 모델에 입력하여 상기 음성 데이터에 포함된 비의미적 특징을 획득하고,상기 비의미적 특징을 합성(Synthetic) 음성 분류 모델에 입력하여 상기 음성 데이터를 합성 음성 또는 사용자 음성 중 어느 하나로 분류하며,상기 분류 결과를 제공하는 하나 이상의 프로세서;를 포함하며,상기 합성 음성 분류 모델은,상기 비의미적 특징 추출 모델에 기초하여 전이 학습된(Transfer learned) 모델인, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 비의미적 특징은,상기 음성 데이터에 대응되는 특징 벡터를 포함하며,상기 하나 이상의 프로세서는,복수의 샘플 사용자 음성 중 제1 샘플 사용자 음성 및 제2 샘플 사용자 음성을 획득하고,상기 제1 샘플 사용자 음성으로부터 제1 부분 음성 및 제2 부분 음성을 획득하며,상기 제2 샘플 사용자 음성으로부터 제3 부분 음성을 획득하며,상기 제1 내지 제3 부분 음성 각각을 상기 비의미적 특징 추출 모델에 입력하여 상기 제1 내지 제3 부분 음성 각각에 대응되는 제1 내지 제3 특징 벡터를 획득하며,상기 제1 내지 제3 특징 벡터에 기초하여 감정 분류 손실(emotion classification loss) 및 유사도 손실(similarity loss)을 획득하며,상기 감정 분류 손실 및 상기 유사도 손실에 기초하여 상기 비의미적 특징 추출 모델을 업데이트하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 하나 이상의 프로세서는,상기 제1 특징 벡터 및 상기 제2 특징 벡터를 감정 분류기(emotion classifier)에 입력하여 상기 제1 특징 벡터에 대응되는 제1 예측 감정(predicted emotion) 및 상기 제2 특징 벡터에 대응되는 제2 예측 감정을 획득하며,상기 제1 예측 감정 및 상기 제2 예측 감정과 상기 제1 샘플 사용자 음성에 대응되는 제1 실제 감정(true emotion)에 기초하여 상기 감정 분류 손실을 획득하며,상기 감정 분류 손실에 대응되는 가중치에 기초하여 상기 감정 분류기를 업데이트하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 제1 예측 감정과 상기 제2 예측 감정은 동일한, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 하나 이상의 프로세서는,상기 제1 내지 제3 특징 벡터 간의 거리 정보에 기초하여 상기 유사도 손실을 획득하며,상기 감정 분류 손실 및 상기 유사도 손실의 집합(Aggregation)에 대응되는 가중치에 기초하여 상기 비의미적 특징 추출 모델을 업데이트하는, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 하나 이상의 프로세서는,상기 비의미적 특징 추출 모델 및 손실 함수(loss function)에 기초하여 상기 합성 음성 분류 모델을 전이 학습시키는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 하나 이상의 프로세서는,복수의 샘플 음성 데이터를 상기 비의미적 특징 추출 모델에 입력하여 상기 복수의 샘플 음성 데이터 각각에 대응되는 비의미적 특징을 획득하며,상기 복수의 샘플 음성 데이터 각각에 대응되는 비의미적 특징을 상기 합성 음성 분류 모델에 입력하여 상기 복수의 샘플 음성 데이터 각각을 상기 합성 음성 또는 상기 사용자 음성 중 어느 하나로 분류한 예측 결과를 획득하며,상기 손실 함수에 기초하여 상기 예측 결과와 실제 결과에 대응되는 크로스 엔트로피 손실(Cross entropy loss)을 획득하며,상기 크로스 엔트로피 손실에 기초하여 상기 합성 음성 분류 모델을 업데이트하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 복수의 샘플 음성 데이터는,복수의 샘플 사용자 음성 및 복수의 샘플 합성 음성을 포함하며,상기 실제 결과는,상기 복수의 샘플 음성 데이터 각각에 대응되는 실제 라벨(True label)에 기초하여 상기 복수의 샘플 음성 데이터 각각을 상기 합성 음성 또는 상기 사용자 음성으로 분류한 결과인, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 합성 음성 분류 모델은,상기 음성 데이터가 상기 합성 음성에 포함될 확률을 출력하며,상기 하나 이상의 프로세서는,상기 확률이 임계 확률을 초과하면, 상기 음성 데이터를 상기 합성 음성으로 분류하는, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 하나 이상의 프로세서는,상기 전자 장치에서 실행 중인 어플리케이션에 대응되는 보안 레벨에 기초하여 상기 임계 확률을 조정하며,상기 음성 데이터가 상기 합성 음성으로 분류되면, 노티를 제공하는, 전자 장치.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 비의미적 특징은,상기 음성 데이터에 대응되는 특징 벡터를 포함하며,상기 하나 이상의 프로세서는,상기 특징 벡터를 감정 분류기(emotion classifier)에 입력하여 상기 특징 벡터에 대응되는 예측 감정(predicted emotion)을 획득하며,상기 예측 감정에 대응되는 피드백을 제공하는, 전자 장치.</claim></claimInfo><claimInfo><claim>12. 전자 장치의 제어 방법에 있어서,음성 데이터를 비의미적 특징 추출(Non-semantic feature extract) 모델에 입력하여 상기 음성 데이터에 포함된 비의미적 특징을 획득하는 단계;비의미적 특징을 합성(Synthetic) 음성 분류 모델에 입력하여 상기 음성 데이터를 합성 음성 또는 사용자 음성 중 어느 하나로 분류하는 단계; 및상기 분류 결과를 제공하는 단계;를 포함하는 제어 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 비의미적 특징은,상기 음성 데이터에 대응되는 특징 벡터를 포함하며,복수의 샘플 사용자 음성 중 제1 샘플 사용자 음성 및 제2 샘플 사용자 음성을 획득하는 단계;상기 제1 샘플 사용자 음성으로부터 제1 부분 음성 및 제2 부분 음성을 획득하는 단계;상기 제2 샘플 사용자 음성으로부터 제3 부분 음성을 획득하는 단계;상기 제1 내지 제3 부분 음성 각각을 상기 비의미적 특징 추출 모델에 입력하여 상기 제1 내지 제3 부분 음성 각각에 대응되는 제1 내지 제3 특징 벡터를 획득하는 단계;상기 제1 내지 제3 특징 벡터에 기초하여 감정 분류 손실(emotion classification loss) 및 유사도 손실(similarity loss)을 획득하는 단계; 및상기 감정 분류 손실 및 상기 유사도 손실에 기초하여 상기 비의미적 특징 추출 모델을 업데이트하는 단계;를 더 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 감정 분류 손실 및 상기 유사도 손실을 획득하는 단계는,상기 제1 특징 벡터 및 상기 제2 특징 벡터를 감정 분류기(emotion classifier)에 입력하여 상기 제1 특징 벡터에 대응되는 제1 예측 감정(predicted emotion) 및 상기 제2 특징 벡터에 대응되는 제2 예측 감정을 획득하는 단계;상기 제1 예측 감정 및 상기 제2 예측 감정과 상기 제1 샘플 사용자 음성에 대응되는 제1 실제 감정(true emotion)에 기초하여 상기 감정 분류 손실을 획득하는 단계; 및상기 감정 분류 손실에 대응되는 가중치에 기초하여 상기 감정 분류기를 업데이트하는 단계;를 더 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 제1 예측 감정과 상기 제2 예측 감정은 동일한, 제어 방법..</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 감정 분류 손실 및 상기 유사도 손실을 획득하는 단계는,상기 제1 내지 제3 특징 벡터 간의 거리 정보에 기초하여 상기 유사도 손실을 획득하는 단계;를 포함하며,상기 업데이트하는 단계는,상기 감정 분류 손실 및 상기 유사도 손실의 집합(Aggregation)에 대응되는 가중치에 기초하여 상기 비의미적 특징 추출 모델을 업데이트하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서,상기 비의미적 특징 추출 모델 및 손실 함수(loss function)에 기초하여 상기 합성 음성 분류 모델을 전이 학습시키는 단계;를 더 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 학습시키는 단계는,복수의 샘플 음성 데이터를 상기 비의미적 특징 추출 모델에 입력하여 상기 복수의 샘플 음성 데이터 각각에 대응되는 비의미적 특징을 획득하는 단계;상기 복수의 샘플 음성 데이터 각각에 대응되는 비의미적 특징을 상기 합성 음성 분류 모델에 입력하여 상기 복수의 샘플 음성 데이터 각각을 상기 합성 음성 또는 상기 사용자 음성 중 어느 하나로 분류한 예측 결과를 획득하는 단계;상기 손실 함수에 기초하여 상기 예측 결과와 실제 결과에 대응되는 크로스 엔트로피 손실(Cross entropy loss)을 획득하는 단계; 및상기 크로스 엔트로피 손실에 기초하여 상기 합성 음성 분류 모델을 업데이트하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 복수의 샘플 음성 데이터는,복수의 샘플 사용자 음성 및 복수의 샘플 합성 음성을 포함하며,상기 실제 결과는,상기 복수의 샘플 음성 데이터 각각에 대응되는 실제 라벨(True label)에 기초하여 상기 복수의 샘플 음성 데이터 각각을 상기 합성 음성 또는 상기 사용자 음성으로 분류한 결과인, 제어 방법.</claim></claimInfo><claimInfo><claim>20. 제12항에 있어서,상기 합성 음성 분류 모델은,상기 음성 데이터가 상기 합성 음성에 포함될 확률을 출력하며,상기 분류하는 단계는,상기 확률이 임계 확률을 초과하면, 상기 음성 데이터를 상기 합성 음성으로 분류하는 단계;를 포함하는, 제어 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>우크라이나 키예프 ***...</address><code> </code><country> </country><engName>SOKOL, Oleksandra</engName><name>소콜 올렉산드라</name></inventorInfo><inventorInfo><address>우크라이나 키예프 ***...</address><code> </code><country> </country><engName>PROGONOV, Dmytro</engName><name>프로고노프 드미트로</name></inventorInfo><inventorInfo><address>우크라이나 키예프 ***...</address><code> </code><country> </country><engName>NAUMENKO, Heorhii</engName><name>나우멘코 헤오르히</name></inventorInfo><inventorInfo><address>우크라이나 키예프 ***...</address><code> </code><country> </country><engName>VOLOBUIEV, Kostiantyn</engName><name>볼로부예프 코스티안틴</name></inventorInfo><inventorInfo><address>우크라이나 키예프 ***...</address><code> </code><country> </country><engName>KUZNETSOV, Vasyl</engName><name>쿠즈네트소프 바실</name></inventorInfo><inventorInfo><address>우크라이나 키예프 ***...</address><code> </code><country> </country><engName>DERKACH, Viacheslav</engName><name>데르카흐 비아체슬라프</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.13</receiptDate><receiptNumber>1-1-2022-1341883-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>접수중 (On receiving) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.16</receiptDate><receiptNumber>1-1-2025-1156411-11</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220174206.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936925b075a6e23cc97c1f71136394ad0587fc0923e0b102aceb65280fbb7616c1923de348eb403c1e7e488b605025c1b3e8bf1cbc53c8a3e2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf28dccbef02564c51e41ada19de52b6958dcb0440f96df304a41de7aeeb6ab6e1018821f2a8ab634439e35a6e9a9f1b84e03ca4d10602ab41</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>