<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:50.450</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.05.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7038087</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>공간과 시간에 따른 어텐션을 이용한 비디오 시퀀스에서 객체 표현에 대한 비지도 학습</inventionTitle><inventionTitleEng>UNSUPERVISED LEARNING OF OBJECT REPRESENTATIONS FROM VIDEO SEQUENCES USING ATTENTION OVER SPACE AND TIME</inventionTitleEng><openDate>2023.12.07</openDate><openNumber>10-2023-0167086</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.03</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.11.03</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 컴퓨터로 구현된 비디오 생성 신경망 시스템은 객체 잠재 변수에 대한 각각의 이전 객체 잠재 분포로부터 샘플링함으로써 객체 잠재 변수 세트 각각에 대한 값을 결정하도록 구성된다. 시스템은 각각의 생성된 이미지 프레임의 각 픽셀과 각각의 생성된 이미지 프레임 시간 단계에 대해, 객체 잠재 변수 각각에 대한 픽셀 분포의 파라미터를 결정하기 위해 상기 결정된 객체 잠재 변수의 값을 처리하고, 결합된 픽셀 분포를 결정하기 위해 각각의 객체 잠재 변수에 대한 픽셀 분포를 결합하고, 픽셀과 시간 단계에 대한 값을 결정하기 위해 상기 결합된 픽셀 분포로부터 샘플링하도록 구성된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.12.01</internationOpenDate><internationOpenNumber>WO2022248712</internationOpenNumber><internationalApplicationDate>2022.05.27</internationalApplicationDate><internationalApplicationNumber>PCT/EP2022/064484</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 객체 표현 신경망 시스템을 트레이닝하는 컴퓨터 구현 방법으로서, 비디오 객체 표현 신경망 시스템은, 각각이 계층 입력에 대해 셀프-어텐션 메커니즘을 적용하도록 구성되고 복수의 셀프-어텐션 신경망 파라미터를 갖는, 하나 이상의 셀프-어텐션 계층을 포함하는 셀프-어텐션 신경망을 포함하고, 상기 방법은,연속된 시간마다 하나씩, T개의 이미지 프레임의 시퀀스를 포함하는 비디오 시퀀스를 획득하는 단계와;T개의 이미지 프레임 각각에 대한 S개의 공간 인코딩 세트를 생성함으로써 비디오 시퀀스에 대한 S×T개의 공간 인코딩 그룹을 획득하도록 각각의 이미지 프레임을 처리하는 단계와, 상기 이미지 프레임의 각 공간 인코딩은 이미지 프레임의 개별 영역의 인코딩을 포함하고;이미지 프레임 시간 및 이미지 프레임 영역에 각각 대응하는 변환된 공간 인코딩 그룹을 생성하기 위해 S×T 공간 인코딩 그룹을 포함하는 계층 입력에 셀프-어텐션 메커니즘을 적용함으로써 셀프-어텐션 신경망을 사용하여 S×T 공간 인코딩 그룹을 처리하는 단계와, 상기 계층 입력에 셀프-어텐션 메커니즘을 적용하는 것은 상이한 이미지 프레임의 공간 인코딩에 셀프-어텐션 메커니즘을 적용하는 것을 포함하고;객체 잠재 변수 세트 각각에 대해, 이미지 프레임의 시간에 걸쳐 상기 변환된 공간 인코딩의 그룹을 집계함으로써 객체 잠재 변수의 객체 잠재 분포를 파라미터화하는 하나 이상의 값을 결정하는 단계와;객체 잠재 변수에 대한 객체 잠재 분포로부터 샘플링함으로써 객체 잠재 변수 세트 각각에 대한 값을 결정하는 단계와;이미지 프레임의 디코딩된 시퀀스를 생성하기 위해 상기 결정된 객체 잠재 변수의 값을 처리하는 단계와; 그리고i) T개의 이미지 프레임의 시퀀스와 이미지 프레임의 디코딩된 시퀀스 사이의 차이의 측정값 및 ii) 각 객체 잠재 분포와 이전 객체 잠재 분포 사이의 차이에 따라 목적 함수를 최적화하기 위해 적어도 셀프-어텐션 신경망 파라미터의 값을 조정함으로써 시스템을 트레이닝하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,프레임 잠재 변수 세트 각각에 대해, 이미지 프레임 영역에 걸쳐 상기 변환된 공간 인코딩 그룹을 집계함으로써 프레임 잠재 변수의 프레임 잠재 변수 분포를 파라미터화하는 하나 이상의 값을 결정하는 단계와;프레임 잠재 변수에 대한 프레임 잠재 분포로부터 샘플링함으로써 프레임 잠재 변수 세트 각각에 대한 값을 결정하는 단계를 더 포함하고,상기 이미지 프레임의 디코딩된 시퀀스를 생성하는 단계는 이미지 프레임의 디코딩된 시퀀스를 생성하기 위해 상기 결정된 프레임 잠재 변수의 값을 처리하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 시스템을 트레이닝하는 단계는,각 프레임 잠재 분포와 이전 프레임 잠재 분포 사이의 차이에 따라 목적 함수를 최적화하기 위해 적어도 셀프-어텐션 신경망 파라미터의 값을 조정하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 임의의 선행하는 항에 있어서,각 공간 인코딩은 이미지 프레임의 개별 영역의 특징 맵을 포함하고, 상기 T개의 이미지 프레임 각각에 대한 S개의 공간 인코딩 세트를 생성하기 위해 각각의 이미지 프레임을 처리하는 단계는,이미지 프레임의 각 영역에 대한 특징 맵을 생성하기 위해 복수의 특징 추출 신경망 파라미터를 갖는 특징 추출 신경망을 사용하여 이미지 프레임 각각을 처리하는 단계를 포함하고, 상기 시스템을 트레이닝하는 단계는 특징 추출 신경망 파라미터의 값을 조정하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 임의의 선행하는 항에 있어서,이미지 프레임의 디코딩된 시퀀스를 생성하기 위해 복수의 이미지 프레임 디코더 신경망 파라미터를 갖는 이미지 프레임 디코더 신경망을 사용하여 상기 결정된 객체 잠재 변수의 값을 처리하는 단계를 포함하고, 그리고상기 시스템을 트레이닝하는 단계는 이미지 프레임 디코더 신경망 파라미터의 값을 조정하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 이미지 프레임의 디코딩된 시퀀스는 연속적인 디코딩된 이미지 프레임 시간 단계 각각에 대한 이미지 프레임을 포함하고, 그리고상기 이미지 프레임의 디코딩된 시퀀스를 생성하기 위해 이미지 프레임 디코더 신경망을 사용하는 것은,각 디코딩된 이미지 프레임의 각 픽셀과 각 디코딩된 이미지 프레임 시간 단계에 대해: 이미지 프레임 디코더 신경망을 사용하여, 픽셀 및 시간 단계에 대해, 객체 잠재 변수 각각에 대한 픽셀 분포의 파라미터를 결정하기 위해 결정된 객체 잠재 변수의 값, 픽셀의 위치를 지정하는 정보 및 시간 단계를 지정하는 정보를 처리하는 것; 결합된 픽셀 분포를 결정하기 위해 객체 잠재 변수 각각에 대한 픽셀 분포를 결합하는 것; 및 픽셀과 시간 단계에 대한 값을 결정하기 위해 상기 결합된 픽셀 분포로부터 샘플링하는 것을 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,각 디코딩된 이미지 프레임의 각 픽셀과 각 디코딩된 이미지 프레임 시간 단계에 대해:이미지 프레임 디코더 신경망을 사용하여, 픽셀 및 시간 단계에 대해, 객체 잠재 변수 각각에 대한 혼합 가중치를 결정하기 위해, 객체 잠재변수의 결정된 값, 픽셀의 위치를 지정하는 정보 및 시간 단계를 지정하는 정보를 처리하는 단계를 더 포함하고, 그리고상기 결합된 픽셀 분포를 결정하기 위해 객체 잠재 변수 각각에 대한 픽셀 분포를 결합하는 것은 개별 혼합 가중치에 의해 가중된 각각의 객체 잠재 변수에 대한 픽셀 분포를 결합하는 것을 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제5항, 제6항 또는 제7항에 있어서,비디오 시퀀스의 하나 이상의 객체 또는 하나 이상의 객체에 대한 객체 속성을 정의하거나 뷰포인트 위치 또는 방향을 정의하는 조건화 입력을 획득하는 단계와; 그리고셀프-어텐션 신경망과 이미지 프레임 디코더 신경망에 조건화 입력을 제공하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 임의의 선행하는 항에 있어서,상기 어텐션 신경망을 사용하여 S×T 공간 인코딩 그룹을 처리하는 단계는,각 공간 인코딩에 대한 쿼리 및 키-값 쌍을 생성하기 위해 하나 이상의 셀프-어텐션 계층 중 하나를 사용하여 S×T 공간 인코딩 그룹을 포함하는 계층 입력을 처리하는 단계와, 그리고 변환된 공간 인코딩 그룹을 결정하기 위해 키-값 쌍에 쿼리를 적용하도록 셀프-어텐션 메커니즘을 사용하는 단계를 포함하고, 그리고상기 셀프-어텐션 신경망 파라미터는 쿼리 및 키-값 쌍을 생성하기 위해 계층 입력에 적용된 학습된 변환의 파라미터를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 임의의 선행하는 항에 있어서,상기 어텐션 신경망을 사용하여 S×T 공간 인코딩 그룹을 처리하는 단계는,제1 셀프-어텐션 계층 출력을 생성하기 위해 어텐션 신경망의 제1 셀프-어텐션 계층에 대한 계층 입력으로 S×T 공간 인코딩 그룹을 제공하는 단계와; 그리고변환된 공간 인코딩 그룹을 생성하기 위해 어텐션 신경망의 제2 셀프-어텐션 계층에 제1 셀프-어텐션 계층 출력을 제공하는 단계로서, S×T 공간 인코딩으로부터 K×T 공간 인코딩으로 공간 인코딩 수를 감소시키는 단계를 포함하고, 여기서 K는 객체 잠재 변수의 수이고 K는 S보다 작은 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 감소시키는 단계는,제1 셀프-어텐션 계층 출력에 풀링 연산을 적용하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 임의의 선행하는 항에 있어서,상기 시스템을 트레이닝하는 단계는,이미지 프레임의 디코딩된 시퀀스를 생성하는 이미지 프레임 디코더 신경망, 셀프-어텐션 신경망, 및 공간 인코딩 세트를 생성하는 특징 추출 신경망을 통해 목적 함수의 기울기를 역전파하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서,객체 잠재 변수로부터 또는 객체 잠재 분포를 파라미터화하는 값으로부터 비디오 시퀀스에 묘사된 하나 이상의 객체의 하나 이상의 속성을 획득하기 위해 상기 트레이닝된 비디오 객체 표현 신경망 시스템을 사용하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>14. 제2항에 종속된 제2항 내지 제13항 중 어느 한 항에 있어서,프레임 잠재 변수로부터 또는 프레임 잠재 분포를 파라미터화하는 값으로부터, 비디오 시퀀스에 대한 뷰포인트의 위치 또는 방향을 획득하기 위해 상기 트레이닝된 비디오 객체 표현 신경망 시스템을 사용하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제12항 중 어느 한 항에 있어서,새로운 이미지 프레임의 디코딩된 시퀀스를 포함하는 새로운 비디오 시퀀스를 생성하기 위해 상기 트레이닝된 비디오 객체 표현 신경망 시스템을 사용하는 단계를 더 포함하며, 이 단계는, 객체 잠재 변수에 대한 이전 객체 잠재 분포로부터 샘플링함으로써 객체 잠재 변수 세트 각각에 대한 값을 결정하는 단계; 및 새로운 이미지 프레임의 디코딩된 시퀀스를 생성하기 위해 상기 결정된 객체 잠재 변수의 값을 처리하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>16. 제2항에 종속된 제15항에 있어서,프레임 잠재 변수에 대한 이전 프레임 잠재 분포로부터 샘플링함으로써 프레임 잠재 변수 세트 각각에 대한 값을 결정하는 단계와; 그리고새로운 이미지 프레임의 디코딩된 시퀀스를 생성하기 위해 상기 결정된 객체 잠재 변수의 값과 상기 결정된 프레임 잠재 변수의 값을 처리하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제12항 중 어느 한 항에 있어서,수정된 이미지 프레임의 디코딩된 시퀀스를 포함하는 수정된 비디오 시퀀스를 생성하기 위해 상기 트레이닝된 비디오 객체 표현 신경망 시스템을 사용하는 단계를 더 포함하며, 이 단계는, 입력 이미지 프레임의 시퀀스를 포함하는 입력 비디오 시퀀스를 획득하는 단계; 입력 비디오 시퀀스에 대한 공간 인코딩 그룹을 획득하기 위해 입력 이미지 프레임 각각을 처리하는 단계; 변환된 공간 인코딩 그룹을 생성하기 위해 어텐션 신경망을 사용하여 입력 비디오 시퀀스에 대한 공간 인코딩 그룹을 처리하는 단계; 변환된 공간 인코딩 그룹으로부터 결정된 객체 잠재 분포로부터 샘플링함으로써 객체 잠재 변수 세트에 대한 값을 결정하는 단계; 수정된 잠재 변수 세트를 획득하기 위해 상기 결정된 객체 잠재 변수 세트에 대한 값을 수정하는 단계; 및 수정된 이미지 프레임의 디코딩된 시퀀스를 생성하기 위해 상기 수정된 잠재 변수 세트를 처리하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>18. 제2항에 종속된 제17항에 있어서,변환된 공간 인코딩 그룹으로부터 결정된 프레임 잠재 분포로부터 샘플링함으로써 프레임 잠재 변수 세트에 대한 값을 결정하는 단계;수정된 잠재 변수 세트를 획득하기 위해 상기 결정된 프레임 잠재 변수 세트에 대한 값을 수정하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>19. 제1항 내지 제10항 중 어느 한 항에 있어서,환경과 상호작용하는 동안 태스크를 수행하도록 에이전트를 제어하기 위해 상기 트레이닝된 비디오 객체 표현 신경망 시스템을 사용하는 단계를 더 포함하고, 상기 방법은,환경의 현재 상태를 특징짓는 관찰을 획득하는 단계와, 상기 관찰은 관찰 비디오 시퀀스를 포함하고;객체 잠재 분포를 파라미터화하는 값을 획득하기 위해 관찰 비디오 시퀀스를 처리하도록 상기 트레이닝된 비디오 객체 표현 신경망 시스템을 사용하는 단계와;제어 시스템을 사용하여, 제어 출력을 생성하기 위해 객체 잠재 분포를 파라미터화하는 값으로부터의 데이터를 처리하는 것을 포함하여 관찰로부터 데이터를 처리하는 단계와; 그리고제어 출력을 사용한 관찰에 응답하여 에이전트에 의해 수행될 액션을 선택하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>20. 하나 이상의 컴퓨터에 의해 실행될 때 하나 이상의 컴퓨터로 하여금 제1항 내지 제19항 중 어느 한 항의 방법의 개별 동작을 수행하게 하는 명령들을 저장한 하나 이상의 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>21. 하나 이상의 컴퓨터 및 하나 이상의 컴퓨터에 의해 실행될 때 하나 이상의 컴퓨터로 하여금 제1항 내지 제19항 중 어느 한 항의 개별 동작을 수행하게 하는 명령들을 저장한 하나 이상의 저장 디바이스를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>22. 컴퓨터로 구현된 비디오 처리 신경망 시스템으로서, 연속된 시간마다 하나씩, T개의 이미지 프레임의 시퀀스를 포함하는 비디오 시퀀스를 수신하고, T개의 이미지 프레임 각각에 대한 S개의 공간 인코딩 세트를 생성함으로써 비디오 시퀀스에 대한 S×T개의 공간 인코딩 그룹을 획득하기 위해 각각의 이미지 프레임을 처리하도록 구성된,트레이닝된 특징 추출 신경망과, 각각의 공간 인코딩은 이미지 프레임의 개별 영역의 인코딩을 포함하고;각각이 계층 입력에 셀프-어텐션 메커니즘을 적용하도록 구성된 하나 이상의 셀프-어텐션 계층을 포함하는 트레이닝된 셀프-어텐션 신경망과, 상기 셀프-어텐션 신경망은,  이미지 프레임 시간 및 이미지 프레임 영역에 각각 대응하는 변환된 공간 인코딩 그룹을 생성하기 위해 S×T 공간 인코딩 그룹을 포함하는 계층 입력에 셀프-어텐션 메커니즘을 적용함으로써 셀프-어텐션 신경망을 사용하여 S×T 공간 인코딩 그룹을 처리하도록 구성되고, 상기 계층 입력에 셀프-어텐션 메커니즘을 적용하는 것은 상이한 이미지 프레임의 공간 인코딩에 셀프-어텐션 메커니즘을 적용하는 것을 포함하고; 그리고상기 비디오 처리 신경망 시스템은,객체 잠재 변수 세트 각각에 대해, 이미지 프레임의 시간에 걸쳐 상기 변환된 공간 인코딩 그룹을 집계함으로써 객체 잠재 변수의 객체 잠재 분포를 파라미터화하는 하나 이상의 값을 결정하고, 그리고 객체 잠재 분포를 파라미터화하는 값으로부터 비디오 시퀀스에 묘사된 하나 이상의 객체의 하나 이상의 속성을 결정하도록 구성되는 것을 특징으로 하는 컴퓨터로 구현된 비디오 처리 신경망 시스템. </claim></claimInfo><claimInfo><claim>23. 컴퓨터로 구현된 비디오 생성 신경망 시스템으로서,객체 잠재 변수에 대한 각각의 이전 객체 잠재 분포로부터 샘플링함으로써 객체 잠재 변수 세트 각각에 대한 값을 결정하도록 구성되고;상기 시스템은,연속적인 시간 단계에서 생성된 이미지 프레임의 시퀀스를 포함하는 비디오 시퀀스를 생성하기 위해 상기 결정된 객체 잠재 변수의 값을 처리하는 트레이닝된 이미지 프레임 디코더 신경망을 포함하고, 상기 이미지 프레임 디코더 신경망은, 각각의 생성된 이미지 프레임의 각 픽셀과 각각의 생성된 이미지 프레임 시간 단계에 대해: 셀 및 시간 단계에 대해, 객체 잠재 변수 각각에 대한 픽셀 분포의 파라미터를 결정하기 위해 상기 결정된 객체 잠재 변수의 값, 픽셀의 위치를 지정하는 정보, 및 시간 단계를 지정하는 정보를 처리하고; 결합된 픽셀 분포를 결정하기 위해 각각의 객체 잠재 변수에 대한 픽셀 분포를 결합하고; 그리고 픽셀과 시간 단계에 대한 값을 결정하기 위해 상기 결합된 픽셀 분포로부터 샘플링하도록 구성되는 것을 특징으로 하는 컴퓨터로 구현된 비디오 생성 신경망 시스템.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 이미지 프레임 디코더 신경망은,각각의 디코딩된 이미지 프레임의 각 픽셀과 각각의 디코딩된 이미지 프레임 시간 단계에 대해: 픽셀 및 시간 단계에 대해, 객체 잠재 변수 각각에 대한 혼합 가중치를 결정하기 위해 상기 결정된 객체 잠재 변수의 값, 픽셀의 위치를 지정하는 정보, 시간 단계를 지정하는 정보를 처리하고; 그리고 결합된 픽셀 분포를 결정하기 위해 개별 혼합 가중치에 의해 가중된 각각의 객체 잠재 변수에 대한 픽셀 분포를 결합하도록 구성되는 것을 특징으로 하는 컴퓨터로 구현된 비디오 생성 신경망 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>영국 런던 이씨*에이 *티더블유 뉴 스트리트 스퀘어 *</address><code>520170032411</code><country>영국</country><engName>DeepMind Technologies Limited</engName><name>딥마인드 테크놀로지스 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>KABRA, Rishabh</engName><name>카브라 리샤브</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>ZORAN, Daniel</engName><name>조란 다니엘</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>ERDOGAN, Goker</engName><name>에르도안 고커</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>CRESWELL, Antonia Phoebe Nina</engName><name>크레스웰 안토니아 피비 니나</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>MATTHEY-DE-L'ENDROIT, Loic</engName><name>매티-데-렌드로이트 로익</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>BOTVINICK, Matthew</engName><name>보트비닉 매튜</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>LERCHNER, Alexander</engName><name>러치너 알렉산더</name></inventorInfo><inventorInfo><address>영국 펄리 씨알*...</address><code> </code><country> </country><engName>BURGESS, Christopher Paul</engName><name>버제스 크리스토퍼 폴</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.05.28</priorityApplicationDate><priorityApplicationNumber>63/194,849</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.11.03</receiptDate><receiptNumber>1-1-2023-1217335-23</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.11.08</receiptDate><receiptNumber>1-5-2023-0178136-54</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237038087.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93440cbd099c584ca6a38cf670011877138502113ddcbbca51b7ec041efda8f8dc80c2027583f620691a4d392f010a3092b4ea0d15715f3f0f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1806e0359c158ae896c07e1ac25774027c58a476ac59e8dae253431057d2078e99c0d3027a6174641c9fe629c8df1ffe77f1b71e77a8a2d3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>