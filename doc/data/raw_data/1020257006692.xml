<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:22:40.2240</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7006692</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>미디어 항목에서 제품의 식별</inventionTitle><inventionTitleEng>PRODUCT IDENTIFICATION IN MEDIA ITEMS</inventionTitleEng><openDate>2025.03.27</openDate><openNumber>10-2025-0042826</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.02.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/783</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/78</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법은 콘텐츠 항목의 제1 메타데이터에 기초하여 콘텐츠 항목과 연관하여 결정된 제1 제품의 제1 식별자를 포함하는 제1 데이터를 획득하는 단계를 포함한다. 방법은 콘텐츠 항목 및 제1 제품과 연관된 제1 신뢰도 값을 획득하는 단계를 추가로 포함한다. 방법은 제1 제품의 제2 식별자와 제2 신뢰도 값을 포함하는 제2 데이터를 획득하는 단계를 추가로 포함한다. 방법은 제1 데이터와 제2 데이터를 훈련된 기계 학습 모델에 제공하는 단계를 추가로 포함한다. 방법은 제1 제품과 연관된 훈련된 기계 학습 모델로부터 제3 신뢰도 값을 획득하는 단계를 추가로 포함한다. 방법은 제3 신뢰도 값을 고려하여 콘텐츠 항목의 제2 메타데이터를 조정하는 단계를 추가로 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.02.08</internationOpenDate><internationOpenNumber>WO2024030387</internationOpenNumber><internationalApplicationDate>2023.07.31</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/029139</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서, 처리 디바이스에 의해 (i) 콘텐츠 항목의 제1 메타데이터에 기초하여 상기 콘텐츠 항목과 연관하여 결정된 제1 제품의 제1 식별자, 및 (ii) 상기 콘텐츠 항목 및 상기 제1 제품과 연관된 제1 신뢰도 값을 포함하는 제1 데이터를 획득하는 단계;상기 처리 디바이스에 의해 (i) 상기 콘텐츠 항목의 제1 이미지 데이터에 기초하여 상기 콘텐츠 항목과 연관하여 결정된 상기 제1 제품의 제2 식별자, 및 (ii) 상기 콘텐츠 항목 및 상기 제1 제품과 연관된 제2 신뢰도 값을 포함하는 제2 데이터를 획득하는 단계;상기 처리 디바이스에 의해 상기 제1 데이터와 상기 제2 데이터를 훈련된 기계 학습 모델에 제공하는 단계;상기 훈련된 기계 학습 모델로부터 상기 제1 제품과 연관된 제3 신뢰도 값을 획득하는 단계; 및상기 제3 신뢰도 값을 고려하여 상기 콘텐츠 항목과 연관된 제2 메타데이터를 조정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서, 상기 콘텐츠 항목의 제1 메타데이터를 제2 모델에 대한 입력으로 제공하는 단계; 및상기 제2 모델의 출력으로 상기 제1 데이터를 획득하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 청구항 2에 있어서, 상기 제1 메타데이터는, 상기 콘텐츠 항목의 제목(title);상기 콘텐츠 항목의 설명; 또는상기 콘텐츠 항목과 연관된 캡션(caption) 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 1에 있어서, 상기 콘텐츠 항목의 제1 이미지 데이터를 제2 모델에 대한 입력으로 제공하는 단계;상기 제2 모델의 출력으로 제1 차원 축소된 데이터(dimensionally reduced data)를 획득하는 단계; 및데이터 저장소로부터 상기 제1 제품과 연관된 제2 차원 축소된 데이터를 획득하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 4에 있어서, 상기 제2 차원 축소된 데이터는 상기 제1 데이터를 획득한 것에 응답하여 상기 데이터 저장소로부터 획득되고, 상기 제2 데이터는 적어도 상기 제1 차원 축소된 데이터와 상기 제2 차원 축소된 데이터에 기초하여 생성되는, 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 4에 있어서, 제2 이미지 데이터를 제3 모델에 제공하는 단계; 및상기 제3 모델로부터 상기 제1 제품의 제3 식별자를 획득하는 단계를 추가로 포함하고, 상기 제2 차원 축소된 데이터는 상기 제1 제품의 제3 식별자를 획득한 것에 응답하여 상기 데이터 저장소로부터 획득되고, 상기 제2 데이터는 적어도 상기 제1 차원 축소된 데이터와 상기 제2 차원 축소된 데이터에 기초하여 생성되는, 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 1에 있어서, 상기 콘텐츠 항목은 비디오이고, 상기 제1 데이터는 상기 제품과 연관된 비디오의 하나 이상의 프레임의 타임스탬프의 지시(indication)를 추가로 포함하고, 상기 제2 메타데이터를 조정하는 단계는 상기 제2 메타데이터에 상기 타임스탬프의 지시와 상기 제1 제품의 지시를 포함하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 청구항 1에 있어서, 상기 제2 메타데이터를 조정하는 단계는 상기 제품과 연관된 캡션을 조정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 1에 있어서, 상기 훈련된 기계 학습 모델을 생성하기 위해 기계 학습 모델을 훈련하는 단계를 추가로 포함하고, 상기 기계 학습 모델을 훈련하는 단계는, 복수의 콘텐츠 항목과 연관된 이미지 기반 제품 데이터를 수신하는 단계 - 상기 이미지 기반 제품 데이터는 하나 이상의 제품 이미지 신뢰도 값과 이미지에서 검출된 하나 이상의 제품의 지시를 포함함 -;상기 복수의 콘텐츠 항목과 연관된 메타데이터 기반 제품 데이터를 수신하는 단계 - 상기 메타데이터 기반 제품 데이터는 하나 이상의 신뢰도 값과 텍스트에서 검출된 하나 이상의 제품의 지시를 포함함 -;상기 복수의 콘텐츠 항목에 포함된 제품을 나타내는 데이터를 수신하는 단계;상기 이미지 기반 제품 데이터와 상기 메타데이터 기반 제품 데이터를 훈련 입력으로 상기 기계 학습 모델에 제공하는 단계; 및상기 복수의 콘텐츠 항목에 포함된 제품을 나타내는 데이터를 목표 출력으로 상기 기계 학습 모델에 제공하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 1에 있어서,상기 콘텐츠 항목과 연관된 제1 제품 카테고리의 제3 식별자를 포함하는 제3 데이터를 수신하는 단계; 및상기 제3 데이터를 상기 훈련된 기계 학습 모델에 제공하는 단계 - 상기 제3 신뢰도 값은 상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터에 기초하여 생성됨 -를 추가로 포함하는, 방법. </claim></claimInfo><claimInfo><claim>11. 방법으로서, 처리 디바이스에 의해 콘텐츠 항목과 연관된 제1 메타데이터를 획득하는 단계;상기 제1 메타데이터를 제1 모델에 제공하는 단계;상기 제1 메타데이터에 기초한 제1 제품 식별자와, 상기 제1 제품 식별자와 연관된 제1 신뢰도 값을 상기 제1 모델의 출력으로 획득하는 단계;상기 콘텐츠 항목의 이미지 데이터를 획득하는 단계;상기 이미지 데이터를 제2 모델에 제공하는 단계;상기 이미지 데이터에 기초한 제2 제품 식별자와, 상기 제2 제품 식별자와 연관된 제2 신뢰도 값을 상기 제2 모델의 출력으로서 획득하는 단계;제3 모델에 대한 입력으로  상기 제1 제품 식별자, 상기 제1 신뢰도 값, 상기 제2 제품 식별자, 및 상기 제2 신뢰도 값 을 포함하는 데이터를 제공하는 단계;제3 제품 식별자와 제3 신뢰도 값을 상기 제3 모델의 출력으로 획득하는 단계; 및상기 제3 제품 식별자와 상기 제3 신뢰도 값을 고려하여 상기 콘텐츠 항목과 연관된 제2 메타데이터를 조정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 청구항 11에 있어서, 상기 제2 신뢰도 값을 생성하는 동작은, 상기 이미지 데이터의 차원을 줄여서 제1 차원 축소된 데이터를 생성하는 동작;데이터 저장소로부터 제2 차원 축소된 데이터를 획득하는 동작 - 상기 제2 차원 축소된 데이터는 상기 제2 제품 식별자에 의해 지시된 제품과 연관됨 -; 및상기 제2 신뢰도 값을 생성하기 위한 하나 이상의 동작을 수행하는 동작 - 상기 제2 신뢰도 값은 상기 제1 차원 축소된 데이터와 상기 제2 차원 축소된 데이터 사이의 하나 이상의 차이에 기초함 -을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 청구항 11에 있어서, 상기 제1 제품 식별자, 상기 제2 제품 식별자 및 상기 제3 제품 식별자는 각각 제1 제품을 식별하는, 방법.</claim></claimInfo><claimInfo><claim>14. 청구항 11에 있어서, 상기 콘텐츠 항목 및 상기 이미지 데이터와 연관된 타임스탬프를 획득하는 단계를 추가로 포함하고, 상기 콘텐츠 항목과 연관된 제2 메타데이터를 조정하는 단계는 상기 제2 제품 식별자에 의해 식별된 제품이 상기 콘텐츠 항목 및 상기 타임스탬프와 연관되어 있다는 지시를 포함하도록 상기 제2 메타데이터를 조정하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>15. 청구항 11에 있어서, 상기 제2 메타데이터는 기계 생성된 캡션을 포함하고, 상기 제1 제품 식별자는 제품과 연관되고, 상기 제품과 연관된 언어는 상기 기계 생성된 캡션을 생성하는 과정에서 잘못 전사되었으며, 상기 콘텐츠 항목과 연관된 제2 메타데이터를 업데이트하는 동작은 상기 제품과 연관된 기계 생성된 캡션의 일부를 상기 제품의 텍스트 식별자로 대체하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>16. 청구항 11에 있어서, 상기 제3 모델에 제4 제품 식별자와 제4 신뢰도 값을 제공하는 단계; 및상기 제3 모델의 출력으로서 제5 제품 식별자를 획득하는 단계 - 상기 제3 제품 식별자는 상기 제1 제품과 연관되고, 상기 제5 제품 식별자는 제2 제품과 연관됨 -를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 명령어를 저장하는 비일시적 기계 판독 가능 저장 매체로서, 상기 명령어는 실행될 때 처리 디바이스로 하여금 동작을 수행하게 하고, 상기 동작은, (i) 콘텐츠 항목의 제1 메타데이터에 기초하여 상기 콘텐츠 항목과 연관하여 결정된 제1 제품의 제1 식별자, 및 (ii) 상기 콘텐츠 항목 및 상기 제1 제품과 연관된 제1 신뢰도 값을 포함하는 제1 데이터를 획득하는 동작;(i) 상기 콘텐츠 항목의 제1 이미지 데이터에 기초하여 상기 콘텐츠 항목과 연관하여 결정된 상기 제1 제품의 제2 식별자, 및 (ii) 상기 콘텐츠 항목 및 상기 제1 제품과 연관된 제2 신뢰도 값을 포함하는 제2 데이터를 획득하는 동작;상기 제1 데이터와 상기 제2 데이터를 훈련된 기계 학습 모델에 제공하는 동작;상기 훈련된 기계 학습 모델로부터 상기 제1 제품과 연관된 제3 신뢰도 값을 획득하는 동작; 및상기 제3 신뢰도 값을 고려하여 상기 콘텐츠 항목과 연관된 제2 메타데이터를 조정하는 동작을 포함하는, 비일시적 기계 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>18. 청구항 17에 있어서, 상기 동작은, 상기 콘텐츠 항목의 제1 이미지 데이터를 제2 모델에 대한 입력으로 제공하는 동작;상기 제2 모델의 출력으로 제1 차원 축소된 데이터를 획득하는 동작;상기 제1 데이터를 획득한 것에 응답하여 상기 제1 제품과 연관된 제2 차원 축소된 데이터를 데이터 저장소로부터 획득하는 동작 - 상기 제2 데이터는 적어도 상기 제1 차원 축소된 데이터와 상기 제2 차원 축소된 데이터에 기초함 -을 추가로 포함하는, 비일시적 기계 판독 가능 저장 매체. </claim></claimInfo><claimInfo><claim>19. 청구항 17에 있어서, 상기 콘텐츠 항목은 비디오이고, 상기 제1 데이터는 상기 제품과 연관된 비디오의 하나 이상의 프레임의 타임스탬프의 지시를 추가로 포함하고, 상기 제2 메타데이터를 조정하는 동작은 상기 제2 메타데이터에 상기 타임스탬프의 지시와 상기 제1 제품의 지시를 포함하는 동작을 포함하는, 비일시적 기계 판독 가능 저장 매체. </claim></claimInfo><claimInfo><claim>20. 청구항 17에 있어서, 상기 동작은, 상기 콘텐츠 항목과 연관된 제1 제품 카테고리의 제3 식별자를 포함하는 제3 데이터를 수신하는 동작; 및상기 제3 데이터를 상기 훈련된 기계 학습 모델에 제공하는 동작 - 상기 제3 신뢰도 값은 상기 제1 데이터, 상기 제2 데이터 및 상기 제3 데이터에 기초하여 생성됨 -을 추가로 포함하는, 비일시적 기계 판독 가능 저장 매체. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>이탈리아</country><engName>ZICCARDI, Marco</engName><name>지카르디, 마르코</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>TSAI, Min-hsuan</engName><name>짜이, 민-솬</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>CHUANG, Wei-Hong</engName><name>촹, 웨이-훙</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>인도</country><engName>BHALERAO, Rahul Sunil</engName><name>발레라오, 라훌 수닐</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>XIA, Ye</engName><name>샤, 예</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>인도</country><engName>SHANBHOGUE, Madhuri</engName><name>샨보구, 마두리</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>SEYEDHOSSEINI, Mojitaba</engName><name>세예드호세이니, 모지타바</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>KRAININ, Mike</engName><name>크라이닌, 마이크</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>KAPISHNIKOV, Andrei</engName><name>카피슈니코프, 안드레이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>LI, Yuanzhen</engName><name>리, 위안전</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.01</priorityApplicationDate><priorityApplicationNumber>17/878,845</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.02.27</receiptDate><receiptNumber>1-1-2025-0227952-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.02.27</receiptDate><receiptNumber>1-1-2025-0228559-46</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.03.04</receiptDate><receiptNumber>1-5-2025-0036436-29</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257006692.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9302b81fc56f5bca417a3439bfcf40e4c7efff07f1699682adc9155cd2f4612827e4aacab15185ad27c9080d4365d88d15f7a6869e88cccebf</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cffd76965aee89ce4c6838e6de401b2f50d28dfa7a99a8adb7aedcbeb2a9c83b80a3efe526a61d787e4e9024a340a9189b6e4105c8e7c5ee79</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>