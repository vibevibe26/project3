<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:42.5342</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0152590</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>혼합 현실과 상호작용하기 위한 방법 및 이를 위한 장치</inventionTitle><inventionTitleEng>Device and method for interacting with Mixed Reality</inventionTitleEng><openDate>2023.05.16</openDate><openNumber>10-2023-0066986</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치에서 혼합 현실(Mixed Reality)과 상호작용하기 위한 방법이 개시된다. 구체적으로, 상기 사용자의 상기 전자 장치를 통해, 상기 사용자에게 가상 오브젝트를 출력하는 단계; 상기 사용자의 응시 방향에 따라 결정된 상기 사용자의 시야 범위(Field of View)에 기초하여, 상기 시야 범위 내에 상기 가상 오브젝트가 위치하는지 여부를 결정하는 단계; 상기 결정에 기초하여, 상기 가상 오브젝트가 상기 사용자에게 청각 신호를 제공하는 청각 모드와 상기 가상 오브젝트가 상기 사용자에게 시각 신호를 제공하는 시각 모드 중 적어도 하나의 모드를 선택하는 단계; 및 상기 선택된 적어도 하나의 모드에 따라, 상기 가상 오브젝트가 상기 사용자와 상호작용하는 단계; 를 포함하는 혼합 현실의 가상 오브젝트를 제공하기 위한 방법이 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 혼합 현실(Mixed Reality)과 상호작용하기 위한 방법에 있어서,사용자의 전자 장치를 통해, 상기 사용자에게 가상 오브젝트를 출력하는 단계;상기 사용자의 응시 방향에 따라 결정된 상기 사용자의 시야 범위(Field of View)에 기초하여, 상기 시야 범위 내에 상기 가상 오브젝트가 위치하는지 여부를 결정하는 단계;상기 결정에 기초하여, 상기 가상 오브젝트가 상기 사용자에게 청각 신호를 제공하는 청각 모드와 상기 가상 오브젝트가 상기 사용자에게 시각 신호를 제공하는 시각 모드 중 적어도 하나의 모드를 선택하는 단계; 및상기 선택된 적어도 하나의 모드에 따라, 상기 가상 오브젝트가 상기 사용자와 상호작용하는 단계; 를 포함하는 혼합 현실과 상호작용하기 위한 방법.</claim></claimInfo><claimInfo><claim>2. 제 1항에 있어서,상기 시야 범위 내에 상기 가상 오브젝트가 위치하는지 여부를 결정하는 단계는,상기 전자 장치의 센싱부를 통해 상기 사용자의 응시 방향을 측정하는 단계;상기 전자 장치의 횡 방향 시야 각(horizontal viewing angle direction) 및 상기 전자 장치의 종 방향 시야 각(vertical viewing angle direction) 중 적어도 하나 및 상기 측정된 응시 방향에 기초하여 상기 사용자의 시야 범위를 결정하는 단계; 및상기 결정된 사용자의 시야 범위에 기초하여, 상기 가상 오브젝트가 상기 시야 범위 내에 위치하는지 여부를 결정하는 단계; 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제 1항에 있어서, 상기 적어도 하나의 모드를 선택하는 단계는,상기 시야 범위 내에 상기 가상 오브젝트가 위치하는 경우 상기 시각 모드 및 상기 청각 모드 중 상기 시각 모드를 선택하고, 상기 시야 범위 밖에 상기 가상 오브젝트가 위치하는 경우 상기 시각 모드 및 상기 청각 모드 중 상기 청각 모드를 선택하는 단계; 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제 1항에 있어서, 상기 청각 모드에 따라 상기 가상 오브젝트가 상기 사용자와 상호작용하는 단계는,상기 사용자가 시청하고 있는 콘텐트(content) 정보, 상기 사용자의 상태 정보 및 상기 가상 오브젝트의 특성 정보 중 적어도 하나에 기초하여, 상기 청각 모드에 따른 상기 청각 신호의 내용을 결정하는 단계;상기 사용자 주변 환경의 소리 정보, 상기 콘텐트를 출력하는 디지털 디스플레이 디바이스의 소리 정보 및 상기 사용자의 상태 정보 중 적어도 하나에 기초하여, 상기 청각 신호를 렌더링하기 위한 렌더링 파라미터를 결정하는 단계; 및상기 결정된 청각 신호의 내용 및 상기 렌더링 파라미터에 기초하여, 상기 청각 신호를 렌더링하는 단계; 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제 4항에 있어서,상기 전자 장치의 출력부를 통해 상기 렌더링된 청각 신호를 기 설정된 주기에 따라 상기 사용자에게 제공하는 단계; 를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제 4항에 있어서, 상기 청각 신호를 렌더링하기 위한 상기 렌더링 파라미터를 결정하는 단계는,상기 전자 장치의 센싱부를 통해 상기 사용자 주변 환경의 소리 정보 및 상기 콘텐트를 출력하는 상기 디지털 디스플레이 디바이스의 소리 정보 중 적어도 하나를 획득하고,상기 사용자 주변 환경의 소리 정보 및 상기 콘텐트를 출력하는 디지털 디스플레이 디바이스의 소리 정보 중 적어도 하나에 기초하여, 상기 사용자 주변의 소리를 소음 모드(Noise Mode) 또는 정숙 모드 (Silence Mode) 중 하나로 결정하는 단계; 및상기 소음 모드 또는 상기 정숙 모드 중 상기 결정된 모드와 대응되도록 상기 렌더링 파라미터를 결정하는 단계; 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제 4항에 있어서, 상기 청각 신호를 렌더링하기 위한 상기 렌더링 파라미터를 결정하는 단계는,상기 전자 장치를 통해, 상기 가상 오브젝트의 위치 정보를 획득하는 단계;상기 가상 오브젝트의 위치 정보에 기초하여, HRTF(Head Related Transfer Function)를 통해 상기 청각 신호의 방향 파라미터 및 상기 청각 신호의 공간 파라미터를 생성하는 단계; 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제 4항에 있어서, 상기 청각 모드에 따른 상기 청각 신호의 내용을 결정하는 단계는,상기 전자 장치의 자동 콘텐트 인식(automatic content recognition)에 기초하여, 상기 사용자가 시청하고 있는 상기 콘텐트의 정보를 획득하는 단계; 및상기 콘텐트의 정보에 대응되는 상기 청각 신호의 내용을 결정하는 단계; 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제 1항에 있어서, 상기 시각 모드에 따라 상기 가상 오브젝트가 상기 사용자와 상호작용하는 단계는,상기 사용자가 시청하고 있는 콘텐트 정보, 상기 사용자의 상태 정보 및 상기 가상 오브젝트의 특성 정보 중 적어도 하나에 기초하여, 상기 가상 오브젝트의 행동 정보 및 상기 가상 오브젝트의 표정 정보 중 적어도 하나를 결정하는 단계; 및상기 행동 정보 및 상기 표정 정보 중 적어도 하나에 기초하여, 상기 가상 오브젝트가 상기 사용자와 상호작용하는 단계; 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제 1항에 있어서, 상기 선택된 적어도 하나의 모드에 따라, 상기 가상 오브젝트가 상기 사용자와 상호작용하는 단계는,상기 시각 모드에 따른 상기 시각 신호 및 상기 청각 모드에 따른 상기 청각 신호를 동기화하는 단계; 및상기 동기화된 시각 신호 및 상기 동기화된 청각 신호에 기초하여, 상기 가상 오브젝트가 상기 사용자와 상호작용하는 단계; 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 혼합 현실과 상호작용하기 위한 전자 장치에 있어서,출력부;하나 이상의 인스트럭션을 저장하는 메모리; 및상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서; 를 포함하며,상기 적어도 하나의 프로세서는,가상 오브젝트를 출력하도록 상기 출력부를 제어하고,사용자의 응시 방향에 따라 결정된 상기 사용자의 시야 범위에 기초하여, 상기 시야 범위 내에 상기 가상 오브젝트가 위치하는지 여부를 결정하고,상기 결정에 기초하여, 상기 가상 오브젝트가 상기 사용자에게 청각 신호를 제공하는 청각 모드와 상기 가상 오브젝트가 상기 사용자에게 시각 신호를 제공하는 시각 모드 중 적어도 하나의 모드를 선택하고, 및상기 선택된 적어도 하나의 모드에 따라, 상기 출력부를 통해 상기 가상 오브젝트가 상기 사용자와 상호작용하도록 상기 가상 오브젝트를 제어하는, 혼합 현실과 상호작용하기 위한 전자 장치.</claim></claimInfo><claimInfo><claim>12. 제 11항에 있어서,상기 전자 장치는 센싱부를 더 포함하고,상기 적어도 하나의 프로세서는 상기 센싱부를 통해 상기 사용자의 응시 방향을 측정하도록 제어하고,상기 전자 장치의 횡 방향 시야 각 및 상기 전자 장치의 종 방향 시야 각 중 적어도 하나 및 상기 측정된 응시 방향에 기초하여 상기 사용자의 시야 범위를 결정하고, 및상기 결정된 사용자의 시야 범위에 기초하여, 상기 가상 오브젝트가 상기 시야 범위 내에 위치하는지 여부를 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제 11항에 있어서,상기 적어도 하나의 프로세서는 상기 시야 범위 내에 상기 가상 오브젝트가 위치하는 경우 상기 시각 모드 및 상기 청각 모드 중 상기 시각 모드를 선택하고, 상기 시야 범위 밖에 상기 가상 오브젝트가 위치하는 경우 상기 시각 모드 및 상기 청각 모드 중 상기 청각 모드를 선택하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제 11항에 있어서,상기 적어도 하나의 프로세서는 상기 사용자가 시청하고 있는 콘텐트 정보, 상기 사용자의 상태 정보 및 상기 가상 오브젝트의 특성 정보 중 적어도 하나에 기초하여, 상기 청각 모드에 따른 상기 청각 신호의 내용을 결정하고,상기 사용자 주변 환경의 소리 정보, 상기 콘텐트를 출력하는 디지털 디스플레이 디바이스의 소리 정보 및 상기 사용자의 상태 정보 중 적어도 하나에 기초하여, 상기 청각 신호를 렌더링하기 위한 렌더링 파라미터를 결정하고, 및상기 결정된 청각 신호의 내용 및 상기 렌더링 파라미터에 기초하여, 상기 청각 신호를 렌더링하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제 14항에 있어서,상기 적어도 하나의 프로세서는 상기 렌더링된 청각 신호를 기 설정된 주기에 따라 상기 출력부를 통해 상기 사용자에게 제공하도록 제어하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제 14항에 있어서,상기 전자 장치는 센싱부를 더 포함하고,상기 적어도 하나의 프로세서는 상기 센싱부를 통해 상기 사용자 주변 환경의 소리 정보 및 상기 콘텐트를 출력하는 디지털 디스플레이 디바이스의 소리 정보 중 적어도 하나를 획득하도록 제어하고,상기 사용자 주변 환경의 소리 정보 및 상기 콘텐트를 출력하는 디지털 디스플레이 디바이스의 소리 정보 중 적어도 하나에 기초하여, 상기 사용자 주변의 소리를 소음 모드 또는 정숙 모드 중 하나로 결정하고, 및상기 소음 모드 또는 상기 정숙 모드 중 상기 결정된 모드와 대응되도록 상기 렌더링 파라미터를 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제 14항에 있어서,상기 적어도 하나의 프로세서는 상기 가상 오브젝트의 위치 정보를 획득하고,상기 가상 오브젝트의 위치 정보에 기초하여, HRTF(Head Related Transfer Function)를 통해 상기 청각 신호의 방향 파라미터 및 상기 청각 신호의 공간 파라미터를 생성하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제 11항에 있어서,상기 적어도 하나의 프로세서는 상기 사용자가 시청하고 있는 콘텐트 정보, 상기 사용자의 상태 정보 및 상기 가상 오브젝트의 특성 정보 중 적어도 하나에 기초하여, 상기 가상 오브젝트의 행동 정보 및 상기 가상 오브젝트의 표정 정보 중 적어도 하나를 결정하고, 및상기 행동 정보 및 상기 표정 정보 중 적어도 하나에 기초하여, 상기 출력부를 통해 상기 가상 오브젝트가 상기 사용자와 상호작용하도록 상기 가상 오브젝트를 제어하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제 11항에 있어서,상기 적어도 하나의 프로세서는 상기 시각 모드에 따른 상기 시각 신호 및 상기 청각 모드에 따른 상기 청각 신호가 동기화되도록 제어하고, 및상기 동기화된 시각 신호 및 상기 동기화된 청각 신호에 기초하여, 상기 출력부를 통해 상기 가상 오브젝트가 상기 사용자와 상호작용하도록 상기 가상 오브젝트를 제어하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>BAIJAL, Anant</engName><name>바이잘 아난트</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YU, Seung Dong</engName><name>유승동</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HYUN, Dae Eun</engName><name>현대은</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.11.08</receiptDate><receiptNumber>1-1-2021-1287059-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.08</receiptDate><receiptNumber>1-1-2024-1230012-87</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.10.23</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210152590.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bc3707d24fb922b28f7a01adf97df52f21d5b1a75801a01a93daac1bfb8583b71b3b91af525e96e9d451af23e2177bfa189ebeb0bccf587f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf386252d8df6a618433067d63cd6ab415bb4fbc8ed87ec6b0a334c9f1badf28be3830544386c78464fa729fa757db39568225d9f18b4adb30</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>