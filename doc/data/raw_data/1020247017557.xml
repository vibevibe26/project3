<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:30:27.3027</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7017557</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>오디오 소스 분리 처리 워크플로우 시스템들 및 방법들</inventionTitle><inventionTitleEng>AUDIO SOURCE SEPARATION PROCESSING WORKFLOW SYSTEMS AND METHODS</inventionTitleEng><openDate>2024.08.19</openDate><openNumber>10-2024-0125561</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.05.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 21/0272</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/78</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/18</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 시스템들 및 방법들은 복수의 소스들로부터 생성된 오디오 신호들의 믹스처를 갖는 단일 트랙 오디오 입력 스트림을 수신하는 것, 수신된 단일 트랙 오디오 입력 스트림을 적어도 부분적으로 사용하여 오디오 소스 분리 모델을 훈련시키는 것, 및 복수의 소스 분리 출력 스템들을 생성하기 위해 하나 이상의 처리 방안들에 따라 오디오 입력 스트림으로부터 오디오 소스들을 분리하는 것을 포함한다. 오디오 분리 모델은 단일 트랙 오디오 입력 스트림을 수신하고 복수의 소스들 중 하나 이상의 오디오 소스들에 대응하는 복수의 오디오 스템들을 생성하도록 훈련된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.05.04</internationOpenDate><internationOpenNumber>WO2023073596</internationOpenNumber><internationalApplicationDate>2022.10.27</internationalApplicationDate><internationalApplicationNumber>PCT/IB2022/060320</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법에 있어서,복수의 소스들로부터 생성된 오디오 신호들의 믹스처를 포함하는 단일 트랙 오디오 입력 스트림을 수신하는 단계;수신된 단일 트랙 오디오 입력 스트림을 적어도 부분적으로 사용하여 오디오 소스 분리 모델을 훈련시키는 단계로서, 오디오 분리 모델은 상기 단일 트랙 오디오 입력 스트림을 수신하고 복수의 소스들 중 하나 이상의 오디오 소스들에 대응하는 복수의 오디오 스템들(audio stems)을 생성하도록 훈련되는, 상기 오디오 소스 분리 모델을 훈련시키는 단계; 및복수의 소스 분리 출력 스템들을 생성하기 위해 하나 이상의 처리 방안들에 따라 상기 오디오 소스 분리 모델을 사용하여 상기 오디오 입력 스트림으로부터 오디오 소스들을 분리하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 하나 이상의 처리 방안들은 복수의 처리 분기들을 포함하고, 각각의 처리 분기는 하나 이상의 오디오 스템들을 출력하도록 훈련되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 상기 처리 분기들 각각은 또한 제 1 처리 분기에서 상기 하나 이상의 오디오 스템들을 출력하고 제 2 처리 분기에서 나머지 보완 신호 믹스처(complement signal mixture)를 출력하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항 내지 제 3 항 중 어느 한 항에 있어서, 상기 오디오 소스 분리 모델은 복수의 신경망들을 포함하고, 각 신경망은 상기 단일 트랙 오디오 입력 스트림의 오디오 신호들의 믹스처로부터 적어도 하나의 소스에 대응하는 오디오 신호들을 분리하도록 훈련되고;상기 복수의 신경망들은 윈도잉 함수(windowing function)를 적용하도록 구성되고;  복수의 훈련된 신경망들은 밴딩 아티팩트들(banding artefacts)을 부드럽게 하기 위해 오버랩 추가 프로세스(overlap-add process)를 수행하도록 구성되고; 및/또는상기 복수의 신경망들은 마스크를 적용하지 않고 소스 분리를 수행하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항 내지 제 4 항 중 어느 한 항에 있어서, 상기 오디오 소스 분리 모델을 훈련시키는 단계는: 복수의 라벨링된 스피치 샘플들 및/또는 복수의 라벨링된 음악 및/또는 노이즈 데이터 샘플들을 포함하는 훈련 데이터세트를 사용하여 오디오 소스 분리 모델을 훈련시키는 단계;상기 훈련된 오디오 소스 분리 모델을 통해 상기 단일 트랙 오디오 입력 스트림을 처리하여 상기 복수의 소스 분리 출력 스템들을 생성하는 단계;소스 분리 출력 스템들 중 하나 이상을 포함하도록 상기 훈련 데이터세트를 업데이트하는 단계; 및업데이트된 훈련 데이터세트를 사용하여 상기 오디오 소스 분리 모델을 재훈련시키는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서, 상기 오디오 소스 분리 모델을 훈련시키는 단계는 상기 훈련 데이터세트를 반복적으로 업데이트하고 상기 훈련된 오디오 소스 분리 모델로부터 생성된 상기 소스 분리 출력 스템들 중 하나 이상을 사용하여 상기 오디오 소스 분리 모델을 재훈련시키는 자기 반복 훈련 프로세스(self-iterative training process)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항 내지 제 6 항 중 어느 한 항에 있어서, 클릭들(clicks), 고조파 왜곡, 고스팅(ghosting) 및/또는 광대역 노이즈를 포함하여, 소스 분리 동안 도입된 아티팩트들을 제거하기 위해 상기 소스 분리 출력 스템들을 후처리하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제 2 항에 있어서, 복수의 소스 분리 출력 스템들을 생성하기 위해 하나 이상의 처리 방안들에 따라 상기 오디오 소스 분리 모델을 사용하여 단일 트랙 오디오 입력 스트림으로부터 오디오 소스들을 분리하는 단계는:처리 분기들 중 하나 이상을 사용하여, 분리된 오디오 소스를 출력하고 나머지 보완 신호 믹스처를 출력하도록 구성된 훈련된 신경망을 통해 단일 트랙 오디오 입력 스트림, 분리된 오디오 소스 및/또는 보완 신호 믹스처를 처리하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항 내지 제 8 항 중 어느 한 항에 있어서, 상기 오디오 소스 분리 모델을 훈련시키는 단계는:훈련 프로세스를 통해 하나 이상의 클래스들의 소스 신호들 및 나머지 보완 신호를 출력하도록 신경망을 훈련시키는 단계를 포함하고, 상기 훈련 프로세스는: 제 1 오디오 샘플 레이트로 제 1 신경망을 훈련시키는 것; 제 1 샘플 레이트보다 높은 제 2 오디오 샘플 레이트로 제 2 신경망을 훈련시키는 것을 포함하고, 상기 제 2 신경망은 적어도 하나의 훈련되지 않은 레이어 및 상기 제 1 신경망으로부터 승계된 연관 파라미터들 및 레이어들을 포함하며, 상기 제 2 신경망을 훈련시키는 것은:  상기 제 1 신경망으로부터 승계된 파라미터들이 고정된 상태로 유지되는 동안 적어도 하나의 훈련되지 않은 레이어로부터의 파라미터들을 훈련시키는 것; 및  상기 제 1 신경망으로부터 승계된 파라미터와 상기 적어도 하나의 훈련되지 않은 레이어로부터의 파라미터들을 미세 조정하기 위해 상기 제 2 신경망을 재훈련시키는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제 1 항 내지 제 8 항 중 어느 한 항에 있어서, 상기 오디오 소스 분리 모델을 훈련시키는 단계는 상기 오디오 소스 분리 모델을 제 1 오디오 샘플 레이트로 훈련시키는 것, 및 상기 오디오 소스 분리 모델을 상기 제 1 오디오 샘플 레이트보다 높은 제 2 오디오 샘플 레이트로 업스케일링하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제 1 항 내지 제 4 항 중 어느 한 항에 있어서, 상기 오디오 소스 분리 모델을 훈련시키는 단계는 사용자 안내 미세 조정 프로세스(user-guided fine-tuning process)를 포함하고, 사용자는 상기 복수의 오디오 스템들 중 하나 이상을 평가하고 복수의 오디오 스템들 중 하나 이상을 오디오 소스 분리 모델을 재훈련시키기 위한 훈련 데이터세트에 추가하고, 하나 이상의 오디오 샘플들을 오디오 소스 분리 모델을 재훈련시키기 위한 훈련 데이터세트에 추가하고, 및/또는 미세 조정 소스 분리 결과들에 하나 이상의 하이퍼파라미터들을 추가하여 오디오 소스 분리 모델을 미세 조정하는, 방법.</claim></claimInfo><claimInfo><claim>12. 시스템에 있어서,기계 판독 가능 명령들을 저장하는 메모리 구성요소; 및상기 기계 판독 가능 명령들을 실행하도록 구성된 논리 장치를 포함하고, 상기 기계 판독 가능 명령들은: 복수의 소스들로부터 생성된 오디오 신호들의 믹스처를 포함하는 단일 트랙 오디오 입력 스트림을 수신하고; 수신된 단일 트랙 오디오 입력 스트림을 적어도 부분적으로 사용하여 오디오 소스 분리 모델을 훈련시키고, 오디오 분리 모델은 상기 단일 트랙 오디오 입력 스트림을 수신하고 복수의 소스들 중 하나 이상의 오디오 소스들에 대응하는 복수의 오디오 스템들을 생성하도록 훈련되고; 복수의 소스 분리 출력 스템들을 생성하기 위해 하나 이상의 처리 방안들에 따라 상기 오디오 소스 분리 모델을 사용하여 상기 오디오 입력 스트림으로부터 오디오 소스들을 분리하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서, 상기 하나 이상의 처리 방안들은 제 1 처리 분기에서 하나 이상의 오디오 스템들을 출력하고 제 2 분기에서 나머지 보완 신호 믹스처를 출력하도록 구성된 복수의 처리 분기들을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>14. 제 12 항 또는 제 13 항에 있어서, 상기 오디오 소스 분리 모델은 복수의 신경망들을 포함하고, 각 신경망은 상기 단일 트랙 오디오 입력 스트림의 오디오 신호들의 믹스처로부터 적어도 하나의 소스에 대응하는 오디오 신호들을 분리하도록 훈련되고;상기 복수의 신경망들은 윈도잉 함수를 적용하도록 구성되고; 복수의 훈련된 신경망들은 밴딩 아티팩트들을 부드럽게 하기 위해 오버랩 추가 프로세스를 수행하도록 구성되고; 및/또는상기 복수의 신경망들은 마스크를 적용하지 않고 소스 분리를 수행하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>15. 제 12 항 내지 제 14 항 중 어느 한 항에 있어서, 상기 논리 장치는 또한:복수의 라벨링된 스피치 샘플들 및/또는 복수의 라벨링된 음악 및/또는 노이즈 데이터 샘플들을 포함하는 훈련 데이터세트를 사용하여 상기 오디오 소스 분리 모델을 훈련시키고;상기 훈련된 오디오 소스 분리 모델을 통해 상기 단일 트랙 오디오 입력 스트림을 처리하여 상기 복수의 소스 분리 출력 스템들을 생성하고;소스 분리 출력 스템들 중 하나 이상을 포함하도록 상기 훈련 데이터세트를 업데이트하고;상기 업데이트된 훈련 데이터세트를 사용하여 상기 오디오 소스 분리 모델을 재훈련시켜 상기 오디오 소스 분리 모델을 훈련시키도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서, 상기 논리 장치는 또한 상기 훈련 데이터세트를 반복적으로 업데이트하고 상기 훈련된 오디오 소스 분리 모델로부터 생성된 상기 소스 분리 출력 스템들 중 하나 이상을 사용하여 상기 오디오 소스 분리 모델을 재훈련시키는 자기 반복 훈련 프로세스를 구현하여 상기 오디오 소스 분리 모델을 훈련시키도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제 12 항 내지 제 16 항 중 어느 한 항에 있어서, 상기 논리 장치는 또한 클릭들, 고조파 왜곡, 고스팅 및/또는 광대역 노이즈를 포함하여, 소스 분리 동안 도입된 아티팩트들을 제거하기 위해 상기 소스 분리 출력 스템들을 후처리하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제 13 항에 있어서, 상기 처리 분기들 각각은 분리된 오디오 소스와 나머지 보완 신호 믹스처를 출력하도록 구성된 훈련된 신경망을 통해 상기 단일 트랙 오디오 입력 스트림, 분리된 오디오 소스 및/또는 보완 신호 믹스처를 처리하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제 12 항 내지 제 18 항 중 어느 한 항에 있어서, 상기 논리 장치는 또한:훈련 프로세스를 통해 하나 이상의 클래스들의 소스 신호들 및 나머지 보완 신호를 출력하도록 신경망을 훈련시켜 상기 오디오 소스 분리 모델을 훈련시키도록 구성되고, 상기 훈련 프로세스는:  제 1 오디오 샘플 레이트로 제 1 신경망을 훈련시키는 것;  제 1 샘플 레이트보다 높은 제 2 오디오 샘플 레이트로 제 2 신경망을 훈련시키는 것을 포함하고, 상기 제 2 신경망은 적어도 하나의 훈련되지 않은 레이어 및 상기 제 1 신경망으로부터 승계된 연관된 파라미터들과 레이어들을 포함하고, 상기 제 2 신경망을 훈련시키는 것은:  상기 제 1 신경망으로부터 승계된 파라미터들이 고정된 상태로 유지되는 동안 적어도 하나의 훈련되지 않은 레이어로부터의 파라미터들을 훈련시키는 것; 및  상기 제 1 신경망으로부터 승계된 파라미터와 상기 적어도 하나의 훈련되지 않은 레이어로부터의 파라미터들을 미세 조정하기 위해 상기 제 2 신경망을 재훈련시키는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 제 12 항 내지 제 14 항 중 어느 한 항에 있어서, 상기 논리 장치는 또한 사용자 안내 미세 조정 프로세스를 실행하여 상기 오디오 소스 분리 모델을 훈련시키도록 구성되고, 사용자는 상기 복수의 오디오 스템들 중 하나 이상을 평가하고 상기 복수의 오디오 스템들 중 하나 이상을 상기 오디오 소스 분리 모델을 재훈련시키기 위한 훈련 데이터세트에 추가하고, 상기 오디오 소스 분리 모델을 재훈련시키기 위한 훈련 상기 훈련 데이터세트에 하나 이상의 오디오 샘플들을 추가하고, 및/또는 미세 조정 소스 분리 결과들에 하나 이상의 하이퍼라라미터들을 추가하여 상기 오디오 소스 분리 모델을 미세 조정하는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>뉴질랜드 **** 웰링톤 미라마 피오 박스 ** ***</address><code>520240353675</code><country>뉴질랜드</country><engName>WingNut Films Productions Limited</engName><name>윙넛 필름스 프로덕션스 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>뉴질랜드 **** 웰링...</address><code> </code><country> </country><engName>DE LA REY, Emile</engName><name>데 라 레이 에밀</name></inventorInfo><inventorInfo><address>뉴질랜드 **** 웰링...</address><code> </code><country> </country><engName>SMARAGDIS, Paris</engName><name>스마라그디스 파리</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 세종대로 ***, **층 (세종로, 광화문빌딩)(법무법인센트럴)</address><code>919990006014</code><country>대한민국</country><engName>HOON CHANG</engName><name>장훈</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.27</priorityApplicationDate><priorityApplicationNumber>63/272,650</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.06.23</priorityApplicationDate><priorityApplicationNumber>17/848,341</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.05.27</receiptDate><receiptNumber>1-1-2024-0567923-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2024.06.04</receiptDate><receiptNumber>1-5-2024-0091725-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2024.07.17</receiptDate><receiptNumber>1-1-2024-0774578-86</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.07.19</receiptDate><receiptNumber>1-5-2024-0118915-54</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247017557.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d86c91b045bff3b12678c0319bda785ab84666e729b7a258a4674cef0276b44b4b16f8b0244d37de6dc660d0ef11571e3cfdced49e551bab</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf638e1b12628e93565865dfd620502caf70bb7a8bfd3a9127b198a63ee06df725fb42b49b68f069e08307ce0463db9237358a172d43ccbf3c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>