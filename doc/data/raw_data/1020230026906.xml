<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:17.617</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0026906</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>포인트 클라우드를 생성하는 방법 및 전자 장치</inventionTitle><inventionTitleEng>METHOD AND ELECTRONIC DEVICE OF GENERATING POINT  CLOUD</inventionTitleEng><openDate>2024.04.16</openDate><openNumber>10-2024-0049128</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/521</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 포인트 클라우드를 생성하는 방법 및 전자 장치에 관한 것이다. 본 개시의 실시예에 따른 포인트 클라우드를 생성하는 방법은, 전자 장치의 적어도 하나의 센서로부터, 객체에 대응하는 제1 센싱 데이터를 획득하는 단계, 제1 센싱 데이터에 기초하여 객체에 대응하는 제1 포인트 클라우드를 획득하는 단계, 적어도 하나의 심층 신경망 모델을 이용하여, 제1 포인트 클라우드에서 적어도 하나의 기 정의된 물리 법칙의 위반을 나타내는 이상치 포인트들을 식별하는 단계, 및 이상치 포인트들에 기초하여, 객체에 대한 재촬영 위치 가이드를 제공하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치가 포인트 클라우드(point cloud)를 생성하는 방법에 있어서,상기 전자 장치(200)의 적어도 하나의 센서(210)로부터, 객체에 대응하는 제1 센싱 데이터를 획득하는 단계 (S310);상기 제1 센싱 데이터에 기초하여 상기 객체에 대응하는 제1 포인트 클라우드를 획득하는 단계 (S320);적어도 하나의 심층 신경망 모델(231)을 이용하여, 상기 제1 포인트 클라우드에서 적어도 하나의 기 정의된 물리 법칙의 위반을 나타내는 이상치 포인트들을 식별하는 단계 (S330); 및상기 이상치 포인트들에 기초하여, 상기 객체에 대한 재촬영 위치 가이드를 제공하는 단계 (S340)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 방법은, 상기 재촬영 위치 가이드를 제공한 후, 상기 적어도 하나의 센서(210)로부터, 상기 객체의 적어도 일부에 대응하는 제2 센싱 데이터를 획득하는 단계; 및상기 제1 센싱 데이터 및 상기 제2 센싱 데이터에 기초하여 제2 포인트 클라우드를 획득하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 재촬영 위치 가이드를 제공하는 단계는,재촬영이 필요한 카메라 위치를 제1 형태(1311)로 시각화한 상기 재촬영 위치 가이드를 상기 전자 장치(200)의 디스플레이(263)에 표시하는 단계;상기 제2 센싱 데이터를 획득한 후, 상기 제2 센싱 데이터가 상기 재촬영이 필요한 카메라 위치에서 촬영된 것인지 결정하는 단계; 및상기 재촬영이 필요한 카메라 위치에서 촬영된 것으로 결정한 것에 기초하여, 상기 제1 형태를 재촬영이 불필요한 카메라 위치를 나타내는 제2 형태(1321)로 변경하여 상기 재촬영 위치 가이드를 상기 전자 장치(200)의 디스플레이(263)에 표시하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 재촬영 위치 가이드를 제공하는 단계는,상기 제1 센싱 데이터에 기초하여 상기 제1 센싱 데이터를 획득한 상기 적어도 하나의 센서의 위치를 추정하는 단계;상기 추정된 위치에 기초하여, 상기 객체와 상기 적어도 하나의 센서 사이의 거리를 추정하는 단계;상기 추정된 거리, 상기 적어도 하나의 센서의 화각, 및 상기 제1 센싱 데이터 중 적어도 하나에 기초하여, 상기 객체에 대응하는 픽셀 해상도를 획득하는 단계;상기 픽셀 해상도가 제1 임계 값 미만인지 여부를 결정하는 단계; 및상기 픽셀 해상도가 상기 제1 임계 값 미만인 경우, 상기 추정된 거리보다 더 가까운 거리에서 상기 객체를 촬영할 것을 지시하는 상기 재촬영 위치 가이드를 제공하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 재촬영 위치 가이드를 제공하는 단계는,상기 제1 센싱 데이터에 기초하여 상기 제1 센싱 데이터를 획득한 상기 적어도 하나의 센서(210)의 제1 위치를 추정하는 단계;상기 추정된 제1 위치에 기초하여, 상기 식별된 부분에 대응하는 제2 센싱 데이터를 획득하기 위한 상기 적어도 하나의 센서(210)의 제2 위치를 추정하는 단계;상기 제1 위치 및 상기 제2 위치를 비교하여 상기 적어도 하나의 센서의 위치 조정 값을 획득하는 단계;상기 위치 조정 값이 제2 임계 값을 초과하는지 여부를 결정하는 단계; 및상기 위치 조정 값이 제2 임계 값을 초과하는 경우, 상기 제2 위치에서 상기 객체를 촬영할 것을 지시하는 상기 재촬영 위치 가이드를 제공하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 제1 포인트 클라우드에서 이상치 포인트들을 식별하는 단계는,상기 제1 포인트 클라우드에 기초하여 상기 객체에 대응하는 멀티 뷰 이미지들을 획득하고, 상기 멀티 뷰 이미지들 각각에 대응하는 카메라 정보를 획득하는 단계;상기 멀티 뷰 이미지들로 구성되는 동영상을 상기 적어도 하나의 심층 신경망 모델(231)에 적용하여, 상기 동영상에서 상기 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는지 여부를 추론하는 단계; 및상기 추론 결과에 기초하여, 상기 객체의 형상 중에서 상기 제1 포인트 클라우드에서 누락된 포인트들을 추정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 객체의 형상 중에서 상기 제1 포인트 클라우드에서 누락된 포인트들을 추정하는 단계는,상기 동영상에서 상기 추론 결과에 대응하는 히트 맵을 획득하는 단계;상기 히트 맵 및 상기 카메라 정보에 기초하여, 상기 객체의 형상 중 상기 제1 포인트 클라우드에서 상기 누락된 포인트들을 추정하는 단계;상기 추정 결과의 신뢰도 값이 제3 임계 값 미만인지 여부를 결정하는 단계; 및상기 신뢰도 값이 제3 임계 값 미만인 경우, 상기 멀티 뷰 이미지들을 추가 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항 및 제7항 중 어느 한 항에 있어서, 상기 동영상에서 상기 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는지 여부를 추론하는 단계는,상기 동영상 중 제1 프레임에서 객체를 지각하는 단계;상기 지각 결과에 기초하여 상기 제1 프레임의 다음 프레임인 제2 프레임의 예측 값을 획득하는 단계;상기 제2 프레임의 예측 값과 상기 제2 프레임의 실제 값 간의 오차가 제4 임계 값을 초과하는지 여부를 결정하는 단계; 및상기 오차가 상기 제4 임계 값보다 크면 상기 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는 것으로 결정하고, 상기 오차가 상기 제4 임계 값보다 작거나 같으면 상기 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하지 않는 것으로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 적어도 하나의 기 정의된 물리 법칙은, 객체 지속성(object persistence), 견고성(solidity), 불변성(unchangeableness), 및 방향 관성(directional inertia) 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 적어도 하나의 심층 신경망 모델(231)은, 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는 영상 시퀀스 및 상기 적어도 하나의 기 정의된 물리 법칙을 위반하지 않는 영상 시퀀스를 포함하는 데이터 셋을 학습 데이터(training data)로 이용하여, 상기 영상 시퀀스에서의 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는지 여부를 추론하도록 학습된, 방법.</claim></claimInfo><claimInfo><claim>11. 포인트 클라우드(point cloud)를 생성하는 전자 장치(200)에 있어서,적어도 하나의 센서(210);하나 이상의 인스트럭션을 저장하는 메모리(280); 및상기 메모리(280)에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서(270)를 포함하되, 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 적어도 하나의 센서(210)로부터, 객체에 대응하는 제1 센싱 데이터를 획득하고,상기 제1 센싱 데이터에 기초하여 상기 객체에 대응하는 제1 포인트 클라우드를 획득하고,적어도 하나의 심층 신경망 모델(231)을 이용하여, 상기 제1 포인트 클라우드에서 적어도 하나의 기 정의된 물리 법칙의 위반을 나타내는 이상치 포인트들을 식별하고,상기 이상치 포인트들에 기초하여, 상기 객체에 대한 재촬영 위치 가이드를 제공하는, 전자 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 재촬영 위치 가이드를 제공한 후, 상기 적어도 하나의 센서(210)로부터, 상기 객체의 적어도 일부에 대응하는 제2 센싱 데이터를 획득하고,상기 제1 센싱 데이터 및 상기 제2 센싱 데이터에 기초하여 제2 포인트 클라우드를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 전자 장치(200)는,디스플레이(263)를 더 포함하고,상기 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써,재촬영이 필요한 카메라 위치를 제1 형태(1311)로 시각화한 상기 재촬영 위치 가이드를 상기 디스플레이(263)에 표시하고;상기 제2 센싱 데이터를 획득한 후, 상기 제2 센싱 데이터가 상기 재촬영이 필요한 카메라 위치에서 촬영된 것인지 결정하고; 및상기 재촬영이 필요한 카메라 위치에서 촬영된 것으로 결정한 것에 기초하여, 상기 제1 형태를 재촬영이 불필요한 카메라 위치를 나타내는 제2 형태(1321)로 변경하여 상기 재촬영 위치 가이드를 상기 디스플레이(263)에 표시하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 센싱 데이터에 기초하여 상기 제1 센싱 데이터를 획득한 상기 적어도 하나의 센서의 위치를 추정하고,상기 추정된 위치에 기초하여, 상기 객체와 상기 적어도 하나의 센서 사이의 거리를 추정하고,상기 추정된 거리, 상기 적어도 하나의 센서의 화각, 및 상기 제1 센싱 데이터 중 적어도 하나에 기초하여, 상기 객체에 대응하는 픽셀 해상도를 획득하고,상기 픽셀 해상도가 제1 임계 값 미만인지 여부를 결정하고,상기 픽셀 해상도가 상기 제1 임계 값 미만인 경우, 상기 추정된 거리보다 더 가까운 거리에서 상기 객체를 촬영할 것을 지시하는 상기 재촬영 위치 가이드를 제공하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제11항 내지 제14항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 센싱 데이터에 기초하여 상기 제1 센싱 데이터를 획득한 상기 적어도 하나의 센서(210)의 제1 위치를 추정하고,상기 추정된 제1 위치에 기초하여, 상기 식별된 부분에 대응하는 제2 센싱 데이터를 획득하기 위한 상기 적어도 하나의 센서(210)의 제2 위치를 추정하고,상기 제1 위치 및 상기 제2 위치를 비교하여 상기 적어도 하나의 센서의 위치 조정 값을 획득하고,상기 위치 조정 값이 제2 임계 값을 초과하는지 여부를 결정하고,상기 위치 조정 값이 제2 임계 값을 초과하는 경우, 상기 제2 위치에서 상기 객체를 촬영할 것을 지시하는 상기 재촬영 위치 가이드를 제공하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제11항 내지 제15항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 포인트 클라우드에 기초하여 상기 객체에 대응하는 멀티 뷰 이미지들을 획득하고, 상기 멀티 뷰 이미지들 각각에 대응하는 카메라 정보를 획득하고,상기 멀티 뷰 이미지들로 구성되는 동영상을 상기 적어도 하나의 심층 신경망 모델(231)에 적용하여, 상기 동영상에서 상기 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는지 여부를 추론하고,상기 추론 결과에 기초하여, 상기 객체의 형상 중에서 상기 제1 포인트 클라우드에서 누락된 포인트들을 추정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 동영상에서 상기 추론 결과에 대응하는 히트 맵을 획득하고,상기 히트 맵 및 상기 카메라 정보에 기초하여, 상기 객체의 형상 중 상기 제1 포인트 클라우드에서 상기 누락된 포인트들을 추정하고,상기 추정 결과의 신뢰도 값이 제3 임계 값 미만인지 여부를 결정하고,상기 신뢰도 값이 제3 임계 값 미만인 경우, 상기 멀티 뷰 이미지들을 추가 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제16항 및 제17항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서(270)는, 상기 하나 이상의 인스트럭션을 실행함으로써,상기 동영상 중 제1 프레임에서 객체를 지각하고,상기 지각 결과에 기초하여 상기 제1 프레임의 다음 프레임인 제2 프레임의 예측 값을 획득하고,상기 제2 프레임의 예측 값과 상기 제2 프레임의 실제 값 간의 오차가 제4 임계 값을 초과하는지 여부를 결정하고,상기 오차가 상기 제4 임계 값보다 크면 상기 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는 것으로 결정하고, 상기 오차가 상기 제4 임계 값보다 작거나 같으면 상기 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하지 않는 것으로 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제11항 내지 제18항 중 어느 한 항에 있어서,상기 적어도 하나의 심층 신경망 모델(231)은, 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는 영상 시퀀스 및 상기 적어도 하나의 기 정의된 물리 법칙을 위반하지 않는 영상 시퀀스를 포함하는 데이터 셋을 학습 데이터로 이용하여, 상기 영상 시퀀스에서의 객체의 움직임이 상기 적어도 하나의 기 정의된 물리 법칙을 위반하는지 여부를 추론하도록 학습된, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Dong Chan</engName><name>김동찬</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>BYUN, Dong Nam</engName><name>변동남</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SHIN, Jae Wook</engName><name>신재욱</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HWANG, Jin Young</engName><name>황진영</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.10.07</priorityApplicationDate><priorityApplicationNumber>1020220129053</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.02.28</receiptDate><receiptNumber>1-1-2023-0233928-39</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230026906.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9331a95b292e3220ea9cab949b85c2b15a1ace3a8789048a0324f66bedbd49953c010e8599624e2df648fdd432d82b80cd0134fb108e2c3b01</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfef3d89fddf14f06bd4a790fff5afcc3bd7b57b8caddb110747faf5dd1583df8d5cb0fc7d8afd6ac98639325cbd28a03ece538704ee5e1ed6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>