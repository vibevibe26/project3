<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:27.4127</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.22</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0189320</applicationNumber><claimCount>12</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 기반으로 동작과 감정을 동시에 검출할 수 있는 장치</inventionTitle><inventionTitleEng>Apparatus for simultaneously detecting motion and emotion  based on the images</inventionTitleEng><openDate>2025.07.02</openDate><openNumber>10-2025-0099492</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.22</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명에 따른 이미지 기반으로 대상자의 동작과 감정을 함께 검출할 수 있는 장치는 대상자의 연속 동작에 대한 복수의 이미지를 획득하는 영상 획득부; 및 상기 복수의 이미지 각각에서 상기 대상자의 바운딩 박스 영역을 검출하고, 상기 검출된 바운딩 박스 영역에 해당하는 이미지들을 소정의 학습된 제1 딥러닝 모델에 적용하여 상기 대상자의 동작과 상기 대상자의 위치를 검출하며, 상기 검출된 동작과 위치에 대한 정보를 소정의 학습된 제2 딥러닝 모델에 적용하여 상기 대상자가 가지고 있는 복수의 감정 종류에 대한 정보를 출력하는 프로세서를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 기반으로 대상자의 동작과 감정을 함께 검출할 수 있는 장치에 있어서,상기 대상자의 연속 동작에 대한 복수의 이미지를 획득하는 영상 획득부; 및상기 복수의 이미지 각각에서 상기 대상자의 바운딩 박스 영역을 검출하고, 상기 검출된 바운딩 박스 영역에 해당하는 이미지들을 소정의 학습된 제1 딥러닝 모델에 적용하여 상기 대상자의 동작과 상기 대상자의 위치를 검출하며, 상기 검출된 동작과 위치에 대한 정보를 소정의 학습된 제2 딥러닝 모델에 적용하여 상기 대상자가 가지고 있는 복수의 감정 종류에 대한 정보를 출력하는 프로세서를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>2. 제 1항에 있어서,상기 프로세서는 상기 출력한 복수의 감정 종류에 대한 정보를 소정의 학습된 제3 딥러닝 모델에 적용하여 상기 대상자의 학습 몰입도에 대해 출력하는, 장치.</claim></claimInfo><claimInfo><claim>3. 제 1항에 있어서,상기 검출된 동작에 대한 정보는 상기 대상자의 동작 범주에 대한 정보를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>4. 제 1항에 있어서,상기 검출된 위치에 대한 정보는 상기 대상자의 얼굴 영역의 위치에 대한 정보를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>5. 제 1항에 있어서,상기 출력된 복수의 감정 종류에 대한 정보에는 상기 복수의 감정 종류 별로 감정 강도 혹은 감정 정도에 대한 정보를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>6. 이미지 기반으로 대상자의 동작과 감정을 함께 검출하는 방법에 있어서,영상 획득부가 상기 대상자의 연속 동작에 대한 복수의 이미지를 획득하는 단계;프로세서가 상기 복수의 이미지 각각에서 상기 대상자의 바운딩 박스 영역을 검출하는 단계;상기 프로세서가 상기 검출된 바운딩 박스 영역에 해당하는 이미지들을 소정의 학습된 제1 딥러닝 모델에 적용하여 상기 대상자의 동작과 상기 대상자의 위치를 검출하는 단계; 및상기 프로세서가 상기 검출된 동작과 위치에 대한 정보를 소정의 학습된 제2 딥러닝 모델에 적용하여 상기 대상자가 가지고 있는 복수의 감정 종류에 대한 정보를 출력하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제 6항에 있어서,상기 프로세서가 상기 출력한 복수의 감정 종류에 대한 정보를 소정의 학습된 제3 딥러닝 모델에 적용하여 상기 대상자의 학습 몰입도에 대해 출력하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 이미지 기반으로 대상자의 동작과 감정을 함께 검출할 수 있는 장치에 있어서,상기 대상자의 연속 동작에 대한 복수의 이미지를 수신하는 통신부; 및상기 수신된 상기 복수의 이미지 각각에서 상기 대상자의 바운딩 박스 영역을 검출하고, 상기 검출된 바운딩 박스 영역에 해당하는 이미지들을 소정의 학습된 제1 딥러닝 모델에 적용하여 상기 대상자의 동작과 상기 대상자의 위치를 검출하며, 상기 검출된 동작과 위치에 대한 정보를 소정의 학습된 제2 딥러닝 모델에 적용하여 상기 대상자가 가지고 있는 복수의 감정 종류에 대한 정보를 출력하는 프로세서를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>9. 제 8항에 있어서,상기 프로세서는 상기 출력한 복수의 감정 종류에 대한 정보를 소정의 학습된 제3 딥러닝 모델에 적용하여 상기 대상자의 학습 몰입도에 대해 출력하는, 장치.</claim></claimInfo><claimInfo><claim>10. 이미지 기반으로 대상자의 동작과 감정을 함께 검출할 수 있는 방법에 있어서,통신부가 상기 대상자의 연속 동작에 대한 복수의 이미지를 수신하는 단계;프로세서가 상기 수신된 상기 복수의 이미지 각각에서 상기 대상자의 바운딩 박스 영역을 검출하는 단계; 상기 프로세서가 상기 검출된 바운딩 박스 영역에 해당하는 이미지들을 소정의 학습된 제1 딥러닝 모델에 적용하여 상기 대상자의 동작과 상기 대상자의 위치를 검출하는 단계; 및상기 프로세서가 상기 검출된 동작과 위치에 대한 정보를 소정의 학습된 제2 딥러닝 모델에 적용하여 상기 대상자가 가지고 있는 복수의 감정 종류에 대한 정보를 출력하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제 6항 또는 제 7항 중 어느 한 항에 기재된 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터-판독가능한 기록매체.</claim></claimInfo><claimInfo><claim>12. 제 10항 중 어느 한 항에 기재된 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터-판독가능한 기록매체. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 노원구...</address><code>220040102654</code><country>대한민국</country><engName>Kwangwoon University Industry-Academic Collaboration Foundation</engName><name>광운대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 남양주시 덕송*로*...</address><code> </code><country> </country><engName>Ki-Baek LEE</engName><name>이기백</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 강남구 도산대로 **길 **, *층 ***호(엠아이피국제특허법률사무소)</address><code>920110004572</code><country>대한민국</country><engName>PARK, Jeong Hwan</engName><name>박정환</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.22</receiptDate><receiptNumber>1-1-2023-1443547-96</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.05.12</receiptDate><receiptNumber>4-1-2025-5125830-64</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230189320.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b50b5d14733fc9b3a52cebdb39afc4359a33036f3193425cee1c3d3eceab75d7a52f3bdae257e69a5c24813f4590970f878984e417d96a99</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0ce06e803298f60705548be801cc1d01058ee2e16012ad86815e830b7d5daebff7c9a5ba46b49f3e123b19e4d4c787a81074618c1fbd8ac8</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>