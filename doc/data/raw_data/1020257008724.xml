<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:58.758</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7008724</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>확산-기반 데이터 압축</inventionTitle><inventionTitleEng>DIFFUSION-BASED DATA COMPRESSION</inventionTitleEng><openDate>2025.06.04</openDate><openNumber>10-2025-0078907</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.17</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/094</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/047</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/088</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/137</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/147</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/162</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/86</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 조정가능한 수의 샘플링 단계들로 구성될 수 있는 잔차 모델을 사용하여 이미지 데이터를 프로세싱하기 위한 시스템들 및 기법들이 설명된다. 예를 들어, 프로세스는 이미지의 잠재 표현을 획득하는 단계 및 기계 학습 모델의 디코더를 사용하여, 초기 복원된 이미지를 생성하기 위해 이미지의 잠재 표현을 프로세싱하는 단계를 포함할 수 있다. 프로세스는 추가로, 잔차 모델을 사용하여, 다수의 샘플링 단계들에 걸쳐 잔차의 복수의 예측들을 예측하기 위해 초기 복원된 이미지 및 잡음 데이터를 프로세싱하는 단계를 포함할 수 있다. 잔차는 이미지와 초기 복원된 이미지 간의 차이를 나타낸다. 프로세스는 잔차의 복수의 예측들로부터, 이미지와 초기 복원된 이미지 사이의 상기 차이를 나타내는 최종 잔차를 획득하는 단계를 포함할 수 있다. 프로세스는 추가로, 초기 복원된 이미지 및 잔차를 결합하여 최종 복원된 이미지를 생성하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.04.04</internationOpenDate><internationOpenNumber>WO2024073213</internationOpenNumber><internationalApplicationDate>2023.08.30</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/073204</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 데이터를 프로세싱하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,이미지의 잠재 표현을 획득하고;기계 학습 모델의 디코더를 사용하여, 초기 복원된 이미지를 생성하기 위해 상기 이미지의 상기 잠재 표현을 프로세싱하고;잔차 모델을 사용하여, 다수의 샘플링 단계들에 걸쳐 잔차의 복수의 예측들을 예측하기 위해 상기 초기 복원된 이미지 및 잡음 데이터를 프로세싱하는 것으로서, 상기 잔차는 상기 이미지와 상기 초기 복원된 이미지 사이의 차이를 나타내는, 상기 초기 복원된 이미지 및 잡음 데이터를 프로세싱하고;상기 잔차의 상기 복수의 예측들로부터, 상기 이미지와 상기 초기 복원된 이미지 사이의 상기 차이를 나타내는 최종 잔차를 획득하며; 그리고상기 초기 복원된 이미지와 상기 잔차를 결합하여 최종 복원된 이미지를 생성하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 샘플링 단계들의 수는, 상기 잠재 표현의 레이트, 상기 최종 복원된 이미지의 지각 품질, 및 상기 이미지와 상기 최종 복원된 이미지 사이의 왜곡 중에서의 트레이드오프를 획득하기 위해 조정가능한, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 적어도 하나의 프로세서는,상기 샘플링 단계들의 수를 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 적어도 하나의 프로세서는,설정에 기초하여 상기 샘플링 단계들의 수를 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 적어도 하나의 프로세서는,입력에 기초하여 상기 설정을 구성하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 적어도 하나의 프로세서는,상기 입력을 수신하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서, 상기 입력은 사용자 인터페이스를 통해 수신된 사용자 입력을 포함하는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>8. 제5항에 있어서, 상기 입력은 컴퓨팅 디바이스와 연관된 제약에 기초하고, 상기 제약은 상기 컴퓨팅 디바이스의 컴퓨팅 제약, 상기 컴퓨팅 디바이스의 전력 제약, 또는 상기 컴퓨팅 디바이스와 연관된 레이턴시 제약 중 적어도 하나를 포함하는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 적어도 하나의 프로세서는,상기 최종 복원된 이미지에 대한 타겟 지각 품질 및 충실도 트레이드-오프에 기초하여 상기 샘플링 단계들의 수를 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 잔차 모델은 상기 초기 복원된 이미지 상에서 컨디셔닝되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 잔차 모델은 추가로, 상기 이미지의 보조 잠재 표현 상에서 컨디셔닝되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 적어도 하나의 프로세서는,제1 샘플링 단계에서 상기 잔차 모델을 사용하여, 상기 잔차의 제1 예측을 예측하기 위해 상기 초기 복원된 이미지 및 상기 잡음 데이터를 프로세싱하고; 그리고제2 샘플링 단계에서 상기 잔차 모델을 사용하여, 상기 잔차의 제2 예측을 예측하기 위해 상기 초기 복원된 이미지 및 상기 잔차의 상기 제1 예측을 프로세싱하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 적어도 하나의 프로세서는,제3 샘플링 단계에서 상기 잔차 모델을 사용하여, 상기 최종 잔차를 예측하기 위해 상기 초기 복원된 이미지 및 상기 잔차의 이전 예측을 프로세싱하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 잔차의 상기 이전 예측은 상기 잔차의 상기 제2 예측인, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서, 상기 제3 샘플링 단계는 최종 샘플링 단계이고, 상기 잔차의 상기 이전 예측은 상기 최종 샘플링 단계 직전의 샘플링 단계에서 결정된 잔차 예측인, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서, 상기 적어도 하나의 프로세서는,상기 이미지를 획득하고; 그리고상기 기계 학습 모델의 인코더를 사용하여, 상기 이미지의 상기 잠재 표현을 생성하기 위해 상기 이미지를 프로세싱하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서, 상기 적어도 하나의 프로세서는,상기 이미지의 보조 잠재 표현을 획득하고; 그리고상기 잔차 모델을 사용하여, 상기 잔차의 상기 복수의 예측들을 예측하기 위해 상기 초기 복원된 이미지, 상기 잡음 데이터, 및 상기 이미지의 상기 보조 잠재 표현을 프로세싱하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제1항에 있어서, 상기 잔차 모델은 확산 모델 또는 순환 뉴럴 네트워크(RNN) 중 하나를 포함하는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>19. 제1항에 있어서, 상기 복수의 예측들은 예측들의 시퀀스를 포함하는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>20. 이미지 데이터를 프로세싱하는 방법으로서,이미지의 잠재 표현을 획득하는 단계;기계 학습 모델의 디코더를 사용하여, 초기 복원된 이미지를 생성하기 위해 상기 이미지의 상기 잠재 표현을 프로세싱하는 단계;잔차 모델을 사용하여, 다수의 샘플링 단계들에 걸쳐 잔차의 복수의 예측들을 예측하기 위해 상기 초기 복원된 이미지 및 잡음 데이터를 프로세싱하는 단계로서, 상기 잔차는 상기 이미지와 상기 초기 복원된 이미지 사이의 차이를 나타내는, 상기 초기 복원된 이미지 및 잡음 데이터를 프로세싱하는 단계;상기 잔차의 상기 복수의 예측들로부터, 상기 이미지와 상기 초기 복원된 이미지 사이의 상기 차이를 나타내는 최종 잔차를 획득하는 단계; 및상기 초기 복원된 이미지와 상기 잔차를 결합하여 최종 복원된 이미지를 생성하는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 샘플링 단계들의 수는, 상기 잠재 표현의 레이트, 상기 최종 복원된 이미지의 지각 품질, 및 상기 이미지와 상기 최종 복원된 이미지 사이의 왜곡 중에서의 트레이드오프를 획득하기 위해 조정가능한, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>22. 제20항에 있어서,입력에 기초하여 설정을 구성하는 단계로서, 상기 입력은 컴퓨팅 디바이스와 연관된 제약에 기초하고, 상기 제약은 상기 컴퓨팅 디바이스의 컴퓨팅 제약, 상기 컴퓨팅 디바이스의 전력 제약, 또는 상기 컴퓨팅 디바이스와 연관된 레이턴시 제약 중 적어도 하나를 포함하는, 상기 설정을 구성하는 단계; 및상기 설정에 기초하여 상기 샘플링 단계들의 수를 결정하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>23. 제20항에 있어서,상기 최종 복원된 이미지에 대한 타겟 지각 품질 및 충실도 트레이드-오프에 기초하여 상기 샘플링 단계들의 수를 결정하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>24. 제20항에 있어서, 상기 잔차 모델은 상기 초기 복원된 이미지 상에서 컨디셔닝되는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 잔차 모델은 추가로, 상기 이미지의 보조 잠재 표현 상에서 컨디셔닝되는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>26. 제20항에 있어서,제1 샘플링 단계에서 상기 잔차 모델을 사용하여, 상기 잔차의 제1 예측을 예측하기 위해 상기 초기 복원된 이미지 및 상기 잡음 데이터를 프로세싱하는 단계; 및제2 샘플링 단계에서 상기 잔차 모델을 사용하여, 상기 잔차의 제2 예측을 예측하기 위해 상기 초기 복원된 이미지 및 상기 잔차의 상기 제1 예측을 프로세싱하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서,제3 샘플링 단계에서 상기 잔차 모델을 사용하여, 상기 최종 잔차를 예측하기 위해 상기 초기 복원된 이미지 및 상기 잔차의 이전 예측을 프로세싱하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>28. 제20항에 있어서,상기 이미지를 획득하는 단계; 및상기 기계 학습 모델의 인코더를 사용하여, 상기 이미지의 상기 잠재 표현을 생성하기 위해 상기 이미지를 프로세싱하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>29. 제20항에 있어서,상기 이미지의 보조 잠재 표현을 획득하는 단계; 및상기 잔차 모델을 사용하여, 상기 잔차의 상기 복수의 예측들을 예측하기 위해 상기 초기 복원된 이미지, 상기 잡음 데이터, 및 상기 이미지의 상기 보조 잠재 표현을 프로세싱하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>30. 제20항에 있어서, 상기 잔차 모델은 확산 모델 또는 순환 뉴럴 네트워크(RNN) 중 하나를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>인도</country><engName>MOHAMED GHOUSE, NOOR FATHIMA KHANUM</engName><name>모하메드 고우스 누르 파티마 카눔</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>독일</country><engName>PETERSEN, JENS</engName><name>페터젠 옌스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>XU, TIANLIN</engName><name>수 톈린</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>프랑스</country><engName>SAUTIERE, GUILLAUME KONRAD</engName><name>소띠에르 기욤 콘라드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>네덜란드</country><engName>WIGGERS, AUKE JORIS</engName><name>비허르스 아우커 요리스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.27</priorityApplicationDate><priorityApplicationNumber>63/410,581</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.08.29</priorityApplicationDate><priorityApplicationNumber>18/458,006</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.17</receiptDate><receiptNumber>1-1-2025-0300262-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.05.01</receiptDate><receiptNumber>1-5-2025-0073553-75</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257008724.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9351e454fd4c7cb381b1c0734e4eecc60613af8442c2d5f9d8942df69711dff0ccb1449675f10c6da93c015bac88389c4f3f789de2bf3d8260</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff3a2680d1840595990e57e90bd7f5ac8b483850c56efdd09235f542a54c0826d781da60fb64745c17a0a770f4b5f3d30c3256280fd6aa76a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>