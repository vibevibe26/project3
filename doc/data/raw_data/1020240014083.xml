<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:21.521</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0014083</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>블러 세그멘테이션 기반의 이미지 개선 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR IMAGE ENHANCEMENT BASED ON BLUR SEGMENTATION</inventionTitleEng><openDate>2025.05.08</openDate><openNumber>10-2025-0061580</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/42</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 블러 세그멘테이션 기반의 이미지 개선 방법 및 장치가 제공된다. 그 방법은 블러 이미지의 각 픽셀의 블러 특성을 미리 정해진 블러 특성 후보들 중 하나로 분류함으로써, 블러 이미지의 각 픽셀의 블러 특성을 나타내는 블러 세그멘테이션 맵을 생성하고, 블러 세그멘테이션 맵을 블러 이미지와 디블러 이미지 간의 차이에 대응하는 이미지 잔차 에러로 변환하고, 블러 이미지 및 이미지 잔차 에러에 기초하여 디블러 이미지를 생성하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 블러 이미지의 각 픽셀의 블러 특성을 미리 정해진 블러 특성 후보들 중 하나로 분류함으로써, 상기 블러 이미지의 각 픽셀의 상기 블러 특성을 나타내는 블러 세그멘테이션 맵을 생성하는 단계;상기 블러 세그멘테이션 맵을 상기 블러 이미지와 디블러 이미지 간의 차이에 대응하는 이미지 잔차 에러로 변환하는 단계; 및상기 블러 이미지 및 상기 이미지 잔차 에러에 기초하여 상기 디블러 이미지를 생성하는 단계를 포함하는 이미지 개선 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 블러 세그멘테이션 맵은특징 표현들(feature representations)을 포함하고, 상기 특징 표현들을 이용하여 상기 블러 이미지의 각 픽셀의 블러 특성을 나타내는,이미지 개선 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 특징 표현들은 상기 블러 이미지의 픽셀들과 대응 쌍들을 구성하고,상기 대응 쌍들의 제1 대응 쌍은 상기 특징 표현들의 제1 특징 표현 및 상기 픽셀들의 제1 픽셀을 포함하고, 상기 제1 특징 표현은 상기 제1 픽셀의 블러 특성을 나타내는,이미지 개선 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 이미지 잔차 에러는상기 블러 특성 후보들에 기초한 상기 블러 세그멘테이션 맵의 이산적인 포맷의 특징 표현들을 연속적인 포맷의 픽셀 값들로 표현하는,이미지 개선 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 블러 세그멘테이션 맵을 생성하는 단계는미리 트레이닝된 뉴럴 클러스터링 모델을 이용하여 상기 블러 이미지에 대응하는 상기 블러 세그멘테이션 맵을 생성하는 단계를 포함하고,상기 블러 세그멘테이션 맵을 상기 이미지 잔차 에러로 변환하는 단계는미리 트레이닝된 뉴럴 변환 모델을 이용하여 상기 블러 세그멘테이션 맵을 상기 이미지 잔차 에러로 변환하는 단계를 포함하는,이미지 개선 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 뉴럴 변환 모델을 이용하여 상기 블러 세그멘테이션 맵을 상기 이미지 잔차 에러로 변환하는 단계는상기 블러 이미지 및 상기 블러 세그멘테이션 맵을 포함하는 입력 데이터로 상기 뉴럴 변환 모델을 실행함으로써 상기 블러 세그멘테이션 맵을 상기 이미지 잔차 에러로 변환하는 단계를 포함하는,이미지 개선 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 뉴럴 클러스터링 모델은뉴럴 커널 추정 모델을 이용하여 제1 샘플 블러 이미지의 기초 커널들을 생성하는 단계;상기 기초 커널들을 이용하여 상기 제1 샘플 블러 이미지를 디컨볼루션함으로써 제1 중간 디컨볼루션 결과들을 생성하는 단계;상기 뉴럴 클러스터링 모델을 이용하여 상기 제1 샘플 블러 이미지의 제1 샘플 블러 세그멘테이션 맵을 생성하는 단계;상기 제1 샘플 블러 세그멘테이션 맵의 특징 표현들을 이용하여 상기 제1 중간 디컨볼루션 결과들로부터 제1 최종 디컨볼루션 결과의 픽셀들을 샘플링함으로써 상기 제1 최종 디컨볼루션 결과를 생성하는 단계; 및상기 제1 최종 디컨볼루션 결과와 제1 샘플 샤프 이미지 간의 차이가 줄어들도록, 상기 뉴럴 클러스터링 모델 및 상기 뉴럴 커널 추정 모델을 트레이닝하는 단계에 기초하여 트레이닝되는, 이미지 개선 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 기초 커널들의 개수는상기 미리 정해진 블러 특성 후보들의 개수와 동일하게 설정되는,이미지 개선 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 제1 최종 디컨볼루션 결과를 생성하는 단계는상기 제1 샘플 블러 세그멘테이션 맵의 상기 특징 표현들 중 제1 위치의 특징 표현에 기초하여 상기 제1 중간 디컨볼루션 결과들의 상기 제1 위치의 대응 위치의 픽셀 값들 중 하나를 선택함으로써 상기 제1 최종 디컨볼루션 결과의 상기 제1 위치의 대응 위치의 픽셀 값을 결정하는 단계를 포함하는,이미지 개선 방법.</claim></claimInfo><claimInfo><claim>10. 제5항에 있어서,상기 뉴럴 변환 모델은상기 뉴럴 클러스터링 모델의 트레이닝이 완료되면, 상기 뉴럴 클러스터링 모델을 이용하여 제2 샘플 블러 이미지의 제2 샘플 블러 세그멘테이션 맵을 생성하는 단계;상기 뉴럴 변환 모델을 이용하여 상기 제2 샘플 블러 세그멘테이션 맵을 상기 제2 샘플 블러 이미지와 제2 샘플 디블러 이미지 간의 차이에 대응하는 샘플 이미지 잔차 에러로 변환하는 단계;상기 제2 샘플 블러 이미지 및 상기 샘플 이미지 잔차 에러에 기초하여 상기 제2 샘플 디블러 이미지를 생성하는 단계; 및상기 뉴럴 클러스터링 모델이 동결된 상태에서, 상기 제2 샘플 디블러 이미지와 제2 샘플 샤프 이미지 간의 차이가 줄어들도록, 상기 뉴럴 변환 모델을 트레이닝하는 단계에 기초하여 트레이닝되는, 이미지 개선 방법.</claim></claimInfo><claimInfo><claim>11. 하드웨어와 결합되어 제1항 내지 제10항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 전자 장치에 있어서,하나 이상의 프로세서; 및명령어들을 저장하는 메모리를 포함하고,상기 명령어들이 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 전자 장치로 하여금,블러 이미지의 각 픽셀의 블러 특성들을 미리 정해진 블러 특성 후보들 중 하나로 분류함으로써, 상기 블러 이미지의 각 픽셀의 상기 블러 특성들을 나타내는 블러 세그멘테이션 맵을 생성하고,상기 블러 세그멘테이션 맵을 상기 블러 이미지와 디블러 이미지 간의 차이에 대응하는 이미지 잔차 에러로 변환하고,상기 블러 이미지 및 상기 이미지 잔차 에러에 기초하여 상기 디블러 이미지를 생성하도록 하는,전자 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 블러 세그멘테이션 맵은특징 표현들(feature representations)을 포함하고, 상기 특징 표현들을 이용하여 상기 블러 이미지의 각 픽셀의 블러 특성을 나타내는,전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 특징 표현들은 상기 블러 이미지의 픽셀들과 대응 쌍들을 구성하고,상기 대응 쌍들의 제1 대응 쌍은 상기 특징 표현들의 제1 특징 표현 및 상기 픽셀들의 제1 픽셀을 포함하고, 상기 제1 특징 표현은 상기 제1 픽셀의 블러 특성을 나타내는,전자 장치.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 블러 세그멘테이션 맵은상기 이미지 잔차 에러의 연속적인 포맷의 픽셀 값들을 상기 블러 특성 후보들에 기초한 이산적인 포맷으로 표현하는,전자 장치.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 명령어들이 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 전자 장치로 하여금,미리 트레이닝된 뉴럴 클러스터링 모델을 이용하여 상기 블러 이미지에 대응하는 상기 블러 세그멘테이션 맵을 생성하고,미리 트레이닝된 뉴럴 변환 모델을 이용하여 상기 블러 세그멘테이션 맵을 상기 이미지 잔차 에러로 변환하도록 하는,전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 뉴럴 클러스터링 모델은뉴럴 커널 추정 모델을 이용하여 제1 샘플 블러 이미지의 기초 커널들을 생성하는 단계;상기 기초 커널들을 이용하여 상기 제1 샘플 블러 이미지를 디컨볼루션함으로써 제1 중간 디컨볼루션 결과들을 생성하는 단계;상기 뉴럴 클러스터링 모델을 이용하여 상기 제1 샘플 블러 이미지의 제1 샘플 블러 세그멘테이션 맵을 생성하는 단계;상기 제1 샘플 블러 세그멘테이션 맵의 특징 표현들을 이용하여 상기 제1 중간 디컨볼루션 결과들로부터 제1 최종 디컨볼루션 결과의 픽셀들을 샘플링함으로써 상기 제1 최종 디컨볼루션 결과를 생성하는 단계; 및상기 제1 최종 디컨볼루션 결과와 제1 샘플 샤프 이미지 간의 차이가 줄어들도록, 상기 뉴럴 클러스터링 모델 및 상기 뉴럴 커널 추정 모델을 트레이닝하는 단계에 기초하여 트레이닝되는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 기초 커널들의 개수는상기 미리 정해진 블러 특성 후보들의 개수와 동일하게 설정되는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서,상기 명령어들이 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 전자 장치로 하여금, 상기 제1 최종 디컨볼루션 결과를 생성하기 위해,상기 제1 샘플 블러 세그멘테이션 맵의 상기 특징 표현들 중 제1 위치의 특징 표현에 기초하여 상기 제1 중간 디컨볼루션 결과들의 상기 제1 위치의 대응 위치의 픽셀 값들 중 하나를 선택함으로써 상기 제1 최종 디컨볼루션 결과의 상기 제1 위치의 대응 위치의 픽셀 값을 결정하도록 하는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서,상기 뉴럴 변환 모델은상기 뉴럴 클러스터링 모델의 트레이닝이 완료되면, 상기 뉴럴 클러스터링 모델을 이용하여 제2 샘플 블러 이미지의 제2 샘플 블러 세그멘테이션 맵을 생성하는 단계;상기 뉴럴 변환 모델을 이용하여 상기 제2 샘플 블러 세그멘테이션 맵을 상기 제2 샘플 블러 이미지와 제2 샘플 디블러 이미지 간의 차이에 대응하는 샘플 이미지 잔차 에러로 변환하는 단계;상기 제2 샘플 블러 이미지 및 상기 샘플 이미지 잔차 에러에 기초하여 상기 제2 샘플 디블러 이미지를 생성하는 단계; 및상기 뉴럴 클러스터링 모델이 동결된 상태에서, 상기 제2 샘플 디블러 이미지와 제2 샘플 샤프 이미지 간의 차이가 줄어들도록, 상기 뉴럴 변환 모델을 트레이닝하는 단계에 기초하여 트레이닝되는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code>420180510946</code><country>대한민국</country><engName>KIM, In Soo</engName><name>김인수</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420210463347</code><country>대한민국</country><engName>SEO, Geon Seok</engName><name>서건석</name></inventorInfo><inventorInfo><address>경기도 용인시 수지구...</address><code>420200358138</code><country>대한민국</country><engName>CHOI, Jae Seok</engName><name>최재석</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420180786048</code><country>대한민국</country><engName>LEE, Hyong Euk</engName><name>이형욱</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.10.27</priorityApplicationDate><priorityApplicationNumber>1020230145879</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.01.30</receiptDate><receiptNumber>1-1-2024-0119049-15</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240014083.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93036444d076c97611e96463e95925fff57fdceac9140b381f0f1f66a6697a8b9aff5b4b54264068a4986992d438aa51b3af5958026d7bfbf5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf79c7f827b03b71dfe87b3b93ca0dabe5011f5a2b573268b8fd93baba29ba21dde8e327d9cf86fa3709971b820d11adf259b1445b99ba2ca2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>