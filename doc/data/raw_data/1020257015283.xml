<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:19.4019</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7015283</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>에너지 효율적인 적응적 3D 감지</inventionTitle><inventionTitleEng>ENERGY-EFFICIENT ADAPTIVE 3D SENSING</inventionTitleEng><openDate>2025.06.16</openDate><openNumber>10-2025-0087636</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.05.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.05.09</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 5/222</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/239</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/254</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/271</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 9/31</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01B 11/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 에너지 효율적인 적응적 3D 감지 시스템. 적응적 3D 감지 시스템은 하나 이상의 카메라 및 하나 이상의 프로젝터를 포함한다. 적응적 3D 감지 시스템은 하나 이상의 카메라를 사용하여 현실 세계 장면의 이미지들을 캡처하고, 이미지들의 픽셀들에 대한 깊이 추정치들 및 깊이 추정 신뢰도 값들을 계산한다. 적응적 3D 감지 시스템은 하나 이상의 깊이 추정 신뢰도 값에 기초하여 어텐션 마스크를 계산하고, 어텐션 마스크에 기초하여 현실 세계 장면의 하나 이상의 영역에 분산형 레이저 빔을 보내도록 하나 이상의 프로젝터에 커맨딩한다. 적응적 3D 감지 시스템은 현실 세계 장면의 하나 이상의 영역의 3D 감지 이미지 데이터를 캡처하고, 3D 감지 이미지 데이터에 기초하여 현실 세계 장면에 대한 3D 감지 데이터를 생성한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.04.18</internationOpenDate><internationOpenNumber>WO2024081154</internationOpenNumber><internationalApplicationDate>2023.10.05</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/034564</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 시스템으로서,하나 이상의 카메라;하나 이상의 프로젝터;상기 하나 이상의 카메라 및 상기 하나 이상의 프로젝터에 동작가능하게 연결된 하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 동작가능하게 연결된 메모리를 포함하고, 상기 메모리는, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금 동작들을 수행하게 하는 명령어들을 저장하고, 상기 동작들은:상기 하나 이상의 카메라를 사용하여, 현실 세계 장면의 이미지 데이터를 캡처하는 것;상기 이미지 데이터에 기초하여 어텐션 마스크(attention mask)를 계산하는 것;상기 어텐션 마스크에 기초하여 상기 현실 세계 장면의 영역에 분산형 레이저 빔(distributed laser beam)을 보내도록 상기 하나 이상의 프로젝터에 커맨딩하는 것;상기 하나 이상의 카메라를 사용하여, 하나 이상의 프로젝터가 상기 현실 세계 장면의 영역에 상기 분산형 레이저 빔을 보내고 있는 동안 상기 현실 세계 장면의 영역의 3차원(3D) 감지 이미지 데이터를 캡처하는 것; 및상기 3D 감지 이미지 데이터에 기초하여 상기 현실 세계 장면에 대한 3D 감지 데이터를 생성하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 프로젝터는 공간 광 변조기(Spatial Light Modulator, SLM) 기반 프로젝터들인, 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 하나 이상의 프로젝터는 MEMS(Microelectromechanical System)+DOE(Diffractive Optical Element) 기반 프로젝터들인, 시스템.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 하나 이상의 MEMS+DOE 기반 프로젝터는 랜덤화된 패턴을 포함하도록 상기 분산형 레이저 빔을 생성하는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 동작들은:깊이 추정 신뢰도 값에 기초하여 상기 현실 세계 장면의 영역을 결정하는 것을 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 동작들은:확장 현실(eXtended Reality, XR) 애플리케이션의 XR 사용자 인터페이스의 가상 객체의 현실 세계 장면에서의 위치에 기초하여 상기 현실 세계 장면의 영역을 결정하는 것을 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 동작들은:상기 현실 세계 장면의 이미지 데이터에 기초하여 상기 현실 세계 장면의 3D 모델을 생성하는 것;상기 시스템의 위치 데이터에 기초하여 상기 현실 세계 장면의 영역이 상기 3D 모델에서 맵핑되지 않는다고 결정하는 것; 및상기 현실 세계 장면의 영역이 상기 3D 모델에서 맵핑되지 않는다고 결정하는 것에 응답하여 상기 현실 세계 장면의 영역을 지정하는 것을 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 시스템은 머리 착용형 디바이스(head-worn device)를 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 시스템은 스마트폰을 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>10. 컴퓨터에 의해 구현되는 방법(computer-implemented method)으로서,시스템의 하나 이상의 카메라를 사용하여, 현실 세계 장면의 이미지 데이터를 캡처하는 단계;상기 이미지 데이터에 기초하여 어텐션 마스크를 계산하는 단계;상기 어텐션 마스크에 기초하여 상기 현실 세계 장면의 영역에 분산형 레이저 빔을 보내도록 상기 시스템의 하나 이상의 프로젝터에 커맨딩하는 단계;상기 하나 이상의 카메라를 사용하여, 하나 이상의 프로젝터가 상기 현실 세계 장면의 영역에 상기 분산형 레이저 빔을 보내고 있는 동안 상기 현실 세계 장면의 영역의 3차원(3D) 감지 이미지 데이터를 캡처하는 단계; 및상기 3D 감지 이미지 데이터에 기초하여 상기 현실 세계 장면에 대한 3D 감지 데이터를 생성하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 하나 이상의 프로젝터는 공간 광 변조기(Spatial Light Modulator, SLM) 기반 프로젝터들인, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 하나 이상의 프로젝터는 MEMS(Microelectromechanical System)+DOE(Diffractive Optical Element) 기반 프로젝터들인, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 하나 이상의 MEMS+DOE 기반 프로젝터는 랜덤화된 패턴을 포함하도록 상기 분산형 레이저 빔을 생성하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,깊이 추정 신뢰도 값에 기초하여 상기 현실 세계 장면의 영역을 결정하는 단계를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서,확장 현실(eXtended Reality, XR) 애플리케이션의 XR 사용자 인터페이스의 가상 객체의 현실 세계 장면에서의 위치에 기초하여 상기 현실 세계 장면의 영역을 결정하는 단계를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>16. 제10항에 있어서,상기 현실 세계 장면의 이미지 데이터에 기초하여 상기 현실 세계 장면의 3D 모델을 생성하는 단계;상기 시스템의 위치 데이터에 기초하여 상기 현실 세계 장면의 영역이 상기 3D 모델에서 맵핑되지 않는다고 결정하는 단계; 및상기 현실 세계 장면의 영역이 상기 3D 모델에서 맵핑되지 않는다고 결정하는 것에 응답하여 상기 현실 세계 장면의 영역을 지정하는 단계를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서, 상기 시스템은 머리 착용형 디바이스를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>18. 제10항에 있어서, 상기 시스템은 스마트폰을 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>19. 비일시적 컴퓨터 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금 동작들을 수행하게 하는 명령어들을 포함하고, 상기 동작들은:하나 이상의 카메라를 사용하여, 현실 세계 장면의 이미지 데이터를 캡처하는 것;상기 이미지 데이터에 기초하여 어텐션 마스크를 계산하는 것;상기 어텐션 마스크에 기초하여 상기 현실 세계 장면의 영역에 분산형 레이저 빔을 보내도록 하나 이상의 프로젝터에 커맨딩하는 것;상기 하나 이상의 카메라를 사용하여, 하나 이상의 프로젝터가 상기 현실 세계 장면의 영역에 상기 분산형 레이저 빔을 보내고 있는 동안 상기 현실 세계 장면의 영역의 3차원(3D) 감지 이미지 데이터를 캡처하는 것; 및상기 3D 감지 이미지 데이터에 기초하여 상기 현실 세계 장면에 대한 3D 감지 데이터를 생성하는 것을 포함하는, 비일시적 컴퓨터 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 동작들은:깊이 추정 신뢰도 값에 기초하여 상기 현실 세계 장면의 영역을 결정하는 것을 추가로 포함하는, 비일시적 컴퓨터 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>WANG, Jian</engName><name>왕, 지안</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>MA, Sizhuo</engName><name>마, 시주오</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>미국</country><engName>TILMON, Brevin</engName><name>틸몬, 브레빈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>WU, Yicheng</engName><name>우, 이청</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>인도</country><engName>KRISHNAN GORUMKONDA, Gurunandan</engName><name>크리쉬난 고룸콘다, 구루난단</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>미국</country><engName>ZAHREDDINE, Ramzi</engName><name>자레딘, 람지</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>그리스</country><engName>EVANGELIDIS, Georgios</engName><name>에반젤리디스, 게오르기오스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.04.13</priorityApplicationDate><priorityApplicationNumber>18/299,923</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>그리스</priorityApplicationCountry><priorityApplicationDate>2022.10.12</priorityApplicationDate><priorityApplicationNumber>20220100840</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.05.09</receiptDate><receiptNumber>1-1-2025-0518998-45</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.05.16</receiptDate><receiptNumber>1-5-2025-0081963-13</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257015283.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930df2a32458d87f3b59212d130651a3fedd8fa54f2dc02778ebe23577658e8b84c6c51775b16f52887cffb69f2ed2ce00d323f6c35e8a8ec0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa53785a25e63a6bdf2cbb8d797d231b3f542e393eed4b46d324e26991e6441a18ff2d03d8065b53e23496e0907e2efe6c8a63977e372714f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>