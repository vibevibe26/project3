<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:40.540</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.02.22</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0023209</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>디스플레이 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>A display apparatus and a method thereof</inventionTitleEng><openDate>2023.08.29</openDate><openNumber>10-2023-0126109</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.03</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06Q 50/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/45</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/466</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 음성 인식기 선택을 위한 상황 정보를 획득하는 단계, 상황 정보에 기반하여 복수의 음성 인식기 중 적어도 하나를 선택하는 단계, 선택된 적어도 하나의 음성 인식기를 이용하여, 사용자의 음성 신호로부터 음성 인식 결과를 획득하는 단계 및 음성 인식 결과로부터 채팅 메시지를 획득하는 단계를 포함하는, 디스플레이 장치의 동작 방법이 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디스플레이 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 음성 인식기 선택을 위한 상황 정보를 획득하고,상기 상황 정보에 기반하여 복수의 음성 인식기 중 적어도 하나를 선택하고,상기 선택된 적어도 하나의 음성 인식기를 이용하여, 사용자의 음성 신호로부터 음성 인식 결과를 획득하고,상기 음성 인식 결과로부터 채팅 메시지를 획득하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 디스플레이부를 더 포함하고,상기 프로세서는 상기 디스플레이부가 콘텐츠 및 상기 콘텐츠와 관련한 채팅 룸의 채팅 메시지들을 디스플레이하도록 제어하고, 상기 상황 정보는 상기 콘텐츠에 대한 콘텐츠 정보 및 채팅과 관련한 채팅 정보 중 적어도 하나를 포함하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서, 상기 채팅 정보는 상기 채팅 룸의 타이틀 및 상기 채팅 메시지들의 내용 중 적어도 하나에 대한 정보를 포함하고,상기 콘텐츠 정보는 상기 콘텐츠의 내용, 상기 콘텐츠와 함께 출력되는 음성 신호, 자막, 상기 콘텐츠의 프로그램명, 콘텐츠 주제, 콘텐츠 타입, 콘텐츠 장르, 채널 종류, 방송국, 제작자, 출연자, 감독, 콘텐츠 방영 시간에 대한 정보 중 적어도 하나를 포함하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서, 상기 복수의 음성 인식기 각각은 하나 이상의 서로 다른 학습 데이터로 훈련된 학습 모델을 포함하고, 상기 서로 다른 학습 데이터는 언어 별 학습 데이터, 분야 별 학습 데이터, 프로그램 타입 별 학습 데이터, 프로그램 장르 별 학습 데이터, 방송국 별 학습 데이터, 채널 별 학습 데이터 제작자 별 학습 데이터, 출연자 별 학습 데이터, 감독 별 학습 데이터, 지역 별 학습 데이터, 사용자 정보를 기반으로 획득한 개인화된 학습 데이터, 및 사용자가 속한 집단의 정보를 기반으로 획득한 집단의 학습 데이터 중 적어도 하나를 포함하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 사용자 정보는, 사용자 프로필 정보, 상기 사용자의 시청 이력 정보, 및 상기 사용자가 입력한 채팅 메시지 내용 정보 중 적어도 하나를 포함하고,상기 사용자가 속한 집단의 정보는 상기 사용자와 사용자 정보가 기준치 이상 중복되는 사람들의 프로필 정보, 시청 이력 정보 및 상기 사람들이 입력한 채팅 메시지 내용 정보 중 적어도 하나를 포함하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서, 상기 복수의 음성 인식기 각각은 하나 이상의 서로 다른 학습 데이터로 훈련된 학습 모델을 포함하고, 상기 복수의 음성 인식기는 학습 모델 훈련에 이용된 학습 데이터 종류를 나타내는 라벨 정보로 식별되고,상기 프로세서는 상기 상황 정보와 상기 라벨 정보의 유사도에 기반하여 상기 복수의 음성 인식기 중 적어도 하나를 선택하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 프로세서는 상기 선택된 음성 인식기가 복수개인 것에 상응하여, 상기 복수개의 음성 인식기를 이용하여 상기 사용자의 음성 신호로부터 복수개의 음성 인식 결과를 획득하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서, 디스플레이부를 더 포함하고,상기 프로세서는 상기 복수개의 음성 인식 결과 중에서 가중치 매트릭스를 기반으로 기 정해진 개수 이하의 음성 인식 결과를 필터링하고, 상기 필터링된 음성 인식 결과에 대응하는 채팅 메시지를 획득하고, 상기 채팅 메시지를 상기 디스플레이부를 통해 출력하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서, 상기 프로세서는 상기 디스플레이를 통해 출력된 채팅 메시지가 복수개인 경우, 상기 복수개의 채팅 메시지 중 사용자가 선택한 하나의 채팅 메시지를 채팅 서버로 전송하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서, 상기 프로세서는 상기 사용자의 선택에 기반하여 상기 가중치 매트릭스를 업데이트하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>11. 음성 인식기 선택을 위한 상황 정보를 획득하는 단계;상기 상황 정보에 기반하여 복수의 음성 인식기 중 적어도 하나를 선택하는 단계;상기 선택된 적어도 하나의 음성 인식기를 이용하여, 사용자의 음성 신호로부터 음성 인식 결과를 획득하는 단계; 및상기 음성 인식 결과로부터 채팅 메시지를 획득하는 단계를 포함하는, 디스플레이 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서, 콘텐츠 및 상기 콘텐츠와 관련한 채팅 룸의 채팅 메시지들을 디스플레이하는 단계를 더 포함하고, 상기 상황 정보는 상기 콘텐츠에 대한 콘텐츠 정보 및 채팅과 관련한 채팅 정보 중 적어도 하나를 포함하는, 디스플레이 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서, 상기 채팅 정보는 상기 채팅 룸의 타이틀 정보 및 상기 채팅 메시지들의 내용 정보 중 적어도 하나를 포함하고, 상기 콘텐츠 정보는 상기 콘텐츠의 내용, 상기 콘텐츠와 함께 출력되는 음성 신호, 자막, 상기 콘텐츠의 프로그램명, 콘텐츠 주제, 콘텐츠 타입, 콘텐츠 장르, 채널 종류, 방송국, 제작자, 출연자, 감독, 콘텐츠 방영 시간에 대한 정보 중 적어도 하나를 포함하는, 디스플레이 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>14. 제11 항에 있어서, 상기 복수의 음성 인식기 각각은 하나 이상의 서로 다른 학습 데이터로 훈련된 학습 모델을 포함하고, 상기 서로 다른 학습 데이터는 언어 별 학습 데이터, 분야 별 학습 데이터, 프로그램 타입 별 학습 데이터, 프로그램 장르 별 학습 데이터, 방송국 별 학습 데이터, 채널 별 학습 데이터, 제작자 별 학습 데이터, 출연자 별 학습 데이터, 감독 별 학습 데이터, 지역 별 학습 데이터, 사용자 정보를 기반으로 획득한 개인화된 학습 데이터, 및 상기 사용자가 속한 집단의 정보를 기반으로 획득한 집단의 학습 데이터 중 적어도 하나를 포함하는, 디스플레이 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서, 상기 사용자 정보는, 사용자 프로필 정보, 상기 사용자의 시청 이력 정보, 및 상기 사용자가 입력한 채팅 메시지 내용 정보 중 적어도 하나를 포함하고,상기 사용자가 속한 집단의 정보는 상기 사용자와 사용자 정보가 기준치 이상 중복되는 사람들의 프로필 정보, 시청 이력 정보 및 상기 사람들이 입력한 채팅 메시지 내용 정보 중 적어도 하나를 포함하는, 디스플레이 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>16. 제11 항에 있어서, 상기 복수의 음성 인식기 각각은 하나 이상의 서로 다른 학습 데이터로 훈련된 학습 모델을 포함하고, 상기 복수의 음성 인식기는 학습 모델 훈련에 이용된 학습 데이터 종류를 나타내는 라벨 정보로 식별되고,상기 복수의 음성 인식기 중 적어도 하나를 선택하는 단계는 상기 상황 정보와 상기 라벨 정보의 유사도에 기반하여 상기 복수의 음성 인식기 중 적어도 하나를 선택하는 단계를 포함하는, 디스플레이 장치의 동작 방법. </claim></claimInfo><claimInfo><claim>17. 제16 항에 있어서, 상기 음성 인식 결과를 획득하는 단계는상기 선택된 음성 인식기가 복수 개인 것에 상응하여, 상기 복수개의 음성 인식기를 이용하여 상기 사용자의 음성 신호로부터 복수개의 음성 인식 결과를 획득하는 단계를 포함하는, 디스플레이 장치의 동작 방법. </claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서, 상기 채팅 메시지를 획득하는 단계는상기 복수개의 음성 인식 결과 중에서 가중치 매트릭스를 기반으로 기 정해진 개수 이하의 음성 인식 결과를 필터링하는 단계; 및상기 필터링된 음성 인식 결과에 대응하는 채팅 메시지를 획득하는 단계를 포함하고,상기 방법은 상기 채팅 메시지를 출력하는 단계를 더 포함하는, 디스플레이 장치의 동작 방법. </claim></claimInfo><claimInfo><claim>19. 제18 항에 있어서, 상기 출력된 채팅 메시지가 복수개인 경우, 상기 복수개의 채팅 메시지 중 사용자가 선택한 하나의 채팅 메시지를 상기 채팅 서버로 전송하는 단계를 더 포함하는, 디스플레이 장치의 동작 방법. </claim></claimInfo><claimInfo><claim>20. 음성 인식기 선택을 위한 상황 정보를 획득하는 단계;상기 상황 정보에 기반하여 복수의 음성 인식기 중 적어도 하나를 선택하는 단계;상기 선택된 적어도 하나의 음성 인식기를 이용하여, 사용자의 음성 신호로부터 음성 인식 결과를 획득하는 단계; 및상기 음성 인식 결과로부터 채팅 메시지를 획득하는 단계를 포함하는, 디스플레이 장치의 동작 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>OH, Seok Jae</engName><name>오석재</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Ye Seul</engName><name>박예슬</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEON, Yu Seong</engName><name>전유성</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.02.22</receiptDate><receiptNumber>1-1-2022-0199378-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.02.03</receiptDate><receiptNumber>1-1-2025-0119484-97</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.02.03</receiptDate><receiptNumber>1-1-2025-0119485-32</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220023209.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936a9b5a1d49b4e8451319ed821e9066dbe052eed673eda7f8700bc0df2eac3a3a6f69ae24a575d029e78970793d8c5c0552f284776e4074c3</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd827885b592c67312068f27c15c9c1474e28d017b86bdba390692c255c3a2ead4202ef557f5cd076689f80ffbab5731acd9ad3d93e6454ba</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>