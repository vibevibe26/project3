<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:50.650</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7024262</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자연어 기반 3차원 객체 조작 장치 및 방법</inventionTitle><inventionTitleEng>NATURAL LANGUAGE-BASED THREE-DIMENSIONAL OBJECT MANIPULATION DEVICE AND METHOD</inventionTitleEng><openDate>2025.11.03</openDate><openNumber>10-2025-0156695</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.07.18</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 3차원 객체 조작 모델을 이용하여 자연어 기반으로 대상 객체의 부분 조작을 수행할 수 있는 자연어 기반 3차원 객체 조작 장치 및 방법에 관한 것으로, 사용자 명령어 및 대상 객체가 입력되면 사용자 명령어로부터 대상 객체의 조작 영역과 조작 정보를 추출하고, 제1 렌더링 모델을 통해 대상 객체의 3차원 원본 이미지를 생성하며, 제2 렌더링 모델을 통해 추출한 조작 정보를 기반으로 대상 객체의 3차원 편집 이미지를 생성하고, 추출한 조작 영역을 기반으로 3차원 원본 이미지의 편집 영역을 결정하며, 결정된 편집 영역을 기반으로 3차원 원본 이미지와 3차원 편집 이미지를 브랜딩하여 3차원 타겟 이미지를 생성할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.09.12</internationOpenDate><internationOpenNumber>WO2024186080</internationOpenNumber><internationalApplicationDate>2024.03.04</internationalApplicationDate><internationalApplicationNumber>PCT/KR2024/002739</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1.  제1 렌더링 모델과 제2 렌더링 모델을 저장하는 메모리; 그리고,상기 제1 렌더링 모델과 제2 렌더링 모델을 기반으로 3차원 객체를 조작하는 프로세서를 포함하고,상기 프로세서는,사용자 명령어 및 대상 객체(source object)가 입력되면 상기 사용자 명령어로부터 상기 대상 객체의 조작 영역과 조작 정보를 추출하고, 상기 제1 렌더링 모델을 통해 상기 대상 객체의 3차원 원본 이미지(3D original image)를 생성하며, 상기 제2 렌더링 모델을 통해 상기 추출한 조작 정보를 기반으로 상기 대상 객체의 3차원 편집 이미지(3D editable image)를 생성하고, 상기 추출한 조작 영역을 기반으로 상기 3차원 원본 이미지의 편집 영역(editing region)을 결정하며, 상기 결정된 편집 영역을 기반으로 상기 3차원 원본 이미지와 상기 3차원 편집 이미지를 브랜딩(blending)하여 3차원 타겟 이미지(3D target image)를 생성하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>2.  제1 항에 있어서,상기 프로세서는,상기 대상 객체의 조작 영역과 조작 정보를 추출할 때, 상기 사용자 명령어가 사용자 프롬프트(user prompt)이면 상기 사용자 프롬프트로부터 조작하고자 하는 대상 객체의 조작 영역에 상응하는 소스 텍스트(source text)와 대상 객체의 조작 정보에 상응하는 타겟 텍스트(target text)를 추출하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>3.  제1 항에 있어서,상기 프로세서는,상기 사용자 명령어와 함께 2차원 원본 이미지(2D original image)를 포함하는 대상 객체가 입력되면 상기 2차원 원본 이미지로부터 상기 대상 객체를 인지하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>4.  제3 항에 있어서,상기 대상 객체의 조작 영역은,상기 대상 객체에 상응하는 2차원 원본 이미지 중 전체 영역 또는 일부 영역을 포함하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>5.  제3 항에 있어서,상기 대상 객체의 조작 정보는,상기 대상 객체에 상응하는 2차원 원본 이미지 중 조작하고자 하는 영역의 컬러 변화(changing color), 농도 제거(removing density), 농도 추가(adding density) 중 적어도 어느 하나를 포함하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>6.  제1 항에 있어서,상기 프로세서는,상기 대상 객체의 3차원 원본 이미지를 생성할 때, 상기 대상 객체의 위치 정보를 상기 제1 렌더링 모델에 입력하여 상기 위치 정보에 상응하는 뷰 방향(view direction)을 갖는 3차원 원본 이미지를 생성하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>7.  제6 항에 있어서,상기 프로세서는,상기 대상 객체의 3차원 원본 이미지를 생성할 때, 상기 3차원 원본 이미지에 상응하는 각 픽셀의 컬러(color)와 농도(density)를 획득하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>8.  제1 항에 있어서,상기 프로세서는,상기 대상 객체의 3차원 편집 이미지를 생성할 때, 상기 대상 객체의 위치 정보를 상기 제2 렌더링 모델에 입력하여 상기 위치 정보에 상응하는 뷰 방향(view direction)을 갖는 3차원 편집 이미지를 생성하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>9.  제8 항에 있어서,상기 프로세서는,상기 대상 객체의 3차원 편집 이미지를 생성할 때, 상기 3차원 편집 이미지에 상응하는 각 픽셀의 컬러(color), 농도(density), 상기 컬러의 브랜딩 비율(blending ratios), 그리고 상기 농도의 브랜딩 비율을 획득하고, 상기 컬러의 브랜딩 비율을 기반으로 상기 대상 객체의 3차원 원본 이미지의 브랜딩 컬러를 산출하며, 상기 농도의 브랜딩 비율을 기반으로 상기 대상 객체의 3차원 원본 이미지의 브랜딩 농도를 산출하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>10.  제1 항에 있어서,상기 프로세서는,상기 3차원 원본 이미지의 편집 영역을 결정할 때, 상기 대상 객체의 조작 영역 관련 데이터와 상기 3차원 원본 이미지를 사전 학습한 이미지 세그먼트 모델에 입력하여 상기 3차원 원본 이미지로부터 조작하고자 하는 영역을 분할하고, 상기 분할한 영역을 기반으로 편집 영역을 결정하며, 상기 결정한 편집 영역에 상응하는 편집 영역 마스크를 생성하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>11.  제1 항에 있어서,상기 프로세서는,상기 3차원 타겟 이미지를 생성할 때, 상기 3차원 편집 이미지를 상기 3차원 원본 이미지의 편집 영역에 매칭하고, 미리 획득한 브랜딩 비율을 기반으로 상기 대상 객체의 3차원 원본 이미지의 편집 영역을 조작하여 상기 3차원 타겟 이미지를 생성하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>12.  제11 항에 있어서,상기 프로세서는,상기 대상 객체의 3차원 원본 이미지의 편집 영역을 조작할 때, 상기 미리 획득한 브랜딩 비율을 기반으로 상기 대상 객체의 3차원 원본 이미지의 편집 영역에 대해 컬러 변화(changing color), 농도 추가(adding densities), 농도 제거(removing densities) 중 적어도 어느 하나를 적용하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>13.  제1 항에 있어서,상기 프로세서는,상기 3차원 타겟 이미지를 생성할 때,  (여기서, 은 손실 균형(loss balance)을 위한 하이퍼파라미터(hyperparameter)들이고, 은 편집 영역이 조작된 3차원 타겟 이미지의 총 손실이고, 은 원하는 텍스트에 따라 편집 영역이 조작된 3차원 타겟 이미지의 손실이며, 은 원하는 영역에 따라 편집 영역이 조작된 3차원 타겟 이미지의 손실이고, 와 는 원하는 비율에 따라 편집 영역이 조작된 3차원 타겟 이미지의 손실임)으로 이루어지는 수식을 기반으로 상기 3차원 타겟 이미지를 생성하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>14.  제1 항에 있어서,상기 프로세서는,상기 3차원 타겟 이미지를 생성할 때, 상기 3차원 원본 이미지의 편집 영역에 컬러 변화, 농도 추가, 농도 제거 중 적어도 하나를 포함하는 조작을 수행하여 상기 편집 영역에 상기 3차원 편집 이미지를 브랜딩하는 것을 특징으로 하는 3차원 객체 조작 장치. </claim></claimInfo><claimInfo><claim>15.  사용자 명령어 및 대상 객체(source object)를 입력받는 단계;상기 사용자 명령어 및 대상 객체가 입력되면 상기 사용자 명령어로부터 상기 대상 객체의 조작 영역과 조작 정보를 추출하는 단계;제1 렌더링 모델을 통해 상기 대상 객체의 3차원 원본 이미지(3D original image)를 생성하고, 제2 렌더링 모델을 통해 상기 추출한 조작 정보를 기반으로 상기 대상 객체의 3차원 편집 이미지(3D editable image)를 생성하는 단계;상기 추출한 조작 영역을 기반으로 상기 3차원 원본 이미지의 편집 영역(editing region)을 결정하는 단계; 및상기 결정된 편집 영역을 기반으로 상기 3차원 원본 이미지와 상기 3차원 편집 이미지를 브랜딩(blending)하여 3차원 타겟 이미지(3D target image)를 생성하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 조작 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 영등포구...</address><code>120020128403</code><country>대한민국</country><engName>LG Electronics Inc.</engName><name>엘지전자 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country>대한민국</country><engName>SONG, Hyeonseop</engName><name>송현섭</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country>대한민국</country><engName>KIM, Taehyeong</engName><name>김태형</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country>대한민국</country><engName>CHOI, Seokhun</engName><name>최석훈</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country>대한민국</country><engName>DO, Hoseok</engName><name>도호석</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** 혜천빌딩 ***호(선영특허법률사무소)</address><code>919980006169</code><country>대한민국</country><engName>Haw, Yong Noke</engName><name>허용록</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.03.03</priorityApplicationDate><priorityApplicationNumber>1020230028666</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.07.18</receiptDate><receiptNumber>1-1-2025-0816577-49</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.10.13</receiptDate><receiptNumber>1-5-2025-0167502-84</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257024262.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9324f0ab33db7d39ad0b03c6ed69b5dfd83fe614db8421601d73a5a8cc1be58f2000213b5807fd5f64bb1aaac2a79ac558a9aadd5f4f7d8f29</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff0b851ef961ec9a72c322086234b25672a84b518b77fa0aeeb6ee04fe3e8c683aa1c0268f7a64cd8d23d2384e57423840f97220cbf7a416f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>