<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:12.5612</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.11.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0152573</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>움직임 데이터 기반의 변환 모델을 이용한 영상 처리 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR IMAGE PROCESSING USING  TRANSFORMATION MODEL BASED ON MOTION DATA</inventionTitleEng><openDate>2024.05.22</openDate><openNumber>10-2024-0070985</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.10.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/14</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 움직임 데이터 기반의 변환 모델을 이용한 영상 처리 방법 및 장치가 제공된다. 그 방법은 이미지 센서를 이용하여 제1 시점의 제1 영상 프레임 및 제2 시점의 제2 영상 프레임을 포함하는 입력 영상 데이터를 생성하고, 움직임 센서를 이용하여 제1 시점과 제2 시점 사이의 이미지 센서의 움직임을 나타내는 움직임 데이터를 생성하고, 움직임 데이터로 뉴럴 네트워크 모델을 실행하여, 제1 영상 프레임과 제2 영상 프레임 간의 전역 움직임에 따른 변환을 수행하는 변환 모델을 추정하고, 및 변환 모델을 이용하여 제1 영상 프레임과 제2 영상 프레임을 결합하여 출력 영상 데이터를 생성하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 센서를 이용하여 제1 시점의 제1 영상 프레임 및 제2 시점의 제2 영상 프레임을 포함하는 입력 영상 데이터를 생성하는 단계;움직임 센서를 이용하여 상기 제1 시점과 상기 제2 시점 사이의 상기 이미지 센서의 움직임을 나타내는 움직임 데이터를 생성하는 단계;상기 움직임 데이터로 뉴럴 네트워크 모델을 실행하여, 상기 제1 영상 프레임과 상기 제2 영상 프레임 간의 전역 움직임에 따른 변환을 수행하는 변환 모델을 추정하는 단계; 및상기 변환 모델을 이용하여 상기 제1 영상 프레임과 상기 제2 영상 프레임을 결합하여 출력 영상 데이터를 생성하는 단계를 포함하는 영상 처리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 출력 영상 데이터를 생성하는 단계는상기 변환 모델을 이용하여 상기 제1 영상 프레임 및 상기 제2 영상 프레임을 상기 출력 영상 데이터에 대응하는 비디오 데이터로 인코딩하는 단계를 포함하는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 비디오 데이터는상기 제1 영상 프레임의 픽셀 블록들과 상기 제2 영상 프레임의 픽셀 블록들 간의 매칭 데이터를 포함하고,상기 인코딩하는 단계는상기 변환 모델을 이용하여 상기 제1 영상 프레임의 제1 픽셀 블록의 블록 매칭을 위한 상기 제2 영상 프레임의 서치 영역을 설정하는 단계; 및상기 제2 영상 프레임의 상기 서치 영역에서 상기 제1 영상 프레임의 상기 제1 픽셀 블록에 매칭되는 제2 픽셀 블록을 서치하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 서치 영역을 설정하는 단계는상기 변환 모델을 이용하여 상기 제1 영상 프레임의 상기 제1 픽셀 블록의 제1 위치를 상기 제2 영상 프레임의 제2 위치로 변환하는 단계; 및상기 제2 위치에 따라 상기 제2 영상 프레임의 상기 서치 영역을 설정하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 서치 영역을 설정하는 단계는상기 변환 모델을 이용하여 상기 제1 영상 프레임의 상기 제1 픽셀 블록에 따른 상기 제1 영상 프레임의 기존 서치 영역을 상기 제2 영상 프레임의 상기 서치 영역으로 변환하는 단계를 포함하는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 출력 영상 데이터를 생성하는 단계는상기 변환 모델을 이용하여 상기 제1 영상 프레임과 상기 제2 영상 프레임 간의 상기 전역 움직임을 보상하여 상기 출력 영상 데이터에 대응하는 사진 데이터를 생성하는 단계를 포함하는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 움직임 데이터는상기 제1 시점과 상기 제2 시점 사이의 상기 이미지 센서의 움직임에 따른 가속도 데이터 및 각속도 데이터 중 적어도 일부를 포함하는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 움직임 센서의 제1 센싱 주기는 상기 이미지 센서의 제2 센싱 주기보다 짧고,상기 제2 센싱 주기 동안 수집된 상기 움직임 센서의 출력 데이터가 결합되어 구성된 움직임 데이터가 상기 뉴럴 네트워크 모델에 입력되는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 뉴럴 네트워크 모델은알려진 테스트 패턴을 상기 이미지 센서로 촬영하여 얻은 촬영 결과 및 상기 이미지 센서가 상기 알려진 테스트 패턴을 촬영하는 동안 상기 움직임 센서로 상기 이미지 센서의 움직임을 측정하여 얻은 측정 결과에 기초한 트레이닝 데이터로 미리 트레이닝되는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 뉴럴 네트워크 모델은알려진 테스트 패턴을 상기 이미지 센서로 촬영하여 얻은 테스트 영상 데이터를 비전 분석하여 제1 테스트 변환 모델을 결정하고,상기 이미지 센서가 상기 알려진 테스트 패턴을 촬영하는 동안 상기 움직임 센서로 상기 이미지 센서의 움직임을 측정하여 얻은 테스트 움직임 데이터를 상기 뉴럴 네트워크 모델에 입력하여 제2 테스트 변환 모델을 추정하고,상기 제1 테스트 변환 모델과 상기 제2 테스트 변환 모델 간의 차이에 대응하는 제1 손실 데이터를 결정하고,상기 제1 손실 데이터에 기초하여 상기 뉴럴 네트워크 모델을 트레이닝 하여,미리 트레이닝되는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 뉴럴 네트워크 모델은상기 제1 테스트 변환 모델을 이용하여 추가 테스트 영상을 변환하여 제1 결과 영상을 생성하고,상기 제2 테스트 변환 모델을 이용하여 상기 추가 테스트 영상을 변환하여 제2 결과 영상을 생성하고,상기 제1 결과 영상과 상기 제2 결과 영상 간의 차이에 대응하는 제2 손실 데이터를 결정하고,상기 제1 손실 데이터 및 상기 제2 손실 데이터에 기초하여 상기 뉴럴 네트워크 모델을 트레이닝하여,미리 트레이닝되는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>12. 하드웨어와 결합되어 제1항 내지 제11항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 제1 시점의 제1 영상 프레임 및 제2 시점의 제2 영상 프레임을 포함하는 입력 영상 데이터를 생성하는 이미지 센서;상기 제1 시점과 상기 제2 시점 사이의 상기 이미지 센서의 움직임을 나타내는 움직임 데이터를 생성하는 움직임 센서; 및상기 움직임 데이터로 뉴럴 네트워크 모델을 실행하여, 상기 제1 영상 프레임과 상기 제2 영상 프레임 간의 전역 움직임에 대응하는 변환 모델을 추정하고, 상기 변환 모델을 이용하여 상기 제1 영상 프레임과 상기 제2 영상 프레임을 결합하여 출력 영상 데이터를 생성하는 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 프로세서는상기 변환 모델을 이용하여 상기 제1 영상 프레임 및 상기 제2 영상 프레임을 상기 출력 영상 데이터에 대응하는 비디오 데이터로 인코딩하는 코덱을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 비디오 데이터는상기 제1 영상 프레임의 픽셀 블록들과 상기 제2 영상 프레임의 픽셀 블록들 간의 매칭 데이터를 포함하고,상기 코덱은상기 변환 모델을 이용하여 상기 제1 영상 프레임의 제1 픽셀 블록의 블록 매칭을 위한 상기 제2 영상 프레임의 서치 영역을 설정하고, 상기 제2 영상 프레임의 상기 서치 영역에서 상기 제1 영상 프레임의 상기 제1 픽셀 블록에 매칭되는 제2 픽셀 블록을 서치하는,전자 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 코덱은, 상기 서치 영역을 설정하기 위해,상기 변환 모델을 이용하여 상기 제1 영상 프레임의 상기 제1 픽셀 블록의 제1 위치를 상기 제2 영상 프레임의 제2 위치로 변환하고, 상기 제2 위치에 따라 상기 제2 영상 프레임의 상기 서치 영역을 설정하는,전자 장치.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 코덱은, 상기 서치 영역을 설정하기 위해,상기 변환 모델을 이용하여 상기 제1 영상 프레임의 상기 제1 픽셀 블록에 따른 상기 제1 영상 프레임의 기존 서치 영역을 상기 제2 영상 프레임의 상기 서치 영역으로 변환하는,전자 장치.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서,상기 프로세서는, 상기 출력 영상 데이터를 생성하기 위해,상기 변환 모델을 이용하여 상기 제1 영상 프레임과 상기 제2 영상 프레임 간의 상기 전역 움직임을 보상하여 상기 출력 영상 데이터에 대응하는 사진 데이터를 생성하는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제13항에 있어서,상기 움직임 센서의 제1 센싱 주기는 상기 이미지 센서의 제2 센싱 주기보다 짧고,상기 제2 센싱 주기 동안 수집된 상기 움직임 센서의 출력 데이터가 결합되어 구성된 움직임 데이터가 상기 뉴럴 네트워크 모델에 입력되는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>20. 제13항에 있어서,상기 뉴럴 네트워크 모델은알려진 테스트 패턴을 상기 이미지 센서로 촬영하여 얻은 촬영 결과 및 상기 이미지 센서가 상기 알려진 테스트 패턴을 촬영하는 동안 상기 움직임 센서로 상기 이미지 센서의 움직임을 측정하여 얻은 측정 결과에 기초한 트레이닝 데이터로 미리 트레이닝되는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 양천구...</address><code>420200351124</code><country>대한민국</country><engName>JEE, Seunghoon</engName><name>지승훈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 강남대로 ***, 산학협동재단빌딩 **층(서초동)</address><code>920071000819</code><country>대한민국</country><engName>PanKorea Patent &amp; Law Firm</engName><name>팬코리아특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.11.15</receiptDate><receiptNumber>1-1-2022-1214737-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>불수리 (Non-acceptance) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.09.03</receiptDate><receiptNumber>1-1-2025-1012736-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>불수리 (Non-acceptance) </commonCodeName><documentEngName> </documentEngName><documentName>[반환신청]서류 반려요청서·반환신청서</documentName><receiptDate>2025.09.10</receiptDate><receiptNumber>1-1-2025-1041215-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.09.10</receiptDate><receiptNumber>1-1-2025-1041216-40</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Reason for Return of Document</documentEngName><documentName>서류반려이유통지서</documentName><receiptDate>2025.09.10</receiptDate><receiptNumber>1-5-2025-0154035-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Reason for Return of Document</documentEngName><documentName>서류반려이유통지서</documentName><receiptDate>2025.09.16</receiptDate><receiptNumber>1-5-2025-0158205-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[반려요청]서류 반려요청서·반환신청서</documentName><receiptDate>2025.09.17</receiptDate><receiptNumber>1-1-2025-1067774-03</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice for Return of Document</documentEngName><documentName>서류반려통지서</documentName><receiptDate>2025.09.24</receiptDate><receiptNumber>1-5-2025-0163047-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[반려요청]서류 반려요청서·반환신청서</documentName><receiptDate>2025.09.25</receiptDate><receiptNumber>1-1-2025-1096212-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice for Return of Document</documentEngName><documentName>서류반려통지서</documentName><receiptDate>2025.10.14</receiptDate><receiptNumber>1-5-2025-0169717-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.20</receiptDate><receiptNumber>1-1-2025-1168069-13</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220152573.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a22c639832dc47dcab21ea31cbffe36f09b0e969a6de1aa7f93e79dbef47ea11832b5ca120f3ec817128a3a0241c575a054557a011b2304c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cffb1d27542dd67aa67060b1c9249bbbf3ceb2116c9f2c8d67a24c8b88aec40254d13decfd747212e3ea633d48dda97c063593042c4a36c983</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>