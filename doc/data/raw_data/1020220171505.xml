<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:15.615</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0171505</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>작업 공간을 공유하는 협동 로봇과 사용자 간 인터랙션 시스템 및 협력 작업 상태 관리 방법</inventionTitle><inventionTitleEng>INTERACTION SYSTEM BETWEEN COLLABORATIVE ROBOTS AND  USERS SHARING WORKSPACE AND COLLABORATIVE WORK STATE  CONTROLLING METHOD</inventionTitleEng><openDate>2024.06.19</openDate><openNumber>10-2024-0086878</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 작업 공간을 공유하는 협동 로봇과 사용자 간 인터랙션 시스템 및 협력 작업 상태 관리 방법을 개시한다. 보다 구체적으로, 협력 작업 상태 관리 방법은 스마트 제조 산업 현장에서 협동 로봇과 작업 공간을 공유하는 사용자의 정신 상태 및 신체 상태를 판단하여 협동 로봇을 투입 및 업무 분산을 통해 사용자의 정신 상태 및 신체 상태가 정상 범위에 포함되도록 관리한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 작업 공간을 공유하는 전용 협동 로봇으로부터 상기 작업 공간에서 사용자의 협동 업무에 따라 변화하는 센싱 정보를 수집하는 단계;상기 센싱 정보로부터 스트레스에 의한 정신 상태 값 또는, 워크로드에 의한 신체 상태 값 중에서 적어도 하나를 예측하는 단계;상기 정신 상태 값과 신체 상태 값 중 적어도 하나의 상태 값과 기 설정된 비정상 임계값을 비교하는 단계; 및비교한 결과를 고려하여 상기 사용자의 정신 상태 값 또는, 신체 상태 값 중 적어도 하나의 상태 값이 정상 범위를 갖도록 인터랙션을 활성화하는 단계를 포함하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 수집하는 단계는,상기 전용 협동 로봇과 연동 가능한 웨어러블 센서 및 비전 센서를 통해 사용자의 협동 업무에 따라 센싱된 사용자의 생체 신호, 상기 사용자의 개인 특성 정보, 상기 작업 공간과 관련된 작업 시스템 정보 및 작업 환경 정보 중 적어도 하나를 포함하는 센싱 정보를 수집하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 예측하는 단계는,상기 사용자의 정신 상태와 관련하여,상기 웨어러블 센서로부터 심리적 변화에 의해 심장계에서 발생하는 내면적 반응 및 상기 비전 센서로부터 생리적 변화에 의해 안면에 나타나는 외면적 반응을 포함하는 생체 신호를 기반으로 상기 사용자의 개인 특성 정보, 작업 시스템 정보 및 작업 환경 정보를 조합하여 상기 스트레스에 의한 정신 상태 값을 예측하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 예측하는 단계는,상기 사용자의 신체 상태와 관련하여,상기 웨어러블 센서로부터 심리적 변화에 의해 신경계에서 발생하는 내면적 반응 및 상기 비전 센서로부터 생리적 변화에 의해 몸에서 나타나는 외면적 반응을 포함하는 생체 신호를 기반으로 상기 사용자의 개인 특성 정보, 작업 시스템 정보 및 작업 환경 정보를 조합하여 상기 워크로드에 의한 신체 상태 값을 예측하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 비교하는 단계는,상기 정신 상태 값 또는, 신체 상태 값 중에서 비정상 임계값보다 큰 값이 존재하는지 여부를 확인하기 위해 상기 적어도 하나의 상태 값과 비정상 임계값을 비교하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 인터랙션을 활성화하는 단계는,상기 큰 값이 존재하지 않는 경우, 상기 사용자의 작업 상태에 관한 우선 순위를 고려하여 상기 정신 상태 값과 신체 상태 값을 조합하는 단계;상기 정신 상태 값과 신체 상태 값을 조합한 결과 값을 이용하여 상기 사용자의 작업 상태가 정상 범위에 포함되는지 여부를 확인하는 단계; 및상기 사용자의 작업 상태가 정상 범위를 벗어나는 경우, 상기 인터랙션을 단계적으로 활성화하는 단계를 포함하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 인터랙션을 활성화하는 단계는,상기 큰 값이 존재하거나 또는, 정상 범위를 벗어난 경우,상기 사용자와 작업 공간을 공유하는 전용 협동 로봇의 작업 속도, 이동 궤적 및 이격 거리 중 적어도 하나의 조건을 조정하여 상기 사용자의 정신 상태 값 또는, 신체 상태 값 중 적어도 하나의 상태 값이 정상 범위를 갖도록 인터랙션을 활성화하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 인터랙션을 활성화하는 단계는,상기 큰 값이 존재하거나 또는, 정상 범위를 벗어난 경우,상기 작업 공간에서 수행되는 사용자의 협동 업무 중 일부 업무를 분업하기 위한 공용 협동 로봇을 투입하여 사용자의 협동 업무를 재 할당하여 상기 사용자의 정신 상태 값 또는, 신체 상태 값 중 적어도 하나의 상태 값이 정상 범위를 갖도록 인터랙션을 활성화하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,상기 인터랙션을 활성화하는 단계는,상기 큰 값이 존재하거나 또는, 정상 범위를 벗어난 경우, 상기 작업 공간을 공유하는 사용자의 협동 업무를 중지하도록 시청각 장치와 연동하여 컨텐츠를 시각화하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>10. 작업 공간을 공유하는 전용 협동 로봇과 협동 업무를 수행하는 사용자의 심리적 변화 및 생리적 변화에 의한 센싱 정보를 수집하는 단계;상기 수집한 센싱 정보를 기반으로 협동 업무를 수행하는 과정에서 발생되는 스트레스에 의한 사용자의 정신 상태 값을 결정하는 단계;상기 수집한 센싱 정보를 기반으로 협동 업무를 수행하는 과정에서 발생되는 워크로드에 의한 사용자의 신체 상태 값을 결정하는 단계;상기 사용자의 정신 상태 값과 사용자의 신체 상태 값을 결합하여 상기 협동 업무를 수행하는 사용자의 작업 상태에 관한 종합 상태 값을 결정하는 단계; 및상기 결정된 종합 상태 값이 정상 범위에 포함되는지 여부를 확인하여 상기 사용자의 작업 상태가 정상 범위에 포함되도록 인터랙션을 단계적으로 활성화하는 단계를 포함하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 종합 상태 값을 결정하는 단계는,상기 사용자의 작업 상태에 관한 사용자의 정신 상태 값과 신체 상태 값에 대한 우선 순위를 결정하고, 결정된 우선 순위를 정수로 매핑하는 단계; 및상기 매핑된 정수에 이용하여 상기 정신 상태 값과 신체 상태 값에 대한 가중치의 합으로 종합 상태 값을 결정하는 단계를 포함하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 단계적으로 활성화하는 단계는,상기 종합 상태 값이 정상 범위를 벗어난 시간을 고려하여 각 시점에 따라 사용자의 작업 상태를 개선하기 위한 서로 다른 인터랙션을 단계적으로 제공하는 협력 작업 상태 관리 방법.</claim></claimInfo><claimInfo><claim>13. 협력 작업 상태 관리 방법을 수행하는 컴퓨팅 장치에 있어서,상기 컴퓨팅 장치는, 프로세서를 포함하고,상기 프로세서는,작업 공간을 공유하는 전용 협동 로봇으로부터 상기 작업 공간에서 사용자의 협동 업무에 따라 변화하는 센싱 정보를 수집하고,상기 센싱 정보로부터 스트레스에 의한 정신 상태 값 또는, 워크로드에 의한 신체 상태 값 중에서 적어도 하나를 예측하고,상기 정신 상태 값과 신체 상태 값 중 적어도 하나의 상태 값과 기 설정된 비정상 임계값을 비교하고,비교한 결과를 고려하여 상기 사용자의 정신 상태 값 또는, 신체 상태 값 중 적어도 하나의 상태 값이 정상 범위를 갖도록 인터랙션을 활성화하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 프로세서는,상기 사용자의 정신 상태와 관련하여,웨어러블 센서로부터 심리적 변화에 의해 심장계에서 발생하는 내면적 반응 및 비전 센서로부터 생리적 변화에 의해 안면에 나타나는 외면적 반응을 포함하는 생체 신호를 기반으로 상기 사용자의 개인 특성 정보, 작업 시스템 정보 및 작업 환경 정보를 조합하여 상기 스트레스에 의한 정신 상태 값을 예측하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 프로세서는,상기 사용자의 신체 상태와 관련하여,웨어러블 센서로부터 심리적 변화에 의해 신경계에서 발생하는 내면적 반응 및 비전 센서로부터 생리적 변화에 의해 몸에서 나타나는 외면적 반응을 포함하는 생체 신호를 기반으로 상기 사용자의 개인 특성 정보, 작업 시스템 정보 및 작업 환경 정보를 조합하여 상기 워크로드에 의한 신체 상태 값을 예측하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 프로세서는,상기 정신 상태 값 또는, 신체 상태 값 중에서 비정상 임계값보다 큰 값이 존재하는지 여부를 확인하기 위해 상기 적어도 하나의 상태 값과 비정상 임계값을 비교하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 프로세서는,상기 큰 값이 존재하지 않는 경우, 상기 사용자의 작업 상태에 관한 우선 순위를 고려하여 상기 정신 상태 값과 신체 상태 값을 조합하고,상기 정신 상태 값과 신체 상태 값을 조합한 결과 값을 이용하여 상기 사용자의 작업 상태가 정상 범위에 포함되는지 여부를 확인하고,상기 사용자의 작업 상태가 정상 범위를 벗어나는 경우, 상기 인터랙션을 단계적으로 활성화하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서는,상기 큰 값이 존재하거나 또는, 정상 범위를 벗어난 경우,상기 사용자와 작업 공간을 공유하는 전용 협동 로봇의 작업 속도, 이격 거리 중 적어도 하나의 조건을 조정하여 상기 사용자의 정신 상태 값 또는, 신체 상태 값 중 적어도 하나의 상태 값이 정상 범위를 갖도록 인터랙션을 활성화하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서,상기 프로세서는,상기 큰 값이 존재하거나 또는, 정상 범위를 벗어난 경우,상기 작업 공간에서 수행되는 사용자의 협동 업무 중 일부 업무를 분업하기 위한 공용 협동 로봇을 투입하여 사용자의 협동 업무를 재 할당하여 상기 사용자의 정신 상태 값 또는, 신체 상태 값 중 적어도 하나의 상태 값이 정상 범위를 갖도록 인터랙션을 활성화하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>20. 제17항에 있어서,상기 프로세서는,상기 큰 값이 존재하거나 또는, 정상 범위를 벗어난 경우, 상기 작업 공간을 공유하는 사용자의 협동 업무를 중지하도록 시청각 장치와 연동하여 컨텐츠를 시각화하는 컴퓨팅 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980077638</code><country>대한민국</country><engName>Electronics and Telecommunications Research Institute</engName><name>한국전자통신연구원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>KIM Jungsook</engName><name>김정숙</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>OH CheonIn</engName><name>오천인</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>YOON Daesub</engName><name>윤대섭</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>LEE Seung-Jun</engName><name>이승준</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>CHOI Daewoong</engName><name>최대웅</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.09</receiptDate><receiptNumber>1-1-2022-1326821-01</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220171505.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93477619a9ef5aa08bdc56780caf4f80bf7cc8b9b0254eb1f7a7935f4491cc9724af260ad4878bd9932418ff5844276dcbd37c205b1a370d22</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa8daf60842d1a0ca215bc2b11d92fba6d0012cc175193b54db5f26066433eb2b69ea74ea5c9d203daef45f68b8745196985023474eb308bf</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>