<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:06.336</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.06.21</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-7002240</applicationNumber><claimCount>29</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>활성화 희소화를 포함하는 신경 네트워크 가속 및 임베딩 압축 시스템 및 방법</inventionTitle><inventionTitleEng>NEURAL NETWORK ACCELERATION AND EMBEDDING COMPRESSION SYSTEMS AND METHODS WITH ACTIVATION SPARSIFICATION</inventionTitleEng><openDate>2021.03.16</openDate><openNumber>10-2021-0029785</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.06.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2021.01.22</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/082</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> (i) 심층 신경망(DNN)의 추론 속도를 가속하고 및 (ii) 이미지, 오디오, 비디오, 및 텍스트 등의 다양한 입력 데이터로부터 DNN에 의해 생성되는 벡터 표현을 압축하기 위한 시스템, 방법, 및 컴퓨터 판독가능 매체에 관한 것이다. 방법 실시예는, 신경망 아키텍처 및 태스크 의존형 손실 함수를 입력으로서 취하고, 신경망이 훈련 데이터세트에 대하여 얼마나 잘 기능하는지를 측정하고, 심층 신경망에 희소성 뉴런 활성화를 출력한다. 본 발명의 절차는, 뉴런들의 희소성 활성화를 촉진하는 일반화 항에 의해 DNN의 기존의 훈련 목적 함수를 증대하며, 다양한 알고리즘에 의해 최적화 문제를 해결함으로써 DNN을 압축한다. 또한, 본 개시 내용은, 다수의 산술 연산이 비례적으로 감소될 수 있도록 DNN의 추론 동안 활성화의 희소성을 이용하는 방법을 예시하며, 효율적 검색 엔진을 구축하도록 DNN에 의해 생성되는 희소성 표현을 이용하는 방법을 예시한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2019.12.26</internationOpenDate><internationOpenNumber>WO2019246491</internationOpenNumber><internationalApplicationDate>2019.06.21</internationalApplicationDate><internationalApplicationNumber>PCT/US2019/038422</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 심층 신경망(DNN) 추론의 연산 비용을 감소시키는 방법으로서, (a) 특정 태스크에 기초하여 심층 신경망의 예측 성능을 측정할 수 있는 손실 함수를 결정하는 단계; (b) 심층 신경망 연산 그래프 및 연관된 파라미터 값을 갖는 초기 심층 신경망을 검색하는 단계; (c) 희소화 비(sparsify ratio)가 수렴될 때까지 상기 심층 신경망의 활성 뉴런의 수를 반복적으로 희소화하는 단계; 및 (d) 활성화 희소화된(activation-sparsified) 심층 신경망을 생성 및 출력하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 희소화하는 단계는, 초기 활성화 함수를 희소화-유도 활성화 함수들의 새로운 세트로 대체함으로써 상기 손실 함수를 확장하여 목적 함수를 형성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 희소화하는 단계는, 상기 손실 함수를 하나 이상의 활성화 일반화로 확장하여 목적 함수를 형성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 희소화하는 단계는, 확장된 상기 활성화 일반화를 이용한 역전파에 의해 상기 목적 함수의 그라디언트를 평가하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서, 상기 희소화하는 단계는, 희소화-유도 활성화 함수를 이용한 역전파에 의해 상기 목적 함수의 그라디언트를 평가하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제4항 또는 제5항에 있어서, 상기 희소화하는 단계는, 상기 그라디언트에 기초하여 상기 심층 신경망에 연관된 하나 이상의 파라미터를 반복적으로 조정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 희소화하는 단계는, 상기 희소화 비의 변화가 미리 정해진 임계값보다 작아지는지 여부를 확인함으로써, 상기 심층 신경망이 수렴되는지 여부를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 특정 태스크는 훈련 데이터세트를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 심층 신경망의 최종 계층에서의 활성 뉴런의 수는 상기 심층 신경망에 의해 생성되는 벡터의 압축된 표현을 취득하도록 감소되는, 방법.</claim></claimInfo><claimInfo><claim>10. 활성화 압축기로서, 복수의 뉴런의 활성화 값을 연산하고 예측을 연산하도록 구성되고, 심층 신경망(DNN)을 파라미터화하는 변수들의 집합을 포함하는 네트워크 모델로서, 상기 심층 신경망은 복수의 계층으로 모듈화되고, 각 계층은 하나 이상의 이전 계층의 출력을 입력 데이터로서 취하고 출력들의 새로운 세트를 연산하는, 네트워크 모델; 상기 네트워크 모델에 통신가능하게 결합되며, 상기 예측과 실측 답(ground-truth answer) 간의 불일치를 측정하는 제1 페널티 값을 연산하도록 구성된 손실 함수 모듈; 상기 네트워크 모델에 통신가능하게 결합되며, 어떠한 뉴런이 상기 네트워크 모델에서의 활성 뉴런의 수를 희소화할 수 있는지를 최소화함으로써 상기 네트워크 모델 모듈의 모든 뉴런의 활성화 레벨을 측정하는 제2 페널티 값을 연산하도록 구성된 활성화 일반화기; 상기 네트워크 모델에 통신가능하게 결합되며, 복수의 데이터 소스로부터 상기 심층 신경망을 위한 입력 데이터를 취득하기 위한 파이프라인을 포함하는 데이터 판독기 모듈; 및 상기 손실 함수 모듈과 상기 활성화 일반화기에 통신가능하게 결합되고, 상기 손실 함수 모듈과 상기 활성화 일반화기에서의 목적 함수를 감소시키기 위해 상기 네트워크 모델에서의 변수들의 집합의 값을 조정하도록 구성된 최적화기를 포함하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 뉴런들은 각 계층의 하나 이상의 출력을 포함하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 예측은 최종 계층의 하나 이상의 출력을 포함하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 손실 함수 모듈은 상기 예측에 대하여 페널티 값의 미분을 연산하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서, 상기 손실 함수 모듈은 아래의 태스크 의존형 손실 함수 표현을 포함하고, 여기서, 는, 상기 심층 신경망의 최종・계층의 출력이고, 타겟 태스크 의 라벨에 관련된 각 샘플의 K개의 점수를 제공하며, 태스크 의존형 손실 함수는, 주어진 훈련 데이터세트 에 대하여 상기 DNN으로부터 예측되는 출력들과 훈련 세트 에 대하여 주어진 정확한 출력들 간의 불일치를 측정하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서, 상기 활성화 일반화기는, 어떠한 뉴런이 상기 신경망에서의 활성 뉴런의 수를 희소화할 수 있는지를 최소화함으로써 상기 신경망에서의 모든 뉴런의 활성화 레벨을 측정하는 미분을 연산하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>16. 제10항에 있어서, 상기 활성화 일반화기는 활성화 값을 직접 일반화하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 활성화 일반화기는 아래의 식으로 표현되는 바와 같이 활성화 값을 직접 일반화하며, 여기서,  항은 조정 하이퍼파라미터를 나타내며,  항(X의 모든 절대값의 합)은, 얼마나 많은 넌제로 성분이 X에 있는지를 대략적으로 측정하는 X의 볼록 대리 함수(convex surrogate function)를 나타내는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>18. 제10항에 있어서, 상기 활성화 일반화기는 각 계층의 활성화의 희소화 레벨을 제어하는 복수의 파라미터를 일반화하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 활성화 일반화기는 상기 활성화의 희소화 레벨을 파라미터를 갖는 활성화 함수와 함께 사용되며, 상기 활성화 함수는, 아래와 같이 표현되고, 최대 값들을 갖는 top-r 요소들의 값들만을 보존하고, 나머지는 제로로 억제하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서, 상기 데이터 판독기 모듈은, 복수의 데이터 소스로부터 상기 심층 신경망을 위한 입력 데이터를 취득하기 위한 파이프라인을 포함하고, 상기 파이프라인은 적어도 하나의 크롭핑, 서브샘플링, 업샘플링, 뱃칭, 화이트닝, 및 일반화를 포함하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>21. 제18항에 있어서, 상기 최적화기 모듈은, 상기 손실 함수와 상기 활성화 일반화기를 포함하는 목적 함수를 감소시키기 위해 상기 네트워크 모델의 변수들의 값들을 조정하도록 구성된, 활성화 압축기.</claim></claimInfo><claimInfo><claim>22. 제18항에 있어서, 상기 입력 데이터는 이미지, 오디오, 비디오, 및 텍스트 중 적어도 하나를 포함하는, 활성화 압축기.</claim></claimInfo><claimInfo><claim>23. 심층 신경망(DNN)의 효율적 연산 방법으로서, (a) 복수의 뉴런의 활성화 값을 연산하고 예측을 연산하기 위한 네트워크 모델을 제공하는 단계로서, 상기 네트워크 모델은 심층 신경망을 파라미터화하는 변수들의 집합을 포함하고, 상기 심층 신경망은 복수의 계층으로 모듈화되고, 각 계층은 하나 이상의 이전 계층의 출력을 입력 데이터로서 취하고 출력들의 새로운 세트를 연산하는, 단계; (b) 네트워크 모델과 데이터 판독기를 통한 역전파에 의해 목적 함수의 그라디언트를 평가하는 단계; (c) 상기 목적 함수를 감소시키기 위해 상기 네트워크 모델의 상기 변수들의 집합의 값들을 조정하기 위한 최적화기에 의해 상기 그라디언트에 기초하여 DNN 파라미터들을 업데이트하는 단계; (d) 최적화기에 의해, 상기 목적이 수렴되었음을 나타내도록 미리 정해진 임계값에 기초하여 상기 그라디언트의 크기 또는 목적의 변화가 충분히 작은지 여부를 결정하는 단계; 상기 목적이 수렴되지 않았다면, 상기 (b) 단계와 (c) 단계를 반복하는 단계; 및 상기 목적이 수렴되었다면, 희소화된 심층 신경망에 의해 출력을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 그라디언트를 평가하는 단계는, 일반화기 그라디언트로부터 파라미터 에 대하여 활성화 일반화기의 그라디언트를 요청하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 그라디언트를 평가하는 단계는, 전처리 파이프라인에 의해 제공되는 입력 데이터를 이용하여 모든 계층 {X(j)}j=1...J (462)의 활성화 값을 연산하도록 상기 네트워크 모델에 요청하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 제23항에 있어서, 상기 DNN 파라미터들을 업데이트하는 단계는, 손실 함수 모듈에 의해 손실 그라디언트로부터 파라미터들 에 대하여 상기 손실 함수의 그라디언트를 요청하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 DNN 파라미터들을 업데이트하는 단계는, 입력 전처리 파이프라인으로부터 상기 네트워크 모델로 제공되는 입력 데이터를 이용하여 예측 (출력) 계층들 의 값들을 연산하고 상기 손실 함수 모듈에 대한 라벨을 보정하도록 상기 네트워크 모델에 요청하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제23항에 있어서, 상기 입력 데이터는 이미지, 오디오, 비디오, 및 텍스트 중 적어도 하나를 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국, 캘리포니아 *****, 로스 알토스, 워싱턴 스트릿 ***</address><code>520210038391</code><country>미국</country><engName>MOFFETT AI, INC.</engName><name>모펫 에이아이, 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국, 캘리포니아 ****...</address><code> </code><country> </country><engName>YAN, Enxu</engName><name>얀, 엔수</name></inventorInfo><inventorInfo><address>미국, 캘리포니아 ****...</address><code> </code><country> </country><engName>WANG, Wei</engName><name>왕, 웨이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** (역삼동, TOWER***) *층(윤특허법률사무소)</address><code>920110002297</code><country>대한민국</country><engName>Choe, yun seo</engName><name>최윤서</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2018.06.22</priorityApplicationDate><priorityApplicationNumber>62/688,891</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.06.20</priorityApplicationDate><priorityApplicationNumber>16/446,938</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2021.01.22</receiptDate><receiptNumber>1-1-2021-0086544-26</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2021.02.18</receiptDate><receiptNumber>1-1-2021-0196970-65</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[New Translation under Article 201 of Patent Act or Article 35 of Utility Model Act] Submission of Document</documentEngName><documentName>[특허법 제201조 또는 실용신안법 제35조에 따른 새로운 번역문]서류제출서</documentName><receiptDate>2021.02.18</receiptDate><receiptNumber>1-1-2021-0197068-75</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2021.02.24</receiptDate><receiptNumber>1-5-2021-0032083-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.06.02</receiptDate><receiptNumber>1-1-2022-0579541-54</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.04.15</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2024.05.14</receiptDate><receiptNumber>9-6-2025-0069214-95</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.04.11</receiptDate><receiptNumber>9-5-2025-0358598-23</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[지정기간연장]기간 연장신청서·기간 단축신청서·기간 경과 구제신청서·절차 계속신청서</documentName><receiptDate>2025.06.10</receiptDate><receiptNumber>1-1-2025-0644724-20</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.07.09</receiptDate><receiptNumber>1-1-2025-0773449-61</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.07.09</receiptDate><receiptNumber>1-1-2025-0773448-15</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020217002240.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93fd7243654565b88d24b2b0c98c3493c986f7f0699e692aca518919cd1bc1fd5be044a10ec5b9ba4ee10670a66df5df2a9cac05bb878fa28c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf57e06699b86c7409b513087cf06ed20a990d150ed56d7c4d99e877ce9fd27788e84903a7ecf8c2fc0fbacb66186dcc89ef8696025bd999be</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>