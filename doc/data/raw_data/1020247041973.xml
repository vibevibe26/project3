<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:21:39.2139</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7041973</applicationNumber><claimCount>48</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오 코딩을 위한 인트라-예측 융합</inventionTitle><inventionTitleEng>INTRA-PREDICTION FUSION FOR VIDEO CODING</inventionTitleEng><openDate>2025.03.12</openDate><openNumber>10-2025-0035510</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.12.18</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/159</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/593</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/105</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/176</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 비디오 데이터를 디코딩하는 방법은, 인트라-예측 모드에 기초하여 비디오 데이터의 블록에 대한 샘플들의 2개 이상의 레퍼런스 라인들로부터의 예측자들의 융합을 생성하는 단계를 포함한다. 그 방법은, 예측자들의 융합 및 인트라-예측 모드를 사용하여 비디오 데이터의 블록을 디코딩하는 단계를 더 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.01.11</internationOpenDate><internationOpenNumber>WO2024010700</internationOpenNumber><internationalApplicationDate>2023.06.23</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/026049</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 데이터를 디코딩하는 방법으로서,인트라-예측 모드에 기초하여 비디오 데이터의 블록에 대한 샘플들의 2개 이상의 레퍼런스 라인들로부터의 예측자들의 융합을 생성하는 단계; 및상기 예측자들의 융합 및 상기 인트라-예측 모드를 사용하여 상기 비디오 데이터의 블록을 디코딩하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 인트라-예측 모드는 비-정수 기울기를 갖는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 비디오 데이터의 블록에 대한 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 융합을 생성하는 단계는,상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하는 단계는,상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제1 레퍼런스 라인에서의 제1 예측자들에 제1 가중치를 적용하는 단계; 및상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제2 레퍼런스 라인에서의 제2 예측자들에 제2 가중치를 적용하는 단계를 포함하고, 상기 제1 레퍼런스 라인은 상기 제2 레퍼런스 라인보다 상기 비디오 데이터의 블록에 더 가까운, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제1 가중치는 0.75이고, 상기 제2 가중치는 0.25인, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 임계치보다 크거나 같은 것에 응답하여 상기 제1 가중치가 0.75이고 상기 제2 가중치가 0.25임을 결정하는 단계; 및상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 상기 임계치보다 작은 것에 응답하여 상기 제1 가중치가 0.5이고 상기 제2 가중치가 0.5임을 결정하는 단계를 더 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 블록에서의 샘플의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초하여 상기 제1 가중치를 결정하는 단계; 및상기 제2 가중치가 상기 샘플의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초함을 결정하는 단계를 더 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 예측자들의 융합을 생성하는 단계는,하나 이상의 예측 샘플들을 생성하기 위해 저역 통과 필터 또는 고역 통과 필터 중 하나를 사용하여 상기 샘플들의 2개 이상의 레퍼런스 라인들을 필터링하는 단계를 포함하고,상기 비디오 데이터의 블록을 디코딩하는 단계는 상기 하나 이상의 예측 샘플들을 사용하여 상기 비디오 데이터의 블록을 디코딩하는 단계를 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 예측자들의 융합을 생성하는 단계는 인트라 서브 파티션 모드가 디스에이블되는 것에 응답하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,적어도 2개의 상이한 인트라-예측 모드들을 사용하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터 상기 예측자들을 결정하는 단계를 더 포함하고, 상기 적어도 2개의 상이한 인트라-예측 모드들은 각도 모드들인, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은 다중 레퍼런스 라인 코딩 모드에 대한 샘플들의 레퍼런스 라인들의 세트로부터의 제1 레퍼런스 라인을 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은, 상기 샘플들의 제1 레퍼런스 라인 위에 있는 그리고 인접해 있는 샘플들의 제2 레퍼런스 라인을 더 포함하는, 비디오 데이터를 디코딩하는 방법.</claim></claimInfo><claimInfo><claim>13. 비디오 데이터를 디코딩하도록 구성된 장치로서,비디오 데이터의 블록을 저장하도록 구성된 메모리; 및회로부에서 구현되고 상기 메모리와 통신하는 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은, 인트라-예측 모드에 기초하여 비디오 데이터의 블록에 대한 샘플들의 2개 이상의 레퍼런스 라인들로부터의 예측자들의 융합을 생성하고; 그리고 상기 예측자들의 융합 및 상기 인트라-예측 모드를 사용하여 상기 비디오 데이터의 블록을 디코딩하도록 구성되는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 인트라-예측 모드는 비-정수 기울기를 갖는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 비디오 데이터의 블록에 대한 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 융합을 생성하기 위해, 상기 하나 이상의 프로세서들은 추가로,상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하도록 구성되는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하기 위해, 상기 하나 이상의 프로세서들은 추가로,상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제1 레퍼런스 라인에서의 제1 예측자들에 제1 가중치를 적용하고; 그리고상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제2 레퍼런스 라인에서의 제2 예측자들에 제2 가중치를 적용하도록 구성되고, 상기 제1 레퍼런스 라인은 상기 제2 레퍼런스 라인보다 상기 비디오 데이터의 블록에 더 가까운, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 제1 가중치는 0.75이고, 상기 제2 가중치는 0.25인, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 하나 이상의 프로세서들은 추가로,상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 임계치보다 크거나 같은 것에 응답하여 상기 제1 가중치가 0.75이고 상기 제2 가중치가 0.25임을 결정하고; 그리고상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 상기 임계치보다 작은 것에 응답하여 상기 제1 가중치가 0.5이고 상기 제2 가중치가 0.5임을 결정하도록 구성되는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 하나 이상의 프로세서들은 추가로,상기 블록에서의 샘플의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초하여 상기 제1 가중치를 결정하고; 그리고상기 제2 가중치가 상기 샘플의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초함을 결정하도록 구성되는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>20. 제13항에 있어서, 상기 예측자들의 융합을 생성하기 위해, 상기 하나 이상의 프로세서들은 추가로,하나 이상의 예측 샘플들을 생성하기 위해 저역 통과 필터 또는 고역 통과 필터 중 하나를 사용하여 상기 2개 이상의 레퍼런스 라인들을 필터링하도록 구성되고,상기 비디오 데이터의 블록을 디코딩하기 위해, 상기 하나 이상의 프로세서들은 추가로, 상기 하나 이상의 예측 샘플들을 사용하여 상기 비디오 데이터의 블록을 디코딩하도록 구성되는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>21. 제13항에 있어서, 상기 하나 이상의 프로세서들은,인트라 서브 파티션 모드가 디스에이블되는 것에 응답하여 상기 예측자들의 융합을 생성하도록 구성되는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>22. 제13항에 있어서, 상기 하나 이상의 프로세서들은 추가로,적어도 2개의 상이한 인트라-예측 모드들을 사용하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터 상기 예측자들을 결정하도록 구성되고, 상기 적어도 2개의 상이한 인트라-예측 모드들은 각도 모드들인, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>23. 제13항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은 다중 레퍼런스 라인 코딩 모드에 대한 샘플들의 레퍼런스 라인들의 세트로부터의 제1 레퍼런스 라인을 포함하는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은, 상기 샘플들의 제1 레퍼런스 라인 위에 있는 그리고 인접해 있는 샘플들의 제2 레퍼런스 라인을 더 포함하는, 비디오 데이터를 디코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>25. 비디오 데이터를 인코딩하는 방법으로서,인트라-예측 모드에 기초하여 비디오 데이터의 블록에 대한 샘플들의 2개 이상의 레퍼런스 라인들로부터의 예측자들의 융합을 생성하는 단계; 및상기 예측자들의 융합 및 상기 인트라-예측 모드를 사용하여 상기 비디오 데이터의 블록을 인코딩하는 단계를 포함하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 인트라-예측 모드는 비-정수 기울기를 갖는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>27. 제25항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 비디오 데이터의 블록에 대한 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 융합을 생성하는 단계는,상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하는 단계를 포함하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하는 단계는,상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제1 레퍼런스 라인에서의 제1 예측자들에 제1 가중치를 적용하는 단계; 및상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제2 레퍼런스 라인에서의 제2 예측자들에 제2 가중치를 적용하는 단계를 포함하고, 상기 제1 레퍼런스 라인은 상기 제2 레퍼런스 라인보다 상기 비디오 데이터의 블록에 더 가까운, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 제1 가중치는 0.75이고, 상기 제2 가중치는 0.25인, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>30. 제28항에 있어서,상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 임계치보다 크거나 같은 것에 응답하여 상기 제1 가중치가 0.75이고 상기 제2 가중치가 0.25임을 결정하는 단계; 및상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 상기 임계치보다 작은 것에 응답하여 상기 제1 가중치가 0.5이고 상기 제2 가중치가 0.5임을 결정하는 단계를 더 포함하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>31. 제28항에 있어서,상기 블록에서의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초하여 상기 제1 가중치를 결정하는 단계; 및상기 제2 가중치가 샘플의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초함을 결정하는 단계를 더 포함하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>32. 제25항에 있어서, 상기 예측자들의 융합을 생성하는 단계는,하나 이상의 예측 샘플들을 생성하기 위해 저역 통과 필터 또는 고역 통과 필터 중 하나를 사용하여 상기 2개 이상의 레퍼런스 라인들을 필터링하는 단계를 포함하고,상기 비디오 데이터의 블록을 인코딩하는 단계는 상기 하나 이상의 예측 샘플들을 사용하여 상기 비디오 데이터의 블록을 인코딩하는 단계를 포함하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>33. 제25항에 있어서, 상기 예측자들의 융합을 생성하는 단계는 인트라 서브 파티션 모드가 디스에이블되는 것에 응답하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>34. 제25항에 있어서,적어도 2개의 상이한 인트라-예측 모드들을 사용하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터 상기 예측자들을 결정하는 단계를 더 포함하고, 상기 적어도 2개의 상이한 인트라-예측 모드들은 각도 모드들인, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>35. 제25항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은 다중 레퍼런스 라인 코딩 모드에 대한 샘플들의 레퍼런스 라인들의 세트로부터의 제1 레퍼런스 라인을 포함하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>36. 제35항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은, 상기 샘플들의 제1 레퍼런스 라인 위에 있는 그리고 인접해 있는 샘플들의 제2 레퍼런스 라인을 더 포함하는, 비디오 데이터를 인코딩하는 방법.</claim></claimInfo><claimInfo><claim>37. 비디오 데이터를 인코딩하도록 구성된 장치로서,비디오 데이터의 블록을 저장하도록 구성된 메모리; 및회로부에서 구현되고 상기 메모리와 통신하는 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은, 인트라-예측 모드에 기초하여 비디오 데이터의 블록에 대한 샘플들의 2개 이상의 레퍼런스 라인들로부터의 예측자들의 융합을 생성하고; 그리고 상기 예측자들의 융합 및 상기 인트라-예측 모드를 사용하여 상기 비디오 데이터의 블록을 인코딩하도록 구성되는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>38. 제37항에 있어서, 상기 인트라-예측 모드는 비-정수 기울기를 갖는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>39. 제37항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 비디오 데이터의 블록에 대한 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 융합을 생성하기 위해, 상기 하나 이상의 프로세서들은 추가로,상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하도록 구성되는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>40. 제39항에 있어서, 상기 인트라-예측 모드에 기초하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터의 상기 예측자들의 가중된 조합에 기초하여 상기 예측자들의 융합을 생성하기 위해, 상기 하나 이상의 프로세서들은 추가로,상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제1 레퍼런스 라인에서의 제1 예측자들에 제1 가중치를 적용하고; 그리고상기 샘플들의 2개 이상의 레퍼런스 라인들 중 제2 레퍼런스 라인에서의 제2 예측자들에 제2 가중치를 적용하도록 구성되고, 상기 제1 레퍼런스 라인은 상기 제2 레퍼런스 라인보다 상기 비디오 데이터의 블록에 더 가까운, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>41. 제40항에 있어서, 상기 제1 가중치는 0.75이고, 상기 제2 가중치는 0.25인, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>42. 제40항에 있어서, 상기 하나 이상의 프로세서들은 추가로,상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 임계치보다 크거나 같은 것에 응답하여 상기 제1 가중치가 0.75이고 상기 제2 가중치가 0.25임을 결정하고; 그리고상기 제1 예측자들 마이너스 상기 제2 예측자들의 절대 값이 상기 임계치보다 작은 것에 응답하여 상기 제1 가중치가 0.5이고 상기 제2 가중치가 0.5임을 결정하도록 구성되는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>43. 제40항에 있어서, 상기 하나 이상의 프로세서들은 추가로,상기 블록에서의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초하여 상기 제1 가중치를 결정하고; 그리고상기 제2 가중치가 샘플의 포지션 및 상기 블록의 폭 또는 높이 중 하나 이상에 기초함을 결정하도록 구성되는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>44. 제37항에 있어서, 상기 예측자들의 융합을 생성하기 위해, 상기 하나 이상의 프로세서들은 추가로,하나 이상의 예측 샘플들을 생성하기 위해 저역 통과 필터 또는 고역 통과 필터 중 하나를 사용하여 상기 2개 이상의 레퍼런스 라인들을 필터링하도록 구성되고,상기 비디오 데이터의 블록을 디코딩하기 위해, 상기 하나 이상의 프로세서들은 추가로, 상기 하나 이상의 예측 샘플들을 사용하여 상기 비디오 데이터의 블록을 디코딩하도록 구성되는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>45. 제37항에 있어서, 상기 하나 이상의 프로세서들은,인트라 서브 파티션 모드가 디스에이블되는 것에 응답하여 상기 예측자들의 융합을 생성하도록 구성되는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>46. 제37항에 있어서, 상기 하나 이상의 프로세서들은 추가로,적어도 2개의 상이한 인트라-예측 모드들을 사용하여 상기 샘플들의 2개 이상의 레퍼런스 라인들로부터 상기 예측자들을 결정하도록 구성되고, 상기 적어도 2개의 상이한 인트라-예측 모드들은 각도 모드들인, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>47. 제37항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은 다중 레퍼런스 라인 코딩 모드에 대한 샘플들의 레퍼런스 라인들의 세트로부터의 제1 레퍼런스 라인을 포함하는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo><claimInfo><claim>48. 제47항에 있어서, 상기 샘플들의 2개 이상의 레퍼런스 라인들은, 상기 샘플들의 제1 레퍼런스 라인 위에 있는 그리고 인접해 있는 샘플들의 제2 레퍼런스 라인을 더 포함하는, 비디오 데이터를 인코딩하도록 구성된 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>중국</country><engName>CAO, KEMING</engName><name>차오 커밍</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>인도</country><engName>RAY, BAPPADITYA</engName><name>레이 밥파디트야</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>대만</country><engName>CHANG, YAO-JEN</engName><name>창 야오-젠</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>SEREGIN, VADIM</engName><name>세레긴 바딤</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country>미국</country><engName>KARCZEWICZ, MARTA</engName><name>카르체비츠 마르타</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.07.06</priorityApplicationDate><priorityApplicationNumber>63/367,804</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.07.12</priorityApplicationDate><priorityApplicationNumber>63/368,221</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.06.22</priorityApplicationDate><priorityApplicationNumber>18/339,302</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.12.18</receiptDate><receiptNumber>1-1-2024-1406280-23</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.02.12</receiptDate><receiptNumber>1-5-2025-0025767-79</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247041973.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93202d7f0e18ca33d9a31d7755c76ef99bf1b1dfce5d03d7e78c78310e9e4e275f7d68c69b9c3d03264df9911a985652a688ccc3ab0f1a0a4d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf94a57c936f6555afc6ad21a01b9d4da4b4b5c1996482150b088d4fbd7975dfe5719c53e5a42f3ceaa5ddefcd85725fd7db0d47c108cdc305</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>