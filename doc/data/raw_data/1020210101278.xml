<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:11:06.116</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.08.02</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0101278</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>시공간 모델을 이용한 비디오 배경 추정</inventionTitle><inventionTitleEng>VIDEO BACKGROUND ESTIMATION USING SPATIO-TEMPORAL  MODELS</inventionTitleEng><openDate>2022.03.11</openDate><openNumber>10-2022-0030879</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 5/272</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 5/265</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 입력 비디오에 기초하여 전경 객체가 없는 최종 배경 화상을 생성하는 것을 포함하는 비디오 배경 추정과 관련된 기법이 논의된다. 이러한 기법은 각각 시간적 및 공간적 배경 화상 모델링을 사용하여 제 1 및 제 2 추정 배경 화상을 생성하는 것 및, 제 1 및 제 2 추정 배경 화상에 대응하는 제 1 및 제 2 신뢰도 맵에 기초하여 제 1 및 제 2 추정 배경 화상을 융합하여 최종 추정 배경 화상을 생성하는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 배경 추정을 수행하기 위한 시스템으로서,입력 비디오 화상을 저장하는 메모리와,상기 메모리에 연결된 하나 이상의 프로세서를 포함하되,상기 하나 이상의 프로세서는,  상기 입력 비디오 화상 및 하나 이상의 시간적으로 이전의 입력 비디오 화상에 기초하여 시간적 배경 화상 모델을 적용하여 상기 입력 비디오 화상에 대한 제 1 추정 배경 화상 및 대응하는 제 1 신뢰도 맵을 생성하고, 상기 입력 비디오 화상에 기초하여 공간적 배경 화상 모델을 적용하여 상기 입력 비디오 화상에 대한 제 2 추정 배경 화상 및 대응하는 제 2 신뢰도 맵을 생성하며, 상기 제 1 신뢰도 맵 및 상기 제 2 신뢰도 맵에 기초하여 상기 제 1 추정 배경 화상 및 상기 제 2 추정 배경 화상을 결합하여 상기 입력 비디오 화상에 대한 결과적인 추정 배경 화상을 생성하도록 구성되는,시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 프로세서는 또한, 전경 객체 검출을 상기 입력 비디오 화상에 적용하여 전경 객체 마스크를 생성하고, 상기 제 1 추정 배경 화상 및 상기 제 1 신뢰도 맵을 생성하는 것 또는 상기 제 2 추정 배경 화상 및 상기 제 2 신뢰도 맵을 생성하는 것 중 적어도 하나는 추가로 상기 전경 객체 마스크에 기초하는,시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 제 1 신뢰도 맵은 상기 제 1 추정 배경 화상과 상기 입력 비디오 화상의 대응하는 픽셀 값 사이의 거리 및 상기 제 1 추정 배경 화상을 생성하는 데 사용되는 통계적 모델의 분산(variance) 중 하나를 포함하는,시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 제 2 추정 배경 화상 및 상기 제 2 신뢰도 맵을 생성하는 것은 상기 제 2 추정 배경 화상 및 상기 제 2 신뢰도 맵을 포함하는 출력 볼륨을 생성하도록 상기 입력 비디오 화상에 기초하여 입력 볼륨에 신경망 계층을 적용하는 것을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 하나 이상의 프로세서가 상기 결과적인 추정 배경 화상의 각각의 픽셀에 대해, 상기 제 1 신뢰도 맵의 대응 값이 상기 제 2 신뢰도 맵의 대응 값을 초과하는 것에 응답하여 상기 제 1 추정 배경 화상으로부터 대응하는 픽셀 값을 선택하는 것 또는 상기 제 2 신뢰도 맵의 대응 값이 상기 제 1 신뢰도 맵의 대응 값을 초과하는 것에 응답하여 상기 제 2 추정 배경 화상으로부터 대응하는 픽셀 값을 선택하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 하나 이상의 프로세서가 상기 결과적인 추정 배경 화상의 각각의 픽셀에 대해, 상기 제 1 및 제 2 신뢰도 맵으로부터의 대응하는 신뢰도 값을 사용하여 가중치가 부여된 상기 제 1 및 제 2 추정 배경 화상으로부터 대응하는 픽셀 값의 가중 평균을 생성하는 것을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 하나 이상의 프로세서가 상기 제 1 및 제 2 추정 배경 화상을 포함하는 입력 볼륨에 신경망 계층을 적용하여 상기 결과적인 추정 배경 화상을 포함하는 출력 볼륨을 생성하는 것을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 하나 이상의 프로세서가 상기 결과적인 추정 배경 화상의 각각의 픽셀에 대해, 상기 제 1 및 제 2 신뢰도 맵의 신뢰도 값 사이의 크기 차이를 생성하는 것 및, 상기 크기 차이가 임계값을 초과하는 것에 응답하여 상기 결과적인 추정 배경 화상의 픽셀 값에 대해 상기 제 1 추정 배경 화상 또는 상기 제 2 추정 배경 화상의 픽셀 값 중 하나를 선택하는 것 또는 상기 크기 차이가 상기 임계값을 초과하지 않는 것에 응답하여 상기 제 1 및 제 2 추정 배경 화상의 상기 픽셀 값의 가중 평균으로서 상기 결과적인 추정 배경 화상의 픽셀 값을 생성하는 것을 포함하는,시스템. </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 하나 이상의 프로세서가상기 제 1 신뢰도 맵에 기초하여 전체 시간적 신뢰도 값 및 상기 제 2 신뢰도 맵에 기초하여 전체 공간적 신뢰도 값을 결정하고,상기 전체 시간적 신뢰도 값과 상기 전체 공간적 신뢰도 값 사이의 크기 차이를 결정하며,상기 크기 차이가 임계값을 초과하는 것에 응답하여 게이팅 기반 융합을 선택하거나 상기 크기 차이가 임계값을 초과하지 않는 것에 응답하여 선형 조합 융합을 선택하는 것을 포함하고,상기 하나 이상의 프로세서가 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은 상기 게이팅 기반 융합 또는 상기 선형 결합 융합 중 선택된 것을 적용하는 것인,시스템.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 시간적 배경 화상 모델을 적용하는 것은 상기 제 2 추정 배경 화상에 더 기초하거나, 또는 상기 하나 이상의 프로세서가 상기 공간적 배경 화상 모델을 적용하는 것은 상기 제 1 추정 배경 화상에 더 기초하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 공간적 배경 화상 모델을 적용하는 것은 상기 제 1 추정 배경 화상 및 상기 제 1 신뢰도 맵에 더 기초하고, 상기 하나 이상의 프로세서가 상기 제 1 신뢰도 맵의 대응하는 신뢰도 값이 임계값을 초과하지 않는 것에 응답하여 상기 공간적 배경 화상 모델을 사용하여 상기 제 2 추정 배경 화상의 픽셀 값을 결정하는 것 또는 상기 제 1 신뢰도 맵의 대응하는 신뢰도 값이 상기 임계값을 초과하지 않는 것에 응답하여 상기 제 1 추정 배경 화상의 대응하는 픽셀 값을 상기 제 2 추정 배경 화상에 복사하는 것을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>12. 비디오 배경 추정을 수행하기 위한 방법으로서,입력 비디오 화상 및 하나 이상의 시간적으로 이전의 입력 비디오 화상에 기초하여 시간적 배경 화상 모델을 적용하여 상기 입력 비디오 화상에 대한 제 1 추정 배경 화상 및 대응하는 제 1 신뢰도 맵을 생성하는 단계와,상기 입력 비디오 화상에 기초하여 공간적 배경 화상 모델을 적용하여 상기 입력 비디오 화상에 대한 제 2 추정 배경 화상 및 대응하는 제 2 신뢰도 맵을 생성하는 단계와,상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 추정 배경 화상 및 상기 제 2 추정 배경 화상을 결합하여 상기 입력 비디오 화상에 대한 결과적인 추정 배경 화상을 생성하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 결과적인 추정 배경 화상의 각각의 픽셀에 대해, 상기 제 1 신뢰도 맵의 대응 값이 상기 제 2 신뢰도 맵의 대응 값을 초과하는 것에 응답하여 상기 제 1 추정 배경 화상으로부터 대응하는 픽셀 값을 선택하거나 또는 상기 제 2 신뢰도 맵의 대응 값이 상기 제 1 신뢰도 맵의 대응 값을 초과하는 것에 응답하여 상기 제 2 추정 배경 화상으로부터 대응하는 픽셀 값을 선택하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 결과적인 추정 배경 화상의 각각의 픽셀에 대해, 상기 제 1 및 제 2 신뢰도 맵으로부터의 대응하는 신뢰도 값을 사용하여 가중치가 부여된 상기 제 1 및 제 2 추정 배경 화상으로부터 대응하는 픽셀 값의 가중 평균을 생성하는 것을 포함하는,방법.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서, 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 하나 이상의 프로세서가 상기 제 1 및 제 2 추정 배경 화상을 포함하는 입력 볼륨에 신경망 계층을 적용하여 상기 결과적인 추정 배경 화상을 포함하는 출력 볼륨을 생성하는 것을 포함하는,방법.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서, 상기 시간적 배경 화상 모델을 적용하는 것은 상기 제 2 추정 배경 화상에 더 기초하거나, 또는 상기 공간적 배경 화상 모델을 적용하는 것은 상기 제 1 추정 배경 화상에 더 기초하는, 방법.</claim></claimInfo><claimInfo><claim>17. 복수의 명령어를 포함하는 적어도 하나의 머신 판독가능 매체로서,상기 명령어는 컴퓨팅 디바이스에서 실행되는 것에 응답하여 상기 컴퓨팅 디바이스로 하여금 비디오 배경 추정을 수행하게 하며, 상기 비디오 배경 추정은,입력 비디오 화상 및 하나 이상의 시간적으로 이전의 입력 비디오 화상에 기초하여 시간적 배경 화상 모델을 적용하여 상기 입력 비디오 화상에 대한 제 1 추정 배경 화상 및 대응하는 제 1 신뢰도 맵을 생성하는 것과,상기 입력 비디오 화상에 기초하여 공간적 배경 화상 모델을 적용하여 상기 입력 비디오 화상에 대한 제 2 추정 배경 화상 및 대응하는 제 2 신뢰도 맵을 생성하는 것과,상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 추정 배경 화상 및 상기 제 2 추정 배경 화상을 결합하여 상기 입력 비디오 화상에 대한 결과적인 추정 배경 화상을 생성하는 것에 의해 수행되는,머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 결과적인 추정 배경 화상의 각각의 픽셀에 대해, 상기 제 1 신뢰도 맵의 대응 값이 상기 제 2 신뢰도 맵의 대응 값을 초과하는 것에 응답하여 상기 제 1 추정 배경 화상으로부터 대응하는 픽셀 값을 선택하거나 또는 상기 제 2 신뢰도 맵의 대응 값이 상기 제 1 신뢰도 맵의 대응 값을 초과하는 것에 응답하여 상기 제 2 추정 배경 화상으로부터 대응하는 픽셀 값을 선택하는 것을 포함하는, 머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 제 1 및 제 2 신뢰도 맵에 기초하여 상기 제 1 및 제 2 추정 배경 화상을 결합하는 것은, 상기 결과적인 추정 배경 화상의 각각의 픽셀에 대해, 상기 제 1 및 제 2 신뢰도 맵으로부터의 대응하는 신뢰도 값을 사용하여 가중치가 부여된 상기 제 1 및 제 2 추정 배경 화상으로부터 대응하는 픽셀 값의 가중 평균을 생성하는 것을 포함하는,머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>20. 제17항에 있어서, 상기 시간적 배경 화상 모델을 적용하는 것은 상기 제 2 추정 배경 화상에 더 기초하거나, 또는 상기 공간적 배경 화상 모델을 적용하는 것은 상기 제 1 추정 배경 화상에 더 기초하는, 머신 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미합중국 캘리포니아 ***** 산타클라라 미션 칼리지 블러바드 ****</address><code>520000333491</code><country>미국</country><engName>Intel Corporation</engName><name>인텔 코포레이션</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>이스라엘 ***** ...</address><code> </code><country> </country><engName>BENOU, Itay</engName><name>베노우 이테이</name></inventorInfo><inventorInfo><address>이스라엘 ***** ...</address><code> </code><country> </country><engName>PRIZIMENT, Yevgeny</engName><name>프리젠트 예브게니</name></inventorInfo><inventorInfo><address>이스라엘 ***** ...</address><code> </code><country> </country><engName>HERSKOVICH, Tzachi</engName><name>허스코비치 짜치</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.09.03</priorityApplicationDate><priorityApplicationNumber>17/011,647</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.08.02</receiptDate><receiptNumber>1-1-2021-0888920-80</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2021.08.04</receiptDate><receiptNumber>9-1-2021-9008935-65</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.08.02</receiptDate><receiptNumber>1-1-2024-0842394-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.08.02</receiptDate><receiptNumber>1-1-2024-0842409-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210101278.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c3842bda46d63a0e0f8c1d0148e0070c24620f0aad27752ea4d3d6e0712b263c8547b808484bbbf8b23fdfb2894dac3dfcc71808499c102d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfeaf8e3570281ea824cab8f71285fe854b843fd7150cfb42fc353856c84ef87089e4520456e13105910269ae16e68fc15059f6061e43fd9c7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>