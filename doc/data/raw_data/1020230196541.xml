<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:36:17.3617</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0196541</applicationNumber><claimCount>12</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>물체의 상대 포즈 보정을 이용한 물체 위치 추정 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR ESTIMATING OBJECT POSITION USING  RELATIVE POSE COMPENSATION OF OBJECT</inventionTitleEng><openDate>2025.07.08</openDate><openNumber>10-2025-0104288</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/136</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 5/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 실시예는, 물체 위치 추정 방법을 제공한다. 본 방법은, 이미지 내에 위치 추정 대상이 되는 객체를 인식하여, 상기 객체에 대해 2차원 세그멘테이션 (segmentation)을 수행하는 단계, 상기 2차원 세그멘테이션이 적용된 제1 객체를 6자유도의 추정 포즈를 갖도록 변환하는 단계, 상기 제1 객체와, 상기 6자유도의 추정 포즈를 갖도록 변환된 제2 객체를 이미지 평면 상에 투영시켜, 상기 제1 객체의 점군 경계점들과 상기 제2 객체의 점군 경계점들을 기초로 초기 오차를 보정하는 단계 및 상기 초기 오차가 보정된 상기 제1 객체와 상기 제2 객체를 정합하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 물체 위치 추정 장치에 의해 수행되는 물체 위치 추정 방법에 있어서,a) 이미지 내에 위치 추정 대상이 되는 객체를 인식하여, 상기 객체에 대해 2차원 세그멘테이션(segmentation)을 수행하는 단계; b) 상기 2차원 세그멘테이션이 적용된 제1 객체를 6자유도의 추정 포즈를 갖도록 변환하는 단계; c) 상기 제1 객체와, 상기 6자유도의 추정 포즈를 갖도록 변환된 제2 객체를 이미지 평면 상에 투영시켜, 상기 제1 객체의 점군 경계점들과 상기 제2 객체의 점군 경계점들을 기초로 초기 오차를 보정하는 단계; 및d) 상기 초기 오차가 보정된 상기 제1 객체와 상기 제2 객체를 정합하는 단계를 포함하는 것인, 물체 위치 추정 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 a) 단계는2차원의 상기 이미지를 입력값으로 하여 상기 이미지 내에서 상기 객체의 형태를 인식하고, 상기 제 1 객체를 추출하도록 학습된 제 1 인공지능 모델을 이용하여 수행되는 것인, 물체 위치 추정 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,상기 b)단계는상기 제 1 객체 및 상기 제 1 객체의 포즈 정보를 입력값으로 하여 상기 제 1 객체의 6 자유도 추정 포즈를 추론하도록 학습된 제 2 인공지능 모델을 이용하여 수행되는 것인, 물체 위치 추정 방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,상기 c) 단계에서 초기 오차 보정은c-1) 상기 제 1 객체의 둘레값을 기준으로 상기 제 2 객체의 둘레값을 일치시키는 둘레 최적화를 수행하는 단계; 및c-2) 상기 제 1 객체의 위치를 기준으로 상기 제 2 객체를 평행 이동하여 오프셋의 값을 조절하는 단계; 및c-3) 상기 제1 객체의 경계점들 각각에 대응되는 상기 제2 객체의 경계점들 간의 거리가 최소가 되도록 상대 포즈 보정을 수행하는 단계를 포함하는 것인, 물체 위치 추정 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,e) 상기 d) 단계에 따라 정합된 결과물을 이용하여 상기 이미지 상의 객체의 위치를 추정하고 지도화하는 단계를 더 포함하는 것인, 물체 위치 추정 방법.</claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서,보정된 포즈는 베이지안 필터의 입력으로 활용되고, 불변 확장 칼만 필터 필터(Invariant extended Kalman filter, Invariant EKF)의 측정치로 사용되는 것인, 물체 위치 추정 방법.</claim></claimInfo><claimInfo><claim>7. 통신 모듈;적어도 하나의 프로세서; 및상기 프로세서와 전기적으로 연결되고, 상기 프로세서에서 수행되는 적어도 하나의 코드(code)가 저장되는 메모리를 포함하고,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,이미지 내에 위치 추정 대상이 되는 객체를 인식하여, 상기 객체에 대해 2차원 세그멘테이션 (segmentation)을 수행하고, 상기 2차원 세그멘테이션이 적용된 제1 객체를 6자유도의 추정 포즈를 갖도록 변환하고, 상기 제1 객체와, 상기 6자유도의 추정 포즈를 갖도록 변환된 제2 객체를 이미지 평면 상에 투영시켜, 상기 제1 객체의 점군 경계점들과 상기 제2 객체의 점군 경계점들을 기초로 초기 오차를 보정하고, 상기 초기 오차가 보정된 상기 제1 객체와 상기 제2 객체를 정합하도록 야기하는 코드를 저장하는 것인, 물체 위치 추정 장치.</claim></claimInfo><claimInfo><claim>8. 제 7 항에 있어서,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,2차원의 상기 이미지를 입력값으로 하여 상기 이미지 내에서 상기 객체의 형태를 인식하고 상기 제 1 객체를 추출하도록 학습된 제 1 인공지능 모델을 이용하여 수행하도록 야기하는 코드를 저장하는 것인, 물체 위치 추정 장치.</claim></claimInfo><claimInfo><claim>9. 제 7 항에 있어서,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,상기 제 1 객체 및 상기 제 1 객체의 포즈 정보를 입력값으로 하여 상기 제 1 객체의 6 자유도 추정 포즈를 추론하도록 학습된 제 2 인공지능 모델을 이용하여 수행하도록 야기하는 코드를 저장하는 것인, 물체 위치 추정 장치.</claim></claimInfo><claimInfo><claim>10. 제 7 항에 있어서,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,초기 오차 보정은 상기 제 1 객체의 둘레값을 기준으로 상기 제 2 객체의 둘레값을 일치시키는 둘레 최적화를 수행하고, 상기 제 1 객체의 위치를 기준으로 상기 제 2 객체를 평행 이동하여 오프셋의 값을 조절하고, 상기 제1 객체의 경계점들 각각에 대응되는 상기 제2 객체의 경계점들 간의 거리가 최소가 되도록 상대 포즈 보정을 수행하도록 야기하는 코드를 저장하는 것인, 물체 위치 추정 장치.</claim></claimInfo><claimInfo><claim>11. 제 7 항에 있어서,상기 메모리는 상기 프로세서를 통해 실행될 때 상기 프로세서가,상기 정합하는 단계에 따라 정합된 결과물을 이용하여 상기 이미지 상의 객체의 위치를 추정하고 지도화하도록 야기하는 코드를 더 저장하는 것인, 물체 위치 추정 장치.</claim></claimInfo><claimInfo><claim>12. 제 10 항에 있어서,보정된 포즈는 베이지안 필터의 입력으로 활용되고, 불변 확장 칼만 필터 필터(Invariant extended Kalman filter, Invariant EKF)의 측정치로 사용되는 것인, 물체 위치 추정 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 관악구...</address><code>120070509242</code><country>대한민국</country><engName>Seoul National University R&amp;DB Foundation</engName><name>서울대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 과천시 별양로 ***...</address><code> </code><country> </country><engName>PARK, Chan Gook</engName><name>박찬국</name></inventorInfo><inventorInfo><address>서울특별시 관악구...</address><code> </code><country> </country><engName>LEE, Han Yeol</engName><name>이한열</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로*길 **, *층 (역삼동, 한동빌딩)</address><code>920111000019</code><country>대한민국</country><engName>MAPS Intellectual Property Law Firm</engName><name>특허법인엠에이피에스</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.29</receiptDate><receiptNumber>1-1-2023-1475960-23</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2024.01.11</receiptDate><receiptNumber>1-5-2024-0006806-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2024.01.12</receiptDate><receiptNumber>1-1-2024-0043641-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.10.29</receiptDate><receiptNumber>4-1-2024-5314378-71</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.06.30</receiptDate><receiptNumber>4-1-2025-5177275-86</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230196541.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93177963701f90017668320c96f0174ba878211a17cec0cb105992bdf6adfe4ff8fde17ef62bea212f085fb2b00439db9f609309b1dfe4b0cb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf3e97f307204c011c27b9b76d3f7a221627bf1f720718b6e8c60c15687646a3e45b8eef024df1bb5af9e753cea165b0ba0df4d7a26c2953bf</path></imagePathInfo><rndInfoArray><rndInfo><rndDepartmentName>과학기술정보통신부</rndDepartmentName><rndDuration>2022.03.01 ~ 2026.02.28</rndDuration><rndManagingInstituteName>서울대학교</rndManagingInstituteName><rndProjectName>개인기초연구(과기정통부)</rndProjectName><rndSpecialInstituteName>한국연구재단</rndSpecialInstituteName><rndTaskContribution>1/1</rndTaskContribution><rndTaskName>실내와 도심환경에서 모바일 장치의 무결성 연속 위치/방향 추정 연구</rndTaskName><rndTaskNumber>1711189147</rndTaskNumber></rndInfo></rndInfoArray></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>