<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:37.3337</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.04.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0056678</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>계층별 학습으로 최적화된 파라미터를 이용하여 그래프 기반 신경망 모델을 양자화하는 방법 및 저장매체</inventionTitle><inventionTitleEng>METHOD AND STORAGE MEDIUM FOR QUANTIZING GRAPH-BASED NEURAL  NETWORK MODELS WITH PARAMETERS OPTIMIZED BY LAYERWISE  LEARNING</inventionTitleEng><openDate>2025.11.05</openDate><openNumber>10-2025-0157699</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/042</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 예시는 방법을 제시한다. 상기 방법은: 제1 신경망모델의 함수 형태로 코딩된 복수의 기능 또는 함수 유닛을 복수의 그래프 모듈로 변환(convert)한 단계와; 상기 복수의 그래프 모듈들 내의 하나 이상의 입력들과 하나 이상의 출력들 간의 관계를 분석하는 단계와; 상기 관계에 기초하여, 상기 복수의 그래프 모듈의 하나 이상의 입력들과 상기 하나 이상의 출력들을 서로 매핑함으로써, 상기 제1 신경망모델에 대응하는 복수의 그래프 모듈을 사용하여 일방향적 비 순환 그래프(DAG) 형태의 제2 신경망모델을 생성하는 단계와; 상기 제2 신경망모델에 포함된 복수의 그래프 모듈들에 복수의 마커를 추가하는 단계와; 상기 복수의 그래프 모듈들 각각의 입력 값과 출력 값을 상기 복수의 마커를 이용하여 수집함으로써, 교정 데이터를 생성하는 단계와; 상기 교정 데이터에 기초하여 상기 제2 신경망모델에 적용가능한 스케일 값과 오프셋 값을 결정하는 단계와; 상기 스케일 값과 상기 오프셋 값에 기초하여, 정수 포맷의 양자화된 가중치 파라미터를 포함하는 제3 신경망모델을 상기 제2 신경망모델에 기초하여 생성하는 단계와; 상기 제3 신경망모델에 포함된 복수의 레이어들 각각에 대하여, 상기 제3 신경망모델의 각 레이어의 출력 값과 상기 각 레이어에 대응되는 상기 제2 신경망모델의 레이어의 출력 값의 차이가 최소가 되도록 상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 제1 신경망모델의 함수 형태로 코딩된 복수의 기능 또는 함수 유닛을 복수의 그래프 모듈로 변환(convert)한 단계와;상기 복수의 그래프 모듈들 내의 하나 이상의 입력들과 하나 이상의 출력들 간의 관계를 분석하는 단계와;상기 관계에 기초하여, 상기 복수의 그래프 모듈의 하나 이상의 입력들과 상기 하나 이상의 출력들을 서로 매핑함으로써, 상기 제1 신경망모델에 대응하는 복수의 그래프 모듈을 사용하여 일방향적 비 순환 그래프(DAG) 형태의 제2 신경망모델을 생성하는 단계와;상기 제2 신경망모델에 포함된 복수의 그래프 모듈들에 복수의 마커를 추가하는 단계와;상기 복수의 그래프 모듈들 각각의 입력 값과 출력 값을 상기 복수의 마커를 이용하여 수집함으로써, 교정 데이터를 생성하는 단계와;상기 교정 데이터에 기초하여 상기 제2 신경망모델에 적용가능한 스케일 값과 오프셋 값을 결정하는 단계와;상기 스케일 값과 상기 오프셋 값에 기초하여, 정수 포맷의 양자화된 가중치 파라미터를 포함하는 제3 신경망모델을 상기 제2 신경망모델에 기초하여 생성하는 단계와;상기 제3 신경망모델에 포함된 복수의 레이어들 각각에 대하여, 상기 제3 신경망모델의 각 레이어의 출력 값과 상기 각 레이어에 대응되는 상기 제2 신경망모델의 레이어의 출력 값의 차이가 최소가 되도록 상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 스케일 값과 상기 오프셋 값은 아래의 수학식에 의해서 구해지고, 여기서 max는 상기 교정 데이터로 수집된 상기 입력 값들과 출력 값들 중에서 최대 값을 의미하고, min은 상기 교정 데이터로 수집된 상기 입력 값들과 출력 값들 중에서 최소 값을 의미하고, bitwidth는 목표 양자화 비트폭을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제3 신경망모델을 상기 제2 신경망모델에 기초하여 생성하는 단계에서, 상기 제3 신경망모델의 가중치 파라미터는 아래의 수학식에 의해서 구해지고, 여기서, weightint는 양자화된 가중치를 나타내고, weightfp는 양자화 할 부동소수점의 가중치를 나타내고, sw는 양자화 할 부동소수점의 가중치에 대한 스케일 값을 나타내고, 는 라운드(Round) 및 클립(Clip) 연산을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계는,상기 가중치 파라미터의 학습 완료에 대응하여, 상기 수학식에 포함된 반올림 연산을 대신하여 상기 가중치 파라미터의 하나 이상의 원소 각각이 올림 또는 내림 연산을 할지 선택하도록 하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계는,상기 제3 신경망모델의 각 레이어의 출력 값과 상기 각 레이어에 대응되는 상기 제2 신경망모델의 레이어의 출력 값의 차이가 최소가 되도록 상기 제1 레이어의 가중치 파라미터의 하나 이상의 원소 각각이 0 또는 1에 수렴하도록 하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계는,상기 제3 신경망모델의 상기 각 레이어의 출력 값과 상기 각 레이어에 대응되는 상기 제2 신경망모델의 레이어의 출력 값의 차이에 대한 손실함수를 이용하여, 상기 가중치 파라미터의 하나 이상의 원소들 각각을 학습하도록 하고,상기 손실함수는 상기 하나 이상의 원소들 각각의 학습이 완료되면 0 또는 1에 수렴하도록 유도하는 유도 함수를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 손실 함수는 상기 유도 함수에 포함된 반올림 연산에 의한 반올림 손실을 최소화하기 위한 정규화 함수를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제3항에 있어서,상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계는,상기 스케일 값은 상기 가중치 파라미터의 각 원소별로 각각 학습되도록 하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계는,상기 각 레이어가 완전 연결 레이어(fully connected layer)인 경우, 상기 스케일 값을 원소별로 학습하기 위한 학습 파라미터는 초기 학습 파라미터 , 가중치 파라미터의 형태로 변환시키는 학습 파라미터, 및 채널별 학습 파라미터 으로 구성되며,상기 제3 신경망모델의 각 레이어의 출력 값과 상기 각 레이어에 대응되는 상기 제2 신경망모델의 레이어의 출력 값의 차이가 최소가 되도록 상기 학습 파라미터들을 업데이트하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 스케일 값의 학습 완료에 대응하여, 상기 제3 신경망모델의 가중치 파라미터는 각 원소 별로 아래 수학식에 의해 구해지며,여기서, 는 학습 파라미터들의 곱을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서, 상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계는,상기 각 레이어가 2차원 컨볼루션 레이어(convolutional layer)인 경우, 상기 스케일 값을 원소별로 학습하기 위한 학습 파라미터는 초기 학습 파라미터 , 가중치 파라미터의 형태로 변환시키는 학습 파라미터 , 및 2차원별 학습 파라미터 와 로 구성되며,상기 제3 신경망모델의 각 레이어의 출력 값과 상기 각 레이어에 대응되는 상기 제2 신경망모델의 레이어의 출력 값의 차이이 최소가 되도록 상기 학습 파라미터들을 업데이트하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 스케일 값의 학습 완료에 대응하여, 상기 제3 신경망모델의 가중치 파라미터는 각 원소 별로 아래 수학식에 의해 구해지며,여기서, 는 학습 파라미터들의 곱을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 복수의 그래프 모듈들로 변환되도록 설정된 상기 복수의 기능 또는 함수 유닛들은 더하기 함수, 빼기 함수, 곱하기 함수, 나누기 함수, 슬라이스(slice) 함수, 연접(concatenation) 함수, 텐서 뷰(tensor view) 함수, reshape 함수, transpose 함수 softmax 함수, permute 함수, chunk 함수, split 함수, clamp 함수, flatten 함수, tensor mean 함수 그리고 sum 함수 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,상기 제2 신경망모델 내에 포함되는 합성곱 연산은 상기 복수의 그래프 모듈들로만 구현되는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서,상기 제1 신경망모델과 상기 제2 신경망모델은 파이토치(PyTochTM) 포맷인, 방법.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서, 상기 제1 신경망모델과 상기 제2 신경망모델의 가중치 파라미터와 입력 특징맵 파라미터는 16비트 내지 32비트 길이를 갖는 부동소수점(floating point) 형태인, 방법.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서,상기 제3 신경망모델은 2비트 내지 8비트 길이의 정수(INT) 포맷을 갖는 형태인, 방법.</claim></claimInfo><claimInfo><claim>18. 명령어들을 기록하고 있는 비휘발성(non-volatile) 컴퓨터 판독가능 저장 매체로서, 상기 명령어들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금:제1 신경망모델의 함수 형태로 코딩된 복수의 기능 또는 함수 유닛을 복수의 그래프 모듈로 변환(convert)한 단계와;상기 복수의 그래프 모듈들 내의 하나 이상의 입력들과 하나 이상의 출력들 간의 관계를 분석하는 단계와;상기 관계에 기초하여, 상기 복수의 그래프 모듈의 하나 이상의 입력들과 상기 하나 이상의 출력들을 서로 매핑함으로써, 상기 제1 신경망모델에 대응하는 복수의 그래프 모듈을 사용하여 일방향적 비 순환 그래프(DAG) 형태의 제2 신경망모델을 생성하는 단계와;상기 제2 신경망모델에 포함된 복수의 그래프 모듈들에 복수의 마커를 추가하는 단계와;상기 복수의 그래프 모듈들 각각의 입력 값과 출력 값을 상기 복수의 마커를 이용하여 수집함으로써, 교정 데이터를 생성하는 단계와;상기 교정 데이터에 기초하여 상기 제2 신경망모델에 적용가능한 스케일 값과 오프셋 값을 결정하는 단계와;상기 스케일 값과 상기 오프셋 값에 기초하여, 정수 포맷의 양자화된 가중치 파라미터를 포함하는 제3 신경망모델을 상기 제2 신경망모델에 기초하여 생성하는 단계와;상기 제3 신경망모델에 포함된 복수의 레이어들 각각에 대하여, 상기 제3 신경망모델의 각 레이어의 출력 값과 상기 각 레이어에 대응되는 상기 제2 신경망모델의 레이어의 출력 값의 차이가 최소가 되도록 상기 제3 신경망모델의 상기 각 레이어의 가중치 파라미터를 학습하는 단계를 수행하도록 하는,비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 제3 신경망모델을 상기 제2 신경망모델에 기초하여 생성하는 단계에서, 상기 제3 신경망모델의 가중치 파라미터는 아래의 수학식에 의해서 구해지고, 여기서, weightint는 양자화된 가중치를 나타내고, weightfp는 양자화 할 부동소수점의 가중치를 나타내고, sw는 양자화 할 부동소수점의 가중치에 대한 스케일 값을 나타내고, 는 라운드(Round) 및 클립(Clip) 연산을 나타내며,상기 가중치 파라미터의 학습 완료에 대응하여, 상기 수학식에 포함된 반올림 연산을 대신하여 상기 가중치 파라미터의 하나 이상의 원소 각각이 올림 또는 내림 연산을 할지 선택하도록 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 제3 신경망모델을 상기 제2 신경망모델에 기초하여 생성하는 단계에서, 상기 제3 신경망모델의 가중치 파라미터는 아래의 수학식에 의해서 구해지고, 여기서, weightint는 양자화된 가중치를 나타내고, weightfp는 양자화 할 부동소수점의 가중치를 나타내고, sw는 양자화 할 부동소수점의 가중치에 대한 스케일 값을 나타내고, 는 라운드(Round) 및 클립(Clip) 연산을 나타내며,상기 스케일 값은 상기 가중치 파라미터의 각 원소별로 각각 학습되도록 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>120180468784</code><country>대한민국</country><engName>DEEPX CO., LTD.</engName><name>주식회사 딥엑스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>KIM, Lok Won</engName><name>김녹원</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, You Jun</engName><name>김유준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JUNG, Bum Jun</engName><name>정범준</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 봉은사로 ***, *층(삼성동, 몽베르빌딩)</address><code>920251000411</code><country>대한민국</country><engName>Intellent IP Law Firm</engName><name>인텔런트특허법인</name></agentInfo><agentInfo><address>서울특별시 강남구 봉은사로 ***, *층(삼성동, 몽베르빌딩)(인텔런트특허법인)</address><code>920060016721</code><country>대한민국</country><engName>Yu, Sang-Geun</engName><name>유상근</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.04.29</receiptDate><receiptNumber>1-1-2024-0466984-18</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.03.25</receiptDate><receiptNumber>1-1-2025-0340132-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.07.23</receiptDate><receiptNumber>4-1-2025-5202493-10</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240056678.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937293b8b70102745be607d9350b9127b511cbc773478acc5fe7361b6894bad9a8bc1398807bf0fc6cc2f5e63650734b479bdd49f2646a4c35</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf747bc370f562d35e59a9daa1fdd4818bb9bf225c601ceae2843adbf43dc700e6739eaf6112fba526c5da5018ffe06b37a3515278ba4e4c4d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>