<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:54.554</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0166096</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전자 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>An electronic apparatus and a method thereof</inventionTitleEng><openDate>2023.06.02</openDate><openNumber>10-2023-0078372</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G10H 1/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 21/0272</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 사용자 상황 정보, 스크린 상황 정보, 및 외부 상황 정보 중 적어도 하나를 포함하는, 음악 연주를 위한 상황 정보를 획득하는 단계, 사용자의 이전 청취 이력에 기반하여 사용자 취향 정보를 획득하는 단계 및 적어도 하나의 뉴럴 네트워크를 이용하여, 음악 연주를 위한 상황 정보 및 사용자 취향 정보 중 적어도 하나로부터 음악 연주를 위한 악보를 획득하는 단계를 포함하는, 전자 장치의 동작 방법이 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,사용자 상황 정보, 스크린 상황 정보, 및 외부 상황 정보 중 적어도 하나를 포함하는, 음악 연주를 위한 상황 정보를 획득하고, 사용자의 이전 음악 청취 이력에 기반하여 사용자 취향 정보를 획득하고,적어도 하나의 뉴럴 네트워크를 이용하여, 상기 음악 연주를 위한 상황 정보 및 상기 사용자 취향 정보 중 적어도 하나로부터 음악 연주를 위한 악보를 획득하는, 전자 장치. </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,제1 뉴럴 네트워크를 이용하여, 상기 사용자 상황 정보 및 상기 스크린 상황 정보 중 적어도 하나로부터 멀티 무드(multi mood) 정보를 획득하고, 제2 뉴럴 네트워크를 이용하여, 상기 사용자 취향 정보, 상기 멀티 무드 정보, 및 상기 외부 상황 정보 및 중 적어도 하나로부터 메타데이터를 획득하고,제3 뉴럴 네트워크를 이용하여, 상기 메타데이터로부터 상기 음악 연주를 위한 악보를 획득하는, 전자 장치. </claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서, 상기 제1 뉴럴 네트워크는 소프트맥스 회귀(Softmax Regression) 함수를 포함하고, 상기 제1 뉴럴 네트워크는 사용자 상황 정보 및 스크린 상황 정보 중 적어도 하나의 변수 및 웨이트의 가중 합과 정답 셋 간의 차이가 최소가 되는 웨이트를 갖도록 학습된 뉴럴 네트워크인, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제2 항에 있어서, 상기 제2 뉴럴 네트워크는 트랜스포머 모델(Transformer model)의 인코더 및 출력 레이어를 포함하고, 상기 메타데이터는 제1 메타데이터 및 제2 메타데이터를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 사용자 취향 정보, 상기 멀티 무드 정보, 및 상기 외부 상황 정보 중 적어도 하나를 임베딩하여 상기 트랜스포머 모델의 인코더에 입력 시키고, 상기 트랜스포머 모델의 인코더에서 출력된 웨이트에 소프트맥스(softmax) 함수를 상기 출력 레이어로 적용하여 상기 제1 메타데이터를 획득하고, 상기 트랜스포머 모델의 인코더에서 출력된 웨이트에 풀리 커넥티드 레이어(fully connected layer)를 상기 출력 레이어로 적용하여 상기 제2 메타데이터를 획득하고, 상기 제1 메타데이터는 템포(tempo), 감도, 악기(instrument), 앰비언트 사운드(ambient sound) 중 적어도 하나를 포함하고, 상기 제2 메타데이터는 피치(pitch) 및 음악 연주 길이 중 적어도 하나를 포함하는, 전자 장치. </claim></claimInfo><claimInfo><claim>5. 제2 항에 있어서, 상기 제3 뉴럴 네트워크는 트랜스포머 XL 모델(Transformer XL model)을 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 메타데이터를 임베딩하여 상기 트랜스포머 XL 모델에 입력 시켜 이벤트 시퀀스의 제1 확률 분포를 획득하고, 상기 이벤트 시퀀스의 제1 확률 분포를 샘플링하여 제1 마디(bar)를 획득하는, 전자 장치. </claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 마디를 상기 트랜스포머 XL 모델에 피드 포워드(feed forward)하여 상기 트랜스포머 XL 모델로부터 이벤트 시퀀스의 제2 확률 분포를 획득하고, 상기 이벤트 시퀀스의 제2 확률 분포를 샘플링하여 상기 제1 마디 다음에 오는 제2 마디를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 이벤트 시퀀스의 제1 확률 분포는 템포(tempo), 감도(velocity), 피치(pitch) 각각에 대한 확률 분포를 포함하는, 전자 장치. </claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서, 사용자 취향 정보 데이터베이스를 더 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 사용자 취향 정보 데이터베이스로부터, 상기 사용자가 이전에 청취한 음악에 대한 정보에 기반하여 획득된 사용자 취향 정보를 획득하고, 상기 음악 연주를 위한 악보에 따라 음악을 재생하고, 상기 음악 재생과 관련된 정보를 상기 사용자 취향 정보 데이터베이스에 추가하여 상기 사용자 취향 정보 데이터베이스를 업데이트하는, 전자 장치. </claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서, 상기 사용자 취향 정보는 상기 사용자의 식별 정보, 상기 사용자가 이전에 청취한 음악의 무드 정보, 감도 정보, 악기 정보, 앰비언트 사운드 정보, 상기 음악이 재생된 빈도 정보, 상기 음악이 재생된 시간 정보, 상기 음악이 재생될 때의 스크린 상황 정보, 및 상기 음악이 재생될 때의 외부 컨텍스트 정보 중 적어도 하나를 포함하는, 전자 장치. </claim></claimInfo><claimInfo><claim>10. 제1 항에 있어서, 상기 사용자 상황 정보는 사용자 식별 정보, 액티비티 정보, 및 감정 정보 중 적어도 하나를 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,오디오 신호로부터 음성 및 노이즈를 분리하고, 상기 음성에 기반하여 상기 사용자를 식별하는 것, 상기 식별된 사용자의 상기 음성에 기반하여 상기 사용자의 감정 정보를 획득하는 것, 및 상기 음성 및 상기 노이즈 중 적어도 하나에 기반하여 상기 사용자가 수행하는 액티비티 정보를 획득하는 것 중 적어도 하나를 수행하여, 상기 음성 및 상기 노이즈 중 적어도 하나로부터 상기 사용자 상황 정보를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>11. 제1 항에 있어서, 디스플레이를 더 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 디스플레이에 출력되는 이미지의 스타일 정보 및 컬러 정보 중 적어도 하나에 기반하여 상기 스크린 상황 정보를 획득하는, 전자 장치. </claim></claimInfo><claimInfo><claim>12. 제1 항에 있어서, 센서 및 통신 모듈 중 적어도 하나를 더 포함하고, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 센서 및 상기 통신 모듈 중 적어도 하나로부터 획득된 날씨 정보, 날짜 정보, 시간 정보, 계절 정보, 조도 정보 및 위치 정보 중 적어도 하나로부터 상기 외부 상황 정보를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 사용자 상황 정보, 스크린 상황 정보, 및 외부 상황 정보 중 적어도 하나를 포함하는, 음악 연주를 위한 상황 정보를 획득하는 단계; 사용자의 이전 청취 이력에 기반하여 사용자 취향 정보를 획득하는 단계; 및적어도 하나의 뉴럴 네트워크를 이용하여, 상기 음악 연주를 위한 상황 정보 및 상기 사용자 취향 정보 중 적어도 하나로부터 음악 연주를 위한 악보를 획득하는 단계를 포함하는, 전자 장치의 동작 방법. </claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서, 상기 음악 연주를 위한 악보를 획득하는 단계는제1 뉴럴 네트워크를 이용하여, 상기 사용자 상황 정보 및 상기 스크린 상황 정보 중 적어도 하나로부터 멀티 무드 정보를 획득하는 단계;제2 뉴럴 네트워크를 이용하여, 상기 사용자 취향 정보, 상기 멀티 무드 정보, 및 상기 외부 상황 정보 및 중 적어도 하나로부터 메타데이터를 획득하는 단계; 및제3 뉴럴 네트워크를 이용하여, 상기 메타데이터로부터 상기 음악 연주를 위한 악보를 획득하는 단계를 포함하는, 전자 장치의 동작 방법. </claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서, 상기 제1 뉴럴 네트워크는 소프트맥스 회귀(Softmax Regression) 함수를 포함하고, 상기 제1 뉴럴 네트워크는 사용자 상황 정보 및 스크린 상황 정보 중 적어도 하나의 변수 및 웨이트의 가중 합과 정답 셋 간의 차이가 최소가 되는 웨이트를 갖도록 학습된 뉴럴 네트워크인, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>16. 제14 항에 있어서, 상기 제2 뉴럴 네트워크는 트랜스포머 모델(Transformer model)의 인코더 및 출력 레이어를 포함하고,상기 메타데이터를 획득하는 단계는 상기 사용자 취향 정보, 상기 멀티 무드 정보, 및 상기 외부 상황 정보 중 적어도 하나를 임베딩하여 상기 트랜스포머 모델의 인코더에 입력 시키는 단계; 상기 인코더에서 출력된 웨이트에 소프트맥스(softmax)함수를 상기 출력 레이어로 적용하여 제1 메타데이터를 획득하는 단계; 및상기 인코더에서 출력된 웨이트에 풀리 커넥티드 레이어(fully connected layer)를 상기 출력 레이어로 적용하여 제2 메타데이터를 획득하는 단계를 포함하고,상기 제1 메타데이터는 템포(tempo), 감도(velocity), 악기(instrument), 앰비언트 사운드(ambient sound) 중 적어도 하나를 포함하고, 상기 제2 메타데이터는 피치(pitch) 및 음악 연주 길이 중 적어도 하나를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서, 상기 제3 뉴럴 네트워크는 트랜스포머 XL 모델(Transformer model)을 포함하고, 상기 음악 연주를 위한 악보를 획득하는 단계는 상기 메타데이터를 임베딩하여 상기 트랜스포머 XL 모델에 입력 시켜 이벤트 시퀀스의 제1 확률 분포를 획득하는 단계; 및상기 이벤트 시퀀스의 제1 확률 분포를 샘플링하여 제1 마디(bar)를 획득하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서, 상기 제1 마디를 상기 트랜스포머 모델에 피드 포워드(feed forward)하여 상기 트랜스포머 XL 모델로부터 이벤트 시퀀스의 제2 확률 분포를 획득하는 단계; 및 상기 이벤트 시퀀스의 제2 확률 분포를 샘플링하여 상기 제1 마디 다음에 오는 제2 마디를 획득하는 단계를 더 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>19. 제18 항에 있어서, 상기 이벤트 시퀀스의 제1 확률 분포는 템포(tempo), 감도(velocity), 피치(pitch) 각각에 대한 확률 분포를 포함하는, 전자 장치의 동작 방법. </claim></claimInfo><claimInfo><claim>20. 사용자 상황 정보, 스크린 상황 정보, 및 외부 상황 정보 중 적어도 하나를 포함하는, 음악 연주를 위한 상황 정보를 획득하는 단계; 사용자의 이전 청취 이력에 기반하여 사용자 취향 정보를 획득하는 단계; 및적어도 하나의 뉴럴 네트워크를 이용하여, 상기 음악 연주를 위한 상황 정보 및 상기 사용자 취향 정보 중 적어도 하나로부터 음악 연주를 위한 악보를 획득하는 단계를 포함하는 전자 장치의 동작 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Do Yun</engName><name>김도연</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>CHO, Eun Ae</engName><name>조은애</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Sang Shin</engName><name>박상신</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.11.26</receiptDate><receiptNumber>1-1-2021-1372674-63</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.26</receiptDate><receiptNumber>1-1-2024-1305623-00</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210166096.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936def61e395fd88b175b6ee92c3ae13c9ccd4098499a8744e18de082e023697c96c85f9ab39a8a73a7611da61ec79112cc03f1cd25d582f13</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe72a049bb82bb2323bd5439e86d60f1f7f24aeba825cb7dbc6e7a111b46b497bd0468068d2280268cea51736f83da9634c7694dffccab03c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>