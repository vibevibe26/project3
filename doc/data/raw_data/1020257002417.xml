<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:36.3336</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7002417</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실을 사용하는 작업들의 로봇 학습</inventionTitle><inventionTitleEng>ROBOTIC LEARNING OF TASKS USING AUGMENTED REALITY</inventionTitleEng><openDate>2025.02.25</openDate><openNumber>10-2025-0026324</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.01.22</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.01.22</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 시연에 의해 로봇 시스템을 프로그램하기 위한 방법이 설명된다. 하나의 양태에서, 이러한 방법은 AR(augmented reality) 디바이스의 디스플레이에 제1 가상 객체를 디스플레이하는 단계- 제1 가상 객체는 AR 디바이스의 물리적 환경에서의 제1 물리적 객체에 대응함 -, AR 디바이스를 사용하여, AR 디바이스의 사용자에 의한 제1 가상 객체의 조작을 추적하는 단계, 이러한 추적에 기초하여 제1 가상 객체의 초기 상태 및 최종 상태를 식별하는 단계- 초기 상태는 제1 가상 객체의 초기 자세에 대응하고, 최종 상태는 제1 가상 객체의 최종 자세에 대응함 -, 및 제1 가상 객체의 조작, 제1 가상 객체의 제1 초기 상태, 및 제1 가상 객체의 최종 상태의 추적을 사용하여 로봇 시스템을 시연에 의해 프로그램하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.12.28</internationOpenDate><internationOpenNumber>WO2023250267</internationOpenNumber><internationalApplicationDate>2023.06.13</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/068380</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,AR(augmented reality) 디바이스의 디스플레이에 제1 가상 객체를 디스플레이하는 단계- 상기 제1 가상 객체는 상기 AR 디바이스의 물리적 환경에서의 제1 물리적 객체에 대응함 -;상기 AR 디바이스를 사용하여, 상기 AR 디바이스의 사용자에 의한 상기 제1 가상 객체의 조작을 추적하는 단계- 상기 제1 가상 객체의 조작은 상기 물리적 환경에서의 제2 물리적 객체 또는 상기 제2 물리적 객체에 대응하는 제2 가상 객체에 상대적임 -;상기 추적에 기초하여 상기 제1 가상 객체의 초기 상태, 복수의 중간 상태들, 및 최종 상태를 식별하는 단계- 상기 초기 상태는 상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 초기 자세에 대응하고, 상기 최종 상태는 상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 최종 자세에 대응하고, 상기 복수의 중간 상태들은 상기 초기 상태와 상기 최종 상태 사이에 있음 -; 및상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 조작, 상기 제1 가상 객체의 제1 초기 상태, 및 상기 제1 가상 객체의 최종 상태의 추적을 사용하여 로봇 시스템을 시연에 의해 프로그램하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 추적하는 단계는 추가로,상기 AR 디바이스의 센서로 상기 물리적 환경의 3차원 공간 정보를 캡처하는 단계;상기 3차원 공간 정보에 기초하여 3차원 포인트 클라우드를 생성하는 단계;상기 3차원 포인트 클라우드로부터 상기 제1 물리적 객체 및 상기 제2 물리적 객체를 식별하는 단계; 및상기 식별된 제1 물리적 객체에 기초하여 상기 제1 가상 객체를 렌더링하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 추가로,상기 식별된 제2 물리적 객체에 기초하여 상기 제2 가상 객체를 렌더링하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 추가로,상기 3차원 포인트 클라우드에 상대적인 상기 사용자의 손 제스처들을 식별하는 단계;기간(a period of time)에 걸쳐 상기 사용자의 손 제스처들을 추적하는 단계;상기 AR 디바이스에서 6 자유도 추적 시스템을 사용하여, 상기 기간에 걸쳐 상기 AR 디바이스의 자세를 추적하는 단계;상기 기간에 걸쳐 상기 증강 현실 디바이스의 자세에 기초하여 상기 AR 디바이스의 궤적을 식별하는 단계; 및상기 사용자의 상기 추적된 손 제스처들 및 상기 AR 디바이스의 상기 궤적에 기초하여 상기 제1 가상 객체의 상기 조작, 상기 제1 가상 객체의 상기 초기 자세, 상기 제1 가상 객체의 상기 최종 자세를 식별하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 추가로,상기 기간에 걸쳐 상기 사용자의 상기 추적된 손 제스처들에 기초하여 상기 제1 가상 객체의 자세를 조정하는 단계; 및상기 제1 가상 객체의 상기 조정된 자세에 기초하여 상기 AR 디바이스의 상기 디스플레이에 상기 제1 가상 객체를 재-렌더링하는 단계- 상기 제1 가상 객체는 상기 사용자의 손에 고정된 것으로 나타남 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서, 추가로,상기 AR 디바이스에서 시연에 의해 프로그래밍의 기록을 시작하라는 요청을 수신하는 단계; 및상기 AR 디바이스에서 시연에 의해 상기 프로그래밍의 기록을 종료하라는 요청을 수신하는 단계를 포함하고,상기 기간은 상기 기록을 시작하라는 요청 및 상기 기록을 종료하라는 요청에 대응하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 제1 가상 객체는 상기 제1 물리적 객체의 제1 3D 모델을 포함하고, 제2 가상 객체는 상기 제2 물리적 객체의 제2 3D 모델을 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 제1 3D 모델은 상기 제1 물리적 객체의 제1 축소 버전 또는 상기 제1 물리적 객체의 제1 확대 버전이고, 상기 제2 3D 모델은 상기 제2 물리적 객체의 제2 축소 버전 또는 상기 제2 물리적 객체의 제2 확대 버전인 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 제1 가상 객체는 상기 물리적 환경에서의 상기 제1 물리적 객체의 제2 위치와는 별개인 상기 물리적 환경에서의 제1 위치에 디스플레이되는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 제1 가상 객체는 상기 물리적 환경에서의 상기 제1 물리적 객체의 위치에 디스플레이되는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 프로그램하는 단계는,상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 조작, 상기 제1 가상 객체의 제1 초기 상태, 상기 제1 가상 객체의 복수의 중간 상태, 및 상기 제1 가상 객체의 최종 상태의 추적을 표시하는 시연 데이터를 상기 로봇 시스템에 전송하는 단계를 포함하고,상기 로봇 시스템은 상기 시연 데이터를 사용하여 프로그램되는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 프로그램하는 단계는,상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 조작, 상기 제1 가상 객체의 제1 초기 상태, 및 상기 제1 가상 객체의 최종 상태의 추적을 표시하는 시연 데이터를, 서버에, 전송하는 단계를 포함하고,상기 서버는 상기 시연 데이터를 사용하여 상기 로봇 시스템을 시연에 의해 프로그램하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>13. AR(augmented reality) 디바이스로서,디스플레이;프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때, 상기 AR 디바이스를 동작들을 수행하도록 구성하고, 상기 동작들은,상기 디스플레이에 제1 가상 객체를 디스플레이하는 동작- 상기 제1 가상 객체는 상기 AR 디바이스의 물리적 환경에서의 제1 물리적 객체에 대응함 -;상기 AR 디바이스를 사용하여, 상기 AR 디바이스의 사용자에 의한 상기 제1 가상 객체의 조작을 추적하는 동작- 상기 제1 가상 객체의 조작은 상기 물리적 환경에서의 제2 물리적 객체 또는 상기 제2 물리적 객체에 대응하는 제2 가상 객체에 상대적임 -;상기 추적에 기초하여 상기 제1 가상 객체의 초기 상태, 복수의 중간 상태들, 및 최종 상태를 식별하는 동작- 상기 초기 상태는 상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 초기 자세에 대응하고, 상기 최종 상태는 상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 최종 자세에 대응하고, 상기 복수의 중간 상태들은 상기 초기 상태와 상기 최종 상태 사이에 있음 -; 및상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 조작, 상기 제1 가상 객체의 제1 초기 상태, 및 상기 제1 가상 객체의 최종 상태의 추적을 표시하는 시연 데이터를, 다른 디바이스에, 제공하는 동작을 포함하는 AR 디바이스.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 추적하는 동작은 추가로,상기 AR 디바이스의 센서로 상기 물리적 환경의 3차원 공간 정보를 캡처하는 동작;상기 3차원 공간 정보에 기초하여 3차원 포인트 클라우드를 생성하는 동작;상기 3차원 포인트 클라우드로부터 상기 제1 물리적 객체 및 상기 제2 물리적 객체를 식별하는 동작; 및상기 식별된 제1 물리적 객체에 기초하여 상기 제1 가상 객체를 렌더링하는 동작을 포함하는 AR 디바이스.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 동작들은,상기 식별된 제2 물리적 객체에 기초하여 상기 제2 가상 객체를 렌더링하는 동작을 포함하는 AR 디바이스.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서, 상기 동작들은,상기 3차원 포인트 클라우드에 상대적인 상기 사용자의 손 제스처들을 식별하는 동작;기간에 걸쳐 상기 사용자의 손 제스처들을 추적하는 동작;상기 AR 디바이스에서 6 자유도 추적 시스템을 사용하여, 상기 기간에 걸쳐 상기 AR 디바이스의 자세를 추적하는 동작;상기 기간에 걸쳐 상기 증강 현실 디바이스의 자세에 기초하여 상기 AR 디바이스의 궤적을 식별하는 동작; 및상기 사용자의 상기 추적된 손 제스처들 및 상기 AR 디바이스의 상기 궤적에 기초하여 상기 제1 가상 객체의 상기 조작, 상기 제1 가상 객체의 상기 초기 자세, 상기 제1 가상 객체의 상기 최종 자세를 식별하는 동작을 포함하는 AR 디바이스.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 동작들은,상기 기간에 걸쳐 상기 사용자의 상기 추적된 손 제스처들에 기초하여 상기 제1 가상 객체의 자세를 조정하는 동작; 및상기 제1 가상 객체의 상기 조정된 자세에 기초하여 상기 AR 디바이스의 상기 디스플레이에 상기 제1 가상 객체를 재-렌더링하는 동작- 상기 제1 가상 객체는 상기 사용자의 손에 고정된 것으로 나타남 -을 포함하는 AR 디바이스.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 동작들은,상기 AR 디바이스에서 시연에 의해 프로그래밍의 기록을 시작하라는 요청을 수신하는 동작; 및상기 AR 디바이스에서 시연에 의해 상기 프로그래밍의 기록을 종료하라는 요청을 수신하는 동작을 포함하고,상기 기간은 상기 기록을 시작하라는 요청 및 상기 기록을 종료하라는 요청에 대응하는 AR 디바이스.</claim></claimInfo><claimInfo><claim>19. 비-일시적 컴퓨터-판독가능 저장 매체로서, 상기 컴퓨터-판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금,AR(augmented reality) 디바이스의 디스플레이에 제1 가상 객체를 디스플레이하게- 상기 제1 가상 객체는 상기 AR 디바이스의 물리적 환경에서의 제1 물리적 객체에 대응함 -;상기 AR 디바이스를 사용하여, 상기 AR 디바이스의 사용자에 의한 상기 제1 가상 객체의 조작을 추적하게- 상기 제1 가상 객체의 조작은 상기 물리적 환경에서의 제2 물리적 객체 또는 상기 제2 물리적 객체에 대응하는 제2 가상 객체에 상대적임 -;상기 추적에 기초하여 상기 제1 가상 객체의 초기 상태, 복수의 중간 상태들, 및 최종 상태를 식별하게- 상기 초기 상태는 상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 초기 자세에 대응하고, 상기 최종 상태는 상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 최종 자세에 대응하고, 상기 복수의 중간 상태들은 상기 초기 상태와 상기 최종 상태 사이에 있음 -; 그리고상기 제2 물리적 객체 또는 상기 제2 가상 객체에 상대적인 상기 제1 가상 객체의 조작, 상기 제1 가상 객체의 제1 초기 상태, 및 상기 제1 가상 객체의 최종 상태의 추적을 사용하여 로봇 시스템을 시연에 의해 프로그램하게 하는 비-일시적 컴퓨터-판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 추적하는 것은 추가로,상기 AR 디바이스의 센서로 상기 물리적 환경의 3차원 공간 정보를 캡처하는 것;상기 3차원 공간 정보에 기초하여 3차원 포인트 클라우드를 생성하는 것;상기 3차원 포인트 클라우드로부터 상기 제1 물리적 객체 및 상기 제2 물리적 객체를 식별하는 것; 및상기 식별된 제1 물리적 객체에 기초하여 상기 제1 가상 객체를 렌더링하는 것을 포함하는 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>ZHOU, Kai</engName><name>저우, 카이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>오스트리아</country><engName>SCHOISENGEIER, Adrian</engName><name>쇼이젠지에, 아드리안</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.06.22</priorityApplicationDate><priorityApplicationNumber>17/846,930</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.01.22</receiptDate><receiptNumber>1-1-2025-0088118-85</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.01.24</receiptDate><receiptNumber>1-5-2025-0016511-98</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.11.09</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257002417.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93020608318577d67684029bd58afea0f45e453f9a14e3ace43d93f287322aca5c09b3c40cbf1f7524c58793657dd0733b714e8bff51a04020</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfcf67aa34dae3b73dd738e50210393801087776956aec83b019fe396bacbe366028f7aa4d59569da826824529daa611cd358ec2d63693b63d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>