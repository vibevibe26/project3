<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:26.526</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.03.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0039872</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>영상 처리 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>An image processing apparatus and a method thereof</inventionTitleEng><openDate>2023.01.17</openDate><openNumber>10-2023-0009806</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4046</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4053</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/13</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/422</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 제1 영상으로부터 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하는 단계, 화질 처리에 대한 제어 정보를 획득하는 단계 및 객체 정보 및 사용자 제어 정보를 기반으로, 제1 영상으로부터 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득하는 단계를 포함하는, 영상 처리 방법이 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 영상 처리 장치에 있어서, 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하고, 화질 처리를 위한 제어 정보를 획득하고,상기 객체 정보 및 상기 제어 정보를 기반으로, 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득하는, 영상 처리 장치. </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 상기 객체 정보는 상기 중요 객체의 종류, 위치, 및 크기 중 적어도 하나에 대한 정보를 포함하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제1 영상으로부터 복수 객체를 검출하고, 상기 복수 객체를 가리키는 객체 식별 정보를 출력하고, 상기 객체 식별 정보 출력에 상응하여 사용자로부터 선택된 객체를 상기 중요 객체로 식별하는, 영상 처리 장치. </claim></claimInfo><claimInfo><claim>4.  제1 항에 있어서, 상기 제어 정보는 객체의 확대 여부, 객체의 확대 정도, 윤곽선 처리, 및 평탄화 처리 중 적어도 하나에 대한 제어 정보를 포함하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 상기 제어 정보에 따라, 상기 객체의 업스케일링, 상기 객체 주위의 윤곽선 처리, 및 상기 객체 내부 평탄화 처리 중 적어도 하나를 수행하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서, 상기 제어 정보는 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함하고, 상기 추론 제어 정보는 이전 영상에 대한 상기 사용자의 이전 제어 이력 정보로부터 획득되고, 상기 실시간 사용자 제어 정보는 상기 제1 영상에 대한 상기 사용자의 실시간 제어 정보를 포함하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서, 상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써, 뉴럴 네트워크를 이용하여, 상기 제1 영상으로부터 상기 제2 영상을 획득하고, 상기 뉴럴 네트워크는 입력 영상, 상기 입력 영상에서 사용자가 관심을 갖는 객체 영역, 및 상기 사용자가 관심을 갖는 객체 영역을 화질 처리한 그라운드 트루쓰(ground thruth) 영상을 학습 데이터 셋으로 학습한 뉴럴 네트워크인, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 제어 정보, 및 상기 객체 정보 중 적어도 하나로부터, 상기 객체가 화질 처리된 제2 영상을 획득하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>9. 제7 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 사용자 제어 정보, 및 상기 객체 정보 중 적어도 하나로부터, 상기 객체에 대한 화질 처리를 위한 평탄화 파라미터 및 윤곽선 파라미터를 획득하고, 상기 프로세서는 사용자 제어 신호에 따라 상기 평탄화 파라미터에 따라 화질 처리된 영상 및 상기 윤곽선 파라미터에 따라 화질 처리된 영상의 블렌딩 정도를 조절하여 화질 처리된 제2 영상을 획득하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>10. 제8 항 또는 제9 항에 있어서, 상기 화질 처리는 상기 객체의 윤곽선 처리, 상기 객체 내부의 평탄화 처리, 및 상기 객체를 업스케일링하는 것 중 적어도 하나를 포함하고, 상기 객체의 윤곽선 처리는 상기 객체의 윤곽선의 디테일, 강도, 색상 중 적어도 하나에 대한 처리를 포함하고, 상기 객체 내부의 평탄화 처리는 상기 객체 내부의 평탄화 정도를 조절하는 처리를 포함하고, 상기 객체를 업스케일링하는 것은 상기 객체의 해상도를 유지하면서 상기 객체의 크기를 확대하는 처리를 포함하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>11. 영상 처리 장치에서 수행하는 영상 처리 방법에 있어서, 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하는 단계;화질 처리에 대한 제어 정보를 획득하는 단계; 및상기 객체 정보 및 상기 사용자 제어 정보를 기반으로, 상기 제1 영상으로부터 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득하는 단계를 포함하는, 영상 처리 방법. </claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서, 상기 객체 정보는 상기 중요 객체의 종류, 위치, 및 크기 중 적어도 하나에 대한 정보를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>13. 제11 항에 있어서, 상기 제1 영상으로부터 복수 객체를 검출하는 단계;상기 복수 객체를 가리키는 객체 식별 정보를 출력하는 단계; 및상기 객체 식별 정보 출력에 상응하여 사용자로부터 선택된 객체를 상기 중요 객체로 식별하는 단계를 더 포함하는, 영상 처리 방법. </claim></claimInfo><claimInfo><claim>14.  제11 항에 있어서, 상기 제어 정보는 객체의 확대 여부, 객체의 확대 정도, 윤곽선 처리, 및 평탄화 처리 중 적어도 하나에 대한 제어 정보를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서, 상기 중요 객체에 대한 화질 처리를 수행하는 단계는 상기 제어 정보에 따라, 상기 객체의 업스케일링, 상기 객체 주위의 윤곽선 처리, 및 상기 객체 내부 평탄화 처리 중 적어도 하나를 수행하는 것을 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>16. 제11 항에 있어서, 상기 제어 정보는 추론 제어 정보 및 실시간 사용자 제어 정보 중 적어도 하나를 포함하고, 상기 추론 제어 정보는 이전 영상에 대한 상기 사용자의 이전 제어 이력 정보로부터 획득되고, 상기 실시간 사용자 제어 정보는 상기 제1 영상에 대한 상기 사용자의 실시간 제어 정보를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>17. 제11 항에 있어서, 상기 제1 영상으로부터 상기 제2 영상을 획득하는 단계는 뉴럴 네트워크를 이용하여 수행되고, 상기 뉴럴 네트워크는 입력 영상, 상기 입력 영상에서 사용자가 관심을 갖는 객체 영역, 및 상기 사용자가 관심을 갖는 객체 영역을 화질 처리한 그라운드 트루쓰(ground thruth) 영상을 학습 데이터 셋으로 학습한 뉴럴 네트워크인, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 제어 정보, 및 상기 객체 정보 중 적어도 하나로부터, 상기 객체가 화질 처리된 제2 영상을 획득하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>19. 제17 항에 있어서, 상기 뉴럴 네트워크는 상기 제1 영상, 상기 사용자 제어 정보, 및 상기 객체 정보 중 적어도 하나로부터, 상기 객체에 대한 화질 처리를 위한 평탄화 파라미터 및 윤곽선 파라미터를 획득하고, 상기 제1 영상으로부터 상기 제2 영상을 획득하는 단계는 사용자 제어에 따라 상기 평탄화 파라미터에 따라 화질 처리된 영상 및 상기 윤곽선 파라미터에 따라 화질 처리된 영상의 블렌딩 정도를 조절하여 화질 처리된 제2 영상을 획득하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>20. 제1 영상으로부터 상기 제1 영상에 포함된 중요 객체에 대한 객체 정보를 획득하는 단계;화질 처리에 대한 제어 정보를 획득하는 단계; 및상기 객체 정보 및 상기 사용자 제어 정보를 기반으로, 상기 제1 영상으로부터 상기 중요 객체에 대한 화질 처리를 수행하여 제2 영상을 획득하는 단계를 포함하는, 영상 처리 방법을 구현하기 위한 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Jae Sung</engName><name>박재성</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Ji Man</engName><name>김지만</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Cheon</engName><name>이천</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JUNG, Seong Woon</engName><name>정성운</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2021.07.09</priorityApplicationDate><priorityApplicationNumber>1020210090571</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.03.30</receiptDate><receiptNumber>1-1-2022-0344151-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.03.27</receiptDate><receiptNumber>1-1-2025-0349311-91</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220039872.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9304a4c1ec268cfecf9ef99ee9ccac72b187c22a59a0868407be2eb5f4891988a2dc2a23728f7dcd9841d3f84a844527d312a6dca987d1af79</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6e986e324fba1c8d8ea5d9e57044d0ea573b5a958dfca9a25bf35f92be23bb20db2c56db9b6f3f8eeefa3fb683977ee4bb66efec9fead33c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>