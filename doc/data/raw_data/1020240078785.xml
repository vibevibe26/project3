<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:31.5131</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.06.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0078785</applicationNumber><claimCount>26</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>텍스트 이미지 모델의 트레이닝 방법, 모델, 장치 및 전자 기기</inventionTitle><inventionTitleEng>METHOD FOR TRAINING TEXT TO IMAGE MODEL, MODEL, APPARATUS,  AND ELECTRONIC DEVICE</inventionTitleEng><openDate>2024.07.05</openDate><openNumber>10-2024-0105330</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.06.18</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/279</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/092</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 텍스트 이미지 모델의 트레이닝 방법, 모델, 장치 및 전자 기기를 제공한다. 강화 학습, 컴퓨터 비전 기술분야에 관한 것이다. 구현 수단은, 제1 텍스트 이미지 모델 및 사전 트레이닝된 보상 모델을 획득하되, 여기서 제1 텍스트 이미지 모델은 입력 텍스트를 기반으로 대응하는 생성 이미지를 생성하는 데 사용되고, 사전 트레이닝된 보상 모델은 입력 텍스트 및 대응하는 생성 이미지로 구성된 데이터 쌍을 기반으로 채점하는 데 사용되는 것이며; 상기 텍스트 이미지 모델의 트레이닝 방법은, 사전 트레이닝된 보상 모델 및 강화 학습 전략을 기반으로 제1 텍스트 이미지 모델의 파라미터를 조정하여 제2 텍스트 이미지 모델을 획득하는 단계를 더 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 텍스트 이미지 모델의 트레이닝 방법으로서, 제1 텍스트 이미지 모델 및 사전 트레이닝된 보상 모델을 획득하되, 상기 제1 텍스트 이미지 모델은 입력 텍스트를 기반으로 대응하는 생성 이미지를 생성하는 데 사용되고, 상기 사전 트레이닝된 보상 모델은 상기 입력 텍스트 및 상기 대응하는 생성 이미지로 구성된 데이터 쌍을 기반으로 채점하는 데 사용되는 단계; 및상기 사전 트레이닝된 보상 모델 및 강화 학습 전략을 기반으로 상기 제1 텍스트 이미지 모델의 파라미터를 조정하여 제2 텍스트 이미지 모델을 획득하는 단계를 포함하고,상기 제2 텍스트 이미지 모델이 텍스트 이미지를 구현하기 위한 생성 시퀀스에서 얻은 누적 보상은 기설정된 조건을 충족시키며, 상기 누적 보상은 상기 생성 시퀀스의 각 단계의 보상을 기반으로 획득된 것인 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 기설정된 조건은 상기 제2 텍스트 이미지 모델이 텍스트 이미지를 구현하기 위한 생성 시퀀스에서 얻은 누적 보상이 상기 제1 텍스트 이미지 모델이 텍스트 이미지를 구현하기 위한 생성 시퀀스에서 얻은 누적 보상보다 높은 것을 포함하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 강화 학습 전략은 근접 정책 최적화 알고리즘을 포함하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 근접 정책 최적화 알고리즘은 행동 서브 모델 및 판정 서브 모델을 사용하고, 상기 행동 서브 모델은 상기 제1 텍스트 이미지 모델을 기반으로 초기화되어 획득된 것이며, 상기 판정 서브 모델은 상기 사전 트레이닝된 보상 모델을 기반으로 초기화되어 획득된 것인 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 생성 시퀀스는 적어도 하나의 단계를 포함하되, 상기 생성 시퀀스의 각 단계에 대해,상기 행동 서브 모델은 제공된 입력 텍스트를 기반으로 대응하는 출력 노이지 이미지를 생성하고;상기 판정 서브 모델은 현재 단계의 상기 입력 텍스트 및 상기 출력 노이지 이미지를 기반으로 상기 현재 단계의 보상을 출력하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 현재 단계의 보상은 상기 현재 단계 전 이전 단계에서 상기 행동 서브 모델의 출력과 상기 현재 단계에서 상기 행동 서브 모델의 출력 사이의 상대 엔트로피를 포함하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 현재 단계의 보상은 상기 현재 단계 전 이전 단계의 평가값과 상기 현재 단계의 평가값 사이의 차이값을 포함하되, 상기 평가값은 제공된 입력 텍스트 및 대응하는 출력 노이지 이미지를 기반으로 상기 사전 트레이닝된 보상 모델로 채점하여 획득된 것인 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서,상기 생성 시퀀스에서 획득된 상기 누적 보상은 총 평점 및 손실항을 포함하되, 상기 총 평점은 상기 생성 시퀀스의 초기 입력 및 최종 출력을 기반으로 상기 사전 트레이닝된 보상 모델에 의해 획득되고, 상기 손실항은 상기 생성 시퀀스의 마지막 단계의 보상과 손실 계수의 곱인 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 제2 텍스트 이미지 모델의 생성 시퀀스 중의 상기 누적 보상을 기반으로, 역전파 알고리즘을 통해 상기 제2 텍스트 이미지 모델의 파라미터를 획득하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 사전 트레이닝된 보상 모델은 피드백 데이터 세트를 기반으로 트레이닝하여 획득된 것이고, 상기 피드백 데이터 세트는 복수의 피드백 데이터를 포함하며, 상기 복수의 피드백 데이터는 상기 입력 텍스트 및 상기 대응하는 생성 이미지로 구성된 데이터 쌍 및 상기 데이터 쌍에 대응하는 피드백 상태를 포함하고, 상기 피드백 상태는 동일한 입력 텍스트에 대해 생성된 상기 대응하는 생성 이미지가 긍정적 피드백 또는 부정적 피드백에 속하는 것을 특성화하는 데 사용되는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 보상 모델을 트레이닝하는 단계는,상기 복수의 피드백 데이터를 기반으로, 비교 학습 형태로 상기 보상 모델을 트레이닝하여 상기 보상 모델이 상기 피드백 상태가 긍정적 피드백인 상기 데이터 쌍에 제1 보상 평점을 출력하고, 상기 피드백 상태가 부정적 피드백인 상기 데이터 쌍에 제2 보상 평점을 출력하도록 하되, 상기 제1 보상 평점과 상기 제2 보상 평점의 차이값은 상기 대응하는 생성 이미지의 품질 차이를 특성화하는 데 사용되는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>12. 제10항 또는 제11항에 있어서,상기 피드백 데이터 세트는 상이한 소스로부터의 적어도 2가지 상기 복수의 피드백 데이터를 포함하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 복수의 피드백 데이터는 사용자 피드백 데이터, 인위적 표기 데이터 및 수동 비교 데이터 중 적어도 2가지를 포함하되,상기 사용자 피드백 데이터는 사용자 행동을 기반으로 상기 피드백 상태를 획득하고;상기 인위적 표기 데이터는 인위적 표기 결과를 기반으로 상기 피드백 상태를 획득하며;상기 수동 비교 데이터는 상이한 버전의 생성 이미지를 기반으로 상기 피드백 상태를 획득하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제14항 중 어느 한 항에 있어서, 제1 텍스트 이미지 모델을 획득하는 상기 단계는, 인위적 표기 이미지 텍스트 쌍을 트레이닝할 상기 제1 텍스트 이미지 모델의 트레이닝 샘플로서 획득하는 단계; 및역전파 알고리즘을 기반으로 트레이닝할 상기 제1 텍스트 이미지 모델의 파라미터를 업데이트하여 지도 트레이닝을 거친 상기 제1 텍스트 이미지 모델을 획득하는 단계를 포함하는 텍스트 이미지 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 따른 방법으로 트레이닝하여 획득된 텍스트 이미지 모델.</claim></claimInfo><claimInfo><claim>16. 텍스트 이미지 모델의 트레이닝 장치로서,제1 텍스트 이미지 모델 및 사전 트레이닝된 보상 모델을 획득하도록 구성되되, 상기 제1 텍스트 이미지 모델은 입력 텍스트를 기반으로 대응하는 생성 이미지를 생성하고, 상기 사전 트레이닝된 보상 모델은 상기 입력 텍스트 및 상기 대응하는 생성 이미지로 구성된 데이터 쌍을 기반으로 채점하는 획득 모듈; 및상기 사전 트레이닝된 보상 모델 및 강화 학습 전략을 기반으로 상기 제1 텍스트 이미지 모델의 파라미터를 조정하여 제2 텍스트 이미지 모델을 획득하도록 구성되는 조정 모듈을 포함하고,상기 제2 텍스트 이미지 모델이 텍스트 이미지를 구현하기 위한 생성 시퀀스에서 얻은 누적 보상은 기설정된 조건을 충족시키며, 상기 누적 보상은 상기 생성 시퀀스의 각 항의 보상의 합을 기반으로 획득된 것인 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 기설정된 조건은 상기 제2 텍스트 이미지 모델이 텍스트 이미지를 구현하기 위한 생성 시퀀스에서 얻은 누적 보상이 상기 제1 텍스트 이미지 모델이 텍스트 이미지를 구현하기 위한 생성 시퀀스에서 얻은 누적 보상보다 높은 것을 포함하는 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>18. 제16항 또는 제17항에 있어서,상기 강화 학습 전략은 근접 정책 최적화 알고리즘을 포함하는 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 근접 정책 최적화 알고리즘은 행동 서브 모델 및 판정 서브 모델을 사용하고;상기 조정 모듈은,상기 제1 텍스트 이미지 모델을 기반으로 상기 행동 서브 모델을 초기화하도록 구성되는 행동 서브 모듈; 및상기 사전 트레이닝된 보상 모듈을 기반으로 상기 판정 서브 모델을 초기화하도록 구성되는 판정 서브 모듈을 포함하는 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 생성 시퀀스는 적어도 하나의 단계를 포함하되, 상기 생성 시퀀스의 각 단계에 대해,상기 행동 서브 모듈은 제공된 입력 텍스트를 기반으로 대응하는 출력 노이지 이미지를 생성하도록 구성되고;상기 판정 서브 모듈은 또한 현재 단계의 입력 텍스트 및 출력 노이지 이미지를 기반으로 현재 단계의 보상을 출력하도록 구성되는 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서,상기 조정 모듈은,총 평점 및 손실항을 기반으로 상기 생성 시퀀스 중의 누적 보상을 생성하도록 구성되는 보상 모듈을 더 포함하되;상기 총 평점은 상기 생성 시퀀스의 초기 입력 및 최종 출력을 기반으로 상기 사전 트레이닝된 보상 모델에 의해 획득되고;상기 손실항은 상기 생성 시퀀스의 마지막 단계의 보상과 손실 계수의 곱인 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>22. 제16항 내지 제21항 중 어느 한 항에 있어서,피드백 데이터 세트를 기반으로 보상 모델을 트레이닝하여 상기 사전 트레이닝된 보상 모델을 획득하도록 구성되는 제1 사전 트레이닝 모듈을 더 포함하되,상기 피드백 데이터 세트는 복수의 피드백 데이터를 포함하며, 상기 복수의 피드백 데이터는 상기 입력 텍스트 및 상기 대응하는 생성 이미지로 구성된 데이터 쌍 및 상기 데이터 쌍에 대응하는 피드백 상태를 포함하고, 상기 피드백 상태는 동일한 입력 텍스트에 대해 생성된 상기 대응하는 생성 이미지가 긍정적 피드백 또는 부정적 피드백에 속하는 것을 특성화하는 데 사용되는 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>23. 제16항 내지 제22항 중 어느 한 항에 있어서,인위적 표기 이미지 텍스트 쌍을 기반으로 트레이닝할 상기 제1 텍스트 이미지 모델을 트레이닝하여 지도 트레이닝을 거친 상기 제1 텍스트 이미지 모델을 획득하도록 구성되는 제2 사전 트레이닝 모듈을 더 포함하는 텍스트 이미지 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>24. 전자 기기로서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되;상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 제1항 내지 제14항 중 어느 한 항에 따른 방법을 수행할 수 있도록 하는 전자 기기.</claim></claimInfo><claimInfo><claim>25. 컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제14항 중 어느 한 항에 따른 방법을 수행하도록 하기 위한 것인 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>26. 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 명령을 포함하고, 상기 명령이 적어도 하나의 프로세서에 의해 실행될 경우 제1항 내지 제14항 중 어느 한 항에 따른 방법을 구현하는, 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 베이징 하이뎬 디스트...</address><code> </code><country> </country><engName>SHI, Yixuan</engName><name>스 이쉬안</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이뎬 디스트...</address><code> </code><country> </country><engName>LI, Wei</engName><name>리 웨이</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이뎬 디스트...</address><code> </code><country> </country><engName>LIU, Jiachen</engName><name>류 자천</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이뎬 디스트...</address><code> </code><country> </country><engName>XIAO, Xinyan</engName><name>샤오 신옌</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920030004930</code><country>대한민국</country><engName>Lim KyuBin</engName><name>임규빈</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2023.07.11</priorityApplicationDate><priorityApplicationNumber>202310845680.6</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.06.18</receiptDate><receiptNumber>1-1-2024-0655443-18</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.06.26</receiptDate><receiptNumber>9-1-2024-9006720-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.04.10</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240078785.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b4fab4a9c7e546a972ebf733a3d8313e3d521b5b97ec3a3b3c693fdd6b1b8a08a51a6b19d06c4150752eebd4288cf72dba1147001c8b8db6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbcde68c088756d463cb20ada272376f9fb96f7a27fa041d432728cd8036e6e4716d33f5277d46032accd58bd22841e09a0ca7247f9ea8e49</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>