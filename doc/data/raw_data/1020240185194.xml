<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:36:40.3640</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.12.12</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0185194</applicationNumber><claimCount>14</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법 및 추론 장치</inventionTitle><inventionTitleEng>GENERATION METHOD VIDEO-LANGUAGE PRE-TRAINED MODEL WITH  ENHANCING MOVEMENT OF OBJECTS AND INFERENCE APPARATUS</inventionTitleEng><openDate>2025.06.20</openDate><openNumber>10-2025-0091130</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법은 비디오를 비디오 인코더에 입력하여 전역 비디오 특징을 생성하는 단계, 상기 데이터 처리 장치가 상기 전역 비디오 특징 및 쿼리 큐브 임베딩을 입력받아 튜브 특징을 생성하는 단계, 상기 데이터 처리 장치가 텍스트를 SRL(semantic role labeling) 생성기에 입력하여 의미적 구문을 생성하는 단계, 상기 데이터 처리 장치가 상기 텍스트를 텍스트 인코더에 입력하여 전역 텍스트 특징을 생성하는 단계, 상기 데이터 처리 장치가 상기 의미적 구문을 상기 텍스트 인코더에 입력하여 의미적 구문 특징을 생성하는 단계, 상기 데이터 처리 장치가 상기 전역 비디오 특징, 상기 튜브 특징, 상기 전역 텍스트 특징 및 상기 의미적 구문 특징에 대한 크로스 어텐션을 통해 융합 임베딩 시퀀스를 생성하는 단계 및 상기 데이터 처리 장치가 상기 융합 임베딩 시퀀스를 이용하여 프록시 태스크를 이용한 사전학습을 수행하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 데이터 처리 장치가 비디오-텍스트 쌍을 입력받는 단계;상기 데이터 처리 장치가 상기 비디오를 비디오 인코더에 입력하여 전역 비디오 특징을 생성하는 단계;상기 데이터 처리 장치가 상기 전역 비디오 특징 및 쿼리 큐브 임베딩을 입력받아 튜브 특징을 생성하는 단계;상기 데이터 처리 장치가 상기 텍스트를 SRL(semantic role labeling) 생성기에 입력하여 의미적 구문을 생성하는 단계;상기 데이터 처리 장치가 상기 텍스트를 텍스트 인코더에 입력하여 전역 텍스트 특징을 생성하는 단계;상기 데이터 처리 장치가 상기 의미적 구문을 상기 텍스트 인코더에 입력하여 의미적 구문 특징을 생성하는 단계;상기 데이터 처리 장치가 상기 전역 비디오 특징, 상기 튜브 특징, 상기 전역 텍스트 특징 및 상기 의미적 구문 특징에 대한 크로스 어텐션을 통해 융합 임베딩 시퀀스를 생성하는 단계; 및상기 데이터 처리 장치가 상기 융합 임베딩 시퀀스를 이용하여 프록시 태스크를 이용한 사전학습을 수행하는 단계를 포함하는, 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 데이터 처리 장치가 상기 비디오 인코더에서 출력하는 토큰들을 경량화하여 상기 전역 비디오 특징을 생성하는 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 SRL 생성기는 상기 텍스트에서 어느 하나의 동사 및 상기 어느 하나의 동사와 관련된 적어도 하나의 명사구를 추출하여 상기 의미적 구문을 생성하는 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 융합 임베딩 시퀀스를 생성하는 단계에서,상기 데이터 처리 장치가 (i) 상기 전역 비디오 특징 및 상기 전역 텍스트 특징에 대한 크로스 어텐션을 수행하여 전역적 문맥 특징에 대한 제1 융합 임베딩 시퀀스를 생성하고, (ii) 상기 의미적 구문 특징 및 상기 튜브 특징에 대한 크로스 어텐션을 수행하여 의미적 특징에 대한 제2 융합 임베딩 시퀀스를 생성하는, 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 프록시 태스크는 MLM(Masked language modeling), VTC(video-text contrastive), VTM(video-text matching), MAM(masked action modeling) 및 ANM(action numbering modeling)을 포함하는 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 프록시 태스크는 MAM (masked action modeling)을 포함하고,상기 MAM에 대한 손실함수는 상기 튜브 특징 및 동사가 마스킹된 상기 의미적 구문 특징에서 상기 마스킹된 동사를 예측하도록 학습되는 크로스 엔트로피 손실함수인, 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 프록시 태스크는 ANM(action numbering modeling)을 포함하고,상기 ANM에 대한 손실함수는 상기 의미적 구문 특징 및 상기 튜브 특징에 대한 크로스 어텐션을 수행하여 산출되는 융합 임베딩 시퀀스를 입력받아 의미적 구문에 있는 동사의 개수를 예측하도록 학습되는 평균 제곱 오차 함수인, 객체 움직임 강조한 비디오-언어 사전학습 모델 생성 방법.</claim></claimInfo><claimInfo><claim>8. 비디오 및 상기 비디오에 대응하는 텍스트를 포함하는 입력 데이터를 입력받는 인터페이스 장치;특정 태스크를 수행하도록 파인 튜닝된 비디오-언어 사전학습 모델을 저장하는 저장장치; 및상기 입력 데이터를 상기 비디오-언어 사전학습에 입력하여 상기 특정 태스크를 추론하는 연산장치를 포함하되,상기 비디오-언어 사전학습 모델은 상기 비디오에 대한 전역 비디오 특징 및 튜브 특징을 생성하고, 상기 텍스트에 대한 전역 텍스트 특징 및 의미적 구문 특징를 생성하고, 상기 전역 비디오 특징, 상기 튜브 특징, 상기 전역 텍스트 특징 및 상기 의미적 구문 특징에 대한 크로스 어텐션을 통해 생성하는 융합 임베딩 시퀀스를 이용하여 상기 특정 태스크를 추론하는, 비디오-언어 사전학습 모델을 이용한 추론 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 비디오-언어 사전학습 모델은 상기 비디오를 입력받아 비디오 인코더에서 출력하는 토큰들을 경량화하여 상기 전역 비디오 특징을 생성하는 비디오-언어 사전학습 모델을 이용한 추론 장치.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 의미적 구문 특징은 상기 텍스트를 입력받아 SRL(semantic role labeling) 생성기가 출력하는 것으로, 상기 SRL 생성기는 상기 텍스트에서 어느 하나의 동사 및 상기 어느 하나의 동사와 관련된 적어도 하나의 명사구를 추출하여 상기 의미적 구문을 생성하는, 비디오-언어 사전학습 모델을 이용한 추론 장치.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서,상기 융합 임베딩 시퀀스는 제1 융합 임베딩 시퀀스 및 제2 융합 임베딩 시퀀스를 포함하고,상기 비디오-언어 사전학습 모델은 (i) 상기 전역 비디오 특징 및 상기 전역 텍스트 특징에 대한 크로스 어텐션을 수행하여 전역적 문맥 특징에 대한 상기 제1 융합 임베딩 시퀀스를 생성하고, (ii) 상기 의미적 구문 특징 및 상기 튜브 특징에 대한 크로스 어텐션을 수행하여 의미적 특징에 대한 상기 제2 융합 임베딩 시퀀스를 생성하는 비디오-언어 사전학습 모델을 이용한 추론 장치.</claim></claimInfo><claimInfo><claim>12. 제8항에 있어서,상기 비디오-언어 사전학습 모델은 학습과정에서 프록시 태스크를 이용하여 사전 학습되되,상기 프록시 태스크는 MLM(Masked language modeling), VTC(video-text contrastive), VTM(video-text matching), MAM(masked action modeling) 및 ANM(action numbering modeling)을 포함하는 비디오-언어 사전학습 모델을 이용한 추론 장치.</claim></claimInfo><claimInfo><claim>13. 제8항에 있어서,상기 비디오-언어 사전학습 모델은 학습과정에서 프록시 태스크를 이용하여 사전 학습되되, 상기 프록시 태스크는 MAM (masked action modeling)을 포함하고,학습과정에서 상기 MAM에 대한 손실함수는 상기 튜브 특징 및 동사가 마스킹된 상기 의미적 구문 특징에서 상기 마스킹된 동사를 예측하도록 학습되는 크로스 엔트로피 손실함수인, 비디오-언어 사전학습 모델을 이용한 추론 장치.</claim></claimInfo><claimInfo><claim>14. 제8항에 있어서,상기 비디오-언어 사전학습 모델은 학습과정에서 프록시 태스크를 이용하여 사전 학습되되, 상기 프록시 태스크는 ANM(action numbering modeling)을 포함하고,학습과정에서 상기 ANM에 대한 손실함수는 상기 의미적 구문 특징 및 상기 튜브 특징에 대한 크로스 어텐션을 수행하여 산출되는 융합 임베딩 시퀀스를 입력받아 의미적 구문에 있는 동사의 개수를 예측하도록 학습되는 평균 제곱 오차 함수인, 비디오-언어 사전학습 모델을 이용한 추론 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220040083301</code><country>대한민국</country><engName>Ewha University - Industry Collaboration Foundation</engName><name>이화여자대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 마포구...</address><code> </code><country>대한민국</country><engName>KANG, Je Won</engName><name>강제원</name></inventorInfo><inventorInfo><address>인천광역시 부평구...</address><code> </code><country>대한민국</country><engName>LEE, Ju Hee</engName><name>이주희</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로**길**, **층, **층(코아렌빌딩)</address><code>920161001214</code><country>대한민국</country><engName>ISIS IP Law LLC</engName><name>특허법인(유한)아이시스</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.12.13</priorityApplicationDate><priorityApplicationNumber>1020230180965</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.12.12</receiptDate><receiptNumber>1-1-2024-1382013-08</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.04.24</receiptDate><receiptNumber>1-1-2025-0464499-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240185194.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93dd5ee96a5f8c074004943f168836e9109b52fb50a81cd816e2889ca42a8d129fed26ee65b8fb3b80542f956708a9d29d5b478e4d79beda86</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf94c730609b01706b0e660f92151c00a49a55ef8096ec1289ff167da79928abc26b6181ec69ae55165d5c0405f07e6f40195869839de1d145</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>