<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:03.53</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.03.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7032303</applicationNumber><claimCount>69</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>섀도우 정보를 이용한 렌더링</inventionTitle><inventionTitleEng>RENDERING USING SHADOW INFORMATION</inventionTitleEng><openDate>2022.12.13</openDate><openNumber>10-2022-0164484</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.02.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.09.16</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/236</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 실세계 객체들 및 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해, 하나 이상의 프로세서들은 상기 장면 지오메트리에 기초하여, 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하는 코드를 포함한다. 상기 프로세서들은 상기 섀도우 정보 및상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하는 코드를 포함한다. 일부 예들에서, 섀도우 정보는 섀도우 팩터들 및 식별자들을 포함한다. 각각의 팩터는 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, 상기 장면의 셰이딩 아틀라스 (shading atlas) 에 통합될 수 있다. 각각의 식별자는 팩터에 의해 영향을 받는 장면의 실세계 객체 표면를 식별한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.10.07</internationOpenDate><internationOpenNumber>WO2021202054</internationOpenNumber><internationalApplicationDate>2021.03.05</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/021244</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 그래픽 프로세싱 방법으로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리 (scene geometry) 를 특징으로 하는 장면에 대해, 상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하는 단계; 및 i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하는 단계를 포함하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 섀도우 정보는,섀도우 팩터들 (shadow factors) 로서, 각각의 섀도우 팩터는 i) 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, ii) 상기 장면의 셰이딩 아틀라스 (shading atlas) 에 통합되는, 상기 섀도우 팩터들, 및 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 생성하는 단계는 제 1 디바이스에 의해 수행되고, 상기 렌더링하고 디스플레이하는 단계는 제 2 디바이스에 의해 수행되고,상기 제 1 디바이스는 네트워크를 거쳐 상기 제 2 디바이스와 통신하고;상기 방법은,상기 렌더링하는 단계 이전에, 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하는 단계;제 1 디바이스에 의해 그리고 네트워크를 거쳐 상기 제 2 디바이스로, 식별자들의 세트 및 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하는 단계;  상기 제 2 디바이스에 의해, 제 1 디바이스로부터 그리고 네트워크를 거쳐, 식별자들의 세트 및 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 수신하는 단계; 및 비디오 스트림을 디코딩하는 단계를 더 포함하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>5. 제 3 항에 있어서,상기 방법은 상기 생성하는 단계 이전에,제 2 디바이스에 의해, 제 2 디바이스 장면 지오메트리를 결정하는 단계;상기 제 2 디바이스에 의해 제 1 디바이스로 상기 네트워크를 거쳐, 상기 제 2 디바이스 장면 지오메트리를 송신하는 단계; 및상기 제 1 디바이스에 의해 상기 제 2 디바이스로부터 네트워크를 거쳐, 송신된 상기 제 2 디바이스 장면 지오메트리를 수신하는 단계를 더 포함하고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 이미지 정보, 또는 상기 제 2 디바이스의 메시 (mesh) 정보 중 하나 이상을 포함하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>7. 제 3 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서, 상기 장면의 하나 이상의 실세계 객체들 상에서 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우들 각각에 대한 섀도우 정보를 생성하는 단계는 상기 장면에서 하나 이상의 실제 광 소스들을 적어도 부분적으로 블로킹하는 단계를 포함하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>9. 컴퓨터 그래픽 프로세싱 방법으로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하는 단계로서, 상기 섀도우 정보는 i) 섀도우 팩터들로서, 각각의 섀도우 팩터는 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, 상기 장면의 셰이딩 아틀라스에 통합되는, 상기 섀도우 팩터들, 및 ii) 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하는, 상기 생성하는 단계; 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하는 단계; 및네트워크를 거쳐 제 2 디바이스로, 식별자들의 세트 및 상기 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하는 단계를 포함하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>11. 제 9 항에 있어서,상기 방법은 상기 생성하는 단계 이전에, 상기 제 2 디바이스로부터 상기 네트워크를 거쳐, 제 2 디바이스 장면 지오메트리를 수신하는 단계를 더 포함하고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 2차원 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>13. 제 9 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 그래픽 프로세싱 방법.</claim></claimInfo><claimInfo><claim>14. 컴퓨터 그래픽 방법으로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,제 2 디바이스에 의해, 제 1 디바이스로부터 그리고 네트워크를 거쳐, i) 식별자들의 세트 및 ii) 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 포함하는 섀도우 정보를 수신하는 단계로서, 상기 셰이딩 아틀라스는 복수의 섀도우 팩터들을 포함하고, 각각의 섀도우 팩터는 상기 장면의 하나 이상의 실세계 객체들 상에서 상기 장면의 CG 객체에 의해 캐스팅된 섀도우의 광 감쇠 효과를 설명하고,  상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체를 식별하는, 상기 수신하는 단계;상기 제 2 디바이스에 의해, 상기 비디오 스트림을 디코딩하는 단계; 및상기 제 2 디바이스에 의해, i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하는 단계를 포함하는, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>16. 제 14 항에 있어서,상기 방법은 상기 수신하는 단계 이전에, 상기 제 2 디바이스에 의해 상기 제 1 디바이스로 그리고 상기 네트워크를 거쳐, 제 2 디바이스 장면 지오메트리를 송신하는 단계를 더 포함하고, 상기 제 1 시간의 장면 지오메트리는 송신된 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서, 상기 송신된 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 2차원 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>18. 제 14 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>19. 그래픽 프로세싱을 위한 장치로서,메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세스를 포함하고, 상기 적어도 하나의 프로세스는, 하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하도록; 그리고i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하도록 구성되는, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>20. 제 19 항에 있어서, 상기 섀도우 정보는,섀도우 팩터들로서, 각각의 섀도우 팩터는 i) 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, ii) 상기 장면의 셰이딩 아틀라스에 통합되는, 상기 섀도우 팩터들, 및 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하는, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서,상기 생성하는 것은 제 1 디바이스의 적어도 하나의 프로세서에 의해 수행되고, 렌더링하고 디스플레이하는 것은 제 2 디바이스의 적어도 하나의 프로세서에 의해 수행되고,상기 제 1 디바이스는 네트워크를 거쳐 상기 제 2 디바이스와 통신하고;상기 적어도 하나의 프로세서들은,렌더링하는 것 이전에, 상기 제 1 디바이스에서, 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하도록;제 1 디바이스에 의해 그리고 네트워크를 거쳐 상기 제 2 디바이스로, 식별자들의 세트 및 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하도록; 상기 제 2 디바이스에 의해, 제 1 디바이스로부터 그리고 네트워크를 거쳐, 식별자들의 리스트 및 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 수신하도록; 그리고상기 제 2 디바이스에서, 비디오 스트림을 디코딩하도록 더 구성되는, 그래픽 프로세싱을 위한 장치.     </claim></claimInfo><claimInfo><claim>22. 제 21 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>23. 제 21 항에 있어서, 상기 적어도 하나의 프로세서는, 상기 생성하는 것 이전에, 제 2 디바이스에 의해, 제 2 디바이스 장면 지오메트리를 결정하도록;상기 제 2 디바이스에 의해 제 1 디바이스로 네트워크를 거쳐, 상기 제 2 디바이스 장면 지오메트리를 송신하도록; 그리고상기 제 1 디바이스에 의해 상기 제 2 디바이스로부터 네트워크를 거쳐, 송신된 제 2 디바이스 장면 지오메트리를 수신하도록 더 구성되고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>24. 제 22 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 이미지 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>25. 제 21 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>26. 그래픽 프로세싱을 위한 장치로서,메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세스를 포함하고, 하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 적어도 하나의 프로세스는, 상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하도록 구성되고, 섀도우 정보는 i) 섀도우 팩터들로서, 각각의 섀도우 팩터는 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, 상기 장면의 셰이딩 아틀라스에 통합되는, 상기 섀도우 팩터들, 및 ii) 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하고; 상기 적어도 하나의 프로세스는, 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하도록 구성되고,상기 적어도 하나의 프로세스는, 네트워크를 거쳐 상기 제 2 디바이스로, 식별자들의 세트 및 상기 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하도록 구성되는, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>27. 제 26 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>28. 제 26 항에 있어서, 상기 적어도 하나의 프로세서는, 상기 생성하는 것 이전에 그리고 상기 제 2 디바이스로부터 상기 네트워크를 거쳐, 제 2 디바이스 장면 지오메트리를 수신하도록 더 구성되고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>29. 제 28 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 2차원 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>30. 제 26 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>31. 컴퓨터 그래픽 방법으로서,메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세스를 포함하고, 하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 적어도 하나의 프로세스는, 제 1 디바이스로부터 그리고 네트워크를 거쳐, i) 식별자들의 세트 및 ii) 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 포함하는 섀도우 정보를 수신하도록 구성되고, 상기 셰이딩 아틀라스는 복수의 섀도우 팩터들을 포함하고, 각각의 섀도우 팩터는 상기 장면의 하나 이상의 실세계 객체들 상에서 상기 장면의 CG 객체에 의해 캐스팅된 섀도우의 광 감쇠 효과를 설명하고,  상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체를 식별하고,상기 적어도 하나의 프로세스는, 비디오 스트림을 디코딩하도록 구성되고;그리고상기 적어도 하나의 프로세스는, i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하도록 구성되는, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>32. 제 31 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>33. 제 31 항에 있어서, 상기 적어도 하나의 프로세서는, 상기 수신하는 것 이전에, 상기 제 1 디바이스에 그리고 상기 네트워크를 거쳐 현재의 장면 지오메트리를 송신하도록 더 구성되고, 상기 제 1 시간의 장면 지오메트리는 송신된 현재의 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>34. 제 33 항에 있어서, 상기 송신된 현재 장면 지오메트리는: 상기 렌더링 프로세서의 디바이스의 포즈 정보, 상기 렌더링 프로세서의 디바이스에 의해 캡처된 2 차원 정보, 또는 상기 렌더링 프로세서의 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>35. 제 31 항에 있어서, 상기 렌더링 프로세서의 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 그래픽 방법.</claim></claimInfo><claimInfo><claim>36. 장치로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하기 위한 수단; 및i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하기 위한 수단을 포함하는, 장치.  </claim></claimInfo><claimInfo><claim>37. 제 36 항에 있어서, 상기 섀도우 정보는,섀도우 팩터들로서, 각각의 섀도우 팩터는 i) 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, ii) 상기 장면의 셰이딩 아틀라스에 통합되는, 상기 섀도우 팩터들, 및 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>38. 제 37 항에 있어서,생성은 제 1 디바이스에 의해 수행되고, 렌더링 및 디스플레이는 제 2 디바이스에 의해 수행되고,상기 제 1 디바이스는 네트워크를 거쳐 상기 제 2 디바이스와 통신하고;상기 장치는,상기 렌더링 이전에, 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하기 위한 수단;제 1 디바이스에 의해 그리고 네트워크를 거쳐 상기 제 2 디바이스로, 식별자들의 세트 및 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하기 위한 수단; 상기 제 2 디바이스에 의해, 상기 제 1 디바이스로부터 그리고 상기 네트워크를 거쳐, 식별자들의 리스트 및 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 수신하기 위한 수단; 및비디오 스트림을 디코딩하기 위한 수단을 더 포함하는, 장치.</claim></claimInfo><claimInfo><claim>39. 제 38 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 장치.</claim></claimInfo><claimInfo><claim>40. 제 38 항에 있어서,생성 이전에, 제 2 디바이스 장면 지오메트리를 결정하기 위한 수단;생성 이전에 그리고 제 1 디바이스로 네트워크를 거쳐, 상기 제 2 디바이스 장면 지오메트리를 송신하기 위한 수단; 및생성 이전에 그리고 상기 제 2 디바이스로부터 네트워크를 거쳐, 송신된 상기 제 2 디바이스 장면 지오메트리를 수신하기 위한 수단을 더 포함하고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 장치.</claim></claimInfo><claimInfo><claim>41. 제 40 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 이미지 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>42. 제 38 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 장치.</claim></claimInfo><claimInfo><claim>43. 컴퓨터 그래픽 프로세싱을 위한 장치로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하기 위한 수단으로서, 상기 섀도우 정보는 i) 섀도우 팩터들로서, 각각의 섀도우 팩터는 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, 상기 장면의 셰이딩 아틀라스에 통합되는, 상기 섀도우 팩터들, 및 ii) 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하는, 상기 생성하기 위한 수단, 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하기 위한 수단; 및네트워크를 거쳐 상기 제 2 디바이스로, 상기 식별자들의 세트 및 상기 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하기 위한 수단을 포함하는, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>44. 제 43 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>45. 제 43 항에 있어서, 상기 장치는, 생성 이전에 그리고 상기 제 2 디바이스로부터 상기 네트워크를 거쳐, 제 2 디바이스 장면 지오메트리를 수신하기 위한 수단을 더 포함하고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>46. 제 45 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 2차원 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>47. 제 43 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>48. 컴퓨터 그래픽 프로세싱을 위한 장치로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,제 2 디바이스에 의해, 제 1 디바이스로부터 그리고 네트워크를 거쳐, i) 식별자들의 세트 및 ii) 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 포함하는 섀도우 정보를 수신하기 위한 수단으로서, 상기 셰이딩 아틀라스는 복수의 섀도우 팩터들을 포함하고, 각각의 섀도우 팩터는 상기 장면의 하나 이상의 실세계 객체들 상에서 상기 장면의 CG 객체에 의해 캐스팅된 섀도우의 광 감쇠 효과를 설명하고,  상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체를 식별하는, 상기 수신하기 위한 수단;상기 제 2 디바이스에 의해, 상기 비디오 스트림을 디코딩하기 위한 수단; 및상기 제 2 디바이스에 의해, i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하기 위한 수단을 포함하는, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>49. 제 48 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>50. 제 48 항에 있어서, 상기 장치는, 상기 제 2 디바이스에 의해 상기 제 1 디바이스에 그리고 상기 네트워크를 거쳐 수신 전에 제 2 디바이스 장면 지오메트리를 송신하기 위한 수단을 더 포함하고, 상기 제 1 시간의 장면 지오메트리는 송신된 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>51. 제 50 항에 있어서, 송신된 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 2차원 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>52. 제 48 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 그래픽 프로세싱을 위한 장치.</claim></claimInfo><claimInfo><claim>53. 그래픽 프로세싱을 위해 컴퓨터 실행가능한 코드를 저장하는 컴퓨터 판독가능한 저장 매체로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하고; 그리고i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하는 코드를 포함하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>54. 제 53 항에 있어서,상기 섀도우 정보는,섀도우 팩터들로서, 각각의 섀도우 팩터는 i) 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, ii) 상기 장면의 셰이딩 아틀라스에 통합되는, 상기 섀도우 팩터들, 및 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>55. 제 54 항에 있어서,생성은 제 1 디바이스에 의해 수행되고, 렌더링 및 디스플레이는 제 2 디바이스에 의해 수행되고,상기 제 1 디바이스는 네트워크를 거쳐 상기 제 2 디바이스와 통신하고;상기 컴퓨터 판독가능한 저장 매체는,상기 렌더링 이전에, 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하고;제 1 디바이스에 의해 그리고 네트워크를 거쳐 상기 제 2 디바이스로, 식별자들의 세트 및 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하고; 상기 제 2 디바이스에 의해, 상기 제 1 디바이스로부터 그리고 상기 네트워크를 거쳐, 상기 식별자들의 리스트 및 상기 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 수신하고;그리고상기 비디오 스트림을 디코딩하는 컴퓨터 실행가능한 코드를 더 포함하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>56. 제 55 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>57. 제 55 항에 있어서,상기 컴퓨터 판독가능한 저장 매체는, 상기 생성 이전에,상기 제 2 디바이스에 의해 제 2 디바이스 장면 지오메트리를 결정하고;상기 제 2 디바이스에 의해 제 1 디바이스로 상기 네트워크를 거쳐, 상기 제 2 디바이스 장면 지오메트리를 송신하고; 그리고상기 제 1 디바이스에 의해 상기 제 2 디바이스로부터 상기 네트워크를 거쳐, 송신된 제 2 디바이스 장면 지오메트리를 수신하는 컴퓨터 실행가능한 코드를 더 저장하고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>58. 제 57 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 이미지 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>59. 제 55 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>60. 그래픽 프로세싱을 위해 컴퓨터 실행가능한 코드를 저장하는 컴퓨터 판독가능한 저장 매체로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 컴퓨터 판독가능한 저장 매체는, 상기 제 1 시간의 상기 장면 지오메트리에 기초하여, 상기 장면의 하나 이상의 실세계 객체들 상에 상기 장면의 CG 객체에 의해 캐스팅된 하나 이상의 섀도우 각각에 대해 섀도우 정보를 생성하는 코드를 포함하고, 상기 섀도우 정보는 i) 섀도우 팩터들로서, 각각의 섀도우 팩터는 실세계 객체 표면 상에 캐스팅된 섀도우의 광 감쇠 효과를 설명하고, 상기 장면의 셰이딩 아틀라스에 통합되는, 상기 섀도우 팩터들, 및 ii) 식별자들의 세트로서, 상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체 표면을 식별하는, 상기 식별자들의 세트를 포함하고, 상기 컴퓨터 판독가능한 저장 매체는, 상기 셰이딩 아틀라스를 비디오 데이터 스트림으로 인코딩하는 코드를 포함하고,상기 컴퓨터 판독가능한 저장 매체는, 네트워크를 거쳐 상기 제 2 디바이스로, 식별자들의 세트 및 상기 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 송신하는 코드를 포함하는, 컴퓨터 판독가능한 저장 매체. </claim></claimInfo><claimInfo><claim>61. 제 60 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>62. 제 60 항에 있어서,상기 컴퓨터 판독가능한 저장 매체는, 생성 이전에, 상기 제 2 디바이스로부터 네트워크를 거쳐, 제 2 디바이스 장면 지오메트리를 수신하는 컴퓨터 실행가능한 코드를 더 저장하고, 상기 제 1 시간의 장면 지오메트리는 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>63. 제 62 항에 있어서, 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 2차원 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>64. 제 60 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>65. 그래픽 프로세싱을 위해 컴퓨터 실행가능한 코드를 저장하는 컴퓨터 판독가능한 저장 매체로서,하나 이상의 실세계 객체들 및 하나 이상의 컴퓨터 생성 (CG) 객체들을 포함하고 제 1 시간의 장면 지오메트리를 특징으로 하는 장면에 대해,상기 컴퓨터 판독가능한 저장 매체는, 제 2 디바이스에 의해, 제 1 디바이스로부터 그리고 네트워크를 거쳐, i) 식별자들의 세트 및 ii) 셰이딩 아틀라스를 인코딩하는 비디오 스트림을 포함하는 섀도우 정보를 수신하는 코드를 포함하고, 상기 셰이딩 아틀라스는 복수의 섀도우 팩터들을 포함하고, 각각의 섀도우 팩터는 상기 장면의 하나 이상의 실세계 객체들 상에서 상기 장면의 CG 객체에 의해 캐스팅된 섀도우의 광 감쇠 효과를 설명하고,  상기 세트에서 각각의 식별자는 섀도우 팩터에 의해 영향을 받는 상기 장면의 실세계 객체를 식별하고,상기 컴퓨터 판독가능한 저장 매체는, 상기 제 2 디바이스에 의해, 비디오 스트림을 디코딩하는 코드를 포함하고; 그리고상기 컴퓨터 판독가능한 저장 매체는, 상기 제 2 디바이스에 의해, i) 상기 섀도우 정보 및 ii) 상기 제 1 시간보다 늦은 렌더링 시의 장면 지오메트리의 함수로서 상기 장면의 프레임을 렌더링하고 디스플레이하는 코드를 포함하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>66. 제 65 항에 있어서, 상기 비디오 스트림은 MPEG (Moving Picture Experts Group) 전송 스트림인, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>67. 제 65 항에 있어서,상기 컴퓨터 판독가능한 저장 매체는, 수신 이전에, 상기 제 2 디바이스에 의해 제 1 디바이스로 그리고 네트워크를 거쳐, 제 2 디바이스 장면 지오메트리를 송신하는 컴퓨터 실행가능한 코드를 더 저장하고, 상기 제 1 시간의 장면 지오메트리는 송신된 상기 제 2 디바이스 장면 지오메트리에 적어도 부분적으로 기초하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>68. 제 67 항에 있어서, 송신된 상기 제 2 디바이스 장면 지오메트리는 상기 제 2 디바이스의 포즈 정보, 상기 제 2 디바이스에 의해 캡처된 2차원 정보, 또는 상기 제 2 디바이스의 메시 정보 중 하나 이상을 포함하는, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo><claimInfo><claim>69. 제 65 항에 있어서, 상기 제 2 디바이스는 비디오 시스루 디바이스 또는 광학 시스루 디바이스 중 하나인, 컴퓨터 판독가능한 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리포니아주 ...</address><code> </code><country> </country><engName>GARVEY, JOSEPH DANIEL</engName><name>가비 조셉 다니엘</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리포니아주 ...</address><code> </code><country> </country><engName>VRCELJ, BOJAN</engName><name>브르첼리 보얀</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.04.03</priorityApplicationDate><priorityApplicationNumber>63/005,155</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.11.02</priorityApplicationDate><priorityApplicationNumber>17/087,252</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.09.16</receiptDate><receiptNumber>1-1-2022-0976082-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.11.09</receiptDate><receiptNumber>1-5-2022-0168099-38</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.02.20</receiptDate><receiptNumber>1-1-2024-0196099-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.02.20</receiptDate><receiptNumber>1-1-2024-0196100-85</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227032303.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f3a3253aec6b83e2b70eb515e9cd9c5c16443946b4c00a336cb7bc1d25fdaa63edeb1ced18491b8c94d3dfd6da8b957dc0651b16b8e35a19</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa276f647ead63f3985975a7eecddb4506d073b57c025b06e7c43587f43d48994fd7c72fe8590d2afed6a1c108d8911f49f1382de321bb1d8</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>