<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:16.016</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.11.02</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0144491</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>대상 객체에 적응적인 객체 추적 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS OF OBJECT TRACKING ADAPTIVE TO  TARGET OBJECT</inventionTitleEng><openDate>2022.05.10</openDate><openNumber>10-2022-0059194</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06T 1/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/02</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 대상 객체에 적응적인 객체 추적 방법 및 장치가 개시된다. 일 실시예에 따르면, 그 방법은 객체의 동적 특징을 예측하고, 예측된 동적 특징에 기초하여 크롭 영역의 사이즈를 결정하고, 크롭 영상을 이용하여 객체의 추적 결과를 생성하는 단계들을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 영상의 프레임들에 기초하여 상기 입력 영상 내 객체의 동적 특징을 예측하는 단계;상기 객체의 상기 예측된 동적 특징에 기초하여 상기 입력 영상의 현재 프레임을 위한 크롭 영역의 사이즈를 결정하는 단계;상기 크롭 영역의 상기 결정된 사이즈에 기초하여 상기 현재 프레임을 크롭하여 크롭 영상을 생성하는 단계; 및상기 크롭 영상을 이용하여 상기 현재 프레임에 관한 상기 객체의 추적 결과를 생성하는 단계를 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 동적 특징은 상기 객체의 움직임을 포함하고,상기 사이즈를 결정하는 단계는상기 움직임이 임계치보다 작은 경우에 비해 상기 움직임이 상기 임계치보다 큰 경우에 상기 크롭 영역의 상기 사이즈를 더 크게 결정하는 단계를 포함하는,객체 추적 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 추적 결과를 생성하는 단계는각각 객체 추적을 수행하는 복수의 뉴럴 네트워크 모델들 중에 상기 크롭 영역의 상기 결정된 사이즈에 대응하는 뉴럴 네트워크 모델을 선택하는 단계; 및상기 크롭 영상 및 상기 선택된 뉴럴 네트워크 모델을 이용하여 상기 객체의 상기 추적 결과를 생성하는 단계를 포함하는, 객체 추적 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 복수의 뉴럴 네트워크 모델들은상기 크롭 영역의 제1 사이즈를 위한 제1 뉴럴 네트워크 모델 및 상기 크롭 영역의 제2 사이즈를 위한 제2 뉴럴 네트워크 모델을 포함하는,객체 추적 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 뉴럴 네트워크 모델을 선택하는 단계는상기 크롭 영역의 상기 결정된 사이즈가 상기 제1 사이즈인 경우 상기 복수의 뉴럴 네트워크 모델들 중에 상기 제1 뉴럴 네트워크 모델을 선택하는 단계; 및상기 크롭 영역의 상기 결정된 사이즈가 상기 제2 사이즈인 경우 상기 복수의 뉴럴 네트워크 모델들 중에 상기 제2 뉴럴 네트워크 모델을 선택하는 단계를 포함하는, 객체 추적 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 제1 사이즈는 상기 제2 사이즈보다 작고,상기 제1 뉴럴 네트워크 모델은 상기 제2 뉴럴 네트워크 모델보다 입력 특징의 정보를 더 많이 증폭하는,객체 추적 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 제1 사이즈는 상기 제2 사이즈보다 작고,상기 제1 뉴럴 네트워크 모델은 상기 제2 뉴럴 네트워크 모델에 비해 더 많은 웨이트 커널로 채널 사이즈를 키움으로써 상기 제2 뉴럴 네트워크 모델에 비해 입력 특징의 정보를 더 많이 증폭하는,객체 추적 방법.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서,상기 제1 사이즈는 상기 제2 사이즈보다 작고,상기 제1 뉴럴 네트워크 모델은 상기 제2 뉴럴 네트워크 모델에 비해 더 작은 풀링 윈도우를 이용함으로써 상기 제2 뉴럴 네트워크 모델에 비해 입력 특징의 정보를 더 많이 증폭하는,객체 추적 방법.</claim></claimInfo><claimInfo><claim>9. 제3항에 있어서,상기 복수의 뉴럴 네트워크 모델들은 적어도 일부의 가중치를 서로 공유하는,객체 추적 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항의 방법을 수행하는 명령어들을 포함하는 하나 이상의 프로그램을 저장한 컴퓨터 판독 가능 저장매체.</claim></claimInfo><claimInfo><claim>11. 프로세서; 및상기 프로세서에서 실행가능한 명령어들을 포함하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에서 실행되면, 상기 프로세서는입력 영상의 프레임들에 기초하여 상기 입력 영상 내 객체의 동적 특징을 예측하고,상기 객체의 상기 예측된 동적 특징에 기초하여 상기 입력 영상의 현재 프레임을 위한 크롭 영역의 사이즈를 결정하고,상기 크롭 영역의 상기 결정된 사이즈에 기초하여 상기 현재 프레임을 크롭하여 크롭 영상을 생성하고,상기 크롭 영상을 이용하여 상기 현재 프레임에 관한 상기 객체의 추적 결과를 생성하는,객체 추적 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 동적 특징은 상기 객체의 움직임을 포함하고,상기 프로세서는상기 움직임이 임계치보다 작은 경우에 비해 상기 움직임이 상기 임계치보다 큰 경우에 상기 크롭 영역의 상기 사이즈를 더 크게 결정하는,객체 추적 장치.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 프로세서는각각 객체 추적을 수행하는 복수의 뉴럴 네트워크 모델들 중에 상기 크롭 영역의 상기 결정된 사이즈에 대응하는 뉴럴 네트워크 모델을 선택하고,상기 크롭 영상 및 상기 선택된 뉴럴 네트워크 모델을 이용하여 상기 객체의 상기 추적 결과를 생성하는,객체 추적 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 복수의 뉴럴 네트워크 모델들은상기 크롭 영역의 제1 사이즈를 위한 제1 뉴럴 네트워크 모델 및 상기 크롭 영역의 제2 사이즈를 위한 제2 뉴럴 네트워크 모델을 포함하는,객체 추적 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 제1 사이즈는 상기 제2 사이즈보다 작고,상기 제1 뉴럴 네트워크 모델은 상기 제2 뉴럴 네트워크 모델보다 입력 특징의 정보를 더 많이 증폭하는,객체 추적 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 제1 사이즈는 상기 제2 사이즈보다 작고,상기 제1 뉴럴 네트워크 모델은 상기 제2 뉴럴 네트워크 모델에 비해 더 많은 웨이트 커널로 채널 사이즈를 키움으로써 상기 제2 뉴럴 네트워크 모델에 비해 입력 특징의 정보를 더 많이 증폭하는,객체 추적 장치.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 프로세서는상기 제1 사이즈는 상기 제2 사이즈보다 작고,상기 제1 뉴럴 네트워크 모델은 상기 제2 뉴럴 네트워크 모델에 비해 더 작은 풀링 윈도우를 이용함으로써 상기 제2 뉴럴 네트워크 모델에 비해 입력 특징의 정보를 더 많이 증폭하는,객체 추적 장치.</claim></claimInfo><claimInfo><claim>18. 감지된 시각 정보에 기초하여 입력 영상을 생성하는 카메라; 및상기 입력 영상의 프레임들에 기초하여 상기 입력 영상 내 객체의 동적 특징을 예측하고,상기 객체의 상기 예측된 동적 특징에 기초하여 상기 입력 영상의 현재 프레임을 위한 크롭 영역의 사이즈를 결정하고,상기 크롭 영역의 상기 결정된 사이즈에 기초하여 상기 현재 프레임을 크롭하여 크롭 영상을 생성하고,상기 크롭 영상을 이용하여 상기 현재 프레임에 관한 상기 객체의 추적 결과를 생성하는, 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 동적 특징은 상기 객체의 움직임을 포함하고,상기 프로세서는상기 예측된 움직임이 임계치보다 작은 경우에 비해 상기 예측된 움직임이 상기 임계치보다 큰 경우에 상기 크롭 영역의 상기 사이즈를 더 크게 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 프로세서는각각 객체 추적을 수행하는 복수의 뉴럴 네트워크 모델들 중에 상기 크롭 영역의 상기 결정된 사이즈에 대응하는 뉴럴 네트워크 모델을 선택하고,상기 크롭 영상 및 상기 선택된 뉴럴 네트워크 모델을 이용하여 상기 객체의 상기 추적 결과를 생성하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170498351</code><country>대한민국</country><engName>Seohyung Lee</engName><name>이서형</name></inventorInfo><inventorInfo><address>경기도 수원시 권선구...</address><code>420190482041</code><country>대한민국</country><engName>LEE, Dong Wook</engName><name>이동욱</name></inventorInfo><inventorInfo><address>경기도 안양시 동안구...</address><code>420170731095</code><country>대한민국</country><engName>SON, Chang Yong</engName><name>손창용</name></inventorInfo><inventorInfo><address>서울특별시 중랑구...</address><code>420200727619</code><country>대한민국</country><engName>KIM, Seung Wook</engName><name>김승욱</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code>420170743681</code><country>대한민국</country><engName>YOO BYUNG IN</engName><name>유병인</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.11.02</receiptDate><receiptNumber>1-1-2020-1166684-53</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.11.02</receiptDate><receiptNumber>1-1-2023-1211269-78</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200144491.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930208669225adfefb3ca838abcc265f2eab8a87e16faf4fdbb2ef3f6cf3656c4930c5972cbe4eb215d07840bf922674f51bf2fbf04f9b036a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9c0133cbd1483f35416586bd542068979ea481bbc430bda59b27bfe723648e694ac7a98ca663190fc86f35645221cbebba70c8a3bf335784</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>