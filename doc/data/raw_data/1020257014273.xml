<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:30:09.309</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7014273</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>실시간 머신 학습 기반 인-페인팅</inventionTitle><inventionTitleEng>REAL-TIME MACHINE LEARNING BASED IN-PAINTING</inventionTitleEng><openDate>2025.06.04</openDate><openNumber>10-2025-0078996</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.04.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.29</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 머신 학습 기술들을 사용하여 실시간 인-페인팅을 수행하기 위한 시스템을 수반한다. 이러한 시스템은 현실-세계 환경에서의 현실-세계 객체의 묘사를 포함하는 비디오를 수신한다. 이러한 시스템은 현실-세계 객체와 연관된 세그먼트화에 액세스하고 비디오의 제1 프레임의 영역으로부터 현실-세계 객체의 묘사를 제거한다. 이러한 시스템은 제1 프레임의 부분들이 현실-세계 객체의 묘사가 제거된 영역에 혼합된 새로운 프레임을 생성하기 위해, 머신 학습 모델에 의해, 제1 프레임 및 제1 프레임에 선행하는 비디오의 하나 이상의 이전 프레임을 처리한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.04.11</internationOpenDate><internationOpenNumber>WO2024076486</internationOpenNumber><internationalApplicationDate>2023.09.27</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/033907</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 현실-세계 환경에서의 현실-세계 객체의 묘사를 포함하는 비디오를 수신하는 단계;상기 현실-세계 객체와 연관된 세그먼트화에 액세스하는 단계;상기 비디오의 제1 프레임의 영역으로부터 상기 현실-세계 객체의 묘사를 제거하는 단계; 및상기 제1 프레임의 부분들이 상기 현실-세계 객체의 상기 묘사가 제거된 상기 영역에 혼합된 새로운 프레임을 생성하기 위해, 머신 학습 모델에 의해, 상기 제1 프레임 및 상기 제1 프레임에 선행하는 상기 비디오의 하나 이상의 이전 프레임을 처리하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 현실-세계 객체의 상기 묘사를 제외하는 그리고 상기 제1 프레임의 상기 부분들이 상기 현실-세계 객체의 상기 묘사가 제거된 상기 영역에 혼합된 상기 비디오의 새로운 프레임을, 디스플레이를 위해, 생성하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 추가로,상기 세그먼트화를 정의하는 입력을 수신하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 추가로,복수의 AR(augmented reality) 경험들을 디스플레이하는 단계;상기 복수의 AR 경험들로부터 주어진 AR 경험을 선택하는 입력을 수신하는 단계; 및상기 선택된 주어진 AR 경험과 연관된 상기 세그먼트화를 검색하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 머신 학습 모델은 GAN(generative adversarial network)을 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 머신 학습 모델에 의해 상기 제1 프레임 및 상기 하나 이상의 이전 프레임을 처리하는 단계는,상기 제1 프레임의 영역으로부터 상기 현실-세계 객체의 묘사를 제거하는 것에 응답하여 수정된 제1 프레임을 생성하는 단계;상기 이전 프레임으로부터 상기 현실-세계 객체의 묘사를 제거하기 위해 상기 하나 이상의 이전 프레임의 이전 프레임에 상기 세그먼트화를 적용하는 것에 응답하여 수정된 이전 프레임을 생성하는 단계; 및상기 수정된 제1 프레임과 연관된 제1 복수의 특징들 및 상기 수정된 이전 프레임과 연관된 제2 복수의 특징들을 생성하기 위해 상기 수정된 제1 프레임 및 상기 수정된 이전 프레임에 인코더를 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 추가로,상기 제1 복수의 특징들의 서브세트를 선택하는 단계;상기 제2 복수의 특징들의 서브세트를 선택하는 단계;상기 제1 프레임 및 상기 이전 프레임과 연관된 유사성 메트릭에 기초하여 상기 제1 복수의 특징들의 서브세트를 상기 제2 복수의 특징들의 서브세트와 조합하는 것에 의해 특징들의 조합된 서브세트를 생성하는 단계; 및상기 새로운 프레임을 생성하기 위해 상기 특징들의 조합된 서브세트에 디코더를 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 제1 복수의 특징들의 서브세트와 상기 제2 복수의 특징들의 서브세트의 가중 평균에 기초하여 상기 특징들의 조합된 서브세트가 생성되는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 추가로,상기 제1 프레임과 상기 이전 프레임 사이의 차이 또는 거리를 표현하는 광학 흐름 프레임을 결정하는 단계; 및상기 광학 흐름 프레임에 기초하여 상기 유사성 메트릭을 컴퓨팅하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 추가로,상기 제1 프레임과 이전 프레임 사이의 카메라 이동 차이를 결정하는 단계; 및상기 카메라 이동 차이에 기초하여 상기 유사성 메트릭을 컴퓨팅하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서, 추가로,조정된 특징들의 제1 세트를 생성하기 위해 상기 유사성 메트릭을 상기 제1 복수의 특징들의 서브세트와 승산하는 단계;1의 값과 상기 유사성 메트릭 사이의 차이를 컴퓨팅하는 단계;조정된 특징들의 제2 세트를 생성하기 위해 상기 차이를 상기 제2 복수의 특징들의 서브세트와 승산하는 단계; 및상기 특징들의 조합된 서브세트를 생성하기 위해 상기 조정된 특징들의 제1 및 제2 세트들을 가산하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제7항에 있어서, 상기 디코더를 적용하는 단계는,상기 제1 복수의 특징들의 서브세트로부터 제외되는 상기 제1 복수의 특징들 중 하나 이상의 특징을 식별하는 단계; 및특징들의 완전한 세트를 생성하기 위해 상기 식별된 하나 이상의 특징을 상기 특징들의 조합된 서브세트에 가산하는 단계- 상기 새로운 프레임을 생성하기 위해 상기 특징들의 완전한 세트에 상기 디코더가 적용됨 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 머신 학습 모델을 트레이닝하는 단계를 추가로 포함하고, 이는,하나 이상의 트레이닝 현실-세계 객체를 묘사하는 복수의 트레이닝 비디오들 및 상기 하나 이상의 트레이닝 현실-세계 객체가 제거된 연관된 실측 비디오들을 포함하는 트레이닝 데이터를 수신하는 단계- 상기 복수의 트레이닝 비디오들 각각은 상이한 현실-세계 환경을 묘사함 -;상기 하나 이상의 트레이닝 현실-세계 객체가 제거된 상기 실측 비디오들 중 제1 실측 비디오와 연관된 상기 복수의 트레이닝 비디오들 중 제1 트레이닝 비디오에 액세스하는 단계;제1 프레임 및 제2 프레임에서 묘사되는 상기 하나 이상의 트레이닝 현실-세계 객체 중 주어진 하나를 제거하기 위해 상기 제1 트레이닝 비디오의 상기 제1 프레임 및 상기 제1 프레임에 인접한 상기 제2 프레임을 수정하는 단계;상기 제1 및 제2 프레임들의 부분들이 상기 하나 이상의 트레이닝 현실-세계 객체 중 상기 주어진 하나의 묘사가 제거된 영역에 혼합된 새로운 트레이닝 프레임을 추정하기 위해 상기 제1 트레이닝 비디오의 상기 제1 및 제2 프레임들에 상기 머신 학습 모델을 적용하는 단계;상기 제1 트레이닝 비디오의 상기 제1 및 제2 프레임들의 플레이 위치에 대응하는 상기 제1 실측 비디오에서의 실측 프레임과 상기 추정된 새로운 트레이닝 프레임 사이의 편차를 컴퓨팅하는 단계; 및상기 컴퓨팅된 편차에 기초하여 상기 머신 학습 모델의 하나 이상의 파라미터를 업데이트하는 단계에 의한 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 추가로,상기 현실-세계 객체와 연관된 상기 세그먼트화를 추정하기 위해 상기 비디오에 전체-신체 세그먼트화 머신 학습 모델을 적용하는 단계- 제거되는 상기 현실-세계 객체의 묘사는 사람의 전체-신체에 대응함 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 추가로,AR 경험과 연관된 하나 이상의 AR(augmented reality) 객체를 검색하는 단계; 및상기 현실-세계 객체의 묘사가 제거된 영역에 대응하는 상기 새로운 프레임의 부분 위에 상기 하나 이상의 AR 객체를 오버레이하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 하나 이상의 AR 객체는 패션 아이템을 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 하나 이상의 AR 객체는 가구 아이템을 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 제거되는 상기 현실-세계 객체의 묘사는 상기 비디오에서의 워터마크에 대응하는 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서,동작들을 수행하도록 구성되는 프로세서를 포함하고, 상기 동작들은,현실-세계 환경에서의 현실-세계 객체의 묘사를 포함하는 비디오를 수신하는 동작;상기 현실-세계 객체와 연관된 세그먼트화에 액세스하는 동작;상기 비디오의 제1 프레임의 영역으로부터 상기 현실-세계 객체의 묘사를 제거하는 동작; 및상기 제1 프레임의 부분들이 상기 현실-세계 객체의 상기 묘사가 제거된 상기 영역에 혼합된 새로운 프레임을 생성하기 위해, 머신 학습 모델에 의해, 상기 제1 프레임 및 상기 제1 프레임에 선행하는 상기 비디오의 하나 이상의 이전 프레임을 처리하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함하는 비-일시적 머신-판독가능 저장 매체로서, 상기 명령어들은, 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하고, 상기 동작들은,현실-세계 환경에서의 현실-세계 객체의 묘사를 포함하는 비디오를 수신하는 동작;상기 현실-세계 객체와 연관된 세그먼트화에 액세스하는 동작;상기 비디오의 제1 프레임의 영역으로부터 상기 현실-세계 객체의 묘사를 제거하는 동작; 및상기 제1 프레임의 부분들이 상기 현실-세계 객체의 상기 묘사가 제거된 상기 영역에 혼합된 새로운 프레임을 생성하기 위해, 머신 학습 모델에 의해, 상기 제1 프레임 및 상기 제1 프레임에 선행하는 상기 비디오의 하나 이상의 이전 프레임을 처리하는 동작을 포함하는 비-일시적 머신-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>이스라엘</country><engName>DUDOVITCH, Gal</engName><name>두도비치, 갈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>이스라엘</country><engName>HAREL, Peleg</engName><name>하렐, 펠레그</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>이스라엘</country><engName>MISHIN SHUVI, Ma'ayan</engName><name>미신 슈비, 마아얀</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>이스라엘</country><engName>SASSON, Gal</engName><name>사슨, 갈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>이스라엘</country><engName>ZOHAR, Matan</engName><name>조하르, 마탄</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.10.03</priorityApplicationDate><priorityApplicationNumber>17/937,734</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.29</receiptDate><receiptNumber>1-1-2025-0486037-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.29</receiptDate><receiptNumber>1-1-2025-0486819-07</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.05.02</receiptDate><receiptNumber>1-5-2025-0073869-97</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257014273.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9351e454fd4c7cb381b1c0734e4eecc6069b5dfb7bbb3e66aea0691ddaee9e5aa543b265efb9476f70887fd291213c489962a39de81d8c1312</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff3a2680d1840595990e57e90bd7f5ac8fe5e8fbbaf4c8af97f7819bdf6fd54f783f96dfdf8a81a403252c596daa64e9f04274d8138e22e12</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>