<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:08:03.83</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.08.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7026607</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>포비티드 감지</inventionTitle><inventionTitleEng>FOVEATED SENSING</inventionTitleEng><openDate>2024.10.28</openDate><openNumber>10-2024-0155200</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.31</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.07</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/117</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/332</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/383</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/951</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 포비티드 감지를 수행하기 위한 시스템들 및 기법들이 설명된다. 일부 양태들에서, 방법(예컨대, 이미지 센서에 의해 구현됨)은, 장면과 연관된 프레임에 대한 센서 데이터를 캡쳐하는 단계, 장면과 연관된 관심 구역(ROI)에 대응하는 정보를 획득하는 단계, ROI에 대응하는 프레임의 제1 부분(제1 해상도를 가짐)을 생성하는 단계, 제2 해상도를 갖는 프레임의 제2 부분을 생성하는 단계, 및 제1 부분 및 제2 부분을 (예컨대, 이미지 신호 프로세서(ISP)에) 출력하는 단계를 포함할 수 있다. 일부 양태들에서, 방법(예컨대, ISP에 의해 구현됨)은, 이미지 센서로부터, 장면과 연관된 프레임에 대한 센서 데이터를 수신하고, 장면과 연관된 ROI에 기초하여 프레임의 제1 버전(제1 해상도를 가짐)을 생성하고, 제2 해상도(제1 해상도보다 낮음)를 갖는 프레임의 제2 버전을 생성할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.08.31</internationOpenDate><internationOpenNumber>WO2023163799</internationOpenNumber><internationalApplicationDate>2022.08.18</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/075177</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프레임들을 생성하는 방법으로서,이미지 센서를 사용하여, 장면과 연관된 프레임에 대한 센서 데이터를 캡쳐하는 단계;관심 구역(ROI)에 대응하는 정보에 기초하여 상기 프레임의 제1 부분을 생성하는 단계로서, 상기 제1 부분은 제1 해상도를 갖는, 상기 제1 부분을 생성하는 단계;상기 프레임의 제2 부분을 생성하는 단계로서, 상기 제2 부분은 상기 제1 해상도보다 낮은 제2 해상도를 갖는, 상기 제2 부분을 생성하는 단계; 및상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 출력하는 단계를 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 이미지 센서는 상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 출력하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 장면과 연관된 마스크를 수신하는 단계를 더 포함하며, 상기 마스크는 이전의 프레임과 연관된 상기 ROI에 대응하는 상기 정보를 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 마스크는 사용자의 시선 정보, 상기 사용자의 예측된 시선, 상기 장면에서 검출된 오브젝트, 상기 장면에 대해 생성된 깊이 맵, 및 상기 장면의 현저성 맵(saliency map) 중 적어도 하나에 기초하여 결정되는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서, 이미지 신호 프로세서를 사용하여, 적어도 부분적으로, 상기 프레임의 상기 제1 부분과 상기 프레임의 상기 제2 부분을 결합함으로써 출력 프레임을 생성하는 단계를 더 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서, 이미지 신호 프로세서를 사용하여, 상기 제1 부분의 시각적 충실도를 개선시키기 위해 제1 하나 이상의 파라미터들에 기초하여 상기 프레임의 상기 제1 부분을 프로세싱하고, 상기 프레임의 상기 제2 부분의 프로세싱을 억제하는 단계를 더 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>7. 제2항에 있어서, 상기 프레임의 상기 제2 부분을 생성하는 단계는,상기 프레임의 상기 제2 부분이 상기 제2 해상도를 갖도록 상기 이미지 센서에서 상기 센서 데이터의 복수의 픽셀들을 결합하는 단계를 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>8. 제2항에 있어서, 상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 출력하는 단계는,상기 이미지 센서와 이미지 신호 프로세서 사이의 인터페이스의 제1 논리 채널을 사용하여 상기 프레임의 상기 제1 부분을 출력하는 단계; 및상기 인터페이스의 제2 논리 채널을 사용하여 상기 프레임의 상기 제2 부분을 출력하는 단계를 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 이미지 신호 프로세서는 상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 출력하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 이미지 신호 프로세서에 의해, 상기 이미지 센서를 포함하는 디바이스와 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터의 모션 정보에 기초하여 상기 장면과 연관된 상기 ROI를 결정하는 단계를 더 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,사용자의 시선 정보, 상기 사용자의 예측된 시선, 상기 장면에서 검출된 오브젝트, 상기 장면에 대해 생성된 깊이 맵, 및 상기 장면의 현저성 맵 중 적어도 하나에 기초하여 상기 ROI를 결정하는 단계를 더 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 이미지 센서를 포함하는 디바이스와 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터 모션 정보를 획득하는 단계; 및상기 모션 정보에 기초하여 상기 ROI를 수정하는 단계를 더 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 사용자의 눈들과 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터 모션 정보를 획득하는 단계; 및상기 모션 정보에 기초하여 상기 ROI를 수정하는 단계를 더 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 ROI를 수정하는 단계는,상기 모션의 방향으로 상기 ROI의 사이즈를 증가시키는 단계를 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>15. 제9항에 있어서,사용자의 눈들과 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터 모션 정보를 획득하는 단계; 및상기 모션 정보에 기초하여 상기 ROI를 수정하는 단계를 더 포함하는, 하나 이상의 프레임들을 생성하는 방법.</claim></claimInfo><claimInfo><claim>16. 하나 이상의 프레임들을 생성하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하며, 상기 적어도 하나의 프로세서는, 이미지 센서로부터, 장면과 연관된 프레임에 대한 센서 데이터를 획득하고; 관심 구역(ROI)에 대응하는 정보에 기초하여 상기 프레임의 제1 부분을 획득하는 것으로서, 상기 제1 부분은 제1 해상도를 갖는, 상기 제1 부분을 획득하고; 상기 프레임의 제2 부분을 획득하는 것으로서, 상기 제2 부분은 상기 제1 해상도보다 낮은 제2 해상도를 갖는, 상기 제2 부분을 획득하고; 그리고 상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 출력하도록구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 적어도 하나의 프로세서는 상기 이미지 센서로부터 상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 획득하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 적어도 하나의 프로세서는,상기 장면과 연관된 마스크를 수신하도록 구성되며, 상기 마스크는 이전의 프레임과 연관된 상기 ROI에 대응하는 상기 정보를 포함하는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 적어도 하나의 프로세서는 사용자의 시선 정보, 상기 사용자의 예측된 시선, 상기 장면에서 검출된 오브젝트, 상기 장면에 대해 생성된 깊이 맵, 및 상기 장면의 현저성 맵 중 적어도 하나에 기초하여 상기 마스크를 결정하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>20. 제17항에 있어서, 상기 적어도 하나의 프로세서는 이미지 신호 프로세서이며, 적어도 부분적으로, 상기 프레임의 상기 제1 부분과 상기 프레임의 상기 제2 부분을 결합함으로써 출력 프레임을 생성하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>21. 제17항에 있어서, 상기 적어도 하나의 프로세서는, 이미지 신호 프로세서를 사용하여, 상기 제1 부분의 시각적 충실도를 개선시키기 위해 제1 하나 이상의 파라미터들에 기초하여 상기 프레임의 상기 제1 부분을 프로세싱하고, 상기 프레임의 상기 제2 부분의 프로세싱을 억제하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>22. 제17항에 있어서, 상기 프레임의 상기 제2 부분을 생성하기 위해, 상기 적어도 하나의 프로세서는,상기 프레임의 상기 제2 부분이 상기 제2 해상도를 갖도록 상기 센서 데이터의 복수의 픽셀들을 결합하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>23. 제17항에 있어서, 상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 출력하기 위해, 상기 적어도 하나의 프로세서는,상기 이미지 센서와 이미지 신호 프로세서 사이의 인터페이스의 제1 논리 채널을 사용하여 상기 프레임의 상기 제1 부분을 출력하고; 그리고상기 인터페이스의 제2 논리 채널을 사용하여 상기 프레임의 상기 제2 부분을 출력하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>24. 제16항에 있어서, 이미지 신호 프로세서는 상기 프레임의 상기 제1 부분 및 상기 프레임의 상기 제2 부분을 출력하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 적어도 하나의 프로세서는, 상기 이미지 신호 프로세서에 의해, 상기 이미지 센서를 포함하는 디바이스와 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터의 모션 정보에 기초하여 상기 장면과 연관된 상기 ROI를 결정하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>26. 제24항에 있어서, 상기 적어도 하나의 프로세서는,사용자의 시선 정보, 상기 사용자의 예측된 시선, 상기 장면에서 검출된 오브젝트, 상기 장면에 대해 생성된 깊이 맵, 및 상기 장면의 현저성 맵 중 적어도 하나에 기초하여 상기 ROI를 결정하도록 구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 적어도 하나의 프로세서는,상기 이미지 센서를 포함하는 디바이스와 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터 모션 정보를 획득하고; 그리고상기 모션 정보에 기초하여 상기 ROI를 수정하도록구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>28. 제26항에 있어서, 상기 적어도 하나의 프로세서는,상기 사용자의 눈들과 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터 모션 정보를 획득하고; 그리고상기 모션 정보에 기초하여 상기 ROI를 수정하도록구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 ROI를 수정하는 것은, 상기 적어도 하나의 프로세서가,상기 모션의 방향으로 상기 ROI의 사이즈를 증가시키도록 구성되는 것을 포함하는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo><claimInfo><claim>30. 제24항에 있어서, 상기 적어도 하나의 프로세서는,사용자의 눈들과 연관된 모션을 식별하는 적어도 하나의 모션 센서로부터 모션 정보를 획득하고; 그리고상기 모션 정보에 기초하여 상기 ROI를 수정하도록구성되는, 하나 이상의 프레임들을 생성하기 위한 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>KUNDU, DEBARATI</engName><name>쿤두 데바라티</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>AMRESH, AMRIT ANAND</engName><name>암레쉬 암리트 아난드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BEHERA, ANIMESH</engName><name>베헤라 아니메쉬</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>CHENG, CHIH-CHI</engName><name>청 치-치</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BAHETI, PAWAN KUMAR</engName><name>바헤티 파완 쿠마르</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>인도</priorityApplicationCountry><priorityApplicationDate>2022.02.23</priorityApplicationDate><priorityApplicationNumber>202241009796</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.07</receiptDate><receiptNumber>1-1-2024-0860574-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.27</receiptDate><receiptNumber>1-5-2024-0157503-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.07.31</receiptDate><receiptNumber>1-1-2025-0872013-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.07.31</receiptDate><receiptNumber>1-1-2025-0872014-69</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247026607.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9360acbdcd394169cfa6d16961ed75b4d554d032b46321412fec2e76213ed974ff9fd7016df523362bf3e4ff6e6b87dc8325b4b8b590d9dd32</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf908c1cdbed7cf646d8605d6e1220036e3b35d06b8d4e685aa77301596bd27f1aaf6821df7d09f8a5e51557db89558d39ff0161bb630be670</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>