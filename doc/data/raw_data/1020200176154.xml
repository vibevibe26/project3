<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:51.4151</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.12.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0176154</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>영상 처리 방법, 영상 처리 장치, 및 영상 처리를 위한 트레이닝 방법</inventionTitle><inventionTitleEng>IMAGE PROCESSING METHOD, IMAGE PROCESSING APPRATUS,  AND TRAINING METHOD FOR IMAGE PROCESSING</inventionTitleEng><openDate>2022.06.23</openDate><openNumber>10-2022-0086049</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.06</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 영상 처리 방법 및 장치가 개시된다. 영상 처리 방법은 입력 영상 및 입력 영상에 대한 회전 정보를 수신하고, 입력 영상에 대응하는 포즈 정보를 기초로, 입력 영상의 특징 벡터를 생성하고, 특징 벡터, 포즈 정보, 및 회전 정보를 기초로 회전 정보에 대응하는 포즈에 따른 대상 구성 요소를 표현하기 위한 보조 특징 벡터를 생성하며, 특징 벡터 및 보조 특징 벡터에 기초하여 회전 정보에 대응하는 포즈를 갖는 타겟 영상을 생성한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 영상 및 상기 입력 영상에 대한 회전 정보를 수신하는 단계;상기 입력 영상에 대응하는 포즈(pose) 정보를 기초로, 상기 입력 영상의 특징 벡터를 생성하는 단계;상기 특징 벡터, 상기 포즈 정보, 및 상기 회전 정보를 기초로, 상기 회전 정보에 대응하는 포즈에 따른 대상 구성 요소(target component)를 표현하기 위한 보조 특징 벡터(assistant feature vector)를 생성하는 단계; 및상기 특징 벡터 및 상기 보조 특징 벡터에 기초하여 상기 회전 정보에 대응하는 포즈를 갖는 타겟 영상을 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 보조 특징 벡터를 생성하는 단계는상기 포즈 정보를 인코더의 중간 레이어에 대응하도록 변환하는 단계; 상기 특징 벡터, 상기 변환된 포즈 정보, 및 상기 회전 정보를 기초로, 상기 타겟 영상에서 상기 대상 구성 요소가 생성될 위치를 내포하는 가중치 맵(weight map)을 생성하는 단계; 및 상기 가중치 맵과 상기 특징 벡터에서 분리된 대상 특징 벡터를 결합함으로써 상기 포즈에 대응하는 상기 대상 구성 요소를 상기 대상 구성 요소가 생성될 위치에 표현하기 위한 상기 보조 특징 벡터를 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 가중치 맵을 생성하는 단계는상기 특징 벡터, 상기 변환된 포즈 정보, 및 상기 회전 정보를 제1 신경망에 인가함으로써 상기 타겟 영상에서 대상 구성 요소가 생성될 위치를 내포하는 가중치 맵을 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 대상 구성 요소가 복수 개인 경우, 상기 가중치 맵을 생성하는 단계는상기 특징 벡터, 상기 변환된 포즈 정보, 및 상기 회전 정보를 기초로, 상기 타겟 영상에서 상기 복수 개의 대상 구성 요소 별로 해당 대상 구성 요소가 생성될 위치를 내포하는 가중치 맵을 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서, 상기 보조 특징 벡터를 생성하는 단계는 상기 특징 벡터에서 상기 대상 구성 요소에 해당하는 상기 대상 특징 벡터를 분리하는 단계; 및 상기 가중치 맵과 상기 대상 특징 벡터를 결합함으로써 상기 포즈에 대응하는 상기 대상 구성 요소를 상기 대상 구성 요소가 생성될 위치에 표현하기 위한 보조 특징 벡터를 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 특징 벡터를 생성하는 단계는상기 입력 영상으로부터 상기 포즈 정보를 추정하는 단계;상기 입력 영상 및 상기 포즈 정보를 상기 제1 특징 벡터를 출력하는 인코더(encoder)에 인가하는 단계; 및 상기 인코더의 중간 레이어에서 상기 특징 벡터를 획득하는 단계;를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 포즈 정보를 추정하는 단계는상기 입력 영상으로부터 상기 대상 구성 요소를 포함하는 대상체의 랜드 마크들(landmarks)을 추출함으로써 상기 대상체에 대응하는 랜드마크 히트 맵(landmark hit map)을 생성하는 단계; 및 상기 랜드마크 히트 맵을 기초로, 상기 포즈 정보를 추정하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 회전 정보는 상기 타겟 영상을 생성하기 위해 상기 입력 영상 내의 대상체를 회전시키고자 하는 회전 방향, 및 상기 대상체의 회전 정도를 지시하는 값 중 적어도 하나를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 포즈 정보는 상기 입력 영상 내 얼굴에 대응하는 랜드마크 히트 맵을 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 타겟 영상을 생성하는 단계는디코더(decoder)를 이용하여, 상기 보조 특징 벡터를 기초로 상기 특징 벡터를 디코딩함으로써 상기 타겟 영상을 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 타겟 영상을 생성하는 단계는상기 디코딩 과정에서 상기 보조 특징 벡터를 상기 특징 벡터와 합산함으로써 상기 타겟 영상을 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 입력 영상은 얼굴을 포함하고, 상기 대상 구성 요소는눈, 코, 입, 및 입꼬리 중 적어도 하나를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>13. 제1 영상 및 상기 제1 영상에 대응하는 제1 포즈 정보를 인코딩하여 제1-1 특징 벡터를 획득하는 단계;상기 제1 영상의 타겟 영상에 해당하는 제2 영상 및 상기 제2 영상에 대응하는 제2 포즈 정보를 인코딩하여 제1-2 특징 벡터를 획득하는 단계;상기 제1-1 특징 벡터와 상기 제1-2 특징 벡터 간의 차이를 기초로, 상기 제1 영상 및 상기 제2 영상에 포함된 대상체의 아이덴티티(identity)가 해당하는 대상체의 포즈와 무관하게 유지되도록 인코더를 트레이닝하는 단계;상기 인코더의 중간 레이어에서 제2 특징 벡터를 획득하는 단계;상기 제1 포즈 정보를 상기 중간 레이어에 대응하도록 변환하는 단계;상기 제2 특징 벡터, 상기 변환된 제1 포즈 정보, 및 회전 정보를 제1 신경망에 인가함으로써 상기 회전 정보에 대응하는 포즈를 갖는 제2 영상에서 대상 구성 요소가 생성될 위치를 내포하는 가중치 맵을 생성하는 단계;상기 제2 특징 벡터에서 상기 대상 구성 요소에 해당하는 대상 특징 벡터를 분리하는 단계;상기 가중치 맵과 상기 대상 특징 벡터를 결합함으로써 상기 포즈에 대응하는 상기 대상 구성 요소를 상기 대상 구성 요소가 생성될 위치에 표현하기 위한 보조 특징 벡터를 생성하는 단계;디코더를 이용하여, 상기 보조 특징 벡터를 기초로 상기 제1-1 특징 벡터를 디코딩하여 제3 영상을 생성하는 단계; 및 상기 제2 영상 및 상기 제3 영상을 기초로, 상기 제1 신경망, 상기 인코더 및 상기 디코더를 트레이닝하는 단계를 포함하는, 트레이닝 방법.</claim></claimInfo><claimInfo><claim>14. 하드웨어와 결합되어 제1항 내지 제12항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 입력 영상 및 상기 입력 영상에 대한 회전 정보를 수신하는 통신 인터페이스; 및 상기 입력 영상에 대응하는 포즈 정보를 기초로, 상기 입력 영상의 특징 벡터를 생성하고, 상기 특징 벡터, 상기 포즈 정보, 및 상기 회전 정보를 기초로, 상기 회전 정보에 대응하는 포즈에 따른 대상 구성 요소를 표현하기 위한 보조 특징 벡터를 생성하며, 상기 특징 벡터 및 상기 보조 특징 벡터에 기초하여 상기 회전 정보에 대응하는 포즈를 갖는 타겟 영상을 생성하는 프로세서를 포함하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 프로세서는상기 포즈 정보를 인코더의 중간 레이어에 대응하도록 변환하고, 상기 특징 벡터, 상기 변환된 포즈 정보, 및 상기 회전 정보를 기초로, 상기 타겟 영상에서 대상 구성 요소가 생성될 위치를 내포하는 가중치 맵을 생성하며, 상기 가중치 맵과 상기 특징 벡터에서 분리된 대상 특징 벡터를 결합함으로써 상기 포즈에 대응하는 상기 대상 구성 요소를 상기 대상 구성 요소가 생성될 위치에 표현하기 위한 상기 보조 특징 벡터를 생성하는,영상 처리 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 프로세서는상기 특징 벡터, 상기 변환된 포즈 정보, 및 상기 회전 정보를 제1 신경망에 인가함으로써 상기 타겟 영상에서 대상 구성 요소가 생성될 위치를 내포하는 가중치 맵을 생성하는,영상 처리 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 대상 구성 요소가 복수 개인 경우, 상기 프로세서는상기 특징 벡터, 상기 변환된 포즈 정보, 및 상기 회전 정보를 기초로, 상기 타겟 영상에서 상기 복수 개의 대상 구성 요소 별로 해당 대상 구성 요소가 생성될 위치를 내포하는 가중치 맵을 생성하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 프로세서는상기 특징 벡터에서 상기 대상 구성 요소에 해당하는 상기 대상 특징 벡터를 분리하고, 상기 가중치 맵과 상기 대상 특징 벡터를 결합함으로써 상기 포즈에 대응하는 상기 대상 구성 요소를 상기 대상 구성 요소가 생성될 위치에 표현하기 위한 보조 특징 벡터를 생성하는,영상 처리 장치.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 영상 처리 장치는 사용자 인증 장치, 첨단 운전자 보조 시스템(Advanced Drivers Assistance System; ADAS), HUD(Head Up Display) 장치, 3D 디지털 정보 디스플레이(Digital Information Display, DID), 내비게이션 장치, 뉴로모픽 장치(neuromorphic device), 3D 모바일 기기, 스마트 폰, 스마트 TV, 스마트 차량, IoT(Internet of Things) 디바이스, 및 의료 디바이스 중 적어도 하나를 포함하는,영상 처리 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 화성...</address><code>420190207179</code><country>대한민국</country><engName>BAEK, Ji Won</engName><name>백지원</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420190288775</code><country>대한민국</country><engName>Park, Seong-Jin</engName><name>박성진</name></inventorInfo><inventorInfo><address>서울특별시 동작구...</address><code>420170481940</code><country>대한민국</country><engName>HAN, Seung Ju</engName><name>한승주</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code>420180510946</code><country>대한민국</country><engName>KIM, In Soo</engName><name>김인수</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code>420170731631</code><country>대한민국</country><engName>Han, Jae Joon</engName><name>한재준</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.12.16</receiptDate><receiptNumber>1-1-2020-1365966-91</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.12.06</receiptDate><receiptNumber>1-1-2023-1366976-29</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200176154.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c935f270026d9590de52ec57f19223199ec0b4afba14b6cc0685a3e508e2a1b8c4e902632490c52a99c000a1ece0ad6de14b270fcdc16f59a2c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff1e118dcbf7721beba57bb07c9c54ce721beacd2ae7e7b5ae73a42b2e1dbc5b939619bccb422cdcc707ba1991d69ac5fc43b809bc50a030d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>