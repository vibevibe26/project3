<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:32.5132</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0119563</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>기하학적 비전 모델들의 비지도 사전 훈련</inventionTitle><inventionTitleEng>UNSUPERVISED PRE-TRAINING OF GEOMETRIC VISION MODELS</inventionTitleEng><openDate>2024.04.18</openDate><openNumber>10-2024-0050270</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법은, 인코더 및 디코더를 포함하는 모델의 비지도 사전 훈련을 수행하는 단계; 및 기하학적 비전 작업을 위해, 작업 특정 인코더 파라미터들의 세트로 초기화된, 모델을 미세-조정하는 단계를 포함하고, 모델의 비지도 사전 훈련을 수행하는 단계는, 상이한 조건들 하에서 또는 상이한 시점들에서 제1 이미지 및 제2 이미지를 획득하는 단계; 인코더에 의해, 제1 이미지를 제1 이미지 표현으로 인코딩하고 제2 이미지를 제2 이미지 표현으로 인코딩하는 단계; 제1 이미지 표현을 변환된 표현으로 변환하는 단계; 디코더에 의해, 변환된 표현을 재구성된 이미지로 디코딩하는 단계; 및 손실의 최소화를 기반으로 인코더 및 디코더 중 적어도 하나의 하나 이상의 파라미터들을 조절하는 단계를 포함하고, 제1 이미지 표현을 변환하는 단계 및 변환된 표현을 디코딩하는 단계는 제1 이미지 표현 및 제2 이미지 표현을 기반으로 한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 다운스트림 기하학적 비전 작업을 위한 작업 특정 기계 학습 모델을 훈련시키는 컴퓨터-구현 기계 학습 방법에 있어서, 상기 방법은,인코더 파라미터들의 세트를 갖는 인코더 및 디코더 파라미터들의 세트를 갖는 디코더를 포함하는 기계 학습 모델의 비지도(unsupervised) 사전 훈련을 수행하는 단계; 상기 사전 훈련된 기계 학습 모델을 기반으로 상기 다운스트림 기하학적 비전 작업을 위한, 작업 특정 인코더 파라미터들의 세트를 갖는 작업 특정 인코더를 포함하는 상기 작업 특정 기계 학습 모델을 구성하는 단계;상기 사전 훈련된 기계 학습 모델의 상기 인코더 파라미터들의 세트로 상기 작업 특정 인코더 파라미터들의 세트를 초기화하는 단계; 및상기 다운스트림 기하학적 비전 작업을 위해, 상기 작업 특정 인코더 파라미터들의 세트로 초기화된, 상기 작업 특정 기계 학습 모델을 미세-조정하는 단계를 포함하고,상기 기계 학습 모델의 상기 비지도 사전 훈련을 수행하는 단계는,동일한 장면을 묘사하고 상이한 조건들 하에서 또는 상이한 시점들에서 촬영되는 제1 이미지 및 제2 이미지를 포함하는 주석이 없는(unannotated) 이미지들의 쌍을 획득하는 단계; 상기 인코더에 의해, 상기 제1 이미지를 제1 이미지 표현으로 인코딩하고 상기 제2 이미지를 제2 이미지 표현으로 인코딩하는 단계;상기 제1 이미지 표현을 변환된 표현으로 변환하는 단계;상기 디코더에 의해, 상기 변환된 표현을 재구성된 이미지로 디코딩하는 단계; 및손실의 최소화를 기반으로 상기 인코더 및 상기 디코더 중 적어도 하나의 하나 이상의 파라미터들을 조절하는 단계를 포함하고,상기 제1 이미지 표현을 변환하는 단계 및 상기 변환된 표현을 디코딩하는 단계는 상기 제1 이미지 표현 및 상기 제2 이미지 표현을 기반으로 하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 기계 학습 모델의 상기 비지도 사전 훈련은 크로스-뷰 정렬(cross-view alignment) 사전 훈련이고,상기 제1 이미지 표현을 변환하는 단계는, 상기 변환된 표현을 생성하기 위해 상기 제1 이미지 표현에 변환을 적용하는 단계를 포함하고, 상기 변환은 상기 변환된 표현이 상기 제2 이미지 표현에 근사하도록, 상기 제1 이미지 표현 및 상기 제2 이미지 표현을 기반으로 결정되는,방법.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 기계 학습 모델의 상기 비지도 사전 훈련은 크로스-뷰 정렬 사전 훈련이고, 상기 손실은 상기 재구성된 이미지와 상기 제2 이미지 사이의 차이를 정량화하는 메트릭(metric)을 기반으로 하는,방법.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,상기 기계 학습 모델의 상기 비지도 사전 훈련은 크로스-뷰 정렬 사전 훈련이고,상기 손실은 상기 변환된 표현과 상기 제2 이미지 표현 사이의 차이를 정량화하는 메트릭을 기반으로 하는,방법.</claim></claimInfo><claimInfo><claim>5. 제2 항에 있어서,상기 제1 이미지 표현은 제1 n 개의 벡터들 세트(, 각 )이고, 상기 제2 이미지 표현은 제2 n 개의 벡터들 세트(, 각 ) 이고,상기 변환을 적용하는 단계는,D-차원 등변 부분과 (K - D)-차원 불변 부분에서 상기 제1 벡터들 세트 및 상기 제2 벡터들 세트의 각 벡터를 분해하는 단계; 및(D x D)-차원 변환 행렬(Ω)을 상기 제1 벡터들 세트의 각 벡터의 상기 등변 부분에 적용하는 단계를 포함하고, 0 003c# D ≤ K인,방법.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 변환은 D-차원 회전이고, 상기 변환 행렬(Ω)은 D-차원 회전 행렬이고, 상기 변환 행렬(Ω)은 상기 제1 벡터들 세트의 벡터들의 등변 부분들을 상기 제2 벡터들 세트의 각각의 벡터들의 등변 부분들과 정렬하는 것을 기반으로 설정되는,방법.</claim></claimInfo><claimInfo><claim>7. 제5 항에 있어서, 하기 수학식에 기반하여 상기 변환 행렬(Ω)을 결정하는 단계를 더 포함하고,여기서, 는 벡터()의 등변 부분을 나타내고, 는 벡터()의 등변 부분을 나타내며, SO(D)는 D-차원 회전 그룹을 나타내는,방법.</claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서,상기 비지도 사전 훈련은 크로스-뷰 완성(cross-view completion) 사전 훈련이고,상기 기계 학습 모델의 상기 크로스-뷰 완성 사전 훈련을 수행하는 단계는,제1 이미지를 제1 비중첩 패치들 세트로 분할하고 상기 제2 이미지를 제2 비중첩 패치들 세트로 분할하는 단계; 및상기 제1 패치들 세트의 패치들 중 하나를 마스킹하는 단계를 더 포함하고, 상기 제1 이미지를 상기 제1 이미지 표현으로 인코딩하는 단계는,상기 인코더에 의해, 상기 제1 패치들 세트의 각 마스킹되지 않은 패치를 대응하는 각각의 마스킹되지 않은 패치 표현으로 인코딩하여, 제1 패치 표현들 세트를 생성하는 단계를 포함하고, 상기 제2 이미지를 상기 제2 이미지 표현으로 인코딩하는 단계는,상기 인코더에 의해, 상기 제2 패치들 세트의 각 패치를 대응하는 각각의 패치 표현으로 인코딩하여, 제2 패치 표현들 세트를 생성하는 단계를 포함하고, 상기 변환된 표현을 디코딩하는 단계는, 상기 디코더에 의해, 상기 제1 패치들 세트의 각 마스킹된 패치에 대해, 상기 변환된 표현 및 상기 제2 패치 표현들 세트를 기반으로 각각의 마스킹된 패치에 대한 예측된 재구성을 생성하는 단계를 포함하고, 손실 함수는 각 마스킹된 패치와 각각의 예측된 재구성 사이의 차이를 정량화하는 메트릭을 기반으로 하는,방법. </claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서, 상기 제1 이미지 표현을 상기 변환된 표현으로 변환하는 단계는,상기 제1 패치들 세트의 각 마스킹된 패치에 대해, 상기 제1 패치 표현들 세트를 상기 마스킹된 패치의 각각의 학습된 표현으로 패딩하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,각 학습된 표현은 표현 파라미터들의 세트를 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 제9 항에 있어서,상기 제1 패치들 세트의 마스킹된 패치의 예측된 재구성을 생성하는 단계는,상기 디코더에 의해, 상기 마스킹된 패치의 상기 학습된 표현을 상기 마스킹된 패치의 상기 예측된 재구성으로 디코딩하는 단계를 포함하고,여기서, 상기 디코더는 상기 제1 패치 표현들 세트 및 상기 제2 패치 표현들 세트를 입력 데이터로서 수신하고, 상기 입력 데이터를 기반으로 상기 마스킹된 패치의 상기 학습된 표현을 디코딩하고, 상기 방법은,각각의 표현 파라미터들의 세트를 조절함으로써 마스킹된 패치들의 학습된 표현들을 조절하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 각각의 표현 파라미터들의 세트를 조절하는 것은 상기 손실의 최소화를 기반으로 상기 표현 파라미터들의 세트를 조절하는 것을 포함하는,방법. </claim></claimInfo><claimInfo><claim>13. 제1 항에 있어서,상기 작업 특정 기계 학습 모델을 미세-조정하는 단계는,상기 작업 특정 기계 학습 모델의 지도(supervised) 미세-조정을 수행하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서, 상기 지도 미세-조정은,i) 상기 다운스트림 기하학적 비전 작업에 따라 출력 데이터를 생성하기 위해, 상기 다운스트림 기하학적 비전 작업에 대한 실측 데이터로 주석이 달려 있는 하나 이상의 주석이 달린(annotated) 이미지들에 상기 작업 특정 기계 학습 모델을 적용하는 것; 및ii) 상기 생성된 출력 데이터와 실측 데이터(ground truth data) 사이의 차이를 정량화하는 메트릭을 기반으로 하는 작업 특정 손실의 최소화를 기반으로 상기 작업 특정 기계 학습 모델의 작업 특정 인코더 파라미터들의 세트를 조절함으로써 상기 작업 특정 기계 학습 모델을 조절하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,미리 결정된 횟수 동안 또는 상기 작업 특정 손실의 최소 값에 도달할 때까지 i) 및 ii)를 반복하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>16. 제14 항에 있어서,상기 다운스트림 기하학적 비전 작업을 위해 하나 이상의 새로운 이미지들로부터 예측 데이터를 추출하기 위해, 상기 하나 이상의 새로운 이미지들에 상기 미세-조정된 작업 특정 기계 학습 모델을 적용하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>17. 제16 항에 있어서,상기 다운스트림 기하학적 비전 작업은 상대적 자세 추정인,방법.</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서,상기 미세-조정된 작업 특정 기계 학습 모델을 적용하는 단계는,새로운 이미지들 쌍의 이미지들 사이의 상대적 회전 및 상대적 변형을 상기 예측 데이터로서 추출하기 위해, 상기 새로운 이미지들 쌍에 상기 미세-조정된 작업 특정 기계 학습 모델을 적용하는 단계를 포함하고,상기 새로운 이미지들 쌍의 상기 이미지들은 동일한 장면의 두 개의 뷰들을 묘사하는,방법.</claim></claimInfo><claimInfo><claim>19. 제16 항에 있어서,상기 다운스트림 기하학적 비전 작업은 깊이 추정인,방법.</claim></claimInfo><claimInfo><claim>20. 제19 항에 있어서, 상기 미세-조정된 작업 특정 기계 학습 모델을 적용하는 단계는,하나 이상의 새로운 이미지들로부터의 하나 이상의 깊이 맵들을 상기 예측 데이터로서 추출하기 위해, 상기 하나 이상의 새로운 이미지들에 상기 미세-조정된 작업 특정 기계 학습 모델을 적용하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>21. 제16 항에 있어서,상기 다운스트림 기하학적 비전 작업은 광학 흐름 추정인,방법.</claim></claimInfo><claimInfo><claim>22. 제21 항에 있어서,상기 미세-조정된 작업 특정 기계 학습 모델을 적용하는 단계는,복수의 픽셀 쌍들을 상기 예측 데이터로서 생성하기 위해, 새로운 제1 이미지 및 새로운 제2 이미지를 포함하는 새로운 이미지 쌍에 상기 미세-조정된 작업 특정 기계 학습 모델을 적용하는 단계를 포함하고, 각 픽셀 쌍은 상기 새로운 제1 이미지의 픽셀과 상기 새로운 제2 이미지의 대응하는 픽셀을 포함하고,상기 새로운 제1 이미지와 상기 새로운 제2 이미지는 상이한 조건들 하에서 또는 상이한 시점들에서 동일한 장면을 묘사하는,방법. </claim></claimInfo><claimInfo><claim>23. 다운스트림 기하학적 비전 작업에 따라 예측 데이터를 생성하기 위한 컴퓨터-구현 기계 학습 방법에 있어서, 상기 방법은,제1 기계 학습 모델의 크로스-뷰 정렬 사전 훈련을 사용하여 상기 다운스트림 기하학적 비전 작업에 대해 제1 작업 특정 기계 학습 모델을 훈련시키는 단계;제2 프리텍스트 기계 학습 모델의 크로스-뷰 완성 사전 훈련을 사용하여 상기 다운스트림 기하학적 비전 작업에 대해 제2 작업 특정 기계 학습 모델을 훈련시키는 단계; 적어도 하나의 이미지에 상기 훈련된 제1 작업 특정 기계 학습 모델을 적용함으로써, 상기 다운스트림 기하학적 비전 작업에 따라 제1 예측 데이터를 생성하는 단계; 상기 적어도 하나의 이미지에 상기 훈련된 제2 작업 특정 기계 학습 모델을 적용함으로써, 상기 다운스트림 기하학적 비전 작업에 따라 제2 예측 데이터를 생성하는 단계;상기 제1 예측 데이터에 대한 제1 신뢰 값 및 상기 제2 예측 데이터에 대한 제2 신뢰 값을 결정하는 단계; 및상기 제1 신뢰 값 및 상기 제2 신뢰 값을 기반으로 상기 제1 예측 데이터와 상기 제2 예측 데이터를 함께 융합함으로써, 상기 기하학적 비전 작업에 따라 결과적인 예측 데이터를 생성하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>24. 컴퓨팅 시스템에 있어서,하나 이상의 프로세서들; 및 상기 하나 이상의 프로세서들에 의해 실행될 때, 다음을 수행하는 코드를 포함하는 메모리를 포함하고, 상기 코드는,인코더 파라미터들의 세트를 갖는 인코더 및 디코더 파라미터들의 세트를 갖는 디코더를 포함하는 기계 학습 모델의 비지도 사전 훈련을 수행하고;상기 사전 훈련된 기계 학습 모델을 기반으로 상기 다운스트림 기하학적 비전 작업을 위한, 작업 특정 인코더 파라미터들을 갖는 작업 특정 인코더를 포함하는 상기 작업 특정 기계 학습 모델을 구성하고;상기 사전 훈련된 기계 학습 모델의 상기 인코더 파라미터들의 세트로 상기 작업 특정 인코더 파라미터들의 세트를 초기화하며;상기 다운스트림 기하학적 비전 작업을 위해, 상기 작업 특정 인코더 파라미터들의 세트로 초기화된, 상기 작업 특정 기계 학습 모델을 미세-조정하고,상기 기계 학습 모델의 상기 비지도 사전 훈련의 수행은,동일한 장면을 묘사하고 상이한 조건들 하에서 또는 상이한 시점들에서 촬영되는 제1 이미지 및 제2 이미지를 포함하는 주석이 없는 이미지들의 쌍을 획득하는 것;상기 인코더에 의해 상기 제1 이미지를 제1 이미지 표현으로 인코딩하고 상기 제2 이미지를 제2 이미지 표현으로 인코딩하는 것; 상기 제1 이미지 표현을 변환된 표현으로 변환하는 것; 상기 디코더에 의해, 상기 변환된 표현을 재구성된 이미지로 디코딩하는 것; 및 손실의 최소화를 기반으로 상기 인코더 및 상기 디코더 중 적어도 하나의 하나 이상의 파라미터들을 조절하는 것을 포함하고, 상기 제1 이미지 표현을 변환하는 것 및 상기 변환된 표현을 디코딩하는 것은 상기 제1 이미지 표현 및 상기 제2 이미지 표현을 기반으로 하는,컴퓨팅 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>119990373888</code><country>대한민국</country><engName>NAVER Corporation</engName><name>네이버 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>프랑스 지에르 ***** *...</address><code> </code><country> </country><engName>BREGIER, Romain</engName><name>브레지에르, 로메인</name></inventorInfo><inventorInfo><address>프랑스 메일랑 **...</address><code> </code><country> </country><engName>CABON, Yohann</engName><name>카본, 요한</name></inventorInfo><inventorInfo><address>프랑스 메일랑 **...</address><code> </code><country> </country><engName>LUCAS, Thomas</engName><name>루카스, 토마스</name></inventorInfo><inventorInfo><address>프랑스 메일랑 **...</address><code> </code><country> </country><engName>REVAUD, Jerome</engName><name>레바우드, 제롬</name></inventorInfo><inventorInfo><address>프랑스 메일랑 **...</address><code> </code><country> </country><engName>WEINZAEPFEL, Philippe</engName><name>웨인즈에펠, 필립</name></inventorInfo><inventorInfo><address>프랑스 메일랑 *****...</address><code> </code><country> </country><engName>CHIDLOVSKII, Boris</engName><name>키드로브스키, 보리스</name></inventorInfo><inventorInfo><address>프랑스 메일랑 **...</address><code> </code><country> </country><engName>LEROY, Vincent</engName><name>레로이, 빈센트</name></inventorInfo><inventorInfo><address>프랑스 세인트 이스미에르...</address><code> </code><country> </country><engName>ANTSFELD, Leonid</engName><name>안츠펠드, 레오니드</name></inventorInfo><inventorInfo><address>프랑스 메일랑 **...</address><code> </code><country> </country><engName>CSURKA KHEDARI, Gabriela</engName><name>시수카 케다리, 가브리엘라</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로***길 ** (논현동) 삼성빌딩 *층(피앤티특허법률사무소)</address><code>920050004530</code><country>대한민국</country><engName>Yang,Sung Bo</engName><name>양성보</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2022.10.11</priorityApplicationDate><priorityApplicationNumber>22306534.3</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.08.04</priorityApplicationDate><priorityApplicationNumber>18/230,414</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.09.08</receiptDate><receiptNumber>1-1-2023-0994897-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(EPO)</documentEngName><documentName>우선권주장증명서류제출서(EPO)</documentName><receiptDate>2023.09.18</receiptDate><receiptNumber>9-1-2023-9010323-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.09.19</receiptDate><receiptNumber>9-1-2023-9010332-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Change of Applicant] Report on Change of Proprietary Status</documentEngName><documentName>[출원인변경]권리관계변경신고서</documentName><receiptDate>2024.07.12</receiptDate><receiptNumber>1-1-2024-0760996-85</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230119563.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9371b02c7f1ae773109d40bb9d38a93e5fdaa5a2c44e4f31198ecdee726e8275d9dc940b0ad9b1baa81c03c5228d4fb68ddba50dfd3d17a812</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf65ac49f31857d0163c6b7d642e093265fc3b6d4126422e902a7f47c6e4c7f5a0b29b5c44d0f448768e0969c1a5827fe0a9c21e59d25c5a95</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>