<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:47.4147</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.08.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0117069</applicationNumber><claimCount>35</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>음성 인식 방법, 딥러닝 모델의 트레이닝 방법, 장치 및 기기</inventionTitle><inventionTitleEng>SPEECH RECOGNITION METHOD, METHOD FOR TRAINING DEEP LEARNING  MODEL, APPARATUS AND DEVICE</inventionTitleEng><openDate>2024.09.20</openDate><openNumber>10-2024-0137507</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>G10L 19/008</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 인공지능 기술분야에 관한 것으로, 특히 음성 인식 및 딥러닝 등 기술분야에 관한 음성 인식 방법, 딥러닝 모델의 트레이닝 방법, 장치 및 기기를 제공한다. 상기 음성 인식 방법은 인식할 음성의 제1 음성 특징을 획득하되, 제1 음성 특징은 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 단계; 제1 디코더를 이용하여 제1 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하되, 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계; 제1 선험적 정보에 기반하여, 제1 음성 특징으로부터 제2 음성 특징을 추출하되, 제1 선험적 정보는 복수의 제1 디코딩 결과를 포함하고, 제2 음성 특징은 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단계; 및 제2 디코더를 이용하여 제2 음성 특징을 디코딩하여 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하되, 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 음성 인식 방법으로서,인식할 음성의 제1 음성 특징을 획득하되, 상기 제1 음성 특징은 상기 인식할 음성 중의 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 단계;제1 디코더를 이용하여 상기 제1 음성 특징을 디코딩하여 상기 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하되, 상기 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계;제1 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하되, 상기 제1 선험적 정보는 상기 복수의 제1 디코딩 결과를 포함하고, 상기 제2 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단계; 및제2 디코더를 이용하여 상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하되, 상기 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,제1 선험적 정보에 기반하여 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계는,상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 주의력 모듈의 조회 특징으로 사용하고, 상기 제1 음성 특징을 상기 주의력 모듈의 키 특징 및 값 특징으로 사용하여, 상기 주의력 모듈에 의해 출력되는 상기 단어에 대응되는 제1 단어 레벨 오디오 특징을 획득하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,제1 선험적 정보에 기반하여 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하는 단계는,제2 인코더를 이용하여 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩을 수행하여 강화된 제2 음성 특징을 획득하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,제2 디코더를 이용하여 상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하는 단계는,상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함하고, 상기 순방향 디코더 및 상기 역방향 디코더는 모두 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징으로 사용하고, 상기 제2 음성 특징을 입력된 키 특징 및 값 특징으로 사용하도록 구성되며, 상기 순방향 디코더는 입력된 특징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성되고, 상기 역방향 디코더는 입력된 특징을 오른쪽에서 왼쪽으로 시간적으로 마스킹하도록 구성되는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제2 디코딩 결과를 획득하는 단계는,상기 순방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 순방향 디코딩 특징 및 상기 역방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 상기 복수의 단어에 대응되는 복수의 융합 특징을 획득하는 단계; 및상기 복수의 융합 특징에 기반하여, 상기 복수의 제2 디코딩 결과를 획득하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제N 디코딩 결과를 상기 제2 디코더의 조회 특징으로 사용하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로 사용하여, 상기 제2 디코더에 의해 출력되는 상기 단어에 대응되는 제N+1 디코딩 결과를 획득하되, N은 2보다 크거나 같은 정수인 단계를 더 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제3항 중 어느 한 항에 있어서,제2 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제3 음성 특징을 추출하되, 상기 제2 선험적 정보는 상기 복수의 제2 디코딩 결과를 포함하고, 상기 제3 음성 특징은 상기 복수의 단어에 대응되는 복수의 제2 단어 레벨 오디오 특징을 포함하는 단계; 및상기 제2 디코더를 이용하여 상기 제3 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제3 디코딩 결과를 획득하되, 상기 제3 디코딩 결과는 대응하는 단어의 제3 인식 결과를 지시하는 단계를 더 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제3항 중 어느 한 항에 있어서,인식할 음성의 제1 음성 특징을 획득하는 단계는,상기 인식할 음성의 원래 음성 특징을 획득하는 단계;상기 원래 음성 특징에 기반하여 상기 인식할 음성 중의 복수의 스파이크를 결정하는 단계; 및상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 복수의 음성 세그먼트 특징은 상기 원래 음성 특징에 대한 스트리밍 절단에 의해 순차적으로 획득된 것이고, 제1 디코더를 이용하여 상기 제1 음성 특징을 디코딩하는 단계는,상기 제1 디코더를 이용하여 상기 복수의 음성 세그먼트 특징에 대해 순차적으로 스트리밍 디코딩을 수행하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,인식할 음성의 제1 음성 특징을 획득하는 단계는,현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하되, 상기 이력 특징 추상 정보는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 상기 이전 음성 세그먼트 특징에 대해 주의력 모델링을 수행함으로써 획득된 것인 단계; 및제1 인코더를 이용하고 상기 이력 특징 추상 정보를 결합하여 상기 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,제1 인코더를 이용하고 상기 이력 특징 추상 정보를 결합하여 상기 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계는,상기 현재 획득된 음성 세그먼트 특징을 상기 제1 인코더의 조회 특징으로 사용하고, 상기 이력 특징 추상 정보와 상기 현재 획득된 음성 세그먼트 특징의 스플라이싱 결과를 상기 제1 인코더의 키 특징 및 값 특징으로 사용하여, 상기 제1 인코더에 의해 출력되는 상기 대응하는 강화된 음성 세그먼트 특징을 획득하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>13. 제9항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는,기설정된 시간 길이를 기반으로 상기 원래 음성 특징을 절단하고, 상기 복수의 스파이크 중 각 스파이크가 위치하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>14. 제9항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는,상기 복수의 스파이크를 기반으로 상기 원래 음성 특징을 절단하고, 인접한 2개의 스파이크 사이마다의 음성 세그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 제2 디코더는 음성 빅모델인 음성 인식 방법.</claim></claimInfo><claimInfo><claim>16. 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법으로서,상기 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 상기 트레이닝 방법은,샘플 음성 및 상기 샘플 음성 중의 복수의 단어의 실제 인식 결과를 획득하는 단계;상기 샘플 음성의 제1 샘플 음성 특징을 획득하되, 상기 제1 샘플 음성 특징은 상기 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하는 단계;제1 디코더를 이용하여 상기 제1 샘플 음성 특징을 디코딩하여 상기 샘플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩 결과를 획득하되, 상기 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 단계;제1 샘플 선험적 정보에 기반하여 상기 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하되, 상기 제1 샘플 선험적 정보는 상기 복수의 제1 샘플 디코딩 결과를 포함하고, 상기 제2 샘플 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단계;제2 디코더를 이용하여 상기 제2 샘플 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 샘플 디코딩 결과를 획득하되, 상기 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 단계; 및상기 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 상기 딥러닝 모델의 파라미터를 조정하여 트레이닝된 딥러닝 모델을 획득하는 단계를 포함하는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>17. 음성 인식 장치로서,인식할 음성의 제1 음성 특징을 획득하도록 구성되되, 상기 제1 음성 특징은 상기 인식할 음성 중의 복수의 음성 세그먼트에 대응되는 복수의 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈;상기 제1 음성 특징을 디코딩하여 상기 인식할 음성 중의 복수의 단어에 대응되는 복수의 제1 디코딩 결과를 획득하도록 구성되되, 상기 제1 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더;제1 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제2 음성 특징을 추출하도록 구성되되, 상기 제1 선험적 정보는 상기 복수의 제1 디코딩 결과를 포함하고, 상기 제2 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모듈; 및상기 제2 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 디코딩 결과를 획득하도록 구성되되, 상기 제2 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더를 포함하는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 단어 레벨 특징 추출 모듈은 주의력 모듈을 포함하고,상기 주의력 모듈은 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 주의력 모듈의 조회 특징으로서 수신하고, 상기 제1 음성 특징을 상기 주의력 모듈의 키 특징 및 값 특징으로서 수신하여, 상기 단어에 대응되는 제1 단어 레벨 오디오 특징으로 출력하도록 구성되는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 단어 레벨 특징 추출 모듈은,상기 복수의 단어에 대응되는 복수의 제1 단어 레벨 오디오 특징에 대해 전역적 인코딩을 수행하여, 강화된 제2 음성 특징을 획득하도록 구성되는 제2 인코더를 포함하는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>20. 제17항 내지 제19항 중 어느 한 항에 있어서,상기 제2 디코더는 상기 복수의 단어 중 각 단어에 대해, 상기 단어에 대응되는 제1 디코딩 결과를 상기 제2 디코더의 조회 특징으로서 수신하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로서 수신하여, 상기 단어에 대응되는 제2 디코딩 결과를 출력하도록 구성되는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서,상기 제2 디코더는 순방향 디코더 및 역방향 디코더를 포함하고, 상기 순방향 디코더 및 상기 역방향 디코더는 모두 상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제1 디코딩 결과를 입력된 조회 특징으로서 수신하고, 상기 제2 음성 특징을 입력된 키 특징 및 값 특징으로서 수신하도록 구성되며, 상기 순방향 디코더는 입력된 특징을 왼쪽에서 오른쪽으로 시간적으로 마스킹하도록 구성되고, 상기 역방향 디코더는 입력된 특징을 오른쪽에서 왼쪽으로 시간적으로 마스킹하도록 구성되는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,상기 제2 디코더는,상기 순방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 순방향 디코딩 특징 및 상기 역방향 디코더에 의해 출력되는 상기 복수의 단어에 대응되는 복수의 역방향 디코딩 특징을 융합하여 상기 복수의 단어에 대응되는 복수의 융합 특징을 획득하고;상기 복수의 융합 특징에 기반하여, 상기 복수의 제2 디코딩 결과를 획득하도록 구성되는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>23. 제20항에 있어서,상기 제2 디코더는,상기 복수의 단어 중 각 단어에 대해, 상기 단어의 제N 디코딩 결과를 상기 제2 디코더의 조회 특징으로서 수신하고, 상기 제2 음성 특징을 상기 제2 디코더의 키 특징 및 값 특징으로서 수신하여, 상기 단어에 대응되는 제N+1 디코딩 결과를 출력하도록 구성되되, N은 2보다 크거나 같은 정수인 음성 인식 장치.</claim></claimInfo><claimInfo><claim>24. 제17항 내지 제19항 중 어느 한 항에 있어서,상기 단어 레벨 특징 추출 모듈은 제2 선험적 정보에 기반하여, 상기 제1 음성 특징으로부터 제3 음성 특징을 추출하도록 구성되되, 상기 제2 선험적 정보는 상기 복수의 제2 디코딩 결과를 포함하고, 상기 제3 음성 특징은 상기 복수의 단어에 대응되는 복수의 제2 단어 레벨 오디오 특징을 포함하며,상기 제2 디코더는 상기 제3 음성 특징을 디코딩하여, 상기 복수의 단어에 대응되는 복수의 제3 디코딩 결과를 획득하도록 구성되되, 상기 제3 디코딩 결과는 대응하는 단어의 제3 인식 결과를 지시하는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>25. 제17항 내지 제19항 중 어느 한 항에 있어서,상기 음성 특징 인코딩 모듈은,상기 인식할 음성의 원래 음성 특징을 획득하고; 상기 원래 음성 특징에 기반하여 상기 인식할 음성 중의 복수의 스파이크를 결정하며;상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하도록 구성되는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서,상기 복수의 음성 세그먼트 특징은 상기 원래 음성 특징에 대한 스트리밍 절단에 의해 순차적으로 획득된 것이고, 상기 제1 디코더는 상기 복수의 음성 세그먼트 특징에 대해 순차적으로 스트리밍 디코딩을 수행하도록 구성되는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서,상기 음성 특징 인코딩 모듈은,현재 획득된 음성 세그먼트 특징에 대해, 대응하는 이력 특징 추상 정보를 획득하도록 구성되되, 상기 이력 특징 추상 정보는 이전 음성 세그먼트 특징에 대응되는 제1 디코딩 결과를 이용하여 상기 이전 음성 세그먼트 특징에 대해 주의력 모델링을 수행함으로써 획득된 것이고;상기 음성 특징 인코딩 모듈은,상기 이력 특징 추상 정보를 결합하여 현재 획득된 음성 세그먼트 특징을 인코딩하여 대응하는 강화된 음성 세그먼트 특징을 출력하도록 구성되는 제1 인코더를 포함하는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서,상기 제1 인코더는 상기 현재 획득된 음성 세그먼트 특징을 상기 제1 인코더의 조회 특징으로서 수신하고, 상기 이력 특징 추상 정보와 상기 현재 획득된 음성 세그먼트 특징의 스플라이싱 결과를 상기 제1 인코더의 키 특징 및 값 특징으로서 수신하여 상기 대응하는 강화된 음성 세그먼트 특징을 출력하도록 구성되는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>29. 제25항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는,기설정된 시간 길이를 기반으로 상기 원래 음성 특징을 절단하고, 상기 복수의 스파이크 중 각 스파이크가 위치하는 음성 세그먼트의 음성 세그먼트 특징을 상기 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>30. 제25항에 있어서,상기 원래 음성 특징을 절단하여 상기 복수의 스파이크에 일대일로 대응되는 상기 복수의 음성 세그먼트 특징을 획득하는 단계는,상기 복수의 스파이크를 기반으로 상기 원래 음성 특징을 절단하고, 인접한 2개의 스파이크 사이마다의 음성 세그먼트의 특징을 하나의 스파이크에 대응되는 음성 세그먼트 특징으로 사용하는 단계를 포함하는 음성 인식 장치.</claim></claimInfo><claimInfo><claim>31. 제17항 내지 제19항 중 어느 한 항에 있어서,상기 제2 디코더는 음성 빅모델인 음성 인식 장치.</claim></claimInfo><claimInfo><claim>32. 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치로서,상기 딥러닝 모델은 제1 디코더 및 제2 디코더를 포함하고, 상기 트레이닝 장치는,샘플 음성 및 상기 샘플 음성 중의 복수의 단어의 실제 인식 결과를 획득하도록 구성되는 획득 모듈; 상기 샘플 음성의 제1 샘플 음성 특징을 획득하도록 구성되되, 상기 제1 샘플 음성 특징은 상기 샘플 음성 중의 복수의 샘플 음성 세그먼트에 대응되는 복수의 샘플 음성 세그먼트 특징을 포함하는 음성 특징 인코딩 모듈; 상기 제1 샘플 음성 특징을 디코딩하여 상기 샘플 음성 중의 복수의 단어에 대응되는 복수의 제1 샘플 디코딩 결과를 획득하도록 구성되되, 상기 제1 샘플 디코딩 결과는 대응하는 단어의 제1 인식 결과를 지시하는 제1 디코더; 제1 샘플 선험적 정보에 기반하여 상기 제1 샘플 음성 특징으로부터 제2 샘플 음성 특징을 추출하도록 구성되되, 상기 제1 샘플 선험적 정보는 상기 복수의 제1 샘플 디코딩 결과를 포함하고, 상기 제2 샘플 음성 특징은 상기 복수의 단어에 대응되는 복수의 제1 샘플 단어 레벨 오디오 특징을 포함하는 단어 레벨 특징 추출 모듈; 상기 제2 샘플 음성 특징을 디코딩하여 상기 복수의 단어에 대응되는 복수의 제2 샘플 디코딩 결과를 획득하도록 구성되되, 상기 제2 샘플 디코딩 결과는 대응하는 단어의 제2 인식 결과를 지시하는 제2 디코더; 및상기 복수의 단어의 실제 인식 결과, 제1 인식 결과 및 제2 인식 결과에 기반하여 상기 딥러닝 모델의 파라미터를 조정하여 트레이닝된 딥러닝 모델을 획득하도록 구성되는 파라미터 조정 모듈을 포함하는 음성 인식에 사용되는 딥러닝 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>33. 전자 기기로서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서와 통신 연결되는 메모리를 포함하되;상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되고, 상기 명령은 상기 적어도 하나의 프로세서에 의해 실행되어 상기 적어도 하나의 프로세서가 제1항 내지 제16항 중 어느 한 항에 따른 방법을 수행할 수 있도록 하는 전자 기기.</claim></claimInfo><claimInfo><claim>34. 컴퓨터 명령이 저장된 비일시적 컴퓨터 판독 가능 저장 매체로서,상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제16항 중 어느 한 항에 따른 방법을 수행하도록 하기 위한 것인 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>35. 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은 명령을 포함하고, 상기 명령이 적어도 하나의 프로세서에 의해 실행될 경우 제1항 내지 제16항 중 어느 한 항에 따른 방법을 구현하는 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 베이징 하이디안 디...</address><code> </code><country> </country><engName>FU, Xiaoyin</engName><name>푸 샤오인</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이디안 디...</address><code> </code><country> </country><engName>ZANG, Qiguang</engName><name>장 치광</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이디안 디...</address><code> </code><country> </country><engName>SHENG, Fenfen</engName><name>성 펀펀</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이디안 디...</address><code> </code><country> </country><engName>WANG, Haifeng</engName><name>왕 하이펑</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이디안 디...</address><code> </code><country> </country><engName>JIA, Lei</engName><name>자 레이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920030004930</code><country>대한민국</country><engName>Lim KyuBin</engName><name>임규빈</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2023.08.29</priorityApplicationDate><priorityApplicationNumber>202311104070.7</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.08.29</receiptDate><receiptNumber>1-1-2024-0950266-20</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.09.26</receiptDate><receiptNumber>9-1-2024-9010377-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.09.27</receiptDate><receiptNumber>9-1-2024-9010492-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.10.11</receiptDate><receiptNumber>9-1-2024-9011126-20</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240117069.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93cfee614daddf932494916502aa5430955fec962eac42cb21df8af5ce65f65a70fbf4d089f4e9c8026c9560b368560844bd11fe550c4a4177</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4cefca99ddc9543e1a76b5b06009e7cfc9991c24f93009e85d9582a250ea8fcd209372913904bda5e248773822e1638e8297592155c1eef1</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>