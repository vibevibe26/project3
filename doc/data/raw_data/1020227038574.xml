<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:55:54.5554</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.09.24</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7038574</applicationNumber><claimCount>11</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오 코딩에서 심층 신경 네트워크 기반 인터프레임 예측을 위한 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR DEEP NEURAL NETWORK BASED INTER-FRAME PREDICTION IN VIDEO CODING</inventionTitleEng><openDate>2022.12.08</openDate><openNumber>10-2022-0162786</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.11.03</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.11.03</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/159</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/105</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/172</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/182</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/577</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 신경 네트워크 기반 인터프레임 예측을 사용하는 비디오 코딩은 2개의 입력 프레임에 기초하여 중간 흐름들을 발생시키고, 재구성 프레임들을 발생시키기 위해 입력 프레임들의 역방향 워핑을 수행하고, 입력 프레임들, 중간 흐름들 및 재구성 프레임들에 기초하여 융합 맵 및 잔차 맵을 발생시킴으로써 현재 참조 프레임을 발생시킴으로써 수행된다. 비디오 코딩 방법은 현재 참조 프레임, 제1 참조 프레임 및 제2 참조 프레임에 기초하여, 상이한 레벨들을 갖는 특징 맵을 발생시키고, 현재 참조 프레임, 제1 참조 프레임, 및 제2 참조 프레임을 정제함으로써 발생된 특징 맵으로부터의 정렬된 특징들에 기초하여 예측된 프레임을 발생시키고, 예측된 프레임에 기초하여 최종 잔차를 발생시키고, 최종 잔차를 현재 참조 프레임에 가산함으로써 향상된 프레임을 출력으로서 계산함으로써 향상된 프레임 또는 가상 참조 픽처를 출력하는 단계를 추가로 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.07.07</internationOpenDate><internationOpenNumber>WO2022146509</internationOpenNumber><internationalApplicationDate>2021.09.24</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/051961</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 신경 네트워크 기반 인터프레임 예측을 사용하는 비디오 코딩의 방법으로서, 상기 방법은 적어도 하나의 프로세서에 의해 수행되고,입력 프레임들에 기초하여 중간 흐름들을 발생시키는 단계;상기 중간 흐름들로 상기 입력 프레임들의 역방향 워핑을 수행함으로써 재구성 프레임들을 발생시키는 단계;상기 입력 프레임들, 상기 중간 흐름들, 및 상기 재구성 프레임들에 기초하여, 융합 맵 및 잔차 맵을 발생시키는 단계;현재 참조 프레임, 제1 참조 프레임, 및 제2 참조 프레임에 기초하여, 제1 신경 네트워크를 사용하여 복수의 레벨을 갖는 특징 맵을 발생시키는 단계;상기 현재 참조 프레임, 상기 제1 참조 프레임, 및 상기 제2 참조 프레임을 정제함으로써 상기 발생된 특징 맵으로부터의 정렬된 특징들에 기초하여 예측된 프레임을 발생시키는 단계;상기 예측된 프레임에 기초하여 최종 잔차를 발생시키는 단계; 및상기 최종 잔차를 상기 현재 참조 프레임에 가산함으로써 향상된 프레임을 출력으로서 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 중간 흐름들은 반복적으로 업데이트되고 대응하는 픽셀들은 2개의 입력 프레임으로부터 잠재적 중간 프레임 내의 동일한 위치로 이동되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 융합 맵에 따라 상기 재구성 프레임들을 선형 조합하고 상기 조합된 재구성 프레임들을 상기 잔차 맵과 가산함으로써 상기 현재 참조 프레임을 발생시키는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 제1 참조 프레임은 출력 순서로 상기 현재 참조 프레임에 선행하는 참조 프레임이고 상기 제2 참조 프레임은 상기 출력 순서로 상기 현재 참조 프레임에 뒤따르는 참조 프레임인, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 특징 맵에서 특징들의 가중치를 결정하는 단계를 추가로 포함하며, 상기 가중치는 후속 최종 잔차들의 발생을 위한 특징들의 서브세트를 강조하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 복수의 레벨에 대한 오프셋을 계산하는 단계;상기 복수의 레벨에 대한 보상 특징들을 발생시키기 위해 변형가능 콘벌루션을 수행하는 단계; 및상기 오프셋 및 상기 발생된 보상 특징들 중 적어도 하나에 기초하여 상기 정렬된 특징들을 발생시키는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,융합된 주의 맵들을 획득하기 위해 콘벌루션을 수행하는 단계;상기 주의 맵들 및 상기 정렬된 특징들에 기초하여 주의 특징들을 발생시키는 단계;제2 신경 네트워크를 사용하여, 상기 주의 맵들 및 상기 주의 특징들에 기초하여, 정렬된 프레임을 발생시키는 단계; 및상기 예측된 프레임을 획득하기 위해 상기 정렬된 프레임을 합성하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 신경 네트워크 기반 인터프레임 예측을 사용하는 비디오 코딩을 위한 장치로서,프로그램 코드를 저장하도록 구성된 적어도 하나의 메모리; 및상기 프로그램 코드를 판독하고 상기 프로그램 코드에 의해 명령되는 바와 같이 동작하도록 구성된 적어도 하나의 프로세서를 포함하며,상기 프로그램 코드는,상기 적어도 하나의 프로세서로 하여금 입력 프레임들에 기초하여 중간 흐름들을 발생시키게 하도록 구성된 제1 발생 코드;상기 적어도 하나의 프로세서로 하여금 재구성 프레임들을 발생시키기 위해 상기 중간 흐름들로 상기 입력 프레임들의 역방향 워핑을 수행하게 하도록 구성된 제2 발생 코드;상기 적어도 하나의 프로세서로 하여금 상기 입력 프레임들, 상기 중간 흐름들, 및 상기 재구성 프레임들에 기초하여, 융합 맵 및 잔차 맵을 발생시키게 하도록 구성된 융합 코드;상기 적어도 하나의 프로세서로 하여금 현재 참조 프레임, 제1 참조 프레임, 및 제2 참조 프레임에 기초하여, 제1 신경 네트워크를 사용하여 복수의 레벨을 갖는 특징 맵을 발생시키게 하도록 구성된 제3 발생 코드;상기 적어도 하나의 프로세서로 하여금 상기 현재 참조 프레임, 상기 제1 참조 프레임, 및 상기 제2 참조 프레임을 정제함으로써 상기 발생된 특징 맵으로부터의 정렬된 특징들에 기초하여 프레임을 예측하게 하도록 구성된 예측 코드;상기 적어도 하나의 프로세서로 하여금 상기 예측된 프레임에 기초하여 최종 잔차를 발생시키게 하도록 구성된 잔차 코드; 및상기 적어도 하나의 프로세서로 하여금 상기 최종 잔차를 상기 현재 참조 프레임에 가산함으로써 향상된 프레임을 출력으로서 발생시키게 하도록 구성된 제4 발생 코드를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 적어도 하나의 프로세서로 하여금 상기 중간 흐름들을 반복적으로 업데이트하게 하고 대응하는 픽셀들을 2개의 입력 프레임으로부터 잠재적 중간 프레임 내의 동일한 위치로 이동시키게 하도록 구성된 업데이팅 코드를 추가로 포함하는, 장치.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 적어도 하나의 프로세서로 하여금 상기 융합 맵에 따라 상기 재구성 프레임들을 선형 조합하고 상기 조합된 재구성 프레임들을 상기 잔차 맵과 가산함으로써 상기 현재 참조 프레임을 발생시키게 하도록 구성된 참조 프레임 코드를 추가로 포함하는, 장치.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서, 상기 제1 참조 프레임은 출력 순서로 상기 현재 참조 프레임에 선행하는 참조 프레임이고 상기 제2 참조 프레임은 상기 출력 순서로 상기 현재 참조 프레임에 뒤따르는 참조 프레임인, 장치.</claim></claimInfo><claimInfo><claim>12. 제8항에 있어서, 상기 적어도 하나의 프로세서로 하여금 상기 특징 맵에서 특징들의 가중치를 결정하게 하도록 구성된 결정 코드를 추가로 포함하며, 상기 가중치는 후속 최종 잔차들을 발생시키기 위한 특징들의 서브세트를 강조하는, 장치.</claim></claimInfo><claimInfo><claim>13. 제8항에 있어서,상기 적어도 하나의 프로세서로 하여금 상기 복수의 레벨에 대한 오프셋을 계산하게 하도록 구성된 계산 코드;상기 적어도 하나의 프로세서로 하여금 상기 복수의 레벨에 대한 보상 특징들을 발생시키기 위해 변형가능 콘벌루션을 수행하게 하도록 구성된 보상 특징 발생 코드; 및상기 적어도 하나의 프로세서로 하여금 상기 오프셋 및 상기 발생된 보상 특징들 중 적어도 하나에 기초하여 상기 정렬된 특징들을 발생시키게 하도록 구성된 정렬된 특징 발생 코드를 추가로 포함하는, 장치.</claim></claimInfo><claimInfo><claim>14. 제8항에 있어서,상기 적어도 하나의 프로세서로 하여금 융합된 주의 맵들을 획득하기 위해 콘벌루션을 수행하게 하도록 구성된 수행 코드;상기 적어도 하나의 프로세서로 하여금 상기 주의 맵들 및 상기 정렬된 특징들에 기초하여 주의 특징들을 발생시키게 하도록 구성된 주의 특징 발생 코드;상기 적어도 하나의 프로세서로 하여금 제2 신경 네트워크를 사용하여, 상기 주의 맵들 및 상기 주의 특징들에 기초하여, 정렬된 프레임을 발생시키게 하도록 구성된 정렬된 프레임 발생 코드; 및상기 적어도 하나의 프로세서로 하여금 상기 예측된 프레임을 획득하기 위해 상기 정렬된 프레임을 합성하게 하도록 구성된 합성 코드를 추가로 포함하는, 장치.</claim></claimInfo><claimInfo><claim>15. 명령어들을 저장하는 비일시적 컴퓨터 판독가능 매체로서,상기 명령어들은, 적어도 하나의 프로세서에 의해 실행될 때, 신경 네트워크 기반 인터프레임 예측을 사용하는 비디오 코딩을 위해, 상기 적어도 하나의 프로세서로 하여금,입력 프레임들에 기초하여 중간 흐름들을 발생시키게 하고;재구성 프레임들을 발생시키기 위해 상기 중간 흐름들로 상기 입력 프레임들의 역방향 워핑을 수행하게 하고;상기 입력 프레임들, 상기 중간 흐름들, 및 상기 재구성 프레임들에 기초하여, 융합 맵 및 잔차 맵을 발생시키게 하고;현재 참조 프레임, 제1 참조 프레임, 및 제2 참조 프레임에 기초하여, 제1 신경 네트워크를 사용하여 복수의 레벨을 갖는 특징 맵을 발생시키게 하고;상기 현재 참조 프레임, 상기 제1 참조 프레임, 및 상기 제2 참조 프레임을 정제함으로써 상기 발생된 특징 맵으로부터의 정렬된 특징들에 기초하여 프레임을 예측하게 하고;상기 예측된 프레임에 기초하여 최종 잔차를 발생시키게 하고;상기 최종 잔차를 상기 현재 참조 프레임에 가산함으로써 향상된 프레임을 출력으로서 발생시키게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행될 때, 추가로 상기 적어도 하나의 프로세서로 하여금 상기 중간 흐름들을 업데이트하게 하고 대응하는 픽셀들을 2개의 입력 프레임으로부터 잠재적 중간 프레임 내의 동일한 위치로 이동시키게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행될 때, 추가로 상기 적어도 하나의 프로세서로 하여금 상기 융합 맵에 따라 상기 재구성 프레임들을 선형 조합하고 상기 조합된 재구성 프레임들을 상기 잔차 맵과 가산함으로써 상기 현재 참조 프레임을 발생시키게 하고,상기 제1 참조 프레임은 출력 순서로 상기 현재 참조 프레임에 선행하는 참조 프레임이고 상기 제2 참조 프레임은 상기 출력 순서로 상기 현재 참조 프레임에 뒤따르는 참조 프레임인, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행될 때, 추가로 상기 적어도 하나의 프로세서로 하여금 상기 특징 맵에서 특징들의 가중치를 결정하게 하며, 상기 가중치는 후속 최종 잔차들을 발생시키기 위한 특징들의 서브세트를 강조하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행될 때, 추가로 상기 적어도 하나의 프로세서로 하여금,상기 복수의 레벨에 대한 오프셋을 계산하게 하고;상기 복수의 레벨에 대한 보상 특징들을 발생시키기 위해 변형가능 콘벌루션을 수행하게 하고;상기 오프셋 및 상기 발생된 보상 특징들 중 적어도 하나에 기초하여 상기 정렬된 특징들을 발생시키게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행될 때, 추가로 상기 적어도 하나의 프로세서로 하여금,융합된 주의 맵들을 획득하기 위해 콘벌루션을 수행하게 하고;상기 주의 맵들 및 상기 정렬된 특징들에 기초하여 주의 특징들을 발생시키게 하고;제2 신경 네트워크를 사용하여, 상기 주의 맵들 및 상기 주의 특징들에 기초하여, 정렬된 프레임을 발생시키게 하고;상기 예측된 프레임을 획득하기 위해 상기 정렬된 프레임을 합성하게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 팔로 알토 파크 블러바드 ****</address><code>520200357391</code><country>미국</country><engName>TENCENT AMERICA LLC</engName><name>텐센트 아메리카 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>LI, Zeqiang</engName><name>리, 쩌창</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>CHOI, Byeongdoo</engName><name>최, 병두</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>WANG, Wei</engName><name>왕, 웨이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>JIANG, Wei</engName><name>장, 웨이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>XU, Xiaozhong</engName><name>쉬, 샤오중</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>LIU, Shan</engName><name>류, 산</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920030004930</code><country>대한민국</country><engName>Lim KyuBin</engName><name>임규빈</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.12.29</priorityApplicationDate><priorityApplicationNumber>63/131,625</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.09.16</priorityApplicationDate><priorityApplicationNumber>17/476,928</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.11.03</receiptDate><receiptNumber>1-1-2022-1169707-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.11.03</receiptDate><receiptNumber>1-1-2022-1167964-80</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.11.03</receiptDate><receiptNumber>1-1-2022-1169694-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.11.09</receiptDate><receiptNumber>1-5-2022-0167663-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.07.11</receiptDate><receiptNumber>9-5-2025-0663174-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.11.07</receiptDate><receiptNumber>1-1-2025-1245874-91</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.11.07</receiptDate><receiptNumber>1-1-2025-1245897-30</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227038574.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93dc122a270efed89a3ecb10c6b5742652bb8e2204fd2a49eb1ad67ddcea802ec5db333bb1af7ee69ebc7f17797b18f175869a069acba32d46</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf88d42de9609b81d9fa23ab9ce1e8e5f1bb1f53e099c86f313e81ceccee5264fec926d0479cf0f370ce75fc6f0532ed14ad6a30edc28835b3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>