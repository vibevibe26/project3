<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:06.416</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7014149</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>멀티모달 융합 기반 딥 뉴럴 네트워크를 사용하는 멀티미디어 비디오들에서의 감정 인식</inventionTitle><inventionTitleEng>EMOTION RECOGNITION IN MULTIMEDIA VIDEOS USING MULTI-MODAL FUSION-BASED DEEP NEURAL NETWORK</inventionTitleEng><openDate>2024.06.24</openDate><openNumber>10-2024-0093516</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.04.26</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 멀티모달 융합 기반 딥 뉴럴 네트워크를 사용하는 멀티미디어 비디오들에서의 감정 인식을 사용하는 랜드마크 검출의 시스템 및 방법이 제공된다. 시스템은, 하나 이상의 피처 추출기, 트랜스포머 인코더들의 네트워크, 융합 어텐션 네트워크, 및 융합 어텐션 네트워크에 커플링되는 출력 네트워크를 포함하는 멀티모달 융합 네트워크를 저장하도록 구성되는 메모리 및 회로부를 포함한다. 시스템은 하나 이상의 피처 추출기에 멀티모달 입력을 입력한다. 멀티모달 입력은, 하나 이상의 비디오에서 나타낸 발화와 연관된다. 시스템은 입력에 대한 하나 이상의 피처 추출기의 출력으로서 입력 임베딩들을 생성하고, 입력 임베딩들에 기초하여 감정 관련 피처들의 세트를 추가로 생성한다. 시스템은 추가로 감정 관련 피처들의 세트의 융합된 피처 표현을 생성하고, 융합된 피처 표현에 기초하여 발화에 대한 감정 레이블을 예측한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.05.19</internationOpenDate><internationOpenNumber>WO2023084348</internationOpenNumber><internationalApplicationDate>2022.10.27</internationalApplicationDate><internationalApplicationNumber>PCT/IB2022/060334</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 시스템으로서,하나 이상의 피처 추출기(feature extractor), 상기 하나 이상의 피처 추출기에 커플링되는 트랜스포머 인코더(transformer encoder)들의 네트워크, 상기 트랜스포머 인코더들의 네트워크에 커플링되는 융합 어텐션 네트워크(fusion attention network), 및 상기 융합 어텐션 네트워크에 커플링되는 출력 네트워크를 포함하는 멀티모달 융합 네트워크(multimodal fusion network)를 저장하도록 구성되는 메모리; 및회로부를 포함하고,상기 회로부는: 상기 하나 이상의 피처 추출기에 멀티모달 입력을 입력하고 - 상기 멀티모달 입력은, 하나 이상의 비디오에서 나타낸 발화(utterance)와 연관됨 -; 상기 입력에 대한 상기 하나 이상의 피처 추출기의 출력으로서 입력 임베딩(input embedding)들을 생성하고 - 상기 입력 임베딩들은 상기 멀티모달 입력의 각각의 모달리티(modality)에 대한 임베딩을 포함함 -; 상기 입력 임베딩들에 대한 상기 트랜스포머 인코더들의 네트워크의 적용에 기초하여 감정 관련 피처들의 세트를 생성하고 - 상기 감정 관련 피처들의 세트는, 상기 멀티모달 입력의 각각의 모달리티에 대응하는 하나 이상의 피처를 포함함 -; 상기 감정 관련 피처들의 세트에 대한 상기 융합 어텐션 네트워크의 적용에 기초하여, 상기 감정 관련 피처들의 세트의 융합된 피처 표현을 생성하고; 상기 융합된 피처 표현에 대한 상기 출력 네트워크의 적용에 기초하여, 상기 발화에 대한 감정 레이블(emotion label)을 예측하도록구성되는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 멀티모달 입력은, 다중 언어 음성(multilingual speech) 및 상기 하나 이상의 피처 추출기와 호환가능한 제1 언어의 상기 다중 언어 음성의 텍스트 전사물(text transcription)을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 멀티모달 입력은, 상기 하나 이상의 피처 추출기와 호환가능한 제1 언어와는 상이한 제2 언어의 음성을 포함하고, 상기 멀티모달 입력은, 상기 하나 이상의 피처 추출기와 호환가능한 제1 언어의 상기 음성의 텍스트 전사물을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 멀티모달 입력은, 상기 발화의 음향들과 연관된 제1 모달리티, 상기 발화의 텍스트 전사본(text transcript)과 연관된 제2 모달리티, 및 상기 발화의 시각적 양태와 연관된 제3 모달리티를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 하나 이상의 피처 추출기는 음향-시각 피처 추출기 및 음향 피처 추출기를 포함하고, 상기 회로부는, 상기 멀티모달 입력에 포함된 상기 발화의 음향 정보에 대한 상기 음향-시각 피처 추출기 또는 상기 음향 피처 추출기 중 하나의 적용에 기초하여 상기 입력 임베딩들의 제1 임베딩을 생성하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 하나 이상의 피처 추출기는 텍스트 피처 추출기를 포함하고, 상기 회로부는, 상기 발화와 연관된 음향 정보의 텍스트 전사본 및 시간적으로 상기 발화에 선행하거나 또는 후행하는 상이한 발화들의 텍스트 전사본들에 대한 상기 텍스트 피처 추출기의 적용에 기초하여 상기 입력 임베딩들의 제2 임베딩을 생성하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 하나 이상의 피처 추출기는 음향-시각 피처 추출기 및 시각 피처 추출기를 포함하고, 상기 회로부는, 상기 하나 이상의 비디오의 프레임들에서의 하나 이상의 말하는 캐릭터의 얼굴 정보 및 프레임들과 연관된 장면 정보에 대한 상기 음향-시각 피처 추출기 또는 상기 시각 피처 추출기 중 하나의 적용에 기초하여 상기 입력 임베딩들의 제3 임베딩을 생성하도록 추가로 구성되고,상기 프레임들은 상기 하나 이상의 비디오에서의 상기 발화의 지속기간에 대응하는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 회로부는 추가로: 상기 음향-시각 피처 추출기 또는 상기 시각 피처 추출기에 상기 발화의 지속기간에 대응하는 상기 하나 이상의 비디오의 프레임들을 입력하고; 수신된 프레임들 각각에 대한 상기 시각 피처 추출기 또는 상기 음향-시각 피처 추출기의 얼굴 검출 모델의 적용에 기초하여, 상기 수신된 프레임들 각각에서 하나 이상의 얼굴을 검출하고; 상기 검출된 하나 이상의 얼굴을 포함하는 하나 이상의 바운딩 박스(bounding box)를 생성하고; 상기 음향-시각 피처 추출기 또는 상기 시각 피처 추출기 중 하나의 적용에 의해, 상기 하나 이상의 바운딩 박스 각각과 연관된 영역을 정규화하고; 상기 검출된 하나 이상의 얼굴 및 상기 정규화에 기초하여 상기 음향-시각 피처 추출기 또는 상기 시각 피처 추출기의 출력으로서 상기 입력 임베딩들의 제3 임베딩을 생성하도록구성되는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 트랜스포머 인코더들의 네트워크는, 상기 멀티모달 입력의 제1 모달리티에 대한 트랜스포머 인코더들의 제1 스택, 상기 멀티모달 입력의 제2 모달리티에 대한 트랜스포머 인코더들의 제2 스택, 및 상기 멀티모달 입력의 제3 모달리티에 대한 트랜스포머 인코더들의 제3 스택을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 트랜스포머 인코더들의 네트워크에서의 인접한 트랜스포머 인코더들의 각각의 쌍 사이의 스킵 커넥션을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 회로부는 추가로: 상기 하나 이상의 비디오를 수신하고; 상기 수신된 하나 이상의 비디오에 대해 장면 검출 모델을 적용하고; 상기 장면 검출 모델의 적용에 기초하여 상기 하나 이상의 비디오로부터 복수의 장면들을 추출하고; 상기 추출된 복수의 장면들 각각에 대해 단일 경계 검출 모델을 적용하고; 상기 단일 경계 검출 모델의 적용에 기초하여, 상기 추출된 복수의 장면들에서 복수의 발화들을 검출하고; 상기 검출에 기초하여 멀티모달 입력들의 시퀀스를 준비하도록구성되고,상기 하나 이상의 피처 추출기에 입력되는 멀티모달 입력은 상기 준비된 멀티모달 입력들의 시퀀스의 일부인, 시스템.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 융합 어텐션 네트워크는 하나 이상의 멀티헤드 어텐션 계층(multi-head attention layer) 및 제1 완전 연결 계층(first fully connected layer)을 포함하고,상기 제1 완전 연결 계층의 입력이 상기 하나 이상의 멀티헤드 어텐션 계층의 출력에 커플링되는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 회로부는 추가로, 상기 감정 관련 피처들의 세트에 대해 하나 이상의 멀티헤드 어텐션 계층을 적용하여: 상기 감정 관련 피처들의 세트 내의 피처 간 매핑(inter-feature mapping)을 결정하고; 상기 피처 간 매핑에 기초하여, 상기 감정 관련 피처들의 세트를 상기 감정 관련 피처들의 세트의 잠재 표현(latent representation)으로 연접(concatenate)하도록구성되는, 시스템.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 감정 관련 피처들의 세트의 융합된 피처 표현은 상기 잠재 표현에 대한 상기 제1 완전 연결 계층의 적용에 기초하여 추가로 생성되는, 시스템.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서,상기 출력 네트워크는, 상기 융합 어텐션 네트워크의 출력에 커플링되는 제2 완전 연결 계층을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>16. 방법으로서,멀티모달 융합 네트워크를 저장한 메모리를 포함하는 시스템에서: 상기 멀티모달 융합 네트워크의 하나 이상의 피처 추출기에 멀티모달 입력을 입력하는 단계 - 상기 멀티모달 입력은, 하나 이상의 비디오에서 나타낸 발화와 연관됨 -; 상기 입력에 대한 상기 하나 이상의 피처 추출기의 출력으로서 입력 임베딩들을 생성하는 단계 - 상기 입력 임베딩들은 상기 멀티모달 입력의 각각의 모달리티에 대한 임베딩을 포함함 -; 상기 입력 임베딩들에 대한 상기 멀티모달 융합 네트워크의 트랜스포머 인코더들의 네트워크의 적용에 기초하여 감정 관련 피처들의 세트를 생성하는 단계 - 상기 감정 관련 피처들의 세트는, 상기 멀티모달 입력의 각각의 모달리티에 대응하는 하나 이상의 피처를 포함함 -; 상기 감정 관련 피처들의 세트에 대한 상기 멀티모달 융합 네트워크의 융합 어텐션 네트워크의 적용에 기초하여, 상기 감정 관련 피처들의 세트의 융합된 피처 표현을 생성하는 단계; 및 상기 융합된 피처 표현에 대한 상기 멀티모달 융합 네트워크의 출력 네트워크의 적용에 기초하여, 상기 발화에 대한 감정 레이블을 예측하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 멀티모달 입력은, 상기 발화의 음향들과 연관된 제1 모달리티, 상기 발화의 텍스트 전사본과 연관된 제2 모달리티, 및 상기 발화의 시각적 양태와 연관된 제3 모달리티를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 융합 어텐션 네트워크는 하나 이상의 멀티헤드 어텐션 계층 및 제1 완전 연결 계층을 포함하고,상기 제1 완전 연결 계층의 입력이 상기 하나 이상의 멀티헤드 어텐션 계층의 출력에 커플링되는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 감정 관련 피처들의 세트에 대해 하나 이상의 멀티헤드 어텐션 계층을 적용하여: 상기 감정 관련 피처들의 세트 내의 피처 간 매핑을 결정하고; 상기 피처 간 매핑에 기초하여, 상기 감정 관련 피처들의 세트를 상기 감정 관련 피처들의 세트의 잠재 표현으로 연접하는 단계를 더 포함하고,상기 감정 관련 피처들의 세트의 융합된 피처 표현은 상기 잠재 표현에 대한 상기 제1 완전 연결 계층의 적용에 기초하여 추가로 생성되는, 방법.</claim></claimInfo><claimInfo><claim>20. 컴퓨터 실행가능 명령어들이 저장된 비일시적 컴퓨터 판독가능 매체로서,상기 컴퓨터 실행가능 명령어들은, 시스템의 회로부에 의해 실행될 때, 상기 회로부로 하여금: 멀티모달 융합 네트워크의 하나 이상의 피처 추출기에 멀티모달 입력을 입력하는 동작 - 상기 멀티모달 입력은, 하나 이상의 비디오에서 나타낸 발화와 연관됨 -; 상기 입력에 대한 상기 하나 이상의 피처 추출기의 출력으로서 입력 임베딩들을 생성하는 동작 - 상기 입력 임베딩들은 상기 멀티모달 입력의 각각의 모달리티에 대한 임베딩을 포함함 -; 상기 입력 임베딩들에 대한 상기 멀티모달 융합 네트워크의 트랜스포머 인코더들의 네트워크의 적용에 기초하여 감정 관련 피처들의 세트를 생성하는 동작 - 상기 감정 관련 피처들의 세트는, 상기 멀티모달 입력의 각각의 모달리티에 대응하는 하나 이상의 피처를 포함함 -; 상기 감정 관련 피처들의 세트에 대한 상기 멀티모달 융합 네트워크의 융합 어텐션 네트워크의 적용에 기초하여, 상기 감정 관련 피처들의 세트의 융합된 피처 표현을 생성하는 동작; 및 상기 융합된 피처 표현에 대한 상기 멀티모달 융합 네트워크의 출력 네트워크의 적용에 기초하여, 상기 발화에 대한 감정 레이블을 예측하는 동작을 포함하는 동작들을 실행하게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>일본국 도쿄도 미나토쿠 코난 *-*-*</address><code>519980961547</code><country>일본</country><engName>Sony Group Corporation</engName><name>소니그룹주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 샌 디에고 비아 에...</address><code> </code><country> </country><engName>WASNIK, Pankaj</engName><name>와스닉 판카즈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 샌 디에고 비아 에...</address><code> </code><country> </country><engName>ONOE, Naoyuki</engName><name>오노에 나오유키</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 샌 디에고 비아 에...</address><code> </code><country> </country><engName>CHUDASAMA, Vishal</engName><name>추다사마 비샬</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990002028</code><country>대한민국</country><engName>LEE, JUNG HEE</engName><name>이중희</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.11.12</priorityApplicationDate><priorityApplicationNumber>63/263,961</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.09</priorityApplicationDate><priorityApplicationNumber>17/941,787</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.04.26</receiptDate><receiptNumber>1-1-2024-0461514-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.04.30</receiptDate><receiptNumber>1-5-2024-0072487-46</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247014149.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936d98bbcc912edd1bf2b3881d629083559b265d137a9a0a1c740afd334399d508cf520b19529144a65887dad6a8d778b13fe2ceafb3d73235</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6358092c2c1bda0d2b4c779720c11baf8b9e2062774ed233a958ee155f93299db78dfd37f6c297d9a2398fe9da3e918e402b0e31e90de72f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>