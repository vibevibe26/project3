<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:44.4044</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.03.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7037323</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>얼굴 표정의 선택을 사용한 온라인 커뮤니티를 위한 콘텐츠에서의 얼굴 합성</inventionTitle><inventionTitleEng>FACIAL SYNTHESIS IN CONTENT FOR ONLINE COMMUNITIES USING A SELECTION OF A FACIAL EXPRESSION</inventionTitleEng><openDate>2023.11.28</openDate><openNumber>10-2023-0162096</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.10.30</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 기술은 컴퓨팅 디바이스에 의해 제1 이미지 데이터를 캡처하고, 제1 이미지 데이터는 타겟 액터의 타겟 얼굴 및 타겟 액터의 얼굴 표정들을 포함하고, 얼굴 표정들은 입술 움직임들을 포함한다. 본 기술은, 소스 미디어 콘텐츠의 프레임들에 적어도 부분적으로 기초하여, 소스 포즈 파라미터들의 세트들을 생성한다. 본 기술은 얼굴 표정들의 세트로부터 특정 얼굴 표정의 선택을 수신한다. 본 기술은 소스 포즈 파라미터들의 세트들 및 특정 얼굴 표정의 선택에 적어도 부분적으로 기초하여, 출력 미디어 콘텐츠를 생성한다. 본 기술은 컴퓨팅 디바이스 상에 디스플레이하기 위해 출력 미디어 콘텐츠에 적어도 부분적으로 기초한 증강 현실 콘텐츠를 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.10.06</internationOpenDate><internationOpenNumber>WO2022212309</internationOpenNumber><internationalApplicationDate>2022.03.29</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/022253</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 하드웨어 프로세서에 의해, 클라이언트 디바이스에 의해 이미지 데이터를 캡처하는 단계- 상기 캡처된 이미지 데이터는 타겟 액터의 타겟 얼굴 및 타겟 액터의 얼굴 표정들을 포함하고, 상기 타겟 액터의 얼굴 표정들은 입술 움직임들을 포함함 -;상기 하나 이상의 하드웨어 프로세서에 의해, 얼굴 표정들의 세트로부터 특정 얼굴 표정의 선택을 수신하는 단계;상기 하나 이상의 하드웨어 프로세서에 의해, 그리고, 상기 소스 미디어 콘텐츠의 프레임들에 적어도 부분적으로 기초하여, 소스 포즈 파라미터들의 세트들을 생성하는 단계- 상기 소스 포즈 파라미터들의 세트들은 상기 소스 미디어 콘텐츠의 프레임들에서의 상기 소스 액터의 머리의 표현들의 위치들 및 상기 소스 액터의 얼굴 표정들을 포함함 -;상기 하나 이상의 하드웨어 프로세서에 의해, 상기 소스 포즈 파라미터들의 세트들 및 상기 특정 얼굴 표정의 선택에 적어도 부분적으로 기초하여, 출력 미디어 콘텐츠를 생성하는 단계- 상기 출력 미디어 콘텐츠의 각각의 프레임은 상기 출력 미디어 콘텐츠의 적어도 하나의 프레임에 상기 캡처된 이미지 데이터로부터의 상기 타겟 얼굴의 이미지를 포함하고, 상기 타겟 얼굴의 이미지는 상기 소스 포즈 파라미터들의 세트들 중 적어도 하나에 기초하여 수정되어 상기 소스 미디어 콘텐츠의 프레임들에서의 상기 소스 액터의 머리의 위치들 중 적어도 하나 및 적어도 상기 얼굴 표정들의 세트로부터의 상기 특정 얼굴 표정을 모방함 -; 및상기 하나 이상의 하드웨어 프로세서에 의해, 컴퓨팅 디바이스 상에 디스플레이하기 위해 상기 출력 미디어 콘텐츠에 적어도 부분적으로 기초한 증강 현실 콘텐츠를 제공하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,디스플레이를 위해 선택가능한 그래픽 아이템들의 세트를 제공하는 단계- 상기 선택가능한 그래픽 아이템들 각각은 얼굴 애니메이션 및 얼굴 합성을 위한 다양한 감정적 특성들을 포함하는 얼굴 표정들의 세트 중에서 특정 얼굴 표정의 특정 표현을 포함함 -;선택가능한 그래픽 아이템들의 세트로부터 특정 선택가능한 그래픽 아이템의 선택을 수신하는 단계;상기 특정 선택가능 그래픽 아이템에 대응하는 특정 얼굴 표정을 결정하는 단계; 및상기 특정 얼굴 표정에 기초하여 상기 캡처된 이미지 데이터에서 상기 타겟 액터의 머리의 표현들 및 상기 타겟 액터의 얼굴 표정들의 수정을 수행하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 타겟 액터의 머리의 표현들 및 상기 타겟 액터의 얼굴 표정들의 수정을 수행하는 단계는상기 소스 액터의 머리의 제1 세트의 숨겨진 특징들 및 상기 소스 액터의 얼굴 표정들에 대응하는 제1 잠재 벡터를 수신하는 단계- 상기 제1 세트의 숨겨진 특징들은 직접 관찰가능하지 않음 -; 및상기 타겟 액터의 타겟 얼굴의 제2 세트의 숨겨진 특징들 및 상기 타겟 액터의 얼굴 표정들에 대응하는 제2 잠재 벡터를 수신하는 단계- 상기 제2 세트의 숨겨진 특징들은 직접 관찰가능하지 않음 -를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,매핑 심층 신경망을 사용하여, 상기 제1 잠재 벡터에 기초하여 제1 중간 잠재 벡터를 생성하는 단계- 상기 매핑 심층 신경망은 3개보다 많은 계층을 통해 상기 제1 잠재 벡터에 비선형 함수를 적용하고, 상기 제1 중간 잠재 벡터는 상기 소스 액터의 머리 및 상기 소스 액터의 얼굴 표정들에 기초하여 상기 특정 얼굴 표정과 연관된 제1 세트의 스타일들을 포함함 -; 및상기 매핑 심층 신경망을 사용하여, 상기 제2 잠재 벡터에 기초하여 제2 중간 잠재 벡터를 생성하는 단계- 상기 매핑 심층 신경망은 3개보다 많은 계층을 통해 상기 제2 잠재 벡터에 비선형 함수를 적용하고, 상기 제2 중간 잠재 벡터는 상기 타겟 액터의 머리 및 상기 타겟 액터의 얼굴 표정들과 연관된 제2 세트의 스타일들을 포함함 -를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,합성 컨볼루션 신경망을 이용하여, 제1 양의 상기 제1 세트의 스타일과 제2 양의 상기 제2 세트의 스타일을 조합하여 조합된 스타일 세트를 생성하는 단계; 및상기 출력 미디어 콘텐츠의 프레임들의 세트를 생성하기 위해 상기 타겟 액터의 타겟 얼굴 및 상기 타겟 액터의 얼굴 표정들을 포함하는 상기 캡처된 이미지 데이터에 상기 조합된 스타일 세트를 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 제1 세트의 스타일들은 대략적 해상도 스타일들의 제1 세트, 중간 해상도 스타일들의 제2 세트, 및 미세 해상도 스타일들의 제3 세트를 포함하고, 상기 대략적 해상도 스타일들은 상기 중간 해상도 스타일들보다 더 낮은 해상도를 갖고, 상기 중간 해상도 스타일들은 상기 미세 해상도 스타일들보다 더 낮은 해상도를 갖는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 조합된 스타일 세트를 적용하는 단계는상기 중간 해상도 스타일들의 제2 세트를 상기 제1 양의 상기 제1 세트의 스타일들과 조합하는 단계; 및상기 조합된 중간 해상도 스타일들의 제2 세트 및 상기 제1 양의 상기 제1 세트의 스타일들을 적용하여 상기 출력 미디어 콘텐츠의 프레임들의 세트를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 출력 미디어 콘텐츠의 프레임들의 세트는 상기 특정 얼굴 표정의 표현을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제5항에 있어서, 상기 매핑 심층 신경망과 상기 합성 컨볼루션 신경망의 조합은 생성적 적대 네트워크(GAN)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제2항에 있어서, 상기 얼굴 표정들의 세트는 소스 액터를 자신감 있는 모습으로, 슬픈 모습으로, 흥분된 모습으로, 생각하는 모습으로, 무표정으로, 긍정적인 모습으로, 화난 모습으로, 걱정하는 모습으로, 놀란 모습으로, 으스스한 모습으로, 함성을 지르는 모습으로, 또는 부끄러워하는 모습으로 보이게 하기 위해 시각적 묘사들을 표현하는 각각의 얼굴 표정에 대응하는 상이한 얼굴 표정들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 시스템으로서,프로세서; 및명령어들을 포함한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금하나 이상의 하드웨어 프로세서에 의해, 클라이언트 디바이스에 의해 이미지 데이터를 캡처하는 동작- 상기 캡처된 이미지 데이터는 타겟 액터의 타겟 얼굴 및 타겟 액터의 얼굴 표정들을 포함하고, 상기 타겟 액터의 얼굴 표정들은 입술 움직임들을 포함함 -;상기 하나 이상의 하드웨어 프로세서에 의해, 얼굴 표정들의 세트로부터 특정 얼굴 표정의 선택을 수신하는 동작;상기 하나 이상의 하드웨어 프로세서에 의해, 그리고, 상기 소스 미디어 콘텐츠의 프레임들에 적어도 부분적으로 기초하여, 소스 포즈 파라미터들의 세트들을 생성하는 동작- 상기 소스 포즈 파라미터들의 세트들은 상기 소스 미디어 콘텐츠의 프레임들에서의 상기 소스 액터의 머리의 표현들의 위치들 및 상기 소스 액터의 얼굴 표정들을 포함함 -;상기 하나 이상의 하드웨어 프로세서에 의해, 상기 소스 포즈 파라미터들의 세트들 및 상기 특정 얼굴 표정의 선택에 적어도 부분적으로 기초하여, 출력 미디어 콘텐츠를 생성하는 동작- 상기 출력 미디어 콘텐츠의 각각의 프레임은 상기 출력 미디어 콘텐츠의 적어도 하나의 프레임에 상기 캡처된 이미지 데이터로부터의 상기 타겟 얼굴의 이미지를 포함하고, 상기 타겟 얼굴의 이미지는 상기 소스 포즈 파라미터들의 세트들 중 적어도 하나에 기초하여 수정되어 상기 소스 미디어 콘텐츠의 프레임들에서의 상기 소스 액터의 머리의 위치들 중 적어도 하나 및 적어도 상기 얼굴 표정들의 세트로부터의 상기 특정 얼굴 표정을 모방함 -; 및상기 하나 이상의 하드웨어 프로세서에 의해, 컴퓨팅 디바이스 상에 디스플레이하기 위해 상기 출력 미디어 콘텐츠에 적어도 부분적으로 기초한 증강 현실 콘텐츠를 제공하는 동작을 포함하는 동작들을 수행하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 동작들은디스플레이를 위해 선택가능한 그래픽 아이템들의 세트를 제공하는 동작- 상기 선택가능한 그래픽 아이템들 각각은 얼굴 애니메이션 및 얼굴 합성을 위한 다양한 감정적 특성들을 포함하는 얼굴 표정들의 세트 중에서 특정 얼굴 표정의 특정 표현을 포함함 -;선택가능한 그래픽 아이템들의 세트로부터 특정 선택가능한 그래픽 아이템의 선택을 수신하는 동작;상기 특정 선택가능 그래픽 아이템에 대응하는 특정 얼굴 표정을 결정하는 동작; 및상기 특정 얼굴 표정에 기초하여 상기 캡처된 이미지 데이터에서 상기 타겟 액터의 머리의 표현들 및 상기 타겟 액터의 얼굴 표정들의 수정을 수행하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 타겟 액터의 머리의 표현들 및 상기 타겟 액터의 얼굴 표정들의 수정을 수행하는 동작은상기 소스 액터의 머리의 제1 세트의 숨겨진 특징들 및 상기 소스 액터의 얼굴 표정들에 대응하는 제1 잠재 벡터를 수신하는 동작- 상기 제1 세트의 숨겨진 특징들은 직접 관찰가능하지 않음 -; 및상기 타겟 액터의 타겟 얼굴의 제2 세트의 숨겨진 특징들 및 상기 타겟 액터의 얼굴 표정들에 대응하는 제2 잠재 벡터를 수신하는 동작- 상기 제2 세트의 숨겨진 특징들은 직접 관찰가능하지 않음 -을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 동작들은매핑 심층 신경망을 사용하여, 상기 제1 잠재 벡터에 기초하여 제1 중간 잠재 벡터를 생성하는 동작- 상기 매핑 심층 신경망은 3개보다 많은 계층을 통해 상기 제1 잠재 벡터에 비선형 함수를 적용하고, 상기 제1 중간 잠재 벡터는 상기 소스 액터의 머리 및 상기 소스 액터의 얼굴 표정들에 기초하여 상기 특정 얼굴 표정과 연관된 제1 세트의 스타일들을 포함함 -; 및상기 매핑 심층 신경망을 사용하여, 상기 제2 잠재 벡터에 기초하여 제2 중간 잠재 벡터를 생성하는 동작- 상기 매핑 심층 신경망은 3개보다 많은 계층을 통해 상기 제2 잠재 벡터에 비선형 함수를 적용하고, 상기 제2 중간 잠재 벡터는 상기 타겟 액터의 머리 및 상기 타겟 액터의 얼굴 표정들과 연관된 제2 세트의 스타일들을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 동작들은합성 컨볼루션 신경망을 이용하여, 상기 제1 양의 제1 세트의 스타일과 상기 제2 양의 제2 세트의 스타일을 조합하여 조합된 스타일 세트를 생성하는 동작; 및상기 출력 미디어 콘텐츠의 프레임들의 세트를 생성하기 위해 상기 타겟 액터의 타겟 얼굴 및 상기 타겟 액터의 얼굴 표정들을 포함하는 상기 캡처된 이미지 데이터에 상기 조합된 스타일 세트를 적용하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 제1 세트의 스타일들은 대략적 해상도 스타일들의 제1 세트, 중간 해상도 스타일들의 제2 세트, 및 미세 해상도 스타일들의 제3 세트를 포함하고, 상기 대략적 해상도 스타일들은 상기 중간 해상도 스타일들보다 더 낮은 해상도를 갖고, 상기 중간 해상도 스타일들은 상기 미세 해상도 스타일들보다 더 낮은 해상도를 갖는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 조합된 스타일 세트를 적용하는 동작은상기 중간 해상도 스타일들의 제2 세트를 제1 양의 상기 제1 세트의 스타일들과 조합하는 동작; 및상기 조합된 중간 해상도 스타일들의 제2 세트 및 상기 제1 양의 상기 제1 세트의 스타일들을 적용하여 상기 출력 미디어 콘텐츠의 프레임들의 세트를 생성하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 출력 미디어 콘텐츠의 프레임들의 세트는 상기 특정 얼굴 표정의 표현을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서, 상기 매핑 심층 신경망과 상기 합성 컨볼루션 신경망의 조합은 생성적 적대 네트워크(GAN)를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함한 비일시적 컴퓨터 판독가능 매체로서, 상기 명령어들은, 컴퓨팅 디바이스에 의해 실행될 때, 상기 컴퓨팅 디바이스로 하여금클라이언트 디바이스에 의해 이미지 데이터를 캡처하는 동작- 상기 캡처된 이미지 데이터는 타겟 액터의 타겟 얼굴 및 타겟 액터의 얼굴 표정들을 포함하고, 상기 타겟 액터의 얼굴 표정들은 입술 움직임들을 포함함 -;얼굴 표정들의 세트로부터 특정 얼굴 표정의 선택을 수신하는 동작;소스 미디어 콘텐츠의 프레임들에 적어도 부분적으로 기초하여, 소스 포즈 파라미터들의 세트들을 생성하는 동작- 상기 소스 포즈 파라미터들의 세트들은 상기 소스 미디어 콘텐츠의 프레임들에서의 소스 액터의 머리의 표현들의 위치들 및 상기 소스 액터의 얼굴 표정들을 포함함 -;상기 소스 포즈 파라미터들의 세트들 및 상기 특정 얼굴 표정의 선택에 적어도 부분적으로 기초하여, 출력 미디어 콘텐츠를 생성하는 동작- 상기 출력 미디어 콘텐츠의 각각의 프레임은 상기 출력 미디어 콘텐츠의 적어도 하나의 프레임에 상기 캡처된 이미지 데이터로부터의 상기 타겟 얼굴의 이미지를 포함하고, 상기 타겟 얼굴의 이미지는 상기 소스 포즈 파라미터들의 세트들 중 적어도 하나에 기초하여 수정되어 상기 소스 미디어 콘텐츠의 프레임들에서의 상기 소스 액터의 머리의 위치들 중 적어도 하나 및 적어도 상기 얼굴 표정들의 세트로부터의 상기 특정 얼굴 표정을 모방함 -; 및컴퓨팅 디바이스 상에 디스플레이하기 위해 상기 출력 미디어 콘텐츠에 적어도 부분적으로 기초한 증강 현실 콘텐츠를 제공하는 동작을 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>GOLOBOKOV, Roman</engName><name>골로보코브, 로만</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>MARINENKO, Alexandr</engName><name>마린엔코, 알렉산드르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>MASHRABOV, Aleksandr</engName><name>마쉬라보브, 알렉산드르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>BROMOT, Aleksei</engName><name>브로모트, 알렉세이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>TKACHENKO, Grigoriy</engName><name>트카첸코, 그리고리</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.03.31</priorityApplicationDate><priorityApplicationNumber>63/168,996</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.10.30</receiptDate><receiptNumber>1-1-2023-1190879-71</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.11.02</receiptDate><receiptNumber>1-5-2023-0174847-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.05.19</receiptDate><receiptNumber>9-5-2025-0472231-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.07.14</receiptDate><receiptNumber>1-1-2025-0790169-25</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.07.14</receiptDate><receiptNumber>1-1-2025-0790188-93</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237037323.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f1562128e7cd4b8c71813fd5c753aa563d51630413ae549e30aca5681732ad4686735f6dc6c2057d505a5704f8cfd5a50b32b68932fe5157</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf7d272feb4ce8dd28b3e56e9627266132867ce148202bc1d6b12d56e1baa2ccfba44e04a1b3e5104a7a553c40f88b79a604cd31f3464d81b2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>