<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:38.3938</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0135197</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>시선을 추정하는 전자 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE FOR ESTIMATING GAZE AND METHOD FOR  OPERATING THE SAME</inventionTitleEng><openDate>2023.06.09</openDate><openNumber>10-2023-0083213</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.10.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 시선을 추정하는 전자 장치 및 그 동작 방법이 개시될 수 있다. 전자 장치의 동작 방법은 객체의 눈이 포함된 이미지의 타겟 정보를 획득하는 동작, 타겟 정보에 기초하여, 이미지에서 눈에 대한 정보를 표현하는 타겟 특징맵을 획득하는 동작 및 타겟 특징맵에 기초하여 이미지에 포함된 눈에 대한 시선 추정을 수행하는 동작을 포함한다. 타겟 정보는 이미지에 대한 어텐션 정보 및 이미지 내 픽셀 사이의 거리 중 어느 하나 또는 둘 이상을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 객체의 눈이 포함된 이미지의 타겟 정보를 획득하는 동작;상기 타겟 정보에 기초하여, 상기 이미지에서 상기 눈에 대한 정보를 표현하는 타겟 특징맵을 획득하는 동작; 및상기 타겟 특징맵에 기초하여 상기 이미지에 포함된 상기 눈에 대한 시선 추정을 수행하는 동작을 포함하고,상기 타겟 정보는 상기 이미지에 대한 어텐션 정보 및 상기 이미지 내 픽셀 사이의 거리 중 어느 하나 또는 둘 이상을 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 어텐션 정보는 적어도 두 프레임의 이미지 사이의 시간 관계 정보를 포함하고, 상기 타겟 특징맵을 획득하는 동작은상기 적어도 두 프레임의 이미지의 제1 특징맵 및 상기 적어도 두 프레임의 이미지 사이의 시간 관계 정보에 기초하여, 상기 이미지의 타겟 특징맵을 획득하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 어텐션 정보는 상기 객체의 얼굴의 정면 특징을 포함하고,상기 타겟 특징맵을 획득하는 동작은상기 이미지의 특정 부분의 제2 특징맵 및 상기 얼굴의 정면 특징에 기초하여, 상기 타겟 특징맵을 획득하고,상기 특정 부분은 상기 객체의 눈, 입, 코, 귀 및 눈썹 부분 중 하나 또는 둘 이상을 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 어텐션 정보는 적어도 두 프레임의 이미지 사이의 시간 관계 정보 및 상기 객체의 얼굴의 정면 특징을 포함하고,상기 타겟 특징맵을 획득하는 동작은상기 얼굴의 정면 특징 및 상기 이미지의 특정 부분의 제2 특징맵에 기초하여, 상기 이미지의 제3 특징맵을 획득하고,상기 적어도 두 프레임의 이미지의 제3 특징맵 및 상기 적어도 두 프레임의 이미지 사이의 시간 관계 정보에 기초하여, 상기 타겟 특징맵을 획득하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 얼굴의 정면 특징은상기 이미지의 얼굴 맵 및 얼굴 마스크를 획득하는 동작;상기 이미지, 상기 얼굴 맵 및 상기 얼굴 마스크에 기초하여, 제1 정면 이미지를 획득하는 동작; 및상기 제1 정면 이미지에 기초하여, 상기 얼굴의 정면 특징을 획득하는 동작에 기초하여 결정되고,상기 얼굴 맵은 상기 이미지에서 상기 얼굴의 각 픽셀의 오프셋을 포함하고,상기 얼굴 마스크는 상기 이미지에서 얼굴 이외의 영역을 가리는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 제1 정면 이미지를 획득하는 동작은상기 이미지, 상기 얼굴 맵 및 상기 얼굴 마스크에 기초하여, 얼굴 영역에 홀이 존재하는 제2 정면 이미지를 획득하고,상기 제2 정면 이미지에 기초하여, 상기 제2 정면 이미지의 홀 마스크 및 제3 정면 이미지를 획득하며,상기 제2 정면 이미지, 상기 홀 마스크 및 상기 제3 정면 이미지에 기초하여, 상기 제1 정면 이미지를 획득하고,상기 홀 마스크는 상기 제2 정면 이미지에서 홀 이외의 이미지 영역을 가리고,상기 제3 정면 이미지는 상기 제2 정면 이미지에서 홀 위치에 대응하는 이미지 영역을 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 타겟 정보는 픽셀 사이의 거리를 포함하고,상기 타겟 특징맵을 획득하는 동작은상기 이미지의 제4 특징맵 및 상기 픽셀 사이의 상대 거리 정보에 기초하여, 상기 타겟 특징맵을 획득하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 타겟 정보는 가중치 정보를 포함하고,상기 타겟 정보를 획득하는 동작은상기 이미지의 제5 특징맵에 기초하여, 상기 이미지의 제1 가중치 맵을 획득하고,상기 타겟 특징맵을 획득하는 동작은상기 제1 가중치 맵 및 상기 제5 특징맵에 기초하여, 상기 타겟 특징맵을 획득하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 어텐션 정보는 가중치 정보를 포함하고,상기 타겟 정보를 획득하는 동작은상기 이미지 중 눈의 위치에 기초하여, 제2 가중치 맵을 획득하고,상기 타겟 특징맵을 획득하는 동작은상기 제2 가중치 맵 및 상기 이미지의 제6 특징맵에 기초하여, 상기 타겟 특징맵을 획득하고,상기 제6 특징맵은 적어도 2개의 컨볼루션 레이어를 통해 상기 이미지에서 특징을 추출하여 획득되는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 타겟 특징맵을 획득하는 동작은상기 제2 가중치 맵 및 중간 특징맵에 기초하여, 제7 특징맵을 획득하고,상기 제6 특징맵 및 상기 제7 특징맵에 기초하여, 상기 타겟 특징맵을 획득하고,상기 중간 특징맵은 상기 적어도 2개의 컨볼루션 레이어 중의 타겟 레이어에 의해 출력된 특징맵인,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 시선 추정을 수행하는 동작은상기 타겟 특징맵 및 타겟 자세 정보에 기초하여, 상기 이미지에 대해 시선 추정을 수행하고,상기 타겟 자세 정보는 상기 이미지 중 타겟 부분의 자세 정보인,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중에서 어느 한 항의 방법을 실행하는 컴퓨터 프로그램을 저장하는 컴퓨터 판독가능 기록매체.</claim></claimInfo><claimInfo><claim>13. 프로세서; 및상기 프로세서에 의해 실행 가능한 적어도 하나의 명령어를 포함하는 메모리를 포함하고,상기 적어도 하나의 명령어가 상기 프로세서에서 실행되면, 상기 프로세서는 객체의 눈이 포함된 이미지의 타겟 정보를 획득하고, 상기 타겟 정보에 기초하여 상기 이미지에서 상기 눈에 대한 정보를 표현하는 타겟 특징맵을 획득하며, 상기 타겟 특징맵에 기초하여 상기 이미지에 포함된 상기 눈에 대한 시선 추정을 수행하고,상기 타겟 정보는 상기 이미지에 대한 어텐션 정보 및 상기 이미지 내 픽셀 사이의 거리 중 어느 하나 또는 둘 이상을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 어텐션 정보는 적어도 두 프레임의 이미지 사이의 시간 관계 정보를 포함하고, 상기 프로세서는상기 적어도 두 프레임의 이미지의 제1 특징맵 및 상기 적어도 두 프레임의 이미지 사이의 시간 관계 정보에 기초하여, 상기 이미지의 타겟 특징맵을 획득하는,전자 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 어텐션 정보는 상기 객체의 얼굴의 정면 특징을 포함하고,상기 프로세서는상기 이미지의 특정 부분의 제2 특징맵 및 상기 얼굴의 정면 특징에 기초하여, 상기 타겟 특징맵을 획득하고,상기 특정 부분은 상기 객체의 눈, 입, 코, 귀 및 눈썹 부분 중 하나 또는 둘 이상을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 어텐션 정보는 적어도 두 프레임의 이미지 사이의 시간 관계 정보 및 상기 객체의 얼굴의 정면 특징을 포함하고,상기 프로세서는상기 얼굴의 정면 특징 및 상기 이미지의 특정 부분의 제2 특징맵에 기초하여, 상기 이미지의 제3 특징맵을 획득하고,상기 적어도 두 프레임의 이미지의 제3 특징맵 및 상기 적어도 두 프레임의 이미지 사이의 시간 관계 정보에 기초하여, 상기 타겟 특징맵을 획득하는,전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 얼굴의 정면 특징은상기 이미지의 얼굴 맵 및 얼굴 마스크를 획득하는 동작;상기 이미지, 상기 얼굴 맵 및 상기 얼굴 마스크에 기초하여, 제1 정면 이미지를 획득하는 동작; 및상기 제1 정면 이미지에 기초하여, 상기 얼굴의 정면 특징을 획득하는 동작에 기초하여 결정되고,상기 얼굴 맵은 상기 이미지에서 상기 얼굴의 각 픽셀의 오프셋을 포함하고,상기 얼굴 마스크는 상기 이미지에서 얼굴 이외의 영역을 가리는,전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서는상기 이미지, 상기 얼굴 맵 및 상기 얼굴 마스크에 기초하여, 얼굴 영역에 홀이 존재하는 제2 정면 이미지를 획득하고,상기 제2 정면 이미지에 기초하여, 상기 제2 정면 이미지의 홀 마스크 및 제3 정면 이미지를 획득하며,상기 제2 정면 이미지, 상기 홀 마스크 및 상기 제3 정면 이미지에 기초하여, 상기 제1 정면 이미지를 획득하고,상기 홀 마스크는 상기 제2 정면 이미지에서 홀 이외의 이미지 영역을 가리고,상기 제3 정면 이미지는 상기 제2 정면 이미지에서 홀 위치에 대응하는 이미지 영역을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제13항에 있어서,상기 타겟 정보는 픽셀 사이의 거리를 포함하고,상기 프로세서는상기 이미지의 제4 특징맵 및 상기 픽셀 사이의 상대 거리 정보에 기초하여, 상기 타겟 특징맵을 획득하는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제13항에 있어서,상기 타겟 정보는 가중치 정보를 포함하고,상기 프로세서는상기 이미지의 제5 특징맵에 기초하여, 상기 이미지의 제1 가중치 맵을 획득하고,상기 제1 가중치 맵 및 상기 제5 특징맵에 기초하여, 상기 타겟 특징맵을 획득하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>LI, Weiming</engName><name>리, 웨이밍</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>WANG, Qiang</engName><name>왕, 치앙</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code>420170474303</code><country>대한민국</country><engName>CHANG, Hyun Sung</engName><name>장현성</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170747602</code><country>대한민국</country><engName>KIM, Jiyeon</engName><name>김지연</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HONG Sung Hoon</engName><name>홍성훈</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 차오양 지구...</address><code> </code><country> </country><engName>MA, Lin</engName><name>마, 린</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2021.12.02</priorityApplicationDate><priorityApplicationNumber>202111463213.4</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.10.19</receiptDate><receiptNumber>1-1-2022-1103899-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2022.10.26</receiptDate><receiptNumber>9-1-2022-9012396-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.02</receiptDate><receiptNumber>1-1-2025-1126879-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220135197.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9381573debefb320cc33ca4e4931ccd3a9110cabbac5eae5b7f7888d235b2b2154e35a0d1cbf857904719c603c2c2f7fcbdd6cb6a744f837c6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfac9a2a4cc18aa7f126d4c481727f238a9ac7066b99342cd2dcf3142f8ca3a92cd36c3d6cf473b92398bad992ea11b93ef3175e540ecc46bb</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>