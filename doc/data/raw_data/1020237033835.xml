<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:25.5625</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7033835</applicationNumber><claimCount>14</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자동 스피치 인식의 로컬 실행을 위한 디바이스 중재</inventionTitle><inventionTitleEng>DEVICE ARBITRATION FOR LOCAL EXECUTION OF AUTOMATIC SPEECH RECOGNITION</inventionTitleEng><openDate>2023.11.06</openDate><openNumber>10-2023-0153450</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.04</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.10.04</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/28</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/51</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 음성 발화의 텍스트 표현은 주어진 클라이언트 디바이스를 사용하여 생성된 음성 발화의 후보 텍스트 표현에 기초하여 및/또는 대응하는 추가 클라이언트 디바이스를 사용하여 각각 생성된 음성 발화의 하나 이상의 추가 후보 텍스트 표현에 기초하여 생성될 수 있다. 다양한 구현예는 주어진 클라이언트 디바이스가 있는 환경의 추가 클라이언트 디바이스 세트로부터 추가 클라이언트 디바이스(들)를 결정하는 것을 포함한다. 다양한 구현예는 추가적으로 또는 대안적으로, 추가 클라이언트 디바이스가 주어진 클라이언트 디바이스의 마이크(들)에 의해 캡처된 오디오 데이터에 기초하여 및/또는 추가 클라이언트 디바이스의 마이크(들)에 의해 캡처된 추가 오디오 데이터에 기초하여 음성 발화의 추가 후보 텍스트 표현을 생성할지 여부를 결정하는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.09.15</internationOpenDate><internationOpenNumber>WO2022191892</internationOpenNumber><internationalApplicationDate>2021.12.14</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/063370</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프로세서에 의해 수행되는 방법으로서,클라이언트 디바이스에서 사용자의 음성 발화를 캡처하는 오디오 데이터를 검출하는 단계, 상기 클라이언트 디바이스는 하나 이상의 추가 클라이언트 디바이스가 있는 환경에 있으며 로컬 네트워크를 통해 하나 이상의 추가 클라이언트 디바이스와 로컬 통신 상태에 있고, 상기 하나 이상의 추가 클라이언트 디바이스는 적어도 제1 추가 클라이언트 디바이스를 포함하며;클라이언트 디바이스에서, 상기 음성 발화의 후보 텍스트 표현을 생성하기 위해 클라이언트 디바이스에 로컬적으로 저장된 자동 스피치 인식(&quot;ASR&quot;) 모델을 사용하여 상기 오디오 데이터를 프로세싱하는 단계;클라이언트 디바이스에서, 로컬 네트워크를 통해, 제1 추가 클라이언트 디바이스로부터, 상기 음성 발화의 제1 추가 후보 텍스트 표현을 수신하는 단계, 상기 제1 추가 클라이언트 디바이스에서 로컬적으로 생성된 음성 발화의 제1 추가 후보 텍스트 표현은 (a) 오디오 데이터 및/또는 (b) 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 로컬적으로 검출된 오디오 데이터에 기초하며, 상기 음성 발화의 제1 추가 후보 텍스트 표현은 상기 오디오 데이터 및/또는 상기 제1 추가 클라이언트 디바이스에 로컬적으로 저장된 제1 추가 ASR 모델을 사용하여 로컬적으로 생성된 오디오 데이터를 프로세싱함으로써 생성되며; 및상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서,상기 하나 이상의 추가 클라이언트 디바이스는 적어도 제1 추가 클라이언트 디바이스 및 제2 추가 클라이언트 디바이스를 포함하고;상기 클라이언트 디바이스에서, 로컬 네트워크를 통해, 상기 제1 추가 클라이언트 디바이스로부터, 상기 제1 추가 후보 텍스트 표현을 수신하는 단계는: 클라이언트 디바이스에서, 로컬 네트워크를 통해, 제2 추가 클라이언트 디바이스로부터, 상기 음성 발화의 제2 추가 후보 텍스트 표현을 수신하는 단계를 더 포함하며, 상기 제2 추가 클라이언트 디바이스에서 로컬적으로 생성된 음성 발화의 제2 추가 후보 텍스트 표현은 (a) 오디오 데이터 및/또는 (b) 제2 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 로컬적으로 추가로 검출된 오디오 데이터에 기초하며, 상기 음성 발화의 제2 추가 후보 텍스트 표현은 상기 오디오 데이터 및/또는 상기 제2 추가 클라이언트 디바이스에 로컬적으로 저장된 제2 추가 ASR 모델을 사용하여 로컬적으로 추가로 생성된 오디오 데이터를 프로세싱함으로써 생성되며; 및상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계는: 상기 음성 발화의 후보 텍스트 표현, 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현 및 상기 제2 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제2 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 청구항 1에 있어서, 상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계는:상기 음성 발화의 후보 텍스트 표현 또는 상기 음성 발화의 제1 추가 후보 텍스트 표현 중 하나를 무작위로 선택하는 단계; 및상기 무작위 선택에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 1에 있어서, 상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계는:상기 후보 텍스트 표현이 텍스트 표현일 확률을 나타내는 후보 텍스트 표현의 신뢰 점수를 결정하는 단계, 상기 신뢰 점수는 상기 클라이언트 디바이스의 하나 이상의 디바이스 파라미터에 기초하며;상기 추가 후보 텍스트 표현이 텍스트 표현일 추가 확률을 나타내는 추가 후보 텍스트 표현의 추가 신뢰 점수를 결정하는 단계, 상기 추가 신뢰 점수는 상기 추가 클라이언트 디바이스의 하나 이상의 추가 디바이스 파라미터에 기초하며;상기 신뢰 점수와 상기 추가 신뢰 점수를 비교하는 단계; 및상기 비교에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 1 또는 청구항 4에 있어서, 상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계는:상기 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 상기 오디오 데이터의 품질을 나타내는 오디오 품질 값을 결정하는 단계;상기 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 추가 오디오 데이터의 품질을 나타내는 추가 오디오 품질 값을 결정하는 단계;상기 오디오 품질 값과 상기 추가 오디오 품질 값을 비교하는 단계; 및상기 비교에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 1, 청구항 4 또는 청구항 5에 있어서, 상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계는:상기 클라이언트 디바이스에 로컬적으로 저장된 ASR 모델의 품질을 나타내는 ASR 품질 값을 결정하는 단계;상기 추가 클라이언트 디바이스에 로컬적으로 저장된 추가 ASR 모델의 품질을 나타내는 추가 ASR 품질 값을 결정하는 단계;상기 ASR 품질 값과 상기 추가 ASR 품질 값을 비교하는 단계; 및상기 비교에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 임의의 선행하는 청구항에 있어서, 상기 음성 발화의 상기 제1 추가 후보 텍스트 표현은 복수의 가설들을 포함하며, 상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계는:상기 클라이언트 디바이스를 사용하여 상기 복수의 가설들의 순위를 재지정하는 단계; 및상기 음성 발화의 후보 텍스트 표현 및 재순위화된 복수의 가설들에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 임의의 선행하는 청구항에 있어서, 상기 클라이언트 디바이스에서, 로컬 네트워크를 통해, 상기 제1 추가 클라이언트 디바이스로부터, 상기 음성 발화의 제1 추가 후보 텍스트 표현을 수신하기 전에:(a) 오디오 데이터 및/또는 (b) 상기 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 로컬적으로 검출된 오디오 데이터에 기초하여 상기 제1 추가 클라이언트 디바이스에서 로컬적으로 음성 발화의 제1 추가 후보 표현을 생성할지 여부를 결정하는 단계를 포함하며, 상기 (a) 오디오 데이터 및/또는 (b) 상기 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 로컬적으로 검출된 오디오 데이터에 기초하여 상기 제1 추가 클라이언트 디바이스에서 로컬적으로 음성 발화의 제1 추가 후보 표현을 생성할지 여부를 결정하는 단계는: 상기 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 상기 오디오 데이터의 품질을 나타내는 오디오 품질 값을 결정하는 단계; 상기 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 상기 로컬적으로 검출된 오디오 데이터의 품질을 나타내는 추가 오디오 품질 값을 결정하는 단계; 상기 오디오 품질 값과 상기 추가 오디오 품질 값을 비교하는 단계; 및 상기 비교에 기초하여 (a) 오디오 데이터 및/또는 (b) 상기 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 로컬적으로 검출된 오디오 데이터에 기초하여 상기 제1 추가 클라이언트 디바이스에서 로컬적으로 음성 발화의 제1 추가 후보 표현을 생성할지 여부를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 8에 있어서, 상기 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 상기 오디오 데이터의 품질을 나타내는 오디오 품질 값을 결정하는 단계는: 상기 클라이언트 디바이스의 하나 이상의 마이크를 식별하는 단계; 및 상기 클라이언트 디바이스의 하나 이상의 마이크에 기초하여 상기 오디오 품질 값을 결정하는 단계를 포함하며; 그리고 상기 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 상기 로컬적으로 검출된 오디오 데이터의 품질을 나타내는 추가 오디오 품질 값을 결정하는 단계는: 상기 제1 추가 클라이언트 디바이스의 하나 이상의 제1 추가 마이크를 식별하는 단계; 및 상기 제1 추가 클라이언트 디바이스의 하나 이상의 제1 추가 마이크에 기초하여 추가 오디오 품질 값을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 8 또는 청구항 9에 있어서, 상기 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 상기 오디오 데이터의 품질을 나타내는 오디오 품질 값을 결정하는 단계는: 상기 음성 발화를 캡처하는 오디오 데이터 프로세싱에 기초하여 신호 대 잡음비 값을 생성하는 단계; 및 상기 신호 대 잡음비 값에 기초하여 상기 오디오 품질 값을 결정하는 단계를 포함하며; 그리고 상기 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 상기 로컬적으로 검출된 오디오 데이터의 품질을 나타내는 추가 오디오 품질 값을 결정하는 단계는: 상기 음성 발화를 캡처하는 오디오 데이터 프로세싱에 기초하여 추가 신호 대 잡음비 값을 생성하는 단계; 및 상기 추가 신호 대 잡음비 값에 기초하여 상기 추가 오디오 품질 값을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 임의의 선행하는 청구항에 있어서,상기 클라이언트 디바이스에서, 로컬 네트워크를 통해, 제1 추가 클라이언트 디바이스로부터, 상기 음성 발화의 제1 추가 후보 텍스트 표현을 수신하기 전에, 상기 음성 발화의 제1 추가 후보 텍스트 표현에 대한 요청을 상기 제1 추가 클라이언트 디바이스에 전송할지 여부를 결정하는 단계;상기 음성 발화의 제1 추가 후보 텍스트 표현에 대한 요청을 제1 추가 클라이언트 디바이스에 전송하기로 결정한 것에 응답하여, 상기 음성 발화의 제1 추가 후보 텍스트 표현에 대한 요청을 제1 추가 클라이언트 디바이스에 전송하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 청구항 11에 있어서, 상기 음성 발화의 제1 추가 후보 텍스트 표현에 대한 요청을 상기 제1 추가 클라이언트 디바이스에 전송할지 여부를 결정하는 단계는:핫워드 모델을 사용하여 사용자의 음성 발화를 캡처하는 오디오 데이터의 적어도 일부를 프로세싱하는 것에 기초하여, 핫워드 신뢰 점수를 결정하는 단계, 상기 핫워드 신뢰 점수는 상기 오디오 데이터의 적어도 일부가 핫워드를 포함하는지 여부의 확률을 나타내며;상기 핫워드 신뢰 점수가 하나 이상의 조건을 만족하는지 여부를 결정하는 단계, 상기 핫워드 신뢰 점수가 하나 이상의 조건을 만족하는지 여부를 결정하는 단계는 상기 핫워드 신뢰 점수가 임계값을 만족하는지 여부를 결정하는 단계를 포함하며;상기 핫워드 신뢰 점수가 임계값을 만족한다는 결정에 응답하여, 상기 핫워드 신뢰 점수가 상기 오디오 데이터의 적어도 일부가 핫워드를 포함할 약한 확률을 나타내는지 여부를 결정하는 단계; 및상기 핫워드 신뢰 점수가 상기 오디오 데이터의 적어도 일부가 핫워드를 포함할 약한 확률을 나타낸다는 결정에 응답하여, 상기 음성 발화의 제1 추가 후보 텍스트 표현에 대한 요청을 제1 추가 클라이언트 디바이스에 전송하기로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 하나 이상의 프로세서들에 의해 실행될 때 상기 하나 이상의 프로세서들로 하여금 동작들을 수행하게 하는 명령어들을 저장하도록 구성된 비일시적 컴퓨터 판독가능 매체에 있어서, 상기 동작들은:클라이언트 디바이스에서 사용자의 음성 발화를 캡처하는 오디오 데이터를 검출하는 동작, 상기 클라이언트 디바이스는 하나 이상의 추가 클라이언트 디바이스가 있는 환경에 있으며 로컬 네트워크를 통해 하나 이상의 추가 클라이언트 디바이스와 로컬 통신 상태에 있고, 상기 하나 이상의 추가 클라이언트 디바이스는 적어도 제1 추가 클라이언트 디바이스를 포함하며;클라이언트 디바이스에서, 상기 음성 발화의 후보 텍스트 표현을 생성하기 위해 클라이언트 디바이스에 로컬적으로 저장된 자동 스피치 인식(&quot;ASR&quot;) 모델을 사용하여 상기 오디오 데이터를 프로세싱하는 동작;클라이언트 디바이스에서, 로컬 네트워크를 통해, 제1 추가 클라이언트 디바이스로부터, 상기 음성 발화의 제1 추가 후보 텍스트 표현을 수신하는 동작, 상기 제1 추가 클라이언트 디바이스에서 로컬적으로 생성된 음성 발화의 제1 추가 후보 텍스트 표현은 (a) 오디오 데이터 및/또는 (b) 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 로컬적으로 검출된 오디오 데이터에 기초하며, 상기 음성 발화의 제1 추가 후보 텍스트 표현은 상기 오디오 데이터 및/또는 상기 제1 추가 클라이언트 디바이스에 로컬적으로 저장된 제1 추가 ASR 모델을 사용하여 로컬적으로 생성된 오디오 데이터를 프로세싱함으로써 생성되며; 및상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 동작을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>14. 시스템으로서,하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행될 때 상기 하나 이상의 프로세서로 하여금 동작들을 수행하게 하는 명령어들을 저장하도록 구성된 메모리를 포함하며, 상기 동작들은:클라이언트 디바이스에서 사용자의 음성 발화를 캡처하는 오디오 데이터를 검출하는 동작, 상기 클라이언트 디바이스는 하나 이상의 추가 클라이언트 디바이스가 있는 환경에 있으며 로컬 네트워크를 통해 하나 이상의 추가 클라이언트 디바이스와 로컬 통신 상태에 있고, 상기 하나 이상의 추가 클라이언트 디바이스는 적어도 제1 추가 클라이언트 디바이스를 포함하며;클라이언트 디바이스에서, 상기 음성 발화의 후보 텍스트 표현을 생성하기 위해 클라이언트 디바이스에 로컬적으로 저장된 자동 스피치 인식(&quot;ASR&quot;) 모델을 사용하여 상기 오디오 데이터를 프로세싱하는 동작;클라이언트 디바이스에서, 로컬 네트워크를 통해, 제1 추가 클라이언트 디바이스로부터, 상기 음성 발화의 제1 추가 후보 텍스트 표현을 수신하는 동작, 상기 제1 추가 클라이언트 디바이스에서 로컬적으로 생성된 음성 발화의 제1 추가 후보 텍스트 표현은 (a) 오디오 데이터 및/또는 (b) 제1 추가 클라이언트 디바이스에서 검출된 음성 발화를 캡처하는 로컬적으로 검출된 오디오 데이터에 기초하며, 상기 음성 발화의 제1 추가 후보 텍스트 표현은 상기 오디오 데이터 및/또는 상기 제1 추가 클라이언트 디바이스에 로컬적으로 저장된 제1 추가 ASR 모델을 사용하여 로컬적으로 생성된 오디오 데이터를 프로세싱함으로써 생성되며; 및상기 음성 발화의 후보 텍스트 표현 및 상기 제1 추가 클라이언트 디바이스에 의해 생성된 음성 발화의 제1 추가 후보 텍스트 표현에 기초하여 상기 음성 발화의 텍스트 표현을 결정하는 동작을 포함하는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SHARIFI, Matthew</engName><name>샤리피 매튜</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>CARBUNE, Victor</engName><name>카분 빅터</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.03.11</priorityApplicationDate><priorityApplicationNumber>17/198,679</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.10.04</receiptDate><receiptNumber>1-1-2023-1085579-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.10.10</receiptDate><receiptNumber>1-5-2023-0159433-19</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237033835.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c932792e67d1a5c8586f0e2ba7b8b7c04159f0b9ef6661c7f8e8955e888cba0faca05fc4c4576a71d7a92bcd34fcf2641581415c8884c6e391f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf462278bba2e48873ae8ba60e0f4bfe1cafad930ab6382e116c44b265f6b85c285db1964cf7f199b1652d84b2fe1fbd9c686b9f26f6e31e9a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>