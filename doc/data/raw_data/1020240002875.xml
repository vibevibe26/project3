<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:03:59.359</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0002875</applicationNumber><claimCount>17</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공지능을 이용한 음성 인식기를 개인화하기 위한 방법 및 그 장치</inventionTitle><inventionTitleEng>A METHOD AND APPARATUS FOR PERSONALIZING SPEECH RECOGNITION  USING ARTIFICIAL INTELLIGENCE</inventionTitleEng><openDate>2025.07.15</openDate><openNumber>10-2025-0108295</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.01.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 음성 신호를 수신하는 단계; 사전 학습된 제1 인공지능 알고리즘 모델에서 상기 음성 신호를 입력으로 하여 상기 음성 신호에 상응하는 텍스트를 생성하는 단계를 포함하고, 제1 모델 파라미터를 포함하는 제1 인공지능 알고리즘 모델은: 합성 음성 및 참조 텍스트를 입력으로 하여 제1 예상 텍스트를 출력하고, 상기 제1 예상 텍스트와 상기 참조 텍스트를 기반으로 제1 손실을 추출하고, 상기 제1 손실을 기반으로 첫번째 사전 학습을 수행하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 제2 모델 파라미터를 포함하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 상기 합성 음성 및 상기 참조 텍스트를 입력으로 하여 제2 예상 텍스트를 출력하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 상기 제2 예상 텍스트와 상기 참조 텍스트를 기반으로 제2 손실을 추출하고, 상기 전자 장치는 상기 제1 손실 및 상기 제2 손실의 비율인 손실률을 결정하고, 상기 손실률이 임계값 이하인 경우 상기 제2 모델 파라미터와 상기 제2 손실을 기반으로 적응 파라미터를 결정하고, 상기 적응 파라미터와 상기 제2 모델 파라미터를 기반으로 제3 모델 파라미터를 결정하고, 두번째 학습된 제1 인공지능 알고리즘 모델은 상기 제3 모델 파라미터를 포함하도록 구성되도록, 상기 제1 인공지능 알고리즘 모델이 반복되어 사전 학습될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서,음성 신호를 수신하는 단계;사전 학습된 제1 인공지능 알고리즘 모델에서 상기 음성 신호를 입력으로 하여 상기 음성 신호에 상응하는 텍스트를 생성하는 단계를 포함하고,제1 모델 파라미터를 포함하는 제1 인공지능 알고리즘 모델은: 합성 음성 및 참조 텍스트를 입력으로 하여 제1 예상 텍스트를 출력하고, 상기 제1 예상 텍스트와 상기 참조 텍스트를 기반으로 제1 손실을 추출하고, 상기 제1 손실을 기반으로 첫번째 사전 학습을 수행하고,상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 제2 모델 파라미터를 포함하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은:상기 합성 음성 및 상기 참조 텍스트를 입력으로 하여 제2 예상 텍스트를 출력하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 상기 제2 예상 텍스트와 상기 참조 텍스트를 기반으로 제2 손실을 추출하고,상기 전자 장치는:상기 제1 손실 및 상기 제2 손실의 비율인 손실률을 결정하고, 상기 손실률이 임계값 이하인 경우 상기 제2 모델 파라미터와 상기 제2 손실을 기반으로 적응 파라미터를 결정하고, 상기 적응 파라미터와 상기 제2 모델 파라미터를 기반으로 제3 모델 파라미터를 결정하고,두번째 사전 학습된 제1 인공지능 알고리즘 모델은 상기 제3 모델 파라미터를 포함하게 구성되도록, 상기 제1 인공지능 알고리즘 모델이 반복되어 사전 학습되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 전자 장치는:상기 손실률이 상기 임계값보다 큰 경우 상기 제3 모델 파라미터를 상기 제2 모델 파라미터로 결정하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 사전 학습된 제1 인공지능 알고리즘 모델은 음성 인코더, 예측 네트워크, 조인트 네트워크를 포함하고,상기 음성 인코더는 비전사 음성 데이터로 자기 지도 학습 방식을 통해 사전 학습된 인공지능 알고리즘 모델인 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 음성 인코더는 &quot;data2vec&quot; 모델의 구조를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 음성 인코더는 컨볼루션 신경 망(convolutional neural network: CNN), 트랜스포머 하위 블록단, 트랜스포머 상위 블록단을 포함하고,상기 CNN 및 상기 트랜스포머 하위 블록단의 파라미터는 일정하게 고정되는 방법.</claim></claimInfo><claimInfo><claim>6. 제3항에 있어서,상기 예측 네트워크는 컨볼루션 신경 망(convolutional neural network: CNN), 임베딩 레이어를 포함하고,상기 임베딩 레이어의 파라미터는 일정하게 고정되는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 임계값은 1+이고,상기 는 하이퍼 파라미터이고,상기 는 고정 값으로 결정되는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 합성 음성은 상기 참조 텍스트를 기반으로 제2 인공지능 알고리즘 모델에서 합성되어 생성되는 방법.</claim></claimInfo><claimInfo><claim>9. 전자 장치에 있어서,메모리;모뎀; 및상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고,상기 프로세서는:음성 신호를 수신하고,사전 학습된 제1 인공지능 알고리즘 모델에서 상기 음성 신호를 입력으로 하여 상기 음성 신호에 상응하는 텍스트를 생성하도록 구성되고,제1 모델 파라미터를 포함하는 제1 인공지능 알고리즘 모델은: 합성 음성 및 참조 텍스트를 입력으로 하여 제1 예상 텍스트를 출력하고, 상기 제1 예상 텍스트와 상기 참조 텍스트를 기반으로 제1 손실을 추출하고, 상기 제1 손실을 기반으로 첫번째 사전 학습을 수행하고,상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 제2 모델 파라미터를 포함하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은:상기 합성 음성 및 상기 참조 텍스트를 입력으로 하여 제2 예상 텍스트를 출력하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 상기 제2 예상 텍스트와 상기 참조 텍스트를 기반으로 제2 손실을 추출하고,상기 프로세서는:상기 제1 손실 및 상기 제2 손실의 비율인 손실률을 결정하고, 상기 손실률이 임계값 이하인 경우 상기 제2 모델 파라미터와 상기 제2 손실을 기반으로 적응 파라미터를 결정하고, 상기 적응 파라미터와 상기 제2 모델 파라미터를 기반으로 제3 모델 파라미터를 결정하고,두번째 학습된 제1 인공지능 알고리즘 모델은 상기 제3 모델 파라미터를 포함하게 구성되도록, 상기 제1 인공지능 알고리즘 모델이 반복되어 사전 학습되는 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 프로세서는:상기 손실률이 상기 임계값보다 큰 경우 상기 제3 모델 파라미터를 상기 제2 모델 파라미터로 결정하도록 구성되는 전자 장치.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 사전 학습된 제1 인공지능 알고리즘 모델은 음성 인코더, 예측 네트워크, 조인트 네트워크를 포함하고,상기 음성 인코더는 비전사 음성 데이터로 자기 지도 학습 방식을 통해 사전 학습된 인공지능 알고리즘 모델인 전자 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 음성 인코더는 &quot;data2vec&quot; 모델의 구조를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 음성 인코더는 컨볼루션 신경 망(convolutional neural network: CNN), 트랜스포머 하위 블록단, 트랜스포머 상위 블록단을 포함하고,상기 CNN 및 상기 트랜스포머 하위 블록단의 파라미터는 일정하게 고정되는 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,상기 예측 네트워크는 컨볼루션 신경 망(convolutional neural network: CNN), 임베딩 레이어를 포함하고,상기 임베딩 레이어의 파라미터는 일정하게 고정되는 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제9항에 있어서,상기 임계값은 1+로 나타내고,상기 는 하이퍼 파라미터이고,상기 는 고정 값으로 결정되는 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제9항에 있어서,상기 합성 음성은 상기 참조 텍스트를 기반으로 제2 인공지능 알고리즘 모델에서 합성되어 생성되는 전자 장치.</claim></claimInfo><claimInfo><claim>17. 프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 음성을 인식하기 위하여 매체에 저장된 프로그램으로서,음성 신호를 수신하는 단계;사전 학습된 제1 인공지능 알고리즘 모델에서 상기 음성 신호를 입력으로 하여 상기 음성 신호에 상응하는 텍스트를 생성하는 단계를 포함하고,제1 모델 파라미터를 포함하는 제1 인공지능 알고리즘 모델은: 합성 음성 및 참조 텍스트를 입력으로 하여 제1 예상 텍스트를 출력하고, 상기 제1 예상 텍스트와 상기 참조 텍스트를 기반으로 제1 손실을 추출하고, 상기 제1 손실을 기반으로 첫번째 사전 학습을 수행하고,상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 제2 모델 파라미터를 포함하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은:상기 합성 음성 및 상기 참조 텍스트를 입력으로 하여 제2 예상 텍스트를 출력하고, 상기 첫번째 사전 학습을 수행한 제1 인공지능 알고리즘 모델은 상기 제2 예상 텍스트와 상기 참조 텍스트를 기반으로 제2 손실을 추출하고,상기 프로세서는:상기 제1 손실 및 상기 제2 손실의 비율인 손실률을 결정하고, 상기 손실률이 임계값보다 작은 경우 상기 제2 모델 파라미터와 상기 제2 손실을 기반으로 적응 파라미터를 결정하고, 상기 적응 파라미터와 상기 제2 모델 파라미터를 기반으로 제3 모델 파라미터를 결정하고,두번째 학습된 제1 인공지능 알고리즘 모델은 상기 제3 모델 파라미터를 포함하게 구성되도록, 상기 제1 인공지능 알고리즘 모델이 반복되어 사전 학습되는 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성동구...</address><code>220040114276</code><country>대한민국</country><engName>IUCF-HYU (Industry-University Cooperation Foundation Hanyang University)</engName><name>한양대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 성동구...</address><code> </code><country> </country><engName>JANG, Joon Hyuk</engName><name>장준혁</name></inventorInfo><inventorInfo><address>서울특별시 성동구...</address><code> </code><country> </country><engName>KIM, Dong Hyun</engName><name>김동현</name></inventorInfo><inventorInfo><address>서울특별시 성동구...</address><code> </code><country> </country><engName>LEE, Jae Hong</engName><name>이재홍</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서초구 서초대로 *** (서초동) ***호(모티버스특허법률사무소)</address><code>920140005853</code><country>대한민국</country><engName>YOON JONGWON</engName><name>윤종원</name></agentInfo><agentInfo><address>서울 서초구 서초대로 *** (서초동) ***호(모티버스특허법률사무소)</address><code>920100003859</code><country>대한민국</country><engName>Chung Sungjoon</engName><name>정성준</name></agentInfo><agentInfo><address>서울 서초구 서초대로 *** (서초동) ***호(모티버스특허법률사무소)</address><code>920120011733</code><country>대한민국</country><engName>Choi Young Soo</engName><name>최영수</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.01.08</receiptDate><receiptNumber>1-1-2024-0025264-98</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2024.01.17</receiptDate><receiptNumber>1-1-2024-0061873-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240002875.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9366f162581ea5e2a35dea60ca3df1326e6677f894d30ea7edcb41e4d46c2319d123925b1e476eaa3fd775aa8de84fa5090ffb49a75a1eeca8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf10656c342785203de5b98f896ab8c27ac11079eaf33d5552991cff2e9ccc97fbf8cd04468610cd2caf2de4f8f0b14a96cfdf658711170c47</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>