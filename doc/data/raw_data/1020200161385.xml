<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:17.617</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.11.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0161385</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>동적 특징 선택에 기반한 이미지 정합 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS OF IMAGE CORRESPONDENCE BASED ON  DYNAMIC FEATURE SELECTION</inventionTitleEng><openDate>2022.01.28</openDate><openNumber>10-2022-0011559</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.10</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4007</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 동적 특징 선택에 기반한 이미지 정합 방법 및 장치가 제공된다. 일 실시예에 따르면, 그 방법은 복수의 특징 맵 쌍들의 각 특징 맵 쌍의 특성을 고려하여 복수의 특징 맵 쌍들 중에 일부의 특징 맵 쌍들을 선택하고, 선택된 일부의 특징 맵 쌍들에 기초하여 입력 이미지 쌍에 관한 정합 결과를 생성하는 단계들을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 이미지 쌍의 입력에 따른 CNN(convolutional neural network)의 복수의 레이어들의 출력에 대응하는 복수의 특징 맵 쌍들을 획득하는 단계;상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍의 특성을 고려하여 상기 복수의 특징 맵 쌍들 중에 일부의 특징 맵 쌍들을 선택하는 단계;상기 선택된 상기 일부의 특징 맵 쌍들에 기초하여 하이퍼 특징 맵 쌍을 생성하는 단계; 및상기 하이퍼 특징 맵 쌍의 상관관계에 기초하여 상기 입력 이미지 쌍에 관한 정합 결과를 생성하는 단계를 포함하는 이미지 정합 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 CNN의 상기 복수의 레이어들은 상기 CNN의 적어도 하나의 중간 레이어를 포함하고,상기 복수의 특징 맵 쌍들은 상기 CNN의 상기 적어도 하나의 중간 레이어에 의해 출력된 적어도 하나의 중간 특징 맵 쌍을 포함하는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 복수의 특징 맵 쌍들을 획득하는 상기 단계는상기 입력 이미지 쌍의 제1 입력 이미지를 상기 CNN에 입력하여 상기 CNN의 상기 복수의 레이어들에서 출력된 제1 특징 맵들을 획득하는 단계;상기 입력 이미지 쌍의 제2 입력 이미지를 상기 CNN에 입력하여 상기 CNN의 상기 복수의 레이어들에서 출력된 제2 특징 맵들을 획득하는 단계; 및상기 CNN의 상기 복수의 레이어들에 따라 상기 제1 특징 맵들 및 상기 제2 특징 맵들을 페어링하여 상기 복수의 특징 맵 쌍들을 결정하는 단계를 포함하는, 이미지 정합 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 일부의 특징 맵 쌍들을 선택하는 상기 단계는상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍에 관한 적어도 하나의 뉴럴 네트워크의 출력에 기초하여 상기 복수의 특징 맵 쌍들 중에 상기 일부의 특징 맵 쌍들을 동적으로 선택하는 단계를 포함하는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 적어도 하나의 뉴럴 네트워크는상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍에 대응하는 채널 방향의 특징 벡터를 관련성 벡터로 인코딩하는 제1 뉴럴 네트워크; 및채널 방향의 차원을 감소시켜서 상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍을 저-차원의 특징 맵 쌍으로 변환하는 제2 뉴럴 네트워크를 포함하는, 이미지 정합 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 적어도 하나의 뉴럴 네트워크는설정 파라미터에 의해 정해진 선택 비율에 기초하여 상기 복수의 특징 맵 쌍들 중에 상기 일부의 특징 맵 쌍들을 선택하도록 트레이닝되는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 일부의 특징 맵 쌍들을 선택하는 상기 단계는상기 복수의 특징 맵 쌍들의 제1 특징 맵 쌍에 대응하는 제1 특징 벡터를 결정하는 단계;상기 제1 특징 벡터의 입력에 따른 다층 퍼셉트론의 출력에 대응하는 제1 관련성 벡터를 획득하는 단계; 및상기 제1 관련성 벡터의 값에 기초하여 상기 제1 특징 맵 쌍을 선택할지 결정하는 단계를 포함하는, 이미지 정합 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 일부의 특징 맵 쌍들을 선택하는 상기 단계는상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍의 특성을 고려하기 위해 상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍을 병렬적으로 처리하여 상기 복수의 특징 맵 쌍들 중에 상기 일부의 특징 맵 쌍들을 선택하는 단계를 포함하는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 일부의 특징 맵 쌍들을 선택하는 상기 단계는설정 파라미터에 의해 정해진 선택 비율에 기초하여 상기 복수의 특징 맵 쌍들 중에 상기 일부의 특징 맵 쌍들을 선택하는 단계를 포함하는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 설정 파라미터는 어플리케이션에 의해 요구되는 속도 및 정확도 중 적어도 하나에 기초하여 결정되는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 하이퍼 특징 맵 쌍을 생성하는 상기 단계는상기 선택된 상기 일부의 특징 맵 쌍들에 기초한 업샘플링 및 연쇄화를 수행하여 상기 하이퍼 특징 맵 쌍을 생성하는 단계를 포함하는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 하이퍼 특징 맵 쌍을 생성하는 상기 단계는상기 선택된 상기 일부의 특징 맵 쌍들에 대응하는 저-차원의 특징 맵 쌍들을 결합하여 상기 하이퍼 특징 맵 쌍을 생성하는 단계를 포함하는,이미지 정합 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항의 방법을 수행하는 명령어들을 포함하는 하나 이상의 프로그램을 저장한 컴퓨터 판독 가능 저장매체.</claim></claimInfo><claimInfo><claim>14. 프로세서; 및상기 프로세서에서 실행가능한 명령어들을 포함하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에서 실행되면, 상기 프로세서는입력 이미지 쌍의 입력에 따른 CNN(convolutional neural network)의 복수의 레이어들의 출력에 대응하는 복수의 특징 맵 쌍들을 획득하고,상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍의 특성을 고려하여 상기 복수의 특징 맵 쌍들 중에 일부의 특징 맵 쌍들을 선택하고,상기 선택된 상기 일부의 특징 맵 쌍들에 기초하여 하이퍼 특징 맵 쌍을 생성하고,상기 하이퍼 특징 맵 쌍의 상관관계에 기초하여 상기 입력 이미지 쌍에 관한 정합 결과를 생성하는,이미지 정합 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 CNN의 상기 복수의 레이어들은 상기 CNN의 적어도 하나의 중간 레이어를 포함하고,상기 복수의 특징 맵 쌍들은 상기 CNN의 상기 적어도 하나의 중간 레이어에 의해 출력된 적어도 하나의 중간 특징 맵 쌍을 포함하는,이미지 정합 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 프로세서는상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍에 관한 적어도 하나의 뉴럴 네트워크의 출력에 기초하여 상기 복수의 특징 맵 쌍들 중에 상기 일부의 특징 맵 쌍들을 동적으로 선택하는,이미지 정합 장치.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 프로세서는설정 파라미터에 의해 정해진 선택 비율에 기초하여 상기 복수의 특징 맵 쌍들 중에 상기 일부의 특징 맵 쌍들을 선택하는,이미지 정합 장치.</claim></claimInfo><claimInfo><claim>18. 입력 이미지 쌍의 적어도 하나의 입력 이미지를 생성하는 카메라; 및상기 입력 이미지 쌍의 입력에 따른 CNN(convolutional neural network)의 복수의 레이어들의 출력에 대응하는 복수의 특징 맵 쌍들을 획득하고, 상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍의 특성을 고려하여 상기 복수의 특징 맵 쌍들 중에 일부의 특징 맵 쌍들을 선택하고, 상기 선택된 상기 일부의 특징 맵 쌍들에 기초하여 하이퍼 특징 맵 쌍을 생성하고, 상기 하이퍼 특징 맵 쌍의 상관관계에 기초하여 상기 입력 이미지 쌍에 관한 정합 결과를 생성하는, 프로세서를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 CNN의 상기 복수의 레이어들은 상기 CNN의 적어도 하나의 중간 레이어를 포함하고,상기 복수의 특징 맵 쌍들은 상기 CNN의 상기 적어도 하나의 중간 레이어에 의해 출력된 적어도 하나의 중간 특징 맵 쌍을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 프로세서는상기 복수의 특징 맵 쌍들의 각 특징 맵 쌍에 관한 적어도 하나의 뉴럴 네트워크의 출력에 기초하여 상기 복수의 특징 맵 쌍들 중에 상기 일부의 특징 맵 쌍들을 동적으로 선택하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo><applicantInfo><address>경상북도 포항시 남구...</address><code>220040433361</code><country>대한민국</country><engName>POSTECH Research and Business Development Foundation</engName><name>포항공과대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 동작구...</address><code>420170481940</code><country>대한민국</country><engName>HAN, Seung Ju</engName><name>한승주</name></inventorInfo><inventorInfo><address>경상북도 포항시 남구...</address><code> </code><country> </country><engName>CHO Min Su</engName><name>조민수</name></inventorInfo><inventorInfo><address>경상북도 포항시 남구...</address><code> </code><country> </country><engName>MIN Ju Hong</engName><name>민주홍</name></inventorInfo><inventorInfo><address>전라북도 전주시 덕진구...</address><code> </code><country> </country><engName>LEE Jong Min</engName><name>이종민</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420200167444</code><country>대한민국</country><engName>PARK, Chang Beom</engName><name>박창범</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2020.07.21</priorityApplicationDate><priorityApplicationNumber>1020200090560</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.11.26</receiptDate><receiptNumber>1-1-2020-1277743-29</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.10.10</receiptDate><receiptNumber>1-1-2023-1106615-32</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200161385.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a387a2122f8fb1b64d8d613f30e073c5cb3906867c473ba21805a6964f45898ecf585a9f4b8ca6c3bf34317a2d8d71987eb99267178825bb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfdf7c280f2d3c31a0998f496009d57ddee29d5c4e09b9d8a4a3a273e431a3c8160f0c7d8f6f9cebacb7ac610bc482ce537b50f04c12dde068</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>