<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:50.4150</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0183315</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>초해상화 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR SUPER RESOLUTION</inventionTitleEng><openDate>2024.05.17</openDate><openNumber>10-2024-0067765</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 초해상화 방법 및 장치에 관한 것이다. 일 실시 예에 따른 뉴럴 네트워크를 포함하는 초해상화 모델의 학습 방법은 입력 이미지에서 추출된 피처 및 참조 이미지에서 추출된 피처에 기초하여, 참조 이미지에서 입력 이미지의 특정 영역에 대응하는 참조 패치를 획득하는 단계, 입력 이미지의 특정 영역에 대응하는 정답 이미지의 정답 패치의 픽셀 값과 참조 패치의 픽셀 값에 기초하여, 참조 이미지에서 참조 패치의 위치를 조정하는 단계, 위치가 조정된 참조 패치에 기초하여, 초해상화 모델에서 출력된 입력 이미지의 초해상화 이미지를 획득하는 단계 및 초해상화 이미지 및 정답 이미지에 기초하여, 초해상화 모델을 학습시키는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 뉴럴 네트워크를 포함하는 초해상화 모델의 학습 방법에 있어서,입력 이미지에서 추출된 피처 및 참조 이미지에서 추출된 피처에 기초하여, 상기 참조 이미지에서 상기 입력 이미지의 특정 영역에 대응하는 참조 패치를 획득하는 단계;상기 입력 이미지의 특정 영역에 대응하는 정답 이미지의 정답 패치의 픽셀 값과 상기 참조 패치의 픽셀 값에 기초하여, 상기 참조 이미지에서 상기 참조 패치의 위치를 조정하는 단계;상기 위치가 조정된 참조 패치에 기초하여, 상기 초해상화 모델에서 출력된 상기 입력 이미지의 초해상화 이미지를 획득하는 단계; 및상기 초해상화 이미지 및 상기 정답 이미지에 기초하여, 상기 초해상화 모델을 학습시키는 단계를 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 입력 이미지의 특정 영역은 미리 정해진 개수의 픽셀들을 포함하는 상기 입력 이미지의 일부 영역을 포함하고,상기 참조 패치는 상기 입력 이미지의 특정 영역에 포함된 픽셀들에 대응하는 상기 참조 이미지의 픽셀들을 포함하는 상기 참조 이미지 내 일부 영역을 포함하며,상기 정답 패치는 상기 입력 이미지의 특정 영역에 포함된 픽셀들에 대응하는 상기 정답 이미지의 픽셀들을 포함하는 상기 정답 이미지 내 일부 영역을 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 참조 패치의 위치를 조정하는 단계는상기 참조 패치에 기초하여 결정된 검색 공간에서 상기 정답 패치에 포함된 픽셀 값들과 차이가 작은 픽셀들을 포함하도록 상기 참조 패치의 위치를 조정하는 단계를 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 검색 공간은 상기 참조 이미지에서 상기 참조 패치의 위치에 기초하여 결정된 미리 정해진 크기의 상기 참조 이미지 내 영역을 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 참조 패치의 위치를 조정하는 단계는상기 정답 패치의 픽셀 값 및 상기 참조 패치의 픽셀 값을 표준화하는 단계; 및상기 표준화된 정답 패치 및 상기 표준화된 참조 패치의 픽셀 값 비교에 기초하여, 상기 참조 이미지에서 상기 참조 패치의 위치를 조정하는 단계를 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 표준화하는 단계는상기 정답 패치에 포함된 픽셀 값들의 평균 및 표준 편차에 기초하여, 상기 정답 패치에 포함된 픽셀 값들을 표준화하는 단계; 및상기 참조 패치에 포함된 픽셀 값들의 평균 및 표준 편차에 기초하여, 상기 참조 패치에 포함된 픽셀 값들을 표준화하는 단계를 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 초해상화 모델을 학습시키는 단계는상기 초해상화 이미지 및 상기 정답 이미지의 차이에 기초한 손실 함수에 기초하여, 상기 초해상화 모델을 학습시키는 단계를 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 참조 이미지는 서로 다른 해상도로 촬영된 복수의 참조 이미지들을 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 참조 패치를 획득하는 단계는상기 입력 이미지에서 논플랫 영역을 추출하는 단계; 및상기 입력 이미지에서 추출된 피처 및 상기 참조 이미지에서 추출된 피처에 기초하여, 상기 입력 이미지의 상기 논플랫 영역에 속하는 상기 특정 영역에 대응하는 상기 참조 패치를 획득하는 단계를 포함하는,학습 방법.</claim></claimInfo><claimInfo><claim>10. 입력 이미지에서 추출된 피처 및 참조 이미지에서 추출된 피처에 기초하여, 상기 참조 이미지에서 상기 입력 이미지의 특정 영역에 대응하는 참조 패치를 획득하는 단계;상기 입력 이미지의 특정 영역의 픽셀 값과 상기 참조 패치의 픽셀 값에 기초하여, 상기 참조 이미지에서 상기 참조 패치의 위치를 조정하는 단계; 및상기 위치가 조정된 상기 참조 패치에 기초하여, 상기 입력 이미지의 초해상화 이미지를 생성하는 단계를 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 입력 이미지의 특정 영역은 미리 정해진 개수의 픽셀들을 포함하는 상기 입력 이미지의 일부 영역을 포함하고,상기 참조 패치는 상기 입력 이미지의 특정 영역에 포함된 픽셀들에 대응하는 상기 참조 이미지의 픽셀들을 포함하는 상기 참조 이미지 내 일부 영역을 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 참조 패치의 위치를 조정하는 단계는상기 참조 패치에 기초하여 결정된 검색 공간에서 상기 입력 이미지의 특정 영역의 픽셀 값들과 차이가 작은 픽셀들을 포함하도록 상기 참조 패치의 위치를 조정하는 단계를 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 검색 공간은 상기 참조 이미지에서 상기 참조 패치의 위치를 기준으로 결정된 미리 정해진 크기의 상기 참조 이미지 내 영역을 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,상기 참조 패치의 위치를 조정하는 단계는상기 입력 이미지의 특정 영역의 픽셀 값 및 상기 참조 패치의 픽셀 값을 표준화하는 단계; 및상기 표준화된 특정 영역 및 상기 표준화된 참조 패치의 픽셀 값 비교에 기초하여, 상기 참조 이미지에서 상기 참조 패치의 위치를 조정하는 단계를 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 표준화하는 단계는상기 입력 이미지의 특정 영역의 픽셀 값들의 평균 및 표준 편차에 기초하여, 상기 입력 이미지의 특정 영역의 픽셀 값들을 표준화하는 단계; 및상기 참조 패치에 포함된 픽셀 값들의 평균 및 표준 편차에 기초하여, 상기 참조 패치에 포함된 픽셀 값들을 표준화하는 단계를 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>16. 초해상화 모델에 의해 입력 이미지에서 추출된 피처 및 참조 이미지에서 추출된 피처에 기초하여, 상기 참조 이미지에서 상기 입력 이미지의 특정 영역에 대응하는 참조 패치를 획득하는 단계; 및상기 참조 패치에 기초하여, 상기 초해상화 모델에서 출력된 상기 입력 이미지의 초해상화 이미지를 획득하는 단계를 포함하고,상기 초해상화 모델은 학습 데이터 및 상기 학습 데이터의 특정 영역의 픽셀 값에 기초하여 추출된 참조 이미지의 참조 패치로부터 상기 학습 데이터의 초해상화 이미지를 출력하도록 학습된 뉴럴 네트워크를 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 초해상화 모델은 학습 방법에 의해 학습된 뉴럴 네트워크를 포함하고,상기 학습 방법은상기 초해상화 모델에 의해 학습 데이터에서 추출된 피처 및 참조 이미지에서 추출된 피처에 기초하여, 상기 참조 이미지에서 상기 학습 데이터의 특정 영역에 대응하는 참조 패치를 획득하는 단계;상기 학습 데이터의 특정 영역에 대응하는 정답 이미지의 정답 패치와 상기 참조 패치의 픽셀 값에 기초하여, 상기 참조 이미지에서 상기 참조 패치의 위치를 조정하는 단계;상기 위치가 조정된 참조 패치에 기초하여, 상기 초해상화 모델에서 출력된 상기 학습 데이터의 초해상화 이미지를 획득하는 단계; 및상기 초해상화 이미지 및 상기 정답 이미지에 기초하여, 상기 초해상화 모델을 학습시키는 단계를 포함하는,초해상화 방법.</claim></claimInfo><claimInfo><claim>18. 하드웨어와 결합되어 제1항 내지 제17항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>19. 입력 이미지에서 추출된 피처 및 참조 이미지에서 추출된 피처에 기초하여, 상기 참조 이미지에서 상기 입력 이미지의 특정 영역에 대응하는 참조 패치를 획득하고,상기 입력 이미지의 특정 영역의 픽셀 값과 상기 참조 패치의 픽셀 값에 기초하여, 상기 참조 이미지에서 상기 참조 패치의 위치를 조정하며,상기 위치가 조정된 상기 참조 패치에 기초하여, 상기 입력 이미지의 초해상화 이미지를 생성하는,프로세서를 포함하는,장치.</claim></claimInfo><claimInfo><claim>20. 초해상화 모델에 의해 입력 이미지에서 추출된 피처 및 참조 이미지에서 추출된 피처에 기초하여, 상기 참조 이미지에서 상기 입력 이미지의 특정 영역에 대응하는 참조 패치를 획득하고,상기 참조 패치에 기초하여, 상기 초해상화 모델에서 출력된 상기 입력 이미지의 초해상화 이미지를 획득하는,프로세서를 포함하고,상기 초해상화 모델은 학습 데이터 및 상기 학습 데이터의 특정 영역의 픽셀 값에 기초하여 추출된 참조 이미지의 참조 패치로부터 상기 학습 데이터의 초해상화 이미지를 출력하도록 학습된 뉴럴 네트워크를 포함하는,장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 성동구...</address><code>420220587545</code><country>대한민국</country><engName>JO, Younghyun</engName><name>조영현</name></inventorInfo><inventorInfo><address>경기도 화성...</address><code>420210524101</code><country>대한민국</country><engName>Ki, Sehwan</engName><name>기세환</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420200293177</code><country>대한민국</country><engName>KANG, Eunhee</engName><name>강은희</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420180786048</code><country>대한민국</country><engName>LEE, Hyong Euk</engName><name>이형욱</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.11.09</priorityApplicationDate><priorityApplicationNumber>1020220148369</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.23</receiptDate><receiptNumber>1-1-2022-1392554-96</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220183315.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936ce9252219f791d04363ae143078cd52295082bf56768102f606325c58fef884ee0e1d14e959b3dddf1ea1a0e5348282ab0411df040f8651</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf92fabec18568e91758d7a739c11686169939446f08a2fdcf514a1e46bf3d3ca9f10ddc7158b7427b29444c5cf360e8f4dbcdc365bf3e6b6f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>