<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:12.4112</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0032776</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>트래킹 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR TRACKING</inventionTitleEng><openDate>2025.09.16</openDate><openNumber>10-2025-0136125</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 예시적 실시예에 따른 트래킹 방법은, 생성부가, 백본(backbone)을 통해, 제1 프레임(frame)에 기초하여 제1 피처(feature)를 생성하는 단계, 생성부가, 객체 검출에 관한 제1 넥(neck)을 통해, 제1 피처에 기초하여 제1 객체에 대한 검출 결과를 나타내는 제1 검출 정보를 생성하는 단계, 생성부가, 객체 재식별(re-identification)에 관한 제2 넥을 통해, 제1 피처에 기초하여 제1 객체의 비주얼 피처(visual feature)에 대한 제1 피처 벡터를 생성하는 단계 및 트래킹부가, 제1 검출 정보 및 제1 피처 벡터에 기초하여 트래킹하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 생성부가, 백본(backbone)을 통해, 제1 프레임(frame)에 기초하여 제1 피처(feature)를 생성하는 단계;상기 생성부가, 객체 검출에 관한 제1 넥(neck)을 통해, 상기 제1 피처에 기초하여 제1 객체에 대한 검출 결과를 나타내는 제1 검출 정보를 생성하는 단계;상기 생성부가, 객체 재식별(re-identification)에 관한 제2 넥을 통해, 상기 제1 피처에 기초하여 상기 제1 객체의 비주얼 피처(visual feature)에 대한 제1 피처 벡터를 생성하는 단계; 및트래킹부가, 상기 제1 검출 정보 및 상기 제1 피처 벡터에 기초하여 트래킹하는 단계를 포함하는 트래킹(tracking) 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,학습부가, 상기 객체 재식별에 관하여 미리 학습된 제1 모델에 기초하여 상기 백본, 상기 제1 넥 및 상기 제2 넥을 포함하는 제2 모델을 학습시키는 단계를 더 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,상기 제2 모델을 학습시키는 단계는,상기 학습부가, 상기 백본 및 상기 제1 넥의 파라미터들을 고정시킨 상태에서 상기 제2 넥을 학습시키는 단계를 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>4. 제2 항에 있어서,상기 제2 모델을 학습시키는 단계는,상기 생성부가, 상기 제1 모델을 통해, 제1 입력 이미지에 기초하여 제2 피처 벡터를 생성하는 단계;상기 생성부가, 상기 백본 및 상기 제2 넥을 통해, 제2 입력 이미지에 기초하여 제3 피처 벡터를 생성하는 단계;상기 생성부가, 상기 제2 피처 벡터 및 상기 제3 피처 벡터에 기초하여 제1 로스를 생성하는 단계;상기 학습부가, 상기 제1 로스에 기초하여 상기 제2 넥을 학습시키는 단계를 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서,상기 제2 모델을 학습시키는 단계는,상기 생성부가, 상기 제3 피처 벡터 및 GT(Ground Truth)에 기초하여 제2 로스를 생성하는 단계; 및상기 학습부가, 상기 제1 로스 및 상기 제2 로스에 기초하여 상기 제2 넥을 학습시키는 단계를 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 제2 로스를 생성하는 단계는,상기 생성부가, 클래시피케이션(classification) 네트워크를 통해, 상기 제3 피처 벡터에 기초하여 클래시피케이션 벡터를 생성하는 단계;상기 생성부가, 상기 클래시피케이션 벡터와 상기 GT를 비교함으로써 상기 제2 로스를 생성하는 단계를 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>7. 제5 항에 있어서,상기 GT는,하드 레이블링(hard labeling)된 데이터를 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>8. 제4 항에 있어서,상기 제2 피처 벡터는,소프트 레이블링(soft labeling)된 데이터를 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>9. 제4 항에 있어서,상기 제1 입력 이미지는,상기 제2 입력 이미지에서 객체 영역을 추출한 이미지인 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>10. 제1 항에 있어서,상기 트래킹하는 단계는,상기 생성부가, 상기 제1 검출 정보와 상기 제1 피처 벡터가 합쳐진 제1 어소시에이션 벡터(association vector)를 생성하는 단계;상기 생성부가, 상기 백본을 통해, 상기 제1 프레임의 다음 프레임인 제2 프레임에 기초하여 제2 피처를 생성하는 단계;상기 생성부가, 상기 제1 넥을 통해, 상기 제2 피처에 기초하여 복수의 제2 객체들에 대한 제2 검출 정보들을 생성하는 단계;상기 생성부가, 상기 제2 넥을 통해, 상기 제2 피처에 기초하여 상기 복수의 제2 객체들의 비주얼 피처들에 대한 제4 피처 벡터들을 생성하는 단계;상기 생성부가, 각각의 상기 제2 검출 정보들과 각각의 상기 제4 피처 벡터들이 합쳐진 제2 어소시에이션 벡터들을 생성하는 단계;상기 트래킹부가, 상기 제2 어소시에이션 벡터들 중 상기 제1 어소시에이션 벡터와 거리가 가장 가까운 어소시에이션 벡터를 갖는 객체를 상기 제1 객체와 어소시에이션함으로써 트래킹하는 단계를 포함하는 것을 특징으로 하는 트래킹 방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨터로 실행 가능한 명령어들(computer-executable instructions)을 저장하도록 구성된 메모리; 및상기 메모리에 액세스(access)하여 상기 명령어들을 실행하도록 구성된 적어도 하나 이상의 프로세서를 포함하고,상기 적어도 하나 이상의 프로세서는, 생성부를 통해, 백본(backbone)을 사용함으로써 제1 프레임(frame)에 기초하여 제1 피처(feature)를 생성하고, 객체 검출에 관한 제1 넥(neck)을 사용함으로써 상기 제1 피처에 기초하여 제1 객체에 대한 검출 결과를 나타내는 제1 검출 정보를 생성하고, 객체 재식별(re-identification)에 관한 제2 넥을 사용함으로써 상기 제1 피처에 기초하여 상기 제1 객체의 비주얼 피처(visual feature)에 대한 제1 피처 벡터를 생성하고,트래킹부를 통해, 상기 제1 검출 정보 및 상기 제1 피처 벡터에 기초하여 트래킹하도록 구성된 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 적어도 하나 이상의 프로세서는,학습부를 통해, 상기 객체 재식별에 관하여 미리 학습된 제1 모델에 기초하여 상기 백본, 상기 제1 넥 및 상기 제2 넥을 포함하는 제2 모델을 학습시키도록 구성된 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 학습부를 통해, 상기 백본 및 상기 제1 넥의 파라미터들을 고정시킨 상태에서 상기 제2 넥을 학습시키도록 구성된 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>14. 제12 항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 생성부를 통해, 상기 제1 모델을 사용함으로써 제1 입력 이미지에 기초하여 제2 피처 벡터를 생성하고, 상기 백본 및 상기 제2 넥을 사용함으로써 제2 입력 이미지에 기초하여 제3 피처 벡터를 생성하고, 상기 제2 피처 벡터 및 상기 제3 피처 벡터에 기초하여 제1 로스를 생성하고,상기 학습부를 통해, 상기 제1 로스에 기초하여 상기 제2 넥을 학습시키도록 구성된 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 생성부를 통해, 상기 제3 피처 벡터 및 GT(Ground Truth)에 기초하여 제2 로스를 생성하고,상기 학습부를 통해, 상기 제1 로스 및 상기 제2 로스에 기초하여 상기 제2 넥을 학습시키도록 구성된 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 생성부를 통해, 클래시피케이션(classification) 네트워크를 사용함으로써 상기 제3 피처 벡터에 기초하여 클래시피케이션 벡터를 생성하고, 상기 클래시피케이션 벡터와 상기 GT를 비교함으로써 상기 제2 로스를 생성하도록 구성된 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>17. 제15 항에 있어서,상기 GT는,하드 레이블링(hard labeling)된 데이터를 포함하는 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>18. 제14 항에 있어서,상기 제2 피처 벡터는,소프트 레이블링(soft labeling)된 데이터를 포함하는 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>19. 제14 항에 있어서,상기 제1 입력 이미지는,상기 제2 입력 이미지에서 객체 영역을 추출한 이미지인 것을 특징으로 하는 트래킹 장치.</claim></claimInfo><claimInfo><claim>20. 제11 항에 있어서,상기 적어도 하나 이상의 프로세서는,상기 생성부를 통해, 상기 제1 검출 정보와 상기 제1 피처 벡터가 합쳐진 제1 어소시에이션 벡터(association vector)를 생성하고, 상기 백본을 사용함으로써 제1 프레임의 다음 프레임인 제2 프레임에 기초하여 제2 피처를 생성하고, 상기 제1 넥을 사용함으로써 상기 제2 피처에 기초하여 복수의 제2 객체들에 대한 제2 검출 정보들을 생성하고, 상기 제2 넥을 사용함으로써 상기 제2 피처에 기초하여 상기 복수의 제2 객체들의 비주얼 피처들에 대한 제4 피처 벡터들을 생성하고, 각각의 상기 제2 검출 정보들과 각각의 상기 제4 피처 벡터들이 합쳐진 제2 어소시에이션 벡터들을 생성하고,트래킹부를 통해, 상기 제2 어소시에이션 벡터들 중 상기 제1 어소시에이션 벡터와 거리가 가장 가까운 어소시에이션 벡터를 갖는 객체를 상기 제1 객체와 어소시에이션함으로써 트래킹하도록 구성된 것을 특징으로 하는 트래킹 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서초구...</address><code>119980045675</code><country>대한민국</country><engName>HYUNDAI MOTOR COMPANY</engName><name>현대자동차주식회사</name></applicantInfo><applicantInfo><address>서울특별시 서초구...</address><code>119980003181</code><country>대한민국</country><engName>Kia Corporation</engName><name>기아 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 양천구...</address><code> </code><country> </country><engName>HAN, Ji Hee</engName><name>한지희</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 청계천로 **, *층(다동, 예금보험공사빌딩)</address><code>920061000421</code><country>대한민국</country><engName>BAE, KIM &amp; LEE IP</engName><name>특허법인태평양</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.07</receiptDate><receiptNumber>1-1-2024-0261191-22</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240032776.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c36a90f6218edad0926340e7bcc794cc6c90028de1ce6d55cb6614f0e71d57962b3b3a4de34278d90f8477749ab53b5d99f87d803c4428ee</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa86d01f579aa2bab0b8b8e8e01041847558cbb900418907035eef5a6a4dffa9929713c12c546f91ccc384e8847a39df72de054f757636bf6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>