<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:49.449</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.03.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7037557</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>부호부여된 거리 맵의 예측에 의한 형상-인지 기관 세그먼트화</inventionTitle><inventionTitleEng>SHAPE-AWARE ORGAN SEGMENTATION BY PREDICTING SIGNED DISTANCE MAPS</inventionTitleEng><openDate>2022.12.07</openDate><openNumber>10-2022-0162153</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.10.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.10.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/174</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 17/17</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 기관 세그먼트화를 위하여 신경망을 훈련시키는 컴퓨터-구현된 방법이 제공될 수 있다. 방법은 데이터베이스로부터 디지털 샘플 이미지들의 세트를 수집하는 단계; 디지털 이미지들의 수지된 세트를 신경망 인식 모델로 입력하는 단계; 및 제1 객체가 제2 디지털 이미지 내의 제2 객체와 유사한 것에 기초하여, 제1 디지털 이미지 내의 제1 객체를 특정 객체로서 인식하기 위하여 신경망 인식 모델을 훈련시키는 단계를 포함할 수 있다. 방법은 세그먼트화 맵과 협력하여 부호부여된 거리 맵(SDM)을 예측하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.11.11</internationOpenDate><internationOpenNumber>WO2021225680</internationOpenNumber><internationalApplicationDate>2021.03.04</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/020836</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 기관 세그먼트화(organ segmentation)를 위하여 신경망을 훈련시키는 컴퓨터-구현된 방법으로서,데이터베이스로부터 디지털 샘플 이미지들의 세트를 수집하는 단계;디지털 이미지들의 상기 수집된 세트를 신경망 인식 모델로 입력하는 단계; 및제1 디지털 이미지 내의 제1 객체가 제2 디지털 이미지 내의 제2 객체와 유사한 것에 기초하여, 상기 제1 객체를 특정 객체로서 인식하기 위하여 상기 신경망 인식 모델을 훈련시키는 단계 - 상기 컴퓨터-구현된 방법은 세그먼트화 맵(segmentation map)과 협력하여 부호부여된 거리 맵(signed distance map)(SDM)을 예측하는 단계를 포함함 -를 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,평탄한 표면으로 기관 세그먼트화를 예측하고 포스트-프로세싱 없이 직접적으로 잡음 세그먼트화를 제거하는 단계를 더 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,미분가능한 근사화된 헤비사이드 함수(Heaviside function)에 의해 상기 세그먼트화 맵 및 상기 SDM을 연결하고 전체적으로 상기 세그먼트화 맵과 협력하여 상기 SDM을 예측하는 단계 - 상기 훈련시키는 단계는 상기 미분가능한 근사화된 헤비사이드 함수를 통해 상기 신경망 인식 모델의 2개의 출력을 연결하고 공동으로 훈련시키는 것을 포함함 - 를 더 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,실세계 캡처된 이미지를 획득하는 단계;입력으로서, 상기 캡처된 이미지를 상기 훈련된 신경망 인식 모델로 입력하는 단계; 및출력으로서, 상기 훈련된 신경망 인식 모델로부터 적어도 하나의 세그먼트화된 기관을 포함하는 세그먼트화 예측 데이터를 출력하는 단계 - 상기 훈련된 신경망 인식 모델은 타깃 실세계 기관을 인식함 - 를 더 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 신경망 인식 모델은 심층 3 차원(three-dimensional)(3D) 유넷(U-net)인, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,(A) 디코더에서의 다운샘플링 및 디코더에서의 대응하는 업샘플링을 이용하는 것, (B) 배치 정규화 대신에 그룹 정규화를 이용하는 것, 및 (C) 활성화 함수로서, 정류된 선형 유닛(ReLU) 대신에 누설 ReLU을 이용하는 것중의 적어도 하나를 수행함으로써 상기 3D 유넷을 수정하는 단계를 더 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,그래픽 프로세싱 유닛(graphics processing unit)(GPU)은 상기 신경망 인식 모델의 프로세싱을 수행하기 위하여 이용되는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>8. 제5항에 있어서,상기 3D 유넷에 의해, 기관 마스크의 상기 SDM을 예측하는 단계를 더 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 3D 유넷이 상기 기관 마스크의 상기 SDM을 예측한 후에, 헤비사이드 함수를 이용하여 상기 기관 마스크의 상기 SDM을 세그먼트화 마스크로 변환하는 단계를 더 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,훈련시키는 단계는 상기 세그먼트화 마스크 및 상기 SDF를 함께 최적화함으로써 상기 신경망을 훈련시키는 것을 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 SDM 예측을 위한 회귀 손실은 2개의 파트를 가지고, 상기 손실의 제1 파트는 예측된 SDF와 실측자료(groundtruth) SDF 사이의 차이를 최소화하고, 제2 파트는 예측된 마스크와 실측자료 마스크 사이의 다이스 유사도 계수(Dice similarity coefficient)를 최대화하고, 세그먼트화 맵 및 거리 맵은 동일한 브랜치(branch)에서 예측됨으로써, 상기 세그먼트화와 SDM 브랜치 사이의 대응성이 보장되는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 손실의 제1 파트는, 실측자료 SDM 및 예측된 SDM을 이용하는 공식에 기초하여 정의되는 곱셈에 기초하여 회귀 태스크에서 이용된 공통 손실을 회귀 손실과 합성함으로써 결정되는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 손실의 제2 파트는 상수 마이너스(minus) 다이스 유사도 계수로서 정의되는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>14. 장치로서,컴퓨터 프로그램 코드를 저장하도록 구성된 적어도 하나의 메모리; 및상기 적어도 하나의 메모리를 액세스하고 상기 컴퓨터 프로그램 코드에 따라 동작하도록 구성된 적어도 하나의 프로세서를 포함하고, 상기 컴퓨터 프로그램 코드는, 상기 적어도 하나의 프로세서로 하여금, 데이터베이스로부터 디지털 샘플 이미지들의 세트를 수집하게 하도록 구성된 수집 코드; 상기 적어도 하나의 프로세서로 하여금, 디지털 이미지들의 상기 수집된 세트를 신경망 인식 모델로 입력하게 하도록 구성된 입력 코드; 및 상기 적어도 하나의 프로세서로 하여금, 제1 디지털 이미지 내의 제1 객체가 제2 디지털 이미지 내의 제2 객체와 유사한 것에 기초하여 상기 제1 객체를 특정 객체로서 인식하기 위하여 신경망 인식 모델을 훈련시키도록 구성된 훈련 코드 - 상기 훈련 코드는 세그먼트화 맵과 협력하여 부호부여된 거리 맵(SDM)을 예측하는 것을 포함함 - 를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 수집하는 것은 실세계 캡처된 이미지를 획득하는 것을 포함하고;상기 입력하는 것은 입력으로서, 상기 캡처된 이미지를 상기 훈련된 신경망 인식 모델로 입력하는 것을 포함하고;상기 컴퓨터 프로그램 코드는, 상기 적어도 하나의 프로세서로 하여금, 출력으로서, 상기 훈련된 신경망 인식 모델로부터 적어도 하나의 세그먼트화된 기관을 포함하는 세그먼트화 예측 데이터를 출력하게 하도록 구성된 출력 코드를 포함하고, 상기 훈련된 신경망 인식 모델은 타깃 실세계 기관을 인식하는, 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 신경망 인식 모델은 심층 3 차원(3D) 유넷인, 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 훈련시키는 것은, (A) 디코더에서의 다운샘플링 및 디코더에서의 대응하는 업샘플링을 이용하는 것, (B) 배치 정규화 대신에 그룹 정규화를 이용하는 것, 및 (C) 활성화 함수로서, 정류된 선형 유닛(ReLU) 대신에 누설 ReLU을 이용하는 것 중의 적어도 하나를 수행함으로써 상기 3D 유넷을 수정하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서,상기 출력하는 것은,3D 유넷에 의해, 기관 마스크의 상기 SDM을 예측하는 것, 및상기 3D 유넷이 상기 기관 마스크의 상기 SDM을 예측한 후에, 헤비사이드 함수를 이용하여 상기 기관 마스크의 상기 SDM을 세그먼트화 마스크로 변환하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 훈련시키는 것은 상기 세그먼트화 마스크 및 상기 SDF를 함께 최적화함으로써 상기 신경망을 훈련시키는 것을 포함하고,상기 SDM 예측을 위한 회귀 손실은 2개의 파트를 가지고, 상기 손실의 제1 파트는 예측된 SDF와 실측자료 SDF 사이의 차이를 최소화하고, 제2 파트는 예측된 마스크와 실측자료 마스크 사이의 다이스 유사도 계수를 최대화하고, 세그먼트화 맵 및 거리 맵은 동일한 브랜치(branch)에서 예측됨으로써, 상기 세그먼트화와 SDM 브랜치 사이의 대응성이 보장되는, 장치.</claim></claimInfo><claimInfo><claim>20. 명령을 저장하는 비-일시적 컴퓨터-판독가능 저장 매체로서,상기 명령은, 하나 이상의 프로세서로 하여금,데이터베이스로부터 디지털 샘플 이미지들의 세트를 수집하게 하고;디지털 이미지들의 상기 수집된 세트를 신경망 인식 모델로 입력하게 하고;세그먼트화 맵과 협력하여 부호부여된 거리 맵(SDM)을 예측하는 것을 포함하여, 제1 디지털 이미지 내의 제1 객체가 제2 디지털 이미지 내의 제2 객체와 유사한 것에 기초하여 상기 제1 객체를 특정 객체로서 인식하기 위하여 상기 신경망 인식 모델을 훈련시키도록 하는, 비-일시적 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 팔로 알토 파크 블러바드 ****</address><code>520200357391</code><country>미국</country><engName>TENCENT AMERICA LLC</engName><name>텐센트 아메리카 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>TANG, Hui</engName><name>탕 후이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>HUANG, Chao</engName><name>황 차오</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>LIN, Shih-Yao</engName><name>린 시-야오</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>QIAN, Zhen</engName><name>치안 전</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 팔로 알...</address><code> </code><country> </country><engName>FAN, Wei</engName><name>판 웨이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, 서림빌딩 **층 (역삼동)</address><code>920011000036</code><country>대한민국</country><engName>YOU ME PATENT &amp; LAW FIRM</engName><name>유미특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.05.07</priorityApplicationDate><priorityApplicationNumber>16/869,012</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.10.27</receiptDate><receiptNumber>1-1-2022-1135618-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.10.27</receiptDate><receiptNumber>1-1-2022-1136469-75</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.10.27</receiptDate><receiptNumber>1-1-2022-1136470-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.11.01</receiptDate><receiptNumber>1-5-2022-0162009-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Deferment (Postponement) of Processing of Examination</documentEngName><documentName>심사처리보류(연기)보고서</documentName><receiptDate>2025.07.30</receiptDate><receiptNumber>9-6-2025-0144399-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.09.29</receiptDate><receiptNumber>9-5-2025-0945772-85</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227037557.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93635c7d0dbb1c9eb52b23b52a46b7cd66ee57079b77fc4b3d7e6927b874d59ba4b54adab7ae144ecab618ef75f8bddc89bd18ae1baad5ae57</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd70e3e9720d035a15c22102c5a880040633bfa5ad6ecf0837ed95a6d712d8a4f7816983e35fd1e0b0a7c7486d10491038f59891095568368</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>