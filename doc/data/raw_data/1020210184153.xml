<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:38:48.3848</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.21</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0184153</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전자 장치 및 그 제어 방법</inventionTitle><inventionTitleEng>ELECTRONIC APPARATUS AND CONTROLLING METHOD THEREOF</inventionTitleEng><openDate>2023.04.28</openDate><openNumber>10-2023-0057237</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/28</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 전자 장치는 복수의 네트워크로 구성된 음성 인식 모델 및 음성 인식 모델을 통해 획득한 제1 사용자 음성에 대응되는 제1 인식 정보를 저장하는 메모리 및 제2 사용자 음성을 복수의 네트워크 중 제1 네트워크에 입력하여 제1 벡터를 획득하고, 제1 인식 정보를 복수의 네트워크 중 제1가중치 정보를 포함하는 제2 네트워크에 입력하여 제2 벡터를 획득하고, 제1 벡터 및 제2 벡터를 복수의 네트워크 중 제2 가중치 정보를 포함하는 제3 네트워크에 입력하여 제2 사용자 음성에 대응되는 제2 인식 정보를 획득하는 프로세서를 포함하고, 제2 가중치 정보 중 적어도 일부는 제1 가중치 정보와 동일한 정보이다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 있어서,복수의 네트워크로 구성된 음성 인식 모델 및 상기 음성 인식 모델을 통해 획득한 제1 사용자 음성에 대응되는 제1 인식 정보를 저장하는 메모리; 및제2 사용자 음성을 상기 복수의 네트워크 중 제1 네트워크에 입력하여 제1 벡터를 획득하고,상기 제1 인식 정보를 상기 복수의 네트워크 중 제1가중치 정보를 포함하는 제2 네트워크에 입력하여 제2 벡터를 획득하고,상기 제1 벡터 및 상기 제2 벡터를 상기 복수의 네트워크 중 제2 가중치 정보를 포함하는 제3 네트워크에 입력하여 상기 제2 사용자 음성에 대응되는 제2 인식 정보를 획득하는 프로세서;를 포함하고,상기 제2 가중치 정보 중 적어도 일부는, 상기 제1 가중치 정보와 동일한 정보인, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 음성 인식 모델은,RNN-T(Recurrent Neural Network Transducer) 모델인, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제1 네트워크는 전사 네트워크(Transcription Network)이고, 상기 제2 네트워크는 예측 네트워크(Prediction Network)이고,상기 제3 네트워크는 조인트 네트워크(Joint Network)인, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 프로세서는,상기 제2 사용자 음성이 수신되면, 상기 제2 사용자 음성에 대응되는 특징 벡터를 획득하고,상기 제2 사용자 음성에 대응되는 특징 벡터 및 상기 제1 네트워크에 포함된 제1 서브 네트워크에 기초하여 상기 제1 벡터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 프로세서는,상기 제1 인식 정보에 대응되는 원-핫 벡터(one-hot vector)를 획득하고,상기 제1 인식 정보에 대응되는 상기 원-핫 벡터, 상기 제1 가중치 정보 및 상기 제2 네트워크에 포함된 제2 서브 네트워크에 기초하여 상기 제2 벡터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 프로세서는,상기 제1 벡터, 상기 제2 벡터 및 상기 제3 네트워크에 포함된 제3 서브 네트워크에 기초하여 제3 벡터를 획득하고,상기 제3 벡터 및 상기 제2 가중치 정보에 기초하여 상기 제2 인식 정보를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 제1 가중치 정보는 기 설정된 개수의 서브 워드에 대응되는 가중치를 포함하고,상기 제2 가중치 정보는 상기 가중치 및 추가 가중치를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 추가 가중치는,상기 제2 사용자 음성에 대응되는 서브 워드가 존재하지 않는 경우 이용되는 가중치이고,상기 기 설정된 개수의 가중치의 차원(dimension)은 상기 추가 가중치의 차원(dimension)과 동일한, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 가중치 정보는,상기 제1 가중치 정보에 따른 손실값의 변화량을 나타내는 제1 그래디언트(gradient), 상기 제2 가중치 정보에 따른 손실값의 변화량을 나타내는 제2 그래디언트(gradient) 및 학습률(Learning rate)에 기초하여 학습되고,상기 제2 가중치 정보는,상기 학습된 제1 가중치 정보에 기초하여 결정되는, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 제1 가중치 정보 및 상기 제2 가중치 정보는,제1 서브 가중치 정보 및 제2 서브 가중치 정보의 평균값에 기초하여 학습되고,상기 제1 서브 가중치는,상기 제1 가중치 정보에 따른 손실값의 변화량을 나타내는 제1 그래디언트 및 학습률에 기초하여 산출되고,상기 제2 서브 가중치는,상기 제2 가중치 정보에 따른 손실값의 변화량을 나타내는 제2 그래디언트 및 상기 학습률에 기초하여 산출되는, 전자 장치.</claim></claimInfo><claimInfo><claim>11. 복수의 네트워크로 구성된 음성 인식 모델 및 상기 음성 인식 모델을 통해 획득한 제1 사용자 음성에 대응되는 제1 인식 정보를 저장하는 전자 장치의 제어 방법에 있어서,제2 사용자 음성을 상기 복수의 네트워크 중 제1 네트워크에 입력하여 제1 벡터를 획득하는 단계;상기 제1 인식 정보를 상기 복수의 네트워크 중 제1가중치 정보를 포함하는 제2 네트워크에 입력하여 제2 벡터를 획득하는 단계; 및상기 제1 벡터 및 상기 제2 벡터를 상기 복수의 네트워크 중 제2 가중치 정보를 포함하는 제3 네트워크에 입력하여 상기 제2 사용자 음성에 대응되는 제2 인식 정보를 획득하는 단계;를 포함하고,상기 제2 가중치 정보 중 적어도 일부는, 상기 제1 가중치 정보와 동일한 정보인, 제어 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 음성 인식 모델은,RNN-T(Recurrent Neural Network Transducer) 모델인, 제어 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 제1 네트워크는 전사 네트워크(Transcription Network)이고, 상기 제2 네트워크는 예측 네트워크(Prediction Network)이고,상기 제3 네트워크는 조인트 네트워크(Joint Network)인, 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,상기 제1 벡터를 획득하는 단계는,상기 제2 사용자 음성이 수신되면, 상기 제2 사용자 음성에 대응되는 특징 벡터를 획득하고,상기 제2 사용자 음성에 대응되는 특징 벡터 및 상기 제1 네트워크에 포함된 제1 서브 네트워크에 기초하여 상기 제1 벡터를 획득하는, 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서,상기 제2 벡터를 획득하는 단계는,상기 제1 인식 정보에 대응되는 원-핫 벡터(one-hot vector)를 획득하고,상기 제1 인식 정보에 대응되는 상기 원-핫 벡터, 상기 제1 가중치 정보 및 상기 제2 네트워크에 포함된 제2 서브 네트워크에 기초하여 상기 제2 벡터를 획득하는, 제어 방법.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서,상기 제2 인식 정보를 획득하는 단계는,상기 제1 벡터, 상기 제2 벡터 및 상기 제3 네트워크에 포함된 제3 서브 네트워크에 기초하여 제3 벡터를 획득하고,상기 제3 벡터 및 상기 제2 가중치 정보에 기초하여 상기 제2 인식 정보를 획득하는, 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서,상기 제1 가중치 정보는 기 설정된 개수의 서브 워드에 대응되는 가중치를 포함하고,상기 제2 가중치 정보는 상기 가중치 및 추가 가중치를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 추가 가중치는,상기 제2 사용자 음성에 대응되는 서브 워드가 존재하지 않는 경우 이용되는 가중치이고,상기 기 설정된 개수의 가중치의 차원(dimension)은 상기 추가 가중치의 차원(dimension)과 동일한, 제어 방법.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서,상기 제1 가중치 정보는,상기 제1 가중치 정보에 따른 손실값의 변화량을 나타내는 제1 그래디언트(gradient), 상기 제2 가중치 정보에 따른 손실값의 변화량을 나타내는 제2 그래디언트(gradient) 및 학습률(Learning rate)에 기초하여 학습되고,상기 제2 가중치 정보는,상기 학습된 제1 가중치 정보에 기초하여 결정되는, 제어 방법.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서,상기 제1 가중치 정보 및 상기 제2 가중치 정보는,제1 서브 가중치 정보 및 제2 서브 가중치 정보의 평균값에 기초하여 학습되고,상기 제1 서브 가중치는,상기 제1 가중치 정보에 따른 손실값의 변화량을 나타내는 제1 그래디언트 및 학습률에 기초하여 산출되고,상기 제2 서브 가중치는,상기 제2 가중치 정보에 따른 손실값의 변화량을 나타내는 제2 그래디언트 및 상기 학습률에 기초하여 산출되는, 제어 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Jin Hwan</engName><name>박진환</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Sung Soo</engName><name>김성수</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JIN, Si Chen</engName><name>김은향</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Jun Mo</engName><name>박준모</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SANDHYANA, Dhairya</engName><name>샌디아나 다이리아</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HAN, Chang Woo</engName><name>한창우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2021.10.21</priorityApplicationDate><priorityApplicationNumber>1020210141388</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.12.21</receiptDate><receiptNumber>1-1-2021-1482093-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.10.30</receiptDate><receiptNumber>1-1-2024-1186586-94</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210184153.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bdce5604bdd44424cb31f21f24a391bddbecbf21e80e448dcc4fcbb5b5d1919825303e9f4356de109d7a015a0ce767d2de433699d95dd0ce</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf799f31d28ceda74e105cbc8be2a3f18187e2c99e4d73cedaed6e8ebdda602bac6f5fc034b16bb33140600addb84e537b12813b2907e856ac</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>