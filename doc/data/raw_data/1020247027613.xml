<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:17.3317</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7027613</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 대체 시스템</inventionTitle><inventionTitleEng>OBJECT REPLACEMENT SYSTEM</inventionTitleEng><openDate>2024.09.20</openDate><openNumber>10-2024-0137630</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.19</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/776</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은, 동작들을 수행하기 위한 프로그램 및 방법을 저장한 컴퓨터-판독가능 저장 매체를 포함하는 시스템을 수반하고, 이러한 동작들은, 현실-세계 환경의 묘사를 포함하는 이미지를 수신하는 동작; 현실-세계 환경에서 현실-세계 객체의 존재를 표시하는 데이터를 획득하기 위해 이미지를 처리하는 동작; AR 객체를 포함하는 AR 경험을 선택하는 입력을 수신하는 동작; 획득된 데이터에서 표시되는 이미지에서 묘사되는 현실-세계 환경에서 검출되는 현실-세계 객체가 AR 객체에 대응한다고 결정하는 동작; 현실-세계 객체가 없는 현실-세계 환경을 묘사하는 새로운 이미지를 생성하기 위해 이미지에 머신 학습 기술을 적용하는 동작; 및 현실-세계 객체 대신에 AR 객체를 포함하는 현실-세계 환경을 묘사하는 수정된 새로운 이미지를 생성하기 위해 새로운 이미지에 AR 객체를 적용하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.07.27</internationOpenDate><internationOpenNumber>WO2023141146</internationOpenNumber><internationalApplicationDate>2023.01.18</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/011032</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 현실-세계 환경의 묘사를 포함하는 이미지를 수신하는 단계;상기 현실-세계 환경에서 현실-세계 객체의 존재를 표시하는 데이터를 획득하기 위해 상기 이미지를 처리하는 단계;AR 객체를 포함하는 AR(augmented reality) 경험을 선택하는 입력을 수신하는 단계;상기 획득된 데이터에서 표시되는 상기 이미지에서 묘사되는 상기 현실-세계 환경에서 검출되는 상기 현실-세계 객체가 상기 AR 경험의 상기 AR 객체에 대응한다고 결정하는 단계;상기 획득된 데이터에서 표시되는 상기 이미지에서 묘사되는 상기 현실-세계 환경에서 검출되는 상기 현실-세계 객체가 상기 AR 경험의 상기 AR 객체에 대응한다고 결정하는 것에 응답하여, 상기 현실-세계 객체가 없는 상기 현실-세계 환경을 묘사하는 새로운 이미지를 생성하기 위해 상기 이미지에 머신 학습 기술을 적용하는 단계; 및상기 현실-세계 객체 대신에 상기 AR 객체를 포함하는 상기 현실-세계 환경을 묘사하는 수정된 새로운 이미지를 생성하기 위해 상기 새로운 이미지에 상기 AR 객체를 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 추가로,복수의 머신 학습 기술들에 액세스하는 단계- 상기 복수의 머신 학습 기술들 중 제1 머신 학습 기술은 제1 타입의 객체를 상기 제1 타입의 객체를 포함하는 제1 환경을 묘사하는 제1 이미지로부터 제거하도록 구성되고, 상기 복수의 머신 학습 기술들 중 제2 머신 학습 기술은 제2 타입의 객체를 상기 제2 타입의 객체를 포함하는 제2 환경을 묘사하는 제2 이미지로부터 제거하도록 구성됨 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 추가로,상기 획득된 데이터에서 표시되는 상기 이미지에서 묘사되는 상기 현실-세계 환경 상에서 검출되는 상기 현실-세계 객체와 연관된 타입을 결정하는 단계; 및상기 타입이 상기 제1 타입의 객체와 매칭된다고 결정하는 것에 응답하여 상기 머신 학습 기술로서 상기 복수의 머신 학습 기술들로부터 상기 제1 머신 학습 기술을 선택하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 현실-세계 객체는 캐비닛 상의 하드웨어, 집 상의 문, 싱크대 상의 수도꼭지, 차량 상의 바퀴, 안경, 헤드웨어, 하나 이상의 귀걸이, 하나 이상의 피어싱, 또는 목걸이 중 적어도 하나를 포함하고, 상기 AR 객체는 캐비닛 상의 AR 하드웨어, 집 상의 AR 문, 싱크대 상의 AR 수도꼭지, 차량 상의 AR 바퀴, AR 안경, AR 헤드웨어, 하나 이상의 AR 귀걸이, 하나 이상의 AR 피어싱, 또는 AR 목걸이 중 적어도 하나를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 새로운 이미지에 상기 AR 객체를 적용하는 단계는 상기 수정된 새로운 이미지에 상기 AR 객체의 묘사를 추가하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 머신 학습 기술은 제1 신경망을 포함하고, 동작들을 수행하는 것에 의해 상기 신경망을 트레이닝하는 단계를 추가로 포함하고, 상기 동작들은,주어진 현실-세계 객체를 갖는 현실-세계 환경들을 묘사하는 복수의 트레이닝 이미지들 및 상기 주어진 현실-세계 객체가 없는 상기 현실-세계 환경들을 묘사하는 실측 이미지들을 포함하는 트레이닝 데이터를 수신하는 동작;상기 주어진 현실-세계 객체가 없는 상기 현실-세계 객체를 묘사하는 이미지를 추정하기 위해 상기 복수의 트레이닝 이미지들 중 제1 트레이닝 이미지에 상기 제1 신경망을 적용하는 동작;상기 추정된 이미지와 상기 제1 트레이닝 이미지와 연관된 상기 실측 이미지 사이의 편차를 컴퓨팅하는 동작; 및상기 컴퓨팅된 편차에 기초하여 상기 제1 신경망의 파라미터들을 업데이트하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 추가로,지식 분류 프로세스를 사용하여 상기 제1 신경망으로부터 제2 신경망을 트레이닝하는 단계- 상기 제2 신경망은 상기 제1 신경망의 콤팩트한 버전이고 모바일 디바이스 상에 구현되도록 구성됨 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서, 상기 편차는 지각 손실에 기초하여 컴퓨팅되는 방법.</claim></claimInfo><claimInfo><claim>9. 제6항 내지 제8항 중 어느 한 항에 있어서, 동작들을 수행하는 것에 의해 상기 트레이닝 데이터를 생성하는 단계를 추가로 포함하고, 상기 동작들은,제1 현실-세계 환경을 묘사하는 상기 제1 트레이닝 이미지를 생성하는 동작;상기 제1 트레이닝 이미지가 상기 제1 현실-세계 환경 상의 상기 주어진 현실-세계 객체의 묘사를 포함한다고 결정하는 동작;상기 제1 현실-세계 환경으로부터 상기 주어진 현실-세계 객체를 제거하기 위해 잠재적 코드 수정 프로세스를 포함하는 생성 모델을 적용하는 동작- 상기 생성 모델의 출력은 상기 주어진 현실-세계 객체가 없는 상기 제1 현실-세계 객체를 묘사하는 중간 이미지를 포함함 -; 및상기 중간 이미지에 기초하여 상기 제1 트레이닝 이미지에 대응하는 상기 실측 이미지를 생성하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 제1 트레이닝 이미지에 대응하는 상기 실측 이미지는 동작들을 수행하는 것에 의해 생성되고, 상기 동작들은,상기 주어진 현실-세계 객체에 대응하는 바이너리 마스크를 생성하기 위해 상기 제1 트레이닝 이미지에 대해 환경 세그먼트화 모델을 적용하는 동작; 및상기 제1 트레이닝 이미지에 대응하는 실측 이미지로서 혼합된 표현을 생성하기 위해 상기 중간 이미지에서의 관심의 영역- 상기 관심의 영역은 상기 바이너리 마스크에 의해 주어짐 -의 특징 표현들을 상기 제1 트레이닝 이미지의 특징 표현들과 조합하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제9항 또는 제10항에 있어서, 동작들을 수행하는 것에 의해 상기 제1 트레이닝 이미지에 대응하는 상기 실측 이미지의 무결성을 검증하는 단계를 추가로 포함하고, 상기 동작들은,속성들의 제1 세트를 생성하기 위해 상기 제1 트레이닝 이미지에 대해 속성 추출기를 적용하는 동작;속성들의 제2 세트를 생성하기 위해 상기 제1 트레이닝 이미지에 대응하는 상기 실측 이미지에 대해 상기 속성 추출기를 적용하는 동작; 및상기 속성들의 제1 및 제2 세트들을 비교하는 것에 의해 하나 이상의 검증 기준이 충족된다고 결정하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 하나 이상의 검증 기준은,상기 속성들의 제1 세트가 상기 주어진 현실-세계 객체의 존재를 표시하고 상기 속성들의 제2 세트가 상기 주어진 현실-세계 객체의 부재를 표시한다는 표시;상기 속성들의 제2 세트에서의 인구통계와 매칭되는 상기 속성들의 제1 세트의 인구통계;상기 속성들의 제2 세트에서의 장면 조명과 매칭되는 상기 제1 속성들의 세트의 장면 조명; 및상기 속성들의 제2 세트에서의 자세와 매칭되는 상기 속성들의 제1 세트의 자세를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 하나 이상의 검증 기준은 상기 속성들의 제2 세트에서의 얼굴 표정과 매칭되는 상기 속성들의 제1 세트의 얼굴 표정을 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제9항 내지 제13항 중 어느 한 항에 있어서, 추가로,제1 인구통계와 연관되는 상기 트레이닝 데이터에서의 이미지들의 제1 수량을 컴퓨팅하는 단계;제2 인구통계와 연관되는 상기 트레이닝 데이터에서의 이미지들의 제2 수량을 컴퓨팅하는 단계; 및상기 제2 수량이 임계값보다 많이 상기 제1 수량을 초과한다고 결정하는 것에 응답하여 상기 트레이닝 데이터에 추가하기 위해 상기 제1 인구통계와 연관된 새로운 이미지를 선택하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제9항 내지 제14항 중 어느 한 항에 있어서, 상기 주어진 현실-세계 객체의 존재를 표시하는 속성과 연관되는 상기 제1 트레이닝 이미지를 식별하기 위해 이미지들의 컬렉션과 연관된 속성들을 탐색하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 이미지는 사람의 클라이언트 디바이스로부터 수신되는 실시간 비디오 피드의 프레임인 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 추가로,상기 현실-세계 객체를 묘사하는 상기 이미지가 제1 위치로부터 제2 위치로 이동되는 것을 포함하는 비디오를 수신하는 단계- 상기 제2 위치는 상기 제1 위치보다 상기 현실-세계 환경에 더 가깝게 근접해 있음 -; 및상기 현실-세계 객체가 이동되고 있음에 따라, 상기 비디오로부터 상기 현실-세계 객체를 점진적으로 사라지게 그리고 제거하기 위해 상기 머신 학습 기술을 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 시스템으로서,동작들을 수행하도록 구성되는 프로세서를 포함하고, 상기 동작들은,현실-세계 환경의 묘사를 포함하는 이미지를 수신하는 동작;상기 현실-세계 환경에서 현실-세계 객체의 존재를 표시하는 데이터를 획득하기 위해 상기 이미지를 처리하는 동작;AR 객체를 포함하는 AR(augmented reality) 경험을 선택하는 입력을 수신하는 동작;상기 획득된 데이터에서 표시되는 상기 이미지에서 묘사되는 상기 현실-세계 환경에서 검출되는 상기 현실-세계 객체가 상기 AR 경험의 상기 AR 객체에 대응한다고 결정하는 동작;상기 획득된 데이터에서 표시되는 상기 이미지에서 묘사되는 상기 현실-세계 환경에서 검출되는 상기 현실-세계 객체가 상기 AR 경험의 상기 AR 객체에 대응한다고 결정하는 것에 응답하여, 상기 현실-세계 객체가 없는 상기 현실-세계 환경을 묘사하는 새로운 이미지를 생성하기 위해 상기 이미지에 머신 학습 기술을 적용하는 동작; 및상기 현실-세계 객체 대신에 상기 AR 객체를 포함하는 상기 현실-세계 환경을 묘사하는 수정된 새로운 이미지를 생성하기 위해 상기 새로운 이미지에 상기 AR 객체를 적용하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 동작들은 추가로, 복수의 머신 학습 기술들에 액세스하는 동작- 상기 복수의 머신 학습 기술들 중 제1 머신 학습 기술은 제1 타입의 객체를 상기 제1 타입의 객체를 포함하는 제1 환경을 묘사하는 제1 이미지로부터 제거하도록 구성되고, 상기 복수의 머신 학습 기술들 중 제2 머신 학습 기술은 제2 타입의 객체를 상기 제2 타입의 객체를 포함하는 제2 환경을 묘사하는 제2 이미지로부터 제거하도록 구성됨 -을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함하는 비-일시적인 머신-판독가능 저장 매체로서, 상기 명령어들은, 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하고, 상기 동작들은,현실-세계 환경의 묘사를 포함하는 이미지를 수신하는 동작;상기 현실-세계 환경에서 현실-세계 객체의 존재를 표시하는 데이터를 획득하기 위해 상기 이미지를 처리하는 동작;AR 객체를 포함하는 AR(augmented reality) 경험을 선택하는 입력을 수신하는 동작;상기 획득된 데이터에서 표시되는 상기 이미지에서 묘사되는 상기 현실-세계 환경에서 검출되는 상기 현실-세계 객체가 상기 AR 경험의 상기 AR 객체에 대응한다고 결정하는 동작;상기 획득된 데이터에서 표시되는 상기 이미지에서 묘사되는 상기 현실-세계 환경에서 검출되는 상기 현실-세계 객체가 상기 AR 경험의 상기 AR 객체에 대응한다고 결정하는 것에 응답하여, 상기 현실-세계 객체가 없는 상기 현실-세계 환경을 묘사하는 새로운 이미지를 생성하기 위해 상기 이미지에 머신 학습 기술을 적용하는 동작; 및상기 현실-세계 객체 대신에 상기 AR 객체를 포함하는 상기 현실-세계 환경을 묘사하는 수정된 새로운 이미지를 생성하기 위해 상기 새로운 이미지에 상기 AR 객체를 적용하는 동작을 포함하는 비-일시적 머신-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>IVANOV, Viacheslav</engName><name>이바노브, 비아체스라브</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>ZHURAVLEV, Aleksei</engName><name>즈허라브레브, 알렉세이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.01.19</priorityApplicationDate><priorityApplicationNumber>17/648,363</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.19</receiptDate><receiptNumber>1-1-2024-0896739-68</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.08.19</receiptDate><receiptNumber>1-1-2024-0899161-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.08.21</receiptDate><receiptNumber>1-5-2024-0136883-03</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247027613.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93cfee614daddf932494916502aa54309578bda5fd4e01505f9a65190a6238588c5765acfd1e156f6f6ced4ed773ce697621694c6a3763e7b6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4cefca99ddc9543e1a76b5b06009e7cf8bbe4ab4189a75ca9e30e0b5973f30e099cd07b25aff06db7a828b094caa67f9e8d830c5eab67a85</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>