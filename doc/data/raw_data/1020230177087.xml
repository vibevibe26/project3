<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:02.102</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0177087</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비원어민의 음성 인식 향상을 위한 모델 훈련 장치, 그 방법 및 자동 음성 인식 장치</inventionTitle><inventionTitleEng>MODEL TRAINING DEVICE, MODEL TRAINING METHOD AND AUTOMATIC  SPEECH RECOGNITION APPARATUS FOR IMPROVING SPEECH  RECOGNITION OF NON-NATIVE SPEAKERS</inventionTitleEng><openDate>2025.06.16</openDate><openNumber>10-2025-0087367</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.07</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 모델 훈련 장치는 발화 음성의 오디오 특징으로부터 악센트 특징을 추출하도록 훈련되는 악센트 모듈, 그리고 상기 악센트 모듈을 이용하여, 상기 오디오 특징에 상기 프롬프트를 연결한 프롬프트 연결 입력으로부터 제1 악센트 특징과 상기 오디오 특징으로부터 제2 악센트 특징을 각각 추출하고, 상기 제1 악센트 특징과 상기 제2 악센트 특징 사이의 상호 의존성을 최소화하도록 적대적으로 훈련되어 상기 오디오 특징으로부터 프롬프트를 생성하는 프롬프트 생성부를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 프로세서에 의해 동작하는 모델 훈련 장치로서, 발화 음성의 오디오 특징으로부터 악센트 특징을 추출하도록 훈련되는 악센트 모듈, 그리고상기 악센트 모듈을 이용하여, 상기 오디오 특징에 상기 프롬프트를 연결한 프롬프트 연결 입력으로부터 제1 악센트 특징과 상기 오디오 특징으로부터 제2 악센트 특징을 각각 추출하고, 상기 제1 악센트 특징과 상기 제2 악센트 특징 사이의 상호 의존성을 최소화하도록 적대적으로 훈련되어 상기 오디오 특징으로부터 프롬프트를 생성하는 프롬프트 생성부를 포함하는, 모델 훈련 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에서,상기 프롬프트 생성부는,상기 프롬프트 연결 입력으로부터 텍스트를 출력하는 음성 인식 모델의 CTC(Connectionist Temporal Classification) 손실을 최소화하도록 훈련되는, 모델 훈련 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에서,상기 악센트 모듈은,주어진 발화의 악센트 특징을 고립하는 악센트 분류 헤드로 훈련되어 상기 오디오 특징으로부터 상기 악센트 특징을 추출하는 악센트 특징 추출부, 그리고상기 악센트 특징 추출부가 추출한 악센트 특징을 사용하여 악센트 강도를 포착하도록 상기 CTC 손실을 예측하는 악센트 강도 회귀 헤드를 포함하는, 모델 훈련 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에서,상기 악센트 특징 추출부는,상기 음성 인식 모델을 통해 획득한 상기 오디오 특징의 숨겨진 상태로부터 상기 악센트 특징을 추출하는, 모델 훈련 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에서,신경망을 사용하여 상기 상호 의존성을 추정하는 상호 정보 뉴럴 추정부를 더 포함하는, 모델 훈련 장치.</claim></claimInfo><claimInfo><claim>6. 제2항에서,상기 음성 인식 모델은,원어민 발화 데이터를 이용하여 훈련된 모델이고, 상기 악센트 모듈 및 상기 프롬프트 생성부의 훈련에 사용되는 발화 음성은,비원어민 발화 음성인, 모델 훈련 장치.</claim></claimInfo><claimInfo><claim>7. 적어도 하나의 프로세서에 의해 동작하는 모델 훈련 장치의 동작 방법으로서,발화 음성의 오디오 특징으로부터 악센트 특징을 추출하도록 악센트 모듈을 훈련시키는 단계,상기 악센트 모듈을 이용하여, 상기 오디오 특징에 상기 프롬프트를 연결한 프롬프트 연결 입력으로부터 제1 악센트 특징, 그리고 상기 오디오 특징으로부터 제2 악센트 특징을 각각 추출하는 단계, 그리고상기 제1 악센트 특징과 상기 제2 악센트 특징 사이의 상호 의존성을 최소화하도록 상기 오디오 특징으로부터 프롬프트를 생성하는 프롬프트 생성부를 적대적으로 훈련시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에서,상기 프롬프트 연결 입력으로부터 텍스트를 출력하는 음성 인식 모델의 CTC(Connectionist Temporal Classification) 손실을 최소화하도록 상기 프롬프트 생성부를 훈련시키는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에서,상기 프롬프트 생성부를 훈련시키는 단계는,상기 오디오 특징을 상기 음성 인식 모델에 입력하여 숨겨진 상태를 획득하는 단계,상기 숨겨진 상태를 상기 프롬프트 생성부에 입력하여 프롬프트를 획득하는 단계,상기 오디오 특징과 상기 프롬프트를 concat 함수를 이용하여 연결하여 상기 프롬프트 연결 입력을 생성하는 단계, 상기 프롬프트 연결 입력을 상기 음성 인식 모델에 입력하여 상기 CTC 손실을 획득하는 단계, 그리고상기 CTC 손실을 최소화하도록 상기 프롬프트 생성부를 훈련시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에서,상기 추출하는 단계는,상기 프롬프트 연결 입력을 상기 음성 인식 모델에 입력하여 제1 숨겨진 상태를 획득하고, 상기 오디오 특징을 상기 음성 인식 모델에 입력하여 제2 숨겨진 상태를 각각 획득하는 단계, 그리고상기 제1 숨겨진 상태를 상기 악센트 모듈에 입력하여 상기 제1 악센트 특징을 추출하고, 상기 제2 숨겨진 상태를 상기 악센트 모듈에 입력하여 상기 제2 악센트 특징을 추출하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에서,상기 적대적으로 훈련시키는 단계는,신경망 모델 기반의 상호 정보 뉴럴 추정부를 이용하여 상기 상호 의존성을 측정하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에서,상기 악센트 모듈을 훈련시키는 단계는,상기 음성 인식 모델을 통해 획득한 상기 오디오 특징의 숨겨진 상태로부터 악센트 특징을 추출하고, 상기 추출한 악센트 특징을 사용하여 상기 CTC 손실을 예측하여 악센트 강도를 포착하도록 상기 악센트 모듈을 훈련시키고, 주어진 발화의 악센트 특징을 고립하는 악센트 분류 헤드로 훈련되어 상기 오디오 특징으로부터 상기 악센트 특징을 추출하도록 상기 악센트 모듈을 훈련시키는, 방법.</claim></claimInfo><claimInfo><claim>13. 적어도 하나의 프로세서에 의해 동작하는 자동 음성 인식 장치로서,발화 음성의 오디오 특징에 숨겨진 상태인 악센트 특징으로부터 프롬프트를 생성하는 프롬프트 생성부, 그리고상기 오디오 특징과 상기 프롬프트를 연결한 프롬프트 연결 입력으로부터 상기 발화 음성에 대한 텍스트를 생성하는 음성 인식 모델을 포함하는, 자동 음성 인식 장치.</claim></claimInfo><claimInfo><claim>14. 제12항에서,상기 프롬프트 생성부는,발화 음성의 오디오 특징에 프롬프트를 연결한 프롬프트 연결 입력으로부터 추출된 제1 악센트 특징과 상기 오디오 특징으로부터 추출된 제2 악센트 특징 사이의 상호 의존성을 최소화하도록 적대적으로 훈련되는, 자동 음성 인식 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에서,상기 프롬프트 생성부는,상기 프롬프트 연결 입력으로부터 텍스트를 출력하는 음성 인식 모델의 CTC(Connectionist Temporal Classification) 손실을 최소화하도록 훈련되는, 자동 음성 인식 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980988661</code><country>대한민국</country><engName>Korea Advanced Institute of Science and Technology</engName><name>한국과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>YOO, CHANGDONG</engName><name>유창동</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>YOON, EUNSEOP</engName><name>윤은섭</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>YOON, HEE SUK</engName><name>윤희석</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, 서림빌딩 **층 (역삼동)</address><code>920011000036</code><country>대한민국</country><engName>YOU ME PATENT &amp; LAW FIRM</engName><name>유미특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.07</receiptDate><receiptNumber>1-1-2023-1375501-78</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.09.27</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230177087.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930df2a32458d87f3b60dd197202350a297b8b3111d7e7241f7fcb713a3b194d8714b359ddc02506e510818e818bff1ab88cade0a20d38b9bf</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa53785a25e63a6bd89c860983543dd65e7f26b2c7f24b429107bf9af79fdce7f29aefe637a90838532a81616ab830004210f3518e81b5ccc</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>