<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:08:24.824</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7018485</applicationNumber><claimCount>60</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>뉴럴 네트워크 기반 비디오 코딩을 위한 프론트-엔드 아키텍처</inventionTitle><inventionTitleEng>A FRONT-END ARCHITECTURE FOR NEURAL NETWORK BASED VIDEO CODING</inventionTitleEng><openDate>2023.08.08</openDate><openNumber>10-2023-0117346</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.05.31</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/124</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/13</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/186</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/88</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/172</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 뉴럴 네트워크 시스템을 사용하여 비디오 데이터를 프로세싱하기 위한 기법들이 본 명세서에서 설명된다. 예를 들어, 프로세스는 뉴럴 네트워크 시스템의 인코더 서브-네트워크의 제 1 컨볼루션 계층에 의해, 프레임의 휘도 채널과 연관된 출력 값들을 생성하는 것을 포함할 수 있다. 프로세스는 인코더 서브-네트워크의 제 2 컨볼루션 계층에 의해, 프레임의 적어도 하나의 색차 채널과 연관된 출력 값들을 생성하는 것을 포함할 수 있다. 프로세스는 프레임의 휘도 채널과 연관된 출력 값들 및 프레임의 적어도 하나의 색차 채널과 연관된 출력 값들에 기반한 제 3 컨볼루션 계층에 의해, 프레임의 결합된 표현을 생성하는 것을 포함할 수 있다. 프로세스는 프레임의 결합된 표현에 기초하여 인코딩된 비디오 데이터를 생성하는 것을 더 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.06.16</internationOpenDate><internationOpenNumber>WO2022126120</internationOpenNumber><internationalApplicationDate>2021.12.09</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/072824</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 데이터의 프로세싱 방법으로서, 뉴럴 네트워크 시스템의 인코더 서브-네트워크의 제 1 컨볼루션 (convolutional) 계층에 의해, 프레임의 휘도 채널과 연관된 출력 값들을 생성하는 단계;상기 인코더 서브-네트워크의 제 2 컨볼루션 계층에 의해, 상기 프레임의 적어도 하나의 색차 채널과 연관된 출력 값들을 생성하는 단계;상기 프레임의 휘도 채널과 연관된 상기 출력 값들 및 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들에 기반한 제 3 컨볼루션 계층에 의해, 상기 프레임의 결합된 표현을 생성하는 단계; 및상기 프레임의 상기 결합된 표현에 기반하여, 인코딩된 비디오 데이터를 생성하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 제 3 컨볼루셔션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서, 추가로상기 인코더 서브-네트워크의 제 1 비선형 계층을 사용하여, 상기 프레임의 휘도 채널과 연관된 상기 출력 값들을 프로세싱하는 단계; 및상기 인코더 서브-네트워크의 제 2 비선형 계층을 사용하여, 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들을 프로세싱하는 단계를 포함하고,상기 결합된 표현은 상기 제 1 비선형 계층의 출력 및 상기 제 2 비선형 계층의 출력에 기반하여 생성되는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서, 상기 프레임의 상기 결합된 표현은 상기 제 1 비선형 계층의 상기 출력 및 상기 제 2 비선형 계층의 상기 출력을 입력으로서 사용하여 상기 제 3 컨볼루션 계층에 의해 생성되는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서, 추가로상기 인코딩된 비디오 데이터를 양자화하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>6. 제 1 항에 있어서, 추가로상기 인코딩된 비디오 데이터를 엔트로피 코딩하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서, 추가로상기 인코딩된 비디오 데이터를 메모리에 저장하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서, 추가로상기 인코딩된 비디오 데이터를 송신 매체를 통해 적어도 하나의 디바이스에 송신하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서, 추가로인코딩된 프레임을 획득하는 단계;상기 뉴럴 네트워크 시스템의 디코더 서브-네트워크의 제 1 컨볼루션 계층에 의해, 상기 인코딩된 프레임의 휘도 채널과 연관된 재구성된 출력 값들을 생성하는 단계; 및상기 디코더 서브-네트워크의 제 2 컨볼루션 계층에 의해, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 재구성된 출력 값들을 생성하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서, 추가로상기 디코더 서브-네트워크의 제 3 컨볼루션 계층을 사용하여, 상기 인코딩된 프레임의 상기 적어도 하나의 색차 채널로부터 상기 인코딩된 프레임의 휘도 채널을 분리하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서, 상기 디코더 서브-네트워크의 상기 제 3 컨볼루션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>12. 제 1 항에 있어서, 상기 프레임은 비디오 프레임을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>13. 제 1 항에 있어서, 상기 적어도 하나의 색차 채널은, 색차-청색 채널 및 색차-적색 채널을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>14. 제 1 항에 있어서, 상기 프레임은 YUV(Luminance-Chrominance) 포맷을 갖는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>15. 비디오 데이터의 프로세싱 장치로서,메모리; 및상기 메모리에 커플링된 프로세서를 포함하고, 상기 프로세서는,뉴럴 네트워크 시스템의 인코더 서브-네트워크의 제 1 컨볼루션 계층을 사용하여, 프레임의 휘도 채널과 연관된 출력 값들을 생성하도록;상기 인코더 서브-네트워크의 제 2 컨볼루션 계층을 사용하여, 상기 프레임의 적어도 하나의 색차 채널과 연관된 출력 값들을 생성하도록;상기 프레임의 휘도 채널과 연관된 상기 출력 값들 및 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들에 기반한 제 3 컨볼루션 계층을 사용하여, 상기 프레임의 결합된 표현을 생성하도록; 그리고상기 프레임의 상기 결합된 표현에 기반하여, 인코딩된 비디오 데이터를 생성하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서, 상기 제 3 컨볼루셔션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>17. 제 15 항에 있어서, 상기 프로세서는,상기 인코더 서브-네트워크의 제 1 비선형 계층을 사용하여, 상기 프레임의 휘도 채널과 연관된 상기 출력 값들을 프로세싱하도록; 그리고상기 인코더 서브-네트워크의 제 2 비선형 계층을 사용하여, 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들을 프로세싱하도록 구성되고,상기 결합된 표현은 상기 제 1 비선형 계층의 출력 및 상기 제 2 비선형 계층의 출력에 기반하여 생성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서, 상기 프레임의 상기 결합된 표현은 상기 제 1 비선형 계층의 상기 출력 및 상기 제 2 비선형 계층의 상기 출력을 입력으로서 사용하여 상기 제 3 컨볼루션 계층에 의해 생성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>19. 제 15 항에 있어서, 상기 프로세서는,상기 인코딩된 비디오 데이터를 양자화하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>20. 제 15 항에 있어서, 상기 프로세서는,상기 인코딩된 비디오 데이터를 엔트로피 코딩하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>21. 제 15 항에 있어서, 상기 프로세서는,상기 인코딩된 비디오 데이터를 메모리에 저장하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>22. 제 15 항에 있어서, 상기 프로세서는,상기 인코딩된 비디오 데이터를 송신 매체를 통해 적어도 하나의 디바이스에 송신하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>23. 제 15 항에 있어서, 상기 프로세서는,인코딩된 프레임을 획득하도록;상기 뉴럴 네트워크 시스템의 디코더 서브-네트워크의 제 1 컨볼루션 계층을 사용하여, 상기 인코딩된 프레임의 휘도 채널과 연관된 재구성된 출력 값들을 생성하도록; 그리고상기 디코더 서브-네트워크의 제 2 컨볼루션 계층을 사용하여, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 재구성된 출력 값들을 생성하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>24. 제 23 항에 있어서, 상기 프로세서는,상기 디코더 서브-네트워크의 제 3 컨볼루션 계층을 사용하여, 상기 인코딩된 프레임의 상기 적어도 하나의 색차 채널로부터 상기 인코딩된 프레임의 휘도 채널을 분리하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>25. 제 24 항에 있어서, 상기 디코더 서브-네트워크의 상기 제 3 컨볼루션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>26. 제 15 항에 있어서, 상기 프레임은 비디오 프레임을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>27. 제 15 항에 있어서, 상기 적어도 하나의 색차 채널은, 색차-청색 채널 및 색차-적색 채널을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>28. 제 15 항에 있어서, 상기 프레임은 YUV(Luminance-Chrominance) 포맷을 갖는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>29. 제 15 항에 있어서, 상기 프로세서는 NPU(neural processing unit)를 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>30. 제 15 항에 있어서, 상기 장치는 모바일 디바이스를 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>31. 제 15 항에 있어서, 하나 이상의 프레임들을 캡처하도록 구성된 카메라 및 디스플레이 중 적어도 하나를 더 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>32. 비디오 데이터의 프로세싱 방법으로서,인코딩된 프레임을 획득하는 단계;디코더 서브-네트워크의 제 1 컨볼루션 계층에 의해, 상기 인코딩된 프레임의 적어도 하나의 색차 채널로부터 상기 인코딩된 프레임의 휘도 채널을 분리하는 단계;뉴럴 네트워크 시스템의 디코더 서브-네트워크의 제 2 컨볼루션 계층에 의해, 상기 인코딩된 프레임의 휘도 채널과 연관된 재구성된 출력 값들을 생성하는 단계;상기 디코더 서브-네트워크의 제 3 컨볼루션 계층에 의해, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 재구성된 출력 값들을 생성하는 단계; 및휘도 채널과 연관된 상기 재구성된 출력 값들 및 적어도 하나의 색차 채널과 연관된 상기 재구성된 출력 값들을 포함하는 출력 프레임을 생성하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>33. 제 32 항에 있어서, 상기 디코더 서브-네트워크의 상기 제 1 컨볼루션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>34. 제 32 항에 있어서, 추가로상기 디코더 서브-네트워크의 제 1 비선형 계층을 사용하여, 상기 인코딩된 프레임의 휘도 채널과 연관된 값들을 프로세싱하는 단계로서, 휘도 채널과 연관된 상기 재구성된 출력 값들은 상기 제 1 비선형 계층의 출력에 기반하여 생성되는, 상기 인코딩된 프레임의 휘도 채널과 연관된 값들을 프로세싱하는 단계; 및상기 디코더 서브-네트워크의 제 2 비선형 계층을 사용하여, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 값들을 프로세싱하는 단계로서, 적어도 하나의 색차 채널과 연관된 상기 재구성된 출력 값들은 상기 제 2 비선형 계층의 출력에 기반하여 생성되는, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 값들을 프로세싱하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>35. 제 32 항에 있어서, 추가로상기 인코딩된 프레임의 샘플들을 역양자화하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>36. 제 32 항에 있어서, 추가로상기 인코딩된 프레임의 샘플들을 엔트로피 디코딩하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>37. 제 32 항에 있어서, 추가로메모리에 상기 출력 프레임을 저장하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>38. 제 32 항에 있어서, 추가로상기 출력 프레임을 디스플레이하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>39. 제 32 항에 있어서, 추가로뉴럴 네트워크 시스템의 인코더 서브-네트워크의 제 1 컨볼루션 계층에 의해, 프레임의 휘도 채널과 연관된 출력 값들을 생성하는 단계;상기 인코더 서브-네트워크의 제 2 컨볼루션 계층에 의해, 상기 프레임의 적어도 하나의 색차 채널과 연관된 출력 값들을 생성하는 단계;상기 프레임의 휘도 채널과 연관된 상기 출력 값들 및 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들에 기반한 상기 인코더 서브-네트워크의 제 3 컨볼루션 계층에 의해, 상기 프레임의 결합된 표현을 생성하는 단계; 및상기 프레임의 결합된 표현에 기반하여, 상기 인코딩된 프레임을 생성하는 단계를 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>40. 제 39 항에 있어서, 상기 인코더 서브-네트워크의 상기 제 3 컨볼루션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>41. 제 39 항에 있어서, 추가로상기 인코더 서브-네트워크의 제 1 비선형 계층을 사용하여, 상기 프레임의 휘도 채널과 연관된 상기 출력 값들을 프로세싱하는 단계; 및상기 인코더 서브-네트워크의 제 2 비선형 계층을 사용하여, 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들을 프로세싱하는 단계를 포함하고,상기 결합된 표현은 상기 제 1 비선형 계층의 출력 및 상기 제 2 비선형 계층의 출력에 기반하여 생성되는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>42. 제 41 항에 있어서, 상기 프레임의 상기 결합된 표현은 상기 제 1 비선형 계층의 상기 출력 및 상기 제 2 비선형 계층의 상기 출력을 입력으로서 사용하여 상기 인코더  서브-네트워크의 상기 제 3 컨볼루션 계층에 의해 생성되는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>43. 제 32 항에 있어서, 상기 인코딩된 프레임은 인코딩된 비디오 프레임을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>44. 제 32 항에 있어서, 상기 적어도 하나의 색차 채널은, 색차-청색 채널 및 색차-적색 채널을 포함하는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>45. 제 32 항에 있어서, 상기 인코딩된 프레임은 YUV(Luminance-Chrominance) 포맷을 갖는, 비디오 데이터의 프로세싱 방법.</claim></claimInfo><claimInfo><claim>46. 비디오 데이터의 프로세싱 장치로서,메모리; 및상기 메모리에 커플링된 프로세서를 포함하고, 상기 프로세서는,인코딩된 프레임을 획득하도록;디코더 서브-네트워크의 제 1 컨볼루션 계층을 사용하여, 상기 인코딩된 프레임의 적어도 하나의 색차 채널로부터 상기 인코딩된 프레임의 휘도 채널을 분리하도록;뉴럴 네트워크 시스템의 디코더 서브-네트워크의 제 2 컨볼루션 계층을 사용하여, 상기 인코딩된 프레임의 휘도 채널과 연관된 재구성된 출력 값들을 생성하도록;상기 디코더 서브-네트워크의 제 3 컨볼루션 계층을 사용하여, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 재구성된 출력 값들을 생성하도록; 그리고휘도 채널과 연관된 상기 재구성된 출력 값들 및 적어도 하나의 색차 채널과 연관된 상기 재구성된 출력 값들을 포함하는 출력 프레임을 생성하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>47. 제 46 항에 있어서, 상기 디코더 서브-네트워크의 상기 제 1 컨볼루션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>48. 제 46 항에 있어서, 상기 프로세서는,상기 디코더 서브-네트워크의 제 1 비선형 계층을 사용하여, 상기 인코딩된 프레임의 휘도 채널과 연관된 값들을 프로세싱하는 것으로서, 휘도 채널과 연관된 상기 재구성된 출력 값들은 상기 제 1 비선형 계층의 출력에 기반하여 생성되는, 상기 인코딩된 프레임의 휘도 채널과 연관된 값들을 프로세싱하는 것을 수행하도록; 그리고 상기 디코더 서브-네트워크의 제 2 비선형 계층을 사용하여, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 값들을 프로세싱하는 것으로서, 적어도 하나의 색차 채널과 연관된 상기 재구성된 출력 값들은 상기 제 2 비선형 계층의 출력에 기반하여 생성되는, 상기 인코딩된 프레임의 적어도 하나의 색차 채널과 연관된 값들을 프로세싱하는 것을 수행하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>49. 제 46 항에 있어서, 상기 프로세서는,상기 인코딩된 프레임의 샘플들을 역양자화하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>50. 제 46 항에 있어서, 상기 프로세서는,상기 인코딩된 프레임의 샘플들을 엔트로피 디코딩하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>51. 제 46 항에 있어서, 상기 프로세서는,메모리에 상기 출력 프레임을 저장하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>52. 제 46 항에 있어서, 상기 프로세서는,상기 출력 프레임을 디스플레이하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>53. 제 46 항에 있어서, 상기 프로세서는,뉴럴 네트워크 시스템의 인코더 서브-네트워크의 제 1 컨볼루션 계층에 의해, 프레임의 휘도 채널과 연관된 출력 값들을 생성하도록;상기 인코더 서브-네트워크의 제 2 컨볼루션 계층에 의해, 상기 프레임의 적어도 하나의 색차 채널과 연관된 출력 값들을 생성하도록;상기 프레임의 휘도 채널과 연관된 상기 출력 값들 및 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들에 기반한 상기 인코더 서브-네트워크의 제 3 컨볼루션 계층에 의해, 상기 프레임의 결합된 표현을 생성하도록; 그리고상기 프레임의 결합된 표현에 기반하여, 상기 인코딩된 프레임을 생성하도록 구성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>54. 제 53 항에 있어서, 상기 인코더 서브-네트워크의 상기 제 3 컨볼루션 계층은 1x1 컨볼루션 계층을 포함하고, 상기 1x1 컨볼루션 계층은 하나 이상의 1x1 컨볼루션 필터들을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>55. 제 53 항에 있어서, 상기 프로세서는,상기 인코더 서브-네트워크의 제 1 비선형 계층을 사용하여, 상기 프레임의 휘도 채널과 연관된 상기 출력 값들을 프로세싱하도록; 그리고상기 인코더 서브-네트워크의 제 2 비선형 계층을 사용하여, 상기 프레임의 적어도 하나의 색차 채널과 연관된 상기 출력 값들을 프로세싱하도록 구성되고,상기 결합된 표현은 상기 제 1 비선형 계층의 출력 및 상기 제 2 비선형 계층의 출력에 기반하여 생성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>56. 제 55 항에 있어서, 상기 프레임의 상기 결합된 표현은 상기 제 1 비선형 계층의 상기 출력 및 상기 제 2 비선형 계층의 상기 출력을 입력으로서 사용하여 상기 인코더  서브-네트워크의 상기 제 3 컨볼루션 계층에 의해 생성되는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>57. 제 46 항에 있어서, 상기 인코딩된 프레임은 인코딩된 비디오 프레임을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>58. 제 57 항에 있어서, 상기 적어도 하나의 색차 채널은, 색차-청색 채널 및 색차-적색 채널을 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>59. 제 46 항에 있어서, 상기 인코딩된 프레임은 YUV(Luminance-Chrominance) 포맷을 갖는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo><claimInfo><claim>60. 제 46 항에 있어서, 하나 이상의 비디오 프레임들을 캡처하도록 구성된 카메라 및 디스플레이 중 적어도 하나를 더 포함하는, 비디오 데이터의 프로세싱 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>EGILMEZ, HILMI ENES</engName><name>에길메즈 힐미 에네스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>SINGH, ANKITESH KUMAR</engName><name>싱 안키테쉬 쿠마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>COBAN, MUHAMMED ZEYD</engName><name>코반 무하메드 제이드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>KARCZEWICZ, MARTA</engName><name>카르체비츠 마르타</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.12.10</priorityApplicationDate><priorityApplicationNumber>63/124,016</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.12.30</priorityApplicationDate><priorityApplicationNumber>63/131,802</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.08</priorityApplicationDate><priorityApplicationNumber>17/643,383</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.05.31</receiptDate><receiptNumber>1-1-2023-0602347-78</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.07.11</receiptDate><receiptNumber>1-5-2023-0111016-81</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.11.20</receiptDate><receiptNumber>1-1-2024-1279945-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.20</receiptDate><receiptNumber>1-1-2024-1279946-86</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.11.20</receiptDate><receiptNumber>1-1-2024-1279947-21</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237018485.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9343ebf029cdca658e3044d9e2e77cbd8cc6850cb1c3ba22896c96db29c049517e294cadd640825b0ac1957ebde95d1cce1e4cf9cbfbbe9a78</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf8b9b20a4b57b2b3b851e94e2dbde7f64d8343772c3dc943e12f9517432afbf52b809fefb2af08d082e354098b9ebf3c63179f21a18352f80</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>