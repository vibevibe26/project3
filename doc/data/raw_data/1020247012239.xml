<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:24.5124</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2017.02.20</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2024-7012239</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal>거절결정 후 재심사중</finalDisposal><inventionTitle>인사이드-아웃 위치, 사용자 신체 및 환경 추적을 갖는 가상 및 혼합 현실을 위한 머리 장착 디스플레이</inventionTitle><inventionTitleEng>HEAD-MOUNTED DISPLAY FOR VIRTUAL AND MIXED REALITY WITH  INSIDE-OUT POSITIONAL, USER BODY AND ENVIRONMENT TRACKING</inventionTitleEng><openDate>2024.04.19</openDate><openNumber>10-2024-0051334</openNumber><originalApplicationDate>2017.02.20</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2022-7022543</originalApplicationNumber><originalExaminationRequestDate>2024.04.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.04.12</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G02B 27/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020227022543</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 가상 또는 혼합 현실에 대해 정확하고 자동적인 인사이드-아웃 위치, 사용자 신체 및 환경 추적을 수행하기 위한 연관된 기술들과 함께 머리 장착 디스플레이 시스템이 개시된다. 시스템은 실시간 추적을 달성하기 위해 다수의 센서들로부터 컴퓨터 비전 방법들 및 데이터 융합을 사용한다. HMD 자체 상에서 프로세싱의 일부를 수행함으로써 높은 프레임 레이트 및 낮은 레이턴시가 달성된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2017.08.24</internationOpenDate><internationOpenNumber>WO2017139871</internationOpenNumber><internationalApplicationDate>2017.02.20</internationalApplicationDate><internationalApplicationNumber>PCT/CA2017/000033</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,비일시적 메모리, 하나 이상의 프로세서, 및 디스플레이 및 제1 카메라 센서와 통신하기 위한 통신 인터페이스를 포함하는 머리 장착 디바이스(HMD)에서, 상기 제1 카메라 센서를 통해, 물리적 환경의 패스-스루(pass-through) 이미지를 획득하는 단계; 상기 물리적 환경과 연관된 깊이 맵을 획득하는 단계; 가상 콘텐츠와 연관된 렌더링된 그래픽들을 생성하는 단계; 상기 깊이 맵에 기초하여 상기 렌더링된 그래픽들을 상기 물리적 환경의 패스-스루 이미지와 혼합함으로써 디스플레이 이미지를 생성하는 단계; 및 상기 디스플레이를 통해, 상기 디스플레이 이미지를 디스플레이하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 HMD는 제2 카메라 센서를 포함하고, 상기 방법은,상기 제2 카메라 센서를 통해, 하나 이상의 이미지를 획득하는 단계; 및상기 제1 카메라 센서로부터의 상기 패스-스루 이미지, 상기 제2 카메라 센서로부터의 상기 하나 이상의 이미지, 및 상기 깊이 맵에 기초하여, 임베디드(embedded) 추적을 수행하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 제1 카메라 센서는 RGB 카메라 센서에 대응하고, 상기 제2 카메라 센서는 모노 카메라 센서에 대응하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 임베디드 추적을 수행하는 단계는, 상기 HMD의 위치 추적 및 상기 HMD의 사용자의 사용자 신체 추적 중 적어도 하나를 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 위치 추적을 수행하는 단계는,상기 제1 카메라 센서로부터의 상기 패스-스루 이미지 및 상기 제2 카메라 센서로부터의 하나 이상의 이미지에서 회전 및 스케일링된 불변 2차원(2D) 이미지 특징부들을 검출하는 단계;상기 검출된 특징부들 각각에 대한 깊이를 추정하는 단계;상기 검출된 특징부들의 각각의 추정된 깊이에 기초하여 3차원(3D) 포인트 클라우드를 생성하는 단계; 및위치 변화들을 추론하기 위해 상기 3D 포인트 클라우드를 실시간으로 추적하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 HMD의 관성 측정 유닛(IMU)으로부터 관성 측정들을 획득하는 단계를 더 포함하고, 상기 위치 추적을 수행하는 단계는, 상기 제1 카메라 센서로부터의 상기 패스-스루 이미지 및 상기 제2 카메라 센서로부터의 상기 하나 이상의 이미지가 불충분한 정보를 제공할 때, 상기 관성 측정들에 기초하여 위치 변화들을 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서, 상기 사용자 신체 추적을 수행하는 단계는,상기 깊이 맵 상에서 신체 세그먼트화(body segmentation)를 수행하는 단계;상기 깊이 맵 및 상기 신체 세그먼트화로부터 신체 메시(body mesh)를 추출하는 단계;상기 신체 메시에 기초하여 스켈레톤 모델을 추출하는 단계; 및상기 HMD의 상기 사용자의 신체 모션을 추적하고 상기 스켈레톤 모델 및 상기 HMD의 상기 사용자의 신체 모션을 제스처 모델들에 매칭함으로써 미리 정의된 제스처들을 인식하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제2항에 있어서, 상기 임베디드 추적을 수행하는 단계는 상기 물리적 환경 내의 하나 이상의 물리적 객체에 대한 환경 추적을 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 환경 추적을 수행하는 단계는,상기 제1 카메라 센서로부터의 상기 패스-스루 이미지, 상기 제2 카메라 센서로부터의 상기 하나 이상의 이미지, 및 상기 임베디드 추적을 사용하여 상기 물리적 환경 내의 상기 하나 이상의 물리적 객체와 연관된 모션 모델을 생성하는 단계;상기 모션 모델과 연관된 키포인트들을 검출하는 단계;견고한 특징부 디스크립터들을 사용하여 상기 키포인트들에 국부적인 특징부들을 추출하는 단계; 및상기 깊이 맵을 상기 추출된 특징부들과 융합함으로써 업데이트된 특징부 디스크립터들을 추정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 키포인트들은 해리스(Harris) 코너, 불변 휴-모멘트(Hu-moment)들에 기초한 로컬 극한점들, 및 헤시안즈(Hessians)의 결정자들 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서, 상기 견고한 특징부 디스크립터들은 히스토그램 오브 그래디언트(histogram of gradients) 또는 하(Haar)형 특징부 디스크립터들에 대응하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제9항에 있어서, 상기 키포인트들에 국부적인 특징부들을 추출하는 단계는 분류 알고리즘 또는 지원 벡터 머신(support vector machine) 중 하나를 사용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제2항에 있어서, 상기 제1 및 제2 카메라 센서들은 공통 축을 공유하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 깊이 맵은, 광선이 비행 시간(ToF) 카메라 센서와 연관된 IR 방출기를 떠나서 상기 ToF 카메라 센서로 복귀하는데 소요되는 시간의 양에 기초하여 상기 HMD의 상기 ToF 카메라 센서에 의해 획득되는, 방법.</claim></claimInfo><claimInfo><claim>15. 머리 장착 디바이스(HMD)로서,제1 및 제2 카메라 센서들 및 디스플레이와 통신하기 위한 통신 인터페이스;하나 이상의 프로세서; 및하나 이상의 프로그램을 저장한 비일시적 메모리를 포함하고, 상기 하나 이상의 프로그램은, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 HMD로 하여금, 상기 제1 및 제2 카메라 센서들을 통해, 물리적 환경의 패스-스루 스테레오 뷰 이미지를 획득하고; 상기 물리적 환경과 연관된 깊이 맵을 획득하고; 가상 콘텐츠와 연관된 렌더링된 그래픽들을 생성하고; 상기 깊이 맵에 기초하여 상기 렌더링된 그래픽들을 상기 물리적 환경의 상기 패스-스루 스테레오 뷰 이미지와 혼합함으로써 디스플레이 이미지를 생성하고; 상기 디스플레이를 통해, 상기 디스플레이 이미지를 디스플레이하게 하는, 머리 장착 디바이스(HMD).</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 HMD는 제3 및 제4 카메라 센서들을 포함하고, 상기 하나 이상의 프로그램은 추가로 상기 HMD로 하여금,상기 제3 및 제4 카메라 센서들을 통해, 스테레오 이미지들을 획득하고;상기 제1 및 제2 카메라 센서들로부터의 상기 패스-스루 스테레오 뷰 이미지, 상기 제3 및 제4 카메라 센서들로부터의 상기 스테레오 이미지들, 및 상기 깊이 맵에 기초하여, 임베디드 추적을 수행하게 하는, 머리 장착 디바이스(HMD).</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 제1 및 제2 카메라 센서들은 RGB 스테레오 카메라 센서들에 대응하고, 상기 제3 및 제4 카메라 센서들은 모노 스테레오 카메라 센서들에 대응하는, 머리 장착 디바이스(HMD).</claim></claimInfo><claimInfo><claim>18. 명령어들이 인코딩되어 있는 비일시적 컴퓨터 판독 가능 매체로서, 상기 명령어들은, 디스플레이 및 제1 및 제2 RGB 스테레오 카메라들과 통신하기 위한 통신 인터페이스를 포함하는 머리 장착 디바이스(HMD)의 하나 이상의 프로세서에 의해 실행될 때, 상기 HMD로 하여금, 상기 제1 및 제2 RGB 스테레오 카메라들을 통해, 물리적 환경의 패스-스루 스테레오 뷰 이미지를 획득하고; 상기 물리적 환경과 연관된 깊이 맵을 획득하고; 가상 콘텐츠와 연관된 렌더링된 그래픽들을 생성하고; 상기 깊이 맵에 기초하여 상기 렌더링된 그래픽들을 상기 물리적 환경의 패스-스루 스테레오 뷰 이미지와 혼합함으로써 디스플레이 이미지를 생성하고; 상기 디스플레이를 통해, 상기 디스플레이 이미지를 디스플레이하게 하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 HMD는 제3 및 제4 모노 카메라 센서들을 포함하고, 상기 명령어들은 추가로 상기 HMD로 하여금,상기 제3 및 제4 모노 카메라 센서들을 통해, 스테레오 이미지들을 획득하고,상기 제1 및 제2 RGB 스테레오 카메라 센서들로부터의 상기 패스-스루 스테레오 뷰 이미지, 상기 제3 및 제4 모노 카메라 센서들로부터의 상기 스테레오 이미지들, 및 상기 깊이 맵에 기초하여, 임베디드 추적을 수행하게 하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 임베디드 추적을 수행하는 것은, 상기 HMD의 위치 추적 및 상기 HMD의 사용자의 사용자 신체 추적 중 적어도 하나를 수행하는 것을 포함하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 (우편번호 *****) 쿠퍼티노 원 애플 파크 웨이</address><code>519990306386</code><country>미국</country><engName>Apple Inc.</engName><name>애플 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>캐나다 에이치*비 *에이* 퀘백주 몬트리...</address><code> </code><country> </country><engName>FORTIN-DESCHENES, Simon</engName><name>포르틴-데쉐네스, 사이먼</name></inventorInfo><inventorInfo><address>캐나다 에이치*비 *에이* 퀘백주 몬트리...</address><code> </code><country> </country><engName>CHAPDELAINE-COUTURE, Vincent</engName><name>차프델레인-쿠튀르, 빈센트</name></inventorInfo><inventorInfo><address>캐나다 에이치*비 *에이* 퀘백주 몬트리...</address><code> </code><country> </country><engName>COTE, Yan</engName><name>코테, 얀</name></inventorInfo><inventorInfo><address>캐나다 에이치*비 *에이* 퀘백주 몬트리...</address><code> </code><country> </country><engName>GHANNOUM, Anthony</engName><name>간노움, 앤서니</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 사직로*길 **, *층 (내자동)(김.장 법률사무소)</address><code>919980005034</code><country>대한민국</country><engName>CHANG, Duck Soon</engName><name>장덕순</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2016.02.18</priorityApplicationDate><priorityApplicationNumber>62/296,829</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2024.04.12</receiptDate><receiptNumber>1-1-2024-0403720-73</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2024.06.12</receiptDate><receiptNumber>9-5-2024-0487458-08</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[지정기간연장]기간 연장신청서·기간 단축신청서·기간 경과 구제신청서·절차 계속신청서</documentName><receiptDate>2024.08.12</receiptDate><receiptNumber>1-1-2024-0873650-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2024.09.10</receiptDate><receiptNumber>1-1-2024-0992387-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Decision to Refuse a Patent</documentEngName><documentName>거절결정서</documentName><receiptDate>2025.02.24</receiptDate><receiptNumber>9-5-2025-0191373-41</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.04.16</receiptDate><receiptNumber>1-1-2025-0430254-65</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인 (Acceptance of amendment) </commonCodeName><documentEngName>Amendment to Description, etc(Reexamination)</documentEngName><documentName>[명세서등 보정]보정서(재심사)</documentName><receiptDate>2025.04.16</receiptDate><receiptNumber>1-1-2025-0430244-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.09.29</receiptDate><receiptNumber>9-5-2025-0945553-93</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247012239.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d5cd3db0349deb55af3f9286dadce3ce50b722a63250c11ca316ebd02e0c2dc1e37fd44e1453a488dc25a71d3040213d67da06c947c7e84e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd221ef5562b82aebf9a5fdd2fa2d86dc25868abe2b8f0518d7b0eeb8fddb57577b8846ce6cc9c0f9fafdd8c4afa2adb8737c0a4600041f14</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>