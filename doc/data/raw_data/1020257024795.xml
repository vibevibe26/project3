<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:10.4010</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7024795</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>머신 판독가능 광학 라벨을 사용한 디바이스 페어링</inventionTitle><inventionTitleEng>DEVICE PAIRING USING MACHINE-READABLE OPTICAL LABEL</inventionTitleEng><openDate>2025.08.28</openDate><openNumber>10-2025-0129049</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.07.23</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06K 19/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 별개의 증강 현실(AR) 디바이스들로부터 좌표계들을 정렬하기 위한 방법이 설명된다. 일 양태에서, 제1 디바이스는 제1 디바이스의 제1 VIO(Visual Inertial Odometry) 시스템으로부터의 제1 자세 데이터에 액세스한다. 제1 디바이스의 카메라는 제2 디바이스의 디스플레이 상에 디스플레이되는 머신 판독가능 코드의 이미지를 캡처한다. 제2 디바이스는 머신 판독가능 코드를 제2 디바이스의 제2 VIO 시스템으로부터의 제2 자세 데이터로 인코딩한다. 제1 디바이스는 머신 판독가능 코드로부터 제2 자세 데이터를 디코딩하고, 제1 자세 데이터 및 제2 자세 데이터에 기초하여 제1 디바이스와 제2 디바이스 사이의 상대적 자세를 결정한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.07.04</internationOpenDate><internationOpenNumber>WO2024145124</internationOpenNumber><internationalApplicationDate>2023.12.20</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/085194</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,제1 디바이스의 제1 VIO(Visual Inertial Odometry) 시스템으로부터 제1 자세 데이터에 액세스하는 단계;제1 디바이스의 카메라를 사용하여, 제2 디바이스의 디스플레이 상에 디스플레이되는 머신 판독가능 코드의 이미지에 액세스하는 단계- 상기 머신 판독가능 코드는 상기 제2 디바이스에 의해 상기 제2 디바이스의 제2 VIO 시스템으로부터의 제2 자세 데이터로 인코딩됨 -;상기 제1 디바이스에서, 상기 머신 판독가능 코드로부터 상기 제2 자세 데이터를 디코딩하는 단계; 및상기 제1 디바이스에서, 상기 제1 자세 데이터 및 상기 제2 자세 데이터에 기초하여 상기 제1 디바이스와 상기 제2 디바이스 사이의 상대적 자세를 결정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제2 디바이스는:상기 제2 VIO 시스템에 의해 생성된 상기 제2 자세 데이터 및 메타데이터를 상기 머신 판독가능 코드로 인코딩하고;상기 머신 판독가능 코드의 이미지를 상기 제2 디바이스의 상기 제2 디스플레이에 디스플레이하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 머신 판독가능 코드는 QR 코드를 포함하고, 상기 QR 코드의 외측 부분은 인코딩된 제1 자세 데이터 및 메타데이터를 포함하고, 상기 QR 코드의 내측 부분은 상기 외측 부분에 대해 미리 정의된 크기를 갖는 미리 정의된 제2 패턴을 포함하며,상기 메타데이터는 상기 제2 디바이스의 카메라의 위치 및 상기 제2 디바이스의 디스플레이의 교정된 관계 파라미터들을 표시하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 상대적 자세를 결정하는 단계는:상기 제1 자세 데이터에 기초하여 상기 제1 VIO 시스템의 제1 기준 좌표 프레임을 식별하는 단계;상기 제2 자세 데이터에 기초하여 상기 제2 VIO 시스템의 제2 기준 좌표 프레임을 식별하는 단계; 및상기 제1 기준 좌표 프레임과 상기 제2 기준 좌표 프레임의 정렬에 기초하여 상기 상대적 자세를 검출하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 상대적 자세를 결정하는 단계는:상기 제1 자세 데이터에 기초하여 상기 제1 VIO 시스템의 제1 기준 좌표 프레임을 식별하는 단계;상기 제2 자세 데이터에 기초하여 상기 제2 VIO 시스템의 제2 기준 좌표 프레임을 식별하는 단계; 및상기 제1 기준 좌표 프레임 및 상기 제2 기준 좌표 프레임에 기초하여 세계 기준 좌표계를 형성하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제1 디바이스의 상기 제1 자세 데이터 및 상기 상대적 자세에 기초하여 상기 제1 디바이스의 디스플레이에 제1 가상 객체를 디스플레이하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 상대적 자세를 상기 제2 디바이스에 통신하는 단계를 추가로 포함하고;상기 제2 디바이스는 상기 제2 디바이스의 상기 제2 자세 데이터 및 상기 상대적 자세에 기초하여 제2 가상 객체를 디스플레이하도록 구성되고,상기 제2 가상 객체는 상기 제1 가상 객체에 대응하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 제1 디바이스는 상기 제1 디바이스의 상기 제1 자세 데이터에 대응하는 제1 타임스탬프를 식별하도록 구성되고,상기 제2 디바이스는 상기 제2 디바이스의 제2 자세 데이터에 액세스하는 것에 응답하여 제2 타임스탬프를 생성하고,상기 방법은:상기 제1 타임스탬프와 상기 제2 타임스탬프 사이의 차이가 미리 설정된 임계값 내에 있다고 결정하는 단계; 및상기 제1 타임스탬프와 상기 제2 타임스탬프 사이의 차이가 상기 미리 설정된 임계값 내에 있는 것에 응답하여, 상기 제1 디바이스와 상기 제2 디바이스 사이의 상대적 자세를 결정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 제1 디바이스는 투명 디스플레이를 갖는 웨어러블 디바이스를 포함하고, 상기 웨어러블 디바이스는 제1 증강 현실 애플리케이션을 동작시키도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 제2 디바이스는 불투명 터치스크린을 갖는 핸드헬드 모바일 디바이스를 포함하고, 상기 핸드헬드 모바일 디바이스는 제2 증강 현실 애플리케이션을 동작시키도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨팅 장치로서,프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때:제1 디바이스의 제1 VIO(Visual Inertial Odometry) 시스템으로부터 제1 자세 데이터에 액세스하고;제1 디바이스의 카메라를 사용하여, 제2 디바이스의 디스플레이 상에 디스플레이되는 머신 판독가능 코드의 이미지에 액세스하고- 상기 머신 판독가능 코드는 상기 제2 디바이스에 의해 상기 제2 디바이스의 제2 VIO 시스템으로부터의 제2 자세 데이터로 인코딩됨 -;상기 제1 디바이스에서, 상기 머신 판독가능 코드로부터 상기 제2 자세 데이터를 디코딩하고;상기 제1 디바이스에서, 상기 제1 자세 데이터 및 상기 제2 자세 데이터에 기초하여 상기 제1 디바이스와 상기 제2 디바이스 사이의 상대적 자세를 결정하도록 상기 장치를 구성하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제2 디바이스는:상기 제2 VIO 시스템에 의해 생성된 상기 제2 자세 데이터 및 메타데이터를 상기 머신 판독가능 코드로 인코딩하고;상기 머신 판독가능 코드의 이미지를 상기 제2 디바이스의 상기 제2 디스플레이에 디스플레이하도록 구성되는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 머신 판독가능 코드는 QR 코드를 포함하고, 상기 QR 코드의 외측 부분은 인코딩된 제1 자세 데이터 및 메타데이터를 포함하고, 상기 QR 코드의 내측 부분은 상기 외측 부분에 대해 미리 정의된 크기를 갖는 미리 정의된 제2 패턴을 포함하며,상기 메타데이터는 상기 제2 디바이스의 카메라의 위치 및 상기 제2 디바이스의 디스플레이의 교정된 관계 파라미터들을 표시하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 상대적 자세를 결정하는 것은:상기 제1 자세 데이터에 기초하여 상기 제1 VIO 시스템의 제1 기준 좌표 프레임을 식별하는 것;상기 제2 자세 데이터에 기초하여 상기 제2 VIO 시스템의 제2 기준 좌표 프레임을 식별하는 것; 및상기 제1 기준 좌표 프레임과 상기 제2 기준 좌표 프레임의 정렬에 기초하여 상기 상대적 자세를 검출하는 것을 추가로 포함하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 상대적 자세를 결정하는 것은:상기 제1 자세 데이터에 기초하여 상기 제1 VIO 시스템의 제1 기준 좌표 프레임을 식별하는 것;상기 제2 자세 데이터에 기초하여 상기 제2 VIO 시스템의 제2 기준 좌표 프레임을 식별하는 것; 및상기 제1 기준 좌표 프레임 및 상기 제2 기준 좌표 프레임에 기초하여 세계 기준 좌표계를 형성하는 것을 추가로 포함하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 명령어들은:상기 제1 디바이스의 상기 제1 자세 데이터 및 상기 상대적 자세에 기초하여 상기 제1 디바이스의 디스플레이에 제1 가상 객체를 디스플레이하도록 상기 장치를 추가로 구성하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 명령어들은:상기 상대적 자세를 상기 제2 디바이스에 통신하도록 상기 장치를 추가로 구성하고,상기 제2 디바이스는 상기 제2 디바이스의 상기 제2 자세 데이터 및 상기 상대적 자세에 기초하여 제2 가상 객체를 디스플레이하도록 구성되고,상기 제2 가상 객체는 상기 제1 가상 객체에 대응하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 제1 디바이스는 상기 제1 디바이스의 상기 제1 자세 데이터에 대응하는 제1 타임스탬프를 식별하도록 구성되고,상기 제2 디바이스는 상기 제2 디바이스의 제2 자세 데이터에 액세스하는 것에 응답하여 제2 타임스탬프를 생성하고,방법은:상기 제1 타임스탬프와 상기 제2 타임스탬프 사이의 차이가 미리 설정된 임계값 내에 있다고 결정하는 단계; 및상기 제1 타임스탬프와 상기 제2 타임스탬프 사이의 차이가 상기 미리 설정된 임계값 내에 있는 것에 응답하여, 상기 제1 디바이스와 상기 제2 디바이스 사이의 상대적 자세를 결정하는 단계를 포함하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 제1 디바이스는 투명 디스플레이를 갖는 웨어러블 디바이스를 포함하고, 상기 웨어러블 디바이스는 제1 증강 현실 애플리케이션을 동작시키도록 구성되고,상기 제2 디바이스는 불투명 터치스크린을 갖는 핸드헬드 모바일 디바이스를 포함하고, 상기 핸드헬드 모바일 디바이스는 제2 증강 현실 애플리케이션을 동작시키도록 구성되는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>20. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금:제1 디바이스의 제1 VIO(Visual Inertial Odometry) 시스템으로부터 제1 자세 데이터에 액세스하게 하고;제1 디바이스의 카메라를 사용하여, 제2 디바이스의 디스플레이 상에 디스플레이되는 머신 판독가능 코드의 이미지에 액세스하게 하고- 상기 머신 판독가능 코드는 상기 제2 디바이스에 의해 상기 제2 디바이스의 제2 VIO 시스템으로부터의 제2 자세 데이터로 인코딩됨 -;상기 제1 디바이스에서, 상기 머신 판독가능 코드로부터 상기 제2 자세 데이터를 디코딩하게 하고;상기 제1 디바이스에서, 상기 제1 자세 데이터 및 상기 제2 자세 데이터에 기초하여 상기 제1 디바이스와 상기 제2 디바이스 사이의 상대적 자세를 결정하게 하는 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>그리스</country><engName>EVANGELIDIS, Georgios</engName><name>에반겔리디스, 게오르기오스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.03.21</priorityApplicationDate><priorityApplicationNumber>18/124,099</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>그리스</priorityApplicationCountry><priorityApplicationDate>2022.12.29</priorityApplicationDate><priorityApplicationNumber>20220101085</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.07.23</receiptDate><receiptNumber>1-1-2025-0836175-67</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.07.28</receiptDate><receiptNumber>1-5-2025-0126736-55</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257024795.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93fe63ff13cf57aae4597267e65b49c9354e6a4066d9a9d77ec958e4b9176ccc9ae5cd3a73143a0b3752527f5f094223a39c2a3cf3b68c5548</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbc1808a92c06af338ae8eabbb0f8c97b570294b594ed2030f6be55323cedd74b5251b41dcf6a673b25f3274b18a35945fb3a6ce45a3e3e3c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>