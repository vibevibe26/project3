<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:23:01.231</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.02</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7029269</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>머신 학습 모델들을 위한 분산형 로딩 및 트레이닝</inventionTitle><inventionTitleEng>DISTRIBUTED LOADING AND TRAINING FOR MACHINE LEARNING MODELS</inventionTitleEng><openDate>2025.10.02</openDate><openNumber>10-2025-0143811</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.09.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.09.02</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 67/563</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 분산형 컴퓨터 시스템에서의 하나 이상의 데이터 로더는 스토리지 컴포넌트로부터의 입력 데이터에 액세스한다. 분산형 컴퓨터 시스템에서의 트레이너는 트레이닝 데이터 요청을 송신한다. 트레이너 및 하나 이상의 데이터 로더는 별도의 프로세서들 상에서 실행된다. 하나 이상의 데이터 로더 중의 데이터 로더에 의해, 트레이닝 데이터 요청을 수신하는 것에 응답하여, 데이터 로더는 트레이닝 일괄처리를 생성하기 위해 데이터 로딩 작업을 실행한다. 데이터 로더는 트레이닝 일괄처리를 트레이너에 송신한다. 트레이너는 머신 학습 알고리즘을 실행하기 위해 트레이닝 일괄처리를 사용하는 것을 포함하는 트레이닝 작업을 실행한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.08.08</internationOpenDate><internationOpenNumber>WO2024163863</internationOpenNumber><internationalApplicationDate>2024.02.02</internationalApplicationDate><internationalApplicationNumber>PCT/US2024/014195</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,분산형 컴퓨터 시스템에서의 하나 이상의 데이터 로더에 의해, 스토리지 컴포넌트로부터의 입력 데이터에 액세스하는 단계;상기 분산형 컴퓨터 시스템에서의 트레이너에 의해, 트레이닝 데이터 요청을 송신하는 단계- 상기 트레이너는 상기 하나 이상의 데이터 로더에 통신가능하게 연결되고, 상기 트레이너 및 상기 하나 이상의 데이터 로더는 별도의 프로세서들 상에서 실행됨 -;상기 하나 이상의 데이터 로더 중의 데이터 로더에 의해, 상기 트레이닝 데이터 요청을 수신하는 것에 응답하여, 상기 데이터 로더에 의해, 데이터 로딩 작업을 실행하는 단계- 상기 데이터 로딩 작업은 트레이닝 일괄처리를 생성하기 위해 상기 입력 데이터로부터 판독되는 입력 일괄처리를 전처리하는 것을 포함함 -;상기 데이터 로더에 의해, 상기 트레이닝 일괄처리를 상기 트레이너에 송신하는 단계; 및상기 트레이너에 의해, 트레이닝 작업을 실행하는 단계- 상기 트레이닝 작업은 모델 구축 프로세스에서 머신 학습 알고리즘을 실행하기 위해 상기 트레이닝 일괄처리를 사용하는 것을 포함함 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 분산형 컴퓨터 시스템에서의 CPU(Central Processing Unit) 리소스들을 상기 하나 이상의 데이터 로더에 할당하는 단계; 및상기 분산형 컴퓨터 시스템에서의 GPU(Graphics Processing Unit) 리소스들을 상기 트레이너에 할당하는 단계- 상기 GPU 리소스들은 각각의 데이터 로더가 상기 GPU 리소스들 중 어느 것도 이용하지 않도록 할당됨 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 트레이너와 하나 이상의 데이터 로더 사이의 통신이 서비스 메시를 통해 이루어지도록 하나 이상의 네트워크 프록시를 배치하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 하나 이상의 네트워크 프록시를 배치하는 단계는 상기 트레이너 또는 상기 하나 이상의 데이터 로더와 고유하게 연관하여 각각의 네트워크 프록시를 배치하는 것에 의해 상기 서비스 메시의 데이터 평면을 정의하는 단계- 각각의 네트워크 프록시는 상기 서비스 메시의 제어 평면에 통신가능하게 연결됨 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 하나 이상의 데이터 로더는 상기 트레이너와 상기 데이터 로더 사이의 일-대-다 관계를 정의하는 복수의 데이터 로더인- 각각의 데이터 로더는 상기 네트워크 프록시들 중 하나와 고유하게 연관됨 - 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 트레이너에 의해, 트레이닝 데이터 요청들을 상기 복수의 데이터 로더들 각각에 송신하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 트레이닝 데이터 요청들은 RPC(Remote Procedure Call) 프로토콜을 사용하여 송신되는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, RPC 프로토콜은 gRPC인 방법.</claim></claimInfo><claimInfo><claim>9. 제5항에 있어서, 각각의 데이터 로더는 상기 분산형 컴퓨터 시스템에서의 서비스의 별도의 인스턴스인 방법.</claim></claimInfo><claimInfo><claim>10. 제6항에 있어서,상기 서비스 메시에 의해, 상기 트레이너와 상기 복수의 데이터 로더들 사이의 트래픽을 제어하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제6항에 있어서,상기 네트워크 프록시들에 의해, 상기 트레이너의 이용을 최적화하기 위해 상기 트레이닝 데이터 요청들을 상기 데이터 로더들로 라우팅하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 라우팅은 상기 데이터 로더들 중 어느 것에 각각의 트레이닝 데이터 요청을 송신할지를 결정하기 위해 응답 레이턴시들의 지수적-가중 이동 평균(exponentially-weighted moving average)을 사용하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제7항에 있어서, 상기 트레이닝 데이터 요청들은 서비스-대-서비스 호출들인- 상기 트레이너와 연관된 상기 네트워크 프록시는 상기 복수의 데이터 로더들에 걸쳐 상기 트레이닝 데이터 요청들을 로드 밸런싱하도록 구성됨 - 방법.</claim></claimInfo><claimInfo><claim>14. 제4항에 있어서, 상기 트레이너 및 각각의 데이터 로더는 상기 분산형 컴퓨터 시스템에서의 각각의 포드에 의해 실행되는- 각각의 네트워크 프록시는 상기 네트워크 프록시와 연관된 상기 데이터 로더 또는 상기 트레이너의 상기 포드에 추가되는 프록시 컨테이너임 - 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 상기 하나 이상의 데이터 로더 및 상기 트레이너는 상기 분산형 컴퓨터 시스템에서의 상이한 머신들 상에서 실행되는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서,각각의 데이터 로더에 의해, 다중-생산자, 다중-소비자 큐(multi-producer, multi-consumer queue)를 구현하는 단계- 상기 구현하는 단계는 판독 작업과 적어도 부분적으로 병렬로 상기 전처리를 수행하는 단계를 포함하고, 상기 판독 작업은, 상기 데이터 로더에 의해, 상기 스토리지 컴포넌트로부터 하나 이상의 입력 일괄처리를 페치하는 단계 및 상기 하나 이상의 입력 일괄처리를 상기 데이터 로더의 전처리 큐에 추가하는 단계를 포함함 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서, 상기 입력 데이터는 손 검출 데이터, 손 추적 데이터, 제스처 검출 데이터, 또는 제스처 추적 데이터 중 적어도 하나를 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 트레이너는 상기 하나 이상의 데이터 로더에 의해 상이한 입력 일괄처리들로부터 생성되는 복수의 트레이닝 일괄처리들을 사용하여 상기 트레이닝 작업이 반복되는 것을 허가하기 위해 복수의 추가적인 트레이닝 데이터 요청들을 송신하도록 구성되고, 상기 방법은, 상기 트레이너에 의해, 상기 모델 구축 프로세스에서의 상기 트레이닝 작업들의 결과에 기초하여 객체 추적 모델을 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>19. 분산형 컴퓨팅 시스템으로서,하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행될 때 상기 하나 이상의 프로세서로 하여금 동작들을 수행하게 하는 명령어들을 포함하는 비-일시적 컴퓨터 판독가능 저장 매체를 포함하고, 상기 동작들은,분산형 컴퓨터 시스템에서의 하나 이상의 데이터 로더에 의해, 스토리지 컴포넌트로부터의 입력 데이터에 액세스하는 동작;상기 분산형 컴퓨터 시스템에서의 트레이너에 의해, 트레이닝 데이터 요청을 송신하는 동작- 상기 트레이너는 상기 하나 이상의 데이터 로더에 통신가능하게 연결되고, 상기 트레이너 및 상기 하나 이상의 데이터 로더는 별도의 프로세서들 상에서 실행됨 -;상기 하나 이상의 데이터 로더 중의 데이터 로더에 의해, 상기 트레이닝 데이터 요청을 수신하는 것에 응답하여, 상기 데이터 로더에 의해, 데이터 로딩 작업을 실행하는 동작- 상기 데이터 로딩 작업은 트레이닝 일괄처리를 생성하기 위해 상기 입력 데이터로부터 판독되는 입력 일괄처리를 전처리하는 것을 포함함 -;상기 데이터 로더에 의해, 상기 트레이닝 일괄처리를 상기 트레이너에 송신하는 동작; 및상기 트레이너에 의해, 트레이닝 작업을 실행하는 동작- 상기 트레이닝 작업은 모델 구축 프로세스에서 머신 학습 알고리즘을 실행하기 위해 상기 트레이닝 일괄처리를 사용하는 것을 포함함 -을 포함하는 분산형 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어 데이터를 갖는 머신-판독가능 비-일시적 저장 매체로서, 상기 명령어 데이터는 머신에 의해 실행가능하여 상기 머신으로 하여금 동작들을 수행하게 하고, 상기 동작들은,분산형 컴퓨터 시스템에서의 하나 이상의 데이터 로더에 의해, 스토리지 컴포넌트로부터의 입력 데이터에 액세스하는 동작;상기 분산형 컴퓨터 시스템에서의 트레이너에 의해, 트레이닝 데이터 요청을 송신하는 동작- 상기 트레이너는 상기 하나 이상의 데이터 로더에 통신가능하게 연결되고, 상기 트레이너 및 상기 하나 이상의 데이터 로더는 별도의 프로세서들 상에서 실행됨 -;상기 하나 이상의 데이터 로더 중의 데이터 로더에 의해, 상기 트레이닝 데이터 요청을 수신하는 것에 응답하여, 상기 데이터 로더에 의해, 데이터 로딩 작업을 실행하는 동작- 상기 데이터 로딩 작업은 트레이닝 일괄처리를 생성하기 위해 상기 입력 데이터로부터 판독되는 입력 일괄처리를 전처리하는 것을 포함함 -;상기 데이터 로더에 의해, 상기 트레이닝 일괄처리를 상기 트레이너에 송신하는 동작; 및상기 트레이너에 의해, 트레이닝 작업을 실행하는 동작- 상기 트레이닝 작업은 모델 구축 프로세스에서 머신 학습 알고리즘을 실행하기 위해 상기 트레이닝 일괄처리를 사용하는 것을 포함함 -을 포함하는 머신-판독가능 비-일시적 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>ZHONG, Lin</engName><name>종, 린</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>러시아</country><engName>CHAKHVADZE, Artur</engName><name>차크바드제, 알터</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>미국</country><engName>HU, Yang</engName><name>후, 양</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.02.03</priorityApplicationDate><priorityApplicationNumber>18/164,230</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.09.02</receiptDate><receiptNumber>1-1-2025-1006461-54</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.09.04</receiptDate><receiptNumber>1-5-2025-0150571-26</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257029269.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d845279955cad783cd3189fd5662e42decbf967b99001b7357573d79e7b5f3af9246dfec551eb296f57ba0dbc5043780f0b2601b47db663e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd425841bf85ad0f0f03eae8eac1ddda296814b08fdfa527237ffe1ef076934aaf149e951a04ee7d3ab4bc6640aa2381292a61c465ab9fb21</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>