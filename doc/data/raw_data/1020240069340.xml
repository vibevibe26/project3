<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:29.4129</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.05.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0069340</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공지능 모델을 이용하여 조직학 이미지로부터 유전자 발현을 예측하는 방법 및 전자 장치</inventionTitle><inventionTitleEng>METHOD AND ELECTRONIC DEVICE FOR PREDICT GENE EXPRESSION  FROM HISTOLOGY IMAGE</inventionTitleEng><openDate>2025.06.25</openDate><openNumber>10-2025-0094514</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.05.28</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G16B 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G16B 25/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G16B 45/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>C12Q 1/6886</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 실시예에서, 전자 장치가 유전자 발현(gene expression)을 예측하는 방법은, 상기 조직학 이미지의 제1 스팟 이미지에 대응하는 글로벌 피쳐 데이터를 획득하는 단계, 제1 스팟 이미지에 대응하는 로컬 피쳐 데이터를 획득하는 단계, 제1 스팟 이미지에 대응하는 이웃 피쳐 데이터를 획득하는 단계 및 글로벌 피쳐 데이터, 로컬 피쳐 데이터 및 이웃 피쳐 데이터를 기초로, 제1 스팟 이미지에 대한 유전자 발현을 예측하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치가 인공지능 모델을 이용하여 조직학 이미지(histology image)로부터 유전자 발현(gene expression)을 예측하는 방법에 있어서,제1 인공지능 모델을 이용하여, 상기 조직학 이미지의 제1 스팟 이미지 및 제2 스팟 이미지를 기초로 제1 스팟 이미지에 대응하는 글로벌 피쳐 데이터를 획득하는 단계;제2 인공지능 모델을 이용하여, 상기 제1 스팟 이미지로부터 상기 제1 스팟 이미지에 대응하는 로컬 피쳐 데이터를 획득하는 단계;제3 인공지능 모델을 이용하여, 상기 조직학 이미지에서 상기 제1 스팟 이미지와 주변 영역을 포함하는 이웃(neighbor) 이미지를 기초로 상기 제1 스팟 이미지에 대응하는 이웃 피쳐 데이터를 획득하는 단계; 및제4 인공지능 모델을 이용하여, 상기 글로벌 피쳐 데이터, 상기 로컬 피쳐 데이터 및 상기 이웃 피쳐 데이터를 기초로, 상기 제1 스팟 이미지에 대한 유전자 발현을 예측하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,제4 인공지능 모델을 이용하여, 상기 글로벌 피쳐 데이터, 상기 로컬 피쳐 데이터 및 상기 이웃 피쳐 데이터를 기초로, 상기 제1 스팟 이미지에 대한 유전자 발현을 예측하는 단계는,제5 인공지능 모델을 이용하여, 상기 글로벌 피쳐 데이터, 상기 로컬 피쳐 데이터 및 상기 이웃 피쳐 데이터를 기초로, 상기 제1 스팟 이미지에 대응하는 퓨전 피쳐 데이터를 획득하는 단계; 및상기 제4 인공지능 모델을 이용하여, 상기 퓨전 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대한 유전자 발현을 예측하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제1 스팟 이미지에 대응하는 퓨전 피쳐 데이터를 획득하는 단계는,상기 제5 인공지능 모델을 이용하여, 상기 글로벌 피쳐 데이터와 상기 이웃 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 글로벌-이웃 퓨전 피쳐 데이터를 획득하고, 상기 글로벌 피쳐 데이터와 상기 로컬 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 글로벌-로컬 퓨전 피쳐 데이터를 획득하는 단계; 및상기 글로벌-이웃 퓨전 피쳐 데이터 및 상기 글로벌-로컬 퓨전 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 퓨전 피쳐 데이터를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 이웃 피쳐 데이터를 획득하는 단계는,상기 이웃 이미지를 제1 서브 영역과 제2 서브 영역을 포함하는 복수의 서브 영역으로 분할하는 단계;기 학습된 모델을 이용하여, 상기 제1 서브 영역으로부터 상기 제1 서브 영역에 대응하는 제1 초기 피쳐 데이터를 획득하고, 상기 제2 서브 영역으로부터 상기 제2 서브 영역에 대응하는 제2 초기 피쳐 데이터를 획득하는 단계; 및상기 제3 인공지능 모델을 이용하여, 상기 제1 초기 피쳐 데이터 및 상기 제2 초기 피쳐 데이터를 기반으로 상기 제1 스팟 이미지에 대응하는 이웃 피쳐 데이터를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 글로벌 피쳐 데이터를 획득하는 단계는,기 학습된 모델을 이용하여, 상기 제1 스팟 이미지로부터 제3 초기 피쳐 데이터를 획득하고, 상기 제2 스팟 이미지로부터 제4 초기 피쳐 데이터를 획득하는 단계; 및상기 제1 인공지능 모델을 이용하여, 상기 제3 초기 피쳐 데이터 및 상기 제4 초기 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 글로벌 피쳐 데이터를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제1 인공지능 모델은, 상기 조직학 이미지에서의 위치 정보를 인코딩하는 위치 정보 인코딩 모델을 포함하고,상기 글로벌 피쳐 데이터를 획득하는 단계는,상기 위치 정보 인코딩 모델을 이용하여, 상기 제1 스팟 이미지의 위치 정보가 인코딩된 상기 제1 스팟 이미지에 대응하는 글로벌 피쳐 데이터를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 제1 인공지능 모델, 상기 제2 인공지능 모델, 상기 제3 인공지능 모델 및 상기 제4 인공지능 모델은 엔드 투 엔드(end-to-end)로 연결되어 동시에 학습되는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제1 인공지능 모델, 상기 제2 인공지능 모델, 상기 제3 인공지능 모델 및 상기 제4 인공지능 모델은, 학습 이미지에 포함된 타겟 스팟 이미지에 대하여 예측되는 유전자 발현 값과 상기 타겟 스팟 이미지에 대한 정답 유전자 발현 값 사이의 차이를 기반으로 하는 손실 함수를 이용하여 학습되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 인공지능 모델, 상기 제2 인공지능 모델, 상기 제3 인공지능 모델 및 상기 제4 인공지능 모델은, 학습 이미지에 포함된 타겟 스팟 이미지에 대응하는 로컬 피쳐 데이터로부터 예측되는 유전자 발현 값, 상기 타겟 스팟 이미지에 대응하는 글로벌 피쳐 데이터로부터 예측되는 유전자 발현 값 또는 상기 타겟 스팟 이미지에 대응하는 이웃 피쳐 데이터로부터 예측되는 유전자 발현 값 중 적어도 하나와 상기 타겟 스팟 이미지에 대응하는 퓨전 피쳐 데이터로부터 예측되는 유전자 발현 값 사이의 차이를 기반으로 하는 손실 함수를 이용하여 학습되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 제1 인공지능 모델, 상기 제2 인공지능 모델, 상기 제3 인공지능 모델 및 상기 제4 인공지능 모델은, 학습 이미지에 포함된 타겟 스팟 이미지에 대응하는 로컬 피쳐 데이터로부터 예측되는 유전자 발현 값, 상기 타겟 스팟 이미지에 대응하는 글로벌 피쳐 데이터로부터 예측되는 유전자 발현 값 또는 상기 타겟 스팟 이미지에 대응하는 이웃 피쳐 데이터로부터 예측되는 유전자 발현 값 중 적어도 하나와 상기 타겟 스팟 이미지에 대한 정답 유전자 발현 값 사이의 차이를 기반으로 하는 손실 함수를 이용하여 학습되는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo><claimInfo><claim>12. 인공지능 모델을 이용하여 조직학 이미지(histology image)로부터 유전자 발현(gene expression)을 예측하는 전자 장치에 있어서,하나 이상의 명령어(instruction)를 저장하는 메모리; 및상기 하나 이상의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서가 상기 하나 이상의 명령어를 실행함으로써 전자 장치는,제1 인공지능 모델을 이용하여, 상기 조직학 이미지의 제1 스팟 이미지 및 제2 스팟 이미지를 기초로 제1 스팟 이미지에 대응하는 글로벌 피쳐 데이터를 획득하고,제2 인공지능 모델을 이용하여, 상기 제1 스팟 이미지로부터 상기 제1 스팟 이미지에 대응하는 로컬 피쳐 데이터를 획득하고,제3 인공지능 모델을 이용하여, 상기 조직학 이미지에서 상기 제1 스팟 이미지와 주변 영역을 포함하는 이웃(neighbor) 이미지를 기초로 상기 제1 스팟 이미지에 대응하는 이웃 피쳐 데이터를 획득하고,제4 인공지능 모델을 이용하여, 상기 글로벌 피쳐 데이터, 상기 로컬 피쳐 데이터 및 상기 이웃 피쳐 데이터를 기초로, 상기 제1 스팟 이미지에 대한 유전자 발현을 예측하는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 적어도 하나의 프로세서가 상기 하나 이상의 명령어를 실행함으로써 전자 장치는,제5 인공지능 모델을 이용하여, 상기 글로벌 피쳐 데이터, 상기 로컬 피쳐 데이터 및 상기 이웃 피쳐 데이터를 기초로, 상기 제1 스팟 이미지에 대응하는 퓨전 피쳐 데이터를 획득하고,상기 제4 인공지능 모델을 이용하여, 상기 퓨전 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대한 유전자 발현을 예측하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 적어도 하나의 프로세서가 상기 하나 이상의 명령어를 실행함으로써 전자 장치는,상기 제5 인공지능 모델을 이용하여, 상기 글로벌 피쳐 데이터와 상기 이웃 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 글로벌-이웃 퓨전 피쳐 데이터를 획득하고, 상기 글로벌 피쳐 데이터와 상기 로컬 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 글로벌-로컬 퓨전 피쳐 데이터를 획득하고,상기 글로벌-이웃 퓨전 피쳐 데이터 및 상기 글로벌-로컬 퓨전 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 퓨전 피쳐 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 적어도 하나의 프로세서가 상기 하나 이상의 명령어를 실행함으로써 전자 장치는,상기 이웃 이미지를 제1 서브 영역과 제2 서브 영역을 포함하는 복수의 서브 영역으로 분할하고,기 학습된 모델을 이용하여, 상기 제1 서브 영역으로부터 상기 제1 서브 영역에 대응하는 제1 초기 피쳐 데이터를 획득하고, 상기 제2 서브 영역으로부터 상기 제2 서브 영역에 대응하는 제2 초기 피쳐 데이터를 획득하고,상기 제3 인공지능 모델을 이용하여, 상기 제1 초기 피쳐 데이터 및 상기 제2 초기 피쳐 데이터를 기반으로 상기 제1 스팟 이미지에 대응하는 이웃 피쳐 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 적어도 하나의 프로세서가 상기 하나 이상의 명령어를 실행함으로써 전자 장치는,기 학습된 모델을 이용하여, 상기 제1 스팟 이미지로부터 제3 초기 피쳐 데이터를 획득하고, 상기 제2 스팟 이미지로부터 제4 초기 피쳐 데이터를 획득하고,상기 제1 인공지능 모델을 이용하여, 상기 제3 초기 피쳐 데이터 및 상기 제4 초기 피쳐 데이터를 기초로 상기 제1 스팟 이미지에 대응하는 글로벌 피쳐 데이터를 획득하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서,상기 제1 인공지능 모델은, 상기 조직학 이미지에서의 위치 정보를 인코딩하는 위치 정보 인코딩 모델을 포함하고,상기 적어도 하나의 프로세서가 상기 하나 이상의 명령어를 실행함으로써 전자 장치는,상기 위치 정보 인코딩 모델을 이용하여, 상기 제1 스팟 이미지의 위치 정보가 인코딩된 상기 제1 스팟 이미지에 대응하는 글로벌 피쳐 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서,상기 제1 인공지능 모델, 상기 제2 인공지능 모델, 상기 제3 인공지능 모델 및 상기 제4 인공지능 모델은, 학습 이미지에 포함된 타겟 스팟 이미지에 대하여 예측되는 유전자 발현 값과 상기 타겟 스팟 이미지에 대한 정답 유전자 발현 값 사이의 차이를 기반으로 하는 손실 함수를 이용하여 학습되는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제12항에 있어서,상기 제1 인공지능 모델, 상기 제2 인공지능 모델, 상기 제3 인공지능 모델 및 상기 제4 인공지능 모델은, 학습 이미지에 포함된 타겟 스팟 이미지에 대응하는 로컬 피쳐 데이터로부터 예측되는 유전자 발현 값, 상기 타겟 스팟 이미지에 대응하는 글로벌 피쳐 데이터로부터 예측되는 유전자 발현 값 또는 상기 타겟 스팟 이미지에 대응하는 이웃 피쳐 데이터로부터 예측되는 유전자 발현 값 중 적어도 하나와 상기 타겟 스팟 이미지에 대응하는 퓨전 피쳐 데이터로부터 예측되는 유전자 발현 값 사이의 차이를 기반으로 하는 손실 함수를 이용하여 학습되는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제12항에 있어서,상기 제1 인공지능 모델, 상기 제2 인공지능 모델, 상기 제3 인공지능 모델 및 상기 제4 인공지능 모델은, 학습 이미지에 포함된 타겟 스팟 이미지에 대응하는 로컬 피쳐 데이터로부터 예측되는 유전자 발현 값, 상기 타겟 스팟 이미지에 대응하는 글로벌 피쳐 데이터로부터 예측되는 유전자 발현 값 또는 상기 타겟 스팟 이미지에 대응하는 이웃 피쳐 데이터로부터 예측되는 유전자 발현 값 중 적어도 하나와 상기 타겟 스팟 이미지에 대한 정답 유전자 발현 값 사이의 차이를 기반으로 하는 손실 함수를 이용하여 학습되는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 장안구...</address><code>220050013604</code><country>대한민국</country><engName>Research ＆ Business Foundation SUNGKYUNKWAN UNIVERSITY</engName><name>성균관대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>CHUNG, Young Min</engName><name>정영민</name></inventorInfo><inventorInfo><address>서울특별시 관악구...</address><code> </code><country> </country><engName>HA, Ji Hoon</engName><name>하지훈</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>LEE, Joo Sang</engName><name>이주상</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.12.18</priorityApplicationDate><priorityApplicationNumber>1020230185082</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.05.28</receiptDate><receiptNumber>1-1-2024-0577746-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.04.09</receiptDate><receiptNumber>4-1-2025-5096062-35</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240069340.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937ec630cf2e4a7e2857e6e78025837c722c658e6f59dc01107a168ffef08aee1c3dd4197a0a7f4c9763ca56c5cef3e4a5bb5c0afbf4c1c9d5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf73701b3b9e784fc02c93c2fa54b5db2ac98422e8f6c69742c16ef4bedf0e375a170d2c8883ce14e3d32bc979414a950604cf0c12ad231228</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>