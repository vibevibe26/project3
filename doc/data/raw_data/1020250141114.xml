<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:46.446</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2025.09.29</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-0141114</applicationNumber><claimCount>17</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>구역에 대한 분석을 수행하기 위한 방법, 시스템 및 비일시성의 컴퓨터 판독 가능한 기록 매체</inventionTitle><inventionTitleEng>METHOD, SYSTEM AND NON-TRANSITORY COMPUTER-READABLE  RECORDING MEDIUM FOR PERFORMING ANALYSIS ON AREAS</inventionTitleEng><openDate>2025.10.20</openDate><openNumber>10-2025-0150514</openNumber><originalApplicationDate>2021.12.24</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2021-0187821</originalApplicationNumber><originalExaminationRequestDate>2025.09.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/187</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020210187821</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 일 태양에 따르면, 구역에 대한 분석을 수행하기 위한 방법으로서, 오프라인 공간에 포함되는 복수의 구역 중에서 분석 대상 구역을 특정하는 단계, 및 상기 오프라인 공간으로부터 획득되는 적어도 하나의 영상 프레임을 참조하여 제1 객체와 상기 분석 대상 구역 사이의 이벤트 발생 여부 또는 상기 제1 객체와 상기 분석 대상 구역 사이에 발생한 이벤트의 유형을 추정하는 단계를 포함하는 방법이 제공된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 구역에 대한 분석을 수행하기 위한 방법으로서,오프라인 공간에 포함되는 복수의 구역 중에서 분석 대상 구역을 특정하는 단계, 및상기 오프라인 공간으로부터 획득되는 적어도 하나의 영상 프레임을 참조하여 제1 객체와 상기 분석 대상 구역 사이의 이벤트 발생 여부 또는 상기 제1 객체와 상기 분석 대상 구역 사이에 발생한 이벤트의 유형을 추정하는 단계를 포함하고,상기 특정 단계에서, 상기 오프라인 공간 내에 위치하는 복수의 객체 중 소정의 기준 포즈를 취하는 객체가 포함되는 구역을 분석 제외 구역으로 특정하고,상기 추정 단계에서, 상기 분석 제외 구역에서 상기 기준 포즈를 취하는 객체의 시각적 특징과 소정 수준 이상으로 일치하는 시각적 특성을 가지는 객체를 상기 이벤트 발생 여부를 추정하기 위한 대상에서 제외하고,상기 시각적 특징은 Re-ID(Re-identification) 모델을 이용하여 추출한 벡터 형식의 텐서인방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 특정 단계에서, 상기 오프라인 공간 내에 위치하는 복수의 객체 중의 하나의 객체를 기준으로 포즈 거리가 소정 수준 이하에 해당하는 객체가 취하는 포즈 및 상기 하나의 객체가 취하는 포즈 중에서 상기 기준 포즈를 결정하는방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 추정 단계에서, 상기 분석 제외 구역에서 상기 기준 포즈와 소정 수준 이상으로 일치하는 포즈를 취하는 객체를 상기 이벤트 발생 여부를 추정하기 위한 대상에서 제외하는방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 추정 단계에서, 상기 분석 제외 구역에서 상기 기준 포즈의 적어도 하나의 특징점과 대응하는 특징점을 포함하는 객체를 상기 이벤트 발생 여부를 추정하기 위한 대상에서 제외하는방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 추정 단계에서, 상기 적어도 하나의 영상 프레임 중에서 상기 제1 객체와 상기 분석 대상 구역 사이에 이벤트가 발생하지 않은 것으로 추정되는 제1 영상 프레임에 대하여, 타임 윈도우를 참조하여 상기 추정 결과의 보정 여부를 결정하는방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 추정 단계에서, 상기 타임 윈도우에 포함되는 복수의 영상 프레임 중에서 상기 제1 객체와 상기 분석 대상 구역 사이에 이벤트가 발생한 것으로 추정되는 영상 프레임의 비율을 참조하여, 상기 제1 영상 프레임에 대한 상기 추정 결과의 보정 여부를 결정하는방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 추정 단계에서, 상기 제1 영상 프레임에 대한 보정 결과를 참조하여, 상기 제1 객체와 상기 분석 대상 구역 사이의 이벤트가 시작되는 제2 영상 프레임 및 상기 제1 객체와 상기 분석 대상 구역 사이의 이벤트가 종료되는 제3 영상 프레임을 결정하는방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 추정 단계에서, 상기 제2 영상 프레임과 상기 제3 영상 프레임 사이의 영상 프레임의 수를 참조하여 상기 이벤트의 유형을 추정하는방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 따른 방법을 실행하기 위한 컴퓨터 프로그램을 기록하는 비일시성의 컴퓨터 판독 가능 기록 매체.</claim></claimInfo><claimInfo><claim>10. 구역에 대한 분석을 수행하기 위한 시스템으로서,오프라인 공간에 포함되는 복수의 구역 중에서 분석 대상 구역을 특정하는 구역 특정부, 및상기 오프라인 공간으로부터 획득되는 적어도 하나의 영상 프레임을 참조하여 제1 객체와 상기 분석 대상 구역 사이의 이벤트 발생 여부 또는 상기 제1 객체와 상기 분석 대상 구역 사이에 발생한 이벤트의 유형을 추정하는 이벤트 관리부를 포함하고,상기 구역 특정부는, 상기 오프라인 공간 내에 위치하는 복수의 객체 중 소정의 기준 포즈를 취하는 객체가 포함되는 구역을 분석 제외 구역으로 특정하고,상기 이벤트 관리부는, 상기 분석 제외 구역에서 상기 기준 포즈를 취하는 객체의 시각적 특징과 소정 수준 이상으로 일치하는 시각적 특성을 가지는 객체를 상기 이벤트 발생 여부를 추정하기 위한 대상에서 제외하고,상기 시각적 특징은 Re-ID(Re-identification) 모델을 이용하여 추출한 벡터 형식의 텐서인시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 구역 특정부는, 상기 오프라인 공간 내에 위치하는 복수의 객체 중의 하나의 객체를 기준으로 포즈 거리가 소정 수준 이하에 해당하는 객체가 취하는 포즈 및 상기 하나의 객체가 취하는 포즈 중에서 상기 기준 포즈를 결정하는시스템.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 이벤트 관리부는, 상기 분석 제외 구역에서 상기 기준 포즈와 소정 수준 이상으로 일치하는 포즈를 취하는 객체를 상기 이벤트 발생 여부를 추정하기 위한 대상에서 제외하는시스템.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,상기 이벤트 관리부는, 상기 분석 제외 구역에서 상기 기준 포즈의 적어도 하나의 특징점과 대응하는 특징점을 포함하는 객체를 상기 이벤트 발생 여부를 추정하기 위한 대상에서 제외하는시스템.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,상기 이벤트 관리부는, 상기 적어도 하나의 영상 프레임 중에서 상기 제1 객체와 상기 분석 대상 구역 사이에 이벤트가 발생하지 않은 것으로 추정되는 제1 영상 프레임에 대하여, 타임 윈도우를 참조하여 상기 추정 결과의 보정 여부를 결정하는시스템.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 이벤트 관리부는, 상기 타임 윈도우에 포함되는 복수의 영상 프레임 중에서 상기 제1 객체와 상기 분석 대상 구역 사이에 이벤트가 발생한 것으로 추정되는 영상 프레임의 비율을 참조하여, 상기 제1 영상 프레임에 대한 상기 추정 결과의 보정 여부를 결정하는시스템.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 이벤트 관리부는, 상기 제1 영상 프레임에 대한 보정 결과를 참조하여, 상기 제1 객체와 상기 분석 대상 구역 사이의 이벤트가 시작되는 제2 영상 프레임 및 상기 제1 객체와 상기 분석 대상 구역 사이의 이벤트가 종료되는 제3 영상 프레임을 결정하는시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 이벤트 관리부는, 상기 제2 영상 프레임과 상기 제3 영상 프레임 사이의 영상 프레임의 수를 참조하여 상기 이벤트의 유형을 추정하는시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강남구...</address><code>120190675376</code><country>대한민국</country><engName>mAy-I Inc.</engName><name>주식회사 메이아이</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 관악구...</address><code> </code><country>대한민국</country><engName>KIM, Jin Yeong</engName><name>김진영</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code> </code><country>대한민국</country><engName>JUNG, Jae Min</engName><name>정재민</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, **층(역삼동, 한국고등교육재단빌딩)</address><code>920211000618</code><country>대한민국</country><engName>SEUM IP</engName><name>특허법인세움</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2025.09.29</receiptDate><receiptNumber>1-1-2025-1109429-30</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020250141114.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338ebd6b9e5188b12e6e3dd807b411c835c5b37bdbd6c8a8ce94d5f6b712d3840876610c780d16acc9e8295cf9461fbd3ed961b6b3b074f80bc9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd79bea3195aba4d57a89e4b02c6d1a1fbec4bd4cd51ad0c413229842a4a12ace183b5a1c47c907a4174e5fdcb15e895b40bcf6b6769f0486</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>