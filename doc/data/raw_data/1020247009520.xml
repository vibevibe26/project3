<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:14:28.1428</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7009520</applicationNumber><claimCount>25</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>단계-전개형(STEP-UNROLLED) 노이즈 제거 신경망</inventionTitle><inventionTitleEng>STEP-UNROLLED DENOISING NEURAL NETWORKS</inventionTitleEng><openDate>2024.04.25</openDate><openNumber>10-2024-0054304</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.03.21</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/047</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/47</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법, 시스템 및 장치는 비-자기회귀 신경망을 사용하여 출력 시퀀스를 생성하기 위한 컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.04.13</internationOpenDate><internationOpenNumber>WO2023057565</internationOpenNumber><internationalApplicationDate>2022.10.06</internationalApplicationDate><internationalApplicationNumber>PCT/EP2022/077806</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 복수의 출력 위치 각각에서 출력 토큰 어휘로부터의 개별 출력 토큰을 포함하는 현재 출력 시퀀스를 입력으로서 수신하고, 컨텍스트 입력을 조건으로 하는 동안 현재 출력 시퀀스를 처리하여 복수의 출력 위치 각각에 대해, 출력 토큰 어휘의 각 출력 토큰에 대한 개별 스코어를 포함하는 디코더 출력을 생성하도록 구성된 디코더 신경망을 포함하는 신경망 시스템의 트레이닝 방법으로서, 상기 방법은, 하나 이상의 트레이닝 예제의 배치(batch)를 획득하는 단계 - 각 트레이닝 예제는 트레이닝 컨텍스트 입력 및 그 트레이닝 컨텍스트 입력에 대한 타겟 출력 시퀀스를 포함함 - 와;배치 내 각 트레이닝 예제에 대해: 출력 시퀀스의 하나 이상의 토큰 각각에 대해, 출력 시퀀스의 출력 토큰을 어휘에서 무작위로 선택된 토큰으로 대체함으로써 타겟 출력 시퀀스로부터 손상된 출력 시퀀스를 생성하는 단계와; 하나 이상의 업데이트 반복마다:  디코더 신경망이 업데이트 반복의 손상된 출력 시퀀스에 대한 디코더 출력을 생성하기 위해 트레이닝 컨텍스트 입력을 조건으로 하는 동안 디코더 신경망을 사용하여 업데이트 반복의 손상된 출력 시퀀스를 처리하고, 그리고  복수의 출력 위치 각각에 대해, 손상된 출력 시퀀스에 대한 디코더 출력을 사용하여 출력 토큰의 어휘로부터 토큰을 선택하여 상기 손상된 출력 시퀀스를 업데이트함으로써, 손상된 출력 시퀀스를 업데이트하는 단계와. 그리고 디코더 신경망이 트레이닝 컨텍스트 입력에 대해 조건화되어 상기 업데이트된 손상된 출력 시퀀스에 대한 디코더 출력을 생성하는 동안 디코더 신경망을 사용하여 마지막 업데이트 반복 이후 그 업데이트된 손상된 출력 시퀀스를 처리하는 단계와; 그리고복수의 출력 위치 각각에 대해, 손상된 출력 시퀀스에 대한 디코더 출력을 사용하여 출력 토큰의 어휘로부터 토큰을 선택함으로써 손상된 출력 시퀀스를 업데이트하는 단계; 그리고각 트레이닝 예제에 대해, 타겟 출력 시퀀스에 대한 마지막 업데이트 반복 이후 업데이트된 손상된 출력 시퀀스에 대한 디코더 출력의 품질을 측정하는 첫 번째 항을 포함하는 손실 함수의 디코더 신경망의 파라미터에 대한 기울기(gradient)를 결정하는 단계와; 그리고기울기를 사용하여 디코더 신경망의 파라미터를 업데이트하는 단계를 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 한 번의 업데이트 반복만 수행되는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 첫 번째 항은,각 트레이닝 예제와 각 출력 위치에 대해, 업데이트된 손상된 출력 시퀀스에 대한 디코더 출력에 의해 타겟 출력 시퀀스의 출력 위치에 있는 출력 토큰에 할당된 스코어의 로그를 측정하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 손실 함수는,각 트레이닝 예에 대해 타겟 출력 시퀀스에 대한 업데이트 반복의 손상된 출력 시퀀스에 대한 디코더 출력의 품질을 측정하는 각 업데이트 반복에 대한 각각의 두 번째 항을 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 두 번째 항은,각 트레이닝 예제와 각 출력 위치에 대해, 타겟 출력 시퀀스의 출력 위치에서 출력 토큰에 대한 업데이트 반복의 상기 손상된 출력 시퀀스에 대한 디코더 출력에 의해 할당된 스코어의 로그를 측정하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>6. 임의의 선행하는 항에 있어서, 상기 출력 시퀀스의 하나 이상의 토큰 각각에 대해, 출력 시퀀스의 출력 토큰을 어휘에서 무작위로 선택된 토큰으로 대체함으로써  타겟 출력 시퀀스로부터 손상된 출력 시퀀스를 생성하는 단계는,제1 분포로부터 예상 손상 비율 값을 샘플링하는 단계;각 출력 위치에 대해, 예상 손상 비율을 이용하여 타겟 출력 시퀀스의 출력 위치에서 출력 토큰을 교체할지 여부를 결정하는 단계;출력 토큰을 교체하기로 결정된 각 출력 위치에 대해: 어휘로부터 무작위 토큰을 샘플링하고; 그리고 출력 위치의 출력 토큰을 어휘에서 샘플링된 무작위 토큰으로 대체하는 단계를 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 각 출력 위치에 대해, 예상 손상 비율을 사용하여 출력 위치에서 출력 토큰을 교체할지 여부를 결정하는 단계는,예상 손상 값으로 파라미터화된 베르누이 분포로부터 출력 위치에 대한 변수를 샘플링하는 단계를 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>8. 임의의 선행하는 항에 있어서, 상기 복수의 출력 위치 각각에 대해, 손상된 출력 시퀀스에 대한 디코더 출력을 사용하여 출력 토큰의 어휘에서 토큰을 선택함으로써 손상된 출력 시퀀스를 업데이트하는 단계는,각각의 출력 위치에 대해: 출력 위치에 대한 개별 스코어에 따라 어휘에서 출력 토큰을 샘플링하는 단계를 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>9. 임의의 선행하는 항에 있어서, 상기 신경망 시스템은 컨텍스트 입력의 인코딩된 표현을 생성하기 위해 컨텍스트 입력을 처리하도록 구성된 인코더 신경망을 포함하고, 각각의 트레이닝 예제에 대해 상기 디코더 신경망은 인코더 신경망에 의해 생성된 트레이닝 컨텍스트 입력의 인코딩된 표현을 조건으로 하며, 상기 방법은,손실 함수의 인코더 신경망의 파라미터에 대한 기울기를 결정하는 단계; 및기울기를 사용하여 인코더 신경망의 파라미터를 업데이트하는 단계를 더 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,트레이닝 후, 새로운 컨텍스트 입력을 수신하는 단계;복수의 출력 위치 각각에서 개별 출력 토큰을 포함하는 새로운 출력 시퀀스를 생성하는 단계와;복수의 생성 반복 각각에서 새로운 출력 시퀀스를 업데이트하는 단계 - 상기 업데이트하는 단계는, 각 생성 반복에서: 디코더 신경망이 새로운 컨텍스트 입력을 조건으로 하는 동안 디코더 신경망을 사용하여 새로운 출력 시퀀스를 업데이트하는 단계를 포함하고- 와; 그리고복수의 업데이트 반복의 마지막 생성 반복 후에 새로운 출력 시퀀스로부터 새로운 컨텍스트 입력에 대한 최종 출력 시퀀스를 생성하는 단계를 더 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 디코더 신경망이 새로운 컨텍스트 입력을 조건으로 하는 동안 새로운 출력 시퀀스를 업데이트하기 위해 디코더 신경망을 사용하는 단계는,디코더 신경망이 새로운 출력 시퀀스에 대한 디코더 출력을 생성하기 위해 새로운 컨텍스트 입력을 조건으로 하는 동안 디코더 신경망을 사용하여 생성 반복에서 새로운 출력 시퀀스를 처리하는 단계; 그리고복수의 출력 위치의 부분집합(subset)에 대해, 새로운 출력 시퀀스에 대한 디코더 출력을 사용하여 출력 토큰의 어휘로부터 토큰을 선택하는 단계를 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 부분집합은 진(proper)부분집합이고, 상기 방법은 부분집합 내의 복수의 출력 위치를 무작위로 선택하는 단계를 더 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 부분집합은 진부분집합이 아닌 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>14. 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 새로운 출력 시퀀스에 대한 디코더 출력을 사용하여 출력 토큰의 어휘에서 토큰을 선택하는 단계는,디코더 출력의 개별 스코어에 온도 값을 적용하여 온도 조정 스코어를 생성하고 그 온도 조정 스코어를 사용하여 토큰을 샘플링하는 단계를 포함하는 것을 특징으로 하는 신경망 시스템의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>15. 하나 이상의 컴퓨터에 의해 수행되는 방법으로서, 상기 방법은,컨텍스트 입력을 수신하는 단계와;복수의 출력 위치 각각에서 각각의 출력 토큰을 포함하는 출력 시퀀스를 생성하는 단계 - 각각의 출력 토큰은 출력 토큰의 어휘로부터 선택됨 - 와;각 출력 위치에 대해 출력 토큰 어휘의 각 출력 토큰에 대한 개별 스코어를 포함하는 개별 스코어 분포를 포함하는 디코더 출력을 생성하기 위해 컨텍스트 입력을 조건으로 하는 디코더 신경망을 사용하여 출력 시퀀스를 처리하는 단계와;각 출력 위치에 대해, 디코더 출력을 사용하여 토큰 어휘로부터 개별 토큰을 선택함으로써 출력 시퀀스를 업데이트하는 단계와; 그리고복수의 생성 반복 각각에서: 생성 반복의 디코더 출력을 사용하여, 출력 위치의 진부분집합를 선택하는 단계; 디코더 출력을 업데이트하기 위해 컨텍스트 입력을 조건으로 하는 디코더 신경망을 사용하여 생성 반복의 출력 시퀀스를 처리하는 단계; 디코더 출력을 업데이트한 후, 진부분집합의 출력 위치 각각에 대해, 디코더 출력을 사용하여 토큰을 샘플링하는 것을 포함하는 임시 출력 시퀀스를 생성하는 단계; 임시 디코더 출력을 생성하기 위해 컨텍스트 입력을 조건으로 하는 디코더 신경망을 사용하여 임시 출력 시퀀스를 처리하는 단계; 및  진부분집합에 없는 각 출력 위치에 대해, 디코더 출력을 사용하여 어휘로부터 토큰을 선택하고;  진부분집합의 각 출력 위치에 대해, 임시 디코더 출력을 사용하여 어휘에서 토큰을 선택함으로써, 출력 시쿼스를 업데이트하는 단계와;복수의 업데이트 반복 중 마지막 업데이트 반복 후에 출력 시퀀스로부터 최종 출력 시퀀스를 생성하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 디코더 신경망은,출력 위치에 대한 개별 스코어 분포를 병렬로 생성하는 비-자기회귀 모델인 것을 특징으로 하는 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>17. 제15항 또는 제16항에 있어서,컨텍스트 입력의 하나 이상의 임베딩 시퀀스를 포함하는 컨텍스트 입력의 인코딩된 표현을 생성하기 위해 인코더 신경망을 사용하여 컨텍스트 입력을 처리하는 단계를 더 포함하고,디코더 신경망은 인코딩된 표현을 조건으로 하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,최종 출력 시퀀스에서 출력 토큰의 예측 개수를 나타내는 예측 타겟 길이를 정의하는 길이 예측을 생성하기 위해 길이 예측 신경망을 사용하여 컨텍스트 입력의 하나 이상의 임베딩을 처리하는 단계를 더 포함하고, 상기 인코딩된 표현은 예측된 목표 길이인 것을 특징으로 하는 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>19. 제15항 내지 제18항 중 어느 한 항에 있어서, 상기 출력 시퀀스를 생성하는 단계는,하나 이상의 출력 위치에 대한 토큰 어휘로부터 토큰을 무작위로 샘플링하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>20. 제15항 내지 제19항 중 어느 한 항에 있어서, 상기 임시 출력 시퀀스를 생성하는 단계는,진부분집합에 없는 출력 위치 각각에 대해, 디코더 출력을 사용하여 토큰을 선택하거나 출력 위치의 토큰으로서 업데이트 반복의 출력 위치에 있는 토큰을 사용하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>21. 제15항 내지 제20항 중 어느 한 항에 있어서, 진부분집합에 없는 각각의 출력 위치에 대해, 디코더 출력을 사용하여 어휘로부터 토큰을 선택하는 단계는 디코더 출력에 따른 위치에 대한 argmax 토큰을 선택하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>22. 제15항 내지 제21항 중 어느 한 항에 있어서, 상기 진부분집합의 각각의 출력 위치에 대해, 임시 디코더 출력을 사용하여 어휘로부터 토큰을 선택하는 단계는 상기 임시 디코더 출력에 따른 위치에 대한 argmax 토큰을 선택하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>23. 제1항 내지 제22항 중 어느 한 항에 있어서,a) 트레이닝 컨텍스트 입력 또는 컨텍스트 입력은 한 언어의 텍스트를 정의하는 시퀀스이고, 목표 또는 최종 출력 시퀀스는 텍스트를 다른 언어로 번역한 것을 나타냅니다. 또는b) 트레이닝 컨텍스트 입력 또는 컨텍스트 입력은 음성 발화를 나타내는 시퀀스이고, 타겟 또는 최종 출력 시퀀스는 발화의 전사인 텍스트 조각을 나타냅니다. 또는c) 트레이닝 컨텍스트 입력 또는 컨텍스트 입력은 자연어로 된 텍스트 또는 텍스트의 특징을 나타내는 시퀀스이고, 목표 또는 최종 출력 시퀀스는 자연어로 말하는 텍스트의 오디오를 정의하는 데이터이다. 또는d) 트레이닝 컨텍스트 입력 또는 컨텍스트 입력은 이미지의 픽셀을 나타내는 시퀀스이고, 타겟 또는 최종 출력 시퀀스는 이미지에 대한 캡션을 나타내는 텍스트 시퀀스이다. 또는e) 트레이닝 컨텍스트 입력 또는 컨텍스트 입력은 이미지 생성을 위한 조건화 입력을 나타내는 시퀀스이고, 목표 또는 최종 출력 시퀀스는 조건화 입력에 따른 이미지의 픽셀을 나타냅니다.</claim></claimInfo><claimInfo><claim>24. 시스템으로서,하나 이상의 컴퓨터; 그리고하나 이상의 컴퓨터에 의해 실행될 때, 하나 이상의 컴퓨터가 제1항 내지 제23항 중 어느 한 항의 각각의 동작을 수행하게 하는 명령어를 저장하는 하나 이상의 저장 장치.</claim></claimInfo><claimInfo><claim>25. 하나 이상의 컴퓨터에 의해 실행될 때 하나 이상의 컴퓨터로 하여금 제1항 내지 제23항 중 어느 한 항의 방법의 각각의 동작을 수행하게 하는 명령어를 저장하는 하나 이상의 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>영국 런던 이씨*에이 *티더블유 뉴 스트리트 스퀘어 *</address><code>520170032411</code><country>영국</country><engName>DeepMind Technologies Limited</engName><name>딥마인드 테크놀로지스 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>SAVINOV, Nikolay</engName><name>사비노프 니콜라이</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>CHUNG, Junyoung</engName><name>정준영</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>BINKOWSKI, Mikolaj</engName><name>빈코프스키 미콜라이</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>VAN DEN OORD, Aaron Gerard Antonius</engName><name>반 덴 오르드 아론 제라드 안토니우스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>ELSEN, Erich Konrad</engName><name>엘센 에리히 콘라드</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.06</priorityApplicationDate><priorityApplicationNumber>63/252,617</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.06</priorityApplicationDate><priorityApplicationNumber>63/252,979</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.03.21</receiptDate><receiptNumber>1-1-2024-0317570-70</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.03.25</receiptDate><receiptNumber>1-5-2024-0051272-01</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247009520.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938d45359b3eade85b745b6386f974e3f91801a13c12d075e6100bb762d8c8148dd54f06c4ea6e369c2ea6eacf5d264f5f685177ca8bb87e93</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfdb30c28d6c233b9fa4937f7dbc90a5a398e2e80cad655e18cf903c127b6ba6a85b8ad5628a3291340bdf67317fe82c7f3f6ce312564e33bf</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>