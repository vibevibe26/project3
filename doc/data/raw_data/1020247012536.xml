<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:32.132</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.08.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7012536</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>마스크킹된 음성 모델링을 위한 안내 데이터 선택</inventionTitle><inventionTitleEng>GUIDED DATA SELECTION FOR MASKED SPEECH MODELING</inventionTitleEng><openDate>2024.05.17</openDate><openNumber>10-2024-0068699</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.16</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.04.16</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 13/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 마스크킹된 음성 모델링을 위한 안내(guided) 데이터 선택 방법(500)은 발언(106)에 대응하는 인코딩된 표현(211) 시퀀스를 획득하는 단계를 포함한다. 각각의 인코딩된 표현에 대해, 방법은 가능한 음성 인식 가설(412)에 대한 대응하는 확률 분포(414)를 생성하도록 각각의 인코딩된 표현(211)을 처리하는 단계 및 각각의 인코딩된 표현에, 가능한 음성 인식 가설에 대한 대응하는 확률 분포로부터 가장 높은 확률로서 신뢰도 스코어(416)를 할당하는 단계를 포함한다. 방법은 또한 인코딩된 표현의 시퀀스에 할당된 신뢰도 스코어에 기초하여 마스킹할 마스킹되지 않은 인코딩된 표현 세트를 선택하는 단계를 포함한다. 방법은 또한 선택된 마스킹되지 않은 인코딩된 표현 세트를 마스킹함으로써 마스크킹된 인코딩된 표현(211m) 세트를 생성하는 단계를 포함한다. 여기서, 각각의 마스크킹된 인코딩된 표현은 선택된 마스킹되지 않은 인코딩된 표현 세트의 마스킹되지 않은 인코딩된 표현 각각에 대응한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.04.13</internationOpenDate><internationOpenNumber>WO2023059958</internationOpenNumber><internationalApplicationDate>2022.08.18</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/075182</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 마스크킹된 음성 모델링을 위한 안내(guided) 데이터 선택을 위한 컴퓨터 구현 방법(500)으로서, 컴퓨터 구현 방법(500)은 데이터 처리 하드웨어(610) 상에서 실행될 때 데이터 처리 하드웨어(610)가 동작들을 수행하게 하며, 상기 동작들은,발언(106)에 대응하는 인코딩된 표현(211) 시퀀스를 획득하는 단계와;인코딩된 표현(211) 시퀀스의 각 인코딩된 표현(211)에 대해: 채점기(scorer) 모델(410)을 사용하여, 각각의 인코딩된 표현(211)에 대한 가능한 음성 인식 가설(412)에 대한 대응하는 확률 분포(414)를 생성하도록 각각의 인코딩된 표현(211)을 처리하는 단계; 및 각각의 인코딩된 표현(211)에, 각각의 인코딩된 표현(211)에 대한 가능한 음성 인식 가설(412)에 대한 대응하는 확률 분포(414)로부터 가장 높은 확률로서 신뢰도 스코어(416)를 할당하는 단계와;인코딩된 표현(211)의 시퀀스에 할당된 신뢰도 스코어(416)에 기초하여, 인코딩된 표현(211) 시퀀스로부터, 마스킹할 마스킹되지 않은(unmasked) 인코딩된 표현(211) 세트를 선택하는 단계와; 그리고선택된 마스킹되지 않은 인코딩된 표현(211) 세트를 마스킹함으로써 마스크킹된 인코딩된 표현(211m) 세트를 생성하는 단계를 포함하고, 상기 마스크킹된 인코딩된 표현(211m) 세트 내의 각각의 마스크킹된 인코딩된 표현(211m)은 선택된 마스킹되지 않은 인코딩된 표현(211) 세트의 마스킹되지 않은 인코딩된 표현(211) 각각에 대응하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 마스킹할 마스킹되지 않은 인코딩된 표현(211) 세트를 선택하는 단계는,가장 높은 신뢰도 스코어(416)를 갖는 인코딩된 표현(211) 시퀀스로부터 상위 K개의 인코딩된 표현(211)을 선택하는 단계를 포함하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, K는 마스킹될 인코딩된 표현(211) 시퀀스에 있는 인코딩된 표현(211)의 사전 결정된 비율에 기초하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 사전 결정된 비율은 40%인 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 동작들은,마스킹할 선택된 마스킹되지 않은 인코딩된 표현(211) 세트의 각각의 마스킹되지 않은 인코딩된 표현(211)에 대해, 양자화기(218)를 사용하여, 각각의 마스킹되지 않은 인코딩된 표현(211)에 대한 대응하는 타겟 컨텍스트 벡터(219)를 생성하는 단계와;마스크킹된 인코딩된 표현(211m) 세트의 각각의 마스크킹된 인코딩된 표현(211m)에 대해: 각각의 마스크킹된 인코딩된 표현(211m)에 대한 대응하는 대조 컨텍스트 벡터(215)를 생성하는 단계; 및 각각의 마스크킹된 인코딩된 표현(211m)에 대응하는 각각의 마스킹되지 않은 인코딩된 표현(211)에 대해 생성된 대응하는 대조 컨텍스트 벡터(215) 및 대응하는 타겟 컨텍스트 벡터(219)에 기초하여 대조 손실(342)을 생성하는 단계와; 그리고마스크킹된 인코딩된 표현(211m) 세트에 대해 생성된 대조 손실(342)을 사용하여 오디오 인코더(210)를 사전 트레이닝하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 동작들은,마스킹할 선택된 마스킹되지 않은 인코딩된 표현(211) 세트의 각각의 마스킹되지 않은 인코딩된 표현(211)에 대해, 클러스터 모듈(222)을 사용하여, 각각의 마스킹되지 않은 인코딩된 표현(211)에 대한 대응하는 K-평균 클러스터(223)를 생성하는 단계와;마스크킹된 인코딩된 표현(211m)의 각각의 마스크킹된 인코딩된 표현(211m)에 대해, 각각의 마스크킹된 인코딩된 표현(211m)에 대응하는 각각의 마스킹되지 않은 인코딩된 표현(211m)에 대해 생성된 대응하는 대조 컨텍스트 벡터(215) 및 대응하는 K-평균 클러스터(223)에 기초하여 교차 엔트로피 손실(355)을 생성하는 단계와; 그리고 마스크킹된 인코딩된 표현(211m) 세트에 대해 생성된 교차 엔트로피 손실(355)을 사용하여 오디오 인코더(210)를 사전 트레이닝하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 동작들은,마스크킹된 인코딩된 표현(211m) 세트의 각각의 마스크킹된 인코딩된 표현(211m)에 대해, 대조 손실(342) 및 교차 엔트로피 손실(355)에 기초하여 최종 트레이닝 목표(365)를 결정하는 단계와; 그리고마스크킹된 인코딩된 표현(211m) 세트에 대해 생성된 최종 트레이닝 목표(365)를 사용하여 오디오 인코더(210)를 사전 트레이닝하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 동작들은,마스크킹된 인코딩된 표현(211m) 세트의 신뢰도 스코어(416)를 평균함으로써 발언 레벨(utterance-level) 신뢰도 스코어(416)를 결정하는 단계와;발언 레벨 신뢰도 스코어(416)에 기초하여 최종 트레이닝 목표(365)를 가중하는 단계와; 그리고가중된 최종 트레이닝 목표(365)를 사용하여 오디오 인코더(210)를 사전 트레이닝하는 단계를 를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>9. 제6항 내지 제8항 중 어느 한 항에 있어서, 상기 동작들은,대조 컨텍스트 벡터(215)로부터 병목 특징(217)을 추출하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 동작들은,추출된 병목 특징(217)을 사용하여 각각의 대응하는 K-평균 클러스터(223)를 정제하는 단계를 더 포함하는 것을 특징으로 하는 컴퓨터 구현 방법(500).</claim></claimInfo><claimInfo><claim>11. 시스템(100)으로서,데이터 처리 하드웨어(610); 및데이터 처리 하드웨어(610)와 통신하며 데이터 처리 하드웨어(610)에서 실행될 때 데이터 처리 하드웨어(610)가 동작들을 수행하게 하는 명령을 저장하는 메모리(620) 하드웨어를 포함하고, 상기 동작들은,발언(106)에 대응하는 인코딩된 표현(211) 시퀀스를 획득하는 동작과;인코딩된 표현(211) 시퀀스의 각 인코딩된 표현(211)에 대해: 채점기 모델(410)을 사용하여, 각각의 인코딩된 표현(211)에 대한 가능한 음성 인식 가설(412)에 대한 대응하는 확률 분포(414)를 생성하도록 각각의 인코딩된 표현(211)을 처리하는 동작; 및 각각의 인코딩된 표현(211)에, 각각의 인코딩된 표현(211)에 대한 가능한 음성 인식 가설(412)에 대한 대응하는 확률 분포(414)로부터 가장 높은 확률로서 신뢰도 스코어(416)를 할당하는 동작과;인코딩된 표현(211)의 시퀀스에 할당된 신뢰도 스코어(416)에 기초하여, 인코딩된 표현(211) 시퀀스로부터, 마스킹할 마스킹되지 않은 인코딩된 표현(211) 세트를 선택하는 동작과; 그리고선택된 마스킹되지 않은 인코딩된 표현(211) 세트를 마스킹함으로써 마스크킹된 인코딩된 표현(211m) 세트를 생성하는 동작을 포함하고, 상기 마스크킹된 인코딩된 표현(211m) 세트 내의 각각의 마스크킹된 인코딩된 표현(211m)은 선택된 마스킹되지 않은 인코딩된 표현(211) 세트의 마스킹되지 않은 인코딩된 표현(211) 각각에 대응하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,마스킹할 마스킹되지 않은 인코딩된 표현(211) 세트를 선택하는 동작은,가장 높은 신뢰도 스코어(416)를 갖는 인코딩된 표현(211) 시퀀스로부터 상위 K개의 인코딩된 표현(211)을 선택하는 동작을 포함하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, K는 마스킹될 인코딩된 표현(211) 시퀀스에 있는 인코딩된 표현(211)의 사전 결정된 비율에 기초하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 사전 결정된 비율은 40%인 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>15. 제11항 내지 제14항 중 어느 한 항에 있어서, 상기 동작들은,마스킹할 선택된 마스킹되지 않은 인코딩된 표현(211) 세트의 각각의 마스킹되지 않은 인코딩된 표현(211)에 대해, 양자화기(218)를 사용하여, 각각의 마스킹되지 않은 인코딩된 표현(211)에 대한 대응하는 타겟 컨텍스트 벡터(219)를 생성하는 동작과;마스크킹된 인코딩된 표현(211m) 세트의 각각의 마스크킹된 인코딩된 표현(211m)에 대해: 각각의 마스크킹된 인코딩된 표현(211m)에 대한 대응하는 대조 컨텍스트 벡터(215)를 생성하는 동작; 및 각각의 마스크킹된 인코딩된 표현(211m)에 대응하는 각각의 마스킹되지 않은 인코딩된 표현(211)에 대해 생성된 대응하는 대조 컨텍스트 벡터(215) 및 대응하는 타겟 컨텍스트 벡터(219)에 기초하여 대조 손실(342)을 생성하는 동작과; 그리고마스크킹된 인코딩된 표현(211m) 세트에 대해 생성된 대조 손실(342)을 사용하여 오디오 인코더(210)를 사전 트레이닝하는 동작을 더 포함하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 동작들은,마스킹할 선택된 마스킹되지 않은 인코딩된 표현(211) 세트의 각각의 마스킹되지 않은 인코딩된 표현(211)에 대해, 클러스터 모듈(222)을 사용하여, 각각의 마스킹되지 않은 인코딩된 표현(211)에 대한 대응하는 K-평균 클러스터(223)를 생성하는 동작과;마스크킹된 인코딩된 표현(211m)의 각각의 마스크킹된 인코딩된 표현(211m)에 대해, 각각의 마스크킹된 인코딩된 표현(211m)에 대응하는 각각의 마스킹되지 않은 인코딩된 표현(211m)에 대해 생성된 대응하는 대조 컨텍스트 벡터(215) 및 대응하는 K-평균 클러스터(223)에 기초하여 교차 엔트로피 손실(355)을 생성하는 동작과; 그리고 마스크킹된 인코딩된 표현(211m) 세트에 대해 생성된 교차 엔트로피 손실(355)을 사용하여 오디오 인코더(210)를 사전 트레이닝하는 동작을 더 포함하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 동작들은,마스크킹된 인코딩된 표현(211m) 세트의 각각의 마스크킹된 인코딩된 표현(211m)에 대해, 대조 손실(342) 및 교차 엔트로피 손실(355)에 기초하여 최종 트레이닝 목표(365)를 결정하는 동작과; 그리고마스크킹된 인코딩된 표현(211m) 세트에 대해 생성된 최종 트레이닝 목표(365)를 사용하여 오디오 인코더(210)를 사전 트레이닝하는 동작을 더 포함하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 동작들은,마스크킹된 인코딩된 표현(211m) 세트의 신뢰도 스코어(416)를 평균함으로써 발언 레벨 신뢰도 스코어(416)를 결정하는 동작과;발언 레벨 신뢰도 스코어(416)에 기초하여 최종 트레이닝 목표(365)를 가중하는 동작과; 그리고가중된 최종 트레이닝 목표(365)를 사용하여 오디오 인코더(210)를 사전 트레이닝하는 동작을 더 포함하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>19. 제16항 내지 제18항 중 어느 한 항에 있어서, 상기 동작들은,대조 컨텍스트 벡터(215)로부터 병목 특징(217)을 추출하는 동작을 더 포함하는 것을 특징으로 하는 시스템(100).</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 동작들은,추출된 병목 특징(217)을 사용하여 각각의 대응하는 K-평균 클러스터(223)를 정제하는 동작을 더 포함하는 것을 특징으로 하는 시스템(100).</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>ROSENBERG, Andrew</engName><name>로젠버그 앤드루</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>RAMABHADRAN, Bhuvana</engName><name>라마브하드란 부바나</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>ZHANG, Yu</engName><name>장 유</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>BASKAR, Murali Karthick</engName><name>바스카 무랄리 카르시크</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.05</priorityApplicationDate><priorityApplicationNumber>63/262,136</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.04.16</receiptDate><receiptNumber>1-1-2024-0414648-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.04.16</receiptDate><receiptNumber>1-1-2024-0417856-45</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.04.18</receiptDate><receiptNumber>1-5-2024-0065749-49</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247012536.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936ce9252219f791d09db9efbfcf06a606fdfae59808d297473f9c579c07886366330aa457b2f96182d10986999ee99d65cb68c02d84368a08</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf92fabec18568e917cff57a23790321a7ad1a1216940ac26acc7ee83af42e548aae3b15109c3e7da96701da0991169fb92019b19dc3c26829</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>