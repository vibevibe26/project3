<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:57.657</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.10</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0089237</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>마스킹된 이미지를 복원하는 사전 훈련 모델을 생성하는 전자 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>AN ELECTRONIC DEVICE FOR GENERATING A PRE-TRAINED  MODEL RESTORING A MASKED IMAGE AND ITS OPERATION  METHOD</inventionTitleEng><openDate>2024.08.13</openDate><openNumber>10-2024-0123218</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.07.10</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 마스킹된 이미지를 복원하는 사전 훈련 모델을 생성하는 전자 장치 및 그 동작 방법이 개시된다. 본 발명의 일 실시예에 따른 전자 장치의 동작 방법은, 입력 이미지를 기반으로 생성된 소스 뷰(source view) 및 타겟 뷰(target view) 각각을 소스 인코더(source encoder) 및 타겟 인코더(target encoder) 각각에 입력하는 단계, 차별 학습(discrimination learning) 및 상기 입력 이미지에 기반하여 상기 소스 인코더의 출력 및 상기 타겟 인코더의 출력으로부터 손실을 계산하는 단계, 및 상기 손실이 적용된 상기 소스 인코더를 포함하는 사전 훈련 모델(pre-trained model)을 생성하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치의 동작 방법에 있어서, 입력 이미지를 기반으로 생성된 소스 뷰(source view) 및 타겟 뷰(target view) 각각을 소스 인코더(source encoder) 및 타겟 인코더(target encoder) 각각에 입력하는 단계; 차별 학습(discrimination learning) 및 상기 입력 이미지에 기반하여 상기 소스 인코더의 출력 및 상기 타겟 인코더의 출력으로부터 손실을 계산하는 단계; 및 상기 손실이 적용된 상기 소스 인코더를 포함하는 사전 훈련 모델(pre-trained model)을 생성하는 단계를 포함하는, 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 입력 이미지를 기반으로 상기 소스 뷰를 생성하는 단계; 및 상기 입력 이미지를 기반으로 상기 타겟 뷰를 생성하는 단계를 더 포함하고, 상기 소스 뷰는, 상기 입력 이미지가 분할된 복수의 소스 패치들(source patches) 및 상기 복수의 소스 패치들 간의 관계 정보를 포함하는 소스 분류 토큰(source classification token)을 포함하고, 상기 복수의 소스 패치들은,복수의 소스 이미지 토큰들 및 복수의 소스 마스크 토큰들을 포함하고,상기 타겟 뷰는,상기 입력 이미지가 분할된 복수의 타겟 패치들(target patches) 및 상기 복수의 타겟 패치들 간의 관계 정보를 포함하는 타겟 분류 토큰(target classification token)을 포함하고,상기 복수의 타겟 패치들은,복수의 타겟 이미지 토큰들 및 복수의 타겟 마스크 토큰들을 포함하는,동작 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 입력 이미지를 기반으로 상기 소스 뷰를 생성하는 단계는, 토큰화(tokenize)를 통해 상기 입력 이미지를 복수의 패치들로 분할하는 단계; 상기 복수의 패치들 중 일부 패치들에 대해 랜덤 마스킹을 수행하여, 상기 랜덤 마스킹된 상기 복수의 소스 마스크 토큰들 및 상기 랜덤 마스킹되지 않은 상기 복수의 소스 이미지 토큰들을 포함하는 상기 복수의 소스 패치들을 생성하는 단계;상기 복수의 소스 패치들 간의 관계 정보를 포함하는 상기 소스 분류 토큰을 생성하는 단계; 및상기 소스 분류 토큰 및 상기 복수의 소스 패치들을 포함하는 상기 소스 뷰를 생성하는 단계를 포함하는, 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 입력 이미지를 기반으로 상기 타겟 뷰를 생성하는 단계는, 토큰화를 통해 상기 입력 이미지를 복수의 패치들로 분할하는 단계; 상기 복수의 패치들에 대해 상기 소스 뷰의 랜덤 마스킹과 겹치지 않도록 마스킹을 수행하여, 상기 마스킹된 상기 복수의 타겟 마스크 토큰들 및 상기 마스킹되지 않은 상기 복수의 타겟 이미지 토큰들을 포함하는 상기 복수의 타겟 패치들을 생성하는 단계;상기 복수의 타겟 패치들 간의 관계 정보를 나타내는 상기 타겟 분류 토큰을 생성하는 단계; 및상기 타겟 분류 토큰 및 상기 복수의 타겟 패치들을 포함하는 상기 타겟 뷰를 생성하는 단계를 포함하는, 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,복수의 소스 출력 패치들을 디코더에 입력하여 상기 복수의 소스 마스크 토큰들을 복원하는 단계; 및상기 복원된 상기 복수의 소스 마스크 토큰들 각각의 불확실성을 계산하는 단계를 더 포함하고,상기 복수의 소스 출력 패치들은,상기 소스 인코더의 상기 출력 중 상기 복수의 소스 패치들에 대한 출력인,동작 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 복원된 상기 복수의 소스 마스크 토큰들 각각의 상기 불확실성을 계산하는 단계는,상기 복원된 상기 복수의 소스 마스크 토큰들 각각과 상기 복수의 소스 마스크 토큰들의 위치에 대응하는 상기 입력 이미지의 패치들 간의 거리인 불확실성을 계산하는 단계를 포함하는, 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서, 상기 소스 인코더의 출력 및 상기 타겟 인코더의 출력으로부터 손실을 계산하는 단계는,상기 복수의 소스 출력 패치들 및 복수의 타겟 출력 패치들 중 상기 불확실성이 임계값 미만인 패치들에 대응하는 토큰들을 로컬 차별 학습 모듈에 입력하여 로컬 손실을 계산하는 단계; 소스 출력 분류 토큰 및 타겟 출력 분류 토큰을 글로벌 차별 학습 모듈에 입력하여 글로벌 손실을 계산하는 단계; 및 상기 복원된 상기 복수의 소스 마스크 토큰들과 상기 입력 이미지를 이용하여 회귀 손실을 계산하는 단계를 포함하고,상기 복수의 타겟 출력 패치들은,상기 타겟 인코더의 상기 출력 중 상기 복수의 타겟 패치들에 대응하는 출력이고,상기 소스 출력 분류 토큰은,상기 소스 인코더의 출력 중 상기 소스 분류 토큰에 대응하는 출력이고, 상기 타겟 출력 분류 토큰은,상기 타겟 인코더의 출력 중 상기 타겟 분류 토큰에 대응하는 출력인,동작 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 손실이 적용된 상기 소스 인코더를 포함하는 상기 사전 훈련 모델을 생성하는 단계는,상기 로컬 손실, 상기 글로벌 손실 및 상기 회귀 손실을 상기 소스 인코더에 반영하여 상기 사전 훈련 모델을 생성하는, 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 사전 훈련 모델에 포함되는 상기 손실이 적용된 상기 소스 인코더의 파라미터를 초기 파라미터로 하여 타겟 모델(target model)을 트레이닝하는 단계를 더 포함하는, 동작 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 타겟 인코더의 파라미터들이 상기 소스 인코더의 파라미터를 이용한 지수 이동 평균(exponential moving average)을 통해 업데이트되는 단계를 더 포함하는, 동작 방법.</claim></claimInfo><claimInfo><claim>11. 전자 장치의 동작 방법에 있어서, 입력 이미지를 기반으로 생성된 소스 뷰 및 타겟 뷰 각각을 소스 인코더 및 타겟 인코더 각각에 입력하는 단계;차별 학습 및 상기 입력 이미지에 기반하여 상기 소스 인코더의 출력 및 상기 타겟 인코더의 출력으로부터 손실을 계산하는 단계;상기 손실이 적용된 상기 소스 인코더를 포함하는 사전 훈련 모델을 생성하는 단계; 및상기 사전 훈련 모델에 포함되는 상기 손실이 적용된 상기 소스 인코더의 파라미터를 초기 파라미터로 하여 타겟 모델(target model)을 트레이닝하는 단계를 포함하고, 상기 타겟 뷰에 포함되는 복수의 타겟 패치들은,상기 소스 뷰에 포함되는 복수의 소스 마스크 토큰들과 겹치지 않도록 마스킹된 복수의 타겟 마스크 토큰들을 포함하고, 동작 방법.</claim></claimInfo><claimInfo><claim>12. 전자 장치에 있어서, 입력 이미지를 기반으로 생성된 소스 뷰(source view) 및 타겟 뷰(target view) 각각을 소스 인코더(source encoder) 및 타겟 인코더(target encoder) 각각에 입력하고, 차별 학습(discrimination learning) 및 상기 입력 이미지에 기반하여 상기 소스 인코더의 출력 및 상기 타겟 인코더의 출력으로부터 손실을 계산하고, 상기 손실이 적용된 상기 소스 인코더를 포함하는 사전 훈련 모델(pre-trained model)을 생성하는 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 프로세서는,상기 입력 이미지를 기반으로 상기 소스 뷰를 생성하고, 상기 입력 이미지를 기반으로 상기 타겟 뷰를 생성하고,상기 소스 뷰는, 상기 입력 이미지가 분할된 복수의 소스 패치들(source patches) 및 상기 복수의 소스 패치들 간의 관계 정보를 포함하는 소스 분류 토큰(source classification token)을 포함하고, 상기 복수의 소스 패치들은,복수의 소스 이미지 토큰들 및 복수의 소스 마스크 토큰들을 포함하고,상기 타겟 뷰는,상기 입력 이미지가 분할된 복수의 타겟 패치들(target patches) 및 상기 복수의 타겟 패치들 간의 관계 정보를 포함하는 타겟 분류 토큰(target classification token)을 포함하고,상기 복수의 타겟 패치들은,복수의 타겟 이미지 토큰들 및 복수의 타겟 마스크 토큰들을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 프로세서는, 토큰화(tokenize)를 통해 상기 입력 이미지를 복수의 패치들로 분할하고, 상기 복수의 패치들 중 일부 패치들에 대해 랜덤 마스킹을 수행하여, 상기 랜덤 마스킹된 상기 복수의 소스 마스크 토큰들 및 상기 랜덤 마스킹되지 않은 상기 복수의 소스 이미지 토큰들을 포함하는 상기 복수의 소스 패치들을 생성하고, 상기 복수의 소스 패치들 간의 관계 정보를 포함하는 상기 소스 분류 토큰을 생성하고, 상기 소스 분류 토큰 및 상기 복수의 소스 패치들을 포함하는 상기 소스 뷰를 생성하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 프로세서는,토큰화를 통해 상기 입력 이미지를 복수의 패치들로 분할하고, 상기 복수의 타겟 패치들에 대해 상기 소스 뷰의 랜덤 마스킹과 겹치지 않도록 마스킹을 수행하여, 상기 마스킹된 상기 복수의 타겟 마스크 토큰들 및 상기 마스킹되지 않은 상기 복수의 타겟 이미지 토큰들을 포함하는 상기 복수의 타겟 패치들을 생성하고, 상기 복수의 타겟 패치들 간의 관계 정보를 나타내는 상기 타겟 분류 토큰을 생성하고, 상기 타겟 분류 토큰 및 상기 복수의 타겟 패치들을 포함하는 상기 타겟 뷰를 생성하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 프로세서는,복수의 소스 출력 패치들을 디코더에 입력하여 상기 복수의 소스 마스크 토큰들을 복원하고, 상기 복원된 상기 복수의 소스 마스크 토큰들 각각의 불확실성을 계산하고,상기 복수의 소스 출력 패치들은,상기 소스 인코더의 상기 출력 중 상기 복수의 소스 패치들에 대한 출력인,전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 프로세서는,상기 복원된 상기 복수의 소스 마스크 토큰들 각각과 상기 복수의 소스 마스크 토큰들의 위치에 대응하는 상기 입력 이미지의 패치들 간의 거리인 불확실성을 계산하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 프로세서는,상기 복수의 소스 출력 패치들 및 복수의 타겟 출력 패치들 중 상기 불확실성이 임계값 미만인 패치들에 대응하는 토큰들을 로컬 차별 학습 모듈에 입력하여 로컬 손실을 계산하고, 소스 출력 분류 토큰 및 타겟 출력 분류 토큰을 글로벌 차별 학습 모듈에 입력하여 글로벌 손실을 계산하고, 상기 복원된 상기 복수의 소스 마스크 토큰들과 상기 입력 이미지를 이용하여 회귀 손실을 계산하고,상기 복수의 타겟 출력 패치들은,상기 타겟 인코더의 상기 출력 중 상기 복수의 타겟 패치들에 대응하는 출력이고,상기 소스 출력 분류 토큰은,상기 소스 인코더의 출력 중 상기 소스 분류 토큰에 대응하는 출력이고, 상기 타겟 출력 분류 토큰은,상기 타겟 인코더의 출력 중 상기 타겟 분류 토큰에 대응하는 출력인,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 프로세서는,상기 로컬 손실, 상기 글로벌 손실 및 상기 회귀 손실을 상기 소스 인코더에 반영하여 상기 사전 훈련 모델을 생성하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제12항에 있어서,상기 프로세서는,상기 사전 훈련 모델에 포함되는 상기 손실이 적용된 상기 소스 인코더의 파라미터를 초기 파라미터로 하여 타겟 모델(target model)을 트레이닝하는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220040083301</code><country>대한민국</country><engName>Ewha University - Industry Collaboration Foundation</engName><name>이화여자대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>MIN Dong Bo</engName><name>민동보</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>CHOI Hye Song</engName><name>최혜송</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>LEE Hun Sang</engName><name>이헌상</name></inventorInfo><inventorInfo><address>서울특별시 동대문구...</address><code> </code><country> </country><engName>PARK Hye Jin</engName><name>박혜진</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.02.06</priorityApplicationDate><priorityApplicationNumber>1020230015695</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.07.10</receiptDate><receiptNumber>1-1-2023-0757109-19</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230089237.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c939c7a81f4c7db7c264c0b41e7ae73bc33a4a424d469236cc9c0d58d2e722e4c0f4d018bdf481040fb682c2664f1e460f83574f65ef481c4ea</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfead3bd35abcd07ed4ee4f9a52bb58bfe6a34b597dc5427a040f34929e7b24eb543240343336e21221d04718de663f89196562c5fdc1fd088</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>