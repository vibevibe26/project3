<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:35.3335</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.04.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0052204</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>스케일 분리를 통한 비디오의 빠른 객체 감지 방법</inventionTitle><inventionTitleEng>METHOD OF FAST OBJECT DETECTION IN VIDEO VIA SCALE  SEPARATION</inventionTitleEng><openDate>2023.11.21</openDate><openNumber>10-2023-0159262</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.10.31</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 감소된 시스템 자원 요구 사항(예: 감소된 계산 부하, 얕은 뉴럴 네트워크 설계 등)을 사용하여 고정밀 비디오 객체 감지를 가능하게 하는 기술 및 장치가 설명될 수 있다. 예를 들어, 객체 검출 방식의 검색 도메인(예: 대상 객체 클래스, 대상 객체 크기, 대상 객체 회전 각도 등)은 하위 도메인(예: 객체 클래스의 하위 도메인, 대상 객체의 하위 도메인, 개체 크기, 하위 도메인 개체 회전 각도 등)으로 구분될 수 있다. 그런 다음 특수화된 하위 도메인 수준 객체 감지/분할 작업이 순차적인 비디오 프레임에 걸쳐 분리될 수 있다. 이와 같이, 상이한 서브도메인 레벨 처리 기술(예: 특수 뉴럴 네트워크를 통해)이 비디오 시퀀스의 상이한 프레임에 걸쳐 구현될 수 있다. 더욱이, 연속적인 비디오 프레임들의 중복 정보가 활용될 수 있어서, 연속적인 프레임들에 걸친 시각적 객체 추적과 결합된 특수화된 객체 검출 작업들이 더 효율적인(예를 들면, 더 정확하고, 덜 계산 집약적인 등) 전체 도메인 객체 검출 및 객체 분할 방식들을 가능하게 할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 처리를 위한 방법에 있어서:비디오를 제1 프레임 및 제2 프레임을 포함하는 복수의 프레임들로 분할하는 단계;제1 도메인에서 동작하도록 트레이닝 된 제1 뉴럴(neural) 네트워크를 이용하여 상기 제1 프레임의 제1 객체에 대한 제1 객체 정보를 생성하는 단계;제2 도메인에서 동작하도록 트레이닝 된 제2 뉴럴 네트워크를 사용하여 상기 제2 프레임의 제2 객체에 대한 제2 객체 정보를 생성하는 단계; 및제1 객체 정보에 기초한 제1 라벨 및 제2 객체 정보에 기초한 제2 라벨을 포함하는 비디오에 대한 라벨 데이터를 생성하는 단계를 포함하는 것을 특징으로 하는 방법. </claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서,교대로 상기 제1 도메인에 대응하는 제1 라벨 데이터를 획득하기 위해 상기 제1 뉴럴 네트워크를 상기 복수의 프레임들의 제1 서브세트에 적용하고, 상기 제2 도메인에 대응하는 제2 라벨 데이터를 획득하기 위해 상기 제2 뉴럴 네트워크를 상기 복수의 프레임들의 제2 서브세트에 적용하는 단계를 더 포함하고,상기 제1 서브세트 및 상기 제2 서브세트는 상기 복수의 프레임들의 시간적 순서에 따라 교번(alternate)하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>3. 청구항 1에 있어서,상기 제2 프레임의 저해상도 버전을 얻기 위해 상기 제2 프레임의 해상도를 감소시키는 단계를 더 포함하고,상기 제2 뉴럴 네트워크는 상기 저해상도 버전을 입력으로 취하고 상기 제1 뉴럴 네트워크는 상기 제1 프레임의 고해상도 버전을 입력으로 취하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 1에 있어서,제3 도메인으로부터 객체들을 감지하도록 트레이닝(training) 된 제3 뉴럴 네트워크를 사용하여 비디오의 제3 프레임에서 제3 객체를 감지하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 1에 있어서,상기 제1 도메인은,상기 제2 도메인의 객체들에 비해 크기가 작은 객체들을 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 1에 있어서,상기 제1 도메인은, 상기 제2 도메인과 겹쳐지는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 1에 있어서,상기 제1 객체 정보는,제1 컴퓨터 비전 태스크(vision task)에 대응하고,제2 객체 정보는,상기 제1 컴퓨터 비전 태스크와 다른 제2 컴퓨터 비전 태스크에 대응하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>8. 청구항 1에 있어서,상기 라벨 데이터를 생성하기 위해 이용 가능한 시스템 자원을 식별하는 단계; 및상기 이용 가능한 시스템 자원에 기초하여 상기 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크에 적용하기 위한 주파수를 선택하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>9. 기계 학습 모델을 트레이닝(training) 시키는 방법에 있어서,제1 도메인에 대응하는 제1 트레이닝 데이터를 식별하는 단계;상기 제1 트레이닝 데이터를 사용하여 제1 컴퓨터 비전 태스크(vision task)를 수행하도록 제1 뉴럴 네트워크를 트레이닝 시키는 단계;제2 도메인에 대응하는 제2 트레이닝 데이터를 식별하는 단계;상기 제2 트레이닝 데이터를 사용하여 제2 컴퓨터 비전 태스크를 수행하도록 제2 뉴럴 네트워크를 트레이닝 시키는 단계; 및상기 제1 뉴럴 네트워크 및 상기 제2 뉴럴 네트워크를 비디오의 프레임들에 교대로(alternately) 적용하여 상기 제1 도메인 및 상기 제2 도메인 모두에 대응하는 라벨 데이터(label data)를 생성하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 9에 있어서,상기 제2 트레이닝 데이터는, 상기 제1 트레이닝 데이터보다 더 낮은 해상도(resolution)를 갖는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>11. 청구항 9에 있어서,상기 제1 뉴럴 네트워크 및 상기 제2 뉴럴 네트워크는 독립적으로 트레이닝 되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>12. 청구항 9에 있어서,제3 도메인에 대응하는 제3 트레이닝 데이터를 식별하는 단계;상기 제3 트레이닝 데이터를 사용하여 제3 컴퓨터 비전 태스크를 수행하도록 제3 뉴럴 네트워크를 트레이닝 시키는 단계; 및상기 비디오의 프레임들에 상기 제3 뉴럴 네트워크를 교대로 적용하여 상기 라벨 데이터를 생성하는 단계를 더 포함하고, 상기 라벨 데이터는 상기 제3 도메인에 대응하는 데이터를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>13. 청구항 9에 있어서,상기 제1 트레이닝 데이터는,상기 제2 도메인의 객체들에 대한 제2 라벨 데이터에 비해 크기가 작은 객체들에 대한 제1 라벨 데이터를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>14. 청구항 9에 있어서,상기 제1 트레이닝 데이터는, 상기 제2 트레이닝 데이터와 겹쳐지는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>15. 이미지 처리를 위한 시스템에 있어서:비디오를 제1 프레임 및 제2 프레임을 포함하는 복수의 프레임들로 분할하는 프레임 선택 컴포넌트;상기 제1 프레임에서의 제1 객체에 대한 제1 객체 정보를 생성하도록 구성된 제1 뉴럴 네트워크, 상기 제1 뉴럴 네트워크는 제1 도메인에서 동작하도록 트레이닝(training) 되고;상기 제2 프레임에서의 제2 객체에 대한 제2 객체 정보를 생성하도록 구성된 제2 뉴럴 네트워크, 상기 제2 뉴럴 네트워크는 제2 도메인에서 동작하도록 트레이닝 되고; 및상기 제1 객체 정보에 기초한 제1 라벨 및 상기 제2 객체 정보에 기초한 제2 라벨을 포함하는 상기 비디오에 대한 라벨 데이터를 생성하도록 구성된 데이터 합성 컴포넌트를 포함하는 것을 특징으로 하는 시스템. </claim></claimInfo><claimInfo><claim>16. 청구항 15에 있어서,상기 시스템은,제3 뉴럴 네트워크를 더 포함하고,상기 제3 뉴럴 네트워크는,제3 프레임에서의 제3 객체에 대한 제3 객체 정보를 생성하도록 구성되고, 상기 제3 뉴럴 네트워크는 제3 도메인에서 동작하도록 트레이닝 되는 것을 특징으로 하는 시스템.</claim></claimInfo><claimInfo><claim>17. 청구항 15에 있어서,상기 시스템은,해상도 감소(resolution reduction) 컴포넌트를 더 포함하고,상기 해상도 감소 컴포넌트는, 상기 제2 프레임의 저해상도 버전을 얻기 위해 상기 제2 프레임의 해상도를 감소시키도록 구성되고, 상기 제2 뉴럴 네트워크는 상기 저해상도 버전을 입력으로 취하고, 상기 제1 뉴럴 네트워크는 상기 제1 프레임의 고해상도 버전을 입력으로 취하는 것을 특징으로 하는 시스템.</claim></claimInfo><claimInfo><claim>18. 청구항 15에 있어서,상기 시스템은,자원 최적화 컴포넌트를 더 포함하고,상기 자원 최적화 컴포넌트는, 상기 라벨 데이터를 생성하기 위한 이용 가능한 시스템 자원들을 식별하고, 상기 이용 가능한 시스템 자원들을 기반으로 상기 제1 뉴럴 네트워크 및 제2 뉴럴 네트워크에 적용하기 위한 주파수를 선택하도록 구성되는 것을 특징으로 하는 시스템.</claim></claimInfo><claimInfo><claim>19. 청구항 15에 있어서,상기 제2 뉴럴 네트워크는,상기 제1 뉴럴 네트워크 보다 적은 파라미터들을 포함하는 것을 특징으로 하는 시스템.</claim></claimInfo><claimInfo><claim>20. 청구항 15에 있어서,상기 시스템은,트레이닝 컴포넌트를 더 포함하고,상기 트레이닝 컴포넌트는 상기 제1 뉴럴 네트워크 및 상기 제2 뉴럴 네트워크를 트레이닝 시키기 위해 구성되는 것을 특징으로 하는 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>GOLDIN, Ishay</engName><name>골드인 이샤이</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>STEIN, Netanel</engName><name>스테인 네타넬</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>DANA, Alexandra</engName><name>다나 알렉산드라</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>INTRATER, Alon</engName><name>인트레이터 알론</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>TSIDKIAHU, David</engName><name>치드키아후 데이비드</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEVY, Nathan</engName><name>레비 나단</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SHABTAI, Omer</engName><name>샤브타이 오메르</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>VITEK, Ran</engName><name>바이텍 란</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HELLER, Tal</engName><name>헬러 탈</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>UKRAINITZ, Yaron</engName><name>우크라이니츠 야론</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PLATNER, Yotam</engName><name>플래트너 요탐</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PILOSOF, Zuf</engName><name>필로소프 주프</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.05.12</priorityApplicationDate><priorityApplicationNumber>17/663,035</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.04.20</receiptDate><receiptNumber>1-1-2023-0448414-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.05.01</receiptDate><receiptNumber>9-1-2023-9005395-64</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.10.31</receiptDate><receiptNumber>1-1-2025-1220077-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.31</receiptDate><receiptNumber>1-1-2025-1220078-34</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230052204.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c932e6423c17ba1b58fb00070635bf3ff45086f5885d656129526728329d65d668df283f9180f4c5c670d07eb19534e8873f1a014c2a1242968</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf84b60fa7f1299404bd8d960db0d65fc00ea81d463f2b23879ba4a602a22521d1ea59c92337c5989313e63466e6b8e4a1d218156e8192bc23</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>