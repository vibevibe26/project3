<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:02.562</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0196432</applicationNumber><claimCount>16</claimCount><examinerName> </examinerName><finalDisposal>등록결정(일반)</finalDisposal><inventionTitle>복수의 이미지들을 분석하여 아이템의 위치를 모델링하는 방법</inventionTitle><inventionTitleEng>METHOD FOR MODELING POSITION OF ITEM BY ANALYZING A  PLURALITY OF IMAGES</inventionTitleEng><openDate>2025.07.08</openDate><openNumber>10-2025-0104251</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06Q 30/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 실시예에 따라 컴퓨팅 장치에 의해 수행되는, 복수의 이미지들을 분석하여 아이템의 위치를 모델링하는 방법이 개시된다. 상기 방법은 매장과 관련된 복수의 이미지들을 획득하는 단계와, 신경망 모델을 활용하여, 상기 복수의 이미지들을 기초로 의미론적(semantic) 지도를 생성하는 단계와, 고객 분석 정보를 획득하는 단계와, 위치 예측 모델을 활용하여, 상기 고객 분석 정보를 기초로 아이템의 위치 좌표를 획득하는 단계와, 생성 모델을 활용하여, 상기 위치 좌표 및 상기 의미론적 지도에 기초하여 상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 장치에 의해 수행되는, 복수의 이미지들을 분석하여 아이템의 위치를 모델링하는 방법으로서,매장과 관련된 복수의 이미지들을 획득하는 단계;신경망 모델을 활용하여, 상기 복수의 이미지들을 기초로 의미론적(semantic) 지도를 생성하는 단계; 고객 분석 정보를 획득하는 단계;위치 예측 모델을 활용하여, 상기 고객 분석 정보를 기초로 아이템의 위치 좌표를 획득하는 단계; 및생성 모델을 활용하여, 상기 위치 좌표 및 상기 의미론적 지도에 기초하여 상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 고객 분석 정보를 획득하는 단계는,제 1 센서에서 획득한 제 1 데이터에 기초하여 고객 통계 정보를 획득하는 단계; 및제 2 센서에서 획득한 제 2 데이터에 기초하여 고객 특성 정보를 획득하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 고객 통계 정보를 획득하는 단계는,깊이 센서에서 획득한 상기 제 1 데이터를 분석하여 고객의 동선 정보를 획득하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 고객 특성 정보를 획득하는 단계는,카메라 센서에서 획득한 상기 제 2 데이터를 분석하여 상기 고객의 인적 정보를 획득하는 단계를 포함하는,방법.  </claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 아이템의 위치 좌표를 획득하는 단계는,상기 위치 예측 모델을 활용하여, 상기 고객 통계 정보, 상기 고객 특성 정보, 및 추가적인 정보를 기초로 상기 아이템의 위치 좌표를 획득하는 단계를 포함하고,상기 추가적인 정보는 아이템 정보와 매장의 그리드 정보 중 적어도 하나를 포함하고, 상기 아이템 정보는 상기 매장 내에서 상기 아이템이 차지하는 공간의 크기 정보, 및 상기 아이템에 대한 타겟 고객층의 분석 정보를 포함하고,상기 매장의 그리드 정보는 상기 매장 내의 공간이 격자 형태로 분할되어 형성된 각 격자 셀에 할당된 위치 정보인,방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 복수의 이미지들을 기초로 상기 의미론적 지도를 생성하는 단계는,상기 복수의 이미지들의 자아 중심적인(egocentric) 특징을 추출하는 단계;상기 자아 중심적인 특징을 환경 중심적인(allocentric) 특징 맵으로 변환하는 단계; 및상기 환경 중심적인 특징 맵을 기초로 환경 중심적인 의미를 예측하고, 상기 의미론적 지도를 생성하는 단계 를 포함하는,방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 자아 중심적인 특징을 상기 환경 중심적인 특징 맵으로 변환하는 단계는,카메라 내부 파라미터 행렬과 이미지의 각 픽셀의 깊이 정보에 기초하여 상기 자아 중심적인 특징을 환경 중심적인 매모리 맵에 투영하는 단계 를 포함하는,방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 자아 중심적인 특징을 상기 환경 중심적인 특징 맵으로 변환하는 단계는,상기 자아 중심적인 특징을 양방향으로 투영하고, 양방향으로 투영된 환경 중심적인 메모리 특징을 융합하여 환경 중심적인 표현을 생성하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 단계는,멀티모달(multi-modal) 기반의 제1 신경망 모델을 활용하여 상기 위치 좌표에 대한 이미지 임베딩 벡터를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 단계는,제 2 신경망 모델을 활용하여 상기 이미지 임베딩 벡터를 입력으로 하고, 상기 의미론적 지도를 조건으로 하여 상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 하나 이상의 프로세서에 의해 실행되는 경우, 상기 하나 이상의 프로세서로 하여금 복수의 이미지들을 분석하여 아이템의 위치를 모델링하는 동작들을 수행하도록 하며, 상기 동작들은:매장과 관련된 복수의 이미지들을 획득하는 동작;신경망 모델을 활용하여, 상기 복수의 이미지들을 기초로 의미론적(semantic) 지도를 생성하는 동작;고객 분석 정보를 획득하는 동작;위치 예측 모델을 활용하여, 상기 고객 분석 정보를 기초로 아이템의 위치 좌표를 획득하는 동작; 및생성 모델을 활용하여, 상기 위치 좌표 및 상기 의미론적 지도에 기초하여 상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 동작을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 고객 분석 정보를 획득하는 동작은,제 1 센서에서 획득한 제 1 데이터에 기초하여 고객 통계 정보를 획득하는 동작; 및제 2 센서에서 획득한 제 2 데이터에 기초하여 고객 특성 정보를 획득하는 동작을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서,상기 아이템의 위치 좌표를 획득하는 동작은,상기 위치 예측 모델을 활용하여, 상기 고객 통계 정보, 상기 고객 특성 정보, 및 추가적인 정보를 기초로 상기 아이템의 위치 좌표를 획득하는 동작을 포함하고,상기 추가적인 정보는 아이템 정보와 매장의 그리드 정보 중 적어도 하나를 포함하고, 상기 아이템 정보는 상기 매장 내에서 상기 아이템이 차지하는 공간의 크기 정보, 및 상기 아이템에 대한 타겟 고객층의 분석 정보를 포함하고,상기 매장의 그리드 정보는 상기 매장 내의 공간이 격자 형태로 분할되어 형성된 각 격자 셀에 할당된 위치 정보인,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>14. 제 11 항에 있어서,상기 복수의 이미지들을 기초로 상기 의미론적 지도를 생성하는 동작은,상기 복수의 이미지들의 자아 중심적인(egocentric) 특징을 추출하는 동작;상기 자아 중심적인 특징을 환경 중심적인(allocentric) 특징 맵으로 변환하는 동작; 및상기 환경 중심적인 특징 맵을 기초로 환경 중심적인 의미를 예측하고, 상기 의미론적 지도를 생성하는 동작 을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 제 11 항에 있어서,상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 동작은,멀티모달(multi-modal) 기반의 제1 신경망 모델을 활용하여 상기 위치 좌표에 대한 이미지 임베딩 벡터를 획득하는 동작을 포함하는, 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서,상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 동작은,제 2 신경망 모델을 활용하여 상기 이미지 임베딩 벡터를 입력으로 하고, 상기 의미론적 지도를 조건으로 하여 상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하는 동작을 더 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>17. 컴퓨팅 장치로서,적어도 하나의 프로세서; 및메모리를 포함하고,상기 적어도 하나의 프로세서는,매장과 관련된 복수의 이미지들을 획득하고,신경망 모델을 활용하여, 상기 복수의 이미지들을 기초로 의미론적(semantic) 지도를 생성하고,고객 분석 정보를 획득하고,위치 예측 모델을 활용하여, 상기 고객 분석 정보를 기초로 아이템의 위치 좌표를 획득하고, 그리고,생성 모델을 활용하여, 상기 위치 좌표 및 상기 의미론적 지도에 기초하여 상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하도록 구성되는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,제 1 센서에서 획득한 제 1 데이터에 기초하여 고객 통계 정보를 획득하고, 그리고,제 2 센서에서 획득한 제 2 데이터에 기초하여 고객 특성 정보를 획득하도록 추가로 구성되는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서,상기 위치 예측 모델을 활용하여, 상기 고객 통계 정보, 상기 고객 특성 정보, 및 추가적인 정보를 기초로 상기 아이템의 위치 좌표를 획득하도록 추가로 구성되고,상기 추가적인 정보는 아이템 정보와 매장의 그리드 정보 중 적어도 하나를 포함하고, 상기 아이템 정보는 상기 매장 내에서 상기 아이템이 차지하는 공간의 크기 정보, 및 상기 아이템에 대한 타겟 고객층의 분석 정보를 포함하고,상기 매장의 그리드 정보는 상기 매장 내의 공간이 격자 형태로 분할되어 형성된 각 격자 셀에 할당된 위치 정보인,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>20. 제 17 항에 있어서,상기 복수의 이미지들의 자아 중심적인(egocentric) 특징을 추출하고,상기 자아 중심적인 특징을 환경 중심적인(allocentric) 특징 맵으로 변환하고, 그리고,상기 환경 중심적인 특징 맵을 기초로 환경 중심적인 의미를 예측하고, 상기 의미론적 지도를 생성하도록 추가로 구성되는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>21. 제 17 항에 있어서,멀티모달(multi-modal) 기반의 제1 신경망 모델을 활용하여 상기 위치 좌표에 대한 이미지 임베딩 벡터를 획득하도록 추가로 구성되는,컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>22. 제 21 항에 있어서,제 2 신경망 모델을 활용하여 상기 이미지 임베딩 벡터를 입력으로 하고, 상기 의미론적 지도를 조건으로 하여 상기 매장 내 상기 아이템의 위치가 모델링 된 이미지를 생성하도록 추가로 구성되는,컴퓨팅 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강남구...</address><code>120230835885</code><country>대한민국</country><engName>SAFEAI</engName><name>주식회사 세이프에이아이</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>LEE, Won Seop</engName><name>이원섭</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>SEOL, Tong Keun</engName><name>설동근</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code> </code><country> </country><engName>KIM, Won Suk</engName><name>김원석</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920090037635</code><country>대한민국</country><engName>LEE, Dae Ho</engName><name>이대호</name></agentInfo><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920120001378</code><country>대한민국</country><engName>Park, Gun Hong</engName><name>박건홍</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.29</receiptDate><receiptNumber>1-1-2023-1475638-36</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.08.20</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2024.10.31</receiptDate><receiptNumber>9-6-2025-0037200-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.02.26</receiptDate><receiptNumber>9-5-2025-0203024-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.04.24</receiptDate><receiptNumber>1-1-2025-0467549-84</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.24</receiptDate><receiptNumber>1-1-2025-0467548-38</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Decision to grant</documentEngName><documentName>등록결정서</documentName><receiptDate>2025.11.10</receiptDate><receiptNumber>9-5-2025-1089465-51</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230196432.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93177963701f90017668320c96f0174ba878211a17cec0cb1017c66cfee393262ff5d577e350a9339ece486781693f30e8166d5e0b1da62981</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf3e97f307204c011c27b9b76d3f7a221627bf1f720718b6e829efb7f411d1d2e0180cc3a4667b8b3bbe3a1bd882d8afa1ade4a85c9c4c9313</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>