<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:03.23</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7036315</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자기-적응형 증류</inventionTitle><inventionTitleEng>SELF-ADAPTIVE DISTILLATION</inventionTitleEng><openDate>2023.11.20</openDate><openNumber>10-2023-0158613</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.10.23</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 하나 이상의 트레이닝된 교사 ASR(automatic speech recognition) 모델들(210)을 다중-언어 학생 모델(200)로 증류(distilling)하기 위한 방법(400)은 복수의 교사 트레이닝 예들(152) 및 복수의 학생 트레이닝 예들(154)을 수신하는 단계를 포함한다. 방법은 또한 복수의 교사 트레이닝 예들을 사용하여 하나 이상의 교사 ASR 모델들을 트레이닝하는 단계를 포함한다. 각각의 교사 ASR 모델은 개개의 오디오 입력의 개개의 텍스트 표현을 출력하도록 구성된다. 방법은, 복수의 학생 트레이닝 예들을 사용하여 다중-언어 학생 ASR 모델을 트레이닝하고, 그리고 튜닝가능한 증류 손실 가중치(222)를 사용하여, 트레이닝된 하나 이상의 교사 ASR 모델들을 다중-언어 학생 ASR 모델로 증류함으로써, 다중-언어 학생 ASR 모델을 생성하는 단계를 더 포함한다. 학생 ASR 모델은, 오디오 입력(14)을 수신하고 수신된 오디오 입력의 대응하는 텍스트 표현(142)을 출력하도록 구성된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.09.29</internationOpenDate><internationOpenNumber>WO2022203729</internationOpenNumber><internationalApplicationDate>2021.12.07</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/062255</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 데이터 프로세싱 하드웨어(134)에 의해 실행될 때 상기 데이터 프로세싱 하드웨어(134)로 하여금 동작들을 수행하게 하는, 컴퓨터에서 구현되는 방법(computer-implemented method)(400)으로서, 상기 동작들은, 복수의 교사(teacher) 트레이닝 예들(152) 및 복수의 학생(student) 트레이닝 예들(154)을 수신하는 동작; 상기 복수의 교사 트레이닝 예들(152)을 사용하여 하나 이상의 교사 ASR(automatic speech recognition) 모델들(210)을 트레이닝하는 동작 — 각각의 교사 ASR 모델(210)은 개개의 오디오 입력(14)의 개개의 텍스트 표현을 출력하도록 구성됨 —; 및  상기 복수의 학생 트레이닝 예들(154)을 사용하여 다중-언어(multi-lingual) 학생 ASR 모델(200)을 트레이닝하고 — 상기 학생 ASR 모델(200)은, 오디오 입력(14)을 수신하고, 상기 수신된 오디오 입력(14)의 대응하는 텍스트 표현(142)을 출력하도록 구성됨 —, 그리고  튜닝가능한 증류 손실 가중치(tunable distillation loss weight)(222)를 사용하여, 상기 트레이닝된 하나 이상의 교사 ASR 모델들(210)을 상기 다중-언어 학생 ASR 모델(200)로 증류(distilling)함으로써, 상기 다중-언어 학생 ASR 모델(200)을 생성하는 동작을 포함하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210)은 상기 다중-언어 학생 ASR 모델(200)보다 더 적은 언어들을 집합적으로 인식하도록 구성되는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>3. 제1 항 또는 제2 항에 있어서, 상기 튜닝가능한 증류 손실 가중치(222)는 상수 값을 포함하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>4. 제1 항 내지 제3 항 중 어느 한 항에 있어서, 상기 다중-언어 학생 모델(200)을 트레이닝하는 것은 n 개의 트레이닝 단계들에 걸쳐 발생하고, 그리고 상기 튜닝가능한 증류 손실 가중치(222)는 상기 n 개의 트레이닝 단계들에 기반하여 감소하는 감소 함수(decreasing function)를 포함하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>5. 제1 항 내지 제4 항 중 어느 한 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210) 및 상기 다중-언어 학생 ASR 모델(200) 각각은 RNN-T(recurrent neural network-transducer) 아키텍처를 포함하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서, 상기 튜닝가능한 증류 손실 가중치(222)는 상기 하나 이상의 교사 ASR 모델들(210)에 대응하는 RNN-T 손실에 기반하는 감소 함수를 포함하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>7. 제5 항 또는 제6 항에 있어서, 상기 튜닝가능한 증류 손실 가중치(222)는 상기 하나 이상의 교사 ASR 모델들(210)에 대응하는 제1 RNN-T 손실 및 상기 다중-언어 학생 ASR 모델(200)에 대응하는 제2 RNN-T 손실에 기반하는 감소 함수를 포함하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서, 상기 감소 함수는,  시간 인스턴스에 걸쳐 상기 하나 이상의 교사 ASR 모델들(210)에 대응하는 상기 제1 RNN-T 손실을 감소시키고, 그리고  상기 시간 인스턴스에 걸쳐 상기 다중-언어 학생 ASR 모델(200)에 대응하는 상기 제2 RNN-T 손실을 증가시키는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 한 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210)의 각각의 교사 ASR 모델(210)은 단일-언어(mono-lingual) 교사 ASR 모델(210)에 대응하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 한 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210)은 단일의 다중-언어 ASR 모델(single multi-lingual ASR model)에 대응하는, 컴퓨터에서 구현되는 방법(400).</claim></claimInfo><claimInfo><claim>11. 시스템(100)으로서, 데이터 프로세싱 하드웨어(134); 및 상기 데이터 프로세싱 하드웨어(134)와 통신하는 메모리 하드웨어(136)를 포함하며, 상기 메모리 하드웨어(136)는, 상기 데이터 프로세싱 하드웨어(134) 상에서 실행될 때 상기 데이터 프로세싱 하드웨어(134)로 하여금 동작들을 수행하게 하는 명령들을 저장하며, 상기 동작들은, 복수의 교사 트레이닝 예들(152) 및 복수의 학생 트레이닝 예들(154)을 수신하는 동작; 상기 복수의 교사 트레이닝 예들(152)을 사용하여 하나 이상의 교사 ASR(automatic speech recognition) 모델들(210)을 트레이닝하는 동작 — 각각의 교사 ASR 모델(210)은 개개의 오디오 입력(14)의 개개의 텍스트 표현을 출력하도록 구성됨 —; 및  상기 복수의 학생 트레이닝 예들(154)을 사용하여 다중-언어 학생 ASR 모델(200)을 트레이닝하고 — 상기 학생 ASR 모델(200)은, 오디오 입력(14)을 수신하고, 상기 수신된 오디오 입력(14)의 대응하는 텍스트 표현(142)을 출력하도록 구성됨 —, 그리고  튜닝가능한 증류 손실 가중치(222)를 사용하여, 상기 트레이닝된 하나 이상의 교사 ASR 모델들(210)을 상기 다중-언어 학생 ASR 모델(200)로 증류함으로써, 상기 다중-언어 학생 ASR 모델(200)을 생성하는 동작을 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210)은 상기 다중-언어 학생 ASR 모델(200)보다 더 적은 언어들을 집합적으로 인식하도록 구성되는, 시스템(100).</claim></claimInfo><claimInfo><claim>13. 제11 항 또는 제12 항에 있어서, 상기 튜닝가능한 증류 손실 가중치(222)는 상수 값을 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>14. 제11 항 내지 제13 항 중 어느 한 항에 있어서, 상기 다중-언어 학생 모델(200)을 트레이닝하는 것은 n 개의 트레이닝 단계들에 걸쳐 발생하고, 그리고 상기 튜닝가능한 증류 손실 가중치(222)는 상기 n 개의 트레이닝 단계들에 기반하여 감소하는 감소 함수를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>15. 제11 항 내지 제14 항 중 어느 한 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210) 및 상기 다중-언어 학생 ASR 모델 각각은 RNN-T(recurrent neural network-transducer) 아키텍처를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서, 상기 튜닝가능한 증류 손실 가중치(222)는 상기 하나 이상의 교사 ASR 모델들(210)에 대응하는 RNN-T 손실에 기반하는 감소 함수를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>17. 제15 항 또는 제16 항에 있어서, 상기 튜닝가능한 증류 손실 가중치(222)는 상기 하나 이상의 교사 ASR 모델들(210)에 대응하는 제1 RNN-T 손실 및 상기 다중-언어 학생 ASR 모델(200)에 대응하는 제2 RNN-T 손실에 기반하는 감소 함수를 포함하는, 시스템(100).</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서, 상기 감소 함수는,  시간 인스턴스에 걸쳐 상기 하나 이상의 교사 ASR 모델들(210)에 대응하는 상기 제1 RNN-T 손실을 감소시키고, 그리고  상기 시간 인스턴스에 걸쳐 상기 다중-언어 학생 ASR 모델(200)에 대응하는 상기 제2 RNN-T 손실을 증가시키는, 시스템(100).</claim></claimInfo><claimInfo><claim>19. 제11 항 내지 제18 항 중 어느 한 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210)의 각각의 교사 ASR 모델(210)은 단일-언어 교사 ASR 모델(210)에 대응하는, 시스템(100).</claim></claimInfo><claimInfo><claim>20. 제11 항 내지 제19 항 중 어느 한 항에 있어서, 상기 하나 이상의 교사 ASR 모델들(210)은 단일의 다중-언어 ASR 모델에 대응하는, 시스템(100).</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>LEAL, Isabel</engName><name>릴, 이사벨</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>GAUR, Neeraj</engName><name>가우르, 니라즈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>HAGHANI, Parisa</engName><name>하가니, 파리사</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>FARRIS, Brian</engName><name>파리스, 브라이언</name></inventorInfo><inventorInfo><address>미국 ***** 뉴욕 마...</address><code> </code><country> </country><engName>RAMABHADRAN, Bhuvana</engName><name>라마바드란, 부바나</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>PRASAD, Manasa</engName><name>프라사드, 마나사</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MENGIBAR, Pedro, J., Moreno</engName><name>멘지바르, 페드로, 제이., 모레노</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ZHU, Yun</engName><name>주, 윤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 서소문로**(서소문동, 정안빌딩*층)</address><code>920121001826</code><country>대한민국</country><engName>NAM &amp; NAM</engName><name>특허법인 남앤남</name></agentInfo><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.03.26</priorityApplicationDate><priorityApplicationNumber>63/166,938</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.10.23</receiptDate><receiptNumber>1-1-2023-1161385-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.10.24</receiptDate><receiptNumber>1-1-2023-1167780-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.10.25</receiptDate><receiptNumber>1-5-2023-0169242-85</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName> </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.03.07</receiptDate><receiptNumber>1-1-2024-0261768-66</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[반환신청]서류 반려요청서·반환신청서</documentName><receiptDate>2024.04.03</receiptDate><receiptNumber>1-1-2024-0369217-20</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.04.03</receiptDate><receiptNumber>1-1-2024-0369230-14</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237036315.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a2d678329cfea7459f4b409ed5d921f5095da3907ba87914b2491825ddf8215e5bcef751601b0e378d2a40aeeb8ca5d5c70f7392dc4eafa2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbc7079a1a6748d76e767b8d8c237844f99bfea40ad8f5876c6e6eb997abb8732da6a32ec391490d66a9d3e9dce9c37919fb523f7460d20a6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>