<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:25.425</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.01.11</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7018749</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>뇌-컴퓨터 인터페이스</inventionTitle><inventionTitleEng>BRAIN-COMPUTER INTERFACE</inventionTitleEng><openDate>2025.06.19</openDate><openNumber>10-2025-0090371</openNumber><originalApplicationDate>2021.01.11</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2022-7027050</originalApplicationNumber><originalExaminationRequestDate>2025.06.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.06.05</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/18</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020227027050</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 시스템 및 방법은 뇌-컴퓨터 인터페이스에 관한 것이고, 여기서, 하나 이상의 오브젝트를 오버레이하는 시각적 자극이 제공되고, 시각적 자극은 특성 변조를 갖는다. 뇌-컴퓨터 인터페이스는 사용자에 의해 뷰잉되는 오브젝트들에 대한 신경 응답을 측정한다. 시각적 자극에 대한 신경 응답은 변조와 상관된다. 방법은 인터페이스가 디스플레이 오브젝트를 단순히 뷰잉하는 것과 그 디스플레이 오브젝트를 (예컨대, 추가의 액션에 대한 트리거로서) 고의적으로 선택하는 것을 판별하는 것을 허용한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.07.15</internationOpenDate><internationOpenNumber>WO2021140247</internationOpenNumber><internationalApplicationDate>2021.01.11</internationalApplicationDate><internationalApplicationNumber>PCT/EP2021/050393</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,다수의 구별가능한 부분들을 갖는 복합 시각적 자극을 생성하는 단계;상기 복합 시각적 자극을 사용자에게 디스플레이하는 단계;상기 복합 시각적 자극의 제1 부분에 응답하여 상기 사용자로부터 캡처된 제1 디코딩된 신경 신호들을 결정하기 위해 제1 디코딩 모델을 이용하는 단계;상기 복합 시각적 자극의 제2 부분에 응답하여 상기 사용자로부터 캡처된 제2 디코딩된 신경 신호들을 디코딩하기 위해 제2 디코딩 모델을 이용하는 단계;상기 사용자의 주의 집중도(attentional engagement)를 평가하기 위해 상기 제1 디코딩된 신경 신호들과 상기 제2 디코딩된 신경 신호들을 비교하는 단계; 및상기 복합 시각적 자극의 상기 제1 부분 및 상기 제2 부분에 대한 밸런싱된 응답에 기초하여 상기 사용자의 주의를 초점을 맞추지 않는 것으로서 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,적어도 하나의 눈 추적 카메라에 의해 캡처된 이미지들을 수신하고 상기 캡처된 이미지에 따라 눈 추적 정보를 결정하는 단계를 더 포함하고,상기 사용자의 주의를 초점을 맞추지 않는 것으로서 결정하는 단계는 상기 눈 추적 정보를 이용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 눈 추적 정보는 응시 방향과 초점 심도 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 복합 시각적 자극의 상기 다수의 구별가능한 부분들에 변조가 선택적으로 적용되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 복합 시각적 자극의 고 공간 주파수(HSF) 성분에 상기 변조가 적용되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 복합 시각적 자극의 상기 다수의 구별가능한 부분들에 컬러가 선택적으로 적용되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 복합 시각적 자극의 상기 다수의 구별가능한 부분들에 모션이 선택적으로 적용되는, 방법.</claim></claimInfo><claimInfo><claim>8. 머신으로서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하는 명령어들을 저장한 적어도 하나의 메모리를 포함하고, 상기 동작들은:다수의 구별가능한 부분들을 갖는 복합 시각적 자극을 생성하는 동작;상기 복합 시각적 자극을 사용자에게 디스플레이하는 동작;상기 복합 시각적 자극의 제1 부분에 응답하여 상기 사용자로부터 캡처된 제1 디코딩된 신경 신호들을 결정하기 위해 제1 디코딩 모델을 이용하는 동작;상기 복합 시각적 자극의 제2 부분에 응답하여 상기 사용자로부터 캡처된 제2 디코딩된 신경 신호들을 디코딩하기 위해 제2 디코딩 모델을 이용하는 동작;상기 사용자의 주의 집중도(attentional engagement)를 평가하기 위해 상기 제1 디코딩된 신경 신호들과 상기 제2 디코딩된 신경 신호들을 비교하는 동작; 및상기 복합 시각적 자극의 상기 제1 부분 및 상기 제2 부분에 대한 밸런싱된 응답에 기초하여 상기 사용자의 주의를 초점을 맞추지 않는 것으로서 결정하는 동작을 포함하는, 머신.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 동작들은:적어도 하나의 눈 추적 카메라에 의해 캡처된 이미지들을 수신하고 상기 캡처된 이미지에 따라 눈 추적 정보를 결정하는 동작을 더 포함하고,상기 사용자의 주의를 초점을 맞추지 않는 것으로서 결정하는 동작은 상기 눈 추적 정보를 이용하는 동작을 더 포함하는, 머신.</claim></claimInfo><claimInfo><claim>10. 머신에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하는 명령어들을 포함한 머신 판독가능 저장 매체로서,상기 동작들은:다수의 구별가능한 부분들을 갖는 복합 시각적 자극을 생성하는 동작;상기 복합 시각적 자극을 사용자에게 디스플레이하는 동작;상기 복합 시각적 자극의 제1 부분에 응답하여 상기 사용자로부터 캡처된 제1 디코딩된 신경 신호들을 결정하기 위해 제1 디코딩 모델을 이용하는 동작;상기 복합 시각적 자극의 제2 부분에 응답하여 상기 사용자로부터 캡처된 제2 디코딩된 신경 신호들을 디코딩하기 위해 제2 디코딩 모델을 이용하는 동작;상기 사용자의 주의 집중도(attentional engagement)를 평가하기 위해 상기 제1 디코딩된 신경 신호들과 상기 제2 디코딩된 신경 신호들을 비교하는 동작; 및상기 복합 시각적 자극의 상기 제1 부분 및 상기 제2 부분에 대한 밸런싱된 응답에 기초하여 상기 사용자의 주의를 초점을 맞추지 않는 것으로서 결정하는 동작을 포함하는, 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>프랑스 ***** 파리 뤼 드 라 호슈푸꼬 **</address><code>520220129087</code><country>프랑스</country><engName>NEXTMIND SAS</engName><name>넥스트마인드 에스에이에스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>KOUIDER, Sid</engName><name>쿠이데르, 시드</name></inventorInfo><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>ZERAFA, Robin</engName><name>제라파, 로빈</name></inventorInfo><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>STEINMETZ, Nelson</engName><name>스테인메츠, 넬슨</name></inventorInfo><inventorInfo><address>프랑스 ***** 파리 뤼...</address><code> </code><country>프랑스</country><engName>BARASCUD, Nicolas</engName><name>바라스쿠드, 니콜라스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.01.07</priorityApplicationDate><priorityApplicationNumber>62/958,072</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.06.05</receiptDate><receiptNumber>1-1-2025-0631192-36</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257018749.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9380d278569d775277dfe8417f89a62d923f2ff9b9b3124d95971efbd763246d19f025813b0b10c70ec4edc0c4c17d7fcd1d3ec2fbb476a0c6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf297428012f3eab7e3a441c2739c067038d4ae6e2d6c8913a190f794f2cec8b262536483336243f9b63fbbcca1c77356fd3b0c2b9e39193c6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>