<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:58.558</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0113187</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>동영상을 처리하는 방법 및 이를 수행하는 장치</inventionTitle><inventionTitleEng>METHOD FOR PROCESSING VIDEO AND APPARATUS PERFORMING  THE SAME</inventionTitleEng><openDate>2024.10.14</openDate><openNumber>10-2024-0149295</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에서, 동영상 처리 방법은 타겟 프레임인 제2 입력 이미지와 동일한 장면(scene) 내에 포함된 제1 입력 이미지로부터 제1 이미지 특징을 추출하는 단계, 상기 제2 입력 이미지로부터 제2 이미지 특징을 추출하는 단계, 상기 제1 이미지 특징 및 상기 제2 이미지 특징에 기초하여 상기 제1 이미지 특징과 상기 제2 이미지 특징 사이의 시간적 변화 정보와 연관된 시간적 특징(temporal feature)을 생성하는 단계, 및 상기 시간적 특징에 기초하여 출력 이미지를 생성하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 타겟 프레임인 제2 입력 이미지와 동일한 장면(scene) 내에 포함된 제1 입력 이미지로부터 제1 이미지 특징을 추출하는 단계;상기 제2 입력 이미지로부터 제2 이미지 특징을 추출하는 단계;상기 제1 이미지 특징 및 상기 제2 이미지 특징에 기초하여 상기 제1 이미지 특징과 상기 제2 이미지 특징 사이의 시간적 변화 정보와 연관된 시간적 특징(temporal feature)을 생성하는 단계; 및상기 시간적 특징에 기초하여 출력 이미지를 생성하는 단계;를 포함하고,상기 시간적 특징을 생성하는 단계는,상기 제1 이미지 특징에 대하여 제1 컨볼루션 연산을 수행하고, 상기 제2 이미지 특징에 대하여 제2 컨볼루션 연산을 수행하는 단계,상기 제1 이미지 특징과 상기 제2 이미지 특징 사이의 픽셀 간 이동량을 학습하는 오프셋 네트워크를 이용하여, 상기 제1 컨볼루션 연산 결과 및 상기 제2 컨볼루션 연산 결과에 기초하여 오프셋이 적용된 이미지 특징을 생성하는 단계,상기 오프셋이 적용된 이미지 특징에 대하여 제3 컨볼루션 연산을 수행하는 단계,상기 오프셋이 적용된 이미지 특징에 대하여 제4 컨볼루션 연산을 수행하는 단계, 및상기 제2 컨볼루션 연산 결과, 상기 제3 컨볼루션 연산 결과, 및 상기 제4 컨볼루션 연산 결과를 각각 쿼리(query), 키(key), 및 밸류(value)로서 이용하는 셀프-어텐션 연산을 수행하여 상기 시간적 특징을 생성하는 단계를 포함하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 오프셋이 적용된 이미지 특징을 생성하는 단계는,제1 오프셋 네트워크를 이용하여, 상기 제1 컨볼루션 연산 결과로부터 제1 오프셋을 생성하는 단계,제2 오프셋 네트워크를 이용하여, 상기 제2 컨볼루션 연산 결과로부터 제2 오프셋을 생성하는 단계, 및상기 제1 이미지 특징에, 상기 제2 오프셋에서 상기 제1 오프셋을 감산하여 획득되는 제3 오프셋을 더하여 상기 오프셋이 적용된 이미지 특징을 생성하는 단계를 포함하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 오프셋 네트워크는깊이 별(depthwise) 컨볼루션 레이어,GELU(Gaussian Error Linear Unit) 활성화 함수, 및포인트 별(pointwise) 컨볼루션 레이어를 포함하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 제1 이미지 특징을 추출하는 단계는, 제1 컨볼루션 레이어를 이용하여 상기 제1 이미지 특징을 추출하고,상기 제2 이미지 특징을 추출하는 단계는, 제2 컨볼루션 레이어를 이용하여 상기 제2 이미지 특징을 추출하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 동영상 처리 방법은 상기 제2 이미지 특징 및 제3 이미지 특징에 기초하여 상기 제2 입력 이미지에 대한 공간적 특징(spatial feature)을 생성하는 단계를 더 포함하고,상기 출력 이미지를 생성하는 단계는 상기 공간적 특징에 더 기초하여 상기 출력 이미지를 생성하고,상기 제3 이미지 특징은 상기 제2 컨볼루션 신경망 내 k-1번째 레이어의 출력이고, k는 상기 제2 컨볼루션 신경망에 포함된 레이어의 개수인, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,상기 공간적 특징을 생성하는 단계는,상기 제2 이미지 특징에 대하여 제5 컨볼루션 연산을 수행하는 단계,상기 제3 이미지 특징에 대하여 제6 컨볼루션 연산을 수행하는 단계,상기 제3 이미지 특징에 대하여 제7 컨볼루션 연산을 수행하는 단계, 및상기 제5 컨볼루션 연산 결과, 상기 제6 컨볼루션 연산 결과, 및 상기 제7 컨볼루션 연산 결과를 각각 쿼리, 키, 및 밸류로서 이용하는 셀프-어텐션 연산을 수행하여 상기 공간적 특징을 생성하는 단계를 포함하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 동영상 처리 방법은,상기 제1 입력 이미지와 상기 제2 입력 이미지를 채널 방향으로 쌓은 행렬로부터 제4 이미지 특징을 추출하는 단계, 및상기 제4 이미지 특징, 상기 시간적 특징 및 상기 공간적 특징에 기초하여 상기 제1 입력 이미지 및 상기 제2 입력 이미지에 대한 시공간적 특징(spatio-temporal feature)을 생성하는 단계를 더 포함하고,상기 출력 이미지를 생성하는 단계는 상기 시공간적 특징에 더 기초하여 상기 출력 이미지를 생성하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 시공간적 특징을 생성하는 단계는,상기 제4 이미지 특징에 대하여 제8 컨볼루션 연산을 수행하는 단계,상기 시간적 특징에 대하여 제9 컨볼루션 연산을 수행하는 단계,상기 시간적 특징에 대하여 제10 컨볼루션 연산을 수행하는 단계,상기 공간적 특징에 대하여 제11 컨볼루션 연산을 수행하는 단계,상기 공간적 특징에 대하여 제12 컨볼루션 연산을 수행하는 단계,상기 제8 컨볼루션 연산 결과, 상기 제9 컨볼루션 연산 결과, 및 상기 제10 컨볼루션 연산 결과를 각각 쿼리, 키, 및 밸류로서 이용하는 셀프-어텐션 연산을 수행하여 제1 중간 결과를 생성하고, 상기 제8 컨볼루션 연산 결과, 상기 제11 컨볼루션 연산 결과, 및 상기 제12 컨볼루션 연산 결과를 각각 쿼리, 키, 및 밸류로서 이용하는 셀프-어텐션 연산을 수행하여 제2 중간 결과를 생성하고, 상기 제1 중간 결과 및 상기 제2 중간 결과를 더하여 상기 시공간적 특징을 생성하는 단계를 포함하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 제1 입력 이미지와 상기 제2 입력 이미지가 동일한 장면 내에 포함되었는지 여부는 상기 동영상의 메타 정보 또는 상기 동영상의 프레임의 변화에 기초하여 결정되는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항의 방법을 수행하기 위한 컴퓨터 프로그램을 저장한, 컴퓨터 판독 가능한 기록 매체.</claim></claimInfo><claimInfo><claim>11. 적어도 하나의 프로세서(710); 및동영상을 처리하기 위한 프로그램이 저장되는 메모리(720)를 포함하고,상기 적어도 하나의 프로세서(710)는 상기 프로그램을 실행함으로써,타겟 프레임인 제2 입력 이미지와 동일한 장면(scene) 내에 포함된 제1 입력 이미지로부터 제1 이미지 특징을 추출하고,상기 제2 입력 이미지로부터 제2 이미지 특징을 추출하고,상기 제1 이미지 특징 및 상기 제2 이미지 특징에 기초하여 상기 제1 이미지 특징과 상기 제2 이미지 특징 사이의 시간적 변화 정보와 연관된 시간적 특징(temporal feature)을 생성하고,상기 시간적 특징에 기초하여 출력 이미지를 생성하되,상기 적어도 하나의 프로세서가 상기 시간적 특징을 생성하는 것은,상기 제1 이미지 특징에 대하여 제1 컨볼루션 연산을 수행하고, 상기 제2 이미지 특징에 대하여 제2 컨볼루션 연산을 수행하는 것,상기 제1 이미지 특징과 상기 제2 이미지 특징 사이의 픽셀 간 이동량을 학습하는 오프셋 네트워크를 이용하여, 상기 제1 컨볼루션 연산 결과 및 상기 제2 컨볼루션 연산 결과에 기초하여 오프셋이 적용된 이미지 특징을 생성하는 것,상기 오프셋이 적용된 이미지 특징에 대하여 제3 컨볼루션 연산을 수행하는 것,상기 오프셋이 적용된 이미지 특징에 대하여 제4 컨볼루션 연산을 수행하는 것, 및상기 제2 컨볼루션 연산 결과, 상기 제3 컨볼루션 연산 결과, 및 상기 제4 컨볼루션 연산 결과를 각각 쿼리(query), 키(key), 및 밸류(value)로서 이용하는 셀프-어텐션 연산을 수행하여 상기 시간적 특징을 생성하는 것을 포함하는, 동영상 처리 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 적어도 하나의 프로세서가 상기 오프셋이 적용된 이미지 특징을 생성하는 것은,제1 오프셋 네트워크를 이용하여, 상기 제1 컨볼루션 연산 결과로부터 제1 오프셋을 생성하는 것,제2 오프셋 네트워크를 이용하여, 상기 제2 컨볼루션 연산 결과로부터 제2 오프셋을 생성하는 것, 및상기 제1 이미지 특징에, 상기 제2 오프셋에서 상기 제1 오프셋을 감산하여 획득되는 제3 오프셋을 더하여 상기 오프셋이 적용된 이미지 특징을 생성하는 것을 포함하는, 동영상 처리 장치.</claim></claimInfo><claimInfo><claim>13. 제11항 또는 제12항에 있어서,상기 오프셋 네트워크는깊이 별(depthwise) 컨볼루션 레이어,GELU(Gaussian Error Linear Unit) 활성화 함수, 및포인트 별(pointwise) 컨볼루션 레이어를 포함하는, 동영상 처리 장치.</claim></claimInfo><claimInfo><claim>14. 제11항 내지 제13항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서가 상기 제1 이미지 특징을 추출하는 것은, 제1 컨볼루션 레이어를 이용하여 상기 제1 이미지 특징을 추출하는 것을 포함하고,상기 적어도 하나의 프로세서가 상기 제2 이미지 특징을 추출하는 것은, 제2 컨볼루션 레이어를 이용하여 상기 제2 이미지 특징을 추출하는 것을 포함하는, 동영상 처리 방법.</claim></claimInfo><claimInfo><claim>15. 제11항 내지 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는 상기 프로그램을 실행함으로써, 상기 제2 이미지 특징 및 제3 이미지 특징에 기초하여 상기 제2 입력 이미지에 대한 공간적 특징(spatial feature)을 생성하고,상기 적어도 하나의 프로세서가 상기 출력 이미지를 생성하는 것은 상기 공간적 특징에 더 기초하여 상기 출력 이미지를 생성하고,상기 제3 이미지 특징은 상기 제2 컨볼루션 신경망 내 k-1번째 레이어의 출력이고, k는 상기 제2 컨볼루션 신경망에 포함된 레이어의 개수인, 동영상 처리 장치.</claim></claimInfo><claimInfo><claim>16. 제11항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서가 상기 공간적 특징을 생성하는 것은,상기 제2 이미지 특징에 대하여 제5 컨볼루션 연산을 수행하는 것,상기 제3 이미지 특징에 대하여 제6 컨볼루션 연산을 수행하는 것,상기 제3 이미지 특징에 대하여 제7 컨볼루션 연산을 수행하는 것, 및상기 제5 컨볼루션 연산 결과, 상기 제6 컨볼루션 연산 결과, 및 상기 제7 컨볼루션 연산 결과를 각각 쿼리, 키, 및 밸류로서 이용하는 셀프-어텐션 연산을 수행하여 상기 공간적 특징을 생성하는 것을 포함하는, 동영상 처리 장치.</claim></claimInfo><claimInfo><claim>17. 제11항 내지 제16항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는 상기 프로그램을 실행함으로써,상기 제1 입력 이미지와 상기 제2 입력 이미지를 채널 방향으로 쌓은 행렬로부터 제4 이미지 특징을 추출하고, 및상기 제4 이미지 특징, 상기 시간적 특징 및 상기 공간적 특징에 기초하여 상기 제1 입력 이미지 및 상기 제2 입력 이미지에 대한 시공간적 특징(spatio-temporal feature)을 생성하고,상기 적어도 하나의 프로세서가 상기 출력 이미지를 생성하는 것은 상기 시공간적 특징에 더 기초하여 상기 출력 이미지를 생성하는, 동영상 처리 장치.</claim></claimInfo><claimInfo><claim>18. 제11항 내지 제17항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서가 상기 시공간적 특징을 생성하는 것은,상기 제4 이미지 특징에 대하여 제8 컨볼루션 연산을 수행하는 것,상기 시간적 특징에 대하여 제9 컨볼루션 연산을 수행하는 것,상기 시간적 특징에 대하여 제10 컨볼루션 연산을 수행하는 것,상기 공간적 특징에 대하여 제11 컨볼루션 연산을 수행하는 것,상기 공간적 특징에 대하여 제12 컨볼루션 연산을 수행하는 것, 및상기 제8 컨볼루션 연산 결과, 상기 제9 컨볼루션 연산 결과, 및 상기 제10 컨볼루션 연산 결과를 각각 쿼리, 키, 및 밸류로서 이용하는 셀프-어텐션 연산을 수행하여 제1 중간 결과를 생성하고, 상기 제8 컨볼루션 연산 결과, 상기 제11 컨볼루션 연산 결과, 및 상기 제12 컨볼루션 연산 결과를 각각 쿼리, 키, 및 밸류로서 이용하는 셀프-어텐션 연산을 수행하여 제2 중간 결과를 생성하고, 상기 제1 중간 결과 및 상기 제2 중간 결과를 더하여 상기 시공간적 특징을 생성하는 것을 포함하는, 동영상 처리 장치.</claim></claimInfo><claimInfo><claim>19. 제11항 내지 제18항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는 상기 동영상의 메타 정보 또는 상기 동영상의 프레임의 변화에 기초하여 상기 제1 입력 이미지와 상기 제2 입력 이미지가 동일한 장면 내에 포함되었는지 여부를 결정하는, 동영상 처리 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Jae Yeon</engName><name>박재연</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>AHN, Il Jun</engName><name>안일준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Kwan Woo</engName><name>박관우</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SONG, Young Chan</engName><name>송영찬</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.04.05</priorityApplicationDate><priorityApplicationNumber>1020230045040</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.28</receiptDate><receiptNumber>1-1-2023-0948946-21</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230113187.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936e5d2f555a8109deaa5ed0ce4e1a0283d7a02f0e451856dc9a4a4cc098b6ba87beecca21c8ab6e27d5b1d76445b461c278abd1ea1c0735a1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1f20709730150463cb745be5da3908f795941e9545a5608392bb31420d5469d4aeb32113a392afabec5cc1354ab40f081357cbc8d56c5205</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>