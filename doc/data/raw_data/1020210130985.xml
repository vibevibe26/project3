<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:03.63</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.10.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0130985</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>깊이맵을 개선하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS OF IMPROVING DEPTH MAP</inventionTitleEng><openDate>2023.04.10</openDate><openNumber>10-2023-0047759</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.25</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/128</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/271</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/122</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/593</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따르면, 깊이맵을 개선하는 방법은 다중 시점의 깊이맵들을, 각 시점에 대응하는 카메라 파라미터를 이용하여 3차원 공간으로 역투사하여 다중 시점의 깊이맵들에 대응하는 포인트 클라우드를 형성하고, 포인트 클라우드의 포인트들에 대응하는 특징 임베딩 벡터들을 추출하고, 포인트 클라우드의 포인트들 중 특정 시점에 해당하는 포인트들의 특징 임베딩 벡터들을 기초로 특정 시점의 2차원 특징맵을 생성하고, 2차원 특징맵을 깊이를 개선하는 네트워크에 인가함으로써 잔차 깊이맵을 획득하며, 잔차 깊이맵을 다중 시점의 깊이맵들 중 특정 시점의 깊이맵에 결합하여 개선된 깊이맵을 출력한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 다중 시점의 깊이맵들을, 각 시점에 대응하는 카메라 파라미터를 이용하여 3차원 공간으로 역투사(un-projection)하여 상기 다중 시점의 깊이맵들에 대응하는 포인트 클라우드(point cloud)를 형성하는 동작;상기 포인트 클라우드의 포인트들에 대응하는 특징 임베딩 벡터들을 추출하는 동작;상기 포인트 클라우드의 포인트들 중 특정 시점에 해당하는 포인트들의 특징 임베딩 벡터들을 기초로, 상기 특정 시점의 2차원 특징맵을 생성하는 동작;상기 2차원 특징맵을, 깊이를 개선하는 네트워크에 인가함으로써 잔차 깊이맵(residual depth map)을 획득하는 동작; 및 상기 잔차 깊이맵을 상기 다중 시점의 깊이맵들 중 상기 특정 시점의 깊이맵에 결합하여 개선된 깊이맵을 출력하는 동작를 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 동일한 객체를 서로 다른 시점으로 촬영한 복수의 프레임들을 포함하는 입력 영상을, 단일 시점의 깊이맵을 추정하는 네트워크에 인가함으로써 상기 다중 시점의 깊이맵들을 추정하는 동작을 더 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 입력 영상은다중 시점의 RGB 영상을 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 특징 임베딩 벡터들을 추출하는 동작은 상기 단일 시점의 깊이맵을 추정하는 네트워크의 마지막 레이어의 특징맵으로부터, 상기 포인트 클라우드의 각 포인트의 위치에 해당하는 특징을 패칭(fetching)하는 동작; 및 상기 패칭한 특징을, 상기 포인트 클라우드에서 대응하는 위치의 각 포인트에 결합하여 상기 특징 임베딩 벡터들을 추출하는 동작을 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 2차원 특징맵을 생성하는 동작은상기 특징 임베딩 벡터들을 상기 특정 시점의 영상 평면(image plane)으로 투영(projection)함으로써 상기 특정 시점의 2차원 특징맵을 생성하는 동작을 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서, 상기 잔차 깊이맵을 획득하는 동작은 상기 입력 영상 및 상기 2차원 특징맵을 상기 깊이를 개선하는 네트워크에 인가함으로써 상기 잔차 깊이맵을 획득하는 동작을 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 잔차 깊이맵을 획득하는 동작은 상기 입력 영상의 채널들을 상기 2차원 특징맵의 채널들에 더하여 상기 깊이를 개선하는 네트워크에 인가함으로써 상기 잔차 깊이맵을 획득하는 동작을 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>8. 제2항에 있어서, 상기 개선된 깊이맵을 출력하는 동작은 상기 잔차 깊이맵을, 상기 다중 시점의 깊이맵들 중 상기 특정 시점의 깊이맵에 결합하는 동작; 및 상기 결합된 깊이맵들의 쉬프트(shift), 스케일(scale), 및 화질 중 적어도 하나를 조정함으로써 상기 개선된 깊이맵을 출력하는 동작 을 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>9. 제2항에 있어서, 상기 개선된 깊이맵에 대하여, 상기 포인트 클라우드를 형성하는 동작, 상기 특징 임베딩 벡터들을 추출하는 동작, 상기 2차원 특징맵을 생성하는 동작, 상기 잔차 깊이맵(residual depth map)을 획득하는 동작, 및 상기 출력하는 동작을 설정된 반복 횟수에 따라 반복적으로 수행하는 동작을 더 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>10. 제2항에 있어서, 상기 개선된 깊이맵에 기초하여, 상기 다중 시점의 깊이맵들에 대응하는 2차원 객체를 3차원 객체로 재구성하는 동작을 더 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 개선된 깊이맵을 출력하는 동작은 상기 잔차 깊이맵을, 상기 다중 시점의 깊이맵들 중 상기 특정 시점의 깊이맵에 결합하는 동작; 및 상기 결합된 깊이맵들의 쉬프트(shift), 스케일(scale), 및 화질 중 적어도 하나를 조정함으로써 상기 개선된 깊이맵을 출력하는 동작을 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 개선된 깊이맵에 대하여, 상기 포인트 클라우드를 형성하는 동작, 상기 특징 임베딩 벡터들을 추출하는 동작, 상기 2차원 특징맵을 생성하는 동작, 상기 잔차 깊이맵을 획득하는 동작, 및 상기 출력하는 동작을 설정된 반복 횟수에 따라 반복적으로 수행하는 동작을 더 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 개선된 깊이맵에 기초하여, 상기 다중 시점의 깊이맵들에 대응하는 2차원 객체를 3차원 객체로 재구성하는 동작을 더 포함하는, 깊이맵을 개선하는 방법.</claim></claimInfo><claimInfo><claim>14. 하드웨어와 결합되어 제1항 내지 제13항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 다중 시점의 깊이맵들을 획득하는 센서;  상기 다중 시점의 깊이맵들을, 각 시점에 대응하는 카메라 파라미터를 이용하여 3차원 공간으로 역투사하여 상기 다중 시점의 깊이맵들에 대응하는 포인트 클라우드를 형성하고, 상기 포인트 클라우드의 포인트들에 대응하는 특징 임베딩 벡터들을 추출하고, 상기 포인트 클라우드의 포인트들 중 특정 시점에 해당하는 포인트들의 특징 임베딩 벡터들을 기초로, 상기 특정 시점의 2차원 특징맵을 생성하고, 상기 2차원 특징맵을, 깊이를 개선하는 네트워크에 인가함으로써 잔차 깊이맵을 획득하며, 상기 잔차 깊이맵을 상기 다중 시점의 깊이맵들 중 상기 특정 시점의 깊이맵에 결합하여 개선된 깊이맵을 생성하는 프로세서; 및 상기 개선된 깊이맵을 출력하는 통신 인터페이스를 포함하는, 깊이맵을 개선하는 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 통신 인터페이스는 동일한 객체를 서로 다른 시점으로 촬영한 복수의 프레임들을 포함하는 입력 영상을 수신하고, 상기 프로세서는 상기 입력 영상을, 단일 시점의 깊이맵을 추정하는 네트워크에 인가함으로써 상기 다중 시점의 깊이맵들을 추정하는,깊이맵을 개선하는 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 프로세서는 상기 단일 시점의 깊이맵을 추정하는 네트워크의 마지막 레이어의 특징맵으로부터, 상기 포인트 클라우드의 각 포인트의 위치에 해당하는 특징을 패칭하고, 상기 패칭한 특징을, 상기 포인트 클라우드에서 대응하는 위치의 각 포인트에 결합하여 상기 특징 임베딩 벡터들을 추출하는,깊이맵을 개선하는 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 프로세서는 상기 입력 영상 및 상기 2차원 특징맵을 상기 깊이를 개선하는 네트워크에 인가함으로써 상기 잔차 깊이맵을 획득하는,깊이맵을 개선하는 장치.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 프로세서는 상기 개선된 깊이맵에 대하여, 상기 포인트 클라우드를 형성하는 동작, 상기 특징 임베딩 벡터들을 추출하는 동작, 상기 2차원 특징맵을 생성하는 동작, 상기 잔차 깊이맵을 획득하는 동작, 및 상기 출력하는 동작을 설정된 반복 횟수에 따라 반복적으로 수행하는, 깊이맵을 개선하는 장치.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서, 상기 프로세서는 상기 개선된 깊이맵에 기초하여, 상기 다중 시점의 깊이맵들에 대응하는 2차원 객체를 3차원 객체로 재구성하는, 깊이맵을 개선하는 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 안양시 동안구...</address><code>420190614365</code><country>대한민국</country><engName>Jang, Seokhwan</engName><name>장석환</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420190573582</code><country>대한민국</country><engName>KIM, Seung Eon</engName><name>김승언</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170495152</code><country>대한민국</country><engName>SON, Minjung</engName><name>손민정</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.10.01</receiptDate><receiptNumber>1-1-2021-1133252-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.25</receiptDate><receiptNumber>1-1-2024-1046834-73</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210130985.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bc74857729d6cf942871b295bf226e99bfb74c1779ae16947e453cbfbe4526f6eab4f7cf81ced066419adb9f743584e9e863e87517a0eadf</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff01840c6cbc04cf0a77145fed4e841c6ca897c4303a61d7a790fa6dccc5f8973907c21555849c8b590e6e74375b58dea530162c4ed8d9fb2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>