<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:56.056</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7000877</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>가상 원격 원거리 신체 검사 시스템</inventionTitle><inventionTitleEng>VIRTUAL REMOTE TELE-PHYSICAL EXAMINATION SYSTEMS</inventionTitleEng><openDate>2025.03.04</openDate><openNumber>10-2025-0029124</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.01.09</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 40/67</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 80/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 20/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 사용자가 가상 환경 내에서 적어도 하나의 가상 객체에 관여하는 동안 사용자의 적어도 하나의 관절에 작용하는 힘을 추정하기 위한 방법, 시스템 및 장치가 설명되어 있다. 사용자의 적어도 하나의 관절의 관절 데이터와 연관된 모션 데이터가 센서로부터 수신될 수 있다. 관절 데이터는 힘 정보를 결정하는 데 사용될 수 있다. 힘 정보는 적어도 하나의 관절과 연관된 사용자 근력을 결정하는 데 사용될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.12.21</internationOpenDate><internationOpenNumber>WO2023244579</internationOpenNumber><internationalApplicationDate>2023.06.13</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/025158</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,디스플레이가 센서의 캘리브레이션(calibration)을 기초로, 가상 환경 내에서 사용자의 아바타를 출력하게 하는 단계;상기 센서로부터 사용자 움직임의 모션 데이터(motion data)를 수신하는 단계- 상기 모션 데이터는 상기 사용자의 적어도 하나의 관절과 연관된 관절 데이터를 포함함 -;상기 관절 데이터를 기초로 힘 정보를 결정하는 단계; 및상기 힘 정보를 기초로 상기 적어도 하나의 관절과 연관된 사용자 근력(strength)을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 디스플레이는 헤드 장착 디스플레이(HMD)인, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 디스플레이는 텔레비전, 모니터, 노트북 또는 태블릿 중 적어도 하나를 포함하는 디스플레이 디바이스인, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 센서는 카메라를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 카메라는 RGB-D 카메라를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 디스플레이는 상기 사용자가 상기 가상 환경 내부의 가상 객체와 상호작용하도록 관여하는 게임을 출력하도록 추가로 구성되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 가상 환경 내의 상기 가상 객체와의 상호작용은 사용자가 하나 이상의 움직임을 수행하게 하는 것을 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서, 상기 관절 데이터를 기초로 힘 정보를 결정하는 단계는,상기 사용자가 상기 가상 객체와 상호작용하는 동안 상기 관절 데이터를 기초로 상기 적어도 하나의 관절의 각도를 추적하는 단계; 및추적된 상기 각도에 기초하여 상기 힘 정보를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서, 상기 힘 정보는 게임 중에 상기 사용자가 상기 가상 객체와 상호작용하는 동안 상기 적어도 하나의 관절에 작용하는 힘에 대한 추정을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,제2 센서로부터 사용자 움직임의 제2 모션 데이터를 수신하는 단계- 상기 제2 모션 데이터는 제2 사용자의 적어도 하나의 관절과 연관된 제2 관절 데이터를 포함함 -;상기 제2 관절 데이터를 기초로 제2 힘 정보를 결정하는 단계- 상기 제2 힘 정보는 상기 제2 사용자가 상기 가상 환경 내에서 제2 가상 객체와 상호작용하는 동안 상기 제2 사용자의 상기 적어도 하나의 관절에 작용하는 힘의 추정을 포함함 -; 및상기 힘 정보와 상기 제2 힘 정보를 기초로, 상기 가상 객체가 상기 제2 가상 객체를 이기도록(overcome) 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,제2 센서로부터 사용자 움직임의 제2 모션 데이터를 수신하는 단계- 상기 제2 모션 데이터는 제2 사용자의 적어도 하나의 관절과 연관된 제2 관절 데이터를 포함함 -;상기 제2 관절 데이터를 기초로 제2 힘 정보를 결정하는 단계- 상기 제2 힘 정보는 상기 제2 사용자가 상기 가상 환경 내에서 제2 가상 객체와 상호작용하는 동안 상기 제2 사용자의 상기 적어도 하나의 관절에 작용하는 힘의 추정을 포함함 -; 및상기 힘 정보와 상기 제2 힘 정보를 기초로, 상기 제2 가상 객체가 상기 가상 객체를 이기도록 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제6항에 있어서, 상기 모션 데이터 및 상기 가상 환경 내의 가상 객체와 상호작용하는 상기 사용자와 연관된 데이터를 원격 액세스를 위해 통신 네트워크로 출력하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 힘 정보는 상기 가상 환경 내의 상기 가상 객체와 상호작용하는 상기 사용자와 연관된 데이터 및 상기 모션 데이터의 출력과의 힘 지각 연관 관계(force perception association)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 힘 정보를 포함하는 데이터를 서버로 발신하는 단계를 더 포함하고, 상기 서버는 상기 사용자와 연관된 데이터베이스에 상기 데이터를 저장하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 상기 센서의 캘리브레이션은 실시간 카메라-골격 자세 캘리브레이션을 수행하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 장치로서,하나 이상의 프로세서; 및프로세서 실행 가능 명령어를 저장하는 메모리를 포함하고, 상기 명령어는 상기 하나 이상의 프로세서에 의해 실행될 때 상기 장치로 하여금, 디스플레이가 센서의 캘리브레이션을 기초로 가상 환경 내에서 사용자의 아바타를 출력하게 하고; 상기 센서로부터 사용자 움직임의 모션 데이터를 수신하고- 상기 모션 데이터는 상기 사용자의 적어도 하나의 관절과 연관된 관절 데이터를 포함함 -; 상기 관절 데이터를 기초로 힘 정보를 결정하고; 상기 힘 정보를 기초로 상기 적어도 하나의 관절과 연관된 사용자 근력을 결정하게 하는, 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 디스플레이는 헤드 장착 디스플레이(HMD)인, 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 디스플레이는 텔레비전, 모니터, 노트북 또는 태블릿 중 적어도 하나를 포함하는 디스플레이 디바이스인, 장치.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 센서는 카메라를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 카메라는 RGB-D 카메라를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>21. 제16항에 있어서, 상기 디스플레이는 상기 사용자가 상기 가상 환경 내부의 가상 객체와 상호작용하도록 관여하는 게임을 출력하도록 추가로 구성되는, 장치.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 가상 환경 내의 상기 가상 객체와의 상호작용은 사용자가 하나 이상의 움직임을 수행하게 하는 것을 더 포함하는, 장치.</claim></claimInfo><claimInfo><claim>23. 제21항에 있어서, 상기 관절 데이터를 기초로 상기 힘 정보를 결정하는 것은상기 사용자가 상기 가상 객체와 상호작용하는 동안 상기 관절 데이터를 기초로 상기 적어도 하나의 관절의 각도를 추적하는 것; 및추적된 상기 각도에 기초하여 상기 힘 정보를 결정하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>24. 제21항에 있어서, 상기 힘 정보는 상기 게임 중에 상기 사용자가 상기 가상 객체에 관여하는 동안 상기 적어도 하나의 관절에 작용하는 힘의 추정을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 메모리는 프로세서 실행 가능 명령어를 저장하고, 상기 명령어는 상기 하나 이상의 프로세서에 의해 실행될 때, 장치로 하여금 추가로제2 센서로부터 사용자 움직임의 제2 모션 데이터를 수신하고- 상기 제2 모션 데이터는 제2 사용자의 적어도 하나의 관절과 연관된 제2 관절 데이터를 포함함 -;상기 제2 관절 데이터를 기초로 제2 힘 정보를 결정하고- 상기 제2 힘 정보는 상기 제2 사용자가 상기 가상 환경 내에서 제2 가상 객체와 상호작용하는 동안 상기 제2 사용자의 상기 적어도 하나의 관절에 작용하는 힘의 추정을 포함함 -; 및상기 힘 정보와 상기 제2 힘 정보를 기초로, 상기 가상 객체가 상기 제2 가상 객체를 이기게 하는, 장치.</claim></claimInfo><claimInfo><claim>26. 제24항에 있어서, 상기 메모리는 프로세서 실행 가능 명령어를 저장하고, 상기 명령어는 상기 하나 이상의 프로세서에 의해 실행될 때, 장치로 하여금 추가로제2 센서로부터 사용자 움직임의 제2 모션 데이터를 수신하고- 상기 제2 모션 데이터는 제2 사용자의 적어도 하나의 관절과 연관된 제2 관절 데이터를 포함함 -;상기 제2 관절 데이터를 기초로 제2 힘 정보를 결정하고- 상기 제2 힘 정보는 상기 제2 사용자가 상기 가상 환경 내에서 제2 가상 객체와 상호작용하는 동안 상기 제2 사용자의 상기 적어도 하나의 관절에 작용하는 힘의 추정을 포함함 -; 및상기 힘 정보와 상기 제2 힘 정보를 기초로, 상기 제2 가상 객체가 상기 가상 객체를 이기게 하는, 장치.</claim></claimInfo><claimInfo><claim>27. 제21항에 있어서, 상기 메모리는 프로세서 실행 가능 명령어를 저장하고, 상기 명령어는 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 장치로 하여금 추가로 상기 모션 데이터 및 상기 가상 환경 내의 가상 객체와 상호작용하는 상기 사용자와 연관된 데이터를 원격 액세스를 위해 통신 네트워크로 출력하게 하는, 장치.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 힘 정보는 상기 가상 환경 내의 상기 가상 객체와 상호작용하는 상기 사용자와 연관된 데이터 및 상기 모션 데이터의 출력과의 힘 지각 연관 관계를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>29. 제16항에 있어서, 상기 메모리는 프로세서 실행 가능 명령어를 저장하고, 상기 명령어는 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 장치로 하여금 추가로 상기 힘 정보를 포함하는 데이터를 서버로 발신하게 하고, 상기 서버는 상기 사용자와 연관된 데이터베이스에 상기 데이터를 저장하는, 장치.</claim></claimInfo><claimInfo><claim>30. 제16항에 있어서, 상기 센서의 캘리브레이션은 실시간 카메라-골격 자세 캘리브레이션을 수행하는 것을 포함하는, 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 워싱턴 디씨 ***** 노쓰웨스트 버몬트 애비뉴 ***</address><code>520070377372</code><country>미국</country><engName>THE UNITED STATES GOVERNMENT AS REPRESENTED BY THE DEPARTMENT OF VETERANS AFFAIRS</engName><name>더 유나이티드 스테이츠 거번먼트 애즈 리프리젠티드 바이 더 디파트먼트 오브 베테랑스 어페어즈</name></applicantInfo><applicantInfo><address>미국 ***** 텍사스주 오스틴 웨스트 *번 스트리트 ***</address><code>520070018758</code><country>미국</country><engName>BOARD OF REGENTS, THE UNIVERSITY OF TEXAS SYSTEM</engName><name>보드 오브 리전츠, 더 유니버시티 오브 텍사스 시스템</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 펜실베니아 ***** 허쉬 메디컬센...</address><code> </code><country>미국</country><engName>ANNASWAMY, Thiru</engName><name>안나스와미, 티루</name></inventorInfo><inventorInfo><address>미국 텍사스 *****...</address><code> </code><country>미국</country><engName>PRABHAKARAN, Balakrishnan</engName><name>프라바카란, 발라크리슈난 </name></inventorInfo><inventorInfo><address>미국 텍사스 *****...</address><code> </code><country>미국</country><engName>DESAI, Kevin</engName><name>데사이, 케빈 </name></inventorInfo><inventorInfo><address>미국 텍사스 *****...</address><code> </code><country>미국</country><engName>KHARGONKAR, Ninad, Arun</engName><name>카르곤카르, 니나드, 아룬 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로 ***, *층(논현동, 썬라이더빌딩)</address><code>920191000813</code><country>대한민국</country><engName>HONESTY &amp; PATENT IP Law Firm</engName><name>특허법인정특</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.06.13</priorityApplicationDate><priorityApplicationNumber>63/351,671</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.01.09</receiptDate><receiptNumber>1-1-2025-0034218-43</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.01.14</receiptDate><receiptNumber>1-1-2025-0048866-81</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2025.01.15</receiptDate><receiptNumber>1-5-2025-0010987-66</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.01.31</receiptDate><receiptNumber>1-1-2025-0109680-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.02.05</receiptDate><receiptNumber>1-5-2025-0020507-54</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257000877.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93665ac818b216ffc511fe65c49c10ef7dfb6b978ba845f6b5140296ff2b9b9dd9c39f51ce9bc52c756be81af37ddd6b29cf3a6ec5a702341b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf95fc9c1fad04230ff4a26615197aed281efef6dd853356b1d4f1dab68dde1a34fa04d7bc52a88e395078062f929d3bfeafcfbf843221ecb0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>