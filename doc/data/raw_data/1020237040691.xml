<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:46.146</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.08.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7040691</applicationNumber><claimCount>55</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>디코더</inventionTitle><inventionTitleEng>DECODER</inventionTitleEng><openDate>2024.01.29</openDate><openNumber>10-2024-0012407</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.07.22</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.11.24</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/094</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 오디오 신호를 디코딩 및/또는 생성하고, 오디오 디코더 및/또는 생성기를 훈련하기 위한 기술이 개시된다. 오디오 디코더(10)는 비트스트림(3)으로부터 오디오 신호(16)를 생성하도록 구성되고, 상기 비트스트림(3)은 상기 오디오 신호(16)를 나타내고, 상기 오디오 신호는 연속하는 프레임들로 세분화 된다. 상기 오디오 디코더(10)는 다음을 포함한다: 복수의 채널들을 가지는 제1 데이터(15)를 제공하기 위한 제1 데이터 제공기(702); 복수의 채널들(47)을 갖는 제1 출력 데이터(69)를 출력하기 위한 제1 처리 블록(40,50,50a-50h); 및 제2 처리 블록(45). 상기 제1 처리 블록(50)은 다음을 포함한다: 상기 비트스트림(3)을 수신하고, 상기 주어진 프레임에 대한 복수의 샘플들 및 복수의 채널들을 갖는 상기 주어진 프레임 내의 상기 오디오 신호(16)를 나타내는 타겟 데이터(12)를 출력하는 학습가능한 레이어(710); 상기 주어진 프레임에 대한 컨디셔닝 특징 파라미터들(74, 75)을 얻기 위하여 상기 주어진 프레임에 대해, 상기 타겟 데이터(12)를 처리하는 컨디셔닝 학습가능한 레이어(71, 72, 73); 및 상기 컨디셔닝 특징 파라미터들(74, 75)을 상기 제1 데이터(15, 59a)에 적용하는 스타일링 요소(77). 상기 제2 처리 블록(45)은 상기 제2 데이터(69)의 상기 복수의 채널들(47)을 결합하여 상기 오디오 신호(16)를 획득한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.11.03</internationOpenDate><internationOpenNumber>WO2022228704</internationOpenNumber><internationalApplicationDate>2021.08.06</internationalApplicationDate><internationalApplicationNumber>PCT/EP2021/072091</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비트스트림(3)으로부터 오디오 신호(16)를 생성하도록 구성된 오디오 디코더(10)로서, 상기 비트스트림(3)은 상기 오디오 신호(16)를 나타내고, 상기 오디오 신호는 연속하는 프레임들로 세분화 되는 상기 오디오 디코더(10)에 있어서,주어진 프레임에 대해, 외부 또는 내부 소스로부터의 입력 신호(14)로부터 또는 상기 비트스트림(3)으로부터 유도되는 제1 데이터(15)를 제공하도록 구성되고, 상기 제1 데이터(15)는 복수의 채널들을 가지는, 제1 데이터 제공기(702);상기 주어진 프레임에 대해, 상기 제1 데이터(15)를 수신하고, 상기 주어진 프레임 내에 제1 출력 데이터(69)를 출력하도록 구성되고, 상기 제1 출력 데이터(69)는 복수의 채널들(47)을 포함하는, 제1 처리 블록(40,50,50a-50h); 및상기 주어진 프레임에 대해, 제2 데이터로서 상기 제1 출력 데이터(69) 또는 상기 제1 출력 데이터(69)로부터 유도된 데이터를 수신하도록 구성되는 제2 처리 블록(45);을 포함하고,상기 제1 처리 블록(50)은, 상기 비트스트림(3)을 수신하고, 상기 주어진 프레임에 대한 복수의 샘플들 및 복수의 채널들을 갖는 상기 주어진 프레임 내의 상기 오디오 신호(16)를 나타내는 타겟 데이터(12)를 출력하도록 구성되는 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710); 상기 주어진 프레임에 대한 컨디셔닝 특징 파라미터들(74,75)을 얻기 위하여 상기 주어진 프레임에 대해, 상기 타겟 데이터(12)를 처리하도록 구성되는 적어도 하나의 컨디셔닝 학습가능한 레이어(71,72,73); 및 상기 컨디셔닝 특징 파라미터들(74,75)을 상기 제1 데이터(15,59a) 또는 정규화된 제1 데이터(59,76')에 적용하도록 구성되는 스타일링 요소(77);를 포함하고, 상기 제2 처리 블록(45)은 상기 제2 데이터(69)의 상기 복수의 채널들(47)을 결합하여 상기 오디오 신호(16)를 획득하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서,상기 제1 처리 블록(50)은 상기 주어진 프레임에 대한 샘플들의 제1 개수로부터, 상기 제1 개수의 샘플들보다 더 많은 상기 주어진 프레임에 대한 샘플들의 제2 개수로, 상기 제1 데이터(15)를 업-샘플링하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>3. 청구항 1 또는 2에 있어서,상기 제2 처리 블록(46)은 상기 주어진 프레임에 대한 샘플들의 제2 개수로부터, 상기 제2 개수의 샘플들보다 더 많은 상기 주어진 프레임에 대한 샘플들의 제3 개수로, 상기 제1 처리 블록(40)으로부터 얻어진 상기 제2 데이터(69)를 업-샘플링하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>4. 앞선 청구항들 중 어느 한 항에 있어서,제1 개수의 채널들로부터, 상기 제1 개수의 채널들보다 더 적은 상기 제1 출력 데이터(69)의 제2 개수의 채널들로, 상기 제1 데이터(15)의 채널들의 개수를 감소시키도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>5. 앞선 청구항들 중 어느 한 항에 있어서,상기 제2 처리 블록(45)은 채널들의 제2 개수로부터, 상기 채널들의 상기 제2 개수보다 적은 상기 오디오 신호(16)의 상기 채널들의 제3 개수로, 상기 제1 처리 블록(40)으로부터 얻어진 상기 제1 출력 데이터(69)의 채널들의 개수를 감소시키도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>6. 청구항 5에 있어서,상기 오디오 신호(16)는 모노 오디오 신호인, 오디오 디코더.</claim></claimInfo><claimInfo><claim>7. 앞선 청구항들 중 어느 한 항에 있어서,상기 비트스트림(3,3b)으로부터 상기 입력 신호(14)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>8. 앞선 청구항들 중 어느 한 항에 있어서,상기 주어진 프레임과 연관된 상기 비트스트림(3)의 적어도 하나의 파라미터(3b)로부터 상기 입력 신호(14)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>9. 앞선 청구항들 중 어느 한 항에 있어서,상기 주어진 프레임 내의 상기 오디오 신호(16)의 피치 래그 또는 다른 피치 데이터를 나타내는 적어도 하나의 파라미터(3b)로부터 상기 입력 신호(14)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>10. 청구항 9에 있어서,상기 피치 래그를 상기 피치 상관(correlation)과 곱하여 상기 입력 신호(14)를 얻도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>11. 청구항 1 내지 6 중 어느 한 항에 있어서,잡음(14)으로부터 상기 입력 신호를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>12. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 스펙트로그램으로서 상기 타겟 데이터(12)를 제공하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>13. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 멜-스펙트로그램으로서 상기 타겟 데이터(12)를 제공하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>14. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림(3) 안에 인코딩된 켑스트럼(cepstrum) 데이터로부터 상기 상기 타겟 데이터(12)를 유도하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>15. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 주어진 프레임과 연관된 상기 비트스트림(3) 안에 인코딩된 적어도 필터 데이터(3a)로부터 상기 상기 타겟 데이터(12)를 유도하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>16. 청구항 15에 있어서,상기 필터 데이터(3a)는 상기 주어진 프레임에 연관된 상기 비트스트림(3) 안에 인코딩된 스펙트럼 포락선 데이터를 포함하는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>17. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림 안에 인코딩된 롱-텀(long-term) 예측 데이터, 주기성(periodicity) 데이터, 조화성(harmonicity) 데이터, 여기(excitation) 데이터 중 적어도 하나로부터 상기 타겟 데이터(12)를 유도하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>18. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림(3) 내에 인코딩된 적어도 피치 데이터(3b)로부터 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>19. 청구항 18에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 피치 래그와 상기 피치 상관을 적어도 곱셈하여 상기 타겟 데이터(12,813)를 유도하도록 구성되는 오디오 디코더. </claim></claimInfo><claimInfo><claim>20. 청구항 19에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 피치 래그와 상기 피치 상관의 곱과 스펙트럼 포락선 데이터를 적어도 컨벌루션하여 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더. </claim></claimInfo><claimInfo><claim>21. 청구항 1 내지 18 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 피치 래그, 상기 피치 상관, 및 스펙트럼 포락선 데이터를 적어도 컨벌루션하여 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더. </claim></claimInfo><claimInfo><claim>22. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림(3)으로부처 얻어진 켑스트럼-기반 계수들, 스펙트로그램-기반 계수들, 및/또는 LPC 계수들(3a,3b)로부터 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더. </claim></claimInfo><claimInfo><claim>23. 앞선 청구항들 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 컨벌루션 맵이고, 상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 컨벌루션 맵 상에서 컨벌루션을 수행하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>24. 청구항 23에 있어서,상기 타겟 데이터(12)는 상기 주어진 프레임 내의 상기 오디오 신호(16)의 켑스트럼 데이터(3a)를 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>25. 앞선 청구항들 중 어느 한 항에 있어서,상기 입력 신호는 상기 주어진 프레임 내의 상기 오디오 신호(16)의 적어도 상관 데이터(correlation data)로부터 획득되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>26. 앞선 청구항들 중 어느 한 항에 있어서,상기 타겟 데이터는 상기 주어진 프레임 내의 상기 오디오 신호(16)의 피치 데이터로부터 획득되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>27. 앞선 청구항들 중 어느 한 항에 있어서,상기 타겟 데이터는 상기 주어진 프레임 내의 상기 오디오 신호(16)의 피치 데이터와 상기 주어진 프레임 내의 상기 오디오 신호의 상관 데이터의 곱셈으로 획득되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>28. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림 또는 이의 처리된 버전으로부터 획득된 적어도 하나의 켑스트럼 데이터를 병치함(juxtaposing)으로써 얻어지는 비트스트림 모델 상에 적어도 하나의 컨벌루션을 수행하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>29. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림으로부터 획득된 적어도 하나의 파라미터를 병치함(juxtaposing)으로써 얻어지는 비트스트림 모델 상에 적어도 하나의 컨벌루션을 수행하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>30. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림(3) 또는 이의 처리된 버전으로부터 획득된 컨벌루션 맵(712, 716, 720, 724, 816, 820, 824, 813, 856) 상에 적어도 하나의 컨벌루션을 수행하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>31. 청구항 30에 있어서,상기 컨벌루션 맵은 다음(subsequent) 프레임들과 연관된 파라미터들을 병치함으로써 얻어지는 오디오 디코더.</claim></claimInfo><claimInfo><claim>32. 청구항 28 내지 31 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)에 의해 수행되는 상기 컨벌루션(들) 중 적어도 하나는 프리컨디셔닝 활성화 함수에 의해 활성화되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>33. 청구항 32에 있어서,상기 프리컨디셔닝 활성화 함수는 ReLu(rectified linear unit) 함수인 오디오 디코더.</claim></claimInfo><claimInfo><claim>34. 청구항 32 또는 33에 있어서,상기 프리컨디셔닝 활성화 함수는 리키(leaky) ReLu(rectified linear unit) 함수인 오디오 디코더.</claim></claimInfo><claimInfo><claim>35. 청구항 28 내지 31 중 어느 한 항에 있어서,상기 적어도 하나의 컨벌루션은 비-조건부(non-conditional) 컨벌루션인 오디오 디코더.</claim></claimInfo><claimInfo><claim>36. 청구항 28 내지 31 중 어느 한 항에 있어서,상기 적어도 하나의 컨벌루션은 뉴럴 네트워크의 일부인 오디오 디코더.</claim></claimInfo><claimInfo><claim>37. 앞선 청구항들 중 어느 한 항에 있어서,상기 제1 처리 블록 및/또는 상기 제2 처리 블록이 이전 프레임을 처리하는 동안 상기 제1 처리 블록 및/또는 상기 제2 처리 블록에 의해 다음으로 처리될 프레임들을 저장하는 큐(queue)를 더 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>38. 앞선 청구항들 중 어느 한 항에 있어서,상기 제1 데이터 제공기는 상기 비트스트림의 바로 이전의 프레임에 인접하는 상기 비트스트림의 상기 주어진 프레임으로부터 얻어지는 코딩된 파라미터들의 한 세트를 병치함(juxtaposing)으로써 획득되는 비트스트림 모델에 컨벌루션을 수행하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>39. 앞선 청구항들 중 어느 한 항에 있어서,상기 학습가능한 레이어들의 컨디셔닝 세트는 하나 또는 적어도 2개의 컨벌루션 레이어들(71-73)을 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>40. 앞선 청구항들 중 어느 한 항에 있어서,제1 컨벌루션 레이어(71-73)는 제1 활성화 함수를 이용해 상기 타겟 데이터(12) 또는 업-샘플링된 타겟 데이터를 컨벌루션하여 제1 컨벌루션된 데이터(71')를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>41. 앞선 청구항들 중 어느 한 항에 있어서,상기 학습가능한 레이어들의 컨디셔닝 세트 및 상기 스타일링 요소(77)는 하나 이상의 잔여 블록들(50, 50a-50h)을 포함하는 뉴럴 네트워크의 잔여 블록(50, 50a-50h) 내의 가중치 블록의 일부인 오디오 디코더.</claim></claimInfo><claimInfo><claim>42. 앞선 청구항들 중 어느 한 항에 있어서,상기 제1 데이터(59a, 15)를 정규화하도록 구성되는 정규화 요소(76)를 더 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>43. 앞선 청구항들 중 어느 한 항에 있어서,상기 채널 차원에서 상기 제1 데이터(59a, 15)를 정규화하도록 구성되는 정규화 요소(76)를 더 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>44. 앞선 청구항들 중 어느 한 항에 있어서,상기 오디오 신호(16)는 음성 오디오 신호인 오디오 디코더.</claim></claimInfo><claimInfo><claim>45. 앞선 청구항들 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 2의 거듭제곱의 배만큼 업-샘플링되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>46. 청구항 45에 있어서,상기 타겟 데이터(12)는 비선형 보간(interpolation)에 의해 업-샘플링(70)되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>47. 앞선 청구항들 중 어느 한 항에 있어서,상기 제1 처리 블록(40, 50, 50a-50k)는 제2 활성화 함수(63b, 64b)를 이용하여 상기 제1 데이터(15, 59, 59a, 59b)로부터 유도되는 데이터를 처리하도록 구성되는 학습가능한 레이어들(62a, 62b)의 다른 세트를 더 포함하고,상기 제2 활성화 함수(63b, 64b)는 게이티드 활성화 함수(gated activation function )인, 오디오 디코더. </claim></claimInfo><claimInfo><claim>48. 청구항 47에 있어서,상기 학습가능한 레이어들(62a, 62b)의 다른 세트는 하나 또는 2 이상의 컨벌루션 레이어를 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>49. 앞선 청구항들 중 어느 한 항에 있어서,상기 제2 활성화 함수(63a, 63b)는 소프트맥스-게이티드(softmax-gated) 하이퍼볼릭 탄젠트(TanH) 함수인 오디오 디코더.</claim></claimInfo><claimInfo><claim>50. 청구항 40 또는 청구항 40을 인용할 때의 청구항 41 내지 49 중 어느 한 항에 있어서,상기 제1 활성화 함수는 리키 ReLu(leaky rectified linear unit) 함수인 오디오 디코더.</claim></claimInfo><claimInfo><claim>51. 앞선 청구항들 중 어느 한 항에 있어서,컨벌루션 연산들(61b, 62b)은 2의 최대 확대 인자(dilation factor)로 수행되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>52. 앞선 청구항들 중 어느 한 항에 있어서,8개의 제1 처리 블록들(50a-50h) 및 하나의 제2 처리 블록(45)을 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>53. 앞선 청구항들 중 어느 한 항에 있어서,상기 제1 데이터(15, 59, 59a, 59b)는 상기 오디오 신호(16)보다 낮은 차원(dimension)을 갖는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>54. 앞선 청구항들 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 스펙트로그램인 오디오 디코더.</claim></claimInfo><claimInfo><claim>55. 앞선 청구항들 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 멜-스펙트로그램인 오디오 디코더.</claim></claimInfo><claimInfo><claim>56. 오디오 신호(16)를 나타내는 비트스트림(3)으로부터 상기 오디오 신호(1, 16)를 디코딩하는 방법으로서, 상기 오디오 신호(1, 16)는 복수의 프레임들로 세분화 되는 상기 방법에 있어서,상기 비트스트림(3)으로부터, 제1 처리 블록(40)의 적어도 하나의 프리컨디셔닝 레이어(710)에 의해 주어진 프레임에 대한 타겟 데이터(15)를 획득하는 단계로서, 상기 타겟 데이터(15)는 상기 오디오 신호(16)를 나타내고 2 차원을 갖는, 단계; 상기 제1 처리 블록(40, 50, 50a-50h)에 의해 및 상기 주어진 프레임의 각각의 샘플에 대하여, 상기 입력 신호(15)로부터 유도되는 제1 데이터(12)를 수신하는 단계;상기 제1 처리 블록(40, 50)의 학습가능한 레이어들(71, 72, 73)의 컨디셔닝 세트에 의해 컨디셔닝 특징 파라미터들(74, 75)을 획득하기 위하여 상기 타겟 데이터(12)를 처리하는 단계;상기 제1 처리 블록(50)의 스타일링 요소(77)에 의해 상기 컨디셔닝 특징 파라미터들(74, 75)을 상기 제1 데이터(15, 59) 또는 정규화된 제1 데이터(76')에 적용하는 단계;상기 제1 처리 블록(40, 50)에 의해 복수의 채널들(47)을 포함하는 제1 출력 데이터(69)를 출력하는 단계;제2 처리 블록(45)에 의해 제2 데이터로서 상기 제1 출력 데이터(69) 또는 상기 제1 출력 데이터(69)로부터 유도된 데이터를 수신하는 단계; 및상기 제2 처리 블록(45)에 의해 상기 오디오 신호(16)를 얻기 위하여 상기 제2 데이터의 상기 복수의 채널들(47)을 결합하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>57. 청구항 56에 있어서,상기 제1 처리 블록(40) 및/또는 상기 제2 처리 블록(45)이 이전 프레임을 처리하는 동안 상기 제1 처리 블록(40) 및/또는 상기 제2 처리 블록(45)에 의해 다음으로 처리될 프레임들을 저장하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>58. 청구항 56 또는 57에 있어서,상기 비트스트림의 바로 이전의 프레임에 인접하는 상기 비트스트림의 상기 주어진 프레임으로부터 얻어지는 코딩된 파라미터들의 한 세트를 병치함으로써 획득되는 비트스트림 모델에 컨벌루션을 수행하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>59. 청구항 56 내지 58 중 어느 한 항에 있어서,상기 학습가능한 레이어들(71-73)의 상기 컨디셔닝 세트는 하나 또는 두 개의 컨벌루션 레이어를 포함하는 방법.</claim></claimInfo><claimInfo><claim>60. 청구항 56 내지 59 중 어느 한 항에 있어서,상기 처리하는 단계는 상기 학습가능한 레이어들(71-73)의 컨디셔닝 세트에 의해, 제1 활성화 함수를 이용하여 제1 컨벌루션된 데이터(71')를 획득하기 위하여 제1 컨벌루션 레이어(71)에 의해 상기 타겟 데이터(12) 또는 업-샘플링 타겟 데이터를 컨벌루션하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>61. 청구항 56 내지 60 중 어느 한 항에 있어서,상기 학습가능한 레이어들(71-73)의 컨디셔닝 세트 및 상기 스타일링 요소(77)는 하나 이상의 잔여 블록들(50, 50a-50h)을 포함하는 뉴럴 네트워크의 잔여 블록(50, 50a-50h) 내의 가중치 블록의 일부인 방법.</claim></claimInfo><claimInfo><claim>62. 청구항 56 내지 61 중 어느 한 항에 있어서,정규화 요소(76)에 의해 상기 제1 데이터(15, 59)를 정규화하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>63. 청구항 56 내지 62 중 어느 한 항에 있어서,상기 오디오 신호(16)는 음성 오디오 신호인 방법.</claim></claimInfo><claimInfo><claim>64. 청구항 56 내지 63 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 2 배 또는 2의 거듭제곱의 배만큼 업-샘플링(70)되는 방법.</claim></claimInfo><claimInfo><claim>65. 청구항 56 내지 64 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 비선형 보간에 의해 업-샘플링(70)되는 방법.</claim></claimInfo><claimInfo><claim>66. 청구항 56 내지 65 중 어느 한 항에 있어서,상기 제1 활성화 함수는 리키 ReLu(leaky rectified linear unit) 함수인 방법.</claim></claimInfo><claimInfo><claim>67. 청구항 56 내지 66 중 어느 한 항에 있어서,컨벌루션 연산들(61b, 62b)은 2의 최대 확대 인자(dilation factor)로 수행되는 방법.</claim></claimInfo><claimInfo><claim>68. 청구항 56 내지 67 중 어느 한 항에 있어서,상기 제1 처리 블록(50, 50a-50h)의 상기 단계들을 8번 수행하고 및 상기 제2 처리 블록(45)의 상기 단계들을 1회 수행하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>69. 청구항 56 내지 68 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 스펙트로그램인 방법.</claim></claimInfo><claimInfo><claim>70. 청구항 69 에 있어서,상기 스펙트로그램은 멜-스펙트로그램인 방법.</claim></claimInfo><claimInfo><claim>71. 청구항 1 내지 55 중 어느 한 항에 따른 오디오 디코더(10)를 훈련(100)시키는 방법에 있어서,청구항 56 내지 70 중 어느 한 항의 상기 단계들을 1회 이상 반복하는 단계를 포함하는 훈련(100) 방법.</claim></claimInfo><claimInfo><claim>72. 청구항 71에 있어서,적어도 하나의 평가기(132)에 의해 상기 생성된 오디오 신호(14, 16)를 평가(130)하는 단계; 및상기 평가(130)의 결과들에 따라 상기 오디오 디코더(10)의 상기 가중치들(74, 75)을 적응시키는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>73. 청구항 72에 있어서,상기 적어도 하나의 평가기(132)는 뉴럴 네트워크인 방법.</claim></claimInfo><claimInfo><claim>74. 청구항 72 또는 73에 있어서,상기 평가의 결과들에 따라 상기 평가기의 상기 가중치들을 적응시키는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>75. 청구항 71 내지 74 중 어느 한 항에 있어서,상기 훈련(130)은 손실 함수(140)의 최적화를 포함하는 방법.</claim></claimInfo><claimInfo><claim>76. 청구항 75에 있어서,상기 손실 함수를 최적화(130)하는 것은 상기 생성된 오디오 신호(16) 및 참조 오디오 신호(104) 사이의 고정된 메트릭(metric)을 산출하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>77. 청구항 76에 있어서,상기 고정된 메트릭을 산출하는 것은 상기 생성된 오디오 신호(16) 및 상기 참조 오디오 신호(104) 사이의 하나 또는 수 개의 스펙트럼 왜곡들을 산출하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>78. 청구항 77에 있어서,상기 하나 또는 수개의 스펙트럼 왜곡들을 산출하는 것은 상기 생성된 오디오 신호(16) 및 상기 참조 오디오 신호(104)의 상기 스펙트럼 표현의 크기 또는 로그-크기에 대해 수행되는 방법.</claim></claimInfo><claimInfo><claim>79. 청구항 77또는 78에 있어서,상기 하나 또는 수개의 스펙트럼 왜곡들을 산출하는 것은 상기 생성된 오디오 신호(16) 및 상기 참조 오디오 신호(104)의 서로 다른 시간 또는 주파수 해상도들(resolutions)에 대해서 수행되는 방법.</claim></claimInfo><claimInfo><claim>80. 청구항 76 내지 79 중 어느 한 항에 있어서,상기 손실 함수(140)를 최적화하는 것은 상기 생성된 오디오 신호(16)의 표현 또는 상기 참조 오디오 신호(103)의 표현을 랜덤하게 제공하고 하나 이상의 평가기(132)에 의해 평가하여 하나 이상의 적대적 메트릭(adversarial metric)을 유도하는 것을 포함하고, 상기 평가하는 것은 상기 제공된 오디오 신호(16, 132)를, 상기 오디오 신호(14, 16)의 자연스러움(naturalness)의 사전훈련된 분류 레벨을 나타내는 미리 결정된 개수의 클래스로 분류하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>81. 청구항 75 내지 80 중 어느 한 항에 있어서,상기 손실 함수를 최적화하는 것은 고정된 메트릭을 산출하고, 하나 이상의 평가기(132)에 의해 적대적 메트릭(adversarial metric)을 유도하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>82. 청구항 81에 있어서,상기 오디오 디코더(10)는 상기 고정된 메트릭을 이용하여 첫번째 훈련되는 방법.</claim></claimInfo><claimInfo><claim>83. 청구항 80 내지 82에 있어서,4개의 평가기들(132a-132d)이 4개의 적대적 메트릭을 유도하는 방법.</claim></claimInfo><claimInfo><claim>84. 청구항 80 내지 83 중 어느 한 항에 있어서,상기 평가기들(132)은 필터-뱅크(110)에 의한 상기 생성된 오디오 신호(16)의 상기 표현 또는 상기 참조 오디오 신호(104)의 상기 표현의 분해(110) 이후 동작하는 방법.</claim></claimInfo><claimInfo><claim>85. 청구항 80 내지 84 중 어느 한 항에 있어서,상기 평가기들(132a-132d) 각각은 입력으로서, 상기 생성된 오디오 신호(16)의 상기 표현 또는 상기 참조 오디오 신호(104)의 상기 표현 중 하나 또는 수 개의 부분들(105a-105d)을 수신하는 방법. </claim></claimInfo><claimInfo><claim>86. 청구항 85에 있어서, 상기 신호 부분들은 랜덤 윈도우 함수들을 이용하여, 상기 입력 신호(14)로부터 랜덤 윈도우들(105a-105d)을 샘플링함으로써 생성되는, 방법.</claim></claimInfo><claimInfo><claim>87. 청구항 86에 있어서,상기 랜덤 윈도우(105a-105d)의 샘플링은 각각의 평가기(132a-132d)에 대해 복수회 반복되는, 방법.</claim></claimInfo><claimInfo><claim>88. 청구항 87에 있어서,상기 랜덤 윈도우(105a-105d)가 각각의 평가기(132a-132d)에 대해 샘플링되는 횟수는 상기 생성된 오디오 신호의 상기 표현 또는 상기 참조 오디오 신호(104)의 상기 표현의 길이에 비례하는, 방법.</claim></claimInfo><claimInfo><claim>89. 청구항 56 내지 88 중 어느 한 항에 있어서,적어도 하나의 프리컨디셔닝 레이어(710)는 학습될 수 있는, 방법.</claim></claimInfo><claimInfo><claim>90. 청구항 56 내지 89 중 어느 한 항에 있어서,적어도 하나의 프리컨디셔닝 레이어(710)는 결정형(deterministic)인, 방법.</claim></claimInfo><claimInfo><claim>91. 청구항 56 내지 90 중 어느 한 항에 있어서,상기 비트스트림은 텍스트로부터 유도되는, 방법.</claim></claimInfo><claimInfo><claim>92. 컴퓨터에 의해 실행될 때, 상기 컴퓨터가 청구항 56 내지 89 중 어느 한 항에 따른 방법을 수행하도록 하는 명령어들을 저장하는 비-일시적 스토리지 유닛</claim></claimInfo><claimInfo><claim>93. 비트스트림(3)으로부터 오디오 신호(16)를 생성하도록 구성된 오디오 디코더(10)로서, 상기 비트스트림(3)은 텍스트로부터 유도되는 상기 오디오 신호(16)를 나타내고, 상기 오디오 신호는 연속하는 프레임들로 세분화 되는 상기 오디오 디코더(10)에 있어서,주어지 프레임에 대해, 외부 또는 내부 소스로부터의 입력 신호(14)로부터 또는 상기 비트스트림(3)으로부터 유도되는 제1 데이터(15)를 제공하도록 구성되고, 상기 제1 데이터(15)는 복수의 채널들을 가지는, 제1 데이터 제공기(702);상기 주어진 프레임에 대해, 상기 제1 데이터(15)를 수신하고, 상기 주어진 프레임 내에 제1 출력 데이터(69)를 출력하도록 구성되고, 상기 제1 출력 데이터(69)는 복수의 채널들(47)을 포함하는, 제1 처리 블록(40, 50, 50a-50h); 및상기 주어진 프레임에 대해, 제2 데이터로서 상기 제1 출력 데이터(69) 또는 상기 제1 출력 데이터(69)로부터 유도된 데이터를 수신하도록 구성되는 제2 처리 블록(45);을 포함하고,상기 제1 처리 블록(50)은, 상기 비트스트림(3)을 수신하고, 상기 주어진 프레임에 대한 복수의 샘플들 및 복수의 채널들을 갖는 상기 주어진 프레임 내의 상기 오디오 신호(16)를 나타내는 타겟 데이터(12)를 출력하도록 구성되는 적어도 하나의 프리컨디셔닝 레이어(710); 상기 주어진 프레임에 대한 컨디셔닝 특징 파라미터들(74, 75)을 얻기 위하여 상기 주어진 프레임에 대해, 상기 타겟 데이터(12)를 처리하도록 구성되는 적어도 하나의 컨디셔닝 학습가능한 레이어(71, 72, 73); 및 상기 컨디셔닝 특징 파라미터들(74, 75)을 상기 제1 데이터(15, 59a) 또는 정규화된 제1 데이터(59, 76')에 적용하도록 구성되는 스타일링 요소(77);를 포함하고,상기 제2 처리 블록(45)은 상기 제2 데이터(69)의 상기 복수의 채널들(47)을 결합하여 상기 오디오 신호(16)를 획득하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>94. 청구항 56 내지 89 중 어느 한 항에 있어서,적어도 하나의 프리컨디셔닝 레이어(710c)는 결정형(deterministic)인, 오디오 디코더.</claim></claimInfo><claimInfo><claim>95. 청구항 93에 있어서,적어도 하나의 프리컨디셔닝 레이어(710c)는 학습될 수 있는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>96. 청구항 93 내지 95 중 어느 한 항에 있어서,적어도 하나의 프리컨디셔닝 레이어(710)는 학습될 수 있고 및 적어도 하나의 프리컨디셔닝 레이어는 결정형인, 오디오 디코더.</claim></claimInfo><claimInfo><claim>97. 청구항 93 내지 96 중 어느 한 항에 있어서,상기 제1 처리 블록(50)은 상기 주어진 프레임에 대한 샘플들의 제1 개수로부터, 상기 제1 개수의 샘플들보다 더 많은 상기 주어진 프레임에 대한 샘플들의 제2 개수로, 상기 제1 데이터(15)를 업-샘플링하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>98. 청구항 93 내지 97 중 어느 한 항에 있어서,상기 제2 처리 블록(46)은 상기 주어진 프레임에 대한 샘플들의 제2 개수로부터, 상기 제2 개수의 샘플들보다 더 많은 상기 주어진 프레임에 대한 샘플들의 제3 개수로, 상기 제1 처리 블록(40)으로부터 얻어진 상기 제2 데이터(69)를 업-샘플링하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>99. 앞선 청구항들 중 어느 한 항에 있어서,제1 개수의 채널들로부터, 상기 제1 개수의 채널들보다 더 적은 상기 제1 출력 데이터(69)의 제2 개수의 채널들로, 상기 제1 데이터(15)의 채널들의 개수를 감소시키도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>100. 청구항 93 내지 99 중 어느 한 항에 있어서,상기 제2 처리 블록(45)은 채널들의 제2 개수로부터, 상기 채널들의 상기 제2 개수보다 적은 상기 오디오 신호(16)의 상기 채널들의 제3 개수로, 상기 제1 처리 블록(40)으로부터 얻어진 상기 제1 출력 데이터(69)의 채널들의 개수를 감소시키도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>101. 청구항 92 내지 100 중 어느 한 항에 있어서,상기 타겟 데이터(102)는 적어도 하나의 잠재적 특징(latent feature)을 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>102. 청구항 93 내지 101 중 어느 한 항에 있어서,상기 비트스트림(3,3b)으로부터 상기 입력 신호(14)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>103. 청구항 93 내지 102 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 적어도 하나의 음향 특징을 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>104. 청구항 103에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트로부터의 상기 비트스트림을 상기 적어도 하나의 음향 특징으로 변환함(1110)으로써 상기 타겟 데이터(12)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>105. 청구항 104에 있어서,상기 적어도 하나의 음향 특징은 로그-스펙트로그램, MFCC 및 멜-스펙트로그램 중 하나인 오디오 디코더.</claim></claimInfo><claimInfo><claim>106. 청구항 103 내지 105 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 적어도 하나의 언어 특징 형태의 상기 비트스트림을 적어도 하나의 음향 특징 형태의 상기 타겟 데이터(12)로 변환함(1114)으로써 상기 타겟 데이터(12)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>107. 청구항 93 내지 106 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 적어도 하나의 언어학 특징을 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>108. 청구항 107에 있어서,적어도 하나의 언어학 특징은 텍스트로부터 얻어지는 음소, 단어 운율, 성조, 구문 중단들 및 채워진 휴지들(pauses) 중 하나인 오디오 디코더.</claim></claimInfo><claimInfo><claim>109. 청구항 107 또는 108에 있어서,상기 프리컨디셔닝 레이어는 텍스트 형태 또는 텍스트의 요소들 형태의 상기 비트스트림을 적어도 하나의 언어 특징 형태의 상기 타겟 데이터(12)로 변환함(1110)으로써 상기 타겟 데이터(12)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>110. 청구항 93 내지 109 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 텍스트로부터 얻어진 단어 및 문자 사이의 적어도 하나를 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>111. 청구항 93 내지 110 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트 분석을 수행하도록 구성된 적어도 하나의 통계 모델을 이용하여 및/또는 음향 모델을 이용하여, 상기 텍스트 형태의 상기 비트스트림으로부터 상기 타겟 데이터(12)로 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더.  </claim></claimInfo><claimInfo><claim>112. 청구항 93 내지 111 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트 분석을 수행하는 학습가능한 모델을 이용하여 및/또는 음향 모델을 이용하여, 상기 텍스트 형태의 상기 비트스트림(3)으로부터 상기 타겟 데이터(12)로 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더.  </claim></claimInfo><claimInfo><claim>113. 청구항 93 내지 112 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트 분석을 수행하는 규칙-기반의 알고리즘을 이용하여 및/또는 음향 모델을 이용하여, 상기 텍스트 형태의 상기 비트스트림으로부터 상기 타겟 데이터(12)로 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더.  </claim></claimInfo><claimInfo><claim>114. 청구항 93 내지 113 중 어느 한 항에 있어서,상기 비트스트림(3)으로부터 유도된 시간-영역 구조 또는 적어도 하나의 시간 포락선 정보로부터 상기 입력 신호(14)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>115. 앞선 청구항들 중 어느 한 항에 있어서,잡음(14)으로부터 상기 입력 신호를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>116. 앞선 청구항들 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 레이어(710)는 스펙트로그램으로서 상기 타겟 데이터(12)를 제공하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>117. 청구항 93 내지 116 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 레이어(710)는 멜-스펙트로그램으로서 상기 타겟 데이터(12)를 제공하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>118. 청구항 93 내지 117 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 레이어(710)는 상기 비트스트림(3)에 인코딩된 켑스트럼 데이터로부터 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>119. 청구항 93 내지 118 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 레이어(710)는 스펙트럼 포락선 데이터를 적어도 컨벌루션함으로써 상기 타겟 데이터(12)를 유도하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>120. 청구항 93 내지 119 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 컨벌루션 맵이고, 및 상기 적어도 하나의 프리컨디셔닝 레이어(710)는 상기 컨벌루션 맵에 컨벌루션을 수행하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>121. 청구항 120에 있어서,상기 타겟 데이터(12)는 상기 주어진 프레임 내의 상기 오디오 신호(16)의 켑스트럼 데이터(3a)를 포함하는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>122. 앞선 청구항들 중 어느 한 항에 있어서,상기 입력 신호는 상기 주어진 프레임 내의 상기 오디오 신호(16)의 적어도 상관 데이터(correlation data)로부터 획득되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>123. 청구항 93 내지 122 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림으로부터 획득된 적어도 하나의 파라미터를 병치함(juxtaposing)으로써 얻어지는 비트스트림 모델 상에 적어도 하나의 컨벌루션을 수행하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>124. 청구항 93 내지 123 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)는 상기 비트스트림(3) 또는 이의 처리된 버전으로부터 획득된 컨벌루션 맵(712, 716, 720, 724, 816, 820, 824, 813, 856) 상에 적어도 하나의 컨벌루션을 수행하도록 구성되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>125. 청구항 124에 있어서,상기 컨벌루션 맵은 다음(subsequent) 프레임들과 연관된 파라미터들을 병치함으로써 얻어지는 오디오 디코더.</claim></claimInfo><claimInfo><claim>126. 청구항 122 내지 125 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 학습가능한 레이어(710)에 의해 수행되는 상기 컨벌루션(들) 중 적어도 하나는 프리컨디셔닝 활성화 함수에 의해 활성화되는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>127. 청구항 126에 있어서,상기 프리컨디셔닝 활성화 함수는 ReLu(rectified linear unit) 함수인 오디오 디코더.</claim></claimInfo><claimInfo><claim>128. 청구항 126 또는 127에 있어서,상기 프리컨디셔닝 활성화 함수는 리키(leaky) ReLu 함수인 오디오 디코더.</claim></claimInfo><claimInfo><claim>129. 청구항 122 내지 125 중 어느 한 항에 있어서,상기 적어도 하나의 컨벌루션은 비-조건부(non-conditional) 컨벌루션인 오디오 디코더.</claim></claimInfo><claimInfo><claim>130. 청구항 122 내지 125 중 어느 한 항에 있어서,상기 적어도 하나의 컨벌루션은 뉴럴 네트워크의 일부인 오디오 디코더.</claim></claimInfo><claimInfo><claim>131. 청구항 93 내지 130 중 어느 한 항에 있어서,상기 제1 처리 블록 및/또는 상기 제2 처리 블록이 이전 프레임을 처리하는 동안 상기 제1 처리 블록 및/또는 상기 제2 처리 블록에 의해 다음으로 처리될 프레임들을 저장하는 큐(queue)를 더 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>132. 청구항 93 내지 131 중 어느 한 항에 있어서,상기 제1 데이터 제공기는 상기 비트스트림의 바로 이전의 프레임에 인접하는 상기 비트스트림의 상기 주어진 프레임으로부터 얻어지는 코딩된 파라미터들의 한 세트를 병치함(juxtaposing)으로써 획득되는 비트스트림 모델에 컨벌루션을 수행하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>133. 청구항 93 내지 132 중 어느 한 항에 있어서,상기 학습가능한 레이어들의 컨디셔닝 세트는 하나 또는 적어도 2개의 컨벌루션 레이어들(71-73)을 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>134. 청구항 93 내지 133 중 어느 한 항에 있어서,제1 컨벌루션 레이어(71-73)는 제1 활성화 함수를 이용해 상기 타겟 데이터(12) 또는 업-샘플링된 타겟 데이터를 컨벌루션하여 제1 컨벌루션된 데이터(71')를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>135. 청구항 93 내지 134 중 어느 한 항에 있어서,상기 학습가능한 레이어들(71-73)의 컨디셔닝 세트 및 상기 스타일링 요소(77)는 하나 이상의 잔여 블록들(50, 50a-50h)을 포함하는 뉴럴 네트워크의 잔여 블록(50, 50a-50h) 내의 가중치 블록의 일부인 오디오 디코더.</claim></claimInfo><claimInfo><claim>136. 청구항 93 내지 135 중 어느 한 항에 있어서,상기 제1 데이터(59a, 15)를 정규화하도록 구성되는 정규화 요소(76)를 더 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>137. 청구항 93 내지 136 중 어느 한 항에 있어서,상기 채널 차원 내의 상기 제1 데이터(59a, 15)를 정규화하도록 구성되는 정규화 요소(76)를 더 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>138. 청구항 93 내지 137 중 어느 한 항에 있어서,상기 오디오 신호(16)는 음성 오디오 신호인 오디오 디코더.</claim></claimInfo><claimInfo><claim>139. 청구항 93 내지 138 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 2의 거듭제곱의 배만큼 업-샘플링되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>140. 청구항 139에 있어서,상기 타겟 데이터(12)는 비선형 보간(interpolation)에 의해 업-샘플링(70)되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>141. 청구항 134 또는 청구항 134를 인용할 때의 청구항 135 내지 140 중 어느 한 항에 있어서,상기 제1 활성화 함수는 리키 ReLu(leaky rectified linear unit) 함수인 오디오 디코더.</claim></claimInfo><claimInfo><claim>142. 청구항 93 내지 141 중 어느 한 항에 있어서,컨벌루션 연산들(61b, 62b)은 2의 최대 확대 인자(dilation factor)로 수행되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>143. 청구항 93 내지 142 중 어느 한 항에 있어서,8개의 제1 처리 블록들(50a-50h) 및 하나의 제2 처리 블록(45)을 포함하는 오디오 디코더.</claim></claimInfo><claimInfo><claim>144. 청구항 93 내지 143 중 어느 한 항에 있어서,상기 제1 데이터(15, 59, 59a, 59b)는 상기 오디오 신호(16)보다 낮은 차원(dimension)을 갖는, 오디오 디코더.</claim></claimInfo><claimInfo><claim>145. 청구항 93 내지 144 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 스펙트로그램인 오디오 디코더.</claim></claimInfo><claimInfo><claim>146. 청구항 93 내지 145 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 멜-스펙트로그램인 오디오 디코더.</claim></claimInfo><claimInfo><claim>147. 오디오 신호(16)를 나타내는 비트스트림(3)으로부터 상기 오디오 신호(1, 16)를 디코딩하는 방법으로서, 상기 방법은 입력 신호(14)를 이용하고, 상기 오디오 신호(1, 16)는 복수의 프레임들로 세분화 되는 상기 방법에 있어서,상기 비트스트림(3)으로부터, 제1 처리 블록(40)의 적어도 하나의 프리컨디셔닝 레이어(710)에 의해 주어진 프레임에 대한 타겟 데이터(15)를 획득하는 단계로서, 상기 타겟 데이터(15)는 상기 오디오 신호(16)를 나타내고 2 차원을 갖는, 단계; 상기 제1 처리 블록(40, 50, 50a-50h)에 의해 및 상기 주어진 프레임의 각각의 샘플에 대하여, 상기 입력 신호(15)로부터 유도되는 제1 데이터(12)를 수신하는 단계;상기 제1 처리 블록(40, 50)의 학습가능한 레이어들(71, 72, 73)의 컨디셔닝 세트에 의해 컨디셔닝 특징 파라미터들(74, 75)을 획득하기 위하여 상기 타겟 데이터(12)를 처리하는 단계;상기 제1 처리 블록(50)의 스타일링 요소(77)에 의해 상기 컨디셔닝 특징 파라미터들(74, 75)을 상기 제1 데이터(15, 59) 또는 정규화된 제1 데이터(76')에 적용하는 단계;상기 제1 처리 블록(40, 50)에 의해 복수의 채널들(47)을 포함하는 제1 출력 데이터(69)를 출력하는 단계;제2 처리 블록(45)에 의해 제2 데이터로서 상기 제1 출력 데이터(69) 또는 상기 제1 출력 데이터(69)로부터 유도된 데이터를 수신하는 단계; 및상기 제2 처리 블록(45)에 의해 상기 오디오 신호(16)를 얻기 위하여 상기 제2 데이터의 상기 복수의 채널들(47)을 결합하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>148. 청구항 147에 있어서,상기 제1 처리 블록(40) 및/또는 상기 제2 처리 블록(45)이 이전 프레임을 처리하는 동안 상기 제1 처리 블록(40) 및/또는 상기 제2 처리 블록(45)에 의해 다음으로 처리될 프레임들을 저장하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>149. 청구항 147 또는 148에 있어서,상기 비트스트림의 바로 이전의 프레임에 인접하는 상기 비트스트림의 상기 주어진 프레임으로부터 얻어지는 코딩된 파라미터들의 한 세트를 병치함으로써 획득되는 비트스트림 모델에 컨벌루션을 수행하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>150. 청구항 147 내지 149 중 어느 한 항에 있어서,상기 학습가능한 레이어들(71-73)의 상기 컨디셔닝 세트는 하나 또는 두 개의 컨벌루션 레이어를 포함하는 방법.</claim></claimInfo><claimInfo><claim>151. 청구항 147 내지 150 중 어느 한 항에 있어서,상기 처리하는 단계는 상기 학습가능한 레이어들(71-73)의 컨디셔닝 세트에 의해, 제1 활성화 함수를 이용하여 제1 컨벌루션된 데이터(71')를 획득하기 위하여 제1 컨벌루션 레이어(71)에 의해 상기 타겟 데이터(12) 또는 업-샘플링 타겟 데이터를 컨벌루션하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>152. 청구항 147 내지 151 중 어느 한 항에 있어서,상기 학습가능한 레이어들(71-73)의 컨디셔닝 세트 및 상기 스타일링 요소(77)는 하나 이상의 잔여 블록들(50, 50a-50h)을 포함하는 뉴럴 네트워크의 잔여 블록(50, 50a-50h) 내의 가중치 블록의 일부인 방법.</claim></claimInfo><claimInfo><claim>153. 청구항 147 내지 152 중 어느 한 항에 있어서,정규화 요소(76)에 의해 상기 제1 데이터(15, 59)를 정규화하는 단계를 더 포함하는 방법</claim></claimInfo><claimInfo><claim>154. 청구항 147 내지 153 중 어느 한 항에 있어서,상기 오디오 신호(16)는 음성 오디오 신호인 방법.</claim></claimInfo><claimInfo><claim>155. 청구항 147 내지 154 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 2 배 또는 2의 거듭제곱의 배만큼 업-샘플링(70)되는 방법.</claim></claimInfo><claimInfo><claim>156. 청구항 147 내지 155 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 비선형 보간에 의해 업-샘플링(70)되는 방법.</claim></claimInfo><claimInfo><claim>157. 청구항 147 내지 156 중 어느 한 항에 있어서,상기 제1 처리 블록(50)의 학습가능한 레이어들(61b, 62b)의 다른 세트에 의해, 제2 활성화 함수(63b, 64b)를 이용하여 상기 제1 데이터(15, 59, 59a, 59b)로부터 유도되는 데이터를 처리하는 단계를 더 포함하고,상기 제2 활성화 함수(63b, 64b)는 게이티드 활성화 함수(gated activation function )인,  방법. </claim></claimInfo><claimInfo><claim>158. 청구항 157에 있어서,상기 학습가능한 레이어들(61b, 62b)의 다른 세트는 하나 또는 두 개의 컨벌루션 레이어를 포함하는 방법</claim></claimInfo><claimInfo><claim>159. 청구항 157 또는 158에 있어서,상기 제2 활성화 함수(63b, 64b)는 소프트맥스-게이티드(softmax-gated) 하이퍼볼릭 탄젠트(TanH) 함수인 방법.</claim></claimInfo><claimInfo><claim>160. 청구항 147 내지 159 중 어느 한 항에 있어서,상기 제1 활성화 함수는 리키 ReLu(leaky rectified linear unit) 함수인 방법.</claim></claimInfo><claimInfo><claim>161. 청구항 147 내지 160 중 어느 한 항에 있어서,컨벌루션 연산들(61b, 62b)은 2의 최대 확대 인자(dilation factor)로 수행되는 방법.</claim></claimInfo><claimInfo><claim>162. 청구항 147 내지 161 중 어느 한 항에 있어서,상기 제1 처리 블록(50, 50a-50h)의 상기 단계들을 8번 수행하고 및 상기 제2 처리 블록(45)의 상기 단계들을 1회 수행하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>163. 청구항 147 내지 162 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 스펙트로그램인 방법.</claim></claimInfo><claimInfo><claim>164. 청구항 163 에 있어서,상기 스펙트로그램은 멜-스펙트로그램인 방법.</claim></claimInfo><claimInfo><claim>165. 청구항 93 내지 146 중 어느 한 항에 따른 오디오 디코더(10)를 훈련시키는 방법에 있어서,청구항 147 내지 164 중 어느 한 항의 상기 단계들을 1회 이상 반복하는 단계를 포함하는 훈련(100) 방법.</claim></claimInfo><claimInfo><claim>166. 청구항 165에 있어서,적어도 하나의 평가기(132)에 의해 상기 생성된 오디오 신호(14, 16)를 평가(130)하는 단계; 및상기 평가(130)의 결과들에 따라 상기 오디오 디코더(10)의 상기 가중치들(74, 75)을 적응시키는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>167. 청구항 166에 있어서,상기 적어도 하나의 평가기(132)는 뉴럴 네트워크인 방법.</claim></claimInfo><claimInfo><claim>168. 청구항 166 또는 167에 있어서,상기 평가의 결과들에 따라 상기 평가기의 상기 가중치들을 적응시키는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>169. 청구항 165 내지 168 중 어느 한 항에 있어서,상기 훈련(130)은 손실 함수(140)의 최적화를 포함하는 방법.</claim></claimInfo><claimInfo><claim>170. 청구항 169에 있어서,상기 손실 함수를 최적화(130)하는 것은 상기 생성된 오디오 신호(16) 및 참조 오디오 신호(104) 사이의 고정된 메트릭(metric)을 산출하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>171. 청구항 170에 있어서,상기 고정된 메트릭을 산출하는 것은 상기 생성된 오디오 신호(16) 및 상기 참조 오디오 신호(104) 사이의 하나 또는 수 개의 스펙트럼 왜곡들을 산출하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>172. 청구항 171에 있어서,상기 하나 또는 수개의 스펙트럼 왜곡들을 산출하는 것은 상기 생성된 오디오 신호(16) 및 상기 참조 오디오 신호(104)의 상기 스펙트럼 표현의 크기 또는 로그-크기에 대해 수행되는 방법.</claim></claimInfo><claimInfo><claim>173. 청구항 171또는 172에 있어서,상기 하나 또는 수개의 스펙트럼 왜곡들을 산출하는 것은 상기 생성된 오디오 신호(16) 및 상기 참조 오디오 신호(104)의 서로 다른 시간 또는 주파수 해상도들(resolutions)에 대해서 수행되는 방법.</claim></claimInfo><claimInfo><claim>174. 청구항 170 내지 173 중 어느 한 항에 있어서,상기 손실 함수(140)를 최적화하는 것은 상기 생성된 오디오 신호(16)의 표현 또는 상기 참조 오디오 신호(103)의 표현을 랜덤하게 제공하고 하나 이상의 평가기(132)에 의해 평가하여 하나 이상의 적대적 메트릭(adversarial metric)을 유도하는 것을 포함하고, 상기 평가하는 것은 상기 제공된 오디오 신호(16, 132)를, 상기 오디오 신호(14, 16)의 자연스러움(naturalness)의 사전 훈련된 분류 레벨을 나타내는 미리 결정된 개수의 클래스로 분류하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>175. 청구항 169 내지 174 중 어느 한 항에 있어서,상기 손실 함수를 최적화하는 것은 고정된 메트릭을 산출하고, 하나 이상의 평가기(132)에 의해 적대적 메트릭(adversarial metric)을 유도하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>176. 청구항 175에 있어서,상기 오디오 디코더(10)는 상기 고정된 메트릭을 이용하여 첫번째 훈련되는 방법.</claim></claimInfo><claimInfo><claim>177. 청구항 174 내지 176에 있어서,4개의 평가기들(132a-132d)이 4개의 적대적 메트릭을 유도하는 방법.</claim></claimInfo><claimInfo><claim>178. 청구항 174 내지 177 중 어느 한 항에 있어서,상기 평가기들(132)은 필터-뱅크(110)에 의한 상기 생성된 오디오 신호(16)의 상기 표현 또는 상기 참조 오디오 신호(104)의 상기 표현의 분해(110) 이후 동작하는 방법. </claim></claimInfo><claimInfo><claim>179. 청구항 174 내지 178 중 어느 한 항에 있어서,상기 평가기들(132a-132d) 각각은 입력으로서, 상기 생성된 오디오 신호(16)의 상기 표현 또는 상기 참조 오디오 신호(104)의 상기 표현 중 하나 또는 수 개의 부분들(105a-105d)을 수신하는 방법. </claim></claimInfo><claimInfo><claim>180. 청구항 179에 있어서, 상기 신호 부분들은 랜덤 윈도우 함수들을 이용하여, 상기 입력 신호(14)로부터 랜덤 윈도우들(105a-105d)을 샘플링함으로써 생성되는, 방법.</claim></claimInfo><claimInfo><claim>181. 청구항 180에 있어서,상기 랜덤 윈도우(105a-105d)의 샘플링은 각각의 평가기(132a-132d)에 대해 복수회 반복되는, 방법.</claim></claimInfo><claimInfo><claim>182. 청구항 181에 있어서,상기 랜덤 윈도우(105a-105d)가 각각의 평가기(132a-132d)에 대해 샘플링되는 횟수는 상기 생성된 오디오 신호의 상기 표현 또는 상기 참조 오디오 신호(104)의 상기 표현의 길이에 비례하는, 방법.</claim></claimInfo><claimInfo><claim>183. 청구항 147 내지 182 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 레이어(710, 710c, 710b)는 학습될 수 있는, 방법.</claim></claimInfo><claimInfo><claim>184. 청구항 147 내지 182 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 레이어(710, 710c, 710b)는 결정형(deterministic)인, 방법.</claim></claimInfo><claimInfo><claim>185. 청구항 147 내지 182 중 어느 한 항에 있어서,상기 적어도 하나의 프리컨디셔닝 레이어(710, 710c, 710b)는 적어도 하나의 결정형(deterministic) 프리컨디셔닝 레이어 및 적어도 하나의 학습가능한 프리컨디셔닝 레이어를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>186. 청구항 147 내지 185 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 적어도 하나의 음향 특징을 포함하는 방법.</claim></claimInfo><claimInfo><claim>187. 청구항 186에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트로부터의 상기 비트스트림을 상기 적어도 하나의 음향 특징으로 변환함(1110)으로써 상기 타겟 데이터(12)를 획득하는 방법.</claim></claimInfo><claimInfo><claim>188. 청구항 187에 있어서,상기 적어도 하나의 음향 특징은 로그-스펙트로그램, MFCC 및 멜-스펙트로그램 중 하나인 방법.</claim></claimInfo><claimInfo><claim>189. 청구항 163, 164, 186 내지 188 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 적어도 하나의 언어 특징 형태의 상기 비트스트림을 적어도 하나의 음향 특징 형태의 상기 타겟 데이터(12)로 변환함(1114)으로써 상기 타겟 데이터(12)를 획득하는 방법.</claim></claimInfo><claimInfo><claim>190. 청구항 147 내지 189 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 적어도 하나의 언어학 특징을 포함하는 방법.</claim></claimInfo><claimInfo><claim>191. 청구항 190에 있어서,적어도 하나의 언어학 특징은 텍스트로부터 얻어지는 음소, 단어 운율, 성조, 구문 중단들 및 채워진 휴지들(pauses) 중 하나인 방법.</claim></claimInfo><claimInfo><claim>192. 청구항 190 또는 191에 있어서,상기 프리컨디셔닝 레이어는 텍스트 형태 또는 텍스트의 요소들 형태의 상기 비트스트림을 적어도 하나의 언어 특징 형태의 상기 타겟 데이터(12)로 변환함(1110)으로써 상기 타겟 데이터(12)를 획득하는 방법.</claim></claimInfo><claimInfo><claim>193. 청구항 147 내지 192 중 어느 한 항에 있어서,상기 타겟 데이터(12)는 텍스트로부터 얻어진 단어 및 문자 사이의 적어도 하나를 포함하는 방법.</claim></claimInfo><claimInfo><claim>194. 청구항 147 내지 193 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트 분석을 수행하도록 구성된 적어도 하나의 통계 모델을 이용하여 및/또는 음향 모델을 이용하여, 상기 텍스트 형태의 상기 비트스트림으로부터 상기 타겟 데이터(12)로 상기 타겟 데이터(12)를 유도하는 방법.  </claim></claimInfo><claimInfo><claim>195. 청구항 147 내지 194 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트 분석을 수행하는 학습가능한 모델을 이용하여 및/또는 음향 모델을 이용하여, 상기 텍스트 형태의 상기 비트스트림(3)으로부터 상기 타겟 데이터(12)로 상기 타겟 데이터(12)를 유도하는 오디오 디코더.  </claim></claimInfo><claimInfo><claim>196. 청구항 147 내지 195 중 어느 한 항에 있어서,상기 프리컨디셔닝 레이어(710, 710c, 710b)는 텍스트 분석을 수행하는 규칙-기반의 알고리즘을 이용하여 및/또는 음향 모델을 이용하여, 상기 텍스트 형태의 상기 비트스트림으로부터 상기 타겟 데이터(12)로 상기 타겟 데이터(12)를 유도하는 오디오 디코더.  </claim></claimInfo><claimInfo><claim>197. 청구항 93 내지 196 중 어느 한 항에 있어서,상기 비트스트림(3)으로부터 유도된 시간-영역 구조 또는 적어도 하나의 시간 포락선 정보로부터 상기 입력 신호(14)를 획득하도록 구성되는 오디오 디코더.</claim></claimInfo><claimInfo><claim>198. 컴퓨터에 의해 실행될 때, 상기 컴퓨터가 청구항 147 내지 197 중 어느 한 항에 따른 방법을 수행하도록 하는 명령어들을 저장하는 비-일시적 스토리지 유닛.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>독일 ***** 뮌헨 한자슈트라쎄 ** 체</address><code>520000324108</code><country>독일</country><engName>FRAUNHOFER-GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E.V.</engName><name>프라운호퍼-게젤샤프트 추르 푀르데룽 데어 안제반텐 포르슝 에 파우</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>독일 ***** 에를랑겐 암 볼프스만텔...</address><code> </code><country> </country><engName>AHMED, Ahmed Mustafa Mahmoud</engName><name>아메드, 아메드 무스타파 마흐무드</name></inventorInfo><inventorInfo><address>독일 ***** 에를랑겐 암 볼프스만텔...</address><code> </code><country> </country><engName>PIA, Nicola</engName><name>피아, 니콜라</name></inventorInfo><inventorInfo><address>독일 ***** 에를랑겐 암 볼프스만텔...</address><code> </code><country> </country><engName>BUETHE, Jan</engName><name>부테, 얀</name></inventorInfo><inventorInfo><address>독일 ***** 에를랑겐 암 볼프스만텔...</address><code> </code><country> </country><engName>KORSE, Srikanth</engName><name>코르세, 스리칸트</name></inventorInfo><inventorInfo><address>독일 ***** 에를랑겐 암 볼프스만텔...</address><code> </code><country> </country><engName>GUPTA, Kishan</engName><name>굽타, 키샨</name></inventorInfo><inventorInfo><address>독일 ***** 에를랑겐 암 볼프스만텔...</address><code> </code><country> </country><engName>MULTRUS, Markus</engName><name>물트루스, 마르쿠스</name></inventorInfo><inventorInfo><address>독일 ***** 에를랑겐 암 볼프스만텔...</address><code> </code><country> </country><engName>FUCHS, Guillaume</engName><name>푹스, 기욤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 새문안로*길 **, 도렴빌딩 ***호 (도렴동)</address><code>920071000410</code><country>대한민국</country><engName>NAMCHON Patent &amp; Law Firm</engName><name>특허법인남촌</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2021.04.27</priorityApplicationDate><priorityApplicationNumber>21170782.3</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.11.24</receiptDate><receiptNumber>1-1-2023-1317925-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.12.07</receiptDate><receiptNumber>1-1-2023-1374588-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[New Translation under Article 201 of Patent Act or Article 35 of Utility Model Act] Submission of Document</documentEngName><documentName>[특허법 제201조 또는 실용신안법 제35조에 따른 새로운 번역문]서류제출서</documentName><receiptDate>2023.12.26</receiptDate><receiptNumber>1-1-2023-1458657-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.12.28</receiptDate><receiptNumber>1-5-2023-0211911-42</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.07.19</receiptDate><receiptNumber>1-1-2024-0787995-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.07.22</receiptDate><receiptNumber>1-1-2024-0794349-06</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of Return of Official Fee</documentEngName><documentName>수수료 반환 안내서</documentName><receiptDate>2024.08.02</receiptDate><receiptNumber>1-5-2024-0126633-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237040691.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93edd78153d233f936f45d4fa5126b70ec31dd452ab634b6e7ae0840152612575f2c84a77cb78c7b610bd1279e89b6618b9f908b826d4408f8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd678b55c9a7ea1b3c9d26c4f58e399d7afb8555d74450e5fb740a5b06d6c60c294158cef56c6539d201bf424bc70531e893418d33f9b2fdd</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>