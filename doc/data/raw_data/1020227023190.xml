<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:35.3335</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.09.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7023190</applicationNumber><claimCount>40</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신경망 모델 업데이트 방법, 및 이미지 처리 방법 및 디바이스</inventionTitle><inventionTitleEng>NEURAL NETWORK MODEL UPDATE METHOD, AND IMAGE PROCESSING METHOD AND DEVICE</inventionTitleEng><openDate>2022.08.11</openDate><openNumber>10-2022-0112813</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.07.06</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.07.06</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 17/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/047</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/063</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 출원은 인공 지능 분야에서의 신경망 모델 업데이트 방법, 이미지 처리 방법, 및 장치를 개시한다. 신경망 모델 업데이트 방법은: 신경망 모델의 구조 및 신경망 모델의 관련 파라미터를 획득하는 단계; 신경망 모델의 관련 파라미터에 기초하여 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 단계; 훈련된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계를 포함한다. 본 출원의 방법에 따르면, 신경망 모델을 업데이트하는 효율이 향상될 수 있고, 더 양호한 성능을 갖는 신경망 모델의 구조 및/또는 신경망 모델의 관련 파라미터가 획득될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.06.24</internationOpenDate><internationOpenNumber>WO2021120719</internationOpenNumber><internationalApplicationDate>2020.09.11</internationalApplicationDate><internationalApplicationNumber>PCT/CN2020/114832</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 신경망 모델 업데이트 방법으로서,신경망 모델의 구조 및 상기 신경망 모델의 관련 파라미터를 획득하는 단계 - 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터(hyper-parameter), 손실 함수(loss function), 및 평가 방식(evaluation manner)을 포함함 - ;훈련 데이터(training data)를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨(prediction label)을 획득하는 단계;상기 예측 라벨 및 상기 훈련 데이터의 라벨에 기초하여 상기 손실 함수의 함수 값을 결정하고, 상기 손실 함수의 함수 값 및 상기 신경망 모델의 하이퍼-파라미터에 기초하여 상기 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하는 단계; 및상기 훈련된 신경망 모델을 상기 평가 방식으로 평가하고, 상기 훈련된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 상기 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고,훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨을 획득하는 단계는:상기 훈련 데이터를 상기 전처리 방식으로 전처리하는 단계; 및전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 상기 예측 라벨을 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고,훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨을 획득하는 단계는:상기 신경망 모델을 상기 신경망 모델의 압축 방식으로 처리하여 처리된 신경망 모델을 획득하는 단계; 및상기 훈련 데이터를 상기 처리된 신경망 모델에 입력하여 상기 예측 라벨을 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계는:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단계 - 각각의 항목에 대응하는 상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함하고, 상기 다른 항목의 관련 정보는 상기 다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고, 각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기 이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제4항 내지 제6항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를 추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련 프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의 학습률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의 드롭아웃 파라미터 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 이미지 처리 방법으로서,처리될 이미지를 획득하는 단계; 및목표 신경망 모델을 사용함으로써 상기 처리될 이미지를 처리하여 상기 처리될 이미지의 처리 결과를 획득하는 단계를 포함하고,상기 목표 신경망 모델은 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트함으로써 획득되고, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함하고, 상기 신경망 모델은 예측 라벨 및 훈련 데이터의 라벨에 기초하여 상기 손실 함수의 함수 값을 결정하고 상기 신경망 모델의 하이퍼-파라미터 및 손실 함수의 함수 값에 기초하여 훈련을 수행함으로써 획득되고, 상기 예측 라벨은 상기 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고, 상기 예측 라벨은 상기 훈련 데이터를 상기 전처리 방식으로 전처리하고 전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 방법.</claim></claimInfo><claimInfo><claim>12. 제10항 또는 제11항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고, 상기 예측 라벨은 상기 신경망 모델을 상기 신경망 모델의 상기 압축 방식으로 처리하고 상기 훈련 데이터를 처리된 신경망 모델에 입력함으로써 획득되는, 방법.</claim></claimInfo><claimInfo><claim>13. 제10항 내지 제12항 중 어느 한 항에 있어서, 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트하는 단계는:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 단계 - 각각의 항목에 대응하는 상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함하고, 상기 다른 항목의 관련 정보는 상기 다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고, 각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기 이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제13항 내지 제15항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를 추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제10항 내지 제16항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련 프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제10항 내지 제17항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의 학습률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의 드롭아웃 파라미터 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 신경망 모델 업데이트 장치로서,신경망 모델의 구조 및 상기 신경망 모델의 관련 파라미터를 획득하도록 구성되는 획득 유닛 - 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함함 - ; 및평가 유닛을 포함하고, 상기 평가 유닛은:훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 예측 라벨을 획득하고;상기 예측 라벨 및 상기 훈련 데이터의 라벨에 기초하여 상기 손실 함수의 함수 값을 결정하고, 상기 손실 함수의 함수 값 및 상기 신경망 모델의 하이퍼-파라미터에 기초하여 상기 신경망 모델을 훈련시켜 훈련된 신경망 모델을 획득하고;상기 훈련된 신경망 모델을 상기 평가 방식으로 평가하고, 상기 훈련된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키지 않으면, 업데이트된 신경망 모델의 평가 결과가 상기 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고, 상기 평가 유닛은:상기 훈련 데이터를 상기 전처리 방식으로 전처리하고;전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력하여 상기 예측 라벨을 획득하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>21. 제19항 또는 제20항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고, 상기 평가 유닛은:상기 신경망 모델을 상기 신경망 모델의 압축 방식으로 처리하여 처리된 신경망 모델을 획득하고;상기 훈련 데이터를 상기 처리된 신경망 모델에 입력하여 상기 예측 라벨을 획득하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>22. 제19항 내지 제21항 중 어느 한 항에 있어서, 상기 평가 유닛은:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하고 - 각각의 항목에 대응하는 상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함하고, 상기 다른 항목의 관련 정보는 상기 다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고, 각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기 이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>25. 제22항 내지 제24항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를 추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>26. 제19항 내지 제25항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련 프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>27. 제19항 내지 제26항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의 학습률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의 드롭아웃 파라미터 중 하나 이상을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>28. 이미지 처리 장치로서,처리될 이미지를 획득하도록 구성되는 획득 유닛; 및목표 신경망 모델을 사용함으로써 상기 처리될 이미지를 처리하여 상기 처리될 이미지의 처리 결과를 획득하도록 구성되는 이미지 처리 유닛을 포함하고,상기 목표 신경망 모델은 업데이트된 신경망 모델의 평가 결과가 미리 설정된 조건을 충족시키고/시키거나 업데이트 횟수가 미리 설정된 횟수에 도달할 때까지 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트함으로써 획득되고, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 하이퍼-파라미터, 손실 함수, 및 평가 방식을 포함하고, 상기 신경망 모델은 예측 라벨 및 훈련 데이터의 라벨에 기초하여 상기 손실 함수의 함수 값을 결정하고 상기 신경망 모델의 하이퍼-파라미터 및 손실 함수의 함수 값에 기초하여 훈련을 수행함으로써 획득되고, 상기 예측 라벨은 상기 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 장치.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 신경망 모델의 관련 파라미터는 전처리 방식을 추가로 포함하고, 상기 예측 라벨은 상기 훈련 데이터를 상기 전처리 방식으로 전처리하고 전처리된 훈련 데이터를 처리를 위해 상기 신경망 모델에 입력함으로써 획득되는, 장치.</claim></claimInfo><claimInfo><claim>30. 제28항 또는 제29항에 있어서, 상기 신경망 모델의 관련 파라미터는 상기 신경망 모델의 압축 방식을 추가로 포함하고, 상기 예측 라벨은 상기 신경망 모델을 상기 신경망 모델의 상기 압축 방식으로 처리하고 상기 훈련 데이터를 처리된 신경망 모델에 입력함으로써 획득되는, 장치.</claim></claimInfo><claimInfo><claim>31. 제28항 내지 제30항 중 어느 한 항에 있어서, 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개를 업데이트하는 것은:상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개의 각각의 항목에 대응하는 제1 정보에 기초하여, 각각의 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 결정하는 것 - 각각의 항목에 대응하는 상기 제1 정보는 상기 평가 결과를 포함함 - ; 및각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포에 기초하여 각각의 항목에 대응하는 상기 복수의 후보 옵션들 내의 하나의 후보 옵션을 각각의 항목의 업데이트된 옵션으로서 결정하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 상기 신경망 모델의 관련 파라미터와 상기 신경망 모델의 구조 중 적어도 2개에서의 다른 항목의 관련 정보를 추가로 포함하고, 상기 다른 항목의 관련 정보는 상기 다른 항목 및/또는 상기 다른 항목에 대응하는 복수의 후보 옵션들의 확률 분포를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>33. 제32항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 각각의 항목의 이력 관련 정보를 추가로 포함하고, 각각의 항목의 상기 이력 관련 정보는 상기 이전 업데이트에서의 각각의 항목의 업데이트된 옵션 및/또는 상기 이전 업데이트에서의 각각의 항목에 대응하는 상기 복수의 후보 옵션들의 확률 분포를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>34. 제31항 내지 제33항 중 어느 한 항에 있어서, 각각의 항목에 대응하는 상기 제1 정보는 훈련 자원 상태 정보를 추가로 포함하고, 상기 훈련 자원 상태 정보는 훈련 머신들의 수량을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>35. 제28항 내지 제34항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는 상기 신경망 모델의 훈련 프로세스에서 변경되지 않은 채로 유지되는 파라미터를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>36. 제28항 내지 제35항 중 어느 한 항에 있어서, 상기 신경망 모델의 하이퍼-파라미터는: 상기 신경망 모델의 학습률, 상기 신경망 모델의 가중치 감쇠 계수, 상기 신경망 모델의 라벨 평활 계수, 또는 상기 신경망 모델의 드롭아웃 파라미터 중 하나 이상을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>37. 신경망 모델 업데이트 장치로서, 프로세서 및 메모리를 포함하고, 상기 메모리는 프로그램 명령어들을 저장하도록 구성되고, 상기 프로세서는 상기 프로그램 명령어들을 호출하여 제1항 내지 제9항 중 어느 한 항에 따른 방법을 수행하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>38. 이미지 처리 장치로서, 프로세서 및 메모리를 포함하고, 상기 메모리는 프로그램 명령어들을 저장하도록 구성되고, 상기 프로세서는 상기 프로그램 명령어들을 호출하여 제10항 내지 제18항 중 어느 한 항에 따른 방법을 수행하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>39. 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 디바이스에 의해 실행될 프로그램 코드를 저장하고, 상기 프로그램 코드는 제1항 내지 제9항 또는 제10항 내지 제18항 중 어느 한 항에 따른 방법을 수행하기 위해 사용되는, 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>40. 칩으로서, 상기 칩은 프로세서 및 데이터 인터페이스를 포함하고, 상기 프로세서는 상기 데이터 인터페이스를 통해 메모리에 저장된 명령어들을 판독하여 제1항 내지 제9항 또는 제10항 내지 제18항 중 어느 한 항에 따른 방법을 수행하는, 칩.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 ****** 광동성 셴젠 롱강 디스트릭트 반티안 후아웨이 어드미니스트레이션 빌딩</address><code>520000572466</code><country>중국</country><engName>HUAWEI TECHNOLOGIES CO., LTD.</engName><name>후아웨이 테크놀러지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 광둥 선전...</address><code> </code><country> </country><engName>ZHANG, Xinyu</engName><name>장, 신위</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전...</address><code> </code><country> </country><engName>YUAN, Peng</engName><name>위안, 펑</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전...</address><code> </code><country> </country><engName>FANG, Muyuan</engName><name>팡, 무위안</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전...</address><code> </code><country> </country><engName>ZHONG, Zhao</engName><name>중, 자오</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920040000059</code><country>대한민국</country><engName>KIM SEONGWOON</engName><name>김성운</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2019.12.19</priorityApplicationDate><priorityApplicationNumber>201911314332.6</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.07.06</receiptDate><receiptNumber>1-1-2022-0703898-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.07.06</receiptDate><receiptNumber>1-1-2022-0705560-90</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.07.12</receiptDate><receiptNumber>1-5-2022-0103285-78</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.02.12</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2025.02.27</receiptDate><receiptNumber>9-6-2025-0128092-28</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.07.17</receiptDate><receiptNumber>9-5-2025-0681032-03</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.10.31</receiptDate><receiptNumber>1-1-2025-1215428-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName> </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.10.31</receiptDate><receiptNumber>1-1-2025-1215412-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227023190.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c939e79c0b4b3e925bae6a7b57f3b2860cb11d369fb13b2ba3f644c04e21f1c217dfcaa612bc75d599cea78c97e318f492c5bb0fd3934506d48</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf3473c4510afdaf532fd6ad2d32bb252f251ded6efbb75a583cc520d7a03419e7fdefe8e12bae1ca500e719edf72bdb04dc98aa49c392bd6a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>