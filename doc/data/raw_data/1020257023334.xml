<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:21.5121</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7023334</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>XR 디바이스들을 위한 콘텐츠 제작 플랫폼</inventionTitle><inventionTitleEng>CONTENT CREATION PLATFORM FOR XR DEVICES</inventionTitleEng><openDate>2025.08.12</openDate><openNumber>10-2025-0121409</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.07.11</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 30/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 확장 현실(eXtended Reality, XR) 시스템들을 위한 콘텐츠 제작 시스템. 콘텐츠 제작 시스템은 XR 디바이스의 모션 데이터를 수신하고, 모션 데이터에 기초하여 현실 세계 장면의 3D 환경 모델 내의 궤적의 궤적 데이터를 생성하며, 여기서 궤적은 현실 세계 장면 내의 XR 디바이스의 모션을 시뮬레이션한다. 콘텐츠 제작 시스템은 사용자 상호작용 이벤트 데이터를 수신하고, 궤적 데이터, 3D 환경 모델, 및 사용자 상호작용 이벤트 데이터에 기초하여 시뮬레이션된 센서 데이터를 생성한다. 콘텐츠 제작 시스템은 시뮬레이션된 센서 데이터에 기초하여 시뮬레이션된 추적 데이터를 생성하고, 시뮬레이션된 추적 데이터를 생성하는 동안 컴퓨터 비전 컴포넌트의 동작에 기초하여 시뮬레이션된 전력 소비 데이터 및 열 조건 데이터를 결정한다. 콘텐츠 제작 시스템은 시뮬레이션된 전력 소비 및 열 데이터와 함께 3D 환경 모델의 사용자의 관점으로부터 디스플레이를 생성한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.06.20</internationOpenDate><internationOpenNumber>WO2024129586</internationOpenNumber><internationalApplicationDate>2023.12.11</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/083358</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터에 의해 구현되는 방법(computer-implemented method)으로서,콘텐츠 제작 플랫폼에 의해, XR 디바이스의 모션의 모션 데이터를 수신하는 단계;상기 콘텐츠 제작 플랫폼에 의해, 상기 모션 데이터에 기초하여 현실 세계 장면의 3D 환경 모델 내의 궤적의 궤적 데이터를 생성하는 단계- 궤적은 상기 현실 세계 장면 내의 상기 XR 디바이스의 모션을 시뮬레이션함 -;상기 콘텐츠 제작 플랫폼에 의해, 사용자 상호작용 이벤트 데이터를 수신하는 단계;데이터 시뮬레이션 플랫폼에 의해, 상기 궤적 데이터, 상기 3D 환경 모델, 및 상기 사용자 상호작용 이벤트 데이터에 기초하여 시뮬레이션된 센서 데이터를 생성하는 단계;운영 체제 에뮬레이터 내의 컴퓨터 비전 컴포넌트에 의해, 시뮬레이션된 센서 데이터에 기초하여 시뮬레이션된 추적 데이터를 생성하는 단계;상기 운영 체제 에뮬레이터에 의해, 상기 시뮬레이션된 추적 데이터를 생성하는 동안 상기 컴퓨터 비전 컴포넌트의 동작에 기초하여 시뮬레이션된 전력 소비 데이터 및 시뮬레이션된 열 조건 데이터를 결정하는 단계; 및상기 콘텐츠 제작 플랫폼에 의해 사용자에게, 상기 시뮬레이션된 전력 소비 데이터 및 상기 시뮬레이션된 열 조건 데이터를 제공하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 XR 디바이스의 상기 모션 데이터를 수신하는 단계는:상기 XR 디바이스가 사용자에 의해 현실 세계 장면을 통해 이동될 때 상기 XR 디바이스의 상기 모션의 상기 데이터를 캡처하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 XR 디바이스의 상기 모션 데이터를 수신하는 단계는:저장된 데이터의 나열으로부터 상기 모션의 상기 데이터를 선택하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 사용자 상호작용 이벤트는 시간 이벤트와 연관되는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 사용자 상호작용 이벤트는 상기 현실 세계 장면 내의 위치와 연관되는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 사용자 상호작용 이벤트는 사용자에 의해 이루어진 제스처인, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 3D 환경 모델 내의 상기 궤적의 상기 궤적 데이터를 생성하는 단계는 추가로:상기 3D 환경 모델의 조명 파라미터를 변경하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 시뮬레이션된 센서 데이터는 카메라 데이터, 관성 모션 유닛 데이터(Inertial Motion data), 및 글로벌 포지셔닝 센서 데이터(Global Positioning Sensor data)를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 시뮬레이션된 추적 데이터는 디바이스 포즈 데이터 및 손 인식 결과 데이터를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 운영 체제 에뮬레이터 내의 상기 컴퓨터 비전 컴포넌트에 의해, 상기 시뮬레이션된 센서 데이터에 기초하여 시뮬레이션된 추적 데이터를 생성하는 단계는, 추가적으로:상기 운영 체제 에뮬레이터에 의해, 시간 경과에 따른 시뮬레이션된 환경 변화들에 기초하여 상기 컴퓨터 비전 컴포넌트의 동작에 영향을 미치는 시뮬레이션된 운영 체제 이벤트들을 생성하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 시뮬레이션된 운영 체제 이벤트들은 열 스로틀링 이벤트, 네트워크 조건 변경 이벤트, 주변 잡음 이벤트 및 디스플레이 조정 이벤트를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>12. 머신으로서:하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하는 명령어들을 저장한 메모리를 포함하고, 상기 동작들은:콘텐츠 제작 플랫폼에 의해, XR 디바이스의 모션의 모션 데이터를 수신하는 것:상기 콘텐츠 제작 플랫폼에 의해, 상기 모션 데이터에 기초하여 현실 세계 장면의 3D 환경 모델 내의 궤적의 궤적 데이터를 생성하는 것- 상기 궤적은 상기 현실 세계 장면 내의 상기 XR 디바이스의 모션을 시뮬레이션함 -;상기 콘텐츠 제작 플랫폼에 의해, 사용자 상호작용 이벤트 데이터를 수신하는 것;데이터 시뮬레이션 플랫폼에 의해, 상기 궤적 데이터, 상기 3D 환경 모델, 및 상기 사용자 상호작용 이벤트 데이터에 기초하여 시뮬레이션된 센서 데이터를 생성하는 것;운영 체제 에뮬레이터 내의 컴퓨터 비전 컴포넌트에 의해, 상기 시뮬레이션된 센서 데이터에 기초하여 시뮬레이션된 추적 데이터를 생성하는 것;상기 운영 체제 에뮬레이터에 의해, 상기 시뮬레이션된 추적 데이터를 생성하는 동안 상기 컴퓨터 비전 컴포넌트의 동작에 기초하여 시뮬레이션된 전력 소비 데이터 및 시뮬레이션된 열 조건 데이터를 결정하는 것; 및상기 콘텐츠 제작 플랫폼에 의해 사용자에게, 상기 시뮬레이션된 전력 소비 데이터 및 상기 시뮬레이션된 열 조건 데이터를 제공하는 것을 포함하는, 머신.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 XR 디바이스의 상기 모션의 데이터를 수신하는 것은:상기 XR 디바이스가 사용자에 의해 현실 세계 장면을 통해 이동될 때 상기 XR 디바이스의 상기 모션의 상기 데이터를 캡처하는 것을 포함하는, 머신.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 XR 디바이스의 상기 모션의 데이터를 수신하는 것은:저장된 데이터의 나열으로부터 상기 모션의 상기 데이터를 선택하는 것을 포함하는, 머신.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서, 상기 사용자 상호작용 이벤트는 시간 이벤트와 연관되는, 머신.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서, 상기 사용자 상호작용 이벤트는 상기 현실 세계 장면 내의 위치와 연관되는, 머신.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서, 상기 사용자 상호작용 이벤트는 사용자에 의해 이루어진 제스처인, 머신.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서, 상기 3D 환경 모델 내의 상기 궤적의 상기 궤적 데이터를 생성하는 것은 추가로:상기 3D 환경 모델의 조명 파라미터를 변경하는 것을 포함하는, 머신.</claim></claimInfo><claimInfo><claim>19. 제12항에 있어서, 상기 시뮬레이션된 센서 데이터는 카메라 데이터, 관성 모션 유닛 데이터(Inertial Motion Unit data), 및 글로벌 포지셔닝 센서 데이터(Global Positioning Sensor data)를 포함하는, 머신.</claim></claimInfo><claimInfo><claim>20. 비일시적 머신 판독가능 저장 매체로서, 상기 머신 판독가능 저장 매체는 컴퓨터에 의해 실행될 때, 컴퓨터로 하여금 동작들을 수행하게 하는 명령어들을 포함하고, 상기 동작들은:콘텐츠 제작 플랫폼에 의해, XR 디바이스의 모션의 모션 데이터를 수신하는 것;상기 콘텐츠 제작 플랫폼에 의해, 상기 모션 데이터에 기초하여 현실 세계 장면의 3D 환경 모델 내의 궤적의 궤적 데이터를 생성하는 것- 상기 궤적은 상기 현실 세계 장면 내의 상기 XR 디바이스의 상기 모션을 시뮬레이션함-;상기 콘텐츠 제작 플랫폼에 의해, 사용자 상호작용 이벤트 데이터를 수신하는 것;데이터 시뮬레이션 플랫폼에 의해, 상기 궤적 데이터, 상기 3D 환경 모델, 및 상기 사용자 상호작용 이벤트 데이터에 기초하여 시뮬레이션된 센서 데이터를 생성하는 것;운영 체제 에뮬레이터 내의 컴퓨터 비전 컴포넌트에 의해, 시뮬레이션된 센서 데이터에 기초하여 시뮬레이션된 추적 데이터를 생성하는 것;상기 운영 체제 에뮬레이터에 의해, 상기 시뮬레이션된 추적 데이터를 생성하는 동안 상기 컴퓨터 비전 컴포넌트의 동작에 기초하여 시뮬레이션된 전력 소비 데이터 및 시뮬레이션된 열 조건 데이터를 결정하는 것; 및상기 콘텐츠 제작 플랫폼에 의해 사용자에게, 상기 시뮬레이션된 전력 소비 데이터 및 상기 시뮬레이션된 열 조건 데이터를 제공하는 것을 포함하는, 비일시적 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>ZHOU, Kai</engName><name>저우, 카이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>HU, Dunxu</engName><name>후, 둔쉬</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>오스트리아</country><engName>SCHNITZER, Dominik</engName><name>슈니처, 도미니크</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.12.13</priorityApplicationDate><priorityApplicationNumber>18/065,180</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.07.11</receiptDate><receiptNumber>1-1-2025-0784992-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.07.17</receiptDate><receiptNumber>1-5-2025-0120937-96</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257023334.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931c70029ce4aa30ede1eaaec04c194cfc56a194f95525cb23ec906154fbd7d3ef27364051af08006c9fdc74a2c92ac392b6da3df9b279a7f9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf439a52ed1fc0317a507b2a1c49d766cf196af706e5b41075eb33fab0beed94eda2e19aa326a4a9605423a095b81e52840d20086300688dfe</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>