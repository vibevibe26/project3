<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:24.024</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0189388</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>대상 객체를 추적하는 장치와 방법, 및 전자 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS OF TRACKING TARGET OBJECT  AND ELECTRIC DEVICE</inventionTitleEng><openDate>2024.07.08</openDate><openNumber>10-2024-0106503</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.12.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/67</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/69</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따르면, 대상 객체를 추적하는 방법 및 장치는 템플릿 영상에서의 제1 타겟 박스의 위치를 기초로, 입력 영상에 포함된 대상 객체의 검색 영역을 설정하고, 신경망 모델에 입력되는 영상의 제1 크기에 대비되는 검색 영역의 제2 크기의 조정 비율에 따라, 신경망 모델의 복수의 네트워크 경로들 중 어느 하나의 네트워크 경로를 선택하며, 선택된 네트워크 경로에 따라 입력 영상에서 대상 객체에 대응하는 제2 타겟 박스의 위치를 추정함으로써 대상 객체를 추적한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 템플릿 영상에서의 제1 타겟 박스의 위치를 기초로, 입력 영상에 포함된 대상 객체의 검색 영역을 설정하는 단계;신경망 모델에 입력되는 영상의 제1 크기에 대비되는 상기 검색 영역의 제2 크기의 조정 비율에 따라, 상기 신경망 모델의 복수의 네트워크 경로들 중 어느 하나의 네트워크 경로를 선택하는 단계; 및  상기 선택된 네트워크 경로에 따라 상기 입력 영역에서 상기 대상 객체에 대응하는 제2 타겟 박스의 위치를 추정함으로써 상기 대상 객체를 추적하는 단계를 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 어느 하나의 네트워크 경로를 선택하는 단계는상기 입력되는 영상의 제1 크기를 상기 검색 영역의 제2 크기로 나눈 값에 의해 상기 조정 비율을 산출하는 단계; 및 상기 조정 비율과 설정된 임계치 간의 비교 결과에 따라, 상기 복수의 네트워크 경로들 중 상기 조정 비율에 따라 정해진 어느 하나의 네트워크 경로를 선택하는 단계를 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 복수의 네트워크 경로들은 서로 다른 커널 사이즈들 각각에 대응하는 컨볼루션 레이어들로 구성된 블록들을 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 조정 비율에 따라 정해진 어느 하나의 네트워크 경로를 선택하는 단계는상기 조정 비율이 상기 임계치보다 크다고 결정된 경우, 제1 커널 사이즈에 대응하는 제1 네트워크 경로를 선택하는 단계; 상기 조정 비율이 상기 임계치와 같다고 결정된 경우, 제2 커널 사이즈에 대응하는 제2 네트워크 경로를 선택하는 단계; 및 상기 조정 비율이 상기 임계치보다 작은 경우, 제3 커널 사이즈에 대응하는 제3 네트워크 경로를 선택하는 단계를 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제2 커널 사이즈는 상기 제1 커널 사이즈보다 큰 값을 가지고, 상기 제3 커널 사이즈는 상기 제2 커널 사이즈 보다 큰 값을 가지는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 신경망 모델은 복수의 커널 사이즈들 별로 구성된 별도의 컨볼루션 레이어들을 가지는 슈퍼 넷(Super Net)을 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 대상 객체를 추적하는 단계는 상기 선택된 네트워크 경로에 따라 리사이징(resizing)된 상기 검색 영역으로부터 제2 특징 맵을 생성하는 단계; 및 상기 템플릿 영상의 제1 특징 맵 및 상기 제2 특징 맵을 이용하여 상기 입력 영상에서 상기 대상 객체에 대응하는 제2 타겟 박스의 위치를 추정하는 단계를 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 제2 타겟 박스의 위치를 추정하는 단계는상기 제1 특징 맵과 상기 제2 특징 맵 간의 유사도를 산출하는 단계; 및 상기 유사도에 의해 상기 입력 영상에서 상기 대상 객체에 대응하는 상기 제2 타겟 박스의 위치를 추정하는 단계를 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 입력 영상의 다음 입력 영상에서의 상기 검색 영역의 설정을 위해 상기 제2 타겟 박스의 위치를 저장하는 단계를 더 포함하는, 대상 객체를 추적하는 방법.</claim></claimInfo><claimInfo><claim>10. 하드웨어와 결합되어 제1항 내지 제9항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터로 판독 가능한 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>11. 템플릿 영상, 상기 템플릿 영상에서의 제1 타겟 박스의 위치, 및 상기 템플릿 영상의 제1 특징 맵 중 적어도 하나를 저장하는 메모리; 및 상기 제1 타겟 박스의 위치를 기초로, 입력 영상에 포함된 대상 객체의 검색 영역을 설정하고, 신경망 모델에 입력되는 영상의 제1 크기에 대비되는 상기 검색 영역의 제2 크기의 조정 비율에 따라, 상기 신경망 모델의 복수의 네트워크 경로들 중 어느 하나의 네트워크 경로를 선택하고, 상기 선택된 네트워크 경로에 의해 상기 입력 영상에서 상기 대상 객체에 대응하는 제2 타겟 박스의 위치를 추정함으로써 상기 대상 객체를 추적하는 프로세서를 포함하는, 대상 객체를 추적하는 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 프로세서는 상기 제1 크기를 상기 제2 크기로 나눈 값에 의해 상기 조정 비율을 산출하고, 상기 조정 비율과 설정된 임계치 간의 비교 결과에 따라, 상기 복수의 네트워크 경로들 중 상기 조정 비율에 따라 정해진 어느 하나의 네트워크 경로를 선택하는, 대상 객체를 추적하는 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 복수의 네트워크 경로들은 서로 다른 커널 사이즈들 각각에 대응하는 컨볼루션 레이어들로 구성된 블록들을 포함하는, 대상 객체를 추적하는 장치.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 프로세서는 상기 조정 비율이 상기 임계치보다 큰 경우, 제1 커널 사이즈에 대응하는 제1 네트워크 경로를 선택하고, 상기 조정 비율이 상기 임계치와 같은 경우, 제2 커널 사이즈에 대응하는 제2 네트워크 경로를 선택하며, 상기 조정 비율이 상기 임계치보다 작은 경우, 제3 커널 사이즈에 대응하는 제3 네트워크 경로를 선택하는, 대상 객체를 추적하는 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 제2 커널 사이즈는 상기 제1 커널 사이즈 보다 큰 값을 가지고, 상기 제3 커널 사이즈는 상기 제2 커널 사이즈 보다 큰 값을 가지는, 대상 객체를 추적하는 장치.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 신경망 모델은 복수의 커널 사이즈들 별로 구성된 별도의 컨볼루션 레이어들을 가지는 슈퍼 넷을 포함하는, 대상 객체를 추적하는 장치.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 프로세서는 상기 선택된 네트워크 경로에 따라 리사이징된 상기 검색 영역으로부터 제2 특징 맵을 생성하고, 상기 제1 특징 맵 및 상기 제2 특징 맵을 이용하여 상기 검색 영역에서 상기 대상 객체에 대응하는 제2 타겟 박스의 위치를 추정하는,  대상 객체를 추적하는 장치.</claim></claimInfo><claimInfo><claim>18. 템플릿 영상 및 입력 영상 중 적어도 하나를 캡쳐하는 카메라; 및 상기 템플릿 영상에서의 제1 타겟 박스의 위치를 기초로, 상기 입력 영상에 포함된 대상 객체의 검색 영역을 설정하고, 신경망 모델에 입력되는 영상의 제1 크기에 대비되는 상기 검색 영역의 제2 크기의 조정 비율에 따라, 상기 신경망 모델의 복수의 네트워크 경로들 중 어느 하나의 네트워크 경로를 선택하고, 상기 선택된 네트워크 경로 별로 상기 검색 영역의 크기를 리사이징하여 상기 입력 영상에서 상기 대상 객체에 대응하는 제2 타겟 박스의 위치를 추정함으로써 상기 대상 객체에 대한 오토 포커싱(auto focusing) 및 오토 줌(auto zooming) 중 적어도 하나의 동작을 수행하는 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 프로세서는 상기 제1 크기와 상기 제2 크기 간의 상기 조정 비율을 산출하고, 상기 조정 비율과 설정된 임계치 간의 비교 결과에 따라, 상기 복수의 네트워크 경로들 중 상기 조정 비율에 따라 정해진 어느 하나의 네트워크 경로를 선택하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 프로세서는 상기 조정 비율이 상기 임계치보다 큰 경우, 제1 커널 사이즈에 대응하는 제1 네트워크 경로를 선택하고, 상기 조정 비율이 상기 임계치와 같은 경우, 상기 제1 커널 사이즈보다 큰 제2 커널 사이즈에 대응하는 제2 네트워크 경로를 선택하며, 상기 조정 비율이 상기 임계치보다 작은 경우, 상기 제2 커널 사이즈보다 큰 제3 커널 사이즈에 대응하는 제3 네트워크 경로를 선택하는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420190527203</code><country>대한민국</country><engName>SONG, Ju Hwan</engName><name>송주환</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420200167444</code><country>대한민국</country><engName>PARK, Chang Beom</engName><name>박창범</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code>420170743681</code><country>대한민국</country><engName>YOO BYUNG IN</engName><name>유병인</name></inventorInfo><inventorInfo><address>경기도 수원시 권선구...</address><code>420190482041</code><country>대한민국</country><engName>LEE, Dong Wook</engName><name>이동욱</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.29</receiptDate><receiptNumber>1-1-2022-1420490-64</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.01</receiptDate><receiptNumber>9-5-2025-0959609-23</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220189388.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93682c07fb8a838fae6ce52040beab13b73a29373c0a68217c1d86e8ce93678830d45db316de6343e54e805ecc9bd1f3b8e57e40eb8b7d2ca4</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff99f7a23f3e0ea420f119d6cf18e753baee177464d5936dd502bbbf2c1ef321fc2fce3d865d2ce2e3d79e5f075bddd0697530b48eb7b4762</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>