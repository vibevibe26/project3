<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:03:50.350</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.02.04</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7020536</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>광류를 사용한 인터 예측 개선을 위한 시스템, 장치 및 방법</inventionTitle><inventionTitleEng>SYSTEMS, APPARATUS AND METHODS FOR INTER PREDICTION  REFINEMENT WITH OPTICAL FLOW</inventionTitleEng><openDate>2025.07.03</openDate><openNumber>10-2025-0100774</openNumber><originalApplicationDate>2020.02.04</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2023-7042446</originalApplicationNumber><originalExaminationRequestDate>2025.07.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.06.19</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/54</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/132</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/182</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/537</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020237042446</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법, 장치 및 시스템이 개시된다. 하나의 실시예에서, 디코딩 방법은, 비디오의 현재 블록에 대해 서브블록 기반 모션 예측 신호를 획득하는 단계; 서브블록 기반 모션 예측 신호의 하나 이상의 공간적 기울기(spatial gradients) 또는 하나 이상의 모션 벡터 차이 값을 획득하는 단계; 하나 이상의 획득된 공간적 기울기 또는 하나 이상의 획득된 모션 벡터 차이 값에 기초하여 현재 블록에 대해 개선 신호(refinement signal)를 획득하는 단계; 서브블록 기반 모션 예측 신호 및 개선 신호에 기초하여 현재 블록에 대해 개선된 모션 예측 신호를 획득하는 단계; 및 개선된 모션 예측 신호에 기초하여 현재 블록을 디코딩하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2020.08.13</internationOpenDate><internationOpenNumber>WO2020163319</internationOpenNumber><internationalApplicationDate>2020.02.04</internationalApplicationDate><internationalApplicationNumber>PCT/US2020/016564</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오를 디코딩하는 방법에 있어서, 블록과 연관된 아핀 모션 모델에 기초하여 화상(picture)의 상기 블록의 서브블록에 대해 서브블록 기반 모션 예측 신호를 생성하는 단계; 상기 블록과 연관된 상기 아핀 모션 모델을 사용하여 상기 서브블록에 대해 화소 레벨 모션 벡터 차이 값들의 세트를 결정하는 단계; 상기 서브블록의 각각의 샘플 위치에 대해, 상기 서브블록 기반 모션 예측 신호의 공간적 기울기(spatial gradient)들을 결정하는 단계 — 확장된 서브블록은 상기 서브블록 기반 모션 예측 신호 및 상기 서브블록을 둘러싸는 복수의 샘플들을 포함하도록 형성되고, 상기 서브블록을 둘러싸는 상기 복수의 샘플들의 각각은 정수 모션 보상에 기초하여 획득됨 —; 상기 결정된 화소 레벨 모션 벡터 차이 값들의 세트 및 상기 결정된 공간적 기울기들에 기초하여, 상기 서브블록에 대해 모션 예측 개선(refinement) 신호를 결정하는 단계; 상기 서브블록에 대해 개선된 모션 예측 신호를 생성하기 위해 상기 서브블록 기반 모션 예측 신호와 상기 모션 예측 개선 신호를 결합하는 단계; 및상기 개선된 모션 예측 신호를 사용하여 상기 비디오를 디코딩하는 단계를 포함하는 비디오를 디코딩하는 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 정수 부분에 기초하는 것인, 비디오를 디코딩하는 방법. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 가장 가까운 정수 모션 벡터에 기초하는 것인, 비디오를 디코딩하는 방법. </claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,  상기 확장된 서브블록을 형성하도록 상기 서브블록은 각각의 방향에서 하나의 샘플만큼 확장되는 것인, 비디오를 디코딩하는 방법. </claim></claimInfo><claimInfo><claim>5. 제1항의 방법에 따라 비디오 데이터를 디코딩하기 위한 명령어들이 저장되어 있는 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>6. 비디오를 인코딩하는 방법에 있어서, 블록과 연관된 아핀 모션 모델에 기초하여 화상(picture)의 상기 블록의 서브블록에 대해 서브블록 기반 모션 예측 신호를 생성하는 단계; 상기 블록과 연관된 상기 아핀 모션 모델을 사용하여 상기 서브블록에 대해 화소 레벨 모션 벡터 차이 값들의 세트를 결정하는 단계; 상기 서브블록의 각각의 샘플 위치에 대해, 상기 서브블록 기반 모션 예측 신호의 공간적 기울기(spatial gradient)들을 결정하는 단계 — 확장된 서브블록은 상기 서브블록 기반 모션 예측 신호 및 상기 서브블록을 둘러싸는 복수의 샘플들을 포함하도록 형성되고, 상기 서브블록을 둘러싸는 상기 복수의 샘플들의 각각은 정수 모션 보상에 기초하여 획득됨 —; 상기 결정된 화소 레벨 모션 벡터 차이 값들의 세트 및 상기 결정된 공간적 기울기들에 기초하여, 상기 서브블록에 대해 모션 예측 개선(refinement) 신호를 결정하는 단계; 상기 서브블록에 대해 개선된 모션 예측 신호를 생성하기 위해 상기 서브블록 기반 모션 예측 신호와 상기 모션 예측 개선 신호를 결합하는 단계; 및상기 개선된 모션 예측 신호를 사용하여 상기 비디오를 인코딩하는 단계를 포함하는 비디오를 인코딩하는 방법. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 정수 부분에 기초하는 것인, 비디오를 인코딩하는 방법. </claim></claimInfo><claimInfo><claim>8. 제6항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 가장 가까운 정수 모션 벡터에 기초하는 것인, 비디오를 인코딩하는 방법. </claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,  상기 확장된 서브블록을 형성하도록 상기 서브블록은 각각의 방향에서 하나의 샘플만큼 확장되는 것인, 비디오를 인코딩하는 방법. </claim></claimInfo><claimInfo><claim>10. 제6항의 방법에 따라 비디오 데이터를 인코딩하기 위한 명령어들이 저장되어 있는 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>11. 비디오를 디코딩하는 장치에 있어서, 프로세서를 포함하고, 상기 프로세서는:블록과 연관된 아핀 모션 모델에 기초하여 화상(picture)의 상기 블록의 서브블록에 대해 서브블록 기반 모션 예측 신호를 생성하고; 상기 블록과 연관된 상기 아핀 모션 모델을 사용하여 상기 서브블록에 대해 화소 레벨 모션 벡터 차이 값들의 세트를 결정하고; 상기 서브블록의 각각의 샘플 위치에 대해, 상기 서브블록 기반 모션 예측 신호의 공간적 기울기(spatial gradient)들을 결정하고 — 확장된 서브블록은 상기 서브블록 기반 모션 예측 신호 및 상기 서브블록을 둘러싸는 복수의 샘플들을 포함하도록 형성되고, 상기 서브블록을 둘러싸는 상기 복수의 샘플들의 각각은 정수 모션 보상에 기초하여 획득됨 —; 상기 결정된 화소 레벨 모션 벡터 차이 값들의 세트 및 상기 결정된 공간적 기울기들에 기초하여, 상기 서브블록에 대해 모션 예측 개선(refinement) 신호를 결정하고; 상기 서브블록에 대해 개선된 모션 예측 신호를 생성하기 위해 상기 서브블록 기반 모션 예측 신호와 상기 모션 예측 개선 신호를 결합하고; 상기 개선된 모션 예측 신호를 사용하여 상기 비디오를 디코딩하도록구성되는 것인, 비디오를 디코딩하는 장치. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 정수 부분에 기초하는 것인, 비디오를 디코딩하는 장치. </claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 가장 가까운 정수 모션 벡터에 기초하는 것인, 비디오를 디코딩하는 장치. </claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 확장된 서브블록을 형성하도록 상기 서브블록은 각각의 방향에서 하나의 샘플만큼 확장되는 것인, 비디오를 디코딩하는 장치. </claim></claimInfo><claimInfo><claim>15. 비디오를 인코딩하는 장치에 있어서, 프로세서를 포함하고, 상기 프로세서는:블록과 연관된 아핀 모션 모델에 기초하여 화상(picture)의 상기 블록의 서브블록에 대해 서브블록 기반 모션 예측 신호를 생성하고; 상기 블록과 연관된 상기 아핀 모션 모델을 사용하여 상기 서브블록에 대해 화소 레벨 모션 벡터 차이 값들의 세트를 결정하고; 상기 서브블록의 각각의 샘플 위치에 대해, 상기 서브블록 기반 모션 예측 신호의 공간적 기울기(spatial gradient)들을 결정하고 — 확장된 서브블록은 상기 서브블록 기반 모션 예측 신호 및 상기 서브블록을 둘러싸는 복수의 샘플들을 포함하도록 형성되고, 상기 서브블록을 둘러싸는 상기 복수의 샘플들의 각각은 정수 모션 보상에 기초하여 획득됨 —; 상기 결정된 화소 레벨 모션 벡터 차이 값들의 세트 및 상기 결정된 공간적 기울기들에 기초하여, 상기 서브블록에 대해 모션 예측 개선(refinement) 신호를 결정하고; 상기 서브블록에 대해 개선된 모션 예측 신호를 생성하기 위해 상기 서브블록 기반 모션 예측 신호와 상기 모션 예측 개선 신호를 결합하고; 상기 개선된 모션 예측 신호를 사용하여 상기 비디오를 인코딩하도록구성되는 것인, 비디오를 인코딩하는 장치. </claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 정수 부분에 기초하는 것인, 비디오를 인코딩하는 장치. </claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 정수 모션 보상은 상기 서브블록의 모션 벡터의 가장 가까운 정수 모션 벡터에 기초하는 것인, 비디오를 인코딩하는 장치. </claim></claimInfo><claimInfo><claim>18. 제15항에 있어서,  상기 확장된 서브블록을 형성하도록 상기 서브블록은 각각의 방향에서 하나의 샘플만큼 확장되는 것인, 비디오를 인코딩하는 장치. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 델라웨어주 윌밍턴 스위트 *** 벨뷰 파크웨이 ***</address><code>520180558519</code><country>미국</country><engName>InterDigital VC Holdings, Inc</engName><name>인터디지털 브이씨 홀딩스 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 뉴 저...</address><code> </code><country>중국</country><engName>LUO, Jiancong</engName><name>루오, 지안콩</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>HE, Yuwen</engName><name>헤, 유웬</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.02.07</priorityApplicationDate><priorityApplicationNumber>62/802,428</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.03.06</priorityApplicationDate><priorityApplicationNumber>62/814,611</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.04.15</priorityApplicationDate><priorityApplicationNumber>62/833,999</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.06.19</receiptDate><receiptNumber>1-1-2025-0688104-53</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.07.21</receiptDate><receiptNumber>1-1-2025-0822141-43</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257020536.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338e49576747ae5d87330ff13fd6c4376ed1b2b29a428c8b91320a337939e075f55cd8922233d5efcaab2d444d6543ec4242585ed27fc5539b45</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd1decb79741282ebd010c37a30f5f058dd63fb21df47ef4f03c156c7c209b7976d0a40596c0224e030adc8e8f3d5a1a21f4e6bc8242003fa</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>