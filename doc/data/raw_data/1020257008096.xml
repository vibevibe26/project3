<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:23:05.235</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7008096</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>데이터 처리 방법 및 장치, 엔티티 링킹 방법 및 장치, 및 컴퓨터 디바이스</inventionTitle><inventionTitleEng>DATA PROCESSING METHOD AND APPARATUS, ENTITY LINKING METHOD AND APPARATUS, AND COMPUTER DEVICE</inventionTitleEng><openDate>2025.04.03</openDate><openNumber>10-2025-0047390</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.11</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/432</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/45</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/41</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/279</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/36</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/901</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 데이터 처리 방법으로서, 제1 훈련 샘플을 취득하는 단계(402) - 제1 훈련 샘플은 제1 훈련 엔티티에 대응하는 시맨틱 특징 데이터와 훈련 콘텐츠 데이터를 포함함 -; 제1 컨텍스트 인코딩 모듈에 의해 훈련 콘텐츠 데이터를 인코딩하여, 제1 훈련 엔티티에 대응하는 제1 컨텍스트 특징 표현을 획득하는 단계(404); 훈련될 제1 엔티티 인코딩 모델에 의해 시맨틱 특징 데이터를 인코딩하여, 제1 훈련 엔티티에 대응하는 제1 시맨틱 특징 표현을 획득하는 단계(406); 및 제1 컨텍스트 특징 표현과 제1 시맨틱 특징 표현 사이의 유사도를 기반으로 제1 특징 표현 손실을 결정하고, 제1 특징 표현 손실을 기반으로 제1 엔티티 인코딩 모델의 모델 파라미터들을 조정하여, 제1 엔티티 인코딩 모델을 훈련시키는 단계(408)를 포함하는, 데이터 처리 방법. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.05.16</internationOpenDate><internationOpenNumber>WO2024099037</internationOpenNumber><internationalApplicationDate>2023.10.17</internationalApplicationDate><internationalApplicationNumber>PCT/CN2023/124915</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 디바이스에 의해 수행되는 데이터 처리 방법으로서,제1 훈련 샘플을 획득하는 단계 - 상기 제1 훈련 샘플은 제1 훈련 엔티티에 대응하는 시맨틱 특징 데이터와 훈련 콘텐츠 데이터를 포함하고, 상기 시맨틱 특징 데이터는 상기 제1 훈련 엔티티의 시맨틱 정보를 포함하고, 상기 훈련 콘텐츠 데이터는 상기 제1 훈련 엔티티의 컨텍스트 정보를 포함함 -;제1 컨텍스트 인코딩 모델을 사용하여 상기 훈련 콘텐츠 데이터를 인코딩하여, 상기 제1 훈련 엔티티에 대응하는 제1 컨텍스트 특징 표현을 획득하는 단계;훈련될 제1 엔티티 인코딩 모델을 사용하여 상기 시맨틱 특징 데이터를 인코딩하여, 상기 제1 훈련 엔티티에 대응하는 제1 시맨틱 특징 표현을 획득하는 단계; 및상기 제1 컨텍스트 특징 표현과 상기 제1 시맨틱 특징 표현 사이의 유사도에 기초하여 제1 특징 표현 손실을 결정하고, 상기 제1 특징 표현 손실에 기초하여 상기 제1 엔티티 인코딩 모델의 모델 파라미터를 조정하여 상기 제1 엔티티 인코딩 모델을 훈련시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 훈련 콘텐츠 데이터가 훈련 텍스트일 때, 상기 훈련 텍스트는 상기 제1 훈련 엔티티에 대응하는 엔티티 멘션(entity mention)을 포함하고; 제1 컨텍스트 인코딩 모델을 사용하여 상기 훈련 콘텐츠 데이터를 인코딩하여, 상기 제1 훈련 엔티티에 대응하는 제1 컨텍스트 특징 표현을 획득하는 단계는:상기 훈련 텍스트 내의 상기 엔티티 멘션에 경계 마크를 추가하여 타깃 훈련 텍스트를 획득하는 단계; 및상기 타깃 훈련 텍스트를 상기 제1 컨텍스트 인코딩 모델에 입력하고, 상기 제1 컨텍스트 인코딩 모델을 사용하여 상기 타깃 훈련 텍스트를 인코딩하여, 상기 제1 훈련 엔티티에 대응하는 컨텍스트 특징 표현을 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 훈련 콘텐츠 데이터가 다수의 모드(multiple modals)에서의 훈련 데이터일 때, 상기 다수의 모드에서의 훈련 데이터는 훈련 텍스트, 훈련 비디오, 또는 훈련 오디오 중 적어도 2개를 포함하고; 제1 컨텍스트 인코딩 모델을 사용하여 상기 훈련 콘텐츠 데이터를 인코딩하여, 상기 제1 훈련 엔티티에 대응하는 제1 컨텍스트 특징 표현을 획득하는 단계는:상기 다수의 모드에서의 훈련 데이터를 상기 제1 컨텍스트 인코딩 모델에 개별적으로 입력하는 단계;상기 제1 컨텍스트 인코딩 모델을 사용하여 상기 다수의 모드에서의 훈련 데이터를 개별적으로 인코딩하여, 상기 다수의 모드에 각각 대응하는 콘텐츠 특징 표현들을 획득하는 단계; 및상기 다수의 모드에 각각 대응하는 상기 콘텐츠 특징 표현들을 융합하여 상기 제1 훈련 엔티티에 대응하는 컨텍스트 특징 표현을 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,타깃 지식 그래프를 획득하고, 상기 타깃 지식 그래프의 타깃 엔티티에 대해, 상기 타깃 지식 그래프로부터 상기 타깃 엔티티를 포함하는 초기 지식 서브-그래프를 결정하는 단계;상기 초기 지식 서브-그래프 내의 각각의 노드에 대해, 상기 타깃 지식 그래프로부터 상기 노드에 대응하는 시맨틱 특징 데이터를 획득하고, 상기 노드에 대응하는 상기 시맨틱 특징 데이터를 훈련된 제1 엔티티 인코딩 모델에 입력하여, 상기 노드에 대응하는 초기 시맨틱 특징 표현을 획득하는 단계;각각의 노드에 대응하는 초기 시맨틱 특징 표현을 사용하여 상기 초기 지식 서브-그래프에 대해 벡터 초기화를 수행하여, 타깃 지식 서브-그래프를 획득하는 단계; 및훈련된 제2 엔티티 인코딩 모델을 사용하여 상기 타깃 지식 서브-그래프를 인코딩하여, 상기 타깃 엔티티에 대응하는 타깃 시맨틱 특징 표현을 획득하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제2 엔티티 인코딩 모델의 훈련 동작은:제2 훈련 샘플을 획득하는 것 - 상기 제2 훈련 샘플은 제2 훈련 엔티티에 대응하는 훈련 지식 서브-그래프와 훈련 콘텐츠 데이터를 포함하고; 상기 훈련 지식 서브-그래프는 상기 제2 훈련 엔티티를 포함하는 초기 지식 서브-그래프에 대해 벡터 초기화를 수행함으로써 획득되고, 상기 제2 훈련 엔티티를 포함하는 상기 초기 지식 서브-그래프는 상기 제2 훈련 엔티티가 위치한 지식 그래프로부터 결정됨 -;제2 컨텍스트 인코딩 모델을 사용하여, 상기 제2 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터를 인코딩하여, 상기 제2 훈련 엔티티에 대응하는 제2 컨텍스트 특징 표현을 획득하는 것;훈련될 제2 엔티티 인코딩 모델을 사용하여 상기 훈련 지식 서브-그래프를 인코딩하여, 상기 제2 훈련 엔티티에 대응하는 제2 시맨틱 특징 표현을 획득하는 것; 및상기 제2 컨텍스트 특징 표현 및 상기 제2 시맨틱 특징 표현에 기초하여 제2 특징 표현 손실을 결정하고, 상기 제2 특징 표현 손실에 기초하여 상기 훈련될 제2 엔티티 인코딩 모델의 모델 파라미터를 조정하여 상기 훈련된 제2 엔티티 인코딩 모델을 획득하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 제2 훈련 샘플을 획득하는 것은:상기 제2 훈련 엔티티에 대해, 상기 제2 훈련 엔티티가 위치한 지식 그래프로부터 상기 제2 훈련 엔티티를 포함하는 지식 서브-그래프를 결정하여, 상기 제2 훈련 엔티티에 대응하는 상기 초기 지식 서브-그래프를 획득하는 것;상기 제2 훈련 엔티티에 대응하는 상기 초기 지식 서브-그래프 내의 각각의 노드에 대해, 상기 제2 훈련 엔티티가 위치한 상기 지식 그래프로부터 상기 노드에 대응하는 시맨틱 특징 데이터를 획득하는 것;상기 노드에 대응하는 시맨틱 특징 데이터를 상기 훈련된 제1 엔티티 인코딩 모델에 입력하여, 상기 노드에 대응하는 초기 시맨틱 특징 표현을 획득하는 것;각각의 노드에 대응하는 초기 시맨틱 특징 표현을 사용하여, 상기 제2 훈련 엔티티에 대응하는 초기 지식 서브-그래프에 대해 벡터 초기화를 수행하여, 상기 제2 훈련 엔티티에 대응하는 훈련 지식 서브-그래프를 획득하는 것; 및상기 제2 훈련 엔티티에 대응하는 훈련 지식 서브-그래프 및 상기 제2 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터에 기초하여 상기 제2 훈련 엔티티에 대응하는 제2 훈련 샘플을 구성하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,제3 훈련 샘플을 획득하는 단계 - 상기 제3 훈련 샘플은 제3 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터를 포함하고; 상기 제3 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터는 상기 제3 훈련 엔티티의 컨텍스트 정보를 포함함 -;훈련될 제3 컨텍스트 인코딩 모델을 사용하여, 상기 제3 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터를 인코딩하여, 상기 제3 훈련 엔티티에 대응하는 제3 컨텍스트 특징 표현을 획득하는 단계;상기 제3 컨텍스트 특징 표현 및 상기 제3 훈련 엔티티에 대응하는 제3 시맨틱 특징 표현에 기초하여 제3 특징 표현 손실을 결정하는 단계 - 상기 제3 시맨틱 특징 표현은 상기 훈련된 제1 엔티티 인코딩 모델을 사용하여 상기 제3 훈련 엔티티에 대응하는 시맨틱 특징 데이터를 인코딩함으로써 획득됨 -; 및상기 제3 특징 표현 손실에 기초하여 상기 제3 컨텍스트 인코딩 모델의 모델 파라미터를 조정하여 상기 제3 컨텍스트 인코딩 모델을 훈련시키는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 컴퓨터 디바이스에 의해 수행되는 엔티티 링킹(entity linking) 방법으로서,타깃 콘텐츠 데이터를 결정하고, 상기 타깃 콘텐츠 데이터에 대해 엔티티 단어 인식을 수행하여 타깃 엔티티 멘션을 획득하는 단계;상기 타깃 콘텐츠 데이터를 인코딩하여 상기 타깃 엔티티 멘션에 대응하는 타깃 컨텍스트 특징 표현을 획득하는 단계;엔티티 멘션과 타깃 지식 그래프 내의 엔티티 사이의 미리 확립된 맵핑 관계에 기초하여, 상기 타깃 엔티티 멘션에 대응하는 적어도 하나의 후보 엔티티를 결정하는 단계;각각의 후보 엔티티에 대해, 상기 후보 엔티티의 타깃 시맨틱 특징 표현을 획득하는 단계 - 상기 타깃 시맨틱 특징 표현은 초기 시맨틱 특징 표현에 기초하여 획득되고, 상기 초기 시맨틱 특징 표현은, 훈련된 제1 엔티티 인코딩 모델을 사용하여, 상기 후보 엔티티에 대응하는 시맨틱 특징 데이터를 인코딩함으로써 획득됨 -; 및각각의 후보 엔티티의 상기 타깃 시맨틱 특징 표현과 상기 타깃 컨텍스트 특징 표현 사이의 유사도에 기초하여, 각각의 후보 엔티티의 신뢰도를 결정하고, 각각의 후보 엔티티의 신뢰도에 기초하여, 상기 적어도 하나의 후보 엔티티로부터 상기 타깃 엔티티 멘션에 대응하는 타깃 엔티티를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 후보 엔티티의 타깃 시맨틱 특징 표현은 엔티티 인코딩 동작을 사용하여 획득되고, 상기 엔티티 인코딩 동작은:상기 타깃 지식 그래프로부터 상기 후보 엔티티를 포함하는 지식 서브-그래프를 결정하여, 상기 후보 엔티티에 대응하는 초기 지식 서브-그래프를 획득하는 것;상기 초기 지식 서브-그래프 내의 각각의 노드에 대해, 상기 타깃 지식 그래프로부터 상기 노드에 대응하는 시맨틱 특징 데이터를 획득하는 것;상기 노드에 대응하는 시맨틱 특징 데이터를 상기 훈련된 제1 엔티티 인코딩 모델에 입력하여, 상기 노드에 대응하는 초기 시맨틱 특징 표현을 획득하는 것;각각의 노드에 대응하는 초기 시맨틱 특징 표현을 사용하여 상기 초기 지식 서브-그래프에 대해 벡터 초기화를 수행하여, 타깃 지식 서브-그래프를 획득하는 것; 및훈련된 제2 엔티티 인코딩 모델을 사용하여, 초기화에 의해 획득된 상기 타깃 지식 서브-그래프를 인코딩하여, 상기 후보 엔티티에 대응하는 타깃 시맨틱 특징 표현을 획득하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 훈련된 제2 엔티티 인코딩 모델의 훈련 동작은:제2 훈련 샘플을 획득하는 것 - 상기 제2 훈련 샘플은 상기 제2 훈련 엔티티에 대응하는 훈련 지식 서브-그래프와 훈련 콘텐츠 데이터를 포함하고; 상기 훈련 지식 서브-그래프는 상기 제2 훈련 엔티티를 포함하는 초기 지식 서브-그래프에 대해 벡터 초기화를 수행함으로써 획득되고, 상기 제2 훈련 엔티티를 포함하는 상기 초기 지식 서브-그래프는 상기 제2 훈련 엔티티가 위치한 지식 그래프로부터 결정됨 -;제2 컨텍스트 인코딩 모델을 사용하여, 상기 제2 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터를 인코딩하여, 상기 제2 훈련 엔티티에 대응하는 제2 컨텍스트 특징 표현을 획득하는 것;훈련될 제2 엔티티 인코딩 모델을 사용하여 상기 훈련 지식 서브-그래프를 인코딩하여, 상기 제2 훈련 엔티티에 대응하는 제2 시맨틱 특징 표현을 획득하는 것; 및상기 제2 컨텍스트 특징 표현 및 상기 제2 시맨틱 특징 표현에 기초하여 제2 특징 표현 손실을 결정하고, 상기 제2 특징 표현 손실에 기초하여 상기 훈련될 제2 엔티티 인코딩 모델의 모델 파라미터를 조정하여 상기 훈련된 제2 엔티티 인코딩 모델을 획득하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제8항 내지 제10항 중 어느 한 항에 있어서, 상기 타깃 콘텐츠 데이터를 인코딩하여 상기 타깃 엔티티 멘션에 대응하는 타깃 컨텍스트 특징 표현을 획득하는 것은:상기 타깃 콘텐츠 데이터를 훈련된 제3 컨텍스트 인코딩 모델에 입력하는 것; 및상기 훈련된 제3 컨텍스트 인코딩 모델을 사용하여 상기 타깃 콘텐츠 데이터를 인코딩하여, 상기 타깃 엔티티 멘션에 대응하는 타깃 컨텍스트 특징 표현을 획득하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 훈련된 제3 컨텍스트 인코딩 모델의 훈련 동작은:제3 훈련 샘플을 획득하는 것 - 상기 제3 훈련 샘플은 제3 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터를 포함하고; 상기 제3 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터는 상기 제3 훈련 엔티티의 컨텍스트 정보를 포함함 -;훈련될 제3 컨텍스트 인코딩 모델을 사용하여, 상기 제3 훈련 엔티티에 대응하는 훈련 콘텐츠 데이터를 인코딩하여, 상기 제3 훈련 엔티티에 대응하는 제3 컨텍스트 특징 표현을 획득하는 것;상기 제3 컨텍스트 특징 표현 및 상기 제3 훈련 엔티티에 대응하는 제3 시맨틱 특징 표현에 기초하여 제3 특징 표현 손실을 결정하는 것 - 상기 제3 시맨틱 특징 표현은 상기 훈련된 제1 엔티티 인코딩 모델을 사용하여 상기 제3 훈련 엔티티에 대응하는 시맨틱 특징 데이터를 인코딩함으로써 획득됨 -; 및상기 제3 특징 표현 손실에 기초하여 상기 제3 컨텍스트 인코딩 모델의 모델 파라미터를 조정하여 상기 훈련된 제3 컨텍스트 인코딩 모델을 획득하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제8항 내지 제12항 중 어느 한 항에 있어서,미리 설정된 콘텐츠 데이터베이스로부터 다수의 엔티티 멘션들을 추출하는 단계;상기 타깃 지식 그래프로부터 각각의 엔티티 멘션에 링크된 적어도 하나의 엔티티를 개별적으로 결정하는 단계;상기 엔티티 멘션에 링크된 각각의 엔티티에 대해, 상기 콘텐츠 데이터베이스에서의 상기 엔티티의 출현 횟수(a quantity of occurrence)를 카운팅하는 단계;상기 엔티티에 링크된 엔티티 멘션에 대해, 상기 엔티티 멘션에 링크된 각각의 엔티티의 출현 횟수를 카운팅하여 상기 엔티티의 카운팅 횟수(counting quantity)를 획득하는 단계; 및상기 카운팅 횟수에 대한 상기 엔티티의 출현 횟수의 비율을 계산하여, 상기 엔티티의 신뢰도 계수를 획득하고, 상기 엔티티와 상기 신뢰도 계수 사이의 맵핑 관계를 확립하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 각각의 후보 엔티티의 상기 타깃 시맨틱 특징 표현과 상기 타깃 컨텍스트 특징 표현 사이의 유사도에 기초하여, 각각의 후보 엔티티의 신뢰도를 결정하는 것은:각각의 후보 엔티티의 상기 타깃 시맨틱 특징 표현과 상기 타깃 컨텍스트 특징 표현 사이의 유사도를 개별적으로 계산하는 것; 및각각의 후보 엔티티에 대응하는 상기 유사도에 각각의 후보 엔티티에 대응하는 신뢰도 계수를 곱하여, 각각의 후보 엔티티의 신뢰도를 획득하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제8항 내지 제14항 중 어느 한 항에 있어서, 상기 훈련된 제1 엔티티 인코딩 모델은 제1 특징 표현 손실에 기초한 훈련을 통해 획득되고, 상기 제1 특징 표현 손실은 제1 컨텍스트 특징 표현 및 제1 시맨틱 특징 표현에 기초하여 결정되고, 상기 제1 컨텍스트 특징 표현은 제1 컨텍스트 인코딩 모델을 사용하여 훈련 콘텐츠 데이터를 인코딩함으로써 획득되고, 상기 훈련 콘텐츠 데이터는 제1 훈련 엔티티에 대응하는 제1 훈련 샘플에 속하고, 상기 제1 훈련 샘플은 상기 제1 훈련 엔티티에 대응하는 시맨틱 특징 데이터를 추가로 포함하고, 상기 제1 시맨틱 특징 표현은 훈련될 제1 엔티티 인코딩 모델을 사용하여 상기 제1 훈련 엔티티에 대응하는 시맨틱 특징 데이터를 인코딩함으로써 획득되고, 상기 훈련 콘텐츠 데이터는 상기 제1 훈련 엔티티의 컨텍스트 정보를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 데이터 처리 장치로서,제1 훈련 샘플을 획득하도록 구성되는 샘플 획득 모듈 - 상기 시맨틱 특징 데이터는 상기 제1 훈련 엔티티의 시맨틱 정보를 포함하고, 상기 훈련 콘텐츠 데이터는 상기 제1 훈련 엔티티의 컨텍스트 정보를 포함함 -;제1 컨텍스트 인코딩 모델을 사용하여 상기 훈련 콘텐츠 데이터를 인코딩하여, 상기 제1 훈련 엔티티에 대응하는 제1 컨텍스트 특징 표현을 획득하도록 구성되는 컨텍스트 인코딩 모듈;훈련될 제1 엔티티 인코딩 모델을 사용하여 상기 시맨틱 특징 데이터를 인코딩하여, 상기 제1 훈련 엔티티에 대응하는 제1 시맨틱 특징 표현을 획득하도록 구성되는 시맨틱 인코딩 모듈; 및상기 제1 컨텍스트 특징 표현과 상기 제1 시맨틱 특징 표현 사이의 유사도에 기초하여 제1 특징 표현 손실을 결정하고, 상기 제1 특징 표현 손실에 기초하여 상기 제1 엔티티 인코딩 모델의 모델 파라미터를 조정하여 상기 제1 엔티티 인코딩 모델을 훈련시키도록 구성되는 손실 결정 모듈을 포함하는, 데이터 처리 장치.</claim></claimInfo><claimInfo><claim>17. 엔티티 링킹 장치로서,타깃 콘텐츠 데이터를 결정하고, 상기 타깃 콘텐츠 데이터에 대해 엔티티 인식을 수행하여 타깃 엔티티 멘션을 획득하도록 구성되는 엔티티 인식 모듈;상기 타깃 콘텐츠 데이터를 인코딩하여 상기 타깃 엔티티 멘션에 대응하는 타깃 컨텍스트 특징 표현을 획득하도록 구성되는 컨텍스트 인코딩 모듈;엔티티 멘션과 타깃 지식 그래프 내의 엔티티 사이의 미리 확립된 맵핑 관계에 기초하여, 상기 타깃 엔티티 멘션에 대응하는 적어도 하나의 후보 엔티티를 결정하도록 구성되는 후보 엔티티 결정 모듈;각각의 후보 엔티티에 대해, 상기 후보 엔티티의 타깃 시맨틱 특징 표현을 획득하도록 구성되는 시맨틱 특징 획득 모듈 - 상기 타깃 시맨틱 특징 표현은 초기 시맨틱 특징 표현에 기초하여 획득되고, 상기 초기 시맨틱 특징 표현은, 훈련된 제1 엔티티 인코딩 모델을 사용하여, 상기 후보 엔티티에 대응하는 시맨틱 특징 데이터를 인코딩함으로써 획득됨 -; 및각각의 후보 엔티티의 상기 타깃 시맨틱 특징 표현과 상기 타깃 컨텍스트 특징 표현 사이의 유사도에 기초하여, 각각의 후보 엔티티의 신뢰도를 결정하고, 각각의 후보 엔티티의 신뢰도에 기초하여, 다수의 후보 엔티티로부터 상기 타깃 엔티티 멘션에 대응하는 타깃 엔티티를 결정하도록 구성되는 타깃 엔티티 결정 모듈을 포함하는, 엔티티 링킹 장치.</claim></claimInfo><claimInfo><claim>18. 컴퓨터 디바이스로서, 메모리 및 프로세서를 포함하고, 상기 메모리는 컴퓨터 판독가능 명령어들을 저장하고, 상기 프로세서는 상기 컴퓨터 판독가능 명령어들을 실행할 때 제1항 내지 제7항 또는 제8항 내지 제15항 중 어느 한 항에 따른 방법의 동작들을 구현하는, 컴퓨터 디바이스.</claim></claimInfo><claimInfo><claim>19. 컴퓨터 판독가능 명령어들이 저장된 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 명령어들은 프로세서에 의해 실행되어 제1항 내지 제7항 또는 제8항 내지 제15항 중 어느 한 항에 따른 방법의 동작들을 구현하는, 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 컴퓨터 판독가능 명령어들을 포함하는 컴퓨터 프로그램 제품으로서, 상기 컴퓨터 판독가능 명령어들은 프로세서에 의해 실행되어 제1항 내지 제7항 또는 제8항 내지 제15항 중 어느 한 항에 따른 방법의 동작들을 구현하는, 컴퓨터 프로그램 제품.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 ****** 광동 센젠 난산 디스트릭트 미드웨스트 디스트릭트 오브 하이-테크 파크 커지중이 로드 텐센트 빌딩 **층</address><code>520050388561</code><country>중국</country><engName>TENCENT TECHNOLOGY(SHENZHEN) COMPANY LIMITED</engName><name>텐센트 테크놀로지(센젠) 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>SHAN, Zifei</engName><name>산, 쯔페이</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>LI, Yuxin</engName><name>리, 위신</name></inventorInfo><inventorInfo><address>중국 ****** 광둥 선전 난산 디스트릭트 미...</address><code> </code><country>중국</country><engName>CHEN, Qian</engName><name>천, 첸</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2022.11.08</priorityApplicationDate><priorityApplicationNumber>202211391389.8</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.11</receiptDate><receiptNumber>1-1-2025-0276289-83</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.03.11</receiptDate><receiptNumber>1-1-2025-0276612-38</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.03.13</receiptDate><receiptNumber>1-5-2025-0043335-81</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257008096.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c932ca3fbd5ad424834ce28bc8dba234ae160c8e86ad378643bf796a58647a02a588783cdc1c677dfc9fe9edc6efd90b80e16d84400dfef2b2a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1cc9d96c33bed50409f7d64faf1080cbc5dc8920071b2f8186690cae736ae8f233d5bb66174d3117e4f9e523bc2358c5460f49b3585435b2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>