<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:12.112</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7028161</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사용자가 제어하는 3차원 장면</inventionTitle><inventionTitleEng>A USER CONTROLLED THREE-DIMENSIONAL SCENE</inventionTitleEng><openDate>2025.01.07</openDate><openNumber>10-2025-0002117</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.22</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 일반적으로 3차원 가상 세계 내에서 사용자가 자신의 가상 표현을 제어하기 위한 시스템 및 방법에 관한 것이다. 본 시스템 및 방법은 추출된 깊이 정보와 사용자의 2차원 이미지 또는 비디오 데이터를 활용하여 3차원 장면에서 사용자 자신의 위치를 파악할 수 있도록 한다. 또한, 사용자가 자신의 가상 표현을 포함하는 3차원 공간에서 출력된 비디오를 시각적 피드백 메커니즘으로 사용하여 자신의 가상 표현을 제어할 수 있는 제어 시스템 및 방법을 제공한다. 사용자는 장면의 다른 가상 객체 또는 아이템과 인터랙션하거나 장면에 시각화된 다른 사용자와도 인터랙션한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.07.27</internationOpenDate><internationOpenNumber>WO2023141340</internationOpenNumber><internationalApplicationDate>2023.01.23</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/011365</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 3차원 장면에서 사용자의 가상 표현을 제어하기 위한 컴퓨터 구현 방법으로서, 이미징 유닛을 사용하여 사용자를 적어도 부분적으로 캡처한 사용자의 2차원 비디오 스트림 데이터를 수신하는 단계;적어도 하나의 가상 객체와 3차원 장면 내의 해당 위치와 연관된 데이터를 포함하는 3차원 장면을 수신하는 단계;2차원 비디오 스트림 데이터에서 사용자의 사용자 표현을 분리하는 단계;2차원 비디오 스트림에서 사용자의 이미징 유닛에 대한 상대적 위치를 기반으로 식별되는 사용자의 위치 정보를 식별하는 단계; 2차원 비디오 스트림에서 사용자의 포즈 정보를 식별하는 단계;위치 정보를 사용하여, 3차원 장면을 구성하는 복셀과 연관된 데이터를 수정하여 사용자 표현을 3차원 장면에 추가하는 단계; 및3차원 장면과 추가된 사용자 표현을 디스플레이 유닛에 디스플레이하는 단계를 포함하고, 디스플레이 유닛에 디스플레이된 추가된 사용자 표현은 사용자와 위치 정보 중 적어도 하나의 변경을 감지한 것을 기반으로 제어되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,사용자의 위치 정보를 식별하는 단계는 2차원 비디오 스트림에서 깊이 정보를 추출하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,깊이 정보를 추출하는 단계는 2차원 비디오 스트림에서 깊이 단서를 인식하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,사용자 표현은 사용자의 적어도 일부의 이미지를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,사용자 표현에서 누락된 신체 부위를 감지하는 단계;데이터 저장 유닛에서 누락된 신체 부위의 표현을 추출하는 단계; 및누락된 신체 부위의 추출된 표현을 사용자 표현에 추가하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,2차원 비디오 스트림 데이터에서 사람을 감지하는 단계;감지된 사람을 의도된 사용자와 비교하는 단계; 감지된 사람이 의도된 사용자인지 판별하는 단계; 및감지된 사람이 의도된 사용자라는 판별에 응답하여 감지된 사람을 사용자로 식별하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,사용자가 수행한 제스처 또는 포즈를 감지하는 것에 대한 응답으로 추가된 사용자 표현을 업데이트하는 단계를 더 포함하고, 추가된 사용자 표현의 업데이트에는 사전 정의된 동작을 수행하는 추가된 사용자 표현이 포함되는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,사용자, 위치 정보 및 포즈 정보 중 적어도 하나의 변경에 따라 3차원 장면에서 추가된 사용자 표현을 업데이트하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,변경에는 사용자가 추가된 사용자 표현이 가상 객체와 인터랙션하도록 하는 것이 포함되는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,사용자가 추가된 사용자 표현이 가상 객체와 인터랙션하도록 하는 것에 대한 응답하여 가상 객체를 업데이트하는 단계를 더 포함하고, 가상 객체를 업데이트하는 것에는 가상 객체가 사전 정의된 동작을 수행하도록 하는 것이 포함되는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,사용자가 추가된 사용자 표현이 제스처를 디스플레이하도록 하는 것에 대한 응답하여 가상 객체를 업데이트하는 단계를 더 포함하고, 가상 객체를 업데이트하는 것에는 제스처를 감지하면 가상 객체가 사전 정의된 동작을 수행하도록 하는 것이 포함되는 방법.</claim></claimInfo><claimInfo><claim>12. 3차원 장면에서 사용자의 가상 표현을 제어하기 위한 컴퓨터 구현 방법으로서,제1 이미징 유닛을 사용하여 제1 사용자를 적어도 부분적으로 캡처한 제1 사용자의 첫 번째 2차원 비디오 스트림 데이터를 수신하는 단계;적어도 하나의 가상 객체와 3차원 장면 내의 해당 위치와 관련된 데이터가 포함된 3차원 장면을 수신하는 단계;제1 사용자의 제1 사용자 표현을 첫 번째 2차원 비디오 스트림 데이터에서 분리하는 단계;제1 사용자의 제1 이미징 유닛에 대한 상대적 위치를 기반으로 식별되는 제1 사용자의 제1 위치 정보를 첫 번째 2차원 비디오 스트림에서 식별하는 단계;제2 이미징 유닛을 사용하여 제2 사용자를 적어도 부분적으로 캡처한 제2 사용자의 두 번째 2차원 비디오 스트림 데이터를 수신하는 단계;제2 사용자의 제2 사용자 표현을 두 번째 2차원 비디오 스트림 데이터에서 분리하는 단계;2차원 비디오 스트림에서 제2 사용자의 제2 이미징 유닛에 대한 상대적 위치를 기반으로 식별되는 제2 사용자의 제2 위치 정보를 식별하는 단계;3차원 장면을 구성하는 복셀과 연관된 데이터를 수정하여 3차원 장면에 제1 및 제2 사용자 표현을 추가하는 단계; 및3차원 장면, 추가된 제1 사용자 표현, 추가된 제2 사용자 표현을 제1 디스플레이 유닛과 제2 디스플레이 유닛에 디스플레이하는 단계를 포함하고, 제1 사용자 표현과 연관된 데이터는 제1 위치 정보를 사용하고 제2 사용자 표현과 연관된 데이터는 제2 위치 정보를 사용하며, 제1 디스플레이 유닛에 디스플레이된 제1 추가된 사용자 표현은 제1 사용자와 제1 위치 정보 중 적어도 하나에 대한 변경을 감지한 것을 기반으로 제어되고, 제2 디스플레이 유닛에 디스플레이된 제2 추가된 사용자 표현은 제2 사용자와 제2 위치 정보 중 적어도 하나에 대한 변경을 감지한 것을 기반으로 제어되는 방법.</claim></claimInfo><claimInfo><claim>13. 제15항에 있어서,제2 사용자와 제2 위치 정보 중 적어도 하나의 변경에 따라 3차원 장면에서 제2 추가된 사용자 표현을 업데이트하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제16항에 있어서,변경에는 제2 사용자가 추가된 제2 사용자 표현이 추가된 제1 사용자 표현과 인터랙션하도록 하는 것이 포함되는 방법.</claim></claimInfo><claimInfo><claim>15. 3차원 장면에서 사용자의 가상 표현을 제어하기 위한 시스템으로서,사용자의 2차원 비디오 스트림 데이터를 캡처하는 이미징 유닛; 컴퓨터 판독 가능 프로그램 명령어가 저장된 저장 유닛; 및저장 유닛과 통신하여, 컴퓨터 판독 가능 프로그램 명령어를 실행하여 시스템이 적어도:이미징 유닛에서 사용자를 적어도 부분적으로 캡처한 사용자의 2차원 비디오 스트림 데이터를 수신하고, 적어도 하나의 가상 객체와 3차원 장면 내의 해당 위치와 관련된 데이터가 포함된 3차원 장면을 수신하며,2차원 비디오 스트림 데이터에서 사용자의 적어도 일부의 이미지가 포함된 사용자의 사용자 표현을 분리하고, 이미징 유닛에 대한 사용자의 상대적 위치를 기반으로 식별되고, 2차원 비디오 스트림에서 추출된 깊이 정보가 포함된 사용자의 위치 정보를 2차원 비디오 스트림에서 식별하며, 2차원 비디오 스트림에서 사용자의 포즈 정보를 식별하고,위치 정보 및 포즈 정보를 사용하여 3차원 장면을 구성하는 복셀과 관련된 데이터를 수정하여 3차원 장면에 사용자 표현을 추가하고, 3차원 장면과 추가된 사용자 표현을 디스플레이 유닛에 디스플레이하도록 구성된 프로세서를 포함하고, 디스플레이 유닛에 디스플레이된 추가된 사용자 표현은 사용자, 위치 정보 및 포즈 정보 중 적어도 하나의 변경을 감지한 것을 기반으로 제어되는 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매사추세츠 렉싱턴 허친슨 로드 *</address><code>620240578884</code><country>미국</country><engName>KUNDU, Malay</engName><name>쿤두 말레이</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 매사...</address><code>620240578884</code><country>미국</country><engName>KUNDU, Malay</engName><name>쿤두 말레이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 송파구 올림픽로 ** (잠실현대빌딩 *층)</address><code>920191002615</code><country>대한민국</country><engName>KBK &amp;amp; Associates</engName><name>특허법인(유한)케이비케이</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.01.23</priorityApplicationDate><priorityApplicationNumber>63/302,112</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.22</receiptDate><receiptNumber>1-1-2024-0916321-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2024.09.03</receiptDate><receiptNumber>1-5-2024-0144488-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[지정기간연장]기간 연장신청서·기간 단축신청서·기간 경과 구제신청서·절차 계속신청서</documentName><receiptDate>2024.11.04</receiptDate><receiptNumber>1-1-2024-1208560-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2024.11.11</receiptDate><receiptNumber>1-1-2024-1234497-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.11.12</receiptDate><receiptNumber>1-5-2024-0183531-38</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247028161.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b2b4840edc8011603429fef83441bd7799de033899ef88d1d43361288c3333052f7e49574fc43a6560371c96140e877530708352547968ad</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf29af1ed9ae3e78d6d1824514ebc1f82c0665ebdbeed803f43f7639ba43dbd1a5605883866a64f3930be151607152bb5d512a834792d35aeb</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>