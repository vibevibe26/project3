<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:55.455</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7001832</applicationNumber><claimCount>48</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다차원 공간에서 에이전트 환경의 파싱 방법</inventionTitle><inventionTitleEng>METHOD OF PARSING AN ENVIRONMENT OF AN AGENT IN A MULTI-DIMENSIONAL SPACE</inventionTitleEng><openDate>2025.03.05</openDate><openNumber>10-2025-0029888</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.01.17</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/579</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 다차원 공간에서 에이전트의 환경을 파싱하기 위한 컴퓨터 구현 방법 및 시스템으로서, 상기 에이전트의 제1 위치에서 제1 센서 데이터를 획득하는 단계; 제2 위치에서 저장된 제2 센서 데이터를 검색하는 단계; 상기 제1 센서 데이터의 복수의 제1 하위 영역을 획득하는 단계; 상기 제2 센서 데이터의 복수의 제2 하위 영역을 획득하는 단계; 상기 제2 하위 영역과 가장 유사한 제1 하위 영역을 결정하기 위해 유사도 비교 측정값을 사용하여 각각의 제1 하위 영역에 대해 상기 제2 하위 영역을 비교하는 단계; 및 상기 에이전트의 상기 제1 위치에서 상기 제2 위치로의 추정된 방향을 나타내는 동작 벡터를 획득하기 위해 연관된 상대 회전을 결정하고 상기 복수의 제2 하위 영역에 대한 상기 상대 회전을 집계하는 단계를 포함하는, 컴퓨터 구현 방법 및 시스템이 제공된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.01.11</internationOpenDate><internationOpenNumber>WO2024009081</internationOpenNumber><internationalApplicationDate>2023.07.04</internationalApplicationDate><internationalApplicationNumber>PCT/GB2023/051757</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 다차원 공간에서 에이전트의 환경을 파싱하는 컴퓨터 구현 방법으로서:에이전트의 제1 위치에서 제1 센서 데이터를 획득하는 단계로서, 상기 제1 센서 데이터는 에이전트 주위의 환경을 기술하는 단계;상기 제1 센서 데이터와 비교하기 위해 저장된 제2 센서 데이터를 검색하는 단계로서, 상기 제2 센서 데이터는 다차원 공간에서 특징을 나타내는 제2 위치 근처의 환경을 기술하는 단계;상기 제1 센서 데이터의 복수의 제1 하위 영역을 획득하는 단계로서, 상기 각각의 제1 하위 영역은 상기 제1 위치에서 상기 에이전트 주위 환경의 제1 부분을 기술하고, 상기 각각의 제1 부분은 상기 제1 위치에서 각각의 제1 방향과 연관되는 단계;상기 제2 센서 데이터의 복수의 제2 하위 영역을 획득하는 단계로서, 상기 각각의 제2 하위 영역은 상기 제2 위치 근처 환경의 제2 부분을 기술하고, 상기 각각의 제2 부분은 상기 제2 위치에서의 각각의 제2 방향과 연관되는 단계; 및 각각의 제2 하위 영역에 대해:유사도 비교 측정값을 사용하여 각각의 제1 하위 영역에 대해 제2 하위 영역을 비교하여 상기 제2 하위 영역과 가장 유사한 제1 하위 영역을 결정하는 단계;상기 제2 하위 영역과 연관된 제2 방향과 상기 가장 유사한 제1 하위 영역과 연관된 상기 제1 방향 사이의 상대 회전을 결정하는 단계를 포함하고;상기 방법은:동작 벡터를 획득하기 위해 상기 복수의 제2 하위 영역에 대한 상기 상대 회전을 집계하는 단계로서, 상기 동작 벡터는 상기 에이전트의 상기 제1 위치에서 상기 다차원 공간의 특징을 나타내는 상기 제2 위치로의 추정된 방향을 나타내는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 센서 데이터 및 상기 제2 센서 데이터는 각각 제1 및 제2 이미지 데이터이고, 상기 제1 하위 영역 각각은 상기 제1 이미지 데이터의 화소의 인접한 하위 집합을 포함하고, 상기 제2 하위 영역 각각은 상기 제2 이미지 데이터의 화소의 인접한 하위 집합을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 선행하는 항 중 어느 한 항에 있어서, 상기 제1 및 제2 센서 데이터는 상기 제1 및 제2 이미지 데이터로부터 각각 연관된 제1 벡터 및 제2 벡터로 배열되는, 방법.</claim></claimInfo><claimInfo><claim>4. 선행하는 항 중 어느 한 항에 있어서, 상기 유사도 측정값은 상기 제1 및 제2 하위 영역 사이의 내적(inner product)인, 방법.</claim></claimInfo><claimInfo><claim>5. 선행하는 항 중 어느 한 항에 있어서, 상기 제1 센서 데이터를 획득하는 단계는:상기 제1 위치에서 상기 에이전트 환경의 기존 제1 센서 데이터를 획득하는 단계;상기 제1 센서 데이터가 기존 제1 센서 데이터에 비해 축소 크기 포맷이도록, 상기 제1 센서 데이터를 획득하고자 상기 기존 제1 센서 데이터의 크기를 축소시키기 위해 상기 기존 제1 센서 데이터를 처리하는 단계를 포함하고;상기 저장된 제2 센서 데이터는 또한 상기 축소된-크기 형식으로 저장되고, 상기 방법은:상기 제2 위치에서 에이전트 환경의 기존 제2 센서 데이터를 획득하는 단계; 및상기 제2 센서 데이터를 획득하기 위해 기존 제2 센서 데이터의 크기를 축소시키기 위해 기존 제2 센서 데이터를 처리하는 단계로서, 상기 제2 센서 데이터가 상기 기존 제2 센서 데이터에 비해 축소 크기 형식이 되도록 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 기존 제1 및 기존 제2 센서 데이터를 처리하는 단계는, 상기 기존 제1 및 기존 제2 센서 데이터 각각의 차원의 크기를 각각 감소시키기 위해 상기 기존 제1 및 기존 제2 센서 데이터에 하나 이상의 필터 및/또는 마스크를 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제5항 또는 제6항에 있어서, 상기 기존 제1 및 기존 제2 센서 데이터는 각각 기존 제1 이미지 데이터 및 기존 제2 이미지 데이터인, 방법.</claim></claimInfo><claimInfo><claim>8. 선행하는 항 중 어느 한 항에 있어서, 상기 제1 센서 데이터의 복수의 제1 하위 영역을 획득하는 단계는:복수의 제1 하위 영역 각각을 추출하기 위해 제1 센서 데이터에 마스크를 반복적으로 적용하는 단계로서, 각 반복에서, 상기 마스크 또는 제1 센서 데이터는 상기 제1 센서 데이터의 하나의 차원에서의 적어도 하나의 데이터 엔트리/셀에 의해 치환되는 단계; 및 상기 제2 센서 데이터의 복수의 제2 하위 영역을 획득하는 단계는:복수의 제2 하위 영역 각각을 추출하기 위해 상기 제2 센서 데이터에 마스크를 반복적으로 적용하는 단계로서, 각 반복에서, 상기 마스크 또는 제2 센서 데이터는 상기 제2 센서 데이터의 하나의 차원에서의 적어도 하나의 데이터 엔트리/셀에 의해 치환되는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 적어도 네 개의 반복이 존재하여, 적어도 네 개의 제1 하위 영역 및 적어도 네 개의 제2 하위 영역이 존재하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제8항 또는 제9항에 있어서, 상기 마스크는 상기 제1 및 제2 센서 데이터보다 작고, 상기 마스크는 주요 차원을 포함하고, 상기 주요 차원은 상기 제1 및 제2 센서 데이터의 대응하는 주요 차원 크기의 50% 이하이거나; 또는제1 및 제2 센서 데이터의 대응하는 주요 차원 크기의 25% 이하인, 방법.</claim></claimInfo><claimInfo><claim>11. 제8항 내지 제10항 중 어느 한 항에 있어서, 상기 제1 및 제2 센서 데이터는 각각 제1 배열 및 제2 배열로 배열되고, 상기 제1 배열 및 상기 제2 배열은 X x Y 셀의 차원을 갖고, 상기 마스크는 (X-m) x Y 셀의 차원을 가지며, m은 양의 정수인, 방법.</claim></claimInfo><claimInfo><claim>12. 선행하는 항 중 어느 한 항에 있어서, 상기 방법은:동작 벡터에 따라 에이전트를 제1 위치에서 이동하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 동작 벡터에 따라 상기 에이전트를 신규 위치로 이동시키는 단계 후에,상기 에이전트의 신규 위치에서 제3 센서 데이터를 획득하는 단계로서, 상기 제3 센서 데이터는 에이전트 주위의 환경을 기술하는 단계;상기 제3 센서 데이터의 복수의 제3 하위 영역을 획득하는 단계로서, 각각의 제3 하위 영역은 상기 제3 위치에서 상기 에이전트 주위 환경의 각각의 제3 부분을 기술하고, 상기 각각의 제3 부분은 상기 제3 위치에서 각각의 제3 방향과 연관되는 단계; 및 각각의 제2 하위 영역에 대해:유사도 비교 측정값을 사용하여 상기 각각의 제3 하위 영역에 대해 상기 제2 하위 영역을 비교하여 상기 제2 하위 영역과 가장 유사한 제3 하위 영역을 결정하는 단계;상기 제2 하위 영역과 연관된 제2 방향과 가장 유사한 제3 하위 영역과 연관된 제3 방향 사이의 상대 회전을 결정하는 단계를 추가로 포함하고; 상기 방법은:갱신된 동작 벡터를 획득하기 위해 복수의 제2 하위 영역에 대한 상대 회전을 집계하고, 갱신된 동작 벡터는 에이전트의 제3 위치에서 다차원 공간의 특징을 나타내는 제2 위치로의 추정된 방향을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>14. 선행하는 항 중 어느 한 항에 있어서, 상기 방법은:관측 비교 측정값이 확인 임계값 수준과 일치하거나 초과하는 경우 다차원 공간에서 환경 특징의 존재를 확인하는 단계를 포함하고, 상기 관측 비교 측정값은 유사도 측정값 및/또는 동작 벡터와 연관되는, 방법.</claim></claimInfo><claimInfo><claim>15. 선행하는 항 중 어느 한 항에 있어서, 상기 상대 회전을 결정하는 단계는 상기 제1 방향과 상기 제2 방향 사이의 오프셋 각도를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 방법은:대향하는 쌍의 제2 하위 영역에 대해, 동작 벡터의 크기를 결정하는 단계;대향하는 쌍의 제2 하위 영역과 연관된 오프셋 각도로부터 평균 오프셋 각도를 결정하는 단계; 및평균 오프셋 각도에 기초하여 크기를 할당하는 단계를 추가로 포함하고, 상기 평균 오프셋 각도의 치수는 크기에 비례하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 제2 하위 영역의 대향하는 쌍과 연관된 오프셋 각도의 복수의 쌍 각각에 대한 각각의 크기를 결정하는 단계, 및 상기 각각의 크기들을 집계/평균하여 상기 동작 벡터의 크기를 형성하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 선행하는 항 중 어느 한 항에 있어서, 상기 제1 센서 데이터는 상기 에이전트 주위의 실질적으로 360도 시야를 나타내고, 상기 제2 센서 데이터는 상기 제2 위치 근처의 실질적으로 360도 시야를 나타내고, 상기 각각의 제1 하위 영역에 의해 기술되는 각각의 제1 부분은 상기 에이전트 주위의 360도 시야의 일부이고, 상기 각각의 제2 하위 영역에 의해 기술되는 각각의 제2 부분은 상기 제2 위치 근처의 360도 시야의 일부인, 방법.</claim></claimInfo><claimInfo><claim>19. 선행하는 항 중 어느 한 항에 있어서, 상기 복수의 제1 하위 영역 각각은 적어도 이웃하는 제1 하위 영역과 중첩하고, 상기 복수의 제2 하위 영역 각각은 적어도 이웃하는 제2 하위 영역과 중첩되는, 방법.</claim></claimInfo><claimInfo><claim>20. 선행하는 항 중 어느 한 항에 있어서, 상기 환경 특징은:다차원 공간에서 특정 위치;이미지나 그 일부; 또는 물체나 그 일부 중 어느 하나인, 방법.</claim></claimInfo><claimInfo><claim>21. 선행하는 항 중 어느 한 항에 있어서, 상기 에이전트는 가상이고, 상기 다차원 공간은 이차원 또는 삼차원 가상 공간이고, 상기 제1 센서 데이터 및 상기 제2 센서 데이터는 가상 센서를 사용하여 획득되는, 방법.</claim></claimInfo><claimInfo><claim>22. 제1항 내지 제20항 중 어느 한 항에 있어서, 상기 에이전트는 물리적 엔티티이고, 상기 다차원 공간은 삼차원 실제 물리적 공간이고, 상기 제1 센서 데이터는 물리적 센서를 사용하여 획득되는, 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 제2 센서 데이터는 상기 다차원 공간 내의 목표 위치를 나타내는 환경을 기술하여, 상기 제2 센서 데이터에 의해 기술된 상기 환경 특징이 상기 목표 위치와 연관되고, 상기 방법은:동작 벡터에 따라 에이전트를 제1 위치에서 목표 위치로 항행시키는, 방법.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 제2 센서 데이터는 제2 센서 데이터 집합의 일부를 형성하고, 상기 세트는 제2 센서 데이터의 복수의 인스턴스를 포함하고, 상기 각각의 인스턴스는 상기 다차원 공간에서 각각의 위치를 나타내는 환경을 기술하며, 상기 방법은:각 반복에서, 상기 제1 위치에서 상기 제2 센서 데이터의 복수의 인스턴스에 의해 표시된 각각의 위치의 목표 위치로 에이전트를 반복적으로 항행하고, 각 반복마다:상기 제2 데이터의 인스턴스 중 하나에 대한 동작 벡터를 획득하고 상기 동작 벡터에 따라 상기 에이전트의 위치에서 제2 데이터의 하나의 인스턴스에 의해 표시된 각각의 위치로 이동하는 단계를 수행하고;이는 상기 목표 위치에 도달할 때까지 수행되는, 방법.</claim></claimInfo><claimInfo><claim>25. 제23항 또는 제24항에 있어서, 상기 동작 벡터에 따라 상기 에이전트를 상기 제1 위치에서 상기 목표 위치로 항행하는 단계는 제1 항행 프로세스를 형성하고, 상기 방법은:제2 항행 프로세스를 사용하여 상기 에이전트를 초기 위치에서 다차원 공간의 제1 위치로 항행하는 단계; 및제2 항행 프로세스에서 제1 위치 또는 그 주위의 제1 항행 프로세스로 전환하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 제2 항행 프로세스는 위치 결정 시스템을 사용하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 위치 결정 시스템은 위성 기반 무선 항행 시스템인, 방법.</claim></claimInfo><claimInfo><claim>28. 선행하는 항 중 어느 한 항에 있어서, 상기 제2 센서 데이터는 원격 접근 가능한 데이터베이스에 저장되는, 방법.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 방법은:기록 에이전트에 의해, 상기 제2 위치에 상기 제2 센서 데이터를 기록하는 단계; 및상기 원격 접근 가능한 데이터베이스에 상기 제2 센서 데이터를 저장하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서, 상기 방법은:상기 제2 센서 데이터에 대응하는 메타데이터를 기록하고 상기 메타데이터를 상기 제2 센서 데이터와 연관시키는 단계로서, 상기 메타데이터는 상기 다차원 공간 내의 상기 제2 위치에 관한 계량값 데이터; 상기 제2 센서 데이터에서 캡처된 상기 제2 위치 근처 환경의 하나 이상의 부분의 변동성 데이터 중 적어도 하나를 포함하는 데이터;상기 제2 센서 데이터에서 캡처된 제2 위치 근처 환경의 하나 이상의 고정적 특징에 관한 데이터;상기 제2 센서 데이터의 캡처에 관한 시간적 데이터;상기 제2 위치에서 신호의 예측된 또는 기결정된 가용성을 나타내는 가용성 계량값; 및제2 센서 데이터에서 캡처된 특정 특징에 관한 데이터를 포함하는 단계를 포함하고;상기 방법은:원격 접근 가능한 데이터베이스에 대응하는 제2 센서 데이터와 함께 메타데이터를 저장하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서, 상기 메타데이터는 상기 다차원 공간 내의 상기 제2 위치에 관한 상기 계량값 데이터를 포함하고, 상기 방법은:상기 다차원 공간에서 상기 에이전트의 제1 위치에 관한 계량값 데이터를 획득하는 단계;상기 제1 위치에 관한 계량값 데이터 및 상기 제2 위치에 관한 계량값 데이터로부터, 상기 제2 위치가 제1 위치의 주위에 있는 것으로 결정하는 단계, 및상기 제2 위치가 상기 제1 위치의 근처에 있는 것으로 결정하는 것에 기초하여 상기 원격 접근 가능한 데이터베이스로부터 상기 제2 센서 데이터를 검색하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>32. 제30항 또는 제31항에 있어서, 제5항을 인용할 때, 상기 메타데이터는 상기 기존 제2 센서 데이터에서 캡처된 상기 제2 위치 근처 환경의 하나 이상의 부분의 변동성 데이터를 포함하고; 상기 기존 제2 센서 데이터의 각각의 차원의 크기를 축소시키기 위해 상기 기존 제2 센서 데이터에 상기 하나 이상의 필터 및/또는 마스크를 적용함으로써 상기 기존 제2 센서 데이터를 처리하는 단계는:상기 메타데이터에 기초하여, 상기 축소된 형식의 제2 센서 데이터가 상기 메타데이터의 데이터에 의해 표시된 환경의 하나 이상의 부분을 포함하지 않도록, 상기 기존 제2 센서 데이터에서 캡처된 제2 위치 근처 환경의 하나 이상의 부분을 필터링하거나 표시하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>33. 제30항 내지 제32항 중 어느 한 항에 있어서, 제5항을 인용할 때, 상기 메타데이터는 상기 기존 제2 센서 데이터에서 캡처된 상기 제2 위치 근처 환경의 하나 이상의 고정적 특징에 관한 데이터를 포함하고; 상기 기존 제2 센서 데이터의 각각의 차원의 크기를 축소시키기 위해 상기 기존 제2 센서 데이터에 상기 하나 이상의 필터 및/또는 마스크를 적용함으로써 상기 기존 제2 센서 데이터를 처리하는 단계는:상기 메타데이터에 기초하여, 상기 축소된 형식의 제2 센서 데이터가 메타데이터의 데이터에 의해 표시된 환경의 하나 이상의 고정적 특징을 포함하도록, 상기 기존 제2 센서 데이터에서 캡처된 제2 위치 근처 환경의 하나 이상의 고정적 특징을 유지하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>34. 제30항 내지 제33항 중 어느 한 항에 있어서, 상기 메타데이터는 상기 제2 위치에서 위치 결정 시스템 신호 및/또는 데이터 접속성 신호의 예측되거나 기결정된 가용성을 표시하는 상기 가용성 계량값을 포함하고;상기 방법은:위치 결정 시스템 신호에 따른 가용성 계량값을 기반으로 상기 에이전트를 항행시키는 단계; 및/또는:상기 데이터 연결 신호에 따라 가용성 계량값에 기초하여 원격 접근 가능한 데이터베이스로부터 데이터를 다운로드할 시기를 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>35. 제28항 내지 제34항 중 어느 한 항에 있어서, 상기 방법은:기록 에이전트에 의해, 제2 센서 데이터를 기록하기 위한 제2 위치를 선택하는 단계를 추가로 포함하고, 상기 선택은:제2 위치와 연관된 탐색 상태; 및에이전트가 제2 위치를 통과할 수 있는지 또는 통과할 수 없는지에 대한 결정 중 적어도 하나를 포함하는 위치 선택 기준에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>36. 시스템으로서:프로세서;메모리; 및센서 또는 가상 센서의 국소 영역에 다차원 공간의 환경을 기술하는 공간 데이터를 캡처하도록 구성된 센서 또는 가상 센서;프로세서에 의해 실행될 때 시스템으로 하여금 제1항 내지 제35항 중 어느 한 항의 방법을 수행하게 하는 명령어가 저장된 메모리를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서, 상기 다차원 공간은 물리적 공간이고, 상기 시스템은 상기 센서를 포함하는 로봇 또는 차량이고, 상기 로봇 또는 차량은 상기 에이전트이고, 상기 시스템은:로봇 또는 차량이 물리적 공간 내에서 이동하도록 구성된 제어 가능한 이동 모듈을 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>38. 제37항에 있어서, 상기 센서는: 자외선 이미징 장치, 카메라, LIDAR 센서, 적외선 센서, 레이더, 촉각 센서 또는 공간 데이터를 제공하도록 구성된 다른 센서 중 하나 이상을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>39. 제36항 내지 제38항 중 어느 한 항에 있어서, 상기 시스템은 복수의 장치를 포함하고, 상기 복수의 장치는 상기 로봇 또는 차량 및 추가 컴퓨팅 장치를 포함하고, 상기 추가 컴퓨팅 장치는 프로세서, 메모리 및 센서를 갖고;상기 추가 컴퓨팅 장치는 기록 에이전트이고, 상기 시스템은 제23항 내지 제30항 중 어느 한 항의 방법을 수행하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>40. 제36항에 있어서, 상기 시스템은 상기 가상 센서를 포함하는 컴퓨터 시스템이고, 상기 컴퓨터 시스템은 가상 공간 상에서 동작하도록 구성되고, 상기 에이전트는 상기 가상 공간 내의 지점에 의해 표현되는, 시스템.</claim></claimInfo><claimInfo><claim>41. 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 제1항 내지 제35항 중 어느 한 항에 따른 방법을 실행하도록 구성되는, 비일시적 컴퓨터 판독 가능 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>42. 다차원 공간에서 환경을 파싱하는 컴퓨터 구현 방법으로서:다차원 공간에서 기록 에이전트에 의해, 상기 기록 에이전트 주위의 환경을 기술하는 센서 데이터를 기록하는 단계;상기 센서 데이터에서 캡처된 환경에 존재하는 하나 이상의 특징을 식별하기 위해 상기 센서 데이터를 처리하는 단계;메타데이터를 상기 식별된 하나 이상의 특징과 연관시키는 단계로서, 상기 특징은:상기 센서 데이터가 상기 다차원 공간에서 캡처될 때의 상기 기록 에이전트의 위치;상기 기록 에이전트 주위 환경의 하나 이상의 부분의 가변성; 및상기 기록 에이전트 주위 환경의 하나 이상의 고정적 특징 중 적어도 하나를 포함하고;상기 방법은:원격 접근 가능한 데이터베이스에 센서 데이터 및 연관된 메타데이터를 저장하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>43. 제42항에 있어서, 상기 방법은:상기 다차원 공간에서 항행 에이전트에 의해, 상기 원격 접근 가능한 데이터베이스로부터 상기 저장 센서 데이터 및 연관된 메타데이터를 검색하는 단계; 상기 항행 에이전트에 의해 캡처된 센서 데이터를 상기 저장 센서 데이터와 비교함으로써, 상기 센서 데이터 및 연관된 메타데이터를 사용하여 다차원 공간을 항행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>44. 제43항에 있어서, 상기 다차원 공간을 항행하기 위해 상기 센서 데이터 및 상기 연관된 메타데이터를 사용하는 단계는 상기 연관된 메타데이터에 따라 상기 저장 센서 데이터를 축소시키는 단계를 추가로 포함하고, 상기 축소된 저장 센서 데이터는 상기 기록 에이전트의 환경에서 식별된 비가변적 또는 고정적 특징에 대응하는 센서 데이터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>45. 제42항 내지 제44항 중 어느 한 항에 있어서, 상기 방법은, 상기 연관된 메타데이터에 따라 상기 센서 데이터를 축소시키는 단계를 추가로 포함하되, 상기 단계 이전에 원격 접근 가능한 데이터베이스에 센서 데이터를 저장하는 단계를 포함하되, 상기 센서 데이터를 저장하는 단계는:상기 환경에서 식별된 비가변적 또는 고정적 특징에 대응하는 센서 데이터를 저장하고 상기 환경에서 식별된 가변적 또는 비고정적 특징에 대응하는 센서 데이터를 폐기하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>46. 제42항 내지 제45항 중 어느 한 항에 있어서, 상기 센서 데이터는 상기 기록 에이전트 주위에 파노라마를 형성하는, 방법.</claim></claimInfo><claimInfo><claim>47. 제1 컴퓨팅 장치 및 서버를 포함하는 시스템으로서, 상기 제1 컴퓨팅 장치는:프로세서;메모리; 및센서 또는 가상 센서의 국소 영역에 다차원 공간의 환경을 기술하는 공간 데이터를 캡처하도록 구성된 센서 또는 가상 센서를 포함하고;상기 서버는:원격 접근 가능한 데이터베이스가 저장된 메모리를 포함하고;상기 시스템은 제42항에 따른 방법을 수행하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>48. 제47항에 있어서, 로봇 또는 차량 또는 가상 로봇을 추가로 포함하고,프로세서;메모리; 및센서 또는 가상 센서의 국소 영역에 다차원 공간의 환경을 기술하는 공간 데이터를 캡처하도록 구성된 센서 또는 가상 센서를 포함하고;상기 로봇 또는 차량 또는 가상 로봇은 항행 에이전트이고, 상기 시스템은 제43항을 인용할 때 제43항 내지 제46항 중 어느 한 항의 방법을 수행하도록 구성되는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>영국, 사우스 요크셔, 셰필드, 포토벨로 ***, 디 이노베이션 센터 (우편번호: 에스* *디피)</address><code>520210640582</code><country>영국</country><engName>OPTERAN TECHNOLOGIES LIMITED</engName><name>옵테란 테크놀로지스 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국 사우스 요크셔 에스* ...</address><code> </code><country>영국</country><engName>COPE, Alexander John</engName><name>코프 알렉산더 존</name></inventorInfo><inventorInfo><address>영국 사우스 요크셔 에스** *에...</address><code> </code><country>영국</country><engName>KELLY, Mark Francis</engName><name>켈리 마크 프랜시스</name></inventorInfo><inventorInfo><address>영국 사우스 요크셔 에스* *디피 셰필드 포...</address><code> </code><country>영국</country><engName>JAMES, Sebastian Scott</engName><name>제임스 세바스티안 스콧</name></inventorInfo><inventorInfo><address>영국 사우스 요크셔 에스* *디피 셰필드 포...</address><code> </code><country>영국</country><engName>BLENKINSOP, Alexander</engName><name>블렌킨섭 알렉산더</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>영국</priorityApplicationCountry><priorityApplicationDate>2022.07.04</priorityApplicationDate><priorityApplicationNumber>2209825.5</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.01.17</receiptDate><receiptNumber>1-1-2025-0067721-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.02.06</receiptDate><receiptNumber>1-5-2025-0021488-42</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257001832.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e2460cc43c4912a91bf8685861b9c9337f008a44abec394d674277a8dc5b8aed5f6c04bcbaffa8925693dcae56dadf19e7b65737fee5141b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1a92421762e336f972b6b319cf47634e355d367f53700d6dc740c103450cae347388d04cb497b4ffcd94b7a8dc489434bf7bed829c9728c0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>