<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:21.221</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7021402</applicationNumber><claimCount>29</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>어시스턴트 명령의 수동적 명확화</inventionTitle><inventionTitleEng>PASSIVE DISAMBIGUATION OF ASSISTANT COMMANDS</inventionTitleEng><openDate>2023.07.25</openDate><openNumber>10-2023-0110788</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.06.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.06.23</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/295</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/9032</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0482</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04842</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에 설명된 구현은 사용자 입력에 응답할 것으로 예측되는 대체 해석(들)과 관련된 대체 어시스턴트 명령(들)에 대한 제안들을 동시에 제공하면서 사용자 입력에 응답할 것으로 예상되는 해석과 관련된 어시스턴트 명령의 실행을 초기화할 수 있는 자동화 어시스턴트에 관한 것이다. 제안된 대체 어시스턴트 명령(들)은 선택될 때 자동화 어시스턴트가 어시스턴트 명령을 실행하는 것으로부터 상기 선택된 대체 어시스턴트 명령(들)의 실행을 초기화하는 것으로 피벗(전환)할 수 있도록 선택 가능할 수 있다. 또한, 제안된 대체 어시스턴트 명령(들)은 임의의 사용자가 선택하기 전에 부분적으로 이행될 수 있다. 따라서, 본 명세서에 설명된 구현은 자동화 어시스턴트가 사용자 입력에 반응할 것으로 예상되는 어시스턴트 명령 사이에서 빠르고 효율적으로 피벗할 수 있게 할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.12.22</internationOpenDate><internationOpenNumber>WO2022265667</internationOpenNumber><internationalApplicationDate>2021.12.09</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/062610</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은,컴퓨팅 디바이스에서, 자동화 어시스턴트로 향하는 사용자의 음성 발언을 수신하는 단계와, 상기 음성 발언은 자동화 어시스턴트에 의해 이행될 어시스턴트 명령(command)을 포함하고;음성 발언에 기초하여, 음성 발언에 반응할 것으로 예측되는 복수의 해석(interpretations)을 특징짓는 어시스턴트 입력 데이터를 생성하는 단계와, 상기 해석 각각은 대응 의도, 대응 의도와 관련된 하나 이상의 대응 파라미터, 및 하나 이상의 대응 파라미터 각각에 대한 하나 이상의 대응 슬롯값을 포함하고, 그리고 각각의 해석은 적어도 하나의 고유한 대응 슬롯값을 포함하며;어시스턴트 입력 데이터에 기초하여, 복수의 해석 각각과 음성 발언에 포함된 어시스턴트 명령 사이의 예측 대응도를 특징짓는 메트릭 데이터를 생성하는 단계와;메트릭 데이터 및 어시스턴트 입력 데이터에 기초하여, 자동화 어시스턴트가 음성 발언에 포함된 어시스턴트 명령을 이행하기 위해 복수의 해석 중 제1 해석과 관련된 제1 동작의 수행을 자동으로 초기화하도록 하는 단계와; 그리고메트릭 데이터 및 어시스턴트 입력 데이터에 기초하여, 하나 이상의 선택 가능 제안 요소가 컴퓨팅 디바이스의 디스플레이 인터페이스에 렌더링되도록 하는 단계를 포함하고, 상기 하나 이상의 선택 가능 제안 요소 각각은 음성 발언에 포함된 어시스턴트 명령을 이행하기 위해 복수의 해석 중 대응하는 대체 해석과 연관되고, 상기 하나 이상의 선택 가능 제안 요소 중 주어진 선택 가능 제안 요소의 사용자 선택은 자동화 어시스턴트가 주어진 선택 가능 제안 요소와 관련된 대응하는 대체 동작의 수행을 초기화하도록 하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 자동화 어시스턴트가 음성 발언에 포함된 어시스턴트 명령을 이행하기 위해 제1 동작의 수행을 자동으로 초기화하도록 하는 단계는,제1 애플리케이션으로 하여금 특정 컨텐츠의 인스턴스를 생성하게 하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,자동화 어시스턴트가 음성 발언에 포함된 어시스턴트 명령을 이행하기 위해 제1 동작의 수행을 자동으로 초기화하도록 하는 것에 응답하여:자동 음성 인식(ASR) 프로세스 또는 자연어 이해(NLU) 프로세스가 하나 이상의 선택 가능 제안 요소와 관련된 컨텐츠에 바이어스(bias)되도록 하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>4. 임의의 선행하는 항에 있어서,메트릭 데이터 및 어시스턴트 입력 데이터에 기초하여, 자동화 어시스턴트가 하나 이상의 선택 가능 제안 요소와 관련된 대응하는 대체 동작을 이행하기 위한 준비를 촉진하기 위해 애플리케이션 데이터에 액세스하도록 하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>5. 임의의 선행하는 항에 있어서,음성 발언에 기초하여, 복수의 해석과 관련된 대응 파라미터 중 하나 이상에 대한 대응 슬롯 값 중 하나 이상이 음성 발언을 통해 사용자에 의해 지정되지 않았다고 결정하는 단계를 더 포함하고, 상기 자동화 어시스턴트는 제1 해석과 관련된 대응 파라미터 중 하나 이상에 대한 특정 슬롯 값을 추론하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,음성 발언에 기초하여, 각각의 대응하는 대체 해석에 대한 대안적인 특정 슬롯 값을 추론하는 단계를 더 포함하고, 상기 주어진 선택 가능 제안 요소의 사용자 선택은 대체 동작이 대안적인 특정 슬롯 값을 사용하여 초기화되게 하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 특정 슬롯 값은 특정 컨텐츠를 렌더링하기 위한 제1 애플리케이션을 식별하고, 그리고상기 대안적인 특정 슬롯 값은 대안적인 특정 컨텐츠를 렌더링하기 위한 다른 제2 애플리케이션을 식별하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서, 상기 특정 슬롯 값은 특정 컨텐츠를 렌더링하기 위한 제1 엔티티 참조를 식별하고, 그리고상기 대안적인 특정 슬롯 값은 대안적인 특정 컨텐츠를 렌더링하기 위한 다른 제2 엔티티 참조를 식별하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>9. 임의의 선행하는 항에 있어서, 상기 하나 이상의 선택 가능 제안 요소가 컴퓨팅 디바이스의 디스플레이 인터페이스에 렌더링되도록 하는 단계는,자동화 어시스턴트가 음성 발언에 포함된 어시스턴트 명령을 이행하기 위해 제1 동작의 수행을 자동으로 초기화하도록 한 후에 하나 이상의 선택 가능 제안 요소가 임계 기간 동안 컴퓨팅 디바이스의 디스플레이 인터페이스에 렌더링되도록 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>10. 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은,컴퓨팅 디바이스에서, 자동화 어시스턴트로 향하는 사용자의 음성 발언을 수신하는 단계와, 상기 음성 발언은 자동화 어시스턴트에 의해 이행될 어시스턴트 명령을 포함하고;음성 발언에 기초하여, 제1 동작이 어시스턴트 명령을 충족시킬 것으로 예측되는 정도를 특징짓는 제1 메트릭과 제2 동작이 어시스턴트 명령을 충족시킬 것으로 예측되는 다른 정도를 특징짓는 제2 메트릭을 식별하는 메트릭 데이터를 생성하는 단계와;제1 동작 및 제2 동작에 기초하여, 음성 발언에 응답하는 어시스턴트 GUI를 특징짓는 그래픽 사용자 인터페이스(GUI) 데이터를 생성하는 단계와, 상기 GUI 데이터는 제1 선택 가능 엘리먼트 및 제2 선택 가능 엘리먼트를 식별하기 위해 생성되고, 그리고 상기 제1 선택 가능 엘리먼트는 제1 동작의 수행을 제어하도록 선택 가능하고, 상기 제2 선택 가능 엘리먼트는 제2 동작의 수행을 자동으로 초기화하도록 선택 가능하며;음성 발언을 수신하는 것에 응답하여, 자동화 어시스턴트가 제1 동작의 수행을 자동으로 초기화하도록 하는 단계와; 그리고컴퓨팅 디바이스의 디스플레이 인터페이스가 GUI 데이터 및 메트릭 데이터에 따라 어시스턴트 GUI를 렌더링하도록 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 어시스턴트 GUI에서, 제1 동작이 어시스턴트 명령을 충족할 것으로 예측되는 정도가 제2 동작이 어시스턴트 명령을 충족할 것으로 예측되는 다른 정도보다 클 때, 상기 제1 선택 가능 엘리먼트는 제2 선택 가능 엘리먼트보다 더 두드러지게 배열되는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>12. 제10항 또는 제11항에 있어서, 상기 디스플레이 인터페이스가 GUI 데이터 및 메트릭 데이터에 따라 어시스턴트 GUI를 렌더링하도록 하는 단계는,제1 선택 가능 엘리먼트가 제2 선택 가능 엘리먼트에 인접하게 배열되도록 하는 단계를 포함하고, 어시스턴트 GUI에서, 제1 동작이 어시스턴트 명령을 충족할 것으로 예측되는 정도가 제2 동작이 어시스턴트 명령을 충족할 것으로 예측되는 다른 정도보다 클 때, 상기 제1 선택 가능 엘리먼트의 제1 영역은 제2 선택 가능 엘리먼트의 제2 영역보다 큰 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>13. 제10항 내지 제12항 중 어느 한 항에 있어서, 상기 디스플레이 인터페이스가 GUI 데이터 및 메트릭 데이터에 따라 어시스턴트 GUI를 렌더링하도록 하는 단계는,제1 선택 가능 엘리먼트가 제2 선택 가능 엘리먼트에 인접하게 배열되도록 하는 단계를 포함하고,어시스턴트 GUI에서, 상기 제1 선택 가능 엘리먼트는 그 제1 선택 가능 엘리먼트에 고유하고 어시스턴트 GUI에서 제1 선택 가능 엘리먼트의 대응하는 제1 위치를 특징짓는 제1 배열 데이터에 따라 배열되고, 그리고상기 제2 선택 가능 엘리먼트는 그 제2 선택 가능 엘리먼트에 고유하고 어시스턴트 GUI에서 제2 선택 가능 엘리먼트의 대응하는 제2 위치를 특징짓는 제2 배열 데이터에 따라 배열되는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>14. 제10항 내지 제13항 중 어느 한 항에 있어서, 어시스턴트 GUI에서, 상기 제1 선택 가능 엘리먼트는 그 제1 선택 가능 엘리먼트에 고유하고 어시스턴트 GUI에서 제1 선택 가능 엘리먼트의 대응하는 제1 디스플레이 특성을 특징짓는 대응하는 제1 디스플레이 데이터에 기초하여 디스플레이되고, 그리고상기 제2 선택 가능 엘리먼트는 그 제2 선택 가능 엘리먼트에 고유하고 어시스턴트 GUI에서 제2 선택 가능 엘리먼트의 대응하는 제2 디스플레이 특성을 특징짓는 대응하는 제2 디스플레이 데이터에 기초하여 디스플레이되는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>15. 제10항 내지 제14항 중 어느 한 항에 있어서,상기 제1 동작은,컴퓨팅 디바이스에서 수행될 특정 동작이고 상기 제2 동작은 별도의 컴퓨팅 디바이스에서 수행될 특정 동작이며, 그리고 상기 제2 선택 가능 엘리먼트의 사용자 선택은,특정 동작이 별도의 컴퓨팅 디바이스에서 초기화되도록 하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>16. 제10항 내지 제15항 중 어느 한 항에 있어서, 상기 제2 선택 가능 엘리먼트는,제1 동작이 실행될 때 컴퓨팅 디바이스의 디스플레이 인터페이스에서의 터치 입력을 통해 선택 가능 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>17. 제10항 내지 제16항 중 어느 한 항에 있어서, 상기 제2 선택 가능 엘리먼트는,실행중인 제1 동작과 동시에 추가 음성 발언을 통해 선택 가능 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>18. 제10항 내지 제17항 중 어느 한 항에 있어서, 어시스턴트 GUI에서, 제2 선택 가능 엘리먼트에 대한 제1 선택 가능 엘리먼트의 렌더링의 종요도는,제1 메트릭과 제2 메트릭 사이의 차이에 기초하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 제2 선택 가능 엘리먼트는,제1 메트릭과 제2 메트릭 사이의 차이가 제안 임계값을 충족하지 않을 때 디스플레이 인터페이스에 렌더링되지 않고, 그리고상기 컴퓨팅 디바이스의 디스플레이 인터페이스에 사용자에 의해 제공되는 특정 터치 제스처는,제2 선택 가능 엘리먼트가 컴퓨팅 디바이스의 디스플레이 인터페이스에 렌더링되도록 하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>20. 하나 이상의 프로세서에 의해 구현되는 방법으로서, 상기 방법은,컴퓨팅 디바이스에서, 자동화 어시스턴트로 향하는 사용자의 음성 발언을 수신하는 단계와, 상기 음성 발언은 자동화 어시스턴트에 의해 이행될 어시스턴트 명령을 포함하고;음성 발언을 수신하는 것에 응답하여, 어시스턴트 명령을 이행하기 위해 자동화 어시스턴트에 의해 초기화될 수 있는 제1 동작을 식별하는 단계와;음성 발언에 응답하여 제1 동작의 수행을 자동으로 초기화하는 단계와;제1 동작이 음성 발언에 응답할 것으로 예측되는 정도에 기초하여, 어시스턴트 명령을 이행하기 위해 자동화 어시스턴트에 의해 초기화될 수 있는 적어도 제2 동작을 식별하는 단계와; 그리고음성 발언에 기초하여, 컴퓨팅 디바이스의 디스플레이 인터페이스가 선택될 때 자동화 어시스턴트로 하여금 제1 동작 대신에 제2 동작을 초기화하게 하는 제2 동작과 관련된 적어도 제2 선택 가능 엘리먼트를 렌더링하도록 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 어시스턴트 명령을 이행하기 위해 자동화 어시스턴트에 의해 초기화될 수 있는 적어도 제2 동작을 식별하는 단계는,제1 동작이 음성 발언에 응답할 것으로 예측되는 정도를 특징짓는 메트릭을 생성하는 단계와, 그리고메트릭이 메트릭 임계값을 충족하는지 여부를 결정하는 단계를 포함하고, 상기 자동화 어시스턴트는 메트릭이 메트릭 임계값을 만족하지 않을 때 사용자에게 제안하기 위한 적어도 제2 동작을 식별하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>22. 제20항 또는 제21항에 있어서, 상기 어시스턴트 명령을 이행하기 위해 자동화 어시스턴트에 의해 초기화될 수 있는 적어도 제2 동작을 식별하는 단계는,제1 동작이 특정 유형의 동작인지 여부를 결정하는 단계를 포함하고,상기 자동화 어시스턴트는 제1 동작이 특정 유형의 동작일 때 적어도 제2 동작을 식별하기로 결정하고, 그리고상기 식별된 제2 동작은 제1 동작의 특정 유형의 동작과 다른 유형의 동작인 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 특정 유형의 동작은,다른 사용자와의 통신을 포함하는 통신 동작을 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>24. 제20항 내지 제23항 중 어느 한 항에 있어서,제2 선택 가능 엘리먼트의 사용자 선택을 수신하는 것에 응답하여:제1 동작의 수행이 종료되도록 하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>25. 제20항 내지 제24항 중 어느 한 항에 있어서, 상기 어시스턴트 명령을 이행하기 위해 자동화 어시스턴트에 의해 초기화될 수 있는 적어도 제2 동작을 식별하는 단계는,컴퓨팅 디바이스의 디스플레이 인터페이스를 통해 사용자에게 제안하기 위해 식별할 추가 동작의 양을 결정하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 컴퓨팅 디바이스의 디스플레이 인터페이스를 통해 사용자에게 제안하기 위해 식별할 추가 동작의 양을 결정하는 단계는,컴퓨팅 디바이스의 디스플레이 인터페이스의 크기에 기초하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>27. 제25항에 있어서, 상기 컴퓨팅 디바이스의 디스플레이 인터페이스를 통해 사용자에게 제안하기 위해 식별할 추가 동작의 양을 결정하는 단계는,각각의 추가 동작이 음성 발언에 응답할 것으로 예측되는 해당 정도를 특징짓는 대응 메트릭에 기초하는 것을 특징으로 하는 하나 이상의 프로세서에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>28. 시스템으로서,적어도 하나의 프로세서; 및실행될 때 적어도 하나의 프로세서로 하여금 제1항 내지 제27항 중 어느 한 항에 대응하는 동작들을 수행하게 하는 명령들을 저장하는 메모리를 포함하는 것을 특징으로 하는 시스템.</claim></claimInfo><claimInfo><claim>29. 실행될 때 적어도 하나의 프로세서로 하여금 제1항 내지 제27항 중 어느 한 항에 대응하는 동작들을 수행하게 하는 명령들을 저장한 비-일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>BARROS, Brett</engName><name>배로스 브렛</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>GOGUELY, Theo</engName><name>고겔리 테오</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.06.16</priorityApplicationDate><priorityApplicationNumber>17/348,929</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.06.23</receiptDate><receiptNumber>1-1-2023-0694826-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.06.27</receiptDate><receiptNumber>1-5-2023-0101992-27</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.08.06</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237021402.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e9fc89530da8eb8dce29eb354f4aec68627e40469977c959c54b01d1295bce9f9f2bd4ec54955b9794db23f1abaf1de3773735ad5422fa1c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe0946c51f862c638ffeb23f150c3d0f87e74ef6055214d0bc96c21353421b70f493d69fb2917eed583b1bd0de9390cb03f1530e04f5ae55f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>