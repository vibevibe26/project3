<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:31.3931</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0188736</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>운동 데이터의 처리 방법 및 이를 수행하는 전자 장치</inventionTitle><inventionTitleEng>EXERCISE DATA PROCESSING METHOD AND ELECTRONIC DEVICE  PERFORMING THE SAME</inventionTitleEng><openDate>2024.04.12</openDate><openNumber>10-2024-0047891</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A63B 71/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A63B 24/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 실시예에 따른 데이터 처리 방법은, 사용자가 제1 운동 종목에 대응하는 운동 상태에서, 상기 사용자와 관련한 제1 센싱 데이터를 획득하는 동작, 상기 운동 종목과 상이한 적어도 하나의 운동 종목에 대응하여 제2 센싱 데이터가 학습된 기존 학습 모델 및 상기 획득한 제1 센싱 데이터에 기반하여, 신규 학습 모델을 획득하는 동작, 상기 사용자가 상기 제1 운동 종목에 대응하는 운동 상태에서, 상기 사용자와 관련한 제3 센싱 데이터를 획득하는 동작, 및 상기 획득한 제3 센싱 데이터 및 상기 생성한 신규 학습 모델에 기반하여, 상기 제1 운동 종목에 대응하는 피드백을 상기 사용자에게 제공하는 동작을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 운동 데이터의 처리 방법에 있어서,사용자가 제1 운동 종목에 대응하는 운동 상태에서, 상기 사용자와 관련한 제1 센싱 데이터를 획득하는 동작(420);상기 제1 운동 종목과 상이한 적어도 하나의 운동 종목에 대응하여 제2 센싱 데이터가 학습된 기존 학습 모델(A; M1) 및 상기 획득한 제1 센싱 데이터에 기반하여, 신규 학습 모델(A'+B; M2)을 획득하는 동작(440);상기 사용자가 상기 제1 운동 종목에 대응하는 운동 상태에서, 상기 사용자와 관련한 제3 센싱 데이터를 획득하는 동작(450); 및상기 획득한 제3 센싱 데이터 및 상기 생성한 신규 학습 모델(A'+B; M2)에 기반하여, 상기 제1 운동 종목에 대응하는 피드백을 상기 사용자에게 제공하는 동작(470)을 포함하는,처리 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제1 운동 종목에 대응하는 동작을 지정된 횟수로 반복하도록 상기 사용자에게 노티피케이션을 제공하는 동작(415)을 더 포함하는,처리 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항 내지 제 2 항 중 어느 하나의 항에 있어서,상기 제1 센싱 데이터를 획득하는 동작(420)은,상기 사용자의 모션 데이터, 상기 사용자의 사운드 데이터 또는 상기 사용자의 생체 데이터 중 적어도 하나 이상을 획득하는,처리 방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항 내지 제 3 항 중 어느 하나의 항에 있어서,상기 제1 센싱 데이터를 획득하는 동작(420)은,상기 사용자에 장착된 상태로 상기 제1 센싱 데이터를 감지하는 외부 전자 장치(102)로부터, 상기 제1 센싱 데이터를 수신하는,처리 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항 내지 제 4 항 중 어느 하나의 항에 있어서,상기 제2 센싱 데이터는, 상기 제1 센싱 데이터와 대응되는 종류의 데이터이고,상기 기존 학습 모델(A; M1)은, 상기 제2 센싱 데이터로부터 상기 적어도 하나의 운동 종목의 반복되는 동작의 패턴이 기계 학습된,처리 방법.</claim></claimInfo><claimInfo><claim>6. 제 1 항 내지 제 5 항 중 어느 하나의 항에 있어서,상기 신규 학습 모델(A'+B; M2)을 획득하는 동작(440)은, 상기 기존 학습 모델(A; M1)에 기반하여 상기 제2 센싱 데이터 및 상기 제1 센싱 데이터를 함께 학습하여 상기 신규 학습 모델(A'+B; M2)을 생성하는,처리 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항 내지 제 5 항 중 어느 하나의 항에 있어서,상기 신규 학습 모델(A'+B; M2)을 획득하는 동작(440)은, 상기 기존 학습 모델(A; M1)에 기반하여, 데이터의 유사성에 따라 상기 제1 센싱 데이터에 포함된 패턴을 구분하도록 학습하는,처리 방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항 내지 제 7 항 중 어느 하나의 항에 있어서,상기 신규 학습 모델(A'+B; M2)을 획득하는 동작(440)은,상기 획득한 제1 센싱 데이터를 서버 또는 외부 장치로 전송하고, 상기 획득한 제1 센싱 데이터 및 상기 기존 학습 모델(A; M1)에 기반하여 생성된 상기 신규 학습 모델(A'+B; M2)을 상기 서버 또는 상기 외부 장치로부터 수신하는,처리 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항 내지 제 8 항 중 어느 하나의 항에 있어서,상기 제3 센싱 데이터는, 상기 제1 센싱 데이터와 대응되는 종류이고,상기 피드백을 제공하는 동작(470)은, 상기 획득한 제3 센싱 데이터 및 상기 생성한 신규 학습 모델(A'+B; M2)에 기반하여, 상기 제1 운동 종목의 반복되는 동작의 패턴을 식별하고, 상기 식별한 패턴에 기반하여 상기 피드백을 제공하는,처리 방법.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 피드백을 제공하는 동작(470)은, 상기 식별한 패턴에 기반하여 상기 제3 센싱 데이터로부터 상기 제1 운동 종목의 반복되는 동작의 횟수를 카운팅하고, 상기 카운팅 결과에 기반하여 상기 피드백을 제공하는,처리 방법.</claim></claimInfo><claimInfo><claim>11. 전자 장치(101)에 있어서,통신 인터페이스(190; 230);적어도 하나의 출력 장치(240);메모리(130; 220); 및상기 통신 인터페이스(190; 230), 상기 적어도 하나의 출력 장치(240) 및 상기 제1 메모리(130; 220)와 동작적으로 연결된 적어도 하나의 프로세서(120; 210)를 포함하고,상기 적어도 하나의 프로세서(120; 210)는:사용자가 제1 운동 종목에 대응하는 운동 상태에서, 상기 사용자와 관련한 제1 센싱 데이터를 획득하고,상기 제1 운동 종목과 상이한 적어도 하나의 운동 종목에 대응하여 제2 센싱 데이터가 학습된 기존 학습 모델(A; M1) 및 상기 획득한 적어도 하나 이상의 제1 센싱 데이터에 기반하여, 신규 학습 모델(A'+B; M2)을 획득하고,상기 사용자가 상기 제1 운동 종목에 대응하는 운동 상태에서, 상기 사용자와 관련한 제3 센싱 데이터를 획득하고,상기 획득한 제3 센싱 데이터 및 상기 생성한 신규 학습 모델(A'+B; M2)에 기반하여, 상기 적어도 하나의 출력 장치(240)를 통하여, 상기 제1 운동 종목에 대응하는 피드백을 제공하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 적어도 하나의 프로세서(120; 210)는:상기 제1 운동 종목에 대응하는 동작을 지정된 횟수로 반복하도록 노티피케이션을 상기 적어도 하나의 출력 장치(240)로 제공하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>13. 제 11 항 내지 제 12 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120; 210)는:상기 제1 센싱 데이터를 획득하는 동작(420)의 적어도 일부로, 상기 사용자의 모션 데이터, 상기 사용자의 사운드 데이터 또는 상기 사용자의 생체 데이터 중 적어도 하나 이상을 획득하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>14. 제 11 항 내지 제 13 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120; 210)는:상기 제1 센싱 데이터를 획득하는 동작(420)의 적어도 일부로, 상기 사용자에 장착된 상태로 상기 제1 센싱 데이터를 감지하는 외부 전자 장치(102)로부터, 상기 통신 인터페이스(190; 230)를 통하여, 상기 제1 센싱 데이터를 획득하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>15. 제 11 항 내지 제 14 항 중 어느 하나의 항에 있어서,상기 제2 센싱 데이터는, 상기 제1 센싱 데이터와 대응되는 종류의 데이터이고,상기 기존 학습 모델(A; M1)은, 상기 제2 센싱 데이터로부터 상기 적어도 하나의 운동 종목의 반복되는 동작의 패턴이 기계 학습된,전자 장치(101).</claim></claimInfo><claimInfo><claim>16. 제 11 항 내지 제 15 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120; 210)는:상기 신규 학습 모델(A'+B; M2)을 획득하는 동작(440)의 적어도 일부로, 상기 메모리(130; 220)에 저장된 상기 기존 학습 모델(A; M1)에 기반하여, 상기 제2 센싱 데이터 및 상기 제1 센싱 데이터를 함께 학습하여 상기 신규 학습 모델(A'+B; M2)을 생성하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서,상기 적어도 하나의 프로세서(120; 210)는:상기 신규 학습 모델(A'+B; M2)을 획득하는 동작(440)의 적어도 일부로, 상기 기존 학습 모델(A; M1)에 기반하여, 데이터의 유사성에 따라 상기 제1 센싱 데이터에 포함된 패턴을 구분하도록 학습하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>18. 제 11 항 내지 제 17 항 중 어느 하나의 항에 있어서,상기 적어도 하나의 프로세서(120; 210)는:상기 신규 학습 모델(A'+B; M2)을 획득하는 동작(440)의 적어도 일부로, 상기 통신 인터페이스(190; 230)를 통하여 상기 획득한 제1 센싱 데이터를 서버 또는 외부 장치로 전송하고, 상기 획득한 제1 센싱 데이터 및 상기 기존 학습 모델(A; M1)에 기반하여 생성된 상기 신규 학습 모델(A'+B; M2)을 상기 통신 인터페이스(190; 230)를 통하여 상기 서버 또는 상기 외부 장치로부터 수신하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>19. 제 11 항 내지 제 18 항 중 어느 하나의 항에 있어서,상기 제3 센싱 데이터는, 상기 제1 센싱 데이터와 대응되는 종류이고,상기 적어도 하나의 프로세서(120; 210)는:상기 피드백을 제공하는 동작(470)의 적어도 일부로, 상기 획득한 제3 센싱 데이터 및 상기 생성한 신규 학습 모델(A'+B; M2)에 기반하여, 상기 제1 운동 종목의 반복되는 동작의 패턴을 식별하고, 상기 식별한 패턴에 기반하여 상기 피드백을 제공하도록 설정된,전자 장치(101).</claim></claimInfo><claimInfo><claim>20. 제 19 항에 있어서,상기 적어도 하나의 프로세서(120; 210)는: 상기 피드백을 제공하는 동작(470)의 적어도 일부로, 상기 식별한 패턴에 기반하여 상기 제3 센싱 데이터로부터 상기 제1 운동 종목의 반복되는 동작의 횟수를 카운팅하고, 상기 카운팅 결과에 기반하여 상기 피드백을 제공하도록 설정된,전자 장치(101).</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Chaewoon</engName><name>박채운</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Ijae</engName><name>김이재</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Choa</engName><name>김초아</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Seonghee</engName><name>박성희</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YU, Shinik</engName><name>유신익</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 종로구 명륜동*가 ***-* 미화빌딩(이건주특허법률사무소)</address><code>920040001063</code><country>대한민국</country><engName>KIM, Jeoung-Hoon</engName><name>김정훈</name></agentInfo><agentInfo><address>서울 종로구 명륜동*가 ***-*  미화빌딩 이건주특허법률사무소</address><code>919980003398</code><country>대한민국</country><engName>LEE, Keon Joo</engName><name>이건주</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.10.05</priorityApplicationDate><priorityApplicationNumber>1020220127161</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.29</receiptDate><receiptNumber>1-1-2022-1418249-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220188736.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93ceb91d785b8d7da07f7d252e60781ed3dd5090e266ef6ee96fc97570418f4e4817b4d00d1ed8ef6377217eacf1a350d0479172e62b62768c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfafe09ec83c3258deada8628de5f878ca1da0e8b14e20d5f3eece4758b85a55a597edd2acf47c1c0e51a545513ea046ce49c25dcaa7b0eea7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>