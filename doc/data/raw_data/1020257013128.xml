<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:52.452</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7013128</applicationNumber><claimCount>17</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>두 개 이상의 이미지를 연관시키는 방법 및 시스템</inventionTitle><inventionTitleEng>METHOD AND SYSTEM FOR ASSOCIATING TWO OR MORE IMAGES</inventionTitleEng><openDate>2025.05.19</openDate><openNumber>10-2025-0069670</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.04.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.21</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06V 10/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/292</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 두 개 이상의 이미지 상의 객체를 연관시키기 위한 컴퓨터 구현 방법 및 시스템이 제공되고, 방법은 제1 이미지 센서로부터 제1 이미지를 수신하고 제2 이미지 센서로부터 제2 이미지를 수신하는 단계; 제1 이미지와 제2 이미지 사이의 대응 지점을 식별하는 단계; 식별된 대응 지점에 기초하여 제1 이미지와 제2 이미지 사이의 투영 행렬을 근사화하는 단계로서, 투영 행렬은 적어도 하나의 다항 방정식을 포함하는, 투영 행렬을 근사화하는 단계; 및 제1 이미지에서 식별된 적어도 하나의 객체를 제2 이미지에서 식별된 대응하는 객체와 연관시키는 단계를 포함한다. 시스템은 차량, 건물 또는 임의의 인프라에 장착될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.28</internationOpenDate><internationOpenNumber>WO2024061713</internationOpenNumber><internationalApplicationDate>2023.09.14</internationalApplicationDate><internationalApplicationNumber>PCT/EP2023/075215</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 두 개 이상의 이미지 상의 객체를 연관시키는 차량 시스템을 포함하는 차량으로서,상기 차량 시스템은 적어도 제1 이미지 센서(104)와 제2 이미지 센서(108), 하나 이상의 프로세서, 및 상기 하나 이상의 프로세서에 의해 실행될 실행 가능 명령어를 저장하는 메모리를 포함하고, 상기 실행 가능 명령어는 컴퓨터 구현 방법을 수행하기 위한 명령어를 포함하고, 상기 방법은, 상기 제1 이미지 센서(104)로부터 제1 이미지를 수신하고 상기 제2 이미지 센서(108)로부터 제2 이미지를 수신하는 단계;상기 제1 이미지와 상기 제2 이미지 사이의 대응 지점을 식별하는 단계;상기 식별된 대응 지점에 기초하여 상기 제1 이미지와 상기 제2 이미지 사이의 투영 행렬을 근사화하는 단계; 및상기 근사화된 투영 행렬에 적어도 기초하여 상기 제1 이미지에서 식별된 적어도 하나의 객체를 상기 제2 이미지에서 식별된 대응하는 객체와 연관시키는 단계를 포함하는, 차량.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서, 상기 하나 이상의 프로세서와 상기 메모리는 상기 하나 이상의 프로세서에 의해 실행될 실행 가능 명령어를 저장하고, 상기 실행 가능 명령어는 컴퓨터 구현 방법을 수행하기 위한 명령어를 포함하고, 상기 방법은,상기 제1 이미지 센서(104)로부터 제1 이미지를 수신하고 상기 제2 이미지 센서(108)로부터 제2 이미지를 수신하는 단계;상기 제1 이미지와 상기 제2 이미지 사이의 대응 지점을 식별하는 단계;상기 식별된 대응 지점에 기초하여 상기 제1 이미지와 상기 제2 이미지 사이의 투영 행렬을 근사화하는 단계;상기 근사화된 투영 행렬에 적어도 기초하여 상기 제1 이미지에서 식별된 적어도 하나의 객체를 상기 제2 이미지에서 식별된 대응하는 객체와 연관시키는 단계; 및식별된 객체의 위치를 하나의 공통 이미지 평면에 묘사(plotting)하는 단계로서, 상기 하나의 공통 이미지 평면은 바람직하게는 상기 차량 주변 객체의 360° 서라운드 뷰를 포함하는, 상기 식별된 객체의 위치를 하나의 공통 이미지 평면에 묘사하는 단계를 포함하는, 차량.</claim></claimInfo><claimInfo><claim>3. 두 개 이상의 이미지 상의 객체를 연관시키는 컴퓨터 구현 방법으로서,제1 이미지 센서(104)로부터 제1 이미지를 수신하고 제2 이미지 센서(108)로부터 제2 이미지를 수신하는 단계;상기 제1 이미지와 상기 제2 이미지 사이의 대응 지점을 식별하는 단계;상기 식별된 대응 지점에 기초하여 상기 제1 이미지와 상기 제2 이미지 사이의 투영 행렬을 근사화하는 단계; 및상기 근사화된 투영 행렬에 적어도 기초하여 상기 제1 이미지에서 식별된 적어도 하나의 객체를 상기 제2 이미지에서 식별된 대응하는 객체와 연관시키는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 3에 있어서, 상기 제1 이미지 센서(104) 및/또는 상기 제2 이미지 센서(108)는 어안 카메라(fisheye camera)이고/이거나, 상기 제1 이미지 센서와 상기 제2 이미지 센서는 상기 제1 이미지 센서에 의해 캡처된 장면의 적어도 하나의 제1 이미지와, 상기 제2 이미지 센서에 의해 캡처된 장면의 적어도 하나의 제2 이미지 사이에 중첩이 있도록 위치되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 3 또는 4에 있어서,상기 대응 지점은 뚜렷한 지점, 바람직하게는 정점 또는 교차점에 대응하는 지점이고/이거나,상기 대응 지점은 주요 지점(keypoint)인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 3 내지 5 중 어느 한 항에 있어서, 상기 주요 지점은 신경망, 바람직하게는 합성곱 신경망 백본과 주요 지점 추출기를 포함하는 신경망을 사용하여 선택되고, 상기 합성곱 신경망 백본은 바람직하게는 제한적 변형 가능 합성곱 모듈을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 3 내지 6 중 어느 한 항에 있어서, 상기 투영 행렬을 근사화하는 단계는 적어도 하나의 다항 방정식을 포함하는 적어도 하나의 투영 행렬을 근사화하는 단계를 포함하고, 바람직하게는 상기 적어도 하나의 다항 방정식은 n의 차수를 갖고, 식별된 대응 지점의 수는 n + 1 내지 n + 7이고, n은 2 이상의 정수이고/이거나, 바람직하게는 상기 적어도 하나의 다항 방정식은 2의 차수를 갖고, 상기 식별된 대응 지점의 수는 3 내지 9인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 청구항 3 내지 7 중 어느 한 항에 있어서, 상기 투영 행렬은 두 개의 다항 방정식, 즉 x-축 좌표에 대한 제1 다항 방정식과, y-축 좌표에 대한 제2 다항 방정식을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 3 내지 8 중 어느 한 항에 있어서, 상기 제1 이미지의 적어도 하나의 객체를 상기 제2 이미지의 대응하는 객체와 연관시키는 단계는,상기 제1 이미지의 적어도 하나의 객체와 상기 제2 이미지의 적어도 하나의 객체를 식별하는 단계;상기 제1 이미지의 적어도 하나의 제1 경계 박스(bounding box)와 상기 제2 이미지의 적어도 하나의 제2 경계 박스를 생성하는 단계로서, 상기 적어도 하나의 제1 경계 박스와 상기 적어도 하나의 제2 경계 박스 각각은 식별된 객체의 공간적 위치를 나타내는, 상기 제1 경계 박스와 제2 경계 박스를 생성하는 단계; 및상기 제1 경계 박스와 상기 대응하는 제2 경계 박스의 투영 사이의 관계에 적어도 기초하여, 각 제1 경계 박스를 대응하는 제2 경계 박스와 연관시키는 단계로서, 상기 투영은 상기 근사화된 투영 행렬에 기초하는, 상기 각 제1 경계 박스를 대응하는 제2 경계 박스와 연관시키는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 9에 있어서, 각 제1 경계 박스를 대응하는 제2 경계 박스와 연관시키는 단계는,상기 근사화된 투영 행렬에 기초하여 상기 적어도 하나의 제1 경계 박스를 상기 제2 이미지에 투영하여 상기 제2 이미지에 투영된 적어도 하나의 제1 경계 박스를 생성하는 단계로서, 각 투영된 제1 경계 박스는 상기 적어도 하나의 제1 경계 박스 중 하나에 대응하는, 상기 제2 이미지에 투영된 적어도 하나의 제1 경계 박스를 생성하는 단계;각 투영된 제1 경계 박스와 각 제2 경계 박스 사이의 관계를 결정하는 단계; 및대응하는 투영된 제1 경계 박스와 상기 대응하는 제2 경계 박스 사이의 결정된 관계에 기초하여 각 제1 경계 박스를 상기 대응하는 제2 경계 박스와 연관시키는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 청구항 10에 있어서, 각 투영된 제1 경계 박스와 각 제2 경계 박스 사이의 관계는,각 투영된 제1 경계 박스와 각 제2 경계 박스 사이의 중첩 정도; 및/또는각 투영된 제1 경계 박스와 각 제2 경계 박스 사이의 거리를 포함하고, 상기 거리는 바람직하게는 각 투영된 제1 경계 박스의 중심과 각 제2 경계 박스의 중심 사이의 거리인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 청구항 9 내지 11 중 어느 한 항에 있어서, 각 제1 경계 박스를 대응하는 제2 경계 박스와 연관시키는 단계는,상기 제1 이미지와 제2 이미지에서 식별된 각 객체의 적어도 하나의 특징을 식별하는 단계로서, 상기 적어도 하나의 특징은 바람직하게는 외관 특징 벡터인, 상기 적어도 하나의 특징을 식별하는 단계; 및상기 제1 이미지에서 식별된 각 객체의 적어도 하나의 특징을 상기 제2 이미지에서 식별된 각 객체의 적어도 하나의 특징과 비교하는 단계를 추가로 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>13. 청구항 3 내지 12 중 어느 한 항에 있어서, 식별된 객체의 위치를 하나의 공통 이미지 평면에 묘사하는 단계를 추가로 포함하고, 상기 하나의 공통 이미지 평면은 바람직하게는 상기 제1, 제2 및 추가 이미지 센서 주변의 객체의 360° 서라운드 뷰를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>14. 청구항 3 내지 13 중 어느 한 항에 있어서,상기 제1 이미지 센서와 제2 이미지 센서는 어안 카메라이고, 상기 제1 이미지 센서에 의해 캡처된 장면의 적어도 하나의 제1 이미지와, 상기 제2 이미지 센서에 의해 캡처된 장면의 적어도 하나의 제2 이미지 사이에 중첩이 있도록 위치되고;상기 대응 지점은 합성곱 신경망 백본과 주요 지점 추출기를 포함하는 신경망을 사용하여 선택되고, 상기 신경망은 장면 클래스로 분류된 이미지를 포함하는 장면 분류 데이터세트에서 훈련되고, 각 장면 클래스는 장면의 중첩 영역을 캡처하는 단일 카메라로부터 캡처된 이미지 시퀀스와, 상기 단일 카메라와 중첩되는 시야를 갖는 다른 카메라에 의해 동일한 시간 기간에 캡처된 이미지 시퀀스를 포함하고, 상기 합성곱 신경망 백본은 제한적 변형 가능 합성곱 모듈을 포함하고;상기 근사화된 투영 행렬은 x-축 좌표에 대한 제1 다항 방정식과, y-축 좌표에 대한 제2 다항 방정식을 포함하고, 상기 제1 다항 방정식과 제2 다항 방정식은 각각 2의 차수를 갖고, 식별된 대응 지점의 개수는 3이고;상기 제1 이미지에서 식별된 적어도 하나의 객체를 상기 제2 이미지에서 대응하는 식별된 객체와 연관시키는 단계는,  상기 제1 이미지의 적어도 하나의 객체와 상기 제2 이미지의 적어도 하나의 객체를 식별하는 단계; 상기 제1 이미지의 적어도 하나의 제1 경계 박스와 상기 제2 이미지의 적어도 하나의 제2 경계 박스를 생성하는 단계로서, 상기 적어도 하나의 제1 경계 박스와 적어도 하나의 제2 경계 박스 각각은 식별된 객체의 공간적 위치를 나타내는, 상기 적어도 하나의 제1 경계 박스와 적어도 하나의 제2 경계 박스를 생성하는 단계; 상기 근사화된 투영 행렬에 기초하여 상기 제2 이미지에 상기 적어도 하나의 제1 경계 박스를 투영하여 상기 제2 이미지에 투영된 적어도 하나의 제1 경계 박스를 생성하는 단계로서, 상기 각 투영된 제1 경계 박스는 상기 적어도 하나의 제1 경계 박스 중 하나에 대응하는, 상기 제2 이미지에 투영된 적어도 하나의 제1 경계 박스를 생성하는 단계; 각 투영된 제1 경계 박스와 각 제2 경계 박스 사이의 중첩 정도를 결정하는 단계; 및 대응하는 투영된 제1 경계 박스와 상기 대응하는 제2 경계 박스 사이의 결정된 중첩 정도에 기초하여 각 제1 경계 박스를 대응하는 제2 경계 박스와 연관시키는 단계 를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>15. 신경망, 특히 청구항 6 또는 14에 따른 신경망을 위한 훈련 데이터세트로서,상기 훈련 데이터세트는 장면 클래스로 분류된 이미지를 포함하고, 각 장면 클래스는,장면의 중첩 영역을 캡처하는 제1 이미지 센서로부터 캡처된 이미지 시퀀스;선택적으로, 상기 제1 이미지 센서와 중첩되는 시야를 갖는 다른 이미지 센서에 의해 동일한 시간 기간에 캡처된 이미지 시퀀스; 및선택적으로, 상기 제1 이미지 센서로부터 캡처된 이미지 시퀀스 및/또는 상기 제1 이미지 센서와 중첩되는 시야를 갖는 다른 이미지 센서에 의해 동일한 시간 기간에 캡처된 이미지 시퀀스로부터 변경된 이미지를 포함하는, 훈련 데이터세트.</claim></claimInfo><claimInfo><claim>16. 차량에서 사용되도록 구성된 시스템으로서,적어도 제1 이미지 센서와 제2 이미지 센서, 하나 이상의 프로세서, 및 상기 하나 이상의 프로세서에 의해 실행될 실행 가능 명령어를 저장하는 메모리를 포함하고, 상기 실행 가능 명령어는 청구항 3 내지 14 중 어느 한 항에 따른 컴퓨터 구현 방법을 수행하기 위한 명령어를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 컴퓨터 프로그램, 기계 판독 가능 저장 매체 또는 데이터 신호로서,하나 이상의 프로세서에서 실행될 때, 상기 하나 이상의 프로세서로 하여금, 청구항 3 내지 14 중 어느 한 항에 따른 컴퓨터 구현 방법의 단계를 수행하게 하는 명령어를 포함하는, 컴퓨터 프로그램, 기계 판독 가능 저장 매체 또는 데이터 신호.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>독일 ***** 잉골슈타트 링글러슈트라쎄 **</address><code>520220440062</code><country>독일</country><engName>Continental Autonomous Mobility Germany GmbH</engName><name>콘티넨탈 오토노머스 모빌리티 저머니 게엠베하</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>인도 ****** 벵갈루루 호수르 로드 보마산드라 인더스트리...</address><code> </code><country>인도</country><engName>PAWAR, Gaurav</engName><name>파와르 가우라브</name></inventorInfo><inventorInfo><address>인도 ****** 벵갈루루 호수르 로드 보마산드라 인더스트리...</address><code> </code><country>인도</country><engName>NAMBI, Pranavi</engName><name>남비 프라나비</name></inventorInfo><inventorInfo><address>인도 ****** 벵갈루루 호수르 로드 보마산드라 인더스트리...</address><code> </code><country>인도</country><engName>KANAGARAJ, Saranya</engName><name>카나가라즈 사라냐</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로***, **,**층(역삼동, 동희빌딩)</address><code>920161001010</code><country>대한민국</country><engName>AJU Kim Chang &amp; Lee</engName><name>특허법인아주김장리</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>영국</priorityApplicationCountry><priorityApplicationDate>2022.09.23</priorityApplicationDate><priorityApplicationNumber>2213945.5</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.21</receiptDate><receiptNumber>1-1-2025-0451944-97</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.21</receiptDate><receiptNumber>1-1-2025-0452308-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.04.24</receiptDate><receiptNumber>1-5-2025-0069135-54</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257013128.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93ce9754784d6c58958f9829e1021328f1e4209fc934789447955ee580716df7f272d62ec161e565930720b37ee767a22dd21d4df667d9341e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0601657871ddbb1a92f861592061b4b7cd0fb111fa31d5cdb33becaa86f99f53f5f980a9b5a7e1df526e6765afab6660a8be26b02781c3ea</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>