<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:29:42.2942</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.11.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7011936</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>3차원 가상공간 생성 방법 및 이를 구현하기 위한 단말기</inventionTitle><inventionTitleEng>METHOD FOR GENERATING THREE-DIMENSIONAL VIRTUAL SPACE AND TERMINAL FOR IMPLEMENTING SAME</inventionTitleEng><openDate>2025.07.25</openDate><openNumber>10-2025-0113389</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.11</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/51</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04815</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 금전적 및 시간적 비용을 최소한으로 하면서 전문가가 아니더라도 누구나 손쉽게 3차원 가상 공간을 생성하는 방법 및 이를 구현하기 위한 단말기에 관한 것으로서, 디스플레이, 복수의 3차원 오브젝트 모델들을 카테고리 별로 저장하는 3차원 오브젝트 모델 DB를 포함하는 메모리, 및 2차원 영상으로부터 적어도 하나의 2차원 오브젝트를 인식하고, 상기 적어도 하나의 2차원 오브젝트 각각에 대응되는 3차원 오브젝트 모델을 상기 3차원 오브젝트 모델 DB에서 검색하고, 상기 검색된 3차원 오브젝트 모델을 이용하여 상기 2차원 영상에 대응되는 3차원 가상 공간을 생성하여 디스플레이하도록 제어하는 제어부를 포함하는 사용자 단말기를 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.05.30</internationOpenDate><internationOpenNumber>WO2024111714</internationOpenNumber><internationalApplicationDate>2022.11.25</internationalApplicationDate><internationalApplicationNumber>PCT/KR2022/018890</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1.  디스플레이;복수의 3차원 오브젝트 모델들을 카테고리 별로 저장하는 3차원 오브젝트 모델 DB를 포함하는 메모리; 및2차원 영상으로부터 적어도 하나의 2차원 오브젝트를 인식하고,상기 적어도 하나의 2차원 오브젝트 각각에 대응되는 3차원 오브젝트 모델을 상기 3차원 오브젝트 모델 DB에서 검색하고,상기 검색된 3차원 오브젝트 모델을 이용하여 상기 2차원 영상에 대응되는 3차원 가상 공간을 생성하여 디스플레이하도록 제어하는 제어부;를 포함하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>2.  제 1 항에 있어서, 상기 3차원 오브젝트 모델 DB는,각 3차원 오브젝트 모델에 대응되는 복수 개의 2차원 오브젝트 모델 이미지들을 저장하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>3.  제 2 항에 있어서,각 3차원 오브젝트 모델에 대응되는 상기 복수 개의 2차원 오브젝트 모델 이미지들은 상기 각 3차원 오브젝트 모델을 서로 다른 시점에서 바라보는 2차원 이미지들인 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>4.  제 3 항에 있어서, 상기 제어부는,상기 적어도 하나의 2차원 오브젝트 중의 한 대상 2차원 오브젝트에 대응되는 대상 3차원 오브젝트 모델을 선정함에 있어서, 상기 2차원 오브젝트 모델 이미지들 중에서 상기 대상 2차원 오브젝트와 가장 매칭이 되는 2차원 모델 이미지를 검색하고, 상기 검색된 2차원 오브젝트 모델 이미지에 대응되는 3차원 오브젝트 모델을 상기 대상 3차원 오브젝트 모델로 선정하도록 제어하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>5.  제 4 항에 있어서, 상기 제어부는,Resnet(Residual neural network) 인공신경망을 이용하여 상기 2차원 오브젝트 모델 이미지들 중에서 상기 대상 2차원 오브젝트와 가장 매칭이 되는 2차원 모델 이미지를 추론하도록 제어하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>6.  제 1 항에 있어서, 상기 제어부는,상기 2차원 영상으로부터 상기 적어도 하나의 2차원 오브젝트가 존재하는 공간에 관한 공간 정보를 획득하도록 제어하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>7.  제 6 항에 있어서,상기 공간 정보는, 상기 공간의 중심, 상기 공간의 배향, 상기 공간의 사이즈, 상기 공간을 구성하는 구성요소, 및 상기 공간을 바라보는 시점 중 적어도 하나에 관한 정보를 포함하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>8.  제 6 항에 있어서, 상기 제어부는,상기 적어도 하나의 2차원 오브젝트 각각의 공간 점유 정보를 획득하도록 제어하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>9.  제 8 항에 있어서,상기 공간 점유 정보는, 각 오브젝트의 사이즈, 각 오브젝트의 중심, 각 오브젝트의 배향, 상기 공간을 바라보는 시점으로부터의 각 오브젝트의 이격 거리, 및 각 오브젝트의 상기 공간 상의 점유 위치 중 적어도 하나에 관한 정보를 포함하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>10.  제 8 항에 있어서, 상기 제어부는,상기 공간 정보 및 각 오브젝트의 상기 공간 점유 정보를 더욱 이용하여 상기 2차원 영상에 대응되는 3차원 가상 공간을 생성하도록 제어하는 것을 특징으로 하는 사용자 단말기. </claim></claimInfo><claimInfo><claim>11.  2차원 영상으로부터 적어도 하나의 2차원 오브젝트를 인식하는 단계;복수의 3차원 오브젝트 모델들을 카테고리 별로 저장하는 3차원 오브젝트 모델 DB에서 상기 적어도 하나의 2차원 오브젝트 각각에 대응되는 3차원 오브젝트 모델을 검색하는 단계; 및상기 검색된 3차원 오브젝트 모델을 이용하여 상기 2차원 영상에 대응되는 3차원 가상 공간을 생성하는 단계;를 포함하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>12.  제 11 항에 있어서, 상기 3차원 오브젝트 모델 DB는,각 3차원 오브젝트 모델에 대응되는 복수 개의 2차원 오브젝트 모델 이미지들을 저장하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>13.  제 12 항에 있어서,각 3차원 오브젝트 모델에 대응되는 상기 복수 개의 2차원 오브젝트 모델 이미지들은 상기 각 3차원 오브젝트 모델을 서로 다른 시점에서 바라보는 2차원 이미지들인 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>14.  제 13 항에 있어서,상기 적어도 하나의 2차원 오브젝트 중의 한 대상 2차원 오브젝트에 대응되는 대상 3차원 오브젝트 모델을 선정함에 있어서, 상기 2차원 오브젝트 모델 이미지들 중에서 상기 대상 2차원 오브젝트와 가장 매칭이 되는 2차원 모델 이미지를 검색하고, 상기 검색된 2차원 오브젝트 모델 이미지에 대응되는 3차원 오브젝트 모델을 상기 대상 3차원 오브젝트 모델로 선정하는 단계를 포함하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>15.  제 14 항에 있어서,Resnet(Residual neural network) 인공신경망을 이용하여 상기 2차원 오브젝트 모델 이미지들 중에서 상기 대상 2차원 오브젝트와 가장 매칭이 되는 2차원 모델 이미지를 추론하는 단계를 포함하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>16.  제 11 항에 있어서,상기 2차원 영상으로부터 상기 적어도 하나의 2차원 오브젝트가 존재하는 공간에 관한 공간 정보를 획득하는 단계를 포함하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>17.  제 16 항에 있어서,상기 공간 정보는, 상기 공간의 중심, 상기 공간의 배향, 상기 공간의 사이즈, 상기 공간을 구성하는 구성요소, 및 상기 공간을 바라보는 시점 중 적어도 하나에 관한 정보를 포함하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>18.  제 16 항에 있어서,상기 적어도 하나의 2차원 오브젝트 각각의 공간 점유 정보를 획득하는 단계를 포함하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>19.  제 18 항에 있어서,상기 공간 점유 정보는, 각 오브젝트의 사이즈, 각 오브젝트의 중심, 각 오브젝트의 배향, 상기 공간을 바라보는 시점으로부터의 각 오브젝트의 이격 거리, 및 각 오브젝트의 상기 공간 상의 점유 위치 중 적어도 하나에 관한 정보를 포함하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo><claimInfo><claim>20.  제 18 항에 있어서,상기 공간 정보 및 각 오브젝트의 상기 공간 점유 정보를 더욱 이용하여 상기 2차원 영상에 대응되는 3차원 가상 공간을 생성하는 단계를 포함하는 것을 특징으로 하는 3차원 가상 공간 생성 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 영등포구...</address><code>120020128403</code><country>대한민국</country><engName>LG Electronics Inc.</engName><name>엘지전자 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country>대한민국</country><engName>OH, Jaehong</engName><name>오재홍</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 송파구 올림픽로 ** (잠실현대빌딩 *층)</address><code>920191002615</code><country>대한민국</country><engName>KBK &amp;amp; Associates</engName><name>특허법인(유한)케이비케이</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.11</receiptDate><receiptNumber>1-1-2025-0410572-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.06.26</receiptDate><receiptNumber>1-5-2025-0106732-15</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257011936.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d41aeaf5ef5dea726b5c80ef9540238c7871dd46edadb154af111f27bd4fc423dd7d9f96887cf1e052a37b9dc1c0faa4c562fa54f0c34dfd</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9e125ac59c421ac5e6c9e80f9bd1e9573b2a11e416ead9dda43f63d5da9e10977fbc566aeda96a734da1fe64f2ff463b5b70397dc305f21a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>