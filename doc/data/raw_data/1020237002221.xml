<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:00.50</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.06.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7002221</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>확장 현실을 위한 개인 제어 인터페이스</inventionTitle><inventionTitleEng>PRIVATE CONTROL INTERFACES FOR EXTENDED REALITY</inventionTitleEng><openDate>2023.04.04</openDate><openNumber>10-2023-0044401</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.06.13</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.01.18</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04815</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G06F 21/32</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G06F 21/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/03</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/042</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 확장 현실 (XR) 경험들을 위한 개인 제어 인터페이스들을 제공하기 위한 시스템들, 방법들, 및 컴퓨터 판독가능 매체들이 개시된다. 일 예의 방법은 XR 디바이스와 연관된 물리적 환경의 맵핑된 장면 내에서 XR 디바이스의 포즈를 결정하는 것; 물리적 환경에서의 개인 영역 및 XR 디바이스의 포즈에 대한 개인 영역의 위치를 검출하는 것으로서, 개인 영역은 XR 디바이스의 사용자의 시야 (FOV) 내에 있고 그리고 물리적 환경에서의 사람, 물리적 환경 내의 기록 디바이스, 및/또는 물리적 환경에서의 오브젝트의 FOV 밖에 있는 것으로 추정되는 영역을 포함하는, 개인 영역 및 개인 영역의 위치를 검출하는 것; XR 디바이스의 포즈 및 개인 영역의 위치에 기초하여, 가상 개인 제어 인터페이스를 개인 영역에 맵핑하는 것; 및 가상 개인 제어 인터페이스를 개인 영역 내에서 렌더링하는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.02.03</internationOpenDate><internationOpenNumber>WO2022026112</internationOpenNumber><internationalApplicationDate>2021.06.30</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/039930</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 확장 현실 디바이스 상에서 동작가능한 방법으로서,상기 확장 현실 디바이스와 연관된 물리적 환경의 맵핑된 장면 내에서 상기 확장 현실 디바이스의 포즈를 결정하는 단계;상기 맵핑된 장면에서의 개인 영역 및 상기 확장 현실 디바이스의 상기 포즈에 대한 상기 개인 영역의 위치를 검출하는 단계로서, 상기 개인 영역은 상기 확장 현실 디바이스의 사용자의 시야 (field of view; FOV) 내에 있고 그리고 상기 물리적 환경에서의 사람, 상기 물리적 환경에서의 기록 디바이스, 및 상기 물리적 환경의 외부로부터 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트 중 적어도 하나의 개별적인 FOV 밖에 있는 것으로 추정되는 영역을 포함하는, 상기 개인 영역 및 상기 개인 영역의 위치를 검출하는 단계;상기 확장 현실 디바이스의 포즈 및 상기 개인 영역이 검출되는 것에 기초하여, 가상 개인 제어 인터페이스를 상기 개인 영역에 맵핑하는 단계; 및상기 맵핑된 장면에서 상기 개인 영역 내에 상기 가상 개인 제어 인터페이스를 렌더링하는 단계를 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 물리적 환경에서 하나 이상의 오브젝트들을 검출하는 것; 및상기 사람, 상기 기록 디바이스 및 상기 오브젝트 중 적어도 하나의 개별적인 FOV 가 상기 하나 이상의 오브젝트들에 의해 폐색된다고 결정하는 것에 의해 구역이 상기 물리적 환경에서 상기 사람, 상기 기록 디바이스 및 상기 오브젝트 중 적어도 하나의 개별적인 FOV 밖에 있다고 결정하는 단계를 더 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서, 상기 개인 영역을 검출하는 단계는:상기 맵핑된 장면을 캡처하는 이미지에서 검출된 제 1 안면과 연관된 인간 안면 위치 데이터를 계산하는 것으로서, 상기 제 1 안면은 사람에 대응하는, 상기 인간 안면 위치 데이터를 계산하는 것;상기 인간 안면 위치 데이터에 기초하여, 사람의 FOV 를 계산하는 것; 및상기 사람의 FOV 및 상기 개인 영역의 위치에 기초하여, 상기 개인 영역이 상기 개인 영역과 상기 사람 사이에 위치된 하나 이상의 오브젝트들에 의해 사람의 뷰로부터 폐색된다고 결정하는 것을 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서, 상기 개인 영역을 검출하는 단계는:상기 맵핑된 장면을 캡처하는 이미지에서 검출된 제 2 안면과 연관된 인간 안면 위치 데이터를 계산하는 것으로서, 상기 제 2 안면은 상기 사용자에 대응하는, 상기 인간 안면 위치 데이터를 계산하는 것;상기 제 2 안면과 연관된 상기 인간 안면 위치 데이터에 기초하여, 상기 사용자의 FOV 를 계산하는 것; 및상기 개인 영역의 위치에 기초하여, 상기 개인 영역이 상기 사용자의 FOV 내에 있다고 결정하는 것을 더 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서, 상기 가상 개인 제어 인터페이스를 상기 개인 영역에 맵핑하고 상기 개인 영역 내에 상기 가상 개인 제어 인터페이스를 렌더링하는 것은:상기 개인 영역의 제 1 사이즈 및 상기 개인 영역의 제 1 배향 중 적어도 하나를 결정하는 것;상기 개인 영역의 제 1 사이즈 및 상기 개인 영역의 제 1 배향 중 적어도 하나에 기초하여, 상기 가상 개인 제어 인터페이스의 제 2 사이즈 및 상기 가상 개인 제어 인터페이스의 제 2 배향 중 적어도 하나를 결정하는 것으로서, 상기 가상 개인 제어 인터페이스의 제 2 사이즈가 상기 개인 영역의 제 1 사이즈와 매칭하거나 또는 제 1 사이즈 내에 맞추어지고 상기 가상 개인 제어 인터페이스들의 제 2 배향은 상기 개인 영역의 제 1 배향과 적어도 부분적으로 정렬하는, 상기 제 2 사이즈 및 제 2 배향 중 적어도 하나를 결정하는 것; 상기 제 2 사이즈 및 상기 제 2 배향 중 적어도 하나에 따라 상기 가상 개인 제어 인터페이스를 생성하는 것; 및상기 가상 개인 제어 인터페이스를 상기 개인 영역과 정렬하는 것을 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>6. 제 1 항에 있어서,상기 물리적 환경의 외부로부터 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트는 윈도우, 유리 도어, 및 개방 도어 중 적어도 하나를 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서,상기 개인 영역은 상기 사용자와 연관된 신체 부분의 표면을 포함하고, 상기 개인 영역을 검출하는 단계는 상기 신체 부분의 표면이 상기 사용자를 향하고 그리고 상기 물리적 환경에서의 사람, 상기 물리적 환경에서의 기록 디바이스, 및 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트 중 적어도 하나로부터 멀리 향하고 있다고 결정하는 것을 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>8. 제 7 항에 있어서, 상기 신체 부분은 손을 포함하고, 상기 신체 부분의 표면은 손의 손바닥을 포함하고, 상기 개인 영역을 검출하는 단계는:손의 손바닥의 하나 이상의 이미지들에 기초하여, 손의 손바닥과 연관된 생체 정보를 검출하는 것; 상기 생체 정보를 사용자와 연관된 이전에 등록된 손바닥과 연관된 이전에 등록된 생체 정보와 비교하는 것; 및상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭한다고 결정하는 것을 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법. </claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서,제 2 가상 개인 제어 인터페이스를 렌더링하기 위하여 손의 손바닥을 식별하는 단계; 및손의 손바닥 위에 상기 제 2 가상 개인 제어 인터페이스를 렌더링하기 전에:  손의 손바닥의 하나 이상의 이미지들에 기초하여, 손의 손바닥과 연관된 생체 정보를 검출하는 단계;  상기 생체 정보를 사용자와 연관된 이전에 등록된 손바닥과 연관된 이전에 등록된 생체 정보와 비교하는 단계; 및 상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭하는지의 여부를 결정하는 단계를 더 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법. </claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭하지 않는다고 결정하는 단계; 및상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭하지 않는다고 결정하는 것에 응답하여, 손의 손바닥에 상기 제 2 가상 개인 제어 인터페이스를 렌더링하지 않는 것으로 결정하는 단계를 더 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서,상기 개인 영역을 검출하는 단계는:상기 맵핑된 장면에서 하나 이상의 오브젝트들을 검출하는 것; 상기 맵핑된 장면에서의 상기 하나 이상의 오브젝트들에 기초하여, 상기 맵핑된 장면에서의 하나 이상의 폐색들을 검출하는 것; 및상기 하나 이상의 폐색들이 상기 사람, 상기 기록 디바이스, 또는 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트에 의한 상기 개인 영역의 가시성을 차단한다고 결정하는 것에 의해 상기 개인 영역을 검출하는 것을 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서, 상기 하나 이상의 폐색들을 검출하는 것은 상기 물리적 환경 내의 광선의 경로를 추적하는 것을 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>13. 제 1 항에 있어서, 상기 기록 디바이스는 카메라를 포함하고, 상기 가상 개인 제어 인터페이스는 증강 현실 인터페이스를 포함하는, 확장 현실 디바이스 상에서 동작가능한 방법.</claim></claimInfo><claimInfo><claim>14. 장치로서,적어도 하나의 메모리; 및회로부로 구현되는 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은: 장치와 연관된 물리적 환경의 맵핑된 장면 내에서 장치의 포즈를 결정하고; 상기 맵핑된 장면에서의 개인 영역 및 상기 장치의 포즈에 대한 개인 영역의 위치를 검출하는 것으로서, 상기 개인 영역은 상기 장치의 사용자의 시야 (field of view; FOV) 내에 있고 그리고 상기 물리적 환경에서의 사람, 상기 물리적 환경에서의 기록 디바이스, 또는 상기 물리적 환경의 외부로부터 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트 중 적어도 하나의 개별적인 FOV 밖에 있는 것으로 추정되는 구역을 포함하는, 상기 개인 영역 및 상기 개인 영역의 위치를 검출하고; 상기 장치의 포즈 및 상기 개인 영역이 검출되는 것에 기초하여, 가상 개인 제어 인터페이스를 상기 개인 영역에 맵핑하는 것으로서, 상기 가상 개인 제어 인터페이스는 하나 이상의 입력 인터페이스 엘리먼트들을 포함하는, 상기 가상 개인 제어 인터페이스를 상기 개인 영역에 맵핑하고; 그리고 상기 맵핑된 장면에서 상기 개인 영역 내에 상기 가상 개인 제어 인터페이스를 렌더링하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서, 상기 하나 이상의 프로세서들은:상기 물리적 환경에서 하나 이상의 오브젝트들을 검출하는 것; 및상기 사람, 상기 기록 디바이스 및 상기 오브젝트 중 적어도 하나의 개별적인 FOV 가 상기 하나 이상의 오브젝트들에 의해 폐색된다고 결정하는 것에 의해 구역이 상기 물리적 환경에서 상기 사람, 상기 기록 디바이스 및 상기 오브젝트 중 적어도 하나의 개별적인 FOV 밖에 있다고 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>16. 제 14 항에 있어서, 상기 개인 영역을 검출하는 것은:상기 맵핑된 장면을 캡처하는 이미지에서 검출된 제 1 안면과 연관된 인간 안면 위치 데이터를 계산하는 것으로서, 상기 제 1 안면은 사람에 대응하는, 상기 인간 안면 위치 데이터를 계산하는 것;상기 인간 안면 위치 데이터에 기초하여, 사람의 FOV 를 계산하는 것; 및상기 사람의 FOV 및 상기 개인 영역의 위치에 기초하여, 상기 개인 영역이 상기 개인 영역과 상기 사람 사이에 위치된 하나 이상의 오브젝트들에 의해 사람의 뷰로부터 폐색된다고 결정하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서, 상기 개인 영역을 검출하는 것은:상기 맵핑된 장면을 캡처하는 이미지에서 검출된 제 2 안면과 연관된 인간 안면 위치 데이터를 계산하는 것으로서, 상기 제 2 안면은 상기 사용자에 대응하는, 상기 인간 안면 위치 데이터를 계산하는 것;상기 제 2 안면과 연관된 상기 인간 안면 위치 데이터에 기초하여, 상기 사용자의 FOV 를 계산하는 것; 및상기 개인 영역의 위치에 기초하여, 상기 개인 영역이 상기 사용자의 FOV 내에 있다고 결정하는 것을 더 포함하는, 장치.</claim></claimInfo><claimInfo><claim>18. 제 14 항에 있어서, 상기 가상 개인 제어 인터페이스를 상기 개인 영역에 맵핑하고 상기 개인 영역 내에 상기 가상 개인 제어 인터페이스를 렌더링하는 것은:상기 개인 영역의 제 1 사이즈 및 상기 개인 영역의 제 1 배향 중 적어도 하나를 결정하는 것;상기 개인 영역의 제 1 사이즈 및 상기 개인 영역의 제 1 배향 중 적어도 하나에 기초하여, 상기 가상 개인 제어 인터페이스의 제 2 사이즈 및 상기 가상 개인 제어 인터페이스의 제 2 배향 중 적어도 하나를 결정하는 것으로서, 상기 가상 개인 제어 인터페이스의 제 2 사이즈가 상기 개인 영역의 제 1 사이즈와 매칭하거나 또는 제 1 사이즈 내에 맞추어지고 상기 가상 개인 제어 인터페이스들의 제 2 배향은 상기 개인 영역의 제 1 배향과 적어도 부분적으로 정렬하는, 상기 제 2 사이즈 및 제 2 배향 중 적어도 하나를 결정하는 것; 상기 제 2 사이즈 및 상기 제 2 배향 중 적어도 하나에 따라 상기 가상 개인 제어 인터페이스를 생성하는 것; 및상기 가상 개인 제어 인터페이스를 상기 개인 영역과 정렬하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>19. 제 14 항에 있어서, 상기 물리적 환경의 외부로부터 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트는 윈도우, 유리 도어, 및 개방 도어 중 적어도 하나를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>20. 제 14 항에 있어서, 상기 개인 영역은 상기 사용자와 연관된 신체 부분의 표면을 포함하고, 상기 개인 영역을 검출하는 것은 상기 신체 부분의 표면이 상기 사용자를 향하고 그리고 상기 물리적 환경에서의 사람, 상기 물리적 환경에서의 기록 디바이스, 및 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트 중 적어도 하나로부터 멀리 향하고 있다고 결정하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서, 상기 신체 부분은 손을 포함하고, 상기 신체 부분의 표면은 손의 손바닥을 포함하고, 상기 개인 영역을 검출하는 것은:손의 손바닥의 하나 이상의 이미지들에 기초하여, 손의 손바닥과 연관된 생체 정보를 검출하는 것; 상기 생체 정보를 사용자와 연관된 이전에 등록된 손바닥과 연관된 이전에 등록된 생체 정보와 비교하는 것; 및상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭한다고 결정하는 것을 포함하는, 장치. </claim></claimInfo><claimInfo><claim>22. 제 14 항에 있어서, 상기 하나 이상의 프로세서들은:제 2 가상 개인 제어 인터페이스를 렌더링하기 위하여 손의 손바닥을 식별하고; 그리고손의 손바닥 위에 상기 제 2 가상 개인 제어 인터페이스를 렌더링하기 전에:  손의 손바닥의 하나 이상의 이미지들에 기초하여, 손의 손바닥과 연관된 생체 정보를 검출하고;  상기 생체 정보를 사용자와 연관된 이전에 등록된 손바닥과 연관된 이전에 등록된 생체 정보와 비교하고; 그리고 상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭하는지의 여부를 결정하도록 구성되는, 장치. </claim></claimInfo><claimInfo><claim>23. 제 22 항에 있어서, 상기 하나 이상의 프로세서들은:상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭하지 않는다고 결정하고; 그리고상기 생체 정보가 상기 이전에 등록된 생체 정보와 매칭하지 않는다고 결정하는 것에 응답하여, 손의 손바닥에 제 2 가상 개인 제어 인터페이스를 렌더링하지 않는 것으로 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>24. 제 14 항에 있어서, 상기 개인 영역을 검출하는 것은:상기 물리적 환경에서 하나 이상의 오브젝트들을 검출하는 것; 상기 물리적 환경에서의 하나 이상의 오브젝트들에 기초하여, 상기 물리적 환경에서의 하나 이상의 폐색들을 검출하는 것; 및상기 하나 이상의 폐색들이 사람, 기록 디바이스 또는 오브젝트에 의한 개인 영역의 가시성을 차단한다고 결정하는 것에 의해 개인 영역을 검출하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>25. 제 24 항에 있어서, 상기 물리적 환경에서 하나 이상의 폐색들을 검출하는 것은 상기 물리적 환경 내의 광선의 경로를 추적하는 것을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>26. 제 14 항에 있어서, 상기 기록 디바이스는 카메라를 포함하고, 상기 가상 개인 제어 인터페이스는 증강 현실 인터페이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>27. 제 14 항에 있어서, 상기 장치는 모바일 디바이스인, 장치.</claim></claimInfo><claimInfo><claim>28. 제 14 항에 있어서, 상기 장치는 증강 현실 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>29. 명령들을 저장한 적어도 하나의 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 명령들은 하나 이상의 프로세서들에 실행될 때, 상기 하나 이상의 프로세서들로 하여금: 확장 현실 디바이스와 연관된 물리적 환경의 맵핑된 장면 내에서 확장 현실 디바이스의 포즈를 결정하게 하고; 상기 맵핑된 장면에서의 개인 영역 및 상기 확장 현실 디바이스의 상기 포즈에 대한 상기 개인 영역의 위치를 검출하게 하는 것으로서, 상기 개인 영역은 상기 확장 현실 디바이스의 사용자의 시야 (field of view; FOV) 내에 있고 그리고 상기 물리적 환경에서의 사람, 상기 물리적 환경에서의 기록 디바이스, 및 상기 물리적 환경의 외부로부터 뷰잉 액세스를 가능하게 하는 상기 물리적 환경에서의 오브젝트 중 적어도 하나의 개별적인 FOV 밖에 있는 것으로 추정되는 영역을 포함하는, 상기 개인 영역 및 상기 개인 영역의 위치를 검출하게 하고; 상기 확장 현실 디바이스의 포즈 및 상기 개인 영역이 검출되는 것에 기초하여, 가상 개인 제어 인터페이스를 상기 개인 영역에 맵핑하게 하는 것으로서, 상기 가상 개인 제어 인터페이스는 하나 이상의 입력 인터페이스 엘리먼트들을 포함하는, 상기 가상 개인 제어 인터페이스를 개인 영역에 맵핑하게 하고; 그리고 상기 맵핑된 장면에서 상기 개인 영역 내에 상기 가상 개인 제어 인터페이스를 렌더링하게 하는, 명령들을 저장한 적어도 하나의 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>30. 제 29 항에 있어서, 상기 물리적 환경에서 하나 이상의 오브젝트들을 검출하는 것; 및사람, 기록 디바이스 및 오브젝트 중 적어도 하나의 개별적인 FOV 가 하나 이상의 오브젝트들에 의해 폐색다고 결정하는 것에 의해 구역이 사람, 기록 디바이스 및 오브젝트 중 적어도 하나의 개별적인 FOV 밖에 있다고 결정하는 것인, 명령들을 저장한 적어도 하나의 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>HOLLAND, WESLEY JAMES</engName><name>홀랜드 웨슬리 제임스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>CHANDRASEKHAR, RAMESH</engName><name>찬드라세카르 라메쉬</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>GUEST, DANIEL JAMES</engName><name>게스트 다니엘 제임스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MOUNIER, SEBASTIEN</engName><name>무니에 세바스띠앙</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>FORUTANPOUR, BIJAN</engName><name>포루탄푸어 비잔</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.07.28</priorityApplicationDate><priorityApplicationNumber>16/941,346</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.01.18</receiptDate><receiptNumber>1-1-2023-0069856-92</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.03.03</receiptDate><receiptNumber>1-5-2023-0035663-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.06.13</receiptDate><receiptNumber>1-1-2024-0638664-58</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.06.13</receiptDate><receiptNumber>1-1-2024-0638665-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.06.13</receiptDate><receiptNumber>1-1-2024-0638666-49</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237002221.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930e6a7ffeb6727e987fc24a0d5d72096dbcc0383ad2c29e9d6a1205c476932eba87d519a55727e51365533fe491ca3e918ef51793b09c40bb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf46a557639437e7b88302ff4ed836d4a49632b1b611cbc7cc9569222480d314785b6374b141f7081449ea957d4892c442fc446c4a0ef10677</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>