<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:47.3947</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.10</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7027333</applicationNumber><claimCount>28</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>확장 현실 시스템들을 위한 오브젝트들의 포즈 예측</inventionTitle><inventionTitleEng>POSE PREDICTION OF OBJECTS FOR EXTENDED REALITY SYSTEMS</inventionTitleEng><openDate>2025.10.28</openDate><openNumber>10-2025-0154377</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.08.14</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/94</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 디스플레이를 위한 가상 콘텐츠를 제공하기 위한 시스템들 및 기법들이 본원에 설명된다. 디스플레이를 위한 가상 콘텐츠를 제공하기 위한 방법이 제공된다. 방법은 디바이스의 카메라에 의해 캡처된 복수의 이미지들을 획득하는 단계로서, 복수의 이미지들의 각각의 이미지는 환경에서의 오브젝트의 각각의 표현을 포함하는, 상기 복수의 이미지들을 획득하는 단계; 복수의 이미지들에 기초하여, 환경과 연관된 기준 좌표계에서의 오브젝트의 포즈를 예측하는 단계; 기준 좌표계에서의 오브젝트의 예측된 포즈에 기초하여, 디바이스에 대한 오브젝트의 포즈를 결정하는 단계; 및 디바이스에 대한 오브젝트의 포즈에 기초하여 가상 콘텐츠를 디바이스의 디스플레이에 제공하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.08.29</internationOpenDate><internationOpenNumber>WO2024177738</internationOpenNumber><internationalApplicationDate>2024.01.10</internationalApplicationDate><internationalApplicationNumber>PCT/US2024/011058</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디스플레이를 위한 가상 콘텐츠를 제공하는 방법으로서,디바이스의 카메라에 의해 캡처된 복수의 이미지들을 획득하는 단계로서, 상기 복수의 이미지들의 각각의 이미지는 환경에서의 오브젝트의 각각의 표현을 포함하는, 상기 복수의 이미지들을 획득하는 단계;상기 복수의 이미지들에 기초하여, 상기 환경과 연관된 기준 좌표계에서의 상기 오브젝트의 포즈를 예측하는 단계;상기 기준 좌표계에서의 상기 오브젝트의 예측된 상기 포즈에 기초하여, 상기 디바이스에 대한 상기 오브젝트의 포즈를 결정하는 단계; 및상기 디바이스에 대한 상기 오브젝트의 상기 포즈에 기초하여 가상 콘텐츠를 상기 디바이스의 디스플레이에 제공하는 단계를 포함하는, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 오브젝트의 포즈를 예측하는 단계는, 트레이닝된 포즈 예측 머신러닝 모델을 사용하여, 상기 복수의 이미지들에 기초하여 상기 기준 좌표계에서의 상기 오브젝트의 상기 예측된 포즈를 추론하는 단계를 포함하는, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 기준 좌표계에서의 상기 오브젝트의 상기 예측된 포즈는 상기 오브젝트의 이전에 결정된 포즈들에 추가로 기초하는, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 오브젝트의 포즈를 예측하는 단계는:다수의 각각의 미래 시간들에서의 상기 오브젝트의 다수의 미래 포즈들을 예측하는 단계; 및예측된 상기 다수의 미래 포즈들 사이의 보간에 기초하여 상기 오브젝트의 상기 포즈를 예측하는 단계를 포함하는, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 디바이스에 대한 상기 오브젝트의 포즈를 결정하는 단계는, 상기 기준 좌표계와 상기 디바이스의 배향과 연관된 디바이스 좌표계 사이의 변환을 획득하는 단계 및 상기 변환을 상기 오브젝트의 상기 예측된 포즈에 적용하는 단계를 포함하는, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 변환은 헤드 포즈 예측 모델에 기초하는, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 카메라에 의해 캡처된 상기 복수의 이미지들은 상기 카메라의 관점으로부터의 상기 오브젝트 및 상기 환경을 포함하고; 그리고상기 방법은, 상기 디바이스의 배향 및 상기 디바이스의 포지션에 따라 상기 디바이스의 사용자의 시선 내의 상기 오브젝트의 포즈와 관련되는 상기 디스플레이의 위치에 상기 가상 콘텐츠를 디스플레이하는 단계를 더 포함하는, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 디바이스는 확장 현실 디바이스인, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 디바이스는 시스루 확장 현실 디바이스인, 가상 콘텐츠를 제공하는 방법.</claim></claimInfo><claimInfo><claim>10. 디스플레이를 위한 가상 콘텐츠를 제공하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는: 디바이스의 카메라에 의해 캡처된 복수의 이미지들을 획득하는 것으로서, 상기 복수의 이미지들의 각각의 이미지는 환경에서의 오브젝트의 각각의 표현을 포함하는, 상기 복수의 이미지들을 획득하고; 상기 복수의 이미지들에 기초하여, 상기 환경과 연관된 기준 좌표계에서의 상기 오브젝트의 포즈를 예측하고; 상기 기준 좌표계에서의 상기 오브젝트의 예측된 상기 포즈에 기초하여, 상기 디바이스에 대한 상기 오브젝트의 포즈를 결정하고; 그리고 상기 디바이스에 대한 상기 오브젝트의 상기 포즈에 기초하여 가상 콘텐츠를 상기 디바이스의 디스플레이에 제공하도록구성되는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 적어도 하나의 프로세서는, 상기 오브젝트의 상기 포즈를 예측하는 것에 있어서, 트레이닝된 포즈 예측 머신러닝 모델을 사용하여, 상기 복수의 이미지들에 기초하여 상기 기준 좌표계에서의 상기 오브젝트의 상기 예측된 포즈를 추론하도록 구성되는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 기준 좌표계에서의 상기 오브젝트의 상기 예측된 포즈는 상기 오브젝트의 이전에 결정된 포즈들에 추가로 기초하는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,상기 적어도 하나의 프로세서는, 상기 오브젝트의 상기 포즈를 예측하는 것에 있어서:다수의 각각의 미래 시간들에서의 상기 오브젝트의 다수의 미래 포즈들을 예측하고; 그리고예측된 상기 다수의 미래 포즈들 사이의 보간에 기초하여 상기 오브젝트의 상기 포즈를 예측하도록구성되는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,상기 적어도 하나의 프로세서는, 상기 디바이스에 대한 상기 오브젝트의 상기 포즈를 결정하는 것에 있어서, 상기 기준 좌표계와 상기 디바이스의 배향과 연관된 디바이스 좌표계 사이의 변환을 획득하고 상기 변환을 상기 오브젝트의 상기 예측된 포즈에 적용하도록 구성되는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 변환은 헤드 포즈 예측 모델에 기초하는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>16. 제10항에 있어서,상기 카메라에 의해 캡처된 상기 복수의 이미지들은 상기 카메라의 관점으로부터의 상기 오브젝트 및 상기 환경을 포함하고; 그리고상기 적어도 하나의 프로세서는 추가로, 상기 디바이스의 배향 및 상기 디바이스의 포지션에 따라 상기 디바이스의 사용자의 시선 내의 상기 오브젝트의 포즈와 관련되는 상기 디스플레이의 위치에 상기 가상 콘텐츠를 디스플레이하도록 구성되는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서,상기 디바이스는 확장 현실 디바이스의 디스플레이 및 카메라를 포함하고, 상기 장치는 상기 확장 현실 디바이스의 프로세서를 포함하는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제10항에 있어서,상기 디바이스는 시스루 확장 현실 디바이스의 디스플레이를 포함하고, 상기 장치는 상기 시스루 확장 현실 디바이스의 프로세서를 포함하는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo><claimInfo><claim>19. 명령들을 저장한 비일시적 컴퓨터 판독가능 저장 매체로서,상기 명령들은, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금:디바이스의 카메라에 의해 캡처된 복수의 이미지들을 획득하게 하는 것으로서, 상기 복수의 이미지들의 각각의 이미지는 환경에서의 오브젝트의 각각의 표현을 포함하는, 상기 복수의 이미지들을 획득하게 하고;상기 복수의 이미지들에 기초하여, 상기 환경과 연관된 기준 좌표계에서의 상기 오브젝트의 포즈를 예측하게 하고;상기 기준 좌표계에서의 상기 오브젝트의 예측된 상기 포즈에 기초하여, 상기 디바이스에 대한 상기 오브젝트의 포즈를 결정하게 하고; 그리고상기 디바이스에 대한 상기 오브젝트의 상기 포즈에 기초하여 가상 콘텐츠를 상기 디바이스의 디스플레이에 제공하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 명령들은, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 상기 오브젝트의 상기 포즈를 예측하는 것에 있어서, 트레이닝된 포즈 예측 머신러닝 모델을 사용하여, 상기 복수의 이미지들에 기초하여 상기 기준 좌표계에서의 상기 오브젝트의 상기 예측된 포즈를 추론하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>21. 제19항에 있어서,상기 기준 좌표계에서의 상기 오브젝트의 상기 예측된 포즈는 상기 오브젝트의 이전에 결정된 포즈들에 추가로 기초하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>22. 제19항에 있어서,상기 명령들은, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 상기 오브젝트의 상기 포즈를 예측하는 것에 있어서:다수의 각각의 미래 시간들에서의 상기 오브젝트의 다수의 미래 포즈들을 예측하고; 그리고예측된 상기 다수의 미래 포즈들 사이의 보간에 기초하여 상기 오브젝트의 상기 포즈를 예측하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>23. 제19항에 있어서,상기 명령들은, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 상기 디바이스에 대한 상기 오브젝트의 상기 포즈를 결정하는 것에 있어서, 상기 기준 좌표계와 상기 디바이스의 배향과 연관된 디바이스 좌표계 사이의 변환을 획득하게 하고 상기 변환을 상기 오브젝트의 상기 예측된 포즈에 적용하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 변환은 헤드 포즈 예측 모델에 기초하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>25. 제19항에 있어서,상기 카메라에 의해 캡처된 상기 복수의 이미지들은 상기 카메라의 관점으로부터의 상기 오브젝트 및 상기 환경을 포함하고; 그리고상기 명령들은, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금 상기 디바이스의 배향 및 상기 디바이스의 포지션에 따라 상기 디바이스의 사용자의 시선 내의 상기 오브젝트의 포즈와 관련되는 상기 디스플레이의 위치에 상기 가상 콘텐츠를 디스플레이하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>26. 제19항에 있어서,상기 디바이스는 확장 현실 디바이스의 디스플레이 및 카메라를 포함하고, 상기 적어도 하나의 프로세서는 상기 확장 현실 디바이스의 컴퓨팅 유닛의 컴포넌트인, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>27. 제19항에 있어서,상기 디바이스는 시스루 확장 현실 디바이스의 디스플레이를 포함하고, 상기 적어도 하나의 프로세서는 상기 시스루 확장 현실 디바이스의 컴퓨팅 유닛의 컴포넌트인, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>28. 디스플레이를 위한 가상 콘텐츠를 제공하기 위한 장치로서,디바이스의 카메라에 의해 캡처된 복수의 이미지들을 획득하기 위한 하나 이상의 수단으로서, 상기 복수의 이미지들의 각각의 이미지는 환경에서의 오브젝트의 각각의 표현을 포함하는, 상기 복수의 이미지들을 획득하기 위한 하나 이상의 수단;상기 복수의 이미지들에 기초하여, 상기 환경과 연관된 기준 좌표계에서의 상기 오브젝트의 포즈를 예측하기 위한 하나 이상의 수단;상기 기준 좌표계에서의 상기 오브젝트의 예측된 상기 포즈에 기초하여, 상기 디바이스에 대한 상기 오브젝트의 포즈를 결정하기 위한 하나 이상의 수단; 및상기 디바이스에 대한 상기 오브젝트의 상기 포즈에 기초하여 가상 콘텐츠를 상기 디바이스의 디스플레이에 제공하기 위한 하나 이상의 수단을 포함하는, 가상 콘텐츠를 제공하기 위한 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>오스트리아</country><engName>VIEHAUSER, ROBERT PETER</engName><name>피하우저 로베르트 페터 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.02.24</priorityApplicationDate><priorityApplicationNumber>18/174,532</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.08.14</receiptDate><receiptNumber>1-1-2025-0931475-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.10.01</receiptDate><receiptNumber>1-5-2025-0166199-63</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257027333.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f1806f8597d1357d00a3f5259d73afbbdd094da4b9e737f77a0823a6308ec82e6baab1a304ffc05bc838b7ef203ada1e13cc73865afd8930</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbe2083a3a6aa3be1896136c8d12d633bf9ed59019a8a21be08dad991359f88b6737c74c7c1a1527b2716c41e92af77f3f2c9cdd125b146ca</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>