<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:16.4016</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7043396</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>발견법-기반 로봇식 파지들</inventionTitle><inventionTitleEng>HEURISTIC-BASED ROBOTIC GRASPS</inventionTitleEng><openDate>2025.02.03</openDate><openNumber>10-2025-0016339</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.12.30</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 15/06</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일부 경우들에서, 이미지들 및 깊이 맵들은 무작위 구성들의 객체들을 갖는 빈들을 정의할 수 있다. 파지 컴퓨테이션들을 수행하기 위해 딥 뉴럴 네트워크들을 트레이닝하는 현재 접근법들은 능력들 및 효율들이 부족하여서, 결과적인 파지 컴퓨테이션들 및 파지들은 다른 단점들 중에서도, 부정확하거나 또는 번거로울 수 있다는 것이 본원에서 인식된다. 합성 깊이 이미지들은, 주석이 달린 합성 데이터세트들을 정의하기 위해, 발견법-기반 분석들에 기초하여 생성되는 파지 주석들로 라벨링될 수 있다. 주석이 달린 합성 데이터세트들은 서로에 대해 다양한 포지션들에 배열된 상이한 객체들에 대한 최상의 파지 위치들을 결정하기 위해 뉴럴 네트워크들을 트레이닝하는 데 사용될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.12.21</internationOpenDate><internationOpenNumber>WO2023244487</internationOpenNumber><internationalApplicationDate>2023.06.08</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/024771</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터-구현(computer-implemented) 방법으로서,깊이 이미지(depth image)를 획득하는 단계 — 상기 깊이 이미지는 복수의 개개의 포지션(position)들에 배열된 복수의 객체들을 정의함 —;노출된 객체들을 식별하기 위해, 상기 복수의 객체들을 파지(grasp)하도록 구성된 로봇(robot)의 엔드 이펙터(end effector)에 노출되는 개개의 표면을 각각 정의하는, 상기 복수의 객체들 중의 한 세트(set)의 객체들을 식별하는 단계;상기 노출된 객체들 각각 상의 파지 위치(grasp location)를 결정하는 단계 — 상기 파지 위치는 개개의 노출된 객체를 파지하기 위해 상기 엔드 이펙터가 상기 노출된 객체와 접촉하는, 상기 노출된 객체의 영역을 정의함 —;상기 노출된 객체들 각각 상의 파지 위치에서 개개의 파지 주석들을 포함하는 확률 맵(map)을 생성하는 단계 — 상기 깊이 이미지 및 상기 확률 맵은 주석이 달린 합성 데이터세트(annotated synthetic dataset)를 정의함 —; 및복수의 구성들로 배열된 객체들 상의 파지 위치들을 결정하기 위해, 상기 주석이 달린 합성 데이터세트로 뉴럴 네트워크(neural network)를 트레이닝(training)하는 단계를 포함하는,컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 상기 엔드 이펙터에 기초하는 파지가능 기준들을 충족시키거나 또는 초과하는, 상기 노출된 객체들의 후보 구역들을 결정하기 위해, 상기 노출된 객체들을 상기 파지가능 기준들과 비교하는 단계를 더 포함하는,컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서, 상기 엔드 이펙터는 진공-기반 그리퍼(vacuum-based gripper)를 정의하며, 상기 방법은, 각각의 후보 구역과 연관된 평면 스코어(planar score)를 결정하기 위해 상기 후보 구역들을 평가하는 단계를 더 포함하며, 상기 평면 스코어들은 개개의 후보 구역에 의해 정의된 곡률을 표시하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,상기 방법은, 각각의 평면 스코어를 미리 결정된 임계치와 비교하는 단계; 및 상기 비교하는 단계에 기초하여, 각각의 노출된 객체와 연관된 파지 주석들을 결정하는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항 내지 제4 항 중 어느 한 항에 있어서, 상기 복수의 구성들은, 적어도 부분적으로 하나가 다른 하나 위에 적층되도록 컨테이너(container)에 포지셔닝(position)된 객체들을 포함하고, 상기 객체들은 서로 비교할 때 상이한 형상들 및 크기들을 정의하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>6. 객체들을 파지하도록 구성된 엔드 이펙터를 정의하는 로봇을 포함하는 시스템(system)으로서,프로세서(processor); 및명령들을 저장하는 메모리(memory)를 포함하며, 상기 명령들은, 상기 프로세서에 의해 실행될 때,  깊이 이미지를 획득하고 — 상기 깊이 이미지는 복수의 개개의 포지션들에 배열된 복수의 객체들을 정의함 —; 노출된 객체들을 식별하기 위해, 상기 로봇의 상기 엔드 이펙터에 노출되는 개개의 표면을 각각 정의하는, 상기 복수의 객체들 중의 한 세트의 객체들을 식별하고; 상기 노출된 객체들 각각 상의 파지 위치를 결정하고 — 상기 파지 위치는 개개의 노출된 객체를 파지하기 위해 상기 엔드 이펙터가 상기 노출된 객체와 접촉하는, 상기 노출된 객체의 영역을 정의함 —; 상기 노출된 객체들 각각 상의 파지 위치에서 개개의 파지 주석들을 포함하는 확률 맵을 생성하고 — 상기 깊이 이미지 및 상기 확률 맵은 주석이 달린 합성 데이터세트를 정의함 —; 그리고 복수의 구성들로 배열된 객체들 상의 파지 위치들을 결정하기 위해, 상기 주석이 달린 합성 데이터세트로 뉴럴 네트워크를 트레이닝하도록 상기 시스템을 구성하는,객체들을 파지하도록 구성된 엔드 이펙터를 정의하는 로봇을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 메모리는, 상기 프로세서에 의해 실행될 때, 상기 엔드 이펙터에 기초하는 파지가능 기준들을 충족시키거나 또는 초과하는, 상기 노출된 객체들의 후보 구역들을 결정하기 위해, 상기 노출된 객체들을 상기 파지가능 기준들과 비교하도록 상기 시스템을 추가로 구성하는 명령들을 추가로 저장하는,객체들을 파지하도록 구성된 엔드 이펙터를 정의하는 로봇을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서, 상기 엔드 이펙터는 진공-기반 그리퍼를 정의하며, 상기 메모리는, 상기 프로세서에 의해 실행될 때, 각각의 후보 구역과 연관된 평면 스코어를 결정하기 위해 상기 후보 구역들을 평가하도록 상기 시스템을 추가로 구성하는 명령들을 추가로 저장하며, 상기 평면 스코어들은 개개의 후보 구역에 의해 정의된 곡률을 표시하는, 객체들을 파지하도록 구성된 엔드 이펙터를 정의하는 로봇을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서, 상기 메모리는, 상기 프로세서에 의해 실행될 때, 각각의 평면 스코어를 미리 결정된 임계치와 비교하고; 그리고 상기 비교에 기초하여, 각각의 노출된 객체와 연관된 파지 주석들을 결정하도록 상기 시스템을 추가로 구성하는 명령들을 추가로 저장하는, 객체들을 파지하도록 구성된 엔드 이펙터를 정의하는 로봇을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>10. 제6 항 내지 제9 항 중 어느 한 항에 있어서, 상기 복수의 구성들은, 적어도 부분적으로 하나가 다른 하나 위에 적층되도록 컨테이너에 포지셔닝된 객체들을 포함하고, 상기 객체들은 서로 비교할 때 상이한 형상들 및 크기들을 정의하는,객체들을 파지하도록 구성된 엔드 이펙터를 정의하는 로봇을 포함하는 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>독일 뮌헨 베르너-본-지멘스-슈트라쎄 * (우: *****)</address><code>519990002521</code><country>독일</country><engName>SIEMENS AKTIENGESELLSCHAFT</engName><name>지멘스 악티엔게젤샤프트</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 버클...</address><code> </code><country>인도</country><engName>SHAHAPURKAR, Yash</engName><name>샤하푸르카르, 야쉬</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>독일</country><engName>SOLOWJOW, Eugen</engName><name>솔로우조우, 오이겐</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 레드...</address><code> </code><country>스페인</country><engName>UGALDE DIAZ, Ines</engName><name>우갈데 디아즈, 이네스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 버클...</address><code> </code><country>터어키</country><engName>ERDOGAN, Husnu Melih</engName><name>에르도안, 후스누 멜리</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2022.06.15</priorityApplicationDate><priorityApplicationNumber>22179085.0</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.12.30</receiptDate><receiptNumber>1-1-2024-1456895-08</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.12.31</receiptDate><receiptNumber>1-5-2024-0213604-11</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247043396.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e7d4a77dfa1f64b7350eb0698d04d0283431705062da057ce8ffcb1de83b8276325d8a3004c749887e255bdc98943da3f83c14cb9be5c50d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4935a89fef392ac96345c578b46afa3658b83da754893e6d16e081fd9e9dc41fa5244f252150bdad57acb1dc19f677b0e4cb5930189307a9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>