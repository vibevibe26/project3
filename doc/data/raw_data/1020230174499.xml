<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:11.4111</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0174499</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다수의 사용자가 뉴럴 래디언스 필드 모델을 생성하고 사용할 수 있는 플랫폼</inventionTitle><inventionTitleEng>PLATFORM FOR ENABLING MULTIPLE USERS TO GENERATE AND USE  NEURAL RADIANCE FIELD MODELS</inventionTitleEng><openDate>2024.06.26</openDate><openNumber>10-2024-0096365</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 사용자가 뉴럴 래디언스 필드 모델들을 생성하고 활용할 수 있도록 하는 시스템 및 방법은 사용자 이미지 데이터들을 획득하고 사용자 이미지 데이터들에 기초하여 하나 이상의 뉴럴 래디언스 필드 모델들을 트레이닝하는 것을 포함할 수 있다. 시스템 및 방법은 사용자 이미지들이 특정 객체 유형의 객체들을 묘사한다는 결정에 기초하여 사용자 이미지들을 획득하는 것을 포함할 수 있다. 트레이닝된 뉴럴 래디언스 필드 모델들은 특정 사용자 객체들의 뷰 합성 이미지 생성에 활용될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 시스템으로서, 상기 시스템은:하나 이상의 프로세서들; 및하나 이상의 프로세서들에 의해 실행될 때 컴퓨팅 시스템으로 하여금 동작들을 수행하게 하는 명령어들을 집합적으로 저장하는 하나 이상의 비일시적 컴퓨터 판독가능 매체를 포함하고, 상기 동작들은: 사용자 이미지 데이터 및 요청 데이터를 획득하는 동작, 상기 사용자 이미지 데이터는 하나 이상의 사용자 객체들을 포함하는 하나 이상의 이미지들을 기술하고, 상기 하나 이상의 이미지들은 사용자 컴퓨팅 장치를 사용하여 생성되었으며; 상기 사용자 이미지 데이터에 기초하여 하나 이상의 뉴럴 래디언스 필드(neural radiance field) 모델들을 트레이닝하는 동작, 상기 하나 이상의 뉴럴 래디언스 필드 모델들은 하나 이상의 객체들의 뷰 합성을 생성하도록 트레이닝되며; 및 상기 요청 데이터에 기초하여 상기 하나 이상의 뉴럴 래디언스 필드 모델들을 사용하여 하나 이상의 뷰 합성 이미지들을 생성하는 동작, 상기 하나 이상의 뷰 합성 이미지들은 하나 이상의 객체들의 하나 이상의 렌더링들을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 요청 데이터는 객체 유형별 컬렉션(collection)을 생성하라는 요청을 기술하고; 그리고상기 동작들은:하나 이상의 객체들이 특정 객체 유형인지 결정하기 위해 상기 사용자 이미지 데이터를 프로세싱하는 동작; 및상기 하나 이상의 뉴럴 래디언스 필드 모델들을 컬렉션 데이터베이스에 저장하는 동작을 더 포함하고, 상기 컬렉션 데이터베이스는 상기 객체 유형별 컬렉션과 연관되는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 동작들은:복수의 추가 사용자 이미지 데이터세트들을 획득하는 동작, 상기 복수의 추가 사용자 이미지 데이터세트들 각각은 사용자 컴퓨팅 장치를 사용하여 생성되었으며;상기 복수의 추가 사용자 이미지 데이터세트들의 서브세트가 특정 객체 유형의 각각의 객체를 포함하는지 결정하기 위해 하나 이상의 객체 결정 모델들로 상기 복수의 추가 사용자 이미지 데이터세트들 각각을 프로세싱하는 동작;상기 복수의 추가 사용자 이미지 데이터세트들의 서브세트의 각각의 추가 사용자 이미지 데이터세트에 대해 각각의 추가 뉴럴 래디언스 필드 모델을 트레이닝하는 동작; 및상기 각각의 추가 뉴럴 래디언스 필드 모델을 상기 컬렉션 데이터베이스에 저장하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 특정 객체 유형은 하나 이상의 의류 품목들과 연관되는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 동작들은:디스플레이를 위해 상기 하나 이상의 뷰 합성 이미지들을 사용자 컴퓨팅 시스템에 제공하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 요청 데이터는 컨텍스트와 연관되고, 상기 컨텍스트는 객체 컨텍스트 또는 환경 컨텍스트 중 적어도 하나를 기술하는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 동작들은:사용자 컴퓨팅 시스템에 가상 객체 사용자 인터페이스를 제공하는 동작을 더 포함하고, 상기 가상 객체 사용자 인터페이스는 디스플레이를 위한 상기 하나 이상의 뷰 합성 이미지들을 제공하고, 하나 이상의 객체들은 상기 사용자 이미지 데이터에 묘사된 원래 환경으로부터 분리되는(isolated), 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 하나 이상의 뷰 합성 이미지들은,하나 이상의 예측 밀도 값들 및 하나 이상의 색상 값들을 생성하기 위해 상기 하나 이상의 뉴럴 래디언스 필드 모델들을 사용하여 포지션 및 뷰 방향을 프로세싱하는 동작; 및상기 하나 이상의 예측 밀도 값들 및 하나 이상의 색상 값들에 기초하여 상기 하나 이상의 뷰 합성 이미지들을 생성하는 동작에 의해 생성되는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 요청 데이터는 하나 이상의 조정 설정(adjustment setting)들을 기술하고; 그리고상기 요청 데이터에 기초하여 상기 하나 이상의 뉴럴 래디언스 필드 모델들을 사용하여 하나 이상의 뷰 합성 이미지들을 생성하는 동작은 상기 하나 이상의 뉴럴 래디언스 필드 모델들에 의해 생성된 예측 값들 세트의 하나 이상의 색상 값들을 조정하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 요청 데이터는 특정 포지션 및 특정 뷰 방향을 기술하고; 그리고상기 요청 데이터에 기초하여 상기 하나 이상의 뉴럴 래디언스 필드 모델들을 사용하여 하나 이상의 뷰 합성 이미지들을 생성하는 동작은 상기 특정 포지션 및 특정 뷰 방향과 연관된 뷰를 기술하는 하나 이상의 객체들의 뷰 렌더링을 생성하기 위해 상기 하나 이상의 뉴럴 래디언스 필드 모델들을 사용하여 상기 특정 포지션 및 특정 뷰 방향을 프로세싱하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 가상 옷장 생성을 위한 컴퓨터 구현 방법으로서, 상기 방법은:하나 이상의 프로세서들을 포함하는 컴퓨팅 시스템에 의해, 복수의 사용자 이미지들을 획득하는 단계, 상기 복수의 사용자 이미지들 각각은 하나 이상의 의류 품목들을 포함하고, 상기 복수의 사용자 이미지들은 복수의 서로 다른 의류 품목들과 연관되며;컴퓨팅 시스템에 의해, 상기 복수의 서로 다른 의류 품목들의 각각의 의류 품목에 대해 각각의 뉴럴 래디언스 필드 모델을 트레이닝하는 단계, 상기 각각의 뉴럴 래디언스 필드 모델은 특정 각각의 의류 품목의 하나 이상의 뷰 합성 렌더링들을 생성하도록 트레이닝되고;컴퓨팅 시스템에 의해, 상기 각각의 뉴럴 래디언스 필드 모델을 컬렉션 데이터베이스에 저장하는 단계; 및컴퓨팅 시스템에 의해, 가상 옷장 인터페이스를 제공하는 단계, 상기 가상 옷장 인터페이스는 복수의 각각의 뉴럴 래디언스 필드 모델들에 기초하여 디스플레이를 위한 복수의 의류 뷰 합성 렌더링들을 제공하며, 상기 복수의 의류 뷰 합성 렌더링들은 적어도 상기 복수의 서로 다른 의류 품목들의 서브세트와 연관되는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 복수의 사용자 이미지들은 획득된 요청 데이터에 기초하여 특정 사용자와 연관된 저장 데이터베이스로부터 자동으로 획득되는, 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 복수의 사용자 이미지들은 메타데이터, 하나 이상의 사용자 입력, 또는 하나 이상의 분류 중 적어도 하나에 기초하여 사용자 이미지 모음(corpus)으로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,컴퓨팅 시스템에 의해, 사용자와 연관된 저장 데이터베이스에 액세스하는 단계; 및컴퓨팅 시스템에 의해, 의류로 분류된 하나 이상의 객체들을 포함하는 상기 복수의 사용자 이미지들을 결정하기 위해 하나 이상의 분류 모델들을 사용하여 상기 사용자 이미지 모음을 프로세싱하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 가상 옷장 인터페이스는 동시에 디스플레이되는 2개 이상의 의류 품목들을 포함하는 의류 앙상블을 보기 위한 하나 이상의 인터페이스 피처들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 복수의 의류 뷰 합성 렌더링들은 하나 이상의 균일한 포즈 파라미터들 및 하나 이상의 균일한 조명 파라미터들에 기초하여 생성되는, 방법.</claim></claimInfo><claimInfo><claim>17. 하나 이상의 컴퓨팅 장치들에 의해 실행될 때 하나 이상의 컴퓨팅 장치들로 하여금 동작들을 수행하게 하는 명령어들을 집합적으로 저장하는 하나 이상의 비일시적 컴퓨터 판독가능 매체로서, 상기 동작들은:복수의 사용자 이미지 데이터세트들을 획득하는 동작, 상기 복수의 사용자 이미지 데이터세트들의 각 사용자 이미지 데이터세트는 하나 이상의 객체들을 포함하는 하나 이상의 이미지들을 기술하며, 상기 하나 이상의 이미지들은 사용자 컴퓨팅 장치를 사용하여 생성되었으며;하나 이상의 특정 객체 유형들을 기술하는 피처들을 포함하는 상기 복수의 사용자 이미지 데이터세트들의 서브세트를 결정하기 위해 하나 이상의 분류 모델들을 사용하여 상기 복수의 사용자 이미지 데이터세트들을 프로세싱하는 동작;상기 복수의 사용자 이미지 데이터세트들의 서브세트에 기초하여 복수의 뉴럴 래디언스 필드(neural radiance field) 모델들을 트레이닝하는 동작, 각각의 뉴럴 래디언스 필드 모델은 상기 복수의 사용자 이미지 데이터세트들의 서브세트의 각각의 사용자 이미지 데이터세트의 하나 이상의 특정 객체들의 뷰 합성을 생성하도록 트레이닝되며;상기 복수의 뉴럴 래디언스 필드 모델들을 사용하여 복수의 뷰 합성 렌더링들을 생성하는 동작, 상기 복수의 뷰 합성 렌더링들은 특정 객체 유형의 복수의 서로 다른 객체들을 기술하며; 및상기 복수의 뷰 합성 렌더링들을 보기 위한 사용자 인터페이스를 제공하는 동작을 포함하는, 하나 이상의 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 사용자 인터페이스는 상기 복수의 뷰 합성 렌더링들을 보기 위한 렌더링 창(pane)을 포함하는, 하나 이상의 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 동작들은:제1 객체 서브 유형을 기술하는 피처들을 포함하는 사용자 이미지 데이터세트들의 제1 세트를 결정하는 동작;뉴럴 래디언스 모델들의 각각의 제1 세트를 제1 객체 서브 유형 레이블과 연관시키는 동작;제2 객체 서브 유형을 기술하는 피처들을 포함하는 사용자 이미지 데이터세트들의 제2 세트를 결정하는 동작; 및뉴럴 래디언스 모델들의 각각의 제2 세트를 제2 객체 서브 유형 레이블과 연관시키는 동작을 더 포함하는, 하나 이상의 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 동작들은:앙상블 렌더링 요청을 수신하는 동작, 상기 앙상블 렌더링 요청은 제1 객체 서브 유형의 제1 객체와 제2 객체 서브 유형의 제2 객체의 뷰 렌더링을 생성하라는 요청을 기술하며; 및뉴럴 래디언스 모델들의 각각의 제1 세트의 제1 뉴럴 래디언스 필드 모델과 뉴럴 래디언스 모델들의 각각의 제2 세트의 제2 뉴럴 래디언스 필드 모델을 사용하여 앙상블 뷰 렌더링을 생성하는 동작을 더 포함하며, 상기 앙상블 뷰 렌더링은 공유 환경에서 제1 객체와 제2 객체를 기술하는 이미지 데이터를 포함하는, 하나 이상의 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>스위스 취리히 **** 브랜...</address><code> </code><country> </country><engName>BONACI, Igor</engName><name>보나치 이고르</name></inventorInfo><inventorInfo><address>스위스 취리히 **** 브랜...</address><code> </code><country> </country><engName>SADR, Arash</engName><name>사드르 아라쉬</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.12.16</priorityApplicationDate><priorityApplicationNumber>63/433,111</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.12.19</priorityApplicationDate><priorityApplicationNumber>63/433,559</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.02.15</priorityApplicationDate><priorityApplicationNumber>18/169,425</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.05</receiptDate><receiptNumber>1-1-2023-1361892-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.12.07</receiptDate><receiptNumber>9-1-2023-9013636-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.12.07</receiptDate><receiptNumber>9-1-2023-9013639-42</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.12.07</receiptDate><receiptNumber>9-1-2023-9013640-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.07.09</receiptDate><receiptNumber>9-5-2025-0655703-76</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.09.09</receiptDate><receiptNumber>1-1-2025-1036156-81</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.09.09</receiptDate><receiptNumber>1-1-2025-1036155-35</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230174499.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931b3323467b072be7cca82958dd75cdbdbd05fe06577a9be725d8b06d961776327303e70a15523a027df9e0c55d69fcaa21a0835710a69c57</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf91ef38f15fa79abfaddaf5e0971d9d346b3455d31faedebb534ebceed83cf6c37396ce0c9191787ecf42e8b777103418fb36883ecd76a7c1</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>