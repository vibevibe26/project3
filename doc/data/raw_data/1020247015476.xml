<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:16.3316</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7015476</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자세 및 음성 입력으로부터의 의도 추론</inventionTitle><inventionTitleEng>INFERRING INTENT FROM POSE AND SPEECH INPUT</inventionTitleEng><openDate>2024.06.20</openDate><openNumber>10-2024-0089525</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.05.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.05.09</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 적어도 하나의 프로그램을 저장하는 컴퓨터 판독가능 저장 매체, 및 사람을 묘사하는 이미지를 수신하는 것, 사람의 골격 관절들의 세트를 식별하는 것, 및 골격 관절들의 세트의 위치확인에 기초하여 이미지에 묘사된 사람의 자세를 식별하는 것을 포함하는 동작들을 수행하기 위한 방법을 포함하는 시스템을 수반한다. 동작들은 또한 AR 동작을 수행하라는 요청 및 모호한 의도를 포함하는 음성 입력을 수신하는 것, 이미지에 묘사된 사람의 자세에 기초하여 음성 입력의 모호한 의도를 분별하는 것, 및 음성 입력을 수신하는 것에 응답하여, 이미지에 묘사된 사람의 자세에 기초하여 음성 입력의 모호한 의도를 분별하는 것에 기초하여 AR 동작을 수행하는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.04.20</internationOpenDate><internationOpenNumber>WO2023064268</internationOpenNumber><internationalApplicationDate>2022.10.11</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/046273</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법은하나 이상의 프로세서에 의해, 사람을 묘사하는 이미지를 수신하는 단계;상기 사람의 골격 관절들의 세트를 식별하는 단계;상기 골격 관절들의 세트의 위치확인에 기초하여 상기 이미지에 묘사된 상기 사람의 자세를 식별하는 단계;증강 현실(AR) 동작을 수행하라는 요청을 포함하는 음성 입력을 수신하는 단계- 상기 음성 입력은 모호한 의도를 포함함 -;상기 이미지에 묘사된 상기 사람의 자세에 기초하여 상기 음성 입력의 모호한 의도를 분별하는 단계; 및상기 음성 입력을 수신하는 것에 응답하여, 상기 이미지에 묘사된 상기 사람의 자세에 기초하여 상기 음성 입력의 모호한 의도를 분별하는 것에 기초하여 상기 AR 동작을 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 모호한 의도는 대명사 또는 부사를 포함하고, 상기 이미지에 묘사된 상기 사람의 자세에 기초하여 상기 대명사 또는 부사에 대응하는 타겟 객체 또는 방향을 식별하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 자세가 타겟 자세와 매칭된다고 결정하는 단계; 및상기 자세가 상기 타겟 자세와 매칭된다고 결정하는 것에 응답하여, 상기 타겟 객체가 상기 이미지에 묘사된 사람을 포함한다고 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 음성 입력을 수신하는 것에 응답하여 그리고 상기 자세가 상기 타겟 자세와 매칭된다고 결정하는 것에 응답하여 상기 이미지에 묘사된 사람에게 하나 이상의 AR 요소를 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 자세가 타겟 자세와 매칭된다고 결정하는 단계; 및상기 자세가 상기 타겟 자세와 매칭된다고 결정하는 것에 응답하여, 상기 타겟 객체가 상기 이미지에 묘사된 상기 사람의 신체 부분을 포함한다고 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 음성 입력을 수신하는 것에 응답하여 그리고 상기 자세가 상기 타겟 자세와 매칭된다고 결정하는 것에 응답하여 상기 이미지에 묘사된 상기 사람의 상기 신체 부분에 하나 이상의 AR 요소를 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제5항 또는 제6항에 있어서,상기 신체 부분에 대응하는 상기 이미지의 부분 상에 묘사된 현실 세계 패션 아이템을 식별하는 단계;상기 이미지에 묘사된 상기 현실 세계 패션 아이템을 세그멘테이션하여 상기 현실 세계 패션 아이템의 세그멘테이션을 생성하는 단계; 및상기 현실 세계 패션 아이템의 세그멘테이션에 기초하여, 상기 현실 세계 패션 아이템의 속성을 상기 하나 이상의 AR 요소로 대체하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 사람은 제1 인물이고, 상기 이미지는 제2 인물을 묘사하고,상기 자세가 타겟 자세와 매칭된다고 결정하는 단계; 및상기 자세가 상기 타겟 자세와 매칭된다고 결정하는 것에 응답하여, 상기 모호한 의도의 대명사가 상기 이미지에 묘사된 상기 제2 인물을 지칭한다고 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 음성 입력을 수신하는 것에 응답하여 그리고 상기 자세가 상기 타겟 자세와 매칭된다고 결정하는 것에 응답하여 상기 이미지에 묘사된 상기 제2 인물에게 하나 이상의 AR 요소를 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제8항 또는 제9항에 있어서,상기 음성 입력이 상기 제2 인물이 착용한 패션 아이템을 지칭한다고 결정하는 단계;상기 음성 입력을 수신하는 것에 응답하여 상기 패션 아이템의 세그멘테이션을 생성하기 위해 상기 제2 인물이 착용한 상기 패션 아이템을 세그멘테이션하는 단계; 및상기 패션 아이템의 세그멘테이션에 기초하여 상기 제2 인물이 착용한 패션 아이템에 상기 하나 이상의 AR 요소를 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제8항 내지 제10항 중 어느 한 항에 있어서,상기 음성 입력을 수신하는 것에 응답하여 그리고 상기 자세가 상기 타겟 자세와 매칭된다고 결정하는 것에 응답하여 상기 이미지에 묘사된 상기 제2 인물이 착용한 패션 아이템의 속성에 기초하여 상기 이미지에 묘사된 상기 제1 인물에게 하나 이상의 AR 요소를 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제8항 내지 제11항 중 어느 한 항에 있어서,상기 음성 입력이 상기 패션 아이템을 지칭한다고 결정하는 단계;상기 음성 입력을 수신하는 것에 응답하여 상기 패션 아이템의 제1 세그멘테이션을 생성하기 위해 상기 제2 인물이 착용한 상기 패션 아이템을 세그멘테이션하는 단계;상기 음성 입력을 수신하는 것에 응답하여 상기 제1 인물이 착용한 상기 패션 아이템을 세그멘테이션하여 상기 패션 아이템의 제2 세그멘테이션을 생성하는 단계;상기 제1 세그멘테이션에 기초하여 상기 제2 인물이 착용한 상기 패션 아이템의 픽셀 값들을 획득하는 단계; 및상기 패션 아이템의 상기 제2 세그멘테이션 및 상기 획득된 픽셀 값들에 기초하여 상기 제1 인물이 착용한 상기 패션 아이템에 상기 하나 이상의 AR 요소를 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서,상기 자세가 타겟 자세와 매칭된다고 결정하는 단계; 및자세가 타겟 자세와 매칭된다고 결정하는 것에 응답하여, 모호한 의도의 대명사가 이미지에 묘사된 인물이 착용한 패션 아이템의 속성을 지칭한다고 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 타겟 자세가 가리키는 상기 이미지의 부분에서의 픽셀 값을 결정하는 단계; 및상기 결정된 픽셀 값에 기초하여 상기 이미지에 묘사된 상기 인물이 착용한 상기 패션 아이템의 속성을 대체하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 자세는 특정 방향을 따라 가리키는 신체 부분을 포함하고,상기 특정 방향을 따라 상기 신체 부분으로부터 연장되는 라인과 교차하는 객체를 식별하는 단계; 및음성 입력의 모호한 의도가 신체 부분으로부터 연장되는 라인과 교차하는 객체에 기초하여 식별된 객체를 지칭함을 분별하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 객체는 상기 이미지에 묘사된 상기 인물이 착용한 제1 패션 아이템, 상기 이미지에 묘사된 제2 인물이 착용한 제2 패션 아이템, 상기 제2 인물, 또는 상기 이미지에서의 픽셀의 색상 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 AR 동작을 수행하라는 상기 요청은 상기 이미지에 묘사된 상기 사람에게 패션 아이템을 추가하는 것 또는 상기 이미지에 묘사된 상기 인물이 착용한 주어진 패션 아이템의 색상 또는 속성을 변경하는 것 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제17항 중 어느 한 항에 있어서, 상기 자세는 형상을 표현하고, 상기 모호한 의도의 대명사는 상기 자세에 의해 표현되는 형상에 기초하여 해석되고, 상기 음성 입력을 수신하는 것에 응답하여 상기 자세에 의해 표현되는 형상에 기초하여 하나 이상의 AR 요소를 제시하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서,동작들을 수행하도록 구성된 하나 이상의 프로세서를 포함하고, 상기 동작들은 사람을 묘사하는 이미지를 수신하는 동작; 상기 사람의 골격 관절들의 세트를 식별하는 동작; 상기 골격 관절들의 세트의 위치확인에 기초하여 상기 이미지에 묘사된 상기 사람의 자세를 식별하는 동작; 증강 현실(AR) 동작을 수행하라는 요청을 포함하는 음성 입력을 수신하는 동작 -상기 음성 입력은 모호한 의도를 포함함 -; 상기 이미지에 묘사된 상기 사람의 자세에 기초하여 상기 음성 입력의 모호한 의도를 분별하는 동작; 및 상기 음성 입력을 수신하는 것에 응답하여, 상기 이미지에 묘사된 상기 사람의 자세에 기초하여 상기 음성 입력의 모호한 의도를 분별하는 것에 기초하여 상기 AR 동작을 수행하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하는 명령어들을 포함하는 증강 현실 시스템을 포함하는 비일시적 머신 판독가능 저장 매체로서, 상기 동작들은사람을 묘사하는 이미지를 수신하는 동작;상기 사람의 골격 관절들의 세트를 식별하는 동작;상기 골격 관절들의 세트의 위치확인에 기초하여 상기 이미지에 묘사된 상기 사람의 자세를 식별하는 동작;증강 현실(AR) 동작을 수행하라는 요청을 포함하는 음성 입력을 수신하는 동작- 상기 음성 입력은 모호한 의도를 포함함 -;상기 이미지에 묘사된 상기 사람의 자세에 기초하여 상기 음성 입력의 모호한 의도를 분별하는 동작; 및상기 음성 입력을 수신하는 것에 응답하여, 상기 이미지에 묘사된 상기 사람의 자세에 기초하여 상기 음성 입력의 모호한 의도를 분별하는 것에 기초하여 상기 AR 동작을 수행하는 동작을 포함하는, 비일시적 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ZOHAR, Matan</engName><name>조하르, 마탄</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ZHAO, Yanli</engName><name>자오, 얀리</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>FULKERSON, Brian</engName><name>풀커슨, 브라이언</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BERGER, Itamar</engName><name>베르거, 이타마르</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.11</priorityApplicationDate><priorityApplicationNumber>17/498,510</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.05.09</receiptDate><receiptNumber>1-1-2024-0503300-23</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.05.09</receiptDate><receiptNumber>1-1-2024-0504853-27</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.05.13</receiptDate><receiptNumber>1-5-2024-0079055-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.08.07</receiptDate><receiptNumber>9-5-2025-0754474-59</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247015476.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936925b075a6e23cc9db4df211df721b1dc607c1eb869822862ae750d2db0ee5d45225a4e591d931ccab61d49b1595db9ce61bfd00eb7e083e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf28dccbef02564c51f97ec698280c09430726ca020304f0f2b9a118b5db67daa71dfbafe26f515856d29c87a1965e2172f3f672f151c90fa1</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>