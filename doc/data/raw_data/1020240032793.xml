<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:14.1014</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0032793</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 인식 모델의 학습 방법 및 그 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR TRAINING OBJECT DETECTION MODEL</inventionTitleEng><openDate>2025.05.20</openDate><openNumber>10-2025-0069805</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 30/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/894</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 아래의 개시는 객체 인식 모델의 학습 방법 및 장치에 관한 것으로, 사전 학습된(pre-trained) 텍스트-가이드 모델 및 이미지 특징 추출기를 이용하는 텍스트-가이드 학습 동작, BEV 인코더 및 포인트 클라우드 인코더를 이용하는 라이다-가이드 학습 동작 및 텍스트-가이드 학습 결과 및 라이다-가이드 학습 결과에 기초하여, 객체 인식 모델을 학습하는 동작을 포함하고, 텍스트-가이드 학습 동작은 하나 이상의 텍스트 입력 및 하나 이상의 텍스트 입력에 대응하는 하나 이상의 이미지 입력을 수신하는 동작 및 텍스트-가이드 모델 및 이미지 특징 추출기를 이용하여, 객체 인식 모델의 학습에 사용되는 하나 이상의 텍스트-이미지 특징을 출력하는 동작을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 사전 학습된(pre-trained) 텍스트-가이드 모델 및 이미지 특징 추출기를 이용하는 텍스트-가이드 학습 동작;BEV 인코더 및 포인트 클라우드 인코더를 이용하는 라이다-가이드 학습 동작; 및상기 텍스트-가이드 학습 결과 및 상기 라이다-가이드 학습 결과에 기초하여, 객체 인식 모델을 학습하는 동작을 포함하고,상기 텍스트-가이드 학습 동작은하나 이상의 텍스트 입력 및 상기 하나 이상의 텍스트 입력에 대응하는 하나 이상의 이미지 입력을 수신하는 동작; 및상기 텍스트-가이드 모델 및 이미지 특징 추출기를 이용하여, 상기 객체 인식 모델의 학습에 사용되는 하나 이상의 텍스트-이미지 특징을 출력하는 동작을 포함하는, 객체 인식 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 하나 이상의 텍스트-이미지 특징을 출력하는 동작은상기 하나 이상의 텍스트 입력에 대해 상기 텍스트-가이드 모델에 포함된 텍스트 인코더 및 제1 투영 레이어 모듈을 통해 의미론적(semantic) 정보 인코딩을 수행하여, 하나 이상의 카메라 변형(camera-variant) 정보를 출력하는 동작; 및상기 하나 이상의 카메라 변형 정보와 상기 이미지 특징 추출기에서 추출된 하나 이상의 이미지 특징을 더하여, 상기 텍스트-이미지 특징을 생성하는 동작을 포함하는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 라이다-가이드 학습 동작은상기 포인트 클라우드 인코더로부터 획득한 라이다 BEV들과 상기 BEV 인코더에 기초하여 생성된 이미지 BEV들을 대조 학습하는 동작을 포함하는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 대조 학습하는 동작은상기 라이다 BEV와 상기 이미지 BEV에 대한 교차 상관 관계를 제2 손실 함수에 기초하여 학습하는 동작을 포함하는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 객체 인식 모델을 학습하는 동작은상기 하나 이상의 텍스트-이미지 특징 또는 상기 대조 학습 결과에 기초하여, 상기 이미지 특징 추출기, 뎁스 추출기, 상기 BEV 인코더, 디텍션 헤드 중 적어도 하나를 업데이트하는 동작을 포함하는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 뎁스 추출기는상기 하나 이상의 텍스트-이미지 특징에 기초하여 제1 뎁스 정보를 생성하고,상기 제1 뎁스 정보, 뎁스 추출 포인트 클라우드로부터 생성된 제2 뎁스 정보 및 뎁스 손실 함수에 기초하여 업데이트되는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 BEV 인코더는상기 뎁스 추출기를 이용하여 추출된 뎁스 특징 및 상기 텍스트-이미지 특징에 기초하여 생성된 합성 이미지 특징에 기초하여, 상기 이미지 BEV를 생성하는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 사전 학습된 텍스트-가이드 모델은텍스트 인코더, 제2 투영 레이어 모듈 및 이미지 인코더를 활용하여, 상기 제2 투영 레이어 모듈을 제1 투영 레이어 모듈로 업데이트하는 텍스트-가이드 모델 학습 방법에 의해 획득되는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 텍스트-가이드 모델 학습 방법은학습용 텍스트 입력 및 학습용 이미지 입력을 수신하고,상기 학습용 텍스트 입력에서 상기 텍스트 인코더 및 상기 제2 투영 레이어 모듈을 이용하여 학습용 텍스트 특징-학습용 카메라 변형 정보를 포함함-을 추출하여, 공유 임베딩 공간에 투영하고,상기 학습용 이미지 입력에서 상기 이미지 인코더를 이용하여 학습용 이미지 특징을 추출하여, 상기 공유 임베딩 공간에 투영하고,미리 결정된 방법을 이용하여, 상기 제2 투영 레이어 모듈을 제1 투영 레이어 모듈로 업데이트하는 방법인, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 미리 결정된 방법은상기 학습용 텍스트 특징과 상기 학습용 이미지 특징을 상기 공유 임베딩 공간에서 대조 정렬 학습하고,상기 대조 정렬 학습 결과 및 제1 손실 함수를 이용하여, 상기 제2 투영 레이어 모듈을 상기 제1 투영 레이어 모듈로 학습하는 방법인, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 제1 손실 함수는상기 학습용 텍스트 특징에서 불분명한 기하학적 노이즈를 억제하는 카메라 분류기를 포함하는, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>12. 텍스트-이미지 쌍의 입력으로부터 카메라 변형 정보를 생성하는 사전 학습된 텍스트-가이드 모델;상기 텍스트-이미지 쌍의 입력으로부터 이미지 특징을 추출하는 이미지 특징 추출기;상기 이미지 특징에 기초하여 뎁스 정보를 추출하는 뎁스 추출기;상기 카메라 변형 정보, 상기 이미지 특징 및 상기 뎁스 정보에 기초하여 이미지 BEV를 생성하는 이미지 BEV; 및상기 이미지 BEV에 기초하여, 객체 인식을 수행하는 디텍션 헤드를 포함하는, 텍스트-가이드 객체 인식 모델.</claim></claimInfo><claimInfo><claim>13. 객체 인식 모델 학습 장치에 있어서,인스트럭션들을 포함하는 메모리; 및사전 학습된 텍스트-가이드 모델, 이미지 특징 추출기, BEV 인코더 및 라이다-가이드 모델 -포인트 클라우드 인코더를 포함함-, 디텍션 헤드를 구동하는 하나 이상의 프로세서를 포함하고,상기 인스트럭션들은 상기 프로세서에 의해 실행될 때, 상기 객체 인식 모델 학습 장치로 하여금하나 이상의 텍스트 입력 및 상기 하나 이상의 텍스트 입력에 대응하는 하나 이상의 이미지 입력을 수신하고, 상기 텍스트-가이드 모델 및 상기 이미지 특징 추출기를 이용하여, 상기 객체 인식 모델의 학습에 사용되는 하나 이상의 텍스트-이미지 특징을 출력하고,상기 텍스트-이미지 특징 및 상기 라이다-가이드 모델의 결과에 기초하여, 객체 인식 모델을 학습하도록 하는, 객체 인식 모델 학습 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 텍스트-가이드 모델은상기 하나 이상의 텍스트 입력에 대해 텍스트 인코더 및 제1 투영 레이어 모듈을 통해 의미론적 정보 인코딩을 수행하여, 상기 하나 이상의 카메라 변형 정보를 생성하고,상기 하나 이상의 텍스트-이미지 특징은상기 하나 이상의 카메라 변형 정보와 상기 이미지 특징 추출기에서 추출된 하나 이상의 이미지 특징을 더하여 생성되는, 객체 인식 모델 학습 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 라이다-가이드 모델은상기 포인트 클라우드 인코더로부터 획득한 라이다 BEV들과 상기 BEV 인코더로부터 획득한 이미지 BEV들을 대조 학습하는 모델인, 객체 인식 모델 학습 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 대조 학습은상기 라이다 BEV와 상기 이미지 BEV에 대한 교차 상관 관계를 제2 손실 함수에 기초하여 상기 객체 인식 모델을 학습하는 방법인, 객체 인식 모델 학습 장치.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 프로세서는상기 하나 이상의 텍스트-이미지 특징 또는 상기 대조 학습 결과에 기초하여, 상기 이미지 특징 추출기, 상기 뎁스 추출기, 상기 BEV 인코더, 상기 디텍션 헤드 중 적어도 하나를 업데이트하는, 객체 인식 모델 학습 장치.</claim></claimInfo><claimInfo><claim>18. 텍스트-가이드 모델 학습 장치에 있어서,인스트럭션들을 포함하는 메모리; 및텍스트 인코더, 제2 투영 레이어 모듈 및 이미지 인코더를 포함하는 하나 이상의 프로세서를 포함하고,상기 인스트럭션들은 상기 프로세서에 의해 실행될 때, 상기 텍스트-가이드 모델 학습 장치로 하여금,텍스트 입력 및 이미지 입력을 수신하고,상기 텍스트 입력에서 상기 텍스트 인코더 및 상기 제2 투영 레이어 모듈을 이용하여 텍스트 특징-카메라 변형 정보를 포함함-을 추출하여, 공유 임베딩 공간에 투영하고,상기 이미지 입력에서 상기 이미지 인코더를 이용하여 이미지 특징을 추출하여, 상기 공유 임베딩 공간에 투영하고,미리 결정된 방법을 이용하여, 상기 제2 투영 레이어 모듈을 제1 투영 레이어 모듈로 업데이트하여, 사전 학습된 텍스트-가이드 모델을 획득하도록 하는, 텍스트-가이드 모델 학습 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 미리 결정된 방법은상기 텍스트 특징과 상기 이미지 특징을 상기 공유 임베딩 공간에서 대조 정렬 학습하고,상기 대조 정렬 학습 결과 및 제1 손실 함수를 이용하여, 상기 제2 투영 레이어 모듈을 상기 제1 투영 레이어 모듈로 학습하는 방법인, 객체 인식 모델 학습 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 제1 손실 함수는상기 학습용 텍스트 특징에서 불분명한 기하학적 노이즈를 억제하는 카메라 분류기를 포함하는, 객체 인식 모델 학습 방법.  </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo><applicantInfo><address>서울특별시 성북구...</address><code>220040170680</code><country>대한민국</country><engName>Korea University Research and Business Foundation</engName><name>고려대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 화성...</address><code>420210366401</code><country>대한민국</country><engName>JANG, Sujin</engName><name>장수진</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM Sang Pil</engName><name>김상필</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM Jin Kyu</engName><name>김진규</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>RYOO Won Jeong</engName><name>류원정</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170730324</code><country>대한민국</country><engName>LEE, Dong Wook</engName><name>이동욱</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>CHANG Gyu Sam</engName><name>장규삼</name></inventorInfo><inventorInfo><address>경기도 화성...</address><code>420170728003</code><country>대한민국</country><engName>JI, DAEHYUN</engName><name>지대현</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.11.10</priorityApplicationDate><priorityApplicationNumber>1020230155437</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.07</receiptDate><receiptNumber>1-1-2024-0261300-13</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240032793.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9372a0444bb10194dc01e1469a04adc2fdaff7e0f3f015a56cbb6e6409d26693fb9f68f47cab5b00fdfe5961ad02688d758c17b83a6685d4e2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb64526f5b1ad5d342636affcebc56288461ed37651b6516e39ed222de9d7f08cfb14ab646abc2047f709f6eb40bd6e464eb670d31ecfb1ea</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>