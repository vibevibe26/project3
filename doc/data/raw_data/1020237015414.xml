<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:00.50</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.10.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7015414</applicationNumber><claimCount>16</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 인코딩 및 디코딩, 비디오 인코딩 및 디코딩, 방법, 시스템 및 훈련 방법</inventionTitle><inventionTitleEng>IMAGE ENCODING AND DECODING, VIDEO ENCODING AND DECODING: METHODS, SYSTEMS AND TRAINING METHODS</inventionTitleEng><openDate>2023.07.17</openDate><openNumber>10-2023-0107563</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.10</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.05.04</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/13</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/124</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/19</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/88</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/184</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/42</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/59</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/91</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/422</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 손실 또는 무손실 이미지 또는 비디오 압축 및 전송을 위한 컴퓨터 구현 방법이 개시된다. 이 방법은, (i) 입력 이미지를 수신하는 단계, (ii) 인코더 훈련된 신경망을 사용해 상기 입력 이미지를 인코딩하여 y 잠재 표현(latent representation)을 생성하는 단계, (iii) 하이퍼인코더 훈련된 신경망을 사용해 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현(hyperlatent representation)을 생성하는 단계, (iv) 지정된 엔트로피 파라미터를 사용해 상기 z 하이퍼 잠재 표현을 양자화하여 양자화 z 하이퍼 잠재 표현을 생성하는 단계, (v) 지정된 엔트로피 파라미터를 사용하여, 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩(entropy encoding)하는 단계, (vi) 하이퍼디코더 훈련된 신경망을 사용해 상기 양자화 z 하이퍼 잠재 표현을 처리하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 컨텍스트 행렬 Ay를 구하는 단계, (vii) 암시적 인코딩 솔버를 사용해 상기 y 잠재 표현, 상기 위치 엔트로피 파라미터 μy 및 상기 컨텍스트 행렬 Ay를 처리하여 양자화 잠재 잔차를 구하는 단계, (viii) 상기 엔트로피 스케일 파라미터 σy를 사용해 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하는 단계, 및 (ix) 상기 제1 비트스트림과 상기 제2 비트스트림을 전송하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.04.28</internationOpenDate><internationOpenNumber>WO2022084702</internationOpenNumber><internationalApplicationDate>2021.10.25</internationalApplicationDate><internationalApplicationNumber>PCT/GB2021/052770</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송을 위한 컴퓨터 구현 방법에 있어서,(i) 입력 이미지를 수신하는 단계,(ii) 인코더 훈련된 신경망을 사용해 상기 입력 이미지를 인코딩하여 y 잠재 표현(latent representation)을 생성하는 단계,(iii) 하이퍼인코더 훈련된 신경망을 사용해 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현(hyperlatent representation)을 생성하는 단계,(iv) 지정된 엔트로피 파라미터를 사용해 상기 z 하이퍼 잠재 표현을 양자화하여 양자화 z 하이퍼 잠재 표현을 생성하는 단계,(v) 지정된 엔트로피 파라미터를 사용하여, 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩(entropy encoding)하는 단계,(vi) 하이퍼디코더 훈련된 신경망을 사용해 상기 양자화 z 하이퍼 잠재 표현을 처리하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 컨텍스트 행렬 Ay를 구하는 단계,(vii) 암시적 인코딩 솔버를 사용해 상기 y 잠재 표현, 상기 위치 엔트로피 파라미터 μy 및 상기 컨텍스트 행렬 Ay를 처리하여 양자화 잠재 잔차를 구하는 단계,(viii) 상기 엔트로피 스케일 파라미터 σy를 사용해 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하는 단계, 및(ix) 상기 제1 비트스트림과 상기 제2 비트스트림을 전송하는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,(iv) 단계의 지정된 엔트로피 파라미터는 지정된 위치 엔트로피 파라미터 μz이며,(v) 단계의 지정된 엔트로피 파라미터는 지정된 위치 엔트로피 파라미터 μz 및 지정된 엔트로피 스케일 파라미터 σzㅇ인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 암시적 인코딩 솔버는,(I) 양자화 잠재 잔차는 y 잠재 표현에서 μy를 뺀 값에, 양자화 y 잠재 표현에 작용하는 Ay를 뺀 값의 양자화 함수와 같다는 암시적 방정식, 및(II) 양자화 y 잠재 표현은 양자화된 잠재 잔차에 μy를 더한 값에, 양자화 y 잠재 표현에 작용하는 Ay를 더한 값과 같다는 암시적 방정식을 푸는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 암시적 인코딩 솔버는,B = I - A를 정의함으로써 암시적 방정식을 풀고, 여기서, A는 m x m 행렬이고 I는 m x m 단위 행렬이고,(a) B가 하삼각 행렬이면, 직렬방식 전진치환(forward substitution)이 사용되거나; 또는(b) B가 상삼각 행렬이면 직렬방식 후진치환(backward substitution)이 사용되거나; 또는(c) B를 삼각 분해로 인수 분해한 다음, 하부 삼각 인수를 전진치환으로 반전시키고 상부 삼각 인수를 후진치환으로 반전시켜 B * y = μ + (은 양자화 잔차(quantized residual)임)를 풀거나; 또는(d) B를 QR 분해로 인수 분해하고(Q는 직교 행렬, R은 상삼각 행렬임), 해는 y = R-1Qtμ(Qt는 Q 전치(transpose))이거나, 또는 B를 B = QL(L은 하삼각행렬) 또는 B = RQ 또는 B = LQ(Q는 전치에 의해 반전되고, R은 후진치환으로 반전되며, L은 전진치환으로 반전됨)로 인수 분해하고 각각의 해는 y = L-1Qtμ, 또는 y = QtR-1μ, 또는 y = QtL-1μ이거나; 또는(e) B= D+L+U(D는 대각 행렬, L은 순하삼각 행렬, U는 순상삼각 행렬)를 계산한 다음 수렴 기준이 충족될 때까지 반복적인 자코비(Jacobi) 방법을 적용하거나; 또는(f) 가우스-사이델(Gauss-Seidel) 방법을 사용하거나; 또는(g) 연속적 과완환(Successive Over Relaxation) 방법을 사용하거나; 또는 (h) 공역 기울기(Conjugate Gradient) 방법을 사용하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 암시적 인코딩 솔버는,반복 솔버를 사용하여 암시적 방정식을 풀고, 수렴 기준이 충족되면 반복을 종료하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,상기 암시적 인코딩 솔버는,잔차 및 양자화 잠재 표현 y를 반환하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 행렬 A는 하삼각행렬, 상삼각행렬, 순하삼각행렬, 또는 순상삼각행렬이거나, 또는A는 성긴 줄무늬 구조이거나, 또는A는 블록 행렬이거나, 또는A는 행렬 놈(matrix norm)이 1보다 작도록 구성되어 있거나, 또는A는 LU 또는 QR 분해와 같은 행렬 인수분해를 통해 파라미터화되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>8. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송을 위한 인코딩 컴퓨터 시스템에 있어서,상기 인코딩 컴퓨터 시스템은,인코딩 컴퓨터,인코더 훈련된 신경망,하이퍼인코더 훈련된 신경망, 및하이퍼디코더 훈련된 신경망을 포함하고,(i) 상기 인코딩 컴퓨터는 입력 이미지를 수신하도록 구성되고,(ii) 상기 인코딩 컴퓨터는 상기 인코더 훈련된 신경망을 사용해 입력 이미지를 인코딩하여 y 잠재 표현을 생성하도록 구성되고,(iii) 상기 인코딩 컴퓨터는 상기 하이퍼인코더 훈련된 신경망을 사용해 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현을 생성하도록 구성되고,(iv) 상기 인코딩 컴퓨터는 지정된 엔트로피 파라미터를 사용해 상기 z 하이퍼 잠재 표현을 양자화하여, 양자화 z 하이퍼 잠재 표현을 생성하도록 구성되고,(v) 상기 인코딩 컴퓨터는 지정된 엔트로피 파라미터를 사용하여, 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩하도록 구성되고,(vi) 상기 인코딩 컴퓨터는 상기 하이퍼디코더 훈련된 신경망을 사용해 상기 양자화 z 하이퍼 잠재 표현을 처리하여, 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 컨텍스트 행렬 Ay를 구하도록 구성되고,(vii) 상기 인코딩 컴퓨터는 암시적 인코딩 솔버를 사용해 상기 y 잠재 표현, 상기 위치 엔트로피 파라미터 μy 및 상기 컨텍스트 행렬 Ay를 처리하여, 양자화 잠재 잔차를 구하도록 구성되고,(viii) 상기 인코딩 컴퓨터는 상기 엔트로피 스케일 파라미터 σy를 사용해 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하도록 구성되고,(ix) 상기 인코딩 컴퓨터는 상기 제1 비트스트림 및 상기 제2 비트스트림을 전송하도록 구성되는것을 특징으로 하는 인코딩 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 인코딩 컴퓨터 시스템은,제1항 내지 제7항 중 어느 한 항의 방법을 수행하도록 구성되는 것을 특징으로 하는 인코딩 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>10. 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 컴퓨터 구현 방법에 있어서,(i) 제1 비트스트림과 제2 비트스트림을 수신하는 단계,(ii) 지정된 엔트로피 파라미터를 사용해, 산술 디코더를 사용하여 상기 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하는 단계,(iii) 하이퍼디코더 훈련된 신경망을 사용해 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 컨텍스트 행렬 Ay를 구하는 단계,(iv) 산술 디코더에서 상기 엔트로피 스케일 파라미터 σy를 사용해 제2 비트스트림을 디코딩하여, 양자화 잠재 잔차를 구하는 단계,(v) (예: 암시적) (예: 선형) 디코딩 솔버를 사용해 상기 양자화 잠재 잔차, 상기 위치 엔트로피 파라미터 μy 및 상기 컨텍스트 행렬 Ay를 처리하여 양자화 y 잠재 표현을 구하는 단계, 및(vi) 디코더 훈련된 신경망을 사용해 상기 양자화 y 잠재 표현을 디코딩하여 재구성된 이미지를 얻는 단계;를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, (ii) 단계의 지정된 엔트로피 파라미터는,지정된 위치 엔트로피 파라미터 μz 및 지정된 엔트로피 스케일 파라미터 σz인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>12. 제10항 또는 제11항에 있어서, (vii) 재구성된 이미지를 저장하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제10항 내지 제12항 중 어느 한 항에 있어서, 상기 (예: 암시적) (예: 선형) 디코딩 솔버는,양자화 y 잠재 표현이 양자화 잠재 잔차에 μy를 더한 값에 양자화 y 잠재 표현에 작용하는 Ay를 더한 값과 같다는 (예: 암시적) 방정식을 푸는것을 특징으로 하는 방법. </claim></claimInfo><claimInfo><claim>14. 제10항 내지 제13항 중 어느 한 항에 있어서, 상기 (예: 암시적) (예: 선형) 디코딩 솔버는,B = I - A를 정의함으로써 (예: 암시적) 방정식을 풀고, 여기서, A는 m x m 행렬이고 I는 m x m 단위 행렬이고,(a) B가 하삼각 행렬이면 직렬방식 전진치환(forward substitution)이 사용되거나; 또는(b) B가 상삼각 행렬이면 직렬방식 후진치환(backward substitution)이 사용되거나; 또는(c) B를 삼각 분해로 인수 분해한 다음, 하부 삼각 인수를 전진치환으로 반전시키고 상부 삼각 인수를 후진치환으로 반전시켜 BB * y = μ + (은 양자화 잔차(quantized residual)임)를 풀거나; 또는(d) B를 QR 분해로 인수 분해하고(Q는 직교 행렬, R은 상삼각 행렬임), 해는 y = R-1Qtμ(Qt는 Q 전치(transpose))이거나, 또는 B를 B = QL(L은 하삼각행렬) 또는 B = RQ 또는 B = LQ(Q는 전치에 의해 반전되고, R은 후진치환으로 반전되며, L은 전진치환으로 반전됨)로 인수 분해하고 각각의 해는 y = L-1Qtμ, 또는 y = QtR-1μ, 또는 y = QtL-1μ이거나; 또는(e) B= D+L+U(D는 대각 행렬, L은 순하삼각 행렬, U는 순상삼각 행렬)를 계산한 다음 수렴 기준이 충족될 때까지 반복적인 자코비 방법을 적용하거나; 또는 (f) 가우스-사이델(Gauss-Seidel) 방법을 사용하거나; 또는(g) 연속적 과완환(Successive Over Relaxation) 방법을 사용하거나; 또는(h) 공역 기울기(Conjugate Gradient) 방법을 사용하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>15. 제10항 내지 제14항 중 어느 한 항에 있어서, 반복 솔버를 사용하고, 수렴 기준이 충족되면 반복을 종료하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>16. 제10항 내지 제15항 중 어느 한 항에 있어서, 상기 (예: 암시적) (예: 선형) 디코딩 솔버는,인코딩에 사용된 솔버와 반드시 동일한 유형의 솔버일 필요가 없는(예: 다른 솔버)것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>17. 제10항 내지 제16항 중 어느 한 항에 있어서, 상기 행렬 A는 하삼각행렬, 상삼각행렬, 순하삼각행렬, 또는 순상삼각행렬이거나, 또는A가 성긴 줄무늬 구조이거나, 또는A가 블록 행렬이거나, 또는A가 행렬 놈(matrix norm)이 1보다 작도록 구성되어 있거나, 또는A가 LU 또는 QR 분해와 같은 행렬 인수분해를 통해 파라미터화되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>18. 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 디코딩 컴퓨터 시스템에 있어서,상기 디코딩 컴퓨터 시스템은,디코딩 컴퓨터,디코더 훈련된 신경망, 및하이퍼디코더 훈련된 신경망을 포함하고,(i) 상기 디코딩 컴퓨터는 제1 비트스트림 및 제2 비트스트림을 수신하도록 구성되고;(ii) 상기 디코딩 컴퓨터는 지정된 엔트로피 파라미터를 사용하고, 산술 디코더를 사용하여 상기 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하도록 구성되고;(iii) 상기 디코딩 컴퓨터는 하이퍼디코더 훈련된 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여, 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 컨텍스트 행렬 Ay를 구하도록 구성되고;(iv) 상기 디코딩 컴퓨터는 산술 디코더로 상기 엔트로피 스케일 파라미터 σy를 사용해, 상기 제2 비트스트림을 디코딩하여 양자화 잠재 잔차를 구하도록 구성되고;(v)  상기 디코딩 컴퓨터는 (예: 암시적) (예: 선형) 디코딩 솔버를 사용해, 상기 양자화 잠재 잔차, 상기 위치 엔트로피 파라미터 μy 및 상기 컨텍스트 행렬 Ay를 처리하여 양자화 y 잠재 표현을 구하도록 구성되고;(vi) 상기 디코딩 컴퓨터는 디코더 훈련된 신경망을 사용해, 상기 양자화 y 잠재 표현을 디코딩하여 재구성된 이미지를 얻도록 구성되는것을 특징으로 하는 디코딩 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 디코딩 컴퓨터 시스템은,제10항 내지 제17항 중 어느 한 항의 방법을 수행하도록 구성되는것을 특징으로 하는 디코딩 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>20. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송, 및 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 컴퓨터 구현 방법에 있어서,제1항 내지 제7항 중 어느 한 항의 방법, 및제10항 내지 제17항 중 어느 한 항의 방법을 포함하는 방법.</claim></claimInfo><claimInfo><claim>21. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송, 그리고 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 시스템에 있어서,제8항 또는 제9항의 시스템, 및제18항 또는 제19항의 시스템을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>22. 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한, 인코더 신경망, 디코더 신경망, 하이퍼인코더 신경망 및 하이퍼디코더 신경망, 및 엔트로피 파라미터, 상기 신경망 및 상기 엔트로피 파라미터를 훈련시키는 컴퓨터 구현 방법에 있어서,(i) 입력 훈련 이미지를 수신하는 단계;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하는 단계;(iii) 상기 하이퍼인코더 신경망을 사용해, 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현을 생성하는 단계;(iv) 상기 엔트로피 파라미터 중 일 엔트로피 파라미터를 사용해, 상기 z 하이퍼 잠재 표현을 양자화하여 양자화 z 하이퍼 잠재 표현을 생성하는 단계;(v) 상기 엔트로피 파라미터를 사용하여, 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩하는 단계;(vi) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 처리하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 컨텍스트 행렬 Ay를 구하는 단계;(vii) 암시적 인코딩 솔버를 사용해, 상기 y 잠재 표현, 위치 엔트로피 파라미터 μy 및 컨텍스트 행렬 Ay를 처리하여 양자화 잠재 잔차를 구하는 단계;(viii) 상기 엔트로피 스케일 파라미터 σy를 사용해 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하는 단계;(ix) 상기 엔트로피 파라미터를 사용해, 산술 디코더를 사용하여 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하는 단계;(x) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 컨텍스트 행렬 Ay를 구하는 단계;(xi) 산술 디코더의 엔트로피 스케일 파라미터 σy를 사용해, 제2 비트스트림을 디코딩하여 양자화 잠재 잔차를 구하는 단계;(xii) (예: 암시적) (예: 선형) 디코딩 솔버를 사용해, 상기 양자화 잠재 잔차, 위치 엔트로피 파라미터 μy 및 컨텍스트 행렬 Ay를 처리하여 양자화 y 잠재 표현을 구하는 단계;(xiii) 상기 디코더 신경망을 사용해, 상기 양자화 y 잠재 표현을 디코딩하여 재구성된 이미지를 얻는 단계;(xiv) 재구성된 이미지와 입력 훈련 이미지 간의 차이를 기반으로 한 손실 함수 및 레이트 항(rate term)을 평가하는 단계;(xv) 상기 손실 함수의 기울기를 평가하는 단계;(xvi) 상기 손실 함수의 기울기를 디코더 신경망, 하이퍼디코더 신경망, 하이퍼인코더 신경망, 인코더 신경망을 통해, 엔트로피 파라미터를 이용해 역전파(back-propagating)하여 인코더, 디코더, 하이퍼인코더 및 하이퍼디코더 신경망의 가중치를 업데이트하고, 상기 엔트로피 파라미터를 업데이트하는 단계; 및(xvii) 훈련 이미지 세트를 이용해 (i) 내지 (xvi) 단계를 반복하여, 훈련된 인코더 신경망, 훈련된 디코더 신경망, 훈련된 하이퍼인코더 신경망 및 훈련된 하이퍼디코더 신경망, 그리고 훈련된 엔트로피 파라미터를 생성하는 단계; 및 (xviii) 상기 훈련된 인코더 신경망, 상기 훈련된 디코더 신경망, 상기 훈련된 하이퍼인코더 신경망 및 상기 훈련된 하이퍼디코더 신경망의 가중치를 저장하고, 상기 훈련된 엔트로피 파라미터를 저장하는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, (iv) 단계의 엔트로피 파라미터는,위치 엔트로피 파라미터 μz이고,(v), (ix) 및 (xvi) 내지 (xviii) 단계의 엔트로피 파라미터는,위치 엔트로피 파라미터 μz 및 엔트로피 스케일 파라미터 σz인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>24. 제22항 또는 제23항에 있어서, 상기 암시적 인코딩 솔버는,(I) 양자화 잠재 잔차는 y 잠재 표현에서 μy를 뺀 값에, 양자화 y 잠재 표현에 작용하는 Ay를 뺀 값의 양자화 함수와 같다는 암시적 방정식; 및(II) 양자화 y 잠재 표현은 양자화된 잠재 잔차에 μy를 더한 값에, 양자화 y 잠재 표현에 작용하는 Ay를 더한 값과 같다는 암시적 방정식 을 푸는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>25. 제22항 내지 제24항 중 어느 한 항에 있어서, 상기 (예: 암시적) (예: 선형) 디코딩 솔버는,양자화 y 잠재 표현이 양자화 잠재 잔차에 μy를 더한 값에 양자화 y 잠재 표현에 작용하는 Ay를 더한 값과 같다는 (예: 암시적) 방정식을 푸는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>26. 제22항 내지 제25항 중 어느 한 항에 있어서, 압축 알고리즘 훈련 중에 실측값 변수(이미지 또는 잠재)를 사용하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>27. 제22항 내지 제26항 중 어느 한 항에 있어서, 상기 암시적 인코딩 솔버는,B = I - A를 정의함으로써 암시적 방정식을 푸는 것으로서, 여기서, A는 m x m 행렬이고, I는 m x m 단위 행렬이고,(a) B가 하삼각 행렬이면 직렬방식 전진치환(forward substitution)이 사용되거나; 또는(b) B가 상삼각 행렬이면 직렬방식 후진치환(backward substitution)이 사용되거나; 또는(c) B를 삼각 분해로 인수 분해한 다음, 하부 삼각 인수를 전진치환으로 반전시키고 상부 삼각 인수를 후진치환으로 반전시켜 B * y = μ + (은 양자화 잔차(quantized residual)임)를 풀거나; 또는(d) B를 QR 분해로 인수 분해하고(Q는 직교 행렬, R은 상삼각 행렬임), 해는 y = R-1Qtμ(Qt는 Q 전치(transpose))이거나, 또는 B를 B = QL(L은 하삼각행렬) 또는 B = RQ 또는 B = LQ(Q는 전치에 의해 반전되고, R은 후진치환으로 반전되며, L은 전진치환으로 반전됨)로 인수 분해하고 각각의 해는 y = L-1Qtμ, 또는 y = QtR-1μ, 또는 y = QtL-1μ이거나; 또는(e) B= D+L+U(D는 대각 행렬, L은 순하삼각 행렬, U는 순상삼각 행렬)를 계산한 다음 수렴 기준이 충족될 때까지 반복적인 자코비(Jacobi) 방법을 적용하거나; 또는(f) 가우스-사이델(Gauss-Seidel) 방법을 사용하거나; 또는(g) 연속적 과완환(Successive Over Relaxation) 방법을 사용하거나; 또는 (h) 공역 기울기(Conjugate Gradient) 방법을 사용하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>28. 제22항 내지 제27항 중 어느 한 항에 있어서, 상기 (예: 암시적) (예: 선형) 디코딩 솔버는,B = I - A를 정의함으로써 (예: 암시적) 방정식을 푸는 것으로서, 여기서, A는 m x m 행렬이고, I는 m x m 단위 행렬이며,(a) B가 하삼각 행렬이면 직렬방식 전진치환(forward substitution)이 사용되거나; 또는(b) B가 상삼각 행렬이면 직렬방식 후진치환(backward substitution)이 사용되거나; 또는(c) B를 삼각 분해로 인수 분해한 다음, 하부 삼각 인수를 전진치환으로 반전시키고 상부 삼각 인수를 후진치환으로 반전시켜 B * y = μ + (은 양자화 잔차(quantized residual)임)를 풀거나; 또는(d) B를 QR 분해로 인수 분해하고(Q는 직교 행렬, R은 상삼각 행렬임), 해는 y = R-1Qtμ(Qt는 Q 전치(transpose))이거나, 또는 B를 B = QL(L은 하삼각행렬) 또는 B = RQ 또는 B = LQ(Q는 전치에 의해 반전되고, R은 후진치환으로 반전되며, L은 전진치환으로 반전됨)로 인수 분해하고 각각의 해는 y = L-1Qtμ, 또는 y = QtR-1μ, 또는 y = QtL-1μ이거나; 또는(e) B= D+L+U(D는 대각 행렬, L은 순하삼각 행렬, U는 순상삼각 행렬)를 계산한 다음 수렴 기준이 충족될 때까지 반복적인 자코비(Jacobi) 방법을 적용하거나; 또는(f) 가우스-사이델(Gauss-Seidel) 방법을 사용하거나; 또는(g) 연속적 과완환(Successive Over Relaxation) 방법을 사용하거나; 또는 (h) 공역 기울기(Conjugate Gradient) 방법을 사용하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>29. 제22항 내지 제28항 중 어느 한 항에 있어서, 상기 솔버가 반환한 양자화 y 잠재 표현이 데이터 압축 파이프라인의 다른 곳에서 사용되어, 훈련 중에 디코드 솔버(Decode Solver)를 실행할 필요성을 제거함으로써, AI 기반 압축 알고리즘을 훈련하는 데 필요한 시간을 크게 단축시킬 수 있는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>30. 제22항 내지 제29항 중 어느 한 항에 있어서,상기 암시적 인코딩 솔버는,반복 솔버를 사용하여 암시적 방정식을 풀며, 수렴 기준이 충족되면 반복을 종료하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>31. 제22항 내지 제30항 중 어느 한 항에 있어서,상기 암시적 인코딩 솔버는,잔차 및 양자화 잠재 표현 y를 반환하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>32. 제22항 내지 제31항 중 어느 한 항에 있어서,상기 행렬 A는 하삼각행렬, 상삼각행렬, 순하삼각행렬, 또는 순상삼각행렬이거나, 또는A가 성긴 줄무늬 구조이거나, 또는A가 블록 행렬이거나, 또는A가 행렬 놈(matrix norm)이 1보다 작도록 구성되어 있거나, 또는A가 LU 또는 QR 분해와 같은 행렬 인수분해를 통해 파라미터화되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>33. 제22항 내지 제32항 중 어느 한 항에 있어서,상기 (예: 암시적) (예: 선형) 디코딩 솔버는,인코딩에 사용된 솔버와 반드시 동일한 유형의 솔버일 필요가 없는(예: 다른 솔버)것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>34. 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한, 인코더 신경망, 디코더 신경망, 하이퍼인코더 신경망 및 하이퍼디코더 신경망, 및 엔트로피 파라미터, 상기 신경망 및 상기 엔트로피 파라미터를 훈련시키기 위해, 프로세서에서 실행 가능한 컴퓨터 프로그램 제품에 있어서,(i) 입력 훈련 이미지를 수신하고;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하고;(iii) 상기 하이퍼인코더 신경망을 사용해, 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현을 생성하고;(iv) 상기 엔트로피 파라미터 중 일 엔트로피 파라미터를 사용해, 상기 z 하이퍼 잠재 표현을 양자화하여 양자화 z 하이퍼 잠재 표현을 생성하고;(v) 상기 엔트로피 파라미터를 사용하여, 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩하고;(vi) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 처리하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 컨텍스트 행렬 Ay를 구하고;(vii) 암시적 인코딩 솔버를 사용해, 상기 y 잠재 표현, 위치 엔트로피 파라미터 μy 및 컨텍스트 행렬 Ay를 처리하여 양자화 잠재 잔차를 구하고;(viii) 상기 엔트로피 스케일 파라미터 σy를 사용해, 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하고;(ix) 상기 엔트로피 파라미터를 사용해, 산술 디코더를 사용하여 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하고;(x) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 컨텍스트 행렬 Ay를 구하고;(xi) 산술 디코더의 엔트로피 스케일 파라미터 σy를 사용해, 제2 비트스트림을 디코딩하여 양자화 잠재 잔차를 구하고;(xii) (예: 암시적) (예: 선형) 디코딩 솔버를 사용해, 상기 양자화 잠재 잔차, 위치 엔트로피 파라미터 μy 및 컨텍스트 행렬 Ay를 처리하여 양자화 y 잠재 표현을 구하고;(xiii) 상기 디코더 신경망을 사용해, 상기 양자화 y 잠재 표현을 디코딩하여 재구성된 이미지를 얻고;(xiv) 재구성된 이미지와 입력 훈련 이미지 간의 차이를 기반으로 한 손실 함수 및 레이트 항(rate term)을 평가하고;(xv) 상기 손실 함수의 기울기를 평가하고;(xvi) 상기 손실 함수의 기울기를 디코더 신경망, 하이퍼디코더 신경망, 하이퍼인코더 신경망, 인코더 신경망을 통해, 엔트로피 파라미터를 이용해 역전파하여 인코더, 디코더, 하이퍼인코더 및 하이퍼디코더 신경망의 가중치를 업데이트하고, 상기 엔트로피 파라미터를 업데이트하고;(xvii) 훈련 이미지 세트를 이용해 (i) 내지 (xvi) 단계를 반복하여, 훈련된 인코더 신경망, 훈련된 디코더 신경망, 훈련된 하이퍼인코더 신경망 및 훈련된 하이퍼디코더 신경망, 그리고 훈련된 엔트로피 파라미터를 생성하고; 및 (xviii) 상기 훈련된 인코더 신경망, 상기 훈련된 디코더 신경망, 상기 훈련된 하이퍼인코더 신경망 및 상기 훈련된 하이퍼디코더 신경망의 가중치를 저장하고, 상기 훈련된 엔트로피 파라미터를 저장하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>35. 제34항에 있어서, 제22항 내지 제33항 중 어느 한 항의 방법을 수행하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>36. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송을 위한 컴퓨터 구현 방법에 있어서,(i) 입력 이미지를 수신하는 단계;(ii) 인코더 훈련된 신경망을 사용해, 상기 입력 이미지를 인코딩하여 y 잠재 표현을 생성하는 단계;(iii) 하이퍼인코더 훈련된 신경망을 사용해, 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현을 생성하는 단계;(iv) 사전 학습된 엔트로피 파라미터를 사용해, 상기 z 하이퍼 잠재 표현을 양자화하여 양자화 z 하이퍼 잠재 표현을 생성하는 단계;(v) 상기 사전 학습된 엔트로피 파라미터를 포함하는 사전 학습된 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하고, 산술 인코더를 사용하여 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩하는 단계;(vi) 하이퍼디코더 훈련된 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 처리하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하는 단계;(vii) 암시적 인코딩 솔버를 사용해, 상기 y 잠재 표현, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 잠재 잔차를 구하는 단계;(viii) 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용하고, 산술 인코더를 사용하여 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하는 단계; 및(ix) 상기 제1 비트스트림과 상기 제2 비트스트림을 전송하는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서, (iv) 단계의 사전 학습된 엔트로피 파라미터는,사전 학습된 위치 엔트로피 파라미터 μz이고,(v) 단계의 사전 학습된 엔트로피 파라미터는,사전 학습된 위치 엔트로피 파라미터 μz 및 사전 학습된 엔트로피 스케일 파라미터 σz인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>38. 제36항 또는 제37항에 있어서, (viii) 단계의 1차원 이산 확률 질량 함수는 0의 평균값(zero mean)을 갖는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>39. 제36항 내지 제38항 중 어느 한 항에 있어서, 상기 암시적 인코딩 솔버는,(I) 양자화 잠재 잔차는 y 잠재 표현에서 μy를 뺀 값에, 양자화 y 잠재 표현에 작용하는 Ly를 뺀 값의 어림 함수(rounding function)와 같다는 암시적 방정식; 및(II) 양자화된 y 잠재 표현은 양자화된 잠재 잔차에 μy를 더하고, 양자화된 y 잠재 표현에 작용하는 Ly를 더하는 것과 같다는 암시적 방정식을 푸는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>40. 제36항 내지 제39항 중 어느 한 항에 있어서,상기 양자화 y 잠재 표현 는 상기 y 잠재 표현의 양자화된 값에서 위치 엔트로피 파라미터 μy를 뺀 값에서, 상기 양자화 y 잠재 표현 에 작용하는 L 컨텍스트 행렬을 뺀 값에, 위치 엔트로피 파라미터 μy를 더한 값에, 상기 양자화 y 잠재 표현 에 작용하는 L 컨텍스트 행렬 Lij를 더한 값과 같은 방정식을 풀고, 이 방정식은 자동 회귀 모델에서 픽셀의 종속성 순서에 따라 픽셀에 대해 순차적으로 풀리며, 모든 픽셀을 자동 회귀 순서대로 반복하고,반복할 때마다를 적용하여 현재 반복에서 양자화된 잠재를 구하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>41. 제36항 내지 제40항 중 어느 한 항에 있어서,희소 컨텍스트 행렬 L에 의해 정의된 자동회귀 구조를 이용하여 직렬 디코딩 패스의 구성 요소를 병렬화하고,상기 접근 방식에서 먼저 잠재 픽셀 간의 종속성 관계를 정의하는 종속성 그래프 DAG(Directed Acyclic Graph)를 생성하고,상기 종속성 그래프는 L 행렬의 희소성 구조를 기반으로 구성되고,그런 다음, DAG의 동일한 레벨에서 서로 조건적으로(conditionally) 독립적인 픽셀이 해당 레벨에 있는 다른 픽셀의 계산에 영향을 주지 않고 모두 병렬로 계산되고, 및상기 그래프는 루트 노드에서 시작하여 DAG 레벨을 통해 반복되고 각 레벨마다 모든 노드가 병렬로 처리되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>42. 제36항 내지 제41항 중 어느 한 항에 있어서,학습된 L-컨텍스트 모듈은,상기 양자화 잠재 표현 y의 엔트로피 모델에 이용되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>43. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송을 위한 인코딩 컴퓨터 시스템에 있어서,상기 인코딩 컴퓨터 시스템은,인코딩 컴퓨터,인코더 훈련된 신경망,하이퍼인코더 훈련된 신경망, 및하이퍼디코더 훈련된 신경망을 포함하고,(i) 상기 인코딩 컴퓨터는 입력 이미지를 수신하도록 구성되고;(ii) 상기 인코딩 컴퓨터는 상기 인코더 훈련된 신경망을 사용해 입력 이미지를 인코딩하여 y 잠재 표현을 생성하도록 구성되고;(iii) 상기 인코딩 컴퓨터는 상기 하이퍼인코더 훈련된 신경망을 사용해 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현을 생성하도록 구성되고;(iv) 상기 인코딩 컴퓨터는 사전 학습된 엔트로피 파라미터를 사용해 상기 z 하이퍼 잠재 표현을 양자화하여, 양자화 z 하이퍼 잠재 표현을 생성하도록 구성되고;(v) 상기 인코딩 컴퓨터는 상기 사전 학습된 엔트로피 파라미터를 포함하는 사전 학습 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하고, 산술 인코더를 사용하여, 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩하도록 구성되고;(vi) 상기 인코딩 컴퓨터는 상기 하이퍼디코더 훈련된 신경망을 사용해 상기 양자화 z 하이퍼 잠재 표현을 처리하여, 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하도록 구성되고;(vii) 상기 인코딩 컴퓨터는 암시적 인코딩 솔버를 사용해 상기 y 잠재 표현, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 잠재 잔차를 구하도록 구성되고;(viii) 상기 인코딩 컴퓨터는 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용하고, 산술 인코더를 사용하여 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하도록 구성되고; 및(ix) 상기 인코딩 컴퓨터는 상기 제1 비트스트림 및 상기 제2 비트스트림을 전송하도록 구성되는것을 특징으로 하는 인코딩 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>44. 제43항에 있어서,상기 인코딩 컴퓨터 시스템은,제36항 내지 제42항 중 어느 한 항의 방법을 수행하도록 구성되는것을 특징으로 하는 인코딩 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>45. 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 컴퓨터 구현 방법에 있어서,(i) 제1 비트스트림과 제2 비트스트림을 수신하는 단계;(ii) 사전 학습된 위치 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하고, 산술 디코더를 사용하여 상기 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하는 단계;(iii) 하이퍼디코더 훈련된 신경망을 사용해 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하는 단계;(iv) 산술 디코더, 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용해, 상기 제2 비트스트림을 디코딩하여 양자화 잠재 잔차를 출력하는 단계;(v) (예: 암시적) (예: 선형) 디코딩 솔버를 사용해 상기 양자화 잠재 잔차, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 y 잠재 표현을 구하는 단계;(vi) 디코더 훈련된 신경망을 사용해, 상기 양자화 y 잠재 표현을 디코딩하여 재구성된 이미지를 얻는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>46. 제45항에 있어서,(ii) 단계의 사전 학습된 엔트로피 파라미터는,사전 학습된 위치 엔트로피 파라미터 μz 및 사전 학습된 엔트로피 스케일 파라미터 σz인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>47. 제45항 또는 제46항에 있어서, (iv) 단계의 1차원 이산 확률 질량 함수는 0의 평균값(zero mean)을 갖는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>48. 제45항 내지 제47항 중 어느 한 항에 있어서,(vii) 재구성된 이미지를 저장하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>49. 제45항 내지 제48항 중 어느 한 항에 있어서,상기 (예: 암시적) (예: 선형) 디코딩 솔버는,양자화 y 잠재 표현이 양자화 잠재 잔차에 μy를 더한 값에 양자화 y 잠재 표현에 작용하는 Ly를 더한 값과 같다는 (예: 암시적) 방정식을 푸는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>50. 제45항 내지 제49항 중 어느 한 항에 있어서,상기 방정식 시스템은, 하삼각행렬이고,표준 전진 치환이 (예: 암시적) 방정식을 푸는 데 사용되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>51. 제45항 내지 제50항 중 어느 한 항에 있어서,희소 컨텍스트 행렬 L에 의해 정의된 자동회귀 구조를 이용하여 직렬 디코딩 패스의 구성 요소를 병렬화하고,상기 접근 방식에서 먼저 잠재 픽셀 간의 종속성 관계를 모델링하는 종속성 그래프 DAG(Directed Acyclic Graph)를 생성하고,상기 종속성 그래프는 L 행렬의 희소성 구조를 기반으로 구성되고,그런 다음, 선형 디코드 방정식을 사용해, DAG 계층을 통해 반복하고 해당 레벨의 모든 픽셀을 병렬로 처리하여 양자화된 잔차에서 양자화 y 잠재를 복구하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>52. 제45항 내지 제51항 중 어느 한 항에 있어서,상기 L-컨텍스트 모델링 단계의 디코딩 패스는 직렬 절차(serial procedure)가 아니며, 병렬로 실행할 수 있는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>53. 제45항 내지 제52항 중 어느 한 항에 있어서,제2 비트스트림으로부터 양자화 잔차를 복구하는 것은 자동회귀가 아니므로, 상기 프로세스는 매우 빠른것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>54. 제45항 내지 제53항 중 어느 한 항에 있어서,인코딩에 L-컨텍스트 모듈이 사용된 경우, L-컨텍스트 모듈을 이용하는것을 특징으로 하는 방법. </claim></claimInfo><claimInfo><claim>55. 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 디코딩 컴퓨터 시스템에 있어서,상기 디코딩 컴퓨터 시스템은,디코딩 컴퓨터,디코더 훈련된 신경망, 및하이퍼디코더 훈련된 신경망을 포함하고,(i) 상기 디코딩 컴퓨터는 제1 비트스트림 및 제2 비트스트림을 수신하도록 구성되고;(ii) 상기 디코딩 컴퓨터는 산술 디코더를 사용하고, 사전 학습된 위치 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하여 상기 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하도록 구성되고;(iii) 상기 디코딩 컴퓨터는 하이퍼디코더 훈련된 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하도록 구성되고;(iv) 상기 디코딩 컴퓨터는 산술 디코더, 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용해, 상기 제2 비트스트림을 디코딩하여 양자화 잠재 잔차를 출력하도록 구성되고;(v) 상기 디코딩 컴퓨터는 (예: 암시적) (예: 선형) 디코딩 솔버를 사용해, 상기 양자화 잠재 잔차, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 y 잠재 표현을 구하도록 구성되고;(vi) 상기 디코딩 컴퓨터는 디코더 훈련된 신경망을 사용하여 상기 양자화 y 잠재 표현을 디코딩함으로써 재구성된 이미지를 얻도록 구성되는것을 특징으로 하는 디코딩 컴퓨터 시스템. </claim></claimInfo><claimInfo><claim>56. 제55항에 있어서,상기 디코딩 컴퓨터 시스템은,제45항 내지 제54항 중 어느 한 항의 방법을 수행하도록 구성되는것을 특징으로 하는 디코딩 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>57. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송, 및 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 컴퓨터 구현 방법에 있어서,제36항 내지 제42항 중 어느 한 항의 방법, 및제45항 내지 제54항 중 어느 한 항의 방법을 포함하는 방법.</claim></claimInfo><claimInfo><claim>58. 손실 또는 무손실 이미지 또는 비디오 압축 및 전송, 그리고 손실 또는 무손실 이미지 또는 비디오 디코딩을 위한 시스템에 있어서,제43항 또는 제44항의 시스템, 및제55항 또는 제56항의 시스템을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>59. 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한, 인코더 신경망, 디코더 신경망, 하이퍼인코더 신경망 및 하이퍼디코더 신경망, 및 엔트로피 파라미터, 상기 신경망 및 상기 엔트로피 파라미터를 훈련시키는 컴퓨터 구현 방법에 있어서,(i) 입력 훈련 이미지를 수신하는 단계;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하는 단계;(iii) 상기 하이퍼인코더 신경망을 사용해, 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현을 생성하는 단계;(iv) 상기 엔트로피 파라미터 중 일 엔트로피 파라미터를 사용해, 상기 z 하이퍼 잠재 표현을 양자화하여 양자화 z 하이퍼 잠재 표현을 생성하는 단계;(v) 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하고, 산술 인코더를 사용하여 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩하는 단계;(vi) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 처리하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하는 단계;(vii) 암시적 인코딩 솔버를 사용해, 상기 y 잠재 표현, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 잠재 잔차를 구하는 단계;(viii) 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용하고, 산술 인코더를 사용하여 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하는 단계;(ix) 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하고, 산술 디코더를 사용하여 상기 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하는 단계;(x) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하는 단계;(xi) 산술 디코더, 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용해, 상기 제2 비트스트림을 디코딩하여 양자화 잠재 잔차를 출력하는 단계;(xii) (예: 암시적) (예: 선형) 디코딩 솔버를 사용해, 상기 양자화 잠재 잔차, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 y 잠재 표현을 구하는 단계;(xiii) 상기 디코더 신경망을 사용해, 상기 양자화 y 잠재 표현을 디코딩하여 재구성된 이미지를 얻는 단계;(xiv) 재구성된 이미지와 입력 훈련 이미지 간의 차이를 기반으로 한 손실 함수 및 레이트 항(rate term)을 평가하는 단계;(xv) 상기 손실 함수의 기울기를 평가하는 단계;(xvi) 상기 손실 함수의 기울기를 디코더 신경망, 하이퍼디코더 신경망, 하이퍼인코더 신경망, 인코더 신경망을 통해, 엔트로피 파라미터를 이용해 역전파(back-propagating)하여 인코더, 디코더, 하이퍼인코더 및 하이퍼디코더 신경망의 가중치를 업데이트하고, 상기 엔트로피 파라미터를 업데이트하는 단계; 및(xvii) 훈련 이미지 세트를 이용해 (i) 내지 (xvi) 단계를 반복하여, 훈련된 인코더 신경망, 훈련된 디코더 신경망, 훈련된 하이퍼인코더 신경망 및 훈련된 하이퍼디코더 신경망, 그리고 훈련된 엔트로피 파라미터를 생성하는 단계; 및 (xviii) 상기 훈련된 인코더 신경망, 상기 훈련된 디코더 신경망, 상기 훈련된 하이퍼인코더 신경망 및 상기 훈련된 하이퍼디코더 신경망의 가중치를 저장하고, 상기 훈련된 엔트로피 파라미터를 저장하는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>60. 제59항에 있어서,(iv) 단계의 엔트로피 파라미터는,위치 엔트로피 파라미터 μz이고,(v), (ix) 및 (xvi) 내지 (xviii) 단계의 엔트로피 파라미터는,위치 엔트로피 파라미터 μz 및 엔트로피 스케일 파라미터 σz인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>61. 제59항 또는 제60항에 있어서, (viii) 단계 및 (xi)의 1차원 이산 확률 질량 함수는 0의 평균값(zero mean)을 갖는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>62. 제59항 내지 제61항 중 어느 한 항에 있어서,상기 암시적 인코딩 솔버는,(I) 양자화 잠재 잔차는 y 잠재 표현에서 μy를 뺀 값에, 양자화 y 잠재 표현에 작용하는 Ly를 뺀 값의 어림 함수(rounding function)와 같다는 암시적 방정식; 및(II) 양자화된 y 잠재 표현은 양자화된 잠재 잔차에 μy를 더하고, 양자화된 y 잠재 표현에 작용하는 Ly를 더하는 것과 같다는 암시적 방정식을 푸는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>63. 제59항 내지 제62항 중 어느 한 항에 있어서,상기 (예: 암시적) (예: 선형) 디코딩 솔버는,양자화 y 잠재 표현이 양자화 잠재 잔차에 μy를 더한 값에 양자화 y 잠재 표현에 작용하는 Ly를 더한 값과 같다는 (예: 암시적) 방정식을 푸는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>64. 제59항 내지 제63항 중 어느 한 항에 있어서, 상기 양자화 y 잠재 표현 는 상기 y 잠재 표현의 양자화된 값에서 위치 엔트로피 파라미터 μ를 뺀 값에서, 상기 양자화 y 잠재 표현 에 작용하는 L 컨텍스트 행렬을 뺀 값에, 위치 엔트로피 파라미터 μ를 더한 값에, 상기 양자화 y 잠재 표현 에 작용하는 L 컨텍스트 행렬 Lij를 더한 값과 같은 방정식을 풀고, 이 방정식은 자동 회귀 모델에서 픽셀의 종속성 순서에 따라 픽셀에 대해 순차적으로 풀리며, 모든 픽셀을 자동 회귀 순서대로 반복하고,반복할 때마다를 적용하여 현재 반복에서 양자화된 잠재를 구하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>65. 제59항 내지 제64항 중 어느 한 항에 있어서, 희소 컨텍스트 행렬 L에 의해 정의된 자동회귀 구조를 이용하여 직렬 디코딩 패스의 구성 요소를 병렬화하고,상기 접근 방식에서 먼저 잠재 픽셀 간의 종속성 관계를 정의하는 종속성 그래프 DAG(Directed Acyclic Graph)를 생성하고,상기 종속성 그래프는 L 행렬의 희소성 구조를 기반으로 구성되고,그런 다음, DAG의 동일한 레벨에서 서로 조건적으로(conditionally) 독립적인 픽셀이 해당 레벨에 있는 다른 픽셀의 계산에 영향을 주지 않고 모두 병렬로 계산되고,상기 그래프는 루트 노드에서 시작하여 DAG 레벨을 통해 반복되고 각 레벨마다 모든 노드가 병렬로 처리되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>66. 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한, 인코더 신경망, 디코더 신경망, 하이퍼인코더 신경망 및 하이퍼디코더 신경망, 및 엔트로피 파라미터, 상기 신경망 및 상기 엔트로피 파라미터를 훈련시키기 위해, 프로세서에서 실행 가능한 컴퓨터 프로그램 제품에 있어서,(i) 입력 훈련 이미지를 수신하고;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하고;(iii) 상기 하이퍼인코더 신경망을 사용해, 상기 y 잠재 표현을 인코딩하여 z 하이퍼 잠재 표현을 생성하고;(iv) 상기 엔트로피 파라미터 중 일 엔트로피 파라미터를 사용해, 상기 z 하이퍼 잠재 표현을 양자화하여 양자화 z 하이퍼 잠재 표현을 생성하고;(v) 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하고, 산술 인코더를 사용하여 상기 양자화 z 하이퍼 잠재 표현을 제1 비트스트림으로 엔트로피 인코딩하고;(vi) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 처리하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 상기 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하고;(vii) 암시적 인코딩 솔버를 사용해, 상기 y 잠재 표현, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 잠재 잔차를 구하고;(viii) 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용하고, 산술 인코더를 사용하여 상기 양자화 잠재 잔차를 제2 비트스트림으로 엔트로피 인코딩하고;(ix) 엔트로피 파라미터에 종속적인 1차원 이산 확률 질량 함수를 사용하고, 산술 디코더를 사용하여 상기 제1 비트스트림을 디코딩함으로써 양자화 z 하이퍼 잠재 표현을 생성하고;(x) 상기 하이퍼디코더 신경망을 사용해, 상기 양자화 z 하이퍼 잠재 표현을 디코딩하여 위치 엔트로피 파라미터 μy, 엔트로피 스케일 파라미터 σy 및 y 잠재 표현의 L-컨텍스트 행렬 Ly를 구하고;(xi) 산술 디코더, 1차원 이산 확률 질량 함수 및 상기 엔트로피 스케일 파라미터 σy를 사용해, 상기 제2 비트스트림을 디코딩하여 양자화 잠재 잔차를 출력하고;(xii) (예: 암시적) (예: 선형) 디코딩 솔버를 사용해, 상기 양자화 잠재 잔차, 상기 위치 엔트로피 파라미터 μy 및 상기 L-컨텍스트 행렬 Ly를 처리하여 양자화 y 잠재 표현을 구하고;(xiii) 상기 디코더 신경망을 사용해, 상기 양자화 y 잠재 표현을 디코딩하여 재구성된 이미지를 얻고;(xiv) 재구성된 이미지와 입력 훈련 이미지 간의 차이를 기반으로 한 손실 함수 및 레이트 항(rate term)을 평가하고;(xv) 상기 손실 함수의 기울기를 평가하고;(xvi) 상기 손실 함수의 기울기를 디코더 신경망, 하이퍼디코더 신경망, 하이퍼인코더 신경망, 인코더 신경망을 통해, 엔트로피 파라미터를 이용해 역전파(back-propagating)하여 인코더, 디코더, 하이퍼인코더 및 하이퍼디코더 신경망의 가중치를 업데이트하고, 상기 엔트로피 파라미터를 업데이트하고;(xvii) 훈련 이미지 세트를 이용해 (i) 내지 (xvi) 단계를 반복하여, 훈련된 인코더 신경망, 훈련된 디코더 신경망, 훈련된 하이퍼인코더 신경망 및 훈련된 하이퍼디코더 신경망, 그리고 훈련된 엔트로피 파라미터를 생성하고;(xviii) 상기 훈련된 인코더 신경망, 상기 훈련된 디코더 신경망, 상기 훈련된 하이퍼인코더 신경망 및 상기 훈련된 하이퍼디코더 신경망의 가중치를 저장하고, 상기 훈련된 엔트로피 파라미터를 저장하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>67. 제66항에 있어서,제59항 내지 제65항 중 어느 한 항의 방법을 수행하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>68. 인코더-디코더 성능을 수정하는 신경망을 포함하는 전체 신경망, 파라미터 θ에 의해 파라미터화되고 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한 인코더 및 디코더 신경망을 포함하는 상기 전체 신경망을 훈련하는 컴퓨터 구현 방법에 있어서,(i) 입력 훈련 이미지 x를 수신하는 단계;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하는 단계;(iii) 상기 잠재 표현을 양자화하여 양자화 잠재 를 생성하는 단계;(iv) 상기 디코더 신경망을 사용해, 상기 양자화 잠재에서 출력 이미지 를 생성하며, 상기 출력 이미지가 입력 이미지의 근사치인 단계;(v) 출력 이미지와 입력 훈련 이미지 간의 차이에 대한 왜곡 함수 평가에 기반하고, 상기 양자화된 잠재 의 압축률 함수와 목표 압축률 r0 간의 차이에 기반하여, 라그랑주 승수 λ를 포함한 라그랑지안 손실 함수(Lagrangian loss function)를 평가하는 단계;(vi) 상기 평가된 라그랑지안 손실 함수의 역전파를 사용하여 전체 신경망 파라미터 기울기를 계산하는 단계;(vii) (vi) 단계에서 평가된 전체 신경망 파라미터 기울기를 기반으로, 전체 신경망 파라미터 θ에 대한 라그랑지안 손실 함수의 하강 단계를 수행하여 전체 신경망 파라미터 θ를 업데이트하는 단계;(viii) 라그랑주 승수에 대한 라그랑지안 손실 함수의 상승 단계를 수행하여 라그랑주 승수를 업데이트하는 단계;(ix) 훈련 이미지 세트를 사용해 (i) 내지 (viii) 단계를 반복하여, 훈련된 파라미터 세트 θ 및 선택적으로 목표 압축률 r0을 생성하는 단계; 및(x) 상기 훈련된 파라미터 세트 θ를 저장하는 단계;를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>69. 인코더-디코더 성능을 수정하는 신경망을 포함하는 전체 신경망, 파라미터 θ에 의해 파라미터화되고 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한 인코더 및 디코더 신경망을 포함하는 상기 전체 신경망을 훈련하는 컴퓨터 구현 방법에 있어서,(i) 입력 훈련 이미지 x를 수신하는 단계;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하는 단계;(iii) 상기 잠재 표현을 양자화하여 양자화 잠재 를 생성하는 단계;(iv) 상기 디코더 신경망을 사용해, 상기 양자화 잠재에서 출력 이미지 를 생성하며, 상기 출력 이미지가 입력 이미지의 근사치인 단계;(v) 출력 이미지와 입력 훈련 이미지 간의 차이에 대한 왜곡 함수 평가에 기반하고, 상기 양자화된 잠재 의 압축률 함수와 목표 압축률 r0 간의 차이에 기반하여, 라그랑주 승수 λ를 포함한 증강 라그랑지안 손실 함수(augmented Lagrangian loss function)를 평가하는 단계;(vi) 상기 평가된 증강 라그랑지안 손실 함수의 역전파를 사용하여 전체 신경망 파라미터 기울기를 계산하는 단계;(vii) SGD 또는 SGD형 옵티마이저가 신경망 파라미터 옵티마이저의 학습률 및 (vi) 단계에서 평가된 전체 신경망 파라미터 기울기에 기반하여 전체 신경망 파라미터 θ를 최적화하는, 옵티마이저 단계를 수행함으로써 전체 신경망 파라미터 θ를 업데이트하는 단계;(viii) 증강 라그랑지안 손실 함수 이차항 가중치(quadratic term weight) μ에 양자화 잠재의 압축률 함수와 목표 압축률 간의 차이를 곱한 값을 평가함으로써 라그랑주 승수의 기울기를 평가하는 단계;(ix) SGD 또는 SGD형 옵티마이저가 라그랑주 승수 옵티마이저의 학습률에 기반하여 라그랑주 승수를 최적화하는, 옵티마이저 단계를 수행함으로써 라그랑주 승수를 업데이트하는 단계;(x) 훈련 이미지 세트를 사용해 (i) 내지 (ix) 단계를 반복하여, 훈련된 파라미터 세트 θ를 생성하는 단계; 및 (xi) 상기 훈련된 파라미터 세트 θ를 저장하는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>70. 제69항에 있어서,(viii) 단계에서 평가된 라그랑주 승수의 기울기를 클리핑하는 단계; 및상기 SGD 또는 SGD형 옵티마이저가 상기 라그랑주 승수 옵티마이저의 학습률 및 상기 라그랑주 승수에 대해 클리핑된 기울기에 기반하여 라그랑주 승수를 최적화하는, 옵티마이저 단계를 수행함으로써 라그랑주 승수를 업데이트하는 단계를 포함하는 방법. </claim></claimInfo><claimInfo><claim>71. 제68항 내지 제70항 중 어느 한 항에 있어서, 상기 훈련된 파라미터 세트 θ는,수렴된 파라미터 세트 θ인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>72. 제69항 내지 제71항 중 어느 한 항에 있어서,상기 증강 라그랑지안 손실 함수는,이고,여기서 D는 데이터 재구성의 왜곡을 측정하는 함수인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>73. 제69항 내지 제72항 중 어느 한 항에 있어서, (ix) 단계는,라그랑주 승수 옵티마이저에 대한 학습률을 손실 함수 이차항 가중치로 곱한 값에 양자화 잠재의 압축률 함수와 목표 압축률 간의 차이를 곱한 값으로 라그랑주 승수를 수정하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>74. 제69항 내지 제73항 중 어느 한 항에 있어서, 라그랑주 승수 옵티마이저의 학습률 계수를 도입하여 손실 함수 이차항 가중치에서 라그랑주 승수의 학습률을 분리하면, 손실 함수 이차항 가중치를 작게 유지하면서 승수는 합리적인 시간 내에 수렴될 수 있는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>75. 제69항 내지 제74항 중 어느 한 항에 있어서,라그랑주 승수를 최적화하는 상기 SGD형 옵티마이저는,Adam 옵티마이저인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>76. 제69항 내지 제75항 중 어느 한 항에 있어서,양자화 잠재 압축률은 전체 신경망 파라미터 θ를 업데이트하는 정방향 패스 단계 (iii)과 (iv) 및 역방향 패스 단계 (v) 내지 (viii) (즉, 기울기 계산)에서는 훈련 양자화 함수를 사용하여 계산하지만, 증강 라그랑지안 방법의 라그랑주 승수로 업데이트를 수행하는 단계 (viii) 및 (ix)에서는 추론 양자화 함수(inference quantisation function)를 사용하여 양자화 잠재 압축률을 계산하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>77. 제69항 내지 제75항 중 어느 한 항에 있어서,양자화 잠재는 정방향 패스 단계 (iii) 및 (iv)에서 추론 양자화 함수를 사용해 계산하고, 역방향 패스 단계 (v) 내지 (viii)(즉, 기울기 계산)에서는 양자화 잠재를 훈련 양자화 함수를 사용해 계산하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>78. 제69항 내지 제77항 중 어느 한 항에 있어서,사용된 훈련 이미지 세트는 인코더와 디코더를 훈련시키는 데 사용되는 훈련 이미지 세트로, 목표 압축률로 압축되도록 수정되고,단계 (v)의 왜곡 함수는 스케일 계수 s(예: 초기에 약 2)만큼 감소하고,훈련 중에 스케일된 왜곡의 실행 평균이 업데이트되고,사전 정의된 훈련 반복 시, 스케일 계수 s는 실행 평균에 비례하여(예: 2배) 조정되며 라그랑주 승수는 스케일 계수 조정에 반비례하는 계수에 의해 수정되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>79. 제78항에 있어서,상기 실행 평균은,산술 평균, 중앙값, 기하 평균, 조화 평균, 지수 이동 평균, 평활 이동 평균, 선형 가중 이동 평균 중 하나인것을 특징으로 하는 방법. </claim></claimInfo><claimInfo><claim>80. 제68항 내지 제79항 중 어느 한 항에 있어서,양자화 잠재는,잠재 공간의 확률 분포, 위치 파라미터 및 스케일 파라미터 σ를 포함하는 확률 분포를 사용하여 표현되고, σ는 컴퓨터 구현 방법의 훈련이 진행됨에 따라 감소(감쇠 스케일 임계값의 사용 등)하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>81. 제80항에 있어서,상기 확률 분포는,가우스(Gaussian) 또는 라플라스(Laplacian) 분포인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>82. 제80항 또는 제81항에 있어서,σ는 σ가 최종 값에 도달할 때까지, 컴퓨터 구현 방법의 훈련이 진행됨에 따라 감소하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>83. 제80항 내지 제82항 중 어느 한 항에 있어서,σ는 점진적으로 감소하는 임계값 t를 사용하여, 컴퓨터 구현 방법의 훈련이 진행됨에 따라 감소하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>84. 제83항에 있어서,σ는 컴퓨터 구현 방법의 훈련이 진행됨에 따라 감소하면서, 훈련 반복 횟수에 따라 t를 연속적으로 감소시키는것을 특징으로 하는 방법. </claim></claimInfo><claimInfo><claim>85. 제83항에 있어서,σ는 컴퓨터 구현 방법의 훈련이 진행됨에 따라 감소하면서, 훈련 반복 횟수에 따라 t를 기하급수적으로 감소시키는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>86. 제83항 내지 제85항 중 어느 한 항에 있어서,σ는 컴퓨터 구현 방법의 훈련이 진행됨에 따라 감소하면서, 손실 메트릭(loss metric)에 따라 t를 감소시키는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>87. 제68항 내지 제79항 중 어느 한 항에 있어서,상기 양자화 잠재는,잠재 공간의 확률 분포, 위치 파라미터 및 스케일 파라미터 σ를 포함하는 확률 분포를 사용하여 표현되며, σ의 모든 실현은 고정 값으로 제한되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>88. 제80항 내지 제87항 중 어느 한 항에 있어서,σ의 모든 실현은 소프트플러스(softplus) 연산, 또는 임계처리(thresholding)를 사용한 제곱 연산, 또는 임계처리를 사용한 절대값 연산과 같이, 정의된 정의역(domain)에 대해 순양의 공역(strictly positive codomain) 함수로 매핑되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>89. 인코더-디코더 성능을 수정하는 신경망을 포함하는 전체 신경망, 파라미터 θ에 의해 파라미터화되고 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한 인코더 및 디코더 신경망을 포함하는 상기 전체 신경망을 훈련시키기 위해 프로세서에서 실행 가능한 컴퓨터 프로그램 제품에 있어서,(i) 입력 훈련 이미지 x를 수신하고;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하고;(iii) 상기 잠재 표현을 양자화하여 양자화 잠재 를 생성하고;(iv) 상기 디코더 신경망을 사용해, 상기 양자화 잠재에서 출력 이미지 를 생성하고(상기 출력 이미지가 입력 이미지의 근사치임);(v) 출력 이미지와 입력 훈련 이미지 간의 차이에 대한 왜곡 함수 평가에 기반하고, 상기 양자화된 잠재 의 압축률 함수와 목표 압축률 r0 간의 차이에 기반하여, 라그랑주 승수 λ를 포함한 라그랑지안 손실 함수(Lagrangian loss function)를 평가하고;(vi) 상기 평가된 라그랑지안 손실 함수의 역전파를 사용하여 전체 신경망 파라미터 기울기를 계산하고;(vii) (vi) 단계에서 평가된 전체 신경망 파라미터 기울기를 기반으로, 전체 신경망 파라미터 θ에 대한 라그랑지안 손실 함수의 하강 단계를 수행하여 전체 신경망 파라미터 θ를 업데이트하고;(viii) 라그랑주 승수에 대한 라그랑지안 손실 함수의 상승 단계를 수행하여 라그랑주 승수를 업데이트하고;(ix) 훈련 이미지 세트를 사용해 (i) 내지 (viii) 단계를 반복하여, 훈련된 파라미터 세트 θ 및 선택적으로 목표 압축률 r0을 생성하고; 및(x) 상기 훈련된 파라미터 세트 θ를 저장하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>90. 인코더-디코더 성능을 수정하는 신경망을 포함하는 전체 신경망, 파라미터 θ에 의해 파라미터화되고 손실 이미지 또는 비디오 압축, 전송 및 디코딩에 사용하기 위한 인코더 및 디코더 신경망을 포함하는 상기 전체 신경망을 훈련시키기 위해 프로세서에서 실행 가능한 컴퓨터 프로그램 제품에 있어서,(i) 입력 훈련 이미지 x를 수신하고;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 y 잠재 표현을 생성하고;(iii) 상기 잠재 표현을 양자화하여 양자화 잠재 를 생성하고;(iv) 상기 디코더 신경망을 사용해, 상기 양자화 잠재에서 출력 이미지 를 생성하고(상기 출력 이미지가 입력 이미지의 근사치임);(v) 출력 이미지와 입력 훈련 이미지 간의 차이에 대한 왜곡 함수 평가에 기반하고, 상기 양자화된 잠재 의 압축률 함수와 목표 압축률 r0 간의 차이에 기반하여, 라그랑주 승수 λ를 포함한 증강 라그랑지안 손실 함수(augmented Lagrangian loss function)를 평가하고;(vi) 상기 평가된 증강 라그랑지안 손실 함수의 역전파를 사용하여 전체 신경망 파라미터 기울기를 계산하고;(vii) SGD 또는 SGD형 옵티마이저가 신경망 파라미터 옵티마이저의 학습률 및 (vi) 단계에서 평가된 전체 신경망 파라미터 기울기에 기반하여 전체 신경망 파라미터 θ를 최적화하는, 옵티마이저 단계를 수행함으로써 전체 신경망 파라미터 θ를 업데이트하고;(viii) 증강 라그랑지안 손실 함수 이차항 가중치 μ에 양자화 잠재의 압축률 함수와 목표 압축률 간의 차이를 곱한 값을 평가함으로써 라그랑주 승수의 기울기를 평가하고;(ix) SGD 또는 SGD형 옵티마이저가 라그랑주 승수 옵티마이저의 학습률에 기반하여 라그랑주 승수를 최적화하는, 옵티마이저 단계를 수행함으로써 라그랑주 승수를 업데이트하고;(x) 훈련 이미지 세트를 사용해 (i) 내지 (ix) 단계를 반복하여, 훈련된 파라미터 세트 θ를 생성하고; 및 (xi) 상기 훈련된 파라미터 세트 θ를 저장하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>91. 제89항 또는 제90항에 있어서,제68항 내지 제88항 중 어느 한 항의 방법을 수행하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>92. 인코더 왜곡을 줄이기 위해 인코더 신경망을 훈련하는 컴퓨터 구현 방법에 있어서,상기 인코더 신경망은,파라미터 θ에 의해 파라미터화되고,상기 인코더는,손실 이미지 또는 비디오 압축에 사용하기 위한 신경망이고,상기 방법은,(i) 입력 훈련 이미지 x를 수신하는 단계;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 이미지 재구성 y를 생성하는 단계;(iii) 이미지 훈련 세트에서 사전 훈련된 특징 임베딩 신경망(feature embedding network)에 입력 훈련 이미지 x를 통과시켜 특징이 포함된 출력 를 생성하는 단계;(iv) 상기 특징 임베딩 신경망에 이미지 재구성 y를 통과시켜 특징이 포함된 출력 를 생성하는 단계;(v) 출력 를 N개의 동일한 크기의 특징 벡터 집합 으로 분할하는 단계;(vi) 출력 를 N개의 동일한 크기의 특징 벡터 집합 으로 분할하는 단계;(vii) 각 특징 벡터  및  쌍에 대해, 거리 계수(distance element) di,j (예: 코사인 거리)를 평가(evaluate)하는 단계;(viii) 각 거리 계수 di,j에 대해, 정규화된 거리 계수(normalised distance element) 를 계산하는 단계(예: di,j /(mink di,k + ε), 여기서 ε는 작은 양의 상수(small positive contant)임);(ix) 각 정규화된 거리 계수 에 대해, 의 기하급수적 감소 함수인 유사도 계수 wi,j를 계산하는 단계(예: exp((1-)/h), 여기서 h는 양의 수이며 대역폭 파라미터임);(x) 각 유사도 계수 wi,j에 대해, wi,j/(Σk wi,k)인 ci,j를 계산하는 단계;(xi) 컨텍스트 손실을 계산하는 단계;(xii) 상기 컨텍스트 손실과 제너레이터에 대한 추가 손실의 합, 즉 x 및 y의 함수인 손실 함수를 평가하는 단계;(xiii) 상기 손실 함수를 역전파하는 단계;(xiv) 파라미터 θ에 의해 파라미터화된 상기 인코더 신경망을 최적화하는 단계;(xv) 훈련 이미지 세트를 사용해 (i) 내지 (xiv) 단계를 반복하여, 훈련된 파라미터 세트 θ를 생성하는 단계; 및 (xvi) 상기 훈련된 파라미터 세트 θ를 저장하는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>93. 제92항에 있어서,상기 컨텍스트 손실은 마이너스 이고, 는 를 N으로 나눈 값과 같은것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>94. 제92항에 있어서,상기 컨텍스트 손실은 마이너스  및 마이너스 의 가중 평균이고, 는 를 N으로 나눈 값과 같은것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>95. 제92항에 있어서,상기 컨텍스트 손실은 마이너스  및 마이너스 의 산술 평균이고, 는 를 N으로 나눈 값과 같은것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>96. 제92항 내지 제95항 중 어느 한 항에 있어서,상기 컨텍스트 손실에 딥 렌더(Deep Render)의 적대적 VMAF(Video Multimethod Assessment Fusion) 프록시 또는 LPIPS(Learned Perceptual Image Patch Similarity) 또는 생성적 적대 손실이 더 포함되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>97. 제92항 내지 제96항 중 어느 한 항에 있어서,상기 접근 방식은 인간 시각 시스템을 사용하여 인식되는, 재구성 이미지의 시각적 품질을 크게 향상시키는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>98. 제92항 내지 제97항 중 어느 한 항에 있어서,일부 잠재 특징 공간에서 이미지 표현 간의 통계적 거리를 사용하는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>99. 인코더 왜곡을 줄이기 위해 인코더 신경망을 훈련하기 위해 프로세스에서 실행 가능한 컴퓨터 프로그램 제품에 있어서,상기 인코더 신경망은,파라미터 θ에 의해 파라미터화되고, 상기 인코더는,손실 이미지 또는 비디오 압축에 사용하기 위한 신경망이고,상기 컴퓨터 프로그램 제품은,(i) 입력 훈련 이미지 x를 수신하고,(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 이미지 재구성 y를 생성하고,(iii) 이미지 훈련 세트에서 사전 훈련된 특징 임베딩 신경망(feature embedding network)에 입력 훈련 이미지 x를 통과시켜 특징이 포함된 출력 를 생성하고,(iv) 상기 특징 임베딩 신경망에 이미지 재구성 y를 통과시켜 특징이 포함된 출력 를 생성하고,(v) 출력 를 N개의 동일한 크기의 특징 벡터 집합 으로 분할하고,(vi) 출력 를 N개의 동일한 크기의 특징 벡터 집합 으로 분할하고,(vii) 각 특징 벡터  및  쌍에 대해, 거리 계수(distance element) di,j (예: 코사인 거리)를 평가(evaluate)하고,(viii) 각 거리 계수 di,j에 대해, 정규화된 거리 계수(normalised distance element) 를 계산하고(예: di,j /(mink di,k + ε), 여기서 ε는 작은 양의 상수(small positive contant)임);(ix) 각 정규화된 거리 계수 에 대해, 의 기하급수적 감소 함수인 유사도 계수 wi,j를 계산하고(예: exp((1-)/h), 여기서 h는 양의 수이며 대역폭 파라미터임);(x) 각 유사도 계수 wi,j에 대해, wi,j/(Σk wi,k)인 ci,j를 계산하고,(xi) 컨텍스트 손실을 계산하고,(xii) 상기 컨텍스트 손실과 제너레이터에 대한 추가 손실의 합, 즉 x 및 y의 함수인 손실 함수를 평가하고,(xiii) 상기 손실 함수를 역전파하고,(xiv) 파라미터 θ에 의해 파라미터화된 상기 인코더 신경망을 최적화하고,(xv) 훈련 이미지 세트를 사용해 (i) 내지 (xiv) 단계를 반복하여, 훈련된 파라미터 세트 θ를 생성하고,(xvi) 상기 훈련된 파라미터 세트 θ를 저장하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>100. 제99항에 있어서,제92항 내지 제98항 중 어느 한 항의 방법을 수행하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>101. 인코더 왜곡을 줄이기 위해 인코더 신경망을 훈련하는 컴퓨터 구현 방법에 있어서,상기 인코더 신경망은, 파라미터 θ에 의해 파라미터화되고, 상기 인코더는, 손실 이미지 또는 비디오 압축에 사용하기 위한 신경망이고,상기 방법은,(i) 입력 훈련 이미지 x를 수신하는 단계;(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 이미지 재구성 y를 생성하는 단계;(iii) 이미지 훈련 세트에서 사전 훈련된 특징 임베딩 신경망(feature embedding network)에 입력 훈련 이미지 x를 통과시켜 특징이 포함된 출력 를 생성하는 단계;(iv) 상기 특징 임베딩 신경망에 이미지 재구성 y를 통과시켜 특징이 포함된 출력 를 생성하는 단계;(v) 에서 함수를 실행하여 나중에 실행되는 함수에 대해서는 기울기가 추적되지 않도록 하고 출력 를 산출하는 단계;(vi) 판별기 신경망(discriminator network)에 출력 를 통과시켜 확률값 pdiscr,real를 제공하는 단계;(vi) 상기 판별기 신경망에 출력 를 통과시켜 확률값 pdiscr,pred를 제공하는 단계;(viii) pdiscr,real에 작용하는 실제 이미지에 대한 판별기 신경망의 분류 손실과 pdiscr,pred에 작용하는 예측 이미지에 대한 판별기 신경망의 분류 손실의 합인 판별기 손실을 구하는 단계;(ix) 상기 판별기 손실을 역전파하는 단계;(x) 상기 판별기 신경망을 최적화하는 단계;(xi) 상기 판별기 신경망에 출력 를 통과시켜 확률값 pgen,pred를 제공하는 단계;(xii) pgen,pred에 작용하는 예측 이미지에 대한 인코더의 분류 손실인 적대 손실을 구하는 단계;(xiii) 상기 적대 손실과 상기 인코더에 대한 추가 손실의 합, 즉 x 및 y의 함수인 손실 함수를 구하는 단계;(xiv) (xiii) 단계의 손실을 역전파하는 단계;(xv) 파라미터 θ에 의해 파라미터화된 상기 인코더 신경망을 최적화하는 단계;(xvi) 훈련 이미지 세트를 사용해 (i) 내지 (xv) 단계를 반복하여, 훈련된 파라미터 세트 θ를 생성하는 단계; 및 (xvii) 상기 훈련된 파라미터 세트 θ를 저장하는 단계를 포함하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>102. 제101항에 있어서,상기 판별기 신경망은,하나의 입력 텐서(input tensor)를 수락(accept)하는 아키텍처로 구성되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>103. 제101항 또는 제102항에 있어서,상기 판별기 신경망은,도 12에 도시된 판별기 신경망인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>104. 제101항에 있어서, 상기 판별기 신경망은,각각 채널 차원을 따라 텐서 연결을 사용하는, 복수의 하위 신경망으로 구성된 컨볼루션 신경망(CNN) 아키텍처를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>105. 제101항 또는 제104항에 있어서,상기 판별기 신경망은,도 13에 도시된 판별기 신경망인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>106. 제101항에 있어서,판별기 신경망은,모든 특징에 개별 판별기가 할당되는 아키텍처를 포함하고,전체 판별기는,모든 개별 판별기의 확률 함수로 정의되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>107. 제101항 또는 제106항에 있어서,상기 판별기 신경망은,도 14에 도시된 판별기 신경망인것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>108. 제101항 내지 제107항 중 어느 한 항에 있어서,상기 손실 함수에 딥 렌더(Deep Render)의 적대적 VMAF(Video Multimethod Assessment Fusion) 프록시 또는 LPIPS(Learned Perceptual Image Patch Similarity) 또는 생성적 적대 손실이 더 포함되는것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>109. 인코더 왜곡을 줄이기 위해 인코더 신경망을 훈련하기 위해 프로세스에서 실행 가능한 컴퓨터 프로그램 제품에 있어서,상기 인코더 신경망은, 파라미터 θ에 의해 파라미터화되고, 상기 인코더는, 손실 이미지 또는 비디오 압축에 사용하기 위한 신경망이고,상기 프로세스에서 실행 가능한 컴퓨터 프,로그램 제품은,(i) 입력 훈련 이미지 x를 수신하고(ii) 상기 인코더 신경망을 사용해, 입력 훈련 이미지를 인코딩하여 이미지 재구성 y를 생성하고,(iii) 이미지 훈련 세트에서 사전 훈련된 특징 임베딩 신경망에 입력 훈련 이미지 x를 통과시켜 특징이 포함된 출력 를 생성하고,(iv) 상기 특징 임베딩 신경망에 이미지 재구성 y를 통과시켜 특징이 포함된 출력 를 생성하고,(v) 에서 함수를 실행하여 나중에 실행되는 함수에 대해서는 기울기가 추적되지 않도록 하고 출력 를 산출하고,(vi) 판별기 신경망(discriminator network)에 출력 를 통과시켜 확률값 pdiscr,real를 제공하고,(vii) 상기 판별기 신경망에 출력 를 통과시켜 확률값 pdiscr,pred를 제공하고,(viii) pdiscr,real에 작용하는 실제 이미지에 대한 판별기 신경망의 분류 손실과 pdiscr,pred에 작용하는 예측 이미지에 대한 판별기 신경망의 분류 손실의 합인 판별기 손실을 구하고,(ix) 상기 판별기 손실을 역전파하고,(x) 상기 판별기 신경망을 최적화하고,(xi) 상기 판별기 신경망에 출력 를 통과시켜 확률값 pgen,pred를 제공하고,(xii)pgen,pred에 작용하는 예측 이미지에 대한 인코더의 분류 손실인 적대 손실을 구하고,(xiii) 상기 적대 손실과 상기 인코더에 대한 추가 손실의 합, 즉 x 및 y의 함수인 손실 함수를 구하고,(xiv) (xiii) 단계의 손실을 역전파하고,(xv) 파라미터 θ에 의해 파라미터화된 상기 인코더 신경망을 최적화하고,(xvi) 훈련 이미지 세트를 사용해 (i) 내지 (xv) 단계를 반복하여, 훈련된 파라미터 세트 θ를 생성하고,(xvii)상기 훈련된 파라미터 θ를 저장하는프로세스에서 실행 가능한 컴퓨터 프로그램 제품</claim></claimInfo><claimInfo><claim>110. 제109항에 있어서,제101항 내지 제108항 중 어느 한 항의 방법을 수행하는프로세서에서 실행 가능한 컴퓨터 프로그램 제품.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>영국 이* *엘엔 런던 커머셜 로드 **-** 딥 랜더 앳 테크스페이스</address><code>520230266064</code><country>영국</country><engName>Deep Render Ltd.</engName><name>딥 랜더 엘티디.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>BESENBRUCH, Chri</engName><name>베센브러치, 크리</name></inventorInfo><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>CHERGANSKI, Aleksandar</engName><name>체르간스키, 알렉산더</name></inventorInfo><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>FINLAY, Christopher</engName><name>핀레이, 크리스토퍼</name></inventorInfo><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>LYTCHIER, Alexander</engName><name>릿처, 알렉산더</name></inventorInfo><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>RAYNER, Jonathan</engName><name>레이너, 조너던</name></inventorInfo><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>RYDER, Tom</engName><name>라이더, 톰</name></inventorInfo><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>XU, Jan</engName><name>수, 잔</name></inventorInfo><inventorInfo><address>영국 런던 이* *에프에이 레먼 스...</address><code> </code><country> </country><engName>ZAFAR, Arsalan</engName><name>자파르, 아살란</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>영국</priorityApplicationCountry><priorityApplicationDate>2020.10.23</priorityApplicationDate><priorityApplicationNumber>2016824.1</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.05.04</receiptDate><receiptNumber>1-1-2023-0501567-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[New Translation under Article 201 of Patent Act or Article 35 of Utility Model Act] Submission of Document</documentEngName><documentName>[특허법 제201조 또는 실용신안법 제35조에 따른 새로운 번역문]서류제출서</documentName><receiptDate>2023.06.23</receiptDate><receiptNumber>1-1-2023-0696320-72</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.06.27</receiptDate><receiptNumber>1-5-2023-0101698-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.05.08</receiptDate><receiptNumber>4-1-2024-5146500-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.10.10</receiptDate><receiptNumber>1-1-2024-1101721-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.10.10</receiptDate><receiptNumber>1-1-2024-1101722-93</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237015414.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9391ad838d05d243aa2fa492c522cc27906beb2567ff08fdfea6f91a90750d2b9877ee6edc0c643a8cf35e8248a16735486f05ba6eec4a84e8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0b11426570398d14f90eedb11e702bb06f33728c2c70336189a7521afa7705c310cec69bbf79db9216300e9bef5634e9381d6fb5813b062a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>