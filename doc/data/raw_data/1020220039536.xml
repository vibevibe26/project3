<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:17.3717</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.03.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0039536</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공신경망을 이용한 6자유도 자세 추정 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR 6 DEGREE OF FREEDOM POSE  ESTIMATION USING ARTIFICAL NEURAL NETWORK</inventionTitleEng><openDate>2023.07.12</openDate><openNumber>10-2023-0106057</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.03.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 컴퓨팅 장치에 의해 수행되는, 6자유도 자세 추정 방법 및 장치가 개시된다. 일 실시예에 따른 컴퓨팅 장치에 의해 수행되는, 6자유도 자세 추정 방법은 제1 프레임의 제1 영상 및 제2 프레임의 제2 영상을 획득하는 단계, 상기 제1 영상 및 제2 영상을 인공신경망에 입력하는 단계, 상기 인공신경망의 특징 추출 네트워크를 이용하여 상기 제1 영상 및 상기 제2 영상으로부터 특징맵을 생성하는 단계, 상기 6자유도에 대응하는 6개의 토큰들 및 상기 특징맵을 이용하여 결합 집합을 생성하는 단계, 상기 특징맵에 포함된 패치들의 위치적 특성을 반영하는 위치 임베딩 벡터를 생성하고, 상기 위치 임베딩 벡터 및 상기 결합 집합을 이용하여 입력 벡터를 생성하는 단계, 상기 인공신경망의 차원 축소 네트워크에 상기 입력 벡터를 입력하는 단계 및 상기 차원 축소 네트워크의 출력으로부터 상기 6자유도를 결정하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 장치에 의해 수행되는, 6자유도 자세 추정 방법에 있어서,제1 프레임의 제1 영상 및 제2 프레임의 제2 영상을 획득하는 단계;상기 제1 영상 및 제2 영상을 인공신경망에 입력하는 단계;상기 인공신경망의 특징 추출 네트워크를 이용하여 상기 제1 영상 및 상기 제2 영상으로부터 특징맵을 생성하는 단계;상기 6자유도에 대응하는 6개의 토큰들 및 상기 특징맵을 이용하여 결합 집합을 생성하는 단계;상기 특징맵에 포함된 패치들의 위치적 특성을 반영하는 위치 임베딩 벡터를 생성하고, 상기 위치 임베딩 벡터 및 상기 결합 집합을 이용하여 입력 벡터를 생성하는 단계;상기 인공신경망의 차원 축소 네트워크에 상기 입력 벡터를 입력하는 단계; 및상기 차원 축소 네트워크의 출력으로부터 상기 6자유도를 결정하는 단계를 포함하는 6자유도 자세 추정 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 특징 추출 네트워크는,상기 제1 영상의 3채널 영상 및 제2 영상의 3채널 영상을 채널방향으로 합친 6채널 영상을 이용하여 특징을 추출하는 6자유도 자세 추정 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 6개의 토큰들 및 상기 특징맵을 이용하여 결합 집합을 생성하는 단계는,상기 생성된 특징맵을 일정한 크기를 가지는 패치들의 집합으로 재구성하는 단계; 및상기 패치들의 집합과 상기 6개의 토큰들을 결합하여 상기 결합 집합을 생성하는 단계를 포함하고상기 6개의 토큰들 각각은 상기 패치들 각각과 같은 크기를 가지는 6자유도 자세 추정 방법.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,상기 결합 집합은,n+6개의 패치들을 포함하고, 상기 n은 상기 특징맵에 포함된 패치들의 개수인 6자유도 자세 추정 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,상기 위치 임베딩 벡터는 상기 패치들과 동일한 크기를 가지는 벡터이며,상기 입력 벡터는,상기 결합 집합을 구성하는 원소 벡터와 위치 임베딩 벡터의 합에 기초하여 결정되는 6자유도 자세 추정 방법.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,상기 차원 축소 네트워크는,상기 입력 벡터에 대한 셀프 어텐션(self-attention) 연산을 반복 진행하여 상기 입력 벡터를 구성하는 패치들의 크기를 감소시키는 6자유도 자세 추정 방법.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 6자유도를 결정하는 단계는,상기 차원 축소 네트워크에 의해 크기가 감소된 입력 벡터의 패치들 가운데 상기 6개의 토큰들에 대응하는 패치들을 추출하는 단계; 및상기 추출한 패치들을 이용하여 패치 별 평균 풀링(average pooling)을 계산하여 6자유도를 추정하는 단계를 포함하는 6자유도 자세 추정 방법.</claim></claimInfo><claimInfo><claim>8. 컴퓨팅 장치에 의해 수행되는, 6자유도 자세 추정을 위한 인공신경망의 학습 방법에 있어서,제1 프레임의 제1 영상 및 제2 프레임의 제2 영상을 획득하는 단계;상기 제1 영상의 제1 깊이맵 및 상기 제2 영상의 제2 깊이맵을 추정하는 단계; 상기 제1 영상 및 상기 제2 영상을 상기 인공신경망에 입력하여 6자유도 정보를 출력하는 단계;상기 6자유도 정보에 기초하여 상기 제1 프레임과 상기 제2 프레임 사이의 변환행렬을 계산하는 단계; 및상기 제1 깊이맵, 상기 제2 깊이맵 및 상기 변환행렬에 기초하여 손실함수의 출력 값을 계산하고 상기 손실함수의 출력 값에 기초하여 상기 인공신경망을 갱신하는 단계를 포함하되,상기 6자유도 정보를 출력하는 단계는,상기 제1 영상 및 제2 영상을 인공신경망에 입력하는 단계;상기 인공신경망의 특징 추출 네트워크를 이용하여 상기 제1 영상 및 상기 제2 영상으로부터 특징맵을 생성하는 단계;상기 6자유도에 대응하는 6개의 토큰들 및 상기 특징맵을 이용하여 결합 집합을 생성하는 단계;상기 특징맵에 포함된 패치들의 위치적 특성을 반영하는 위치 임베딩 벡터를 생성하고, 상기 위치 임베딩 벡터 및 상기 결합 집합을 이용하여 입력 벡터를 생성하는 단계;상기 인공신경망의 차원 축소 네트워크에 상기 입력 벡터를 입력하는 단계; 및상기 차원 축소 네트워크의 출력으로부터 상기 6자유도를 결정하는 단계를 포함하는 인공신경망 학습방법.</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서,상기 6개의 토큰들 및 상기 위치 임베딩 벡터는,소정의 초기 값들로 설정된 이후 상기 손실함수의 출력 값이 작아지도록 갱신되는 인공신경망 학습방법.</claim></claimInfo><claimInfo><claim>10. 제8 항에 있어서,상기 손실함수의 출력은 소정 조건을 만족하는 유효 픽셀에 대하여 상기 변환행렬 및 제1 깊이맵을 이용하여 제2 프레임을 재구성한 제3 프레임과 제1 프레임 간의 차이를 모두 더하는 하는 제1 보조함수의 출력에 기초하여 결정되고,상기 제1 보조함수는,상기 유효 픽셀에 대하여 상기 제1 프레임과 상기 제3 프레임 간의 구조적 유사 지수를 나타내는 항을 더 포함하고상기 제1 깊이맵을 상기 변환행렬로 재구성한 제3 깊이맵과 제2 깊이맵이 제1 깊이맵과 같은 픽셀 그리드에 위치하도록 재구성한 제4 깊이맵에 대하여 제3 깊이맵과 제4 깊이맵의 차이를 제3 깊이맵과 제4 깊이맵의 합으로 나눈 정규화 함수를 곱하여 계산하는 함수이고,상기 구조적 유사 지수는 픽셀 간의 휘도, 대비, 구조에 대한 비교를 기반으로 하고,상기 소정 조건은 상기 제1 프레임과 제3 프레임에서의 차이가 제1 프레임과 제2 프레임에서의 차이보다 적은 픽셀인 인공신경망 학습방법.</claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서,상기 손실함수의 출력은 공간상 모든 픽셀에 대하여 상기 제1 프레임의 공간상 기울기 성분과 제1 깊이맵의 기울기 성분의 곱을 모두 더하는 제2 보조함수의 출력을 더 고려하여 결정되는 인공신경망 학습방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 손실함수의 출력은 상기 정규화 함수를 상기 유효 픽셀에 대하여 모두 더하는 제3 보조함수의 출력을 더 고려하여 결정되는 인공신경망 학습방법.</claim></claimInfo><claimInfo><claim>13. 제8 항에 있어서,상기 6자유도에 대응하는 6개의 토큰들 및 상기 특징맵을 이용하여 결합 집합을 생성하는 단계는,상기 생성된 특징맵을 겹치지 않는 일정한 크기의 패치들로 나누는 단계;상기 패치들로 이루어진 패치 집합을 생성하는 단계;상기 패치들과 같은 크기를 갖고 상기 6자유도에 대응되는 6개의 토큰들을 생성하는 단계; 및상기 패치 집합과 상기 6개의 토큰들을 결합하여 상기 결합 집합을 생성하는 단계를 포함하고상기 결합 집합은,n+6개의 패치들을 포함하고, 상기 n은 상기 특징맵에 포함된 패치들의 개수인 인공신경망 학습방법.</claim></claimInfo><claimInfo><claim>14. 제8 항에 있어서,상기 6자유도를 결정하는 단계는,상기 차원 축소 네트워크에 의해 크기가 감소된 입력 벡터의 패치들 가운데 상기 6개의 토큰들에 대응하는 패치들을 추출하는 단계; 및추출한 패치들을 이용하여 패치 별 평균 풀링을 계산하여 6자유도를 추정하는 단계를 포함하는 인공신경망 학습방법.</claim></claimInfo><claimInfo><claim>15. 컴퓨팅 장치에 있어서,프로세서를 포함하며, 상기 프로세서는 제1 프레임의 제1 영상 및 제2 프레임의 제2 영상을 획득하는 단계; 상기 제1 영상 및 제2 영상을 인공신경망에 입력하는 단계; 상기 인공신경망의 특징 추출 네트워크를 이용하여 상기 제1 영상 및 상기 제2 영상으로부터 특징맵을 생성하는 단계; 상기 6자유도에 대응하는 6개의 토큰들 및 상기 특징맵을 이용하여 결합 집합을 생성하는 단계; 상기 특징맵에 포함된 패치들의 위치적 특성을 반영하는 위치 임베딩 벡터를 생성하고, 상기 위치 임베딩 벡터 및 상기 결합 집합을 이용하여 입력 벡터를 생성하는 단계; 상기 인공신경망의 차원 축소 네트워크에 상기 입력 벡터를 입력하는 단계; 및 상기 차원 축소 네트워크의 출력으로부터 상기 6자유도를 결정하는 단계를 수행하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 컴퓨팅 장치에 있어서,프로세서를 포함하며, 상기 프로세서는 제1 프레임의 제1 영상 및 제2 프레임의 제2 영상을 획득하는 단계; 상기 제1 영상의 제1 깊이맵 및 상기 제2 영상의 제2 깊이맵을 추정하는 단계; 상기 제1 영상 및 상기 제2 영상을 상기 인공신경망에 입력하여 6자유도 정보를 출력하는 단계; 상기 6자유도 정보에 기초하여 상기 제1 프레임과 상기 제2 프레임 사이의 변환행렬을 계산하는 단계; 및 상기 제1 깊이맵, 상기 제2 깊이맵 및 상기 변환행렬에 기초하여 손실함수의 출력 값을 계산하고 상기 손실함수의 출력 값에 기초하여 상기 인공신경망을 갱신하는 단계를 수행하되,상기 6자유도 정보를 출력하는 단계는,상기 제1 영상 및 제2 영상을 인공신경망에 입력하는 단계;상기 인공신경망의 특징 추출 네트워크를 이용하여 상기 제1 영상 및 상기 제2 영상으로부터 특징맵을 생성하는 단계;상기 6자유도에 대응하는 6개의 토큰들 및 상기 특징맵을 이용하여 결합 집합을 생성하는 단계;상기 특징맵에 포함된 패치들의 위치적 특성을 반영하는 위치 임베딩 벡터를 생성하고, 상기 위치 임베딩 벡터 및 상기 결합 집합을 이용하여 입력 벡터를 생성하는 단계;상기 인공신경망의 차원 축소 네트워크에 상기 입력 벡터를 입력하는 단계; 및상기 차원 축소 네트워크의 출력으로부터 상기 6자유도를 결정하는 단계를 포함하는 컴퓨팅 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성북구...</address><code>220040468902</code><country>대한민국</country><engName>Kookmin University Industry Academy Cooperation Foundation</engName><name>국민대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 시흥시 장곡로**번길 *...</address><code> </code><country> </country><engName>CHAE Jae Min</engName><name>채재민</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>LEE Soochahn</engName><name>이수찬</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 성동구  아차산로**길 ** ,*동 ***호 (skv센터)</address><code>920181002017</code><country>대한민국</country><engName>Young BEE Intellectual Property</engName><name>특허법인영비</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.01.05</priorityApplicationDate><priorityApplicationNumber>1020220001473</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.03.30</receiptDate><receiptNumber>1-1-2022-0342154-07</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2023.11.23</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2024.02.28</receiptDate><receiptNumber>9-6-2025-0046483-76</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.03.14</receiptDate><receiptNumber>9-5-2025-0256869-32</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.28</receiptDate><receiptNumber>1-1-2025-0480247-51</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.04.28</receiptDate><receiptNumber>1-1-2025-0480248-07</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220039536.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b79cf97cdecbae3caca82b321a3ad7a26966528bebf4540d7bb6d97a1fe64a921d3e45cc3317b78e09460e743fe23da4d1258fe80d419de0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf77b491e8590cc39c5529643e0148b03e610512ee14c7392eff0641454b0c9c2c791b622e9ab5dace4b96d61d6f4b321aa8375cdf19fe72f9</path></imagePathInfo><rndInfoArray><rndInfo><rndDepartmentName>과학기술정보통신부</rndDepartmentName><rndDuration>2021.09.01 ~ 2022.02.28</rndDuration><rndManagingInstituteName>국민대학교</rndManagingInstituteName><rndProjectName>개인기초연구(과기정통부)(R＆D)</rndProjectName><rndSpecialInstituteName>한국연구재단</rndSpecialInstituteName><rndTaskContribution>1/1</rndTaskContribution><rndTaskName>시공간적 그래프 시퀸스의 생성적 모델링 및 학습 기술 연구</rndTaskName><rndTaskNumber>1711140465</rndTaskNumber></rndInfo></rndInfoArray></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>