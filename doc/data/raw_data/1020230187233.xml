<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:36:31.3631</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0187233</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>로봇 및 그의 영상 투사 방법</inventionTitle><inventionTitleEng>ROBOT AND METHOD FOR PROJECTING IMAGE THEREOF</inventionTitleEng><openDate>2025.06.27</openDate><openNumber>10-2025-0096205</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 9/31</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 19/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06K 19/06</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 로봇이 개시된다. 본 로봇은 프로젝터, 카메라, 구동부 및 프로젝터를 이용하여 마커가 이동되는 제1 캘리브레이션 영상을 투사하고, 카메라를 이용하여 로봇에 의해 투사된 제1 캘리브레이션 영상 및 다른 로봇에 의해 투사된 제1 캘리브레이션 영상을 촬영하여 영상을 획득하고, 획득된 영상에 기초하여 로봇에 의해 투사된 제1 캘리브레이션 영상 및 다른 로봇에 의해 투사된 제1 캘리브레이션 영상 각각의 마커의 위치를 식별하고, 식별된 위치에 기초하여 로봇에 의해 투사될 영상의 재생 시점을 조정하기 위한 딜레이 시간을 식별하고, 로봇이 영상이 투사될 투사면에 대응되는 위치에 있는 동안 딜레이 시간에 기초하여 영상을 투사면에 투사하도록 프로젝터를 제어하는 하나 이상의 프로세;를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 로봇에 있어서,프로젝터;카메라; 구동부; 및상기 프로젝터를 이용하여 마커가 이동되는 제1 캘리브레이션 영상을 투사하고,상기 카메라를 이용하여 상기 로봇에 의해 투사된 제1 캘리브레이션 영상 및 다른 로봇에 의해 투사된 제1 캘리브레이션 영상을 촬영하여 영상을 획득하고,상기 획득된 영상에 기초하여 상기 로봇에 의해 투사된 제1 캘리브레이션 영상 및 상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상 각각의 마커의 위치를 식별하고,상기 식별된 위치에 기초하여 상기 로봇에 의해 투사될 영상의 재생 시점을 조정하기 위한 딜레이 시간을 식별하고,상기 로봇이 상기 영상이 투사될 투사면에 대응되는 위치에 있는 동안 상기 딜레이 시간에 기초하여 상기 영상을 상기 투사면에 투사하도록 상기 프로젝터를 제어하는 하나 이상의 프로세서;를 포함하는 로봇. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상은, 상기 마커가 이동되는 영상인 로봇. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 하나 이상의 프로세서는,상기 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 기초하여 상기 로봇에 의해 투사된 제1 캘리브레이션 영상의 재생 시점을 식별하고,상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 기초하여 상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상의 재생 시점을 식별하고,상기 식별된 재생 시점들의 차이를 상기 딜레이 시간으로 식별하는 로봇.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 하나 이상의 프로세서는,상기 마커의 복수의 이동 정도에 대응되는 복수의 재생 시점 중에서 상기 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 대응되는 재생 시점을 식별하고, 상기 식별된 재생 시점을 상기 로봇에 의해 재생된 제1 캘리브레이션 영상의 재생 시점으로 식별하고,상기 마커의 복수의 이동 정도에 대응되는 복수의 재생 시점 중에서 상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 대응되는 재생 시점을 식별하고, 상기 식별된 재생 시점을 상기 다른 로봇에 의해 재생된 제1 캘리브레이션 영상의 재생 시점으로 식별하는 로봇. </claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 로봇 및 상기 다른 로봇 각각에 의해 투사된 제1 캘리브레이션 영상에 포함된 마커는, QR 코드를 포함하는 로봇. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 하나 이상의 프로세서는,상기 로봇이 상기 영상이 투사될 투사면에 대응되는 위치에 있는 동안 상기 프로젝터를 이용하여 제2 캘리브레이션 영상을 투사하고, 상기 카메라를 이용하여 상기 로봇에 의해 투사된 제2 캘리브레이션 영상 및 상기 다른 로봇에 의해 투사된 제2 캘리브레이션 영상을 촬영하여 영상을 획득하고, 상기 로봇에 의해 투사된 제2 캘리브레이션 영상 및 상기 다른 로봇에 의해 투사된 제2 캘리브레이션 영상이 서로 정합되도록 상기 획득된 영상에 기초하여 상기 구동부를 이용하여 상기 로봇의 움직임을 제어하고,상기 로봇의 움직임이 제어된 후 상기 딜레이 시간에 기초하여 상기 영상을 투사하도록 상기 프로젝터를 제어하는 로봇. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 하나 이상의 프로세서는,상기 획득된 영상에 기초하여 상기 로봇에 의해 투사된 제2 캘리브레이션 영상의 마커에 대응되는 타겟 영역을 식별하고,상기 획득된 영상에서 상기 다른 로봇에 의해 투사된 제2 캘리브레이션 영상의 마커가 상기 타겟 영역에 위치하도록 상기 구동부를 이용하여 상기 로봇의 움직임을 제어하는 로봇.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 로봇 및 상기 다른 로봇 각각에 의해 투사된 제2 캘리브레이션 영상에 포함된 마커는, 고정된 위치를 배치된 QR 코드를 포함하는 로봇. </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 투사면에 대응되는 위치는, 사용자 입력에 따라 설정된 투사면의 위치, 영상의 사이즈 및 영상의 종횡비 중 적어도 하나에 기초하여 결정되는 로봇.</claim></claimInfo><claimInfo><claim>10. 프로젝터 및 카메라를 포함하는 로봇의 영상 투사 방법에 있어서,상기 프로젝터를 이용하여 마커가 이동되는 제1 캘리브레이션 영상을 투사하는 단계; 상기 카메라를 이용하여 상기 로봇에 의해 투사된 제1 캘리브레이션 영상 및 다른 로봇에 의해 투사된 제1 캘리브레이션 영상을 촬영하여 영상을 획득하는 단계;상기 획득된 영상에 기초하여 상기 로봇에 의해 투사된 제1 캘리브레이션 영상 및 상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상 각각의 마커의 위치를 식별하는 단계; 상기 식별된 위치에 기초하여 상기 로봇에 의해 투사될 영상의 재생 시점을 조정하기 위한 딜레이 시간을 식별하는 단계; 및 상기 로봇이 상기 영상이 투사될 투사면에 대응되는 위치에 있는 동안 상기 딜레이 시간에 기초하여 상기 영상을 상기 투사면에 투사하도록 상기 프로젝터를 제어하는 단계; 포함하는 영상 투사 방법. </claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상은, 상기 마커가 이동되는 영상인 영상 투사 방법. </claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 딜레이 시간을 식별하는 단계는,상기 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 기초하여 상기 로봇에 의해 투사된 제1 캘리브레이션 영상의 재생 시점을 식별하는 단계; 상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 기초하여 상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상의 재생 시점을 식별하는 단계; 및상기 식별된 재생 시점들의 차이를 상기 딜레이 시간으로 식별하는 단계;를 포함하는 영상 투사 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 로봇에 의해 투사된 제1 캘리브레이션 영상의 재생 시점을 식별하는 단계는, 상기 마커의 복수의 이동 정도에 대응되는 복수의 재생 시점 중에서 상기 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 대응되는 재생 시점을 식별하는 단계; 및 상기 식별된 재생 시점을 상기 로봇에 의해 재생된 제1 캘리브레이션 영상의 재생 시점으로 식별하는 단계;를 포함하고,상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상의 재생 시점을 식별하는 단계는, 상기 마커의 복수의 이동 정도에 대응되는 복수의 재생 시점 중에서 상기 다른 로봇에 의해 투사된 제1 캘리브레이션 영상의 마커의 위치에 대응되는 재생 시점을 식별하는 단계; 및상기 식별된 재생 시점을 상기 다른 로봇에 의해 재생된 제1 캘리브레이션 영상의 재생 시점으로 식별하는 단계;를 포함하는 영상 투사 방법. </claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,상기 로봇 및 상기 다른 로봇 각각에 의해 투사된 제1 캘리브레이션 영상에 포함된 마커는, QR 코드를 포함하는 영상 투사 방법. </claim></claimInfo><claimInfo><claim>15. 제10항에 있어서,상기 로봇이 상기 영상이 투사될 투사면에 대응되는 위치에 있는 동안 상기 프로젝터를 이용하여 제2 캘리브레이션 영상을 투사하는 단계;상기 카메라를 이용하여 상기 로봇에 의해 투사된 제2 캘리브레이션 영상 및 상기 다른 로봇에 의해 투사된 제2 캘리브레이션 영상을 촬영하여 영상을 획득하는 단계; 상기 로봇에 의해 투사된 제2 캘리브레이션 영상 및 상기 다른 로봇에 의해 투사된 제2 캘리브레이션 영상이 서로 정합되도록 상기 획득된 영상에 기초하여 상기 로봇의 움직임을 제어하는 단계; 및상기 로봇의 움직임이 제어된 후 상기 딜레이 시간에 기초하여 상기 영상을 투사하도록 상기 프로젝터를 제어하는 단계;를 포함하는 영상 투사 방법. </claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 제어하는 단계는,상기 획득된 영상에 기초하여 상기 로봇에 의해 투사된 제2 캘리브레이션 영상의 마커에 대응되는 타겟 영역을 식별하는 단계; 및상기 획득된 영상에서 상기 다른 로봇에 의해 투사된 제2 캘리브레이션 영상의 마커가 상기 타겟 영역에 위치하도록 상기 로봇의 움직임을 제어하는 단계;를 포함하는 영상 투사 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 로봇 및 상기 다른 로봇 각각에 의해 투사된 제2 캘리브레이션 영상에 포함된 마커는, 고정된 위치를 배치된 QR 코드를 포함하는 영상 투사 방법. </claim></claimInfo><claimInfo><claim>18. 제10항에 있어서,상기 투사면에 대응되는 위치는, 사용자 입력에 따라 설정된 투사면의 위치, 영상의 사이즈 및 영상의 종횡비 중 적어도 하나에 기초하여 결정되는 영상 투사 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEON, Bo Seong</engName><name>전보성</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Hyo Muk</engName><name>김효묵</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.20</receiptDate><receiptNumber>1-1-2023-1432855-96</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230187233.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93077b17865ae086e1bbde7bdeed961a7a80793432b255b9c68573b79474d7cdd01f408ebc24b0f2867e914f2a8de1a8d29aa3c16e2e9b0f58</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf23fa01a3efe0f671ed42a21d6aeefd1f202db25fe4f77df8bc85d492b560886de700a02f774b88a91d7fc31eddf198af4a20e4d3d95ea561</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>