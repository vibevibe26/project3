<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:59.3759</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.08.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0097197</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>교차 도메인 메트릭 학습 시스템 및 방법</inventionTitle><inventionTitleEng>CROSS-DOMAIN METRIC LEARNING SYSTEM AND METHOD</inventionTitleEng><openDate>2021.02.17</openDate><openNumber>10-2021-0018114</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.08.01</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/082</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 30/27</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 하나 이상의 컨볼루션 신경망들(convolutional neural network; CNN)을 프로세싱하도록 동작가능한 제어기 및 하나 이상의 2차원 RGB 이미지들을 얻도록 동작가능한 시각화 디바이스를 포함할 수 있는 증강 현실(AR) 시스템 및 방법이 개시된다. 제어기는 앵커 이미지가 제 1 컨볼루션 신경망(CNN)에 제공되는 것에 응답하여 시멘틱 공간에서 앵커 벡터를 생성할 수 있다. 앵커 이미지는 2차원 RGB 이미지들 중 하나일 수 있다. 제어기는 네거티브 이미지 및 포지티브 이미지가 제 2 CNN에 제공되는 것에 응답하여 시멘틱 공간에서 포지티브 벡터 및 네거티브 벡터를 생성할 수 있다. 네거티브 및 포지티브 이미지들은 3차원 CAD 이미지들로서 제공될 수 있다. 제어기는 앵커 벡터, 포지티브 벡터, 및 네거티브 벡터를 이용하여 시멘틱 공간에서 이미지 피처(image feature)들을 추출하도록 동작가능한 교차 도메인 심층 메트릭 학습 알고리즘을 적용할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컨볼루션 신경망(convolutional neural network; CNN) 방법에 있어서:앵커 이미지가 제 1 CNN에 제공되는 것에 응답하여 시멘틱 공간에서 앵커 벡터를 생성하는 단계로서, 상기 앵커 이미지는 2차원 RGB 이미지이고, 상기 제 1 CNN은 하나 이상의 제 1 컨볼루션 층들, 하나 이상의 제 1 최대 풀링 층들, 제 1 평탄화 층, 제 1 드롭아웃 층, 및 제 1 완전하게 연결된 층을 포함하는, 상기 앵커 벡터를 생성하는 단계;네거티브 이미지 및 포지티브 이미지가 제 2 CNN에 제공되는 것에 응답하여 상기 시멘틱 공간에서 포지티브 벡터 및 네거티브 벡터를 생성하는 단계로서, 상기 네거티브 이미지는 제 1 3차원 CAD 이미지이고 상기 포지티브 이미지는 제 2 3차원 CAD 이미지이고, 상기 제 2 CNN은 하나 이상의 제 2 컨볼루션 층들, 하나 이상의 제 2 최대 풀링 층들, 제 2 평탄화 층, 제 2 드롭아웃 층, 및 제 2 완전하게 연결된 층을 포함하는, 상기 포지티브 벡터 및 네거티브 벡터를 생성하는 단계; 및상기 앵커 벡터, 포지티브 벡터, 및 네거티브 벡터를 이용하여 상기 시멘틱 공간에서 이미지 피처(image feature)들을 추출하도록 동작가능한 교차 도메인 심층 메트릭 학습 알고리즘을 적용하는 단계를 포함하는, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 교차 도메인 심층 메트릭 학습 알고리즘은 상기 시멘틱 공간에서 상기 앵커 벡터와 상기 포지티브 벡터 사이의 제 1 거리를 감소시키고 상기 시멘틱 공간에서 상기 앵커 벡터와 상기 네거티브 벡터 사이의 제 2 거리를 증가시키도록 동작가능한 삼중항 손실 알고리즘(triplet loss algorithm)인, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,상기 하나 이상의 제 1 컨볼루션 층들 및 하나 이상의 제 2 컨볼루션 층들은 하나 이상의 활성화 함수들을 적용하도록 동작가능한, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 하나 이상의 활성화 함수들은 정류화된 선형 유닛을 이용하여 구현되는, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>5. 제 3 항에 있어서,상기 제 1 CNN 및 제 2 CNN은 하나 이상의 정규화 층들을 더 포함하는, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>6. 제 1 항에 있어서,상기 제 2 CNN은 샴 네트워크(Siamese network)를 이용하여 설계되는, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서,상기 제 1 CNN 및 제 2 CNN은 스킵 연결 아키텍처를 이용하는, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서,상기 시멘틱 공간에서 추출된 상기 이미지 피처들을 분석함으로써 단계 인식을 수행하는 단계를 더 포함하는, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서,상기 시멘틱 공간에서의 상기 이미지 피처들의 분석에 기초하여 유효하지 않은 보수 시퀀스가 발생했는지를 결정하는 단계를 더 포함하는, 컨볼루션 신경망 방법.</claim></claimInfo><claimInfo><claim>10. 증강 현실 시스템에 있어서:하나 이상의 RGB 이미지들을 얻도록 동작가능한 시각화 디바이스; 및제어기를 포함하고, 상기 제어기는,앵커 이미지가 제 1 CNN에 제공되는 것에 응답하여, 시멘틱 공간에서 앵커 벡터를 생성하는 것으로서, 상기 앵커 이미지는 2차원 RGB 이미지이고, 상기 제 1 CNN은 하나 이상의 제 1 컨볼루션 층들, 하나 이상의 제 1 최대 풀링 층들, 제 1 평탄화 층, 제 1 드롭아웃 층, 및 제 1 완전하게 연결된 층을 포함하는, 상기 앵커 벡터를 생성하고;네거티브 이미지 및 포지티브 이미지가 제 2 CNN에 제공되는 것에 응답하여, 상기 시멘틱 공간에서 포지티브 벡터 및 네거티브 벡터를 생성하는 것으로서, 상기 네거티브 이미지는 제 1 3차원 CAD 이미지이고 상기 포지티브 이미지는 제 2 3차원 CAD 이미지이고, 상기 제 2 CNN은 하나 이상의 제 2 컨볼루션 층들을 포함하고, 상기 제 2 CNN은 하나 이상의 제 2 컨볼루션 층들, 하나 이상의 제 2 최대 풀링 층들, 제 2 평탄화 층, 제 2 드롭아웃 층, 및 제 2 완전하게 연결된 층을 포함하는, 상기 포지티브 벡터 및 네거티브 벡터를 생성하며;상기 앵커 벡터, 포지티브 벡터, 및 네거티브 벡터를 이용하여 상기 시멘틱 공간에서 이미지 피처들을 추출하도록 동작가능한 교차 도메인 심층 메트릭 학습 알고리즘을 적용하도록 동작가능한, 증강 현실 시스템.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서,상기 제어기는 상기 하나 이상의 RGB 이미지들 내에서 이미지 객체의 포즈(pose)를 결정하도록 더 동작가능한, 증강 현실 시스템.</claim></claimInfo><claimInfo><claim>12. 제 10 항에 있어서,상기 제어기는 상기 시멘틱 공간에서 상기 앵커 벡터와 상기 포지티브 벡터 사이의 제 1 거리를 감소시키고 상기 시멘틱 공간에서 상기 앵커 벡터와 상기 네거티브 벡터 사이의 제 2 거리를 증가시키도록 더 동작가능한, 증강 현실 시스템.</claim></claimInfo><claimInfo><claim>13. 제 10 항에 있어서,상기 제어기는 상기 하나 이상의 RGB 이미지들에 사후 프로세싱 이미지 알고리즘을 적용하도록 더 동작가능한, 증강 현실 시스템.</claim></claimInfo><claimInfo><claim>14. 제 10 항에 있어서,상기 제어기는 작업 절차의 현재 단계를 결정하도록 더 동작가능한, 증강 현실 시스템.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서,상기 제어기는 상기 작업 절차의 현재 단계에 기초하여 상기 시각화 디바이스에 지시들을 디스플레이하도록 더 동작가능한, 증강 현실 시스템.</claim></claimInfo><claimInfo><claim>16. 제 10 항에 있어서,상기 제 2 CNN은 샴 네트워크를 이용하여 설계되는, 증강 현실 시스템.</claim></claimInfo><claimInfo><claim>17. 증강 현실 방법에 있어서:앵커 이미지가 제 1 CNN에 제공되는 것에 응답하여 시멘틱 공간에서 앵커 벡터를 생성하는 단계로서, 상기 앵커 이미지는 2차원 RGB 이미지이고, 상기 제 1 CNN은 하나 이상의 제 1 컨볼루션 층들, 하나 이상의 제 1 최대 풀링 층들, 제 1 평탄화 층, 제 1 드롭아웃 층, 및 제 1 완전하게 연결된 층을 포함하는, 상기 앵커 벡터를 생성하는 단계;네거티브 이미지 및 포지티브 이미지가 제 2 CNN에 제공되는 것에 응답하여 상기 시멘틱 공간에서 포지티브 벡터 및 네거티브 벡터를 생성하는 단계로서, 상기 네거티브 이미지는 제 1 3차원 CAD 이미지이고 상기 포지티브 이미지는 제 2 3차원 CAD 이미지이고, 상기 제 2 CNN은 하나 이상의 제 2 컨볼루션 층들, 하나 이상의 제 2 최대 풀링 층들, 제 2 평탄화 층, 제 2 드롭아웃 층, 및 제 2 완전하게 연결된 층을 포함하는, 상기 포지티브 벡터 및 네거티브 벡터를 생성하는 단계; 및상기 앵커 벡터, 포지티브 벡터, 및 네거티브 벡터를 이용하여 상이한 양식들로부터 하나 이상의 이미지 피처들을 추출하는 단계를 포함하는, 증강 현실 방법.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,상기 시멘틱 공간에서 상기 앵커 벡터와 상기 포지티브 벡터 사이의 제 1 거리를 감소시키고 상기 시멘틱 공간에서 상기 앵커 벡터와 상기 네거티브 벡터 사이의 제 2 거리를 증가시키도록 동작가능한 삼중항 손실 알고리즘을 적용하는 단계를 더 포함하는, 증강 현실 방법.</claim></claimInfo><claimInfo><claim>19. 제 17 항에 있어서,상기 시멘틱 공간에서 추출된 상기 이미지 피처들을 분석함으로써 단계 인식을 수행하는 단계를 더 포함하는, 증강 현실 방법.</claim></claimInfo><claimInfo><claim>20. 제 17 항에 있어서,상기 시멘틱 공간에서의 상기 이미지 피처들의 분석에 기초하여 유효하지 않은 보수 시퀀스가 발생했는지를 결정하는 단계를 더 포함하는, 증강 현실 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>독일 데-***** 슈투트가르트 포스트파흐 ** ** **</address><code>519980640388</code><country>독일</country><engName>ROBERT BOSCH GMBH</engName><name>로베르트 보쉬 게엠베하</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 ****...</address><code> </code><country> </country><engName>REN Liu</engName><name>렌 리우</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ****...</address><code> </code><country> </country><engName>YE Mao</engName><name>예 마오</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 서니베...</address><code> </code><country> </country><engName>YAN Zhixin</engName><name>얀 지신</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 세종대로 ***, **층 (세종로, 광화문빌딩)(법무법인센트럴)</address><code>919990006014</code><country>대한민국</country><engName>HOON CHANG</engName><name>장훈</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.08.05</priorityApplicationDate><priorityApplicationNumber>16/531,630</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.08.04</receiptDate><receiptNumber>1-1-2020-0816649-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2020.08.06</receiptDate><receiptNumber>9-1-2020-9007399-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.08.01</receiptDate><receiptNumber>1-1-2023-0848590-58</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.08.01</receiptDate><receiptNumber>1-1-2023-0848619-94</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200097197.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e573586f14dc226df40e43dcdced82af1f916305f9fdc98f689a6b40097ceea88a5c77e052f71a7e2cafcc5d17a077fbc016a134f6537957</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2a63a52cf35aaabccaf97e5fcdc3a1d5b16dfec22ebdc8ec6db004d04d4246333c5506f86856ae3833e70d0cce0346e0d63080dec211f6ea</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>