<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:00.20</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.01.24</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7028466</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>합성 미디어 자산을 생성하기 위해 데이터 필터링 및 동기화를 통해 다중 모드 메타데이터에 기초하여 미조정 콘텐츠를 조정하기 위한 방법들 및 시스템</inventionTitle><inventionTitleEng>METHODS AND SYSTEM FOR COORDINATING UNCOORDINATED CONTENT BASED ON MULTI-MODAL METADATA THROUGH DATA FILTRATION AND SYNCHRONIZATION IN ORDER TO GENERATE COMPOSITE MEDIA ASSETS</inventionTitleEng><openDate>2023.10.05</openDate><openNumber>10-2023-0137949</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.01.24</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.08.22</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/487</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/41</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에서는 위에서 논의된 문제들을 해결하고, 특히 미조정 콘텐츠에 대한 조정을 제공하기 위한 방법들 및 시스템들이 개시된다. 방법들 및 시스템들은 단순히 이용가능 콘텐츠를 보관 및/또는 조직화하는 것 외에도, 임의의 주어진 소스 콘텐츠를 넘어서는 풍부한 상세들 및 보완 데이터를 제공하는 합성 미디어 자산들을 생성한다. 방법들 및 시스템들은 새로운 데이터 필터링 및 동기화 프로세스를 통해 이를 달성한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.07.28</internationOpenDate><internationOpenNumber>WO2022159821</internationOpenNumber><internationalApplicationDate>2022.01.24</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/013538</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 합성 미디어 자산들을 생성하기 위해 데이터 필터링 및 동기화를 통해 다중 모드 메타데이터에 기초하여 미조정 콘텐츠를 조정하기 위한 시스템으로서,하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행될 때 동작들을 유발하는 명령어들을 포함하는 저장 회로를 포함하며, 상기 동작들은:공유 시간 윈도우에서 공유 지리 위치에 대한 질량 중심 포인트에 기초하여 합성 미디어 자산을 요청하는 제1 사용자 입력을 수신하는 동작;상기 공유 지리 위치에 대한 상기 질량 중심 포인트에 기초하여 공유 객체 배향을 결정하는 동작;제1 미디어 자산에 대해 제1 미디어 자산 데이터 구조를 검색하는 동작 - 상기 제1 미디어 자산 데이터 구조는 제1 위치 정보, 제1 시간 정보 및 제1 객체 정보를 포함하고, 상기 제1 위치 정보는 상기 제1 미디어 자산에 대응하는 제1 지리 위치를 나타내고, 상기 제1 시간 정보는 상기 제1 미디어 자산에 대응하는 제1 시간을 나타내고, 상기 제1 객체 정보는 상기 제1 미디어 자산에 포함된 제1 객체를 나타냄 -;제2 미디어 자산에 대해 제2 미디어 자산 데이터 구조를 검색하는 동작 - 상기 제2 미디어 자산 데이터 구조는 제2 위치 정보, 제2 시간 정보 및 제2 객체 정보를 포함하고, 상기 제2 위치 정보는 상기 제1 미디어 자산에 대응하는 제2 지리 위치를 나타내고, 상기 제2 시간 정보는 상기 제2 미디어 자산에 대응하는 제2 시간을 나타내고, 상기 제2 객체 정보는 상기 제2 미디어 자산에 포함된 제2 객체를 나타냄 -;상기 제1 위치 정보 및 상기 제2 위치 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 동작;상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 것에 응답하여, 상기 제1 시간 정보 및 상기 제2 시간 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 동작;상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 것에 응답하여, 상기 제1 객체 정보 및 상기 제2 객체 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 공유 객체 배향에 대응한다고 결정하는 동작; 및상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 객체 배향에 대응한다고 결정하는 것에 응답하여, 상기 질량 중심 포인트에 대해 상기 제1 미디어 자산과 상기 제2 미디어 자산을 병합함으로써 상기 제1 미디어 자산 및 상기 제2 미디어 자산에 기초하여 상기 합성 미디어 자산을 생성하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>2. 데이터 필터링 및 동기화를 통해 다중 모드 메타데이터에 기초하여 미조정 콘텐츠를 조정하기 위한 방법으로서, 공유 시간 윈도우에서 공유 지리 위치에 대한 질량 중심 포인트에 기초하여 합성 미디어 자산을 요청하는 제1 사용자 입력을 수신하는 단계;상기 공유 지리 위치에 대한 상기 질량 중심 포인트에 기초하여 공유 객체 배향을 결정하는 단계;제1 미디어 자산에 대해 제1 미디어 자산 데이터 구조를 검색하는 단계 - 상기 제1 미디어 자산 데이터 구조는 제1 위치 정보, 제1 시간 정보 및 제1 객체 정보를 포함함 -; 제2 미디어 자산에 대해 제2 미디어 자산 데이터 구조를 검색하는 단계 - 제2 미디어 자산 데이터 구조는 제2 위치 정보, 제2 시간 정보 및 제2 객체 정보를 포함함 -; 상기 제1 위치 정보 및 상기 제2 위치 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 단계; 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 것에 응답하여, 상기 제1 시간 정보 및 상기 제2 시간 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 단계; 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 것에 응답하여, 상기 제1 객체 정보 및 상기 제2 객체 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 객체 배향에 대응한다고 결정하는 단계; 및 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 객체 배향에 대응한다고 결정하는 것에 응답하여, 상기 질량 중심 포인트에 대해 상기 제1 미디어 자산과 상기 제2 미디어 자산을 병합함으로써 상기 제1 미디어 자산 및 상기 제2 미디어 자산에 기초하여 상기 합성 미디어 자산을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 제1 위치 정보 및 상기 제2 위치 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 단계는:상기 공유 지리 위치를 나타내는 제2 사용자 입력을 수신하는 단계; 및 상기 공유 지리 위치를 나타내는 상기 제2 사용자 입력을 수신하는 것에 응답하여, 복수의 이용가능 미디어 자산에 대한 각각의 위치 정보와 상기 공유 지리 위치의 비교에 기초하여 상기 복수의 이용가능 미디어 자산을 필터링하여 미디어 자산들의 제1 서브세트를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제1 시간 정보 및 상기 제2 시간 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 단계는:상기 공유 시간 윈도우를 나타내는 제3 사용자 입력을 수신하는 단계; 및 상기 공유 시간 윈도우를 나타내는 상기 제3 사용자 입력을 수신하는 것에 응답하여, 상기 미디어 자산들의 제1 서브세트에 대한 각각의 시간 정보와 상기 공유 시간 윈도우의 비교에 기초하여 상기 미디어 자산들의 제1 서브세트를 필터링하여 미디어 자산들의 제2 서브세트를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서, 상기 제1 객체 정보 및 상기 제2 객체 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 객체 배향에 대응한다고 결정하는 단계는:상기 질량 중심 포인트에 대응하는 알려진 객체를 식별하는 단계; 상기 공유 객체 배향에서 상기 알려진 객체에 대한 복수의 알려진 객체 상세를 검색하는 단계; 및 상기 복수의 알려진 객체 상세 중의 알려진 객체 상세가 상기 제1 미디어 자산 및 상기 제2 미디어 자산 둘 다에 존재한다고 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서, 상기 제1 미디어 자산 및 상기 제2 미디어 자산을 병합함으로써 상기 제1 미디어 자산 및 상기 제2 미디어 자산에 기초하여 상기 합성 미디어 자산을 생성하는 단계는:상기 제1 미디어 자산 및 상기 제2 미디어 자산 둘 다에서 공유 객체를 식별하는 단계; 및상기 제1 미디어 자산으로부터의 제1 객체 상세 및 상기 제2 미디어 자산으로부터의 제2 객체 상세를 사용하여 상기 합성 미디어 자산 내의 상기 공유 객체의 표현을 생성하는 단계를 더 포함하며, 상기 제2 미디어 자산은 상기 제1 객체 상세를 포함하지 않고, 상기 제1 미디어 자산은 상기 제2 객체 상세를 포함하지 않는, 방법.</claim></claimInfo><claimInfo><claim>7. 제2항에 있어서, 상기 제1 위치 정보는 상기 제1 미디어 자산에 대응하는 제1 지리 위치를 나타내고, 상기 제1 시간 정보는 상기 제1 미디어 자산에 대응하는 제1 시간을 나타내고, 상기 제1 객체 정보는 상기 제1 미디어 자산에 포함된 제1 객체를 나타내는, 방법.</claim></claimInfo><claimInfo><claim>8. 제2항에 있어서, 상기 제1 미디어 자산은 복수의 프레임을 포함하고, 상기 제1 미디어 자산에 대해 상기 제1 미디어 자산 데이터 구조를 검색하는 단계는:상기 합성 미디어 자산을 생성하기 위한 상기 복수의 프레임 중 제1 프레임을 결정하는 단계; 상기 제1 프레임에 대응하는 상기 제1 미디어 자산 데이터 구조의 서브세트를 결정하는 단계; 및 상기 제1 미디어 자산 데이터 구조의 상기 서브세트로부터 상기 위치 정보, 상기 제1 시간 정보 및 상기 제1 객체 정보를 검색하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제2항에 있어서, 상기 공유 객체 배향은 콘텐츠 캡처 디바이스가 각각의 미디어 자산을 캡처할 때 향하는 방향을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제2항에 있어서, 상기 질량 중심 포인트에 대해 상기 제1 미디어 자산과 상기 제2 미디어 자산을 병합함으로써 상기 제1 미디어 자산 및 상기 제2 미디어 자산에 기초하여 상기 합성 미디어 자산을 생성하는 단계는:초점이 맞지 않는 객체에 대응하는 상기 제1 미디어 자산의 제1 부분을 식별하는 단계; 상기 제1 미디어 자산 내의 상기 초점이 맞지 않는 객체에 대응하는 상기 제2 미디어 자산의 제2 부분을 선택하는 단계; 및 상기 제1 미디어 자산의 상기 제1 부분을 상기 제2 부분으로 대체하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제2항에 있어서, 상기 공유 시간 윈도우에서 상기 공유 지리 위치에 대한 상기 질량 중심 포인트에 기초하여 상기 합성 미디어 자산을 요청하는 상기 제1 사용자 입력을 수신하는 단계는:상기 제1 미디어 자산 내의 객체의 사용자 선택을 수신하는 단계; 상기 객체가 발견되는 지리 위치를 결정하는 단계; 상기 지리 위치를 상기 공유 지리 위치로서 할당하는 단계; 및 상기 지리 위치에서의 상기 객체의 위치를 상기 질량 중심 포인트로서 할당하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 하나 이상의 프로세서에 의해 실행될 때 동작들을 유발하는 명령어들을 포함하는 비일시적 컴퓨터 판독가능 매체로서,상기 동작들은:공유 시간 윈도우에서 공유 지리 위치에 대한 질량 중심 포인트에 기초하여 합성 미디어 자산을 요청하는 제1 사용자 입력을 수신하는 동작;상기 공유 지리 위치에 대한 상기 질량 중심 포인트에 기초하여 공유 객체 배향을 결정하는 동작;제1 미디어 자산에 대해 제1 미디어 자산 데이터 구조를 검색하는 동작 - 상기 제1 미디어 자산 데이터 구조는 제1 위치 정보, 제1 시간 정보 및 제1 객체 정보를 포함함 -; 제2 미디어 자산에 대해 제2 미디어 자산 데이터 구조를 검색하는 동작 - 제2 미디어 자산 데이터 구조는 제2 위치 정보, 제2 시간 정보 및 제2 객체 정보를 포함함 -; 상기 제1 위치 정보 및 상기 제2 위치 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 동작; 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 것에 응답하여, 상기 제1 시간 정보 및 상기 제2 시간 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 동작; 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 것에 응답하여, 상기 제1 객체 정보 및 상기 제2 객체 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 객체 배향에 대응한다고 결정하는 동작; 및 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 객체 배향에 대응한다고 결정하는 것에 응답하여, 상기 질량 중심 포인트에 대해 상기 제1 미디어 자산과 상기 제2 미디어 자산을 병합함으로써 상기 제1 미디어 자산 및 상기 제2 미디어 자산에 기초하여 상기 합성 미디어 자산을 생성하는 동작을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제1 위치 정보 및 상기 제2 위치 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 지리 위치에 대응한다고 결정하는 동작은:상기 공유 지리 위치를 나타내는 제2 사용자 입력을 수신하는 동작; 및 상기 공유 지리 위치를 나타내는 상기 제2 사용자 입력을 수신하는 것에 응답하여, 복수의 이용가능 미디어 자산에 대한 각각의 위치 정보와 상기 공유 지리 위치의 비교에 기초하여 상기 복수의 이용가능 미디어 자산을 필터링하여 미디어 자산들의 제1 서브세트를 생성하는 동작을 더 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 제1 시간 정보 및 상기 제2 시간 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 시간 윈도우에 대응한다고 결정하는 동작은:상기 공유 시간 윈도우를 나타내는 제3 사용자 입력을 수신하는 동작; 및 상기 공유 시간 윈도우를 나타내는 상기 제3 사용자 입력을 수신하는 것에 응답하여, 상기 미디어 자산들의 제1 서브세트에 대한 각각의 시간 정보와 상기 공유 시간 윈도우의 비교에 기초하여 상기 미디어 자산들의 제1 서브세트를 필터링하여 미디어 자산들의 제2 서브세트를 생성하는 동작을 더 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서, 상기 제1 객체 정보 및 상기 제2 객체 정보를 분석하는 것에 기초하여 상기 제1 미디어 자산 및 상기 제2 미디어 자산이 상기 공유 객체 배향에 대응한다고 결정하는 동작은:상기 질량 중심 포인트에 대응하는 알려진 객체를 식별하는 동작; 상기 공유 객체 배향에서 상기 알려진 객체에 대한 복수의 알려진 객체 상세를 검색하는 동작; 및 상기 복수의 알려진 객체 상세 중의 알려진 객체 상세가 상기 제1 미디어 자산 및 상기 제2 미디어 자산 둘 다에 존재한다고 결정하는 동작을 더 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서, 상기 제1 미디어 자산 및 상기 제2 미디어 자산을 병합함으로써 상기 제1 미디어 자산 및 상기 제2 미디어 자산에 기초하여 상기 합성 미디어 자산을 생성하는 동작은:상기 제1 미디어 자산 및 상기 제2 미디어 자산 둘 다에서 공유 객체를 식별하는 동작; 및상기 제1 미디어 자산으로부터의 제1 객체 상세 및 상기 제2 미디어 자산으로부터의 제2 객체 상세를 사용하여 상기 합성 미디어 자산 내의 상기 공유 객체의 표현을 생성하는 동작을 더 포함하며, 상기 제2 미디어 자산은 상기 제1 객체 상세를 포함하지 않고, 상기 제1 미디어 자산은 상기 제2 객체 상세를 포함하지 않는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서, 상기 제1 위치 정보는 상기 제1 미디어 자산에 대응하는 제1 지리 위치를 나타내고, 상기 제1 시간 정보는 상기 제1 미디어 자산에 대응하는 제1 시간을 나타내고, 상기 제1 객체 정보는 상기 제1 미디어 자산에 포함된 제1 객체를 나타내는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서, 상기 제1 미디어 자산은 복수의 프레임을 포함하고, 상기 제1 미디어 자산에 대해 상기 제1 미디어 자산 데이터 구조를 검색하는 동작은:상기 합성 미디어 자산을 생성하기 위한 상기 복수의 프레임 중 제1 프레임을 결정하는 동작; 상기 제1 프레임에 대응하는 상기 제1 미디어 자산 데이터 구조의 서브세트를 결정하는 동작; 및 상기 제1 미디어 자산 데이터 구조의 상기 서브세트로부터 상기 위치 정보, 상기 제1 시간 정보 및 상기 제1 객체 정보를 검색하는 동작을 더 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>19. 제12항에 있어서, 상기 공유 객체 배향은 콘텐츠 캡처 디바이스가 각각의 미디어 자산을 캡처할 때 향하는 방향을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>20. 제12항에 있어서, 상기 질량 중심 포인트에 대해 상기 제1 미디어 자산과 상기 제2 미디어 자산을 병합함으로써 상기 제1 미디어 자산 및 상기 제2 미디어 자산에 기초하여 상기 합성 미디어 자산을 생성하는 동작은:초점이 맞지 않는 객체에 대응하는 상기 제1 미디어 자산의 제1 부분을 식별하는 동작; 상기 제1 미디어 자산 내의 상기 초점이 맞지 않는 객체에 대응하는 상기 제2 미디어 자산의 제2 부분을 선택하는 동작; 및 상기 제1 미디어 자산의 상기 제1 부분을 상기 제2 부분으로 대체하는 동작을 더 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매릴랜드주 컴버랜드 그린 스트리트 ***</address><code>520200602821</code><country>미국</country><engName>EMERGEX, LLC</engName><name>에머젝스, 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 메릴랜...</address><code> </code><country> </country><engName>KARLIN, Michael Joseph</engName><name>카린, 마이클 조셉</name></inventorInfo><inventorInfo><address>미국 ***** 디스트릭트 오브 ...</address><code> </code><country> </country><engName>FEINSON, Roy</engName><name>페인슨, 로이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.01.25</priorityApplicationDate><priorityApplicationNumber>63/141,171</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.08.22</receiptDate><receiptNumber>1-1-2023-0922310-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.08.30</receiptDate><receiptNumber>1-5-2023-0138771-00</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.01.24</receiptDate><receiptNumber>1-1-2025-0103180-04</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237028466.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9367e202351212a42004c63707e32aa7b4ccd612e2ebeef12d96e126a1599aa2981e35a2d5539786a43360919544242adbd71ee35915f49377</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbd98389d5627f7213b130db0683bf924c1c97e46bd3a8f9e438e6f52968859dc1425fb634d075d7c4ae6b1a62d5c7376d885c1ce9e625505</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>