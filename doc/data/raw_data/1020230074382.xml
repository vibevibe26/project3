<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:38:40.3840</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0074382</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 영상을 이용하여 사용자에게 가이드를 제공하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR PROVIDING GUIDE TO USER  USING AUGMENTED REALITY VIDEO</inventionTitleEng><openDate>2024.12.17</openDate><openNumber>10-2024-0174747</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06V 10/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/279</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/9535</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06F 3/048</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 증강 현실 장치가 사용자에게 가이드(guide)를 제공하는 방법을 제공한다. 증강 현실 장치의 동작 방법은, 사용자에게 가이드로 제공할 동작(action)을 식별하는 단계, 카메라를 통해 현실 장면(real-world scene) 이미지를 획득하는 단계, 현실 장면 이미지에 기초하여 동작에 대응되는 증강 현실 영상을 생성하는 단계, 및 사용자에게 증강 현실 영상을 이용하여 가이드를 제공하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 증강 현실 장치(100)가 사용자에게 가이드(guide)를 제공하는 방법에 있어서,상기 사용자에게 가이드로 제공할 동작(action)을 식별하는 단계;카메라(120)를 통해 현실 장면(real-world scene) 이미지를 획득하는 단계;상기 현실 장면 이미지에 기초하여 상기 동작에 대응되는 증강 현실 영상을 생성하는 단계; 및상기 사용자에게 상기 증강 현실 영상을 이용하여 가이드를 제공하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 사용자에게 가이드로 제공할 동작을 식별하는 단계는,서버로부터 상기 동작과 관련된 정보를 수신하는 단계;상기 카메라(120)를 통해 상기 동작과 관련된 정보를 획득하는 단계; 또는메모리(150)에 기 저장된 상기 동작과 관련된 정보를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 사용자에게 가이드로 제공할 동작을 식별하는 단계는,동작과 관련된 텍스트(text)가 포함된 이미지를 획득하는 단계; 및상기 획득한 이미지를 자연어 처리(natural language processing, NLP)하여 상기 사용자에게 가이드로 제공할 동작을 식별하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 현실 장면 이미지에 기초하여 상기 동작에 대응되는 증강 현실 영상을 생성하는 단계는,상기 현실 장면 이미지를 세분화(segmentation)하는 단계;상기 세분화된 현실 장면 이미지로부터 상기 동작과 관련된 적어도 하나의 객체 이미지를 식별하는 단계; 및상기 적어도 하나의 객체 이미지의 상기 현실 장면 이미지 내 위치 정보에 기초하여, 상기 동작에 대응되는 증강 현실 영상을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 세분화된 현실 장면 이미지로부터 상기 동작과 관련된 적어도 하나의 객체 이미지가 식별되지 않는 경우, 미확인 객체 정보 확인 요청 메시지를 출력하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,상기 사용자와 관련된 사용자 정보를 획득하는 단계를 더 포함하고,상기 증강 현실 영상을 생성하는 단계는, 상기 현실 장면 이미지 및 상기 사용자 정보에 기초하여 상기 동작에 대응되는 증강 현실 영상을 생성하는 것인, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 사용자와 관련된 사용자 정보를 획득하는 단계는,센서(130)를 통해 상기 사용자와 관련된 사용자 정보를 획득하는 단계; 또는메모리(150)에 기 저장된 상기 사용자와 관련된 사용자 정보를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서,상기 사용자 정보는, 키(height), 팔 길이, 몸무게, 주로 사용하는 손, 또는 신체적 장애 관련 정보 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 사용자에게 가이드로 제공할 동작은 시간적 선후관계를 갖는 복수의 세부 동작들의 시퀀스(sequence)로 구성되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 사용자에게 상기 증강 현실 영상을 이용하여 가이드를 제공하는 단계는,상기 사용자가 가이드로 제공된 상기 동작을 수행 완료하였는지 여부를 판단하는 단계; 및상기 사용자가 상기 동작을 수행 완료하지 않았다고 판단되는 경우, 상기 증강 현실 영상을 일정 주기로 반복적으로 출력하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 사용자에게 가이드(guide)를 제공하는 증강 현실 장치(100)에 있어서,현실 장면 이미지(real-world scene)를 획득하도록 구성되는 카메라(120);디스플레이부(162);적어도 하나의 명령어(instruction)를 포함하는 프로그램을 저장하는 메모리(150); 및적어도 하나의 프로세서(140)를 포함하고,상기 적어도 하나의 프로세서(140)는,상기 사용자에게 가이드로 제공할 동작(action)을 식별하고,상기 카메라(120)를 통해 현실 장면 이미지를 획득하고,상기 현실 장면 이미지에 기초하여 상기 동작에 대응되는 증강 현실 영상을 생성하고,상기 디스플레이부(162)를 통해 상기 사용자에게 상기 증강 현실 영상을 이용하여 가이드를 제공하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 적어도 하나의 프로세서(140)는,통신 인터페이스(110)를 통해 서버로부터 상기 동작과 관련된 정보를 수신하거나,상기 카메라(120)를 통해 상기 동작과 관련된 정보를 획득하거나, 또는상기 메모리(150)에 기 저장된 상기 동작과 관련된 정보를 획득하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>13. 제11항 또는 제12항에 있어서,상기 적어도 하나의 프로세서(140)는,동작과 관련된 텍스트(text)가 포함된 이미지를 획득하고,상기 획득한 이미지를 자연어 처리(natural language processing, NLP)하여 상기 사용자에게 가이드로 제공할 동작을 식별하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>14. 제11항 내지 제13항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 현실 장면 이미지를 세분화(segmentation)하고,상기 세분화된 현실 장면 이미지로부터 상기 동작과 관련된 적어도 하나의 객체 이미지를 식별하고,상기 적어도 하나의 객체 이미지의 상기 현실 장면 이미지 내 위치 정보에 기초하여, 상기 동작에 대응되는 증강 현실 영상을 생성하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 세분화된 현실 장면 이미지로부터 상기 동작과 관련된 적어도 하나의 객체 이미지가 식별되지 않는 경우, 출력 인터페이스(160)를 통해 미확인 객체 정보 확인 요청 메시지를 출력하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>16. 제11항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 사용자와 관련된 사용자 정보를 더 획득하고,상기 현실 장면 이미지 및 상기 사용자 정보에 기초하여 상기 동작에 대응되는 증강 현실 영상을 생성하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 적어도 하나의 프로세서(140)는,센서(130)를 통해 상기 사용자와 관련된 사용자 정보를 획득하거나, 또는메모리(150)에 기 저장된 상기 사용자와 관련된 사용자 정보를 획득하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>18. 제16항 또는 제17항에 있어서,상기 사용자 정보는, 키(height), 팔 길이, 몸무게, 주로 사용하는 손, 또는 신체적 장애 관련 정보 중 적어도 하나를 포함하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>19. 제11항 내지 제18항 중 어느 한 항에 있어서,상기 사용자에게 가이드로 제공할 동작은 시간적 선후관계를 갖는 복수의 세부 동작들의 시퀀스(sequence)로 구성되는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>20. 제11항 내지 제19항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 사용자가 가이드로 제공된 상기 동작을 수행 완료하였는지 여부를 판단하고,상기 사용자가 상기 동작을 수행 완료하지 않았다고 판단되는 경우, 상기 증강 현실 영상을 일정 주기로 반복적으로 출력하는, 증강 현실 장치(100).</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Jeong Won</engName><name>김정원</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KOO, Bon Kon</engName><name>구본곤</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Do Youn</engName><name>김도윤</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>RYU, Jae Yeol</engName><name>류재열</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>SHIN, Sung Hwan</engName><name>신성환</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.06.09</receiptDate><receiptNumber>1-1-2023-0637866-61</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230074382.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93cfd6c489c6f0656bfd9f67db89123da0880ac5afbe05084d7f8bddf69b5aff1633a3c09f54e7838cd5b1d5c9add1034d3baf2080ad748e20</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9e8e49e4a78f002bb1b4d687ef59ec11350d3efd456148ec256396ed3be07ca10ea0bfabd3b6b626531be42cba5ec1201834d9b70a1f1f99</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>