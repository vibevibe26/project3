<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:03:18.318</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.11.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0156527</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>무용 인식을 통해 검출되는 사용자의 감정을 이용하여 음악 콘텐츠를 추천하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR RECOMMENDING MUSIC CONTENT USING  USER'S EMOTION DETECTED THROUGH DANCE RECOGNITION</inventionTitleEng><openDate>2025.05.19</openDate><openNumber>10-2025-0069444</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2012.01.01)</ipcDate><ipcNumber>G06Q 50/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2012.01.01)</ipcDate><ipcNumber>G06Q 50/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2012.01.01)</ipcDate><ipcNumber>G06Q 50/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2025.01.01)</ipcDate><ipcNumber>G06F 16/332</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 일 실시예에 따른 무용 인식을 통해 검출되는 사용자의 감정을 이용하여 음악 콘텐츠를 추천하는 방법은, 무용 동작을 수행하는 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도를 포함하는 동작 정보를 획득하는 단계; 기 학습된 제1 딥러닝 모델을 통해, 상기 동작 정보로부터 상기 무용 동작에 대응되는 감정 정보를 결정하는 단계; 및 상기 감정 정보를 기초로 순위화되는 음악-감정 데이터베이스를 이용하여, 상기 감정 정보에 대응되는 음악 콘텐츠를 추천하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 무용 인식을 통해 검출되는 사용자의 감정을 이용하여 음악 콘텐츠를 추천하는 방법으로서,무용 동작을 수행하는 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도를 포함하는 동작 정보를 획득하는 단계;기 학습된 제1 딥러닝 모델을 통해, 상기 동작 정보로부터 상기 무용 동작에 대응되는 감정 정보를 결정하는 단계; 및상기 감정 정보를 기초로 순위화되는 음악-감정 데이터베이스를 이용하여, 상기 감정 정보에 대응되는 음악 콘텐츠를 추천하는 단계를 포함하고,상기 제1 딥러닝 모델은 상기 동작 정보를 입력 받아, 상기 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도에 대한 대칭성을 기초로, 상기 감정 정보를 출력하도록 학습되는음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 동작 정보를 획득하는 단계는,웨어러블 센서 또는 모션 인식 알고리즘에 기초하여, 상기 동작 정보를 획득하는 단계를 포함하는음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 동작 정보를 획득하는 단계에서,상기 사용자의 적어도 두 개 이상의 신체 부위는,좌측 어깨, 우측 어깨, 좌측 팔꿈치, 우측 팔꿈치, 좌측 허벅지, 우측 허벅지, 좌측 무릎 및 우측 무릎 중 적어도 두 개를 포함하는 음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,상기 감정 정보를 결정하는 단계는,상기 제1 딥러닝 모델을 이용하여 상기 무용 동작에 대응되는 적어도 하나의 감정 벡터를 추출하는 단계를 포함하고,상기 적어도 하나의 감정 벡터는,무감정(neutral), 행복(happy), 슬픔(sad), 화남(angry) 및 두려움(fear) 중 적어도 하나에 대한 감정 벡터를 포함하는음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,상기 음악-감정 데이터베이스는 음악-감정 매트릭스(matrix)를 포함하고,상기 음악 콘텐츠를 추천하는 단계는,상기 음악-감정 매트릭스와 적어도 하나의 감정 벡터 간의 코사인 유사도를 연산하는 단계;상기 연산된 코사인 유사도를 기초로, 상기 음악-감정 매트릭스(matrix)를 정렬하는 단계; 및상기 정렬된 음악-감정 매트릭스에서 결정되는 순위를 참조하여, 상기 사용자에게 상기 음악 콘텐츠를 추천하는 단계를 포함하는음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 음악-감정 매트릭스(matrix)는,음악 데이터셋으로부터 획득되는 음악 콘텐츠에 대한 메타데이터를 기 학습된 제2 딥러닝 모델에 입력하여 생성되고,상기 제2 딥러닝 모델은 사전 학습된 자연어 처리 모델을 기초로 전이 학습된 것인음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 추천된 음악 콘텐츠에 대한 상기 사용자의 조작 정보를 입력 받는 단계; 및상기 사용자의 조작 정보를 기초로, 상기 음악-감정 데이터베이스를 업데이트하는 단계를 더 포함하는음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 음악-감정 데이터베이스를 업데이트하는 단계는,상기 사용자의 웹사이트 링크 클릭 여부, 음원 재생 여부 및 음원 재생 시간을 기초로 상기 추천된 음악 콘텐츠에 대한 적합성을 판단하는 피드백 루프를 이용하여, 상기 음악-감정 데이터베이스를 업데이트하는 단계를 포함하는음악 콘텐츠 추천 방법.</claim></claimInfo><claimInfo><claim>9. 무용 인식을 통해 검출되는 사용자의 감정을 이용하여 음악 콘텐츠를 추천하는 장치로서,음악 콘텐츠 추천 프로그램이 저장된 메모리; 및상기 메모리에서 상기 음악 콘텐츠 추천 프로그램을 로드하여, 상기 음악 콘텐츠 추천 프로그램을 실행하는 프로세서를 포함하고,상기 프로세서는,무용 동작을 수행하는 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도를 포함하는 동작 정보를 획득하고,기 학습된 제1 딥러닝 모델을 통해, 상기 동작 정보로부터 상기 무용 동작에 대응되는 감정 정보를 결정하고,상기 감정 정보를 기초로 순위화되는 음악-감정 데이터베이스를 이용하여, 상기 감정 정보에 대응되는 음악 콘텐츠를 추천하되,상기 제1 딥러닝 모델은 상기 동작 정보를 입력 받아, 상기 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도에 대한 대칭성을 기초로, 상기 감정 정보를 출력하도록 학습되는음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,상기 프로세서는,웨어러블 센서 또는 모션 인식 알고리즘에 기초하여, 상기 동작 정보를 획득하는음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>11. 제9 항에 있어서,상기 사용자의 적어도 두 개 이상의 신체 부위는,좌측 어깨, 우측 어깨, 좌측 팔꿈치, 우측 팔꿈치, 좌측 허벅지, 우측 허벅지, 좌측 무릎 및 우측 무릎 중 적어도 두 개를 포함하는 음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>12. 제9 항에 있어서,상기 프로세서는,상기 제1 딥러닝 모델을 이용하여 상기 무용 동작에 대응되는 적어도 하나의 감정 벡터를 추출하고,상기 적어도 하나의 감정 벡터는,무감정(neutral), 행복(happy), 슬픔(sad), 화남(angry) 및 두려움(fear) 중 적어도 하나에 대한 감정 벡터를 포함하는음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>13. 제9 항에 있어서,상기 음악-감정 데이터베이스는 음악-감정 매트릭스(matrix)를 포함하고,상기 프로세서는,상기 음악-감정 매트릭스와 적어도 하나의 감정 벡터 간의 코사인 유사도를 연산하고,상기 연산된 코사인 유사도를 기초로, 상기 음악-감정 매트릭스(matrix)를 정렬하고,상기 정렬된 음악-감정 매트릭스에서 결정되는 순위를 참조하여, 상기 사용자에게 상기 음악 콘텐츠를 추천하는음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 음악-감정 매트릭스(matrix)는,음악 데이터셋으로부터 획득되는 음악 콘텐츠에 대한 메타데이터를 기 학습된 제2 딥러닝 모델에 입력하여 생성되고,상기 제2 딥러닝 모델은 사전 학습된 자연어 처리 모델을 기초로 전이 학습된 것인음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>15. 제9 항에 있어서,상기 프로세서는,상기 추천된 음악 콘텐츠에 대한 상기 사용자의 조작 정보를 입력 받고,상기 사용자의 조작 정보를 기초로, 상기 음악-감정 데이터베이스를 업데이트하는음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서,상기 프로세서는,상기 사용자의 웹사이트 링크 클릭 여부, 음원 재생 여부 및 음원 재생 시간을 기초로 상기 추천된 음악 콘텐츠에 대한 적합성을 판단하는 피드백 루프를 이용하여, 상기 음악-감정 데이터베이스를 업데이트하는음악 콘텐츠 추천 장치.</claim></claimInfo><claimInfo><claim>17. 컴퓨터 프로그램을 저장하고 있는 컴퓨터 판독 가능 기록매체로서,상기 컴퓨터 프로그램은, 프로세서에 의해 실행되면,무용 동작을 수행하는 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도를 포함하는 동작 정보를 획득하는 단계;기 학습된 제1 딥러닝 모델을 통해, 상기 동작 정보로부터 상기 무용 동작에 대응되는 감정 정보를 결정하는 단계; 및상기 감정 정보를 기초로 순위화되는 음악-감정 데이터베이스를 이용하여, 상기 감정 정보에 대응되는 음악 콘텐츠를 추천하는 단계를 포함하고,상기 제1 딥러닝 모델은 상기 동작 정보를 입력 받아, 상기 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도에 대한 대칭성을 기초로, 상기 감정 정보를 출력하도록 학습되는음악 콘텐츠 추천 방법을 상기 프로세서가 수행하도록 하기 위한 명령어를 포함하는컴퓨터 판독 가능한 기록매체.</claim></claimInfo><claimInfo><claim>18. 컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은, 프로세서에 의해 실행되면,무용 동작을 수행하는 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도를 포함하는 동작 정보를 획득하는 단계;기 학습된 제1 딥러닝 모델을 통해, 상기 동작 정보로부터 상기 무용 동작에 대응되는 감정 정보를 결정하는 단계; 및상기 감정 정보를 기초로 순위화되는 음악-감정 데이터베이스를 이용하여, 상기 감정 정보에 대응되는 음악 콘텐츠를 추천하는 단계를 포함하고,상기 제1 딥러닝 모델은 상기 동작 정보를 입력 받아, 상기 사용자의 적어도 두 개 이상의 신체 부위의 속도 및 각도에 대한 대칭성을 기초로, 상기 감정 정보를 출력하도록 학습되는음악 콘텐츠 추천 방법을 상기 프로세서가 수행하도록 하기 위한 명령어를 포함하는컴퓨터 판독 가능한 기록매체에 저장되어 있는 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980988661</code><country>대한민국</country><engName>Korea Advanced Institute of Science and Technology</engName><name>한국과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country>대한민국</country><engName>Park, Inkyu</engName><name>박인규</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country>대한민국</country><engName>Kim, Jeounghoon</engName><name>김정훈</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code>420140181464</code><country>대한민국</country><engName>Bokyung Seo</engName><name>서예주</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country>대한민국</country><engName>JOUNG, JEEHYUN</engName><name>정지현</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country>대한민국</country><engName>Lee, gihun</engName><name>이기훈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.11.09</priorityApplicationDate><priorityApplicationNumber>1020230154358</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.11.06</receiptDate><receiptNumber>1-1-2024-1220281-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.01.22</receiptDate><receiptNumber>1-1-2025-0087401-23</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.03.12</receiptDate><receiptNumber>1-1-2025-0280986-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.09.12</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240156527.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93ce9754784d6c58954d224c13e8bce213a70999ed74900442a1cb938742a50b65fa691c61b1c10e1a166419884c4b410f64568456c7da76ce</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0601657871ddbb1aef5d43c054815a80bac1f1c7fdae0ad7368473b3d8307778ca3b3930e4d7a6709e338023f871999b1078d8ec4eb8da89</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>