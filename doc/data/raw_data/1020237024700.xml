<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:48.148</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7024700</applicationNumber><claimCount>22</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>지도된 자율 파지</inventionTitle><inventionTitleEng>SUPERVISED AUTONOMOUS GRASPING</inventionTitleEng><openDate>2023.08.22</openDate><openNumber>10-2023-0122118</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.07.19</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B62D 57/032</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 로봇(100)을 위한 방법(500)은 로봇 주위의 환경(10) 내의 공간에 대한 센서 데이터(134)의 3차원 포인트 클라우드를 수신하는 단계를 포함한다. 상기 방법은 공간에 대응하는 이미지(300)에 표현된 목표 물체의 사용자 선택을 나타내는 선택 입력을 수신하는 단계를 포함한다. 목표 물체는 로봇 매니퓰레이터(126)의 엔드 이펙터(150)에 의해 파지하기 위한 것이다. 상기 방법은 이미지의 선택된 목표 물체로부터 복수의 광선들(218)을 센서 데이터의 3차원 포인트 클라우드 상으로 투사함으로써 로봇 매니퓰레이터의 엔드 이펙터에 대한 파지 영역(216)을 생성하는 단계를 포함한다. 상기 방법은 로봇 매니퓰레이터가 파지 영역 내의 목표 물체를 파지하기 위한 파지 지오메트리(212)를 결정하는 단계를 포함한다. 상기 방법은 파지 지오메트리에 기초하여 파지 영역 내의 목표 물체를 파지하도록 로봇 매니퓰레이터의 엔드 이펙터에 명령하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.06.30</internationOpenDate><internationOpenNumber>WO2022140190</internationOpenNumber><internationalApplicationDate>2021.12.17</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/064105</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 로봇(robot)(100)의 데이터 처리 하드웨어(data processing hardware)(142)에 의해 실행될 때 상기 데이터 처리 하드웨어(142)가 동작들을 수행하게 하는, 컴퓨터 구현 방법(500)으로서,상기 동작들은,상기 로봇(100) 주위의 환경(10) 내의 공간에 대한 센서 데이터(sensor data)(134)의 3차원 포인트 클라우드(three-dimensional point cloud)를 수신하는 동작;상기 공간에 대응하는 이미지(300)에 표현된 목표 물체의 사용자 선택을 나타내는 선택 입력을 수신하는 동작 — 상기 목표 물체는 상기 로봇(100)의 로봇 매니퓰레이터(robotic manipulator)(126)의 엔드 이펙터(end-effector)(128H, 150)에 의해 파지하기 위한 것임 —;상기 이미지(300)의 선택된 목표 물체로부터 복수의 광선들(218)을 상기 센서 데이터(134)의 3차원 포인트 클라우드 상으로 투사함으로써 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 대한 파지 영역(216)을 생성하는 동작;상기 로봇 매니퓰레이터(126)가 상기 파지 영역(216) 내의 목표 물체를 파지하기 위한 파지 지오메트리(grasp geometry)(212)를 결정하는 동작; 및상기 파지 지오메트리(212)에 기초하여 상기 파지 영역(216) 내의 목표 물체를 파지하도록 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 명령하는 동작을 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 로봇 매니퓰레이터(126)가 상기 파지 영역(216) 내의 상기 목표 물체를 파지하기 위한 상기 파지 지오메트리(212)를 결정하는 동작은,상기 파지 영역(216) 내의 목표 물체에 기초하여 복수의 후보 파지 지오메트리들(212)을 생성하는 동작;상기 복수의 후보 파지 지오메트리들(212)의 각각의 후보 파지 지오메트리(212)에 대해, 상기 목표 물체를 파지하기 위한 파지 스코어(grasping score)(242)를 결정하는 동작 — 상기 파지 스코어(242)는 개개의 후보 파지 지오메트리(212)에 기초하여 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)를 사용하여 상기 목표 물체를 파지할 성공 가능성을 나타냄 —;상기 목표 물체를 파지하도록 지정된 초기 파지 지오메트리(212I)로서 최대의 파지 스코어(242)를 갖는 개개의 후보 파지 지오메트리(212)를 선택하는 동작 — 상기 초기 파지 지오메트리(212I)는 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 대한 초기 포즈(pose)에 기초함 —을 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,상기 동작들은,상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)의 제2 포즈에 대한 업데이트된 센서 데이터(134U)를 수신하는 동작; 업데이트된 센서 데이터(134U)에 기초하여 새로운 세트의 후보 파지 지오메트리들(212N)을 결정하는 동작 — 상기 새로운 세트의 후보 파지 지오메트리들(212N)의 각각의 후보 파지 지오메트리(212N)는 개개의 파지 스코어(242)를 포함함 —;상기 새로운 세트의 후보 파지 지오메트리들(212N)로부터의 개개의 후보 파지 지오메트리(212N)가 상기 초기 파지 지오메트리(212I)의 파지 스코어(242)를 초과하는 대응하는 파지 스코어(242)를 포함한다고 결정하는 동작; 및상기 새로운 세트의 후보 파지 지오메트리들(212N)로부터의 개개의 후보 파지 지오메트리(212N)에 기초하여 상기 초기 파지 지오메트리(212I)를 수정하는 동작을 더 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1 항 내지 제3 항 중 어느 한 항에 있어서,상기 동작들은 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)가 상기 목표 물체를 파지하기 위한 하나 이상의 자유도들을 제약하는 엔드 이펙터 제약조건을 수신하는 동작을 더 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항 내지 제4 항 중 어느 한 항에 있어서,상기 공간에 대응하는 상기 이미지(300)에 표현된 상기 목표 물체는 머신 러닝 알고리즘(machine learning algorithm)에 의해 분류된 물체에 대응하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제1 항 내지 제5 항 중 어느 한 항에 있어서,상기 동작들은,상기 공간에 대응하는 상기 이미지(300)를 수신하는 동작; 및머신 러닝 물체 분류 알고리즘(machine learning object classification algorithm)을 사용하여 수신된 이미지(300) 내에서 파지 가능한 물체들을 분류하는 동작을 더 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1 항 내지 제6 항 중 어느 한 항에 있어서,상기 파지 지오메트리(212)에 기초하여 상기 파지 영역(216) 내의 목표 물체를 파지하도록 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 명령하는 동작은,상기 목표 물체를 향해 피칭(pitching)하도록 상기 로봇(100)의 몸체(110)에 명령하는 동작; 또는상기 로봇(100)의 제1 다리(120)의 상부 부재(122U)를 무릎 관절(JK)을 중심으로 상기 제1 다리(120)의 하부 부재(122L)를 향해 회전시키도록 상기 로봇(100)의 제1 다리(120)에 명령하는 동작을 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1 항 내지 제7 항 중 어느 한 항에 있어서,상기 공간에 대응하는 상기 이미지(300)에 표현된 상기 목표 물체를 선택하는 상기 선택 입력을 수신하는 동작은 상기 로봇(100)의 데이터 처리 하드웨어(142)와 원격 통신하는 사용자 디바이스(20)에서 일어나는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 한 항에 있어서,상기 동작들은,상기 공간에 대응하는 상기 이미지(300)를 수신하는 동작; 및수신된 이미지(300)를 보정하는 동작을 더 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 한 항에 있어서,상기 엔드 이펙터(128H, 150)는 가동 죠(movable jaw) 및 고정 죠(fixed jaw)를 갖는 그리퍼(gripper)(128H, 150)를 포함하며, 상기 가동 죠는 상기 그리퍼(128H, 150)의 개방 포지션과 상기 그리퍼(128H, 150)의 폐쇄 포지션 사이에서 이동하기 위해 상기 고정 죠에 대해 이동하도록 구성되는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제1 항 내지 제10 항 중 어느 한 항에 있어서,상기 로봇 매니퓰레이터(126)는 상기 로봇(100) 주위의 환경(10) 내의 공간에 대한 상기 3차원 포인트 클라우드를 규정하는 상기 센서 데이터(134)를 캡처하도록 상기 엔드 이펙터(128H, 150)에 또는 그 근처에 장착된 하나 이상의 센서들(130, 130c)을 포함하는,컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 로봇(100)으로서,몸체(110);상기 몸체(110)에 결합된 복수의 다리들(120);상기 몸체(110)에 결합된 로봇 매니퓰레이터(126) — 상기 로봇 매니퓰레이터(126)는 상기 로봇(100) 주위의 환경(10) 내의 물체들을 파지하도록 구성된 엔드 이펙터(128H, 150)를 포함함 —;상기 로봇 매니퓰레이터(126)와 통신하는 데이터 처리 하드웨어(142); 및상기 데이터 처리 하드웨어(142)와 통신하는 메모리 하드웨어(memory hardware)(144, 164)를 포함하며, 상기 메모리 하드웨어(144, 164)는 상기 데이터 처리 하드웨어(142)에서 실행될 때 상기 데이터 처리 하드웨어(142)가 동작들을 수행하게 하는 명령들을 저장하고, 상기 동작들은,상기 로봇(100) 주위의 환경(10) 내의 공간에 대한 센서 데이터(134)의 3차원 포인트 클라우드를 수신하는 동작;상기 로봇(100)의 사용자로부터, 상기 공간에 대응하는 이미지(300)에 표현된 목표 물체의 사용자 선택을 나타내는 선택 입력을 수신하는 동작 — 상기 목표 물체는 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 의해 파지하기 위한 것임 —;상기 이미지(300)의 선택된 목표 물체로부터 복수의 광선(218)을 상기 센서 데이터의 3차원 포인트 클라우드(134) 상으로 투사함으로써 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 대한 파지 영역(216)을 생성하는 동작;상기 로봇 매니퓰레이터(126)가 상기 파지 영역(216) 내의 목표 물체를 파지하기 위한 파지 지오메트리(212)를 결정하는 동작; 및상기 파지 지오메트리(212)에 기초하여 상기 파지 영역(216) 내의 목표 물체를 파지하도록 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 명령하는 동작을 포함하는,로봇.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 로봇 매니퓰레이터(126)가 상기 파지 영역(216) 내의 상기 목표 물체를 파지하기 위한 상기 파지 지오메트리(212)를 결정하는 동작은,상기 파지 영역(216) 내의 목표 물체에 기초하여 복수의 후보 파지 지오메트리들(212)을 생성하는 동작;상기 복수의 후보 파지 지오메트리들(212)의 각각의 후보 파지 지오메트리(212)에 대해, 상기 목표 물체를 파지하기 위한 파지 스코어(242)를 결정하는 동작 — 상기 파지 스코어(242)는 개개의 후보 파지 지오메트리(212)에 기초하여 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)를 사용하여 상기 목표 물체를 파지할 성공 가능성을 나타냄 —;상기 목표 물체를 파지하도록 지정된 초기 파지 지오메트리(212I)로서 최대의 파지 스코어(242)를 갖는 개개의 후보 파지 지오메트리(212)를 선택하는 동작 — 상기 초기 파지 지오메트리(212I)는 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 대한 초기 포즈에 기초함 —을 포함하는,로봇.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 동작들은,상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)의 제2 포즈에 대한 업데이트된 센서 데이터(134U)를 수신하는 동작; 업데이트된 센서 데이터(134U)에 기초하여 새로운 세트의 후보 파지 지오메트리들(212N)을 결정하는 동작 — 상기 새로운 세트의 후보 파지 지오메트리들(212N)의 각각의 후보 파지 지오메트리(212N)는 개개의 파지 스코어(242)를 포함함 —;상기 새로운 세트의 후보 파지 지오메트리들(212N)로부터의 개개의 후보 파지 지오메트리(212N)가 상기 초기 파지 지오메트리(212I)의 파지 스코어(242)를 초과하는 대응하는 파지 스코어(242)를 포함한다고 결정하는 동작; 및상기 새로운 세트의 후보 파지 지오메트리들(212N)로부터의 개개의 후보 파지 지오메트리(212N)에 기초하여 상기 초기 파지 지오메트리(212I)를 수정하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>15. 제12 항 내지 제14 항 중 어느 한 항에 있어서,상기 동작들은 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)가 상기 목표 물체를 파지하기 위한 하나 이상의 자유도들을 제약하는 엔드 이펙터 제약조건을 수신하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>16. 제12 항 내지 제15 항 중 어느 한 항에 있어서,상기 공간에 대응하는 상기 이미지(300)에 표현된 상기 목표 물체는 머신 러닝 알고리즘에 의해 분류된 물체에 대응하는,로봇.</claim></claimInfo><claimInfo><claim>17. 제12 항 내지 제16 항 중 어느 한 항에 있어서,상기 동작들은,상기 공간에 대응하는 상기 이미지(300)를 수신하는 동작; 및머신 러닝 물체 분류 알고리즘을 사용하여 수신된 이미지(300) 내에서 파지 가능한 물체들을 분류하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>18. 제12 항 내지 제17 항 중 어느 한 항에 있어서,상기 파지 지오메트리(212)에 기초하여 상기 파지 영역(216) 내의 목표 물체를 파지하도록 상기 로봇 매니퓰레이터(126)의 엔드 이펙터(128H, 150)에 명령하는 동작은,상기 목표 물체를 향해 피칭하도록 상기 로봇(100)의 몸체(110)에 명령하는 동작; 또는상기 로봇(100)의 제1 다리(120)의 상부 부재(122U)를 무릎 관절(JK)을 중심으로 상기 제1 다리(120)의 하부 부재(122L)를 향해 회전시키도록 상기 로봇(100)의 제1 다리(120)에 명령하는 동작을 포함하는,로봇.</claim></claimInfo><claimInfo><claim>19. 제12 항 내지 제18 항 중 어느 한 항에 있어서,상기 공간에 대응하는 상기 이미지(300)에 표현된 상기 목표 물체를 선택하는 상기 선택 입력을 수신하는 동작은 상기 로봇(100)의 데이터 처리 하드웨어(142)와 원격 통신하는 사용자 디바이스(20)에서 일어나는,로봇.</claim></claimInfo><claimInfo><claim>20. 제12 항 내지 제19 항 중 어느 한 항에 있어서,상기 동작들은,상기 공간에 대응하는 상기 이미지(300)를 수신하는 동작; 및수신된 이미지(300)를 보정하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>21. 제12 항 내지 제20 항 중 어느 한 항에 있어서,상기 엔드 이펙터(128H, 150)는 가동 죠 및 고정 죠를 갖는 그리퍼(128H, 150)를 포함하며, 상기 가동 죠는 상기 그리퍼(128H, 150)의 개방 포지션과 상기 그리퍼(128H, 150)의 폐쇄 포지션 사이에서 이동하기 위해 상기 고정 죠에 대해 이동하도록 구성되는,로봇.</claim></claimInfo><claimInfo><claim>22. 제12 항 내지 제21 항 중 어느 한 항에 있어서,상기 로봇 매니퓰레이터(126)는 상기 로봇(100) 주위의 환경(10) 내의 공간에 대한 상기 3차원 포인트 클라우드를 규정하는 상기 센서 데이터(134)를 캡처하도록 상기 엔드 이펙터(128H, 150)에 또는 그 근처에 장착된 하나 이상의 센서들(130, 130c)을 포함하는,로봇.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매사추세츠주 월섬 스미스 스트리트 *** 유닛 ****</address><code>520200430545</code><country>미국</country><engName>Boston Dynamics, Inc.</engName><name>보스턴 다이나믹스, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 매사추세츠 ...</address><code> </code><country> </country><engName>BARRY, Andrew, James</engName><name>배리, 앤드류, 제임스</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠 ...</address><code> </code><country> </country><engName>RIZZI, Alfred, Anthony</engName><name>리지, 알프레드, 앤서니</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 서소문로**(서소문동, 정안빌딩*층)</address><code>920121001826</code><country>대한민국</country><engName>NAM &amp; NAM</engName><name>특허법인 남앤남</name></agentInfo><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.12.21</priorityApplicationDate><priorityApplicationNumber>63/128,736</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.07.19</receiptDate><receiptNumber>1-1-2023-0794476-51</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.07.24</receiptDate><receiptNumber>1-5-2023-0118153-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.03.13</receiptDate><receiptNumber>1-1-2024-0281102-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.12.12</receiptDate><receiptNumber>1-1-2024-1377585-73</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.06.13</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237024700.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93868d186cba78672bb59af9ec069a2e2d0316c13b9ed3497da898c56df9f2b79d26236dca01acf37209d42eddbdd05f1646e230b20cf65c58</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0e55142fb8810c478f7765864f18f8b15dab8af98adf55efddcc934c17cb16946b3b907ccc92ab1c946ecc97efda96619c0947a31e38bf3b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>