<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:23:16.2316</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7010155</applicationNumber><claimCount>36</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>멀티 모드 입력을 사용하여 인터렉티브 에이전트 제어</inventionTitle><inventionTitleEng>CONTROLLING INTERACTIVE AGENTS USING MULTI-MODAL INPUTS</inventionTitleEng><openDate>2024.05.02</openDate><openNumber>10-2024-0057422</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.03.26</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0499</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/047</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/092</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 13/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 에이전트를 제어하기 위한 컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램을 포함하는 방법, 시스템 및 장치이다. 특히, 관찰 이미지와 자연어 텍스트 시퀀스를 모두 포함하는 멀티 모드 입력에 기초하여 인터렉티브 에이전트를 제어할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.06.15</internationOpenDate><internationOpenNumber>WO2023104880</internationOpenNumber><internationalApplicationDate>2022.12.07</internationalApplicationDate><internationalApplicationNumber>PCT/EP2022/084780</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 컴퓨터에 의해 수행되고 환경과 인터렉션하는 에이전트를 제어하기 위한 방법으로서, 복수의 시간 단계들 각각에서:상기 시간 단계에 환경의 상태를 나타내는 관찰 이미지를 수신하는 단계;상기 시간 단계에 환경에서 에이전트에 의해 수행되는 작업을 나타내는 상기 시간 단계에 대한 자연어 텍스트 시퀀스를 수신하는 단계;상기 관찰 이미지를 나타내는 복수의 이미지 임베딩들을 생성하기 위해 이미지 임베딩 신경 네트워크를 사용하여 상기 관찰 이미지를 프로세싱하는 단계;상기 자연어 텍스트 시퀀스를 나타내는 복수의 텍스트 임베딩들을 생성하기 위해 텍스트 임베딩 신경 네트워크를 사용하여 자연어 텍스트 시퀀스를 프로세싱하는 단계;집합 임베딩을 생성하기 위해 멀티 모드 트랜스포머 신경 네트워크를 사용하여 상기 이미지 임베딩 및 상기 텍스트 임베딩을 포함하는 입력을 프로세싱하는 단계, 상기 멀티 모드 트랜스포머 신경 네트워크는 (i) 적어도 상기 복수의 텍스트 임베딩들에 대해 각각의 업데이트 임베딩을 생성하기 위해 적어도 상기 텍스트 임베딩 및 상기 이미지 임베딩에 대해 셀프 어텐션을 적용하고 (ii) 상기 텍스트 임베딩에 대한 적어도 각각의 업데이트 임베딩으로부터 상기 집합 임베딩을 생성하도록 구성되며;상기 집합 임베딩을 사용하여, 관찰 이미지에 응답하여 에이전트에 의해 수행될 하나 이상의 액션을 선택하는 단계; 및상기 에이전트가 하나 이상의 선택된 액션을 수행하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서, 상기 멀티 모드 트랜스포머 신경 네트워크는 각각 하나 이상의 셀프 어텐션 헤드를 갖는 하나 이상의 셀프 어텐션 레이어를 포함하고, 상기 셀프 어텐션을 적용하는 것은 하나 이상의 셀프 어텐션 레이어를 통해 입력을 프로세싱하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 청구항 2에 있어서, 상기 멀티 모드 트랜스포머 신경 네트워크에 대한 입력은 상기 이미지 임베딩, 상기 텍스트 임베딩 및 하나 이상의 전용 임베딩을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 3에 있어서, 상기 셀프 어텐션을 적용하는 것은 상기 이미지 임베딩을 업데이트하지 않고, 상기 텍스트 임베딩과 상기 전용 임베딩에 대해 각각 업데이트 임베딩을 생성하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 3 또는 4에 있어서, 각 셀프 어텐션 레이어의 각 셀프 어텐션 헤드는:(i) 상기 이미지 임베딩 신경 네트워크에 의해 생성된 상기 이미지 임베딩 및 (ii) 상기 텍스트 임베딩 및 상기 전용 임베딩에 대한 각각의 현재 임베딩을 포함하는 헤드 입력을 수신하고;상기 각각의 현재 임베딩으로부터, 각각의 텍스트 임베딩 및 각각의 전용 임베딩에 대응하는 각각의 쿼리를 생성하고;상기 이미지 임베딩과 상기 각각의 현재 임베딩으로부터, 각 이미지 임베딩, 각 텍스트 임베딩, 각 전용 임베딩에 대응하는 각각의 키를 생성하고;상기 이미지 임베딩과 상기 각각의 현재 임베딩으로부터, 각 이미지 임베딩, 각 텍스트 임베딩, 각 전용 임베딩에 대응하는 각각의 값을 생성하고; 그리고상기 이미지 임베딩을 업데이트하지 않고 각 텍스트 임베딩 및 각 전용 임베딩에 대한 각각의 초기 업데이트 임베딩을 생성하기 위해 상기 각각의 쿼리, 키 및 값에 대해 쿼리-키-값 어텐션을 적용하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 3 내지 5 중 어느 한 항에 있어서, 상기 집합 임베딩을 생성하는 것은:초기 집합 임베딩을 생성하기 위해 상기 텍스트 임베딩과 상기 전용 임베딩에 대한 상기 각각의 업데이트 임베딩을 집합시키는 것; 및상기 집합 임베딩을 생성하기 위해 상기 전용 임베딩에 대한 각각의 업데이트 임베딩을 초기 집합 임베딩과 결합하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 6에 있어서, 상기 결합은 각각의 전용 임베딩에 대한 각각의 업데이트 임베딩과 상기 초기 통합 임베딩을 연결하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 임의의 선행하는 청구항에 있어서, 상기 집합 임베딩을 사용하여, 관찰 이미지에 응답하여 에이전트에 의해 수행될 하나 이상의 액션을 선택하는 단계는:상기 집합 임베딩으로부터 상태 표현을 생성하는 단계; 및상기 상태 표현을 사용하여 하나 이상의 액션을 선택하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 8에 있어서, 상기 상태 표현을 생성하는 단계는 메모리 신경 네트워크를 사용하여 집합 임베딩을 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 9에 있어서, 상기 메모리 신경 네트워크는 순환 신경 네트워크인, 방법.</claim></claimInfo><claimInfo><claim>11. 청구항 8 내지 14 중 어느 한 항에 있어서,상기 시간 단계에 대한 출력 텍스트 시퀀스를 생성하기 위해 자연어 생성 신경 네트워크를 사용하여 상태 표현을 프로세싱하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 청구항 11에 있어서, 상기 자연어 텍스트 시퀀스는 상기 환경 내의 다른 에이전트로부터 음성화된 발화를 전사함으로써 생성되고, 상기 방법은:상기 시간 단계에 대한 상기 출력 텍스트 시퀀스를 나타내는 스피치를 생성하는 단계; 및상기 에이전트가 상기 생성된 스피치를 말로 표현하게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 청구항 11 또는 12 중 어느 한 항에 있어서,텍스트가 상기 시간 단계에서 생성되어야 하는지 여부에 대한 표시를 생성하기 위해 텍스트 무작동(no-op) 신경 네트워크를 사용하여 상기 상태 표현을 프로세싱하는 단계; 및상기 시간 단계에 대한 출력 텍스트 시퀀스를 생성하기 위해 자연어 생성 신경 네트워크를 사용하여 상기 시간 단계에 대한 상기 상태 표현을 프로세싱하는 단계는:상기 표시가 상기 시간 단계에서 텍스트가 생성되어야 함을 나타내는 경우에만 상기 출력 텍스트 시퀀스를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 청구항 8 내지 13에 있어서, 상기 상태 표현을 사용하여 상기 하나 이상의 액션을 선택하는 단계는:상기 이미지 관찰에 응답하여 수행될 단일 액션을 선택하기 위해 액션 정책 신경 네트워크를 사용하여 상기 상태 표현을 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 청구항 8 내지 14에 있어서, 상기 상태 표현을 사용하여 상기 하나 이상의 액션을 선택하는 단계는:상기 이미지 관찰에 응답하여 수행될 복수의 액션들의 시퀀스를 선택하기 위해 상기 상태 표현을 프로세싱하는 단계를 포함하며, 상기 시퀀스는 복수의 포지션들 각각에서의 개별 액션을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 청구항 15에 있어서, 상기 상태 표현을 프로세싱하는 단계는:상기 시퀀스의 각 포지션에 대한 각각의 하위 레벨 입력을 생성하기 위해 상위 레벨 컨트롤러 신경 네트워크를 사용하여 상기 상태 표현을 프로세싱하는 단계; 및각 포지션에 대해, 상기 시퀀스의 상기 포지션에서 상기 에이전트에 의해 수행될 액션을 선택하기 위해 정책 신경 네트워크를 사용하여 상기 포지션에 대한 각각의 하위 레벨 입력을 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 청구항 16에 있어서, 상기 상위 레벨 컨트롤러 신경 네트워크는 상기 상태 표현을 입력으로 수신한 후 상기 시퀀스의 각 포지션에 대해 각각의 하위 레벨 입력을 자동 회귀적으로 생성하는, 방법.</claim></claimInfo><claimInfo><claim>18. 청구항 17에 있어서, 상기 상위 레벨 컨트롤러 신경 네트워크는 순환 신경 네트워크인, 방법.</claim></claimInfo><claimInfo><claim>19. 청구항 8 내지 18 중 어느 한 항에 있어서,임의의 액션이 상기 시간 단계에서 수행되어야 하는지 여부에 대한 표시를 생성하기 위해 액션 무작동(no-op) 신경 네트워크를 사용하여 상기 상태 표현을 프로세싱하는 단계를 더 포함하며; 그리고상기 에이전트가 하나 이상의 선택된 액션을 수행하게 하는 단계는:상기 표시가 액션이 상기 시간 단계에서 수행되어야 한다고 나타낼 때만 상기 에이전트가 액션을 수행하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 임의의 선행하는 청구항에 있어서, 상기 자연어 텍스트 시퀀스는 상기 환경 내의 다른 에이전트로부터 음성화된 발화를 전사함으로써 생성되는, 방법.</claim></claimInfo><claimInfo><claim>21. 하나 이상의 컴퓨터에 의해 수행되고 환경과 인터렉션하는 에이전트를 제어하기 위한 방법으로서, 복수의 시간 단계들 각각에서:상기 시간 단계에 환경의 상태를 나타내는 상기 시간 단계에 대한 관찰 이미지를 수신하는 단계;상기 시간 단계에 환경에서 에이전트에 의해 수행되는 작업을 나타내는 상기 시간 단계에 대한 자연어 텍스트 시퀀스를 수신하는 단계;상기 시간 단계에 대한 상태 표현을 생성하기 위해 상기 관찰 이미지 및 상기 자연어 텍스트 시퀀스를 프로세싱하는 단계;상기 시간 단계에서 상기 관찰 이미지에 응답하여, 상기 에이전트에 의해 수행될 복수의 액션들의 시퀀스를 생성하는 단계, 상기 시퀀스는 복수의 포지션들 각각에서 상기 에이전트에 의해 수행될 각각의 액션을 포함하고, 상기 생성하는 단계는: 상기 시퀀스의 각 포지션에 대한 각각의 하위 레벨 입력을 생성하기 위해 상위 레벨 컨트롤러 신경 네트워크를 사용하여 상기 상태 표현을 프로세싱하는 단계; 및 각 포지션에 대해, 상기 시퀀스의 상기 포지션에서 상기 에이전트에 의해 수행될 액션을 생성하기 위해 액션 정책 신경 네트워크를 사용하여 상기 포지션에 대한 각각의 하위 레벨 입력을 프로세싱하는 단계; 및상기 에이전트가 액션들의 시퀀스를 수행하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>22. 청구항 21에 있어서,상기 시간 단계에 대한 출력 텍스트 시퀀스를 생성하기 위해 자연어 생성 신경 네트워크를 사용하여 상기 시간 단계에 대한 상기 상태 표현을 프로세싱하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 청구항 22에 있어서, 상기 자연어 텍스트 시퀀스는 상기 환경 내의 다른 에이전트로부터 음성화된 발화를 전사함으로써 생성되고, 상기 방법은:상기 시간 단계에 대한 상기 출력 텍스트 시퀀스를 나타내는 스피치를 생성하는 단계; 및상기 에이전트가 상기 생성된 스피치를 말로 표현하게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 청구항 22 또는 23 중 어느 한 항에 있어서,텍스트가 상기 시간 단계에서 생성되어야 하는지 여부에 대한 표시를 생성하기 위해 텍스트 무작동(no-op) 신경 네트워크를 사용하여 상기 상태 표현을 프로세싱하는 단계; 및상기 시간 단계에 대한 출력 텍스트 시퀀스를 생성하기 위해 자연어 생성 신경 네트워크를 사용하여 상기 시간 단계에 대한 상기 상태 표현을 프로세싱하는 단계는:상기 표시가 상기 시간 단계에서 텍스트가 생성되어야 함을 나타내는 경우에만 상기 출력 텍스트 시퀀스를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>25. 청구항 21 내지 24 중 어느 한 항에 있어서,임의의 액션이 상기 시간 단계에서 수행되어야 하는지 여부에 대한 표시를 생성하기 위해 액션 무작동(no-op) 신경 네트워크를 사용하여 상기 상태 표현을 프로세싱하는 단계를 더 포함하며; 그리고상기 에이전트가 액션들의 시퀀스를 수행하게 하는 단계는:상기 표시가 액션이 상기 시간 단계에서 수행되어야 한다고 나타낼 때만 상기 에이전트가 액션들의 시퀀스를 수행하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 청구항 21 내지 25 중 어느 한 항에 있어서, 상기 상위 레벨 컨트롤러 신경 네트워크는 상기 상태 표현을 입력으로 수신한 후 상기 시퀀스의 각 포지션에 대해 각각의 하위 레벨 입력을 자동 회귀적으로 생성하는, 방법.</claim></claimInfo><claimInfo><claim>27. 청구항 21 내지 26 중 어느 한 항에 있어서, 상기 액션 정책 신경 네트워크는 복수의 서브 액션들 각각에 대한 각각의 서브 네트워크를 포함하고, 상기 시퀀스의 상기 포지션에서 상기 에이전트에 의해 수행될 액션을 생성하기 위해 액션 정책 신경 네트워크를 사용하여 상기 포지션에 대한 각각의 하위 레벨 입력을 프로세싱하는 단계는:상기 복수의 서브 액션들 각각에 대해, 상기 포지션에 대한 서브 액션에 대한 값을 선택하기 위해 서브 액션에 대한 서브 네트워크를 사용하여 포지션에 대한 각각의 하위 레벨 입력을 포함하는 입력을 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>28. 청구항 27에 있어서, 상기 서브 액션 중 적어도 하나에 대해, 상기 입력은 상기 포지션에서 다른 서브 액션 중 하나 이상에 대해 선택된 값을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>29. 시간 단계에서 환경의 상태를 나타내는 관찰 이미지와 환경을 나타내는 자연어 텍스트 시퀀스를 입력으로 수신하고, 상기 시간 단계에 대해 인코딩된 표현을 출력으로 생성하도록 구성된 지각 인코더(perceptual encoder) 신경 네트워크를 트레이닝하는 방법에 있어서,복수의 트레이닝 쌍을 획득하는 단계, 상기 복수의 트레이닝 쌍은: (i) 동일한 시간 단계에 대응하는 관찰 이미지와 자연어 텍스트 시퀀스를 포함하는 제1 쌍, 및 (ii) 서로 다른 시간 단계에 대응하는 관찰 이미지와 자연어 텍스트 시퀀스를 각각 포함하는 하나 이상의 제2 쌍을 포함하며;각 트레이닝 쌍에 대한 각각의 인코딩된 표현을 생성하기 위해 지각 인코더 신경 네트워크를 사용하여 각 트레이닝 쌍을 프로세싱하는 단계;각각의 트레이닝 쌍에 대해, 상기 인코딩된 표현이 생성된 상기 쌍에서 상기 관찰 이미지와 상기 자연어 텍스트 시퀀스가 동일한 시간 단계에 대응할 가능성을 나타내는 각각의 판별자 점수를 생성하기 위해 각각의 인코딩된 표현을 프로세싱하도록 구성된 판별자 신경 네트워크를 사용하여 각각의 트레이닝 쌍에 대한 각각의 인코딩된 표현을 프로세싱하는 단계; 및각 트레이닝 쌍에 대한 각각의 판별자 점수에 기초하여 대조 학습 손실을 사용하여 상기 지각 인코더 신경 네트워크를 트레이닝하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>30. 청구항 29에 있어서, 상기 지각 인코더 신경 네트워크는 청구항 1 내지 28 중 어느 한 항의 텍스트 임베딩 신경 네트워크, 이미지 임베딩 신경 네트워크, 멀티 모드 트랜스포머 신경 네트워크를 포함하고, 상기 인코딩된 표현은 멀티 모드 트랜스포머 신경 네트워크에 의해 생성된 집합 임베딩인, 방법.</claim></claimInfo><claimInfo><claim>31. 청구항 29 또는 30에 있어서, 상기 대조 학습 손실은 제1 쌍에 대한 각각의 판별자 점수는 더 높아지게 하고, 제2 쌍에 대한 각각의 판별자 점수는 더 낮아지게 하는, 방법.</claim></claimInfo><claimInfo><claim>32. 청구항 29 내지 31 중 어느 한 항에 있어서, 상기 판별자 신경 네트워크는 대응하는 트레이닝 쌍에 대한 각각의 판별자 점수를 생성하기 위해 각각의 인코딩된 표현을 독립적으로 프로세싱하는 피드포워드 신경 네트워크인, 방법.</claim></claimInfo><claimInfo><claim>33. 청구항 29 내지 32 중 어느 한 항에 있어서,상기 제1 트레이닝 쌍에 대한 인코딩된 표현으로부터, 적어도 정책 신경 네트워크를 사용하여, 액션 시퀀스의 하나 이상의 포지션 각각에 대한 액션 세트에 대해 각각의 확률 분포를 생성하는 단계;상기 하나 이상의 포지션 각각에서 전문가 에이전트에 의해 수행되는 각각의 실측 액션을 지정하는 데이터를 획득하는 단계; 및상기 액션 시퀀스의 각 포지션에 대해 상기 포지션에 대한 확률 분포에 의해 상기 포지션에서 실측 액션에 할당된 확률을 측정하는 행동 복제 손실에 기초하여 적어도 상기 정책 신경 네트워크 및 상기 지각 인코더 신경 네트워크를 트레이닝하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>34. 청구항 29 내지 33 중 어느 한 항에 있어서, 상기 제1 트레이닝 쌍에 대해, 상기 제1 트레이닝 쌍에 대한 각각의 판별자 점수와 상기 쌍에서 상기 관찰 이미지 및 상기 텍스트 시퀀스가 동일한 시간 단계에 대응한다고 표시하는 제1 점수 사이의 오류 및 상기 각각의 제2 트레이닝 쌍에 대해, 상기 제2 트레이닝 쌍에 대한 각각의 판별자 점수와 상기 쌍에서 상기 관찰 이미지 및 상기 텍스트 시퀀스가 동일한 시간 단계에 대응하지 않는다고 표시하는 제2 점수 사이의 오류를 측정하는 목적 함수에 대해 상기 판별자 신경 네트워크를 트레이닝하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>35. 하나 이상의 컴퓨터와 명령어가 저장된 하나 이상의 저장 디바이스를 포함하는 시스템으로서, 상기 명령어는 하나 이상의 컴퓨터에 의해 실행될 때, 상기 하나 이상의 컴퓨터로 하여금 청구항 1 내지 34 중 어느 한 항의 각각의 방법의 동작을 수행하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>36. 명령어가 저장된 하나 이상의 컴퓨터 저장 매체로서, 상기 명령어는 하나 이상의 컴퓨터에 의해 실행될 때, 상기 하나 이상의 컴퓨터로 하여금 청구항 1 내지 34 중 어느 한 항의 각각의 방법의 동작을 수행하게 하는, 하나 이상의 컴퓨터 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>영국 런던 이씨*에이 *티더블유 뉴 스트리트 스퀘어 *</address><code>520170032411</code><country>영국</country><engName>DeepMind Technologies Limited</engName><name>딥마인드 테크놀로지스 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>ABRAMSON, Joshua Simon</engName><name>아브람슨 조슈아 시몬</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>AHUJA, Arun</engName><name>아후자 아런</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>CARNEVALE, Federico Javier</engName><name>카네발 페더리코 자비에</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>GEORGIEV, Petko Ivanov</engName><name>조지브 페트코 이바노브</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>HUNG, Chia-Chun</engName><name>헝 치아 춘</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>LILLICRAP, Timothy Paul</engName><name>릴리크랩 티모시 폴</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>MULDAL, Alistair Michael</engName><name>멀달 앨리스테어 마이클</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>SANTORO, Adam Anthony</engName><name>산토로 아담 안토니</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>VON GLEHN, Tamara Louise</engName><name>본 글렌 타마라 루이스</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>LANDON, Jessica Paige</engName><name>란돈 제시카 페이지</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>WAYNE, Gregory Duncan</engName><name>웨인 그레고리 던칸</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country> </country><engName>YAN, Chen</engName><name>얀 첸</name></inventorInfo><inventorInfo><address>캐나다 앨버타주 티*제이 *비* 에드...</address><code> </code><country> </country><engName>ZHU, Rui</engName><name>주 루이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.07</priorityApplicationDate><priorityApplicationNumber>63/286,999</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.03.26</receiptDate><receiptNumber>1-1-2024-0338745-00</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.03.29</receiptDate><receiptNumber>1-5-2024-0054802-14</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247010155.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9355b1c9ef5e4edb14fbd6f4c09eb1eb627471df77f232b637b8ff17eb33393965cab6cf72ff1ad4275649e969b5ba1466931d8119ec2cb28d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf468f609106abddb262c32456cdc56a5fbb91c9d2eee8df86ebb446e1064d7e8e08702a77b5828cf3fab8ac072d07aa5d0473d7530e07ba2f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>