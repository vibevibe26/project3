<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:48.148</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7014393</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>프라이빗 미러 디센트(Private Mirror Descent)를 사용하여 신경 네트워크 트레이닝에서 퍼블릭 데이터 활용하기</inventionTitle><inventionTitleEng>LEVERAGING PUBLIC DATA IN TRAINING NEURAL NETWORKS WITH PRIVATE MIRROR DESCENT</inventionTitleEng><openDate>2024.06.21</openDate><openNumber>10-2024-0090278</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.04.29</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/098</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법(300)은 대응하는 프라이빗 데이터(private data)(139) 프로세싱에 기초하여 각각 생성된 차등 프라이빗(DP, differentially private) 그래디언트(gradient)들(143)의 세트를 획득하는 동작, 및 대응하는 퍼블릭 데이터(160) 프로세싱에 기초하여 각각 생성된 퍼블릭 그래디언트들의 세트(117)를 획득하는 동작을 포함한다. 방법은 또한 상기 DP 그래디언트들의 세트에 대한 지오메트리(215)를 학습하기 위해 퍼블릭 그래디언트들의 세트에 미러 디센트(mirror descent)를 적용하는 동작, 및 학습된 지오메트리에 기초하여 DP 그래디언트들의 세트를 재형성하는 동작을 포함한다. 상기 방법은 재형성된 DP 그래디언트들의 세트(225)에 기초하여 기계 학습 모델(150)을 트레이닝하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.04.13</internationOpenDate><internationOpenNumber>WO2023060055</internationOpenNumber><internationalApplicationDate>2022.10.04</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/077497</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 데이터 프로세싱 하드웨어(410)에서 실행될 때 상기 데이터 프로세싱 하드웨어(410)로 하여금 동작들을 수행하게 하는 컴퓨터로 구현되는 방법(300)으로서, 상기 동작들은:대응하는 프라이빗 데이터(private data)(139) 프로세싱에 기초하여 각각 생성된 차등 프라이빗(DP, differentially private) 그래디언트(gradient)들(143)의 세트를 획득하는 동작;대응하는 퍼블릭 데이터(160) 프로세싱에 기초하여 각각 생성된 퍼블릭 그래디언트들의 세트(117)를 획득하는 동작; 상기 DP 그래디언트(143)들의 세트에 대한 지오메트리(215)를 학습하기 위해 퍼블릭 그래디언트들(117)의 세트에 미러 디센트(mirror descent)를 적용하는 동작;학습된 지오메트리(215)에 기초하여 DP 그래디언트들(143)의 세트를 재형성하는 동작; 및재형성된 DP 그래디언트들의 세트(225)에 기초하여 기계 학습 모델(150)을 트레이닝하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서, DP 그래디언트들(143)의 세트의 각 DP 그래디언트(143)는:기계 학습 모델(135)을 사용하여, 대응하는 예측된 프라이빗 출력(141)을 생성하기 위해 대응하는 프라이빗 데이터(139)를 프로세싱하는 것; 상기 대응하는 예측된 프라이빗 출력(141) 및 대응하는 프라이빗 그라운드 트루스(private ground truth)(144)에 기초하여 프라이빗 손실 함수를 결정하는 것; 및DP 그래디언트(143)를 생성하기 위해 상기 프라이빗 손실 함수로부터 도출된 프라이빗 그래디언트에 노이즈를 추가하는 것에 의해 생성되는, 방법.</claim></claimInfo><claimInfo><claim>3. 청구항 2에 있어서, 상기 프라이빗 손실 함수는 볼록하고 L-Lipschitz인, 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 1 내지 3 중 어느 한 항에 있어서, 상기 프라이빗 데이터(139) 및 상기 퍼블릭 데이터(160)는 동일한 소스 분포로부터 도출되는, 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 1 내지 4 중 어느 한 항에 있어서, 퍼블릭 그래디언트들(117)의 세트의 각 퍼블릭 그래디언트(117)는:기계 학습 모델(150)을 사용하여, 대응하는 예측된 퍼블릭 출력(115)을 생성하기 위해 대응하는 퍼블릭 데이터(160)를 프로세싱하는 것; 대응하는 예측된 퍼블릭 출력(115) 및 대응하는 퍼블릭 그라운드 트루스(118)에 기초하여 퍼블릭 손실 함수를 결정하는 것; 및퍼블릭 손실 함수로부터 퍼블릭 그래디언트(117)를 도출하는 것에 의해 생성되는, 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 5에 있어서, DP 그래디언트들(143)의 세트에 대한 지오메트리(215)를 학습하기 위해 퍼블릭 그래디언트(117) 세트에 미러 디센트를 적용하는 동작은 DP 그래디언트들(143)의 세트에 대한 지오메트리(215)를 학습하기 위해 퍼블릭 손실 함수로부터 도출된 퍼블릭 그래디언트들(117)를 사용하여 미러 디센트를 미러 맵(mirror map)으로서 적용하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 5 또는 청구항 6에 있어서, 상기 퍼블릭 손실 함수는 강한 컨벡스(convex)인, 방법.</claim></claimInfo><claimInfo><claim>8. 청구항 1 내지 7 중 어느 한 항에 있어서,상기 데이터 프로세싱 하드웨어(410)는 중앙 서버에 상주하며; 그리고DP 그래디언트들(143)의 세트 및 퍼블릭 그래디언트들(117)의 세트는 상기 중앙 서버에 상주하는 중앙 저장소(119)에 저장되는, 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 1 내지 7 중 어느 한 항에 있어서,상기 데이터 프로세싱 하드웨어(410)는 원격 시스템에 상주하며;상기 DP 그래디언트들(143)의 세트를 획득하는 동작은 대응하는 프라이빗 데이터(139) 중 어느 것도 수신하지 않고 연합 학습을 통해 하나 이상의 클라이언트 디바이스(130)로부터 DP 그래디언트들(143)의 세트를 수신하는 것을 포함하며; 그리고DP 그래디언트들의(143) 세트의 각 DP 그래디언트(143)는 하나 이상의 클라이언트 디바이스(130) 중 각각의 클라이언트 디바이스에 로컬적으로 생성되는, 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 1 내지 9 중 어느 한 항에 있어서, 상기 기계 학습 모델(150)은 이미지 분류 모델을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 청구항 1 내지 9 중 어느 한 항에 있어서, 상기 기계 학습 모델(150)은 언어 모델을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 청구항 1 내지 9 중 어느 한 항에 있어서, 상기 기계 학습 모델(150)은 스피치 인식 모델을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 시스템으로서,데이터 프로세싱 하드웨어(410); 및상기 데이터 프로세싱 하드웨어(410)와 통신하는 메모리 하드웨어(420)를 포함하며, 상기 메모리 하드웨어(420)는 상기 데이터 프로세싱 하드웨어(410)에 의해 실행될 때 상기 데이터 프로세싱 하드웨어(410)로 하여금 동작들을 수행하게 하는 명령어들을 저장하며, 상기 동작들은:대응하는 프라이빗 데이터(private data)(139) 프로세싱에 기초하여 각각 생성된 차등 프라이빗(DP, differentially private) 그래디언트(gradient)들(143)의 세트를 획득하는 동작;대응하는 퍼블릭 데이터(160) 프로세싱에 기초하여 각각 생성된 퍼블릭 그래디언트들의 세트(117)를 획득하는 동작; 상기 DP 그래디언트(143)들의 세트에 대한 지오메트리(215)를 학습하기 위해 퍼블릭 그래디언트들(117)의 세트에 미러 디센트(mirror descent)를 적용하는 동작;학습된 지오메트리(215)에 기초하여 DP 그래디언트들(143)의 세트를 재형성하는 동작; 및재형성된 DP 그래디언트들의 세트(225)에 기초하여 기계 학습 모델(150)을 트레이닝하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>14. 청구항 13에 있어서, DP 그래디언트들(143)의 세트의 각 DP 그래디언트(143)는:기계 학습 모델(135)을 사용하여, 대응하는 예측된 프라이빗 출력(141)을 생성하기 위해 대응하는 프라이빗 데이터(139)를 프로세싱하는 것; 상기 대응하는 예측된 프라이빗 출력(141) 및 대응하는 프라이빗 그라운드 트루스(private ground truth)(144)에 기초하여 프라이빗 손실 함수를 결정하는 것; 및DP 그래디언트(143)를 생성하기 위해 상기 프라이빗 손실 함수로부터 도출된 프라이빗 그래디언트에 노이즈를 추가하는 것에 의해 생성되는, 시스템.</claim></claimInfo><claimInfo><claim>15. 청구항 14에 있어서, 상기 프라이빗 손실 함수는 볼록하고 L-Lipschitz인, 시스템.</claim></claimInfo><claimInfo><claim>16. 청구항 13 내지 15 중 어느 한 항에 있어서, 상기 프라이빗 데이터(139) 및 상기 퍼블릭 데이터(160)는 동일한 소스 분포로부터 도출되는, 시스템.</claim></claimInfo><claimInfo><claim>17. 청구항 13 내지 16 중 어느 한 항에 있어서, 퍼블릭 그래디언트들(117)의 세트의 각 퍼블릭 그래디언트(117)는:기계 학습 모델(150)을 사용하여, 대응하는 예측된 퍼블릭 출력(115)을 생성하기 위해 대응하는 퍼블릭 데이터(160)를 프로세싱하는 것; 대응하는 예측된 퍼블릭 출력(115) 및 대응하는 퍼블릭 그라운드 트루스(118)에 기초하여 퍼블릭 손실 함수를 결정하는 것; 및퍼블릭 손실 함수로부터 퍼블릭 그래디언트(117)를 도출하는 것에 의해 생성되는, 시스템.</claim></claimInfo><claimInfo><claim>18. 청구항 17에 있어서, DP 그래디언트들(143)의 세트에 대한 지오메트리(215)를 학습하기 위해 퍼블릭 그래디언트(117) 세트에 미러 디센트를 적용하는 동작은 DP 그래디언트들(143)의 세트에 대한 지오메트리(215)를 학습하기 위해 퍼블릭 손실 함수로부터 도출된 퍼블릭 그래디언트들(117)를 사용하여 미러 디센트를 미러 맵(mirror map)으로서 적용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 청구항 17 또는 청구항 18에 있어서, 상기 퍼블릭 손실 함수는 강한 컨벡스(convex)인, 시스템.</claim></claimInfo><claimInfo><claim>20. 청구항 13 내지 19 중 어느 한 항에 있어서,상기 데이터 프로세싱 하드웨어(410)는 중앙 서버에 상주하며; 그리고DP 그래디언트들(143)의 세트 및 퍼블릭 그래디언트들(117)의 세트는 상기 중앙 서버에 상주하는 중앙 저장소(119)에 저장되는, 시스템.</claim></claimInfo><claimInfo><claim>21. 청구항 13 내지 19 중 어느 한 항에 있어서,상기 데이터 프로세싱 하드웨어(410)는 원격 시스템에 상주하며;상기 DP 그래디언트들(143)의 세트를 획득하는 동작은 대응하는 프라이빗 데이터(139) 중 어느 것도 수신하지 않고 연합 학습을 통해 하나 이상의 클라이언트 디바이스(130)로부터 DP 그래디언트들(143)의 세트를 수신하는 것을 포함하며; 그리고DP 그래디언트들의(143) 세트의 각 DP 그래디언트(143)는 하나 이상의 클라이언트 디바이스(130) 중 각각의 클라이언트 디바이스에 로컬적으로 생성되는, 시스템.</claim></claimInfo><claimInfo><claim>22. 청구항 13 내지 21 중 어느 한 항에 있어서, 상기 기계 학습 모델(150)은 이미지 분류 모델을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>23. 청구항 13 내지 21 중 어느 한 항에 있어서, 상기 기계 학습 모델(150)은 언어 모델을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>24. 청구항 13 내지 21 중 어느 한 항에 있어서, 상기 기계 학습 모델(150)은 스피치 인식 모델을 포함하는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>THAKKAR, Om Dipakbhai</engName><name>타카르 옴 디파카이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>AMID, Ehsan</engName><name>아미드 이산</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>GANESH, Arun</engName><name>가네시 아런</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>MATHEWS, Rajiv</engName><name>매튜 라지브</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>RAMASWAMY, Swaroop</engName><name>라마스와미 스와루프</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SONG, Shuang</engName><name>송 수앙</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>STEINKE, Thomas</engName><name>스테인케 토마스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SURIYAKUMAR, Vinith</engName><name>수리야구마 비니스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>THAKURTA, Abhradeep Guha</engName><name>타쿠르타 아브라딥 구하</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.05</priorityApplicationDate><priorityApplicationNumber>63/262,129</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.04.29</receiptDate><receiptNumber>1-1-2024-0468316-97</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.05.01</receiptDate><receiptNumber>1-5-2024-0073256-85</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247014393.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930e3df87762206cf6e6e8ea84d1eab47859b5914b843b66b9dc04ce30b6b037b54bce967ba9d42d36feda63f54f53b5f815cc138e190b471a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2aeac9f833dc818394264d432bd4f77d1998035f1afc624bcf034c2e30090ca095b1ef29855286514f963c6b56ba2beac9138e89feb1c4c6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>