<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:26:56.2656</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.11.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0147215</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강현실 기능을 지원하는 전자 장치 및 이의 동작 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE SUPPORTING AUGMENTED REALITY  FUNCTION AND METHOD OF OPERATING THE SAME</inventionTitleEng><openDate>2024.04.04</openDate><openNumber>10-2024-0044289</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 다양한 실시예들은 증강현실 기능을 지원하는 전자 장치 및 이의 동작 방법에 관한 것으로, 적어도 하나의 센서 모듈로부터 상기 사용자의 손과 관련한 제 1 데이터를 획득하는 동작, 상기 제 1 AI(artificial intelligence) 모델을 이용하여 상기 제 1 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하는 동작, 상기 제 1 AI 모델을 이용하여 확인된 사용자의 손의 위치 및 손 관절에 기반하여, 상기 사용자의 손과 AR(augmented reality) 이미지에 포함된 적어도 하나의 오브젝트 간의 상호작용(interaction) 여부를 결정하는 동작, 및 상기 사용자의 손과 상기 AR 이미지에 포함된 적어도 하나의 오브젝트 간의 상호작용이 있는 것으로 결정한 것에 기반하여, 제 2 AI 모델을 선택하는 동작, 상기 적어도 하나의 센서 모듈로부터 상기 사용자의 손과 관련한 제 2 데이터를 획득하는 동작, 및 상기 제 2 AI 모델을 이용하여 상기 제 2 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하는 동작을 포함할 수 있다. 그 외에도 다양한 실시 예들이 가능하다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 있어서,사용자의 손을 감지하는 적어도 하나의 센서 모듈; 및상기 적어도 하나의 센서 모듈과 작동적으로 연결된 프로세서를 포함하고,상기 프로세서는,상기 사용자에게 AR(augmented reality) 이미지를 제공하기 위한 제 1 어플리케이션을 실행하고,상기 제 1 어플리케이션의 실행에 기반하여, 제 1 AI(artificial intelligence) 모델을 선택하고,상기 적어도 하나의 센서 모듈로부터 상기 사용자의 손과 관련한 제 1 데이터를 획득하고,상기 제 1 AI 모델을 이용하여 상기 제 1 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하고,상기 제 1 AI 모델을 이용하여 확인된 사용자의 손의 위치 및 손 관절에 기반하여, 상기 사용자의 손과 상기 AR 이미지에 포함된 적어도 하나의 오브젝트 간의 상호작용(interaction) 여부를 결정하고, 및상기 사용자의 손과 상기 AR 이미지에 포함된 적어도 하나의 오브젝트 간의 상호작용이 있는 것으로 결정한 것에 기반하여, 제 2 AI 모델을 선택하고,상기 적어도 하나의 센서 모듈로부터 상기 사용자의 손과 관련한 제 2 데이터를 획득하고, 및상기 제 2 AI 모델을 이용하여 상기 제 2 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하고,상기 제 1 AI 모델은 특정 시간 기간 동안 제 1 연산량을 처리하는 AI 모델이고, 상기 제 2 AI 모델은 상기 특정 시간 기간 동안 상기 제 1 연산량보다 많은 제 2 연산량을 처리하는 AI 모델인,전자 장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제 1 AI 모델은 상기 특정 시간 기간 동안 제 1 FPS(frame per second)의 이미지 데이터를 처리하도록 구성된 AI 모델이고,상기 제 2 AI 모델은 상기 특정 시간 기간 동안 제 2 FPS(frame per second)의 이미지 데이터를 처리하도록 구성된 AI 모델인,전자 장치.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,상기 제 2 AI 모델에 의해 소모되는 상기 프로세서의 리소스 사용량은, 상기 제 1 AI 모델에 의해 소모되는 상기 프로세서의 리소스 사용량보다 많은,전자 장치.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,상기 프로세서는,상기 제 1 AI 모델을 이용하여 확인된 사용자의 손의 위치 및 손 관절에 기반하여, 상기 사용자의 손의 제스처를 결정하고,상기 결정된 제스처가 지정된 제스처인지 확인하고, 및상기 결정된 제스처가 지정된 제스처이면, 상기 상호작용이 있는 것으로 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,상기 지정된 제스처는 상기 적어도 하나의 오브젝트에 대한 포인팅 제스처를 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서,상기 지정된 제스처는 상기 적어도 하나의 오브젝트에 대한 핀치 제스처를 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>7. 제 1 항 또는 제 4 항에 있어서,상기 프로세서는,상기 적어도 하나의 오브젝트가 상호작용하도록 설정된 오브젝트인지 확인하고,상기 적어도 하나의 오브젝트가 상호작용하도록 설정되지 않은 오브젝트이면, 상기 상호작용이 없는 것으로 결정하고,상기 적어도 하나의 오브젝트가 상호작용하도록 설정된 오브젝트이면, 상기 사용자의 손의 위치와 상기 적어도 하나의 오브젝트 간의 거리가 지정된 거리보다 긴지 확인하고,상기 사용자의 손의 위치와 상기 적어도 하나의 오브젝트 간의 거리가 지정된 거리보다 길면, 상기 상호작용이 없는 것으로 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>8. 제 7 항에 있어서,상기 프로세서는,상기 사용자의 손의 위치와 상기 적어도 하나의 오브젝트 간의 거리가 지정된 거리보다 짧거나 같으면, 상기 상호작용이 있는 것으로 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서,상기 프로세서는,상기 제 1 AI 모델 또는 상기 제 2 AI 모델을 이용하여 상기 제 1 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하는 동안에, 상기 전자 장치가 지정된 제 1 조건을 충족하는지 확인하고, 및상기 제 1 조건을 충족하면, 고정적으로 상기 제 1 AI 모델을 이용하여 상기 사용자의 손을 추적하는 제 1 고정 모드를 활성화하는,전자 장치.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 제 1 조건은,상기 제 1 조건과 관련한 사용자 입력을 수신하는 것, 또는배터리 잔량이 임계값보다 낮은 상태를 감지하는 것을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서,상기 프로세서는,상기 제 1 AI 모델 또는 상기 제 2 AI 모델을 이용하여 상기 제 1 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하는 동안에, 상기 전자 장치가 지정된 제 2 조건을 충족하는지 확인하고, 및상기 제 2 조건을 충족하면, 고정적으로 상기 제 2 AI 모델을 이용하여 상기 사용자의 손을 추적하는 제 2 고정 모드를 활성화하는,전자 장치.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 제 1 조건은,상기 제 2 조건과 관련한 사용자 입력을 수신하는 것, 또는상기 사용자의 제스처를 지정된 횟수 이상으로 반복하여 인식하지 못하는 상태를 감지하는 것을 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>13. 전자 장치의 방법에 있어서,사용자에게 AR(augmented reality) 이미지를 제공하기 위한 제 1 어플리케이션을 실행하는 동작,상기 제 1 어플리케이션의 실행에 기반하여, 제 1 AI(artificial intelligence) 모델을 선택하는 동작,적어도 하나의 센서 모듈로부터 상기 사용자의 손과 관련한 제 1 데이터를 획득하는 동작,상기 제 1 AI 모델을 이용하여 상기 제 1 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하는 동작,상기 제 1 AI 모델을 이용하여 확인된 사용자의 손의 위치 및 손 관절에 기반하여, 상기 사용자의 손과 상기 AR 이미지에 포함된 적어도 하나의 오브젝트 간의 상호작용(interaction) 여부를 결정하는 동작, 및상기 사용자의 손과 상기 AR 이미지에 포함된 적어도 하나의 오브젝트 간의 상호작용이 있는 것으로 결정한 것에 기반하여, 제 2 AI 모델을 선택하는 동작,상기 적어도 하나의 센서 모듈로부터 상기 사용자의 손과 관련한 제 2 데이터를 획득하는 동작, 및상기 제 2 AI 모델을 이용하여 상기 제 2 데이터를 연산하는 것에 의해 상기 사용자의 손의 위치 및 상기 손 관절의 형태를 확인하는 동작을 포함하고,상기 제 1 AI 모델은 특정 시간 기간 동안 제 1 연산량을 처리하는 AI 모델이고, 상기 제 2 AI 모델은 상기 특정 시간 기간 동안 상기 제 1 연산량보다 많은 제 2 연산량을 처리하는 AI 모델인,방법.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 제 1 AI 모델은 상기 특정 시간 기간 동안 제 1 FPS(frame per second)의 이미지 데이터를 처리하도록 구성된 AI 모델이고,상기 제 2 AI 모델은 상기 특정 시간 기간 동안 제 2 FPS(frame per second)의 이미지 데이터를 처리하도록 구성된 AI 모델인,방법.</claim></claimInfo><claimInfo><claim>15. 제 13 항에 있어서,상기 제 2 AI 모델에 의해 소모되는 상기 프로세서의 리소스 사용량은, 상기 제 1 AI 모델에 의해 소모되는 상기 프로세서의 리소스 사용량보다 많은,방법.</claim></claimInfo><claimInfo><claim>16. 제 13 항에 있어서,상기 제 1 AI 모델을 이용하여 확인된 사용자의 손의 위치 및 손 관절에 기반하여, 상기 사용자의 손의 제스처를 결정하는 동작,상기 결정된 제스처가 지정된 제스처인지 확인하는 동작, 및상기 결정된 제스처가 지정된 제스처이면, 상기 상호작용이 있는 것으로 결정하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서,상기 지정된 제스처는 상기 적어도 하나의 오브젝트에 대한 포인팅 제스처를 포함하는,방법.</claim></claimInfo><claimInfo><claim>18. 제 16 항에 있어서,상기 지정된 제스처는 상기 적어도 하나의 오브젝트에 대한 핀치 제스처를 포함하는,방법.</claim></claimInfo><claimInfo><claim>19. 제 13 항 또는 제 16 항에 있어서,상기 적어도 하나의 오브젝트가 상호작용하도록 설정된 오브젝트인지 확인하는 동작,상기 적어도 하나의 오브젝트가 상호작용하도록 설정되지 않은 오브젝트이면, 상기 상호작용이 없는 것으로 결정하는 동작,상기 적어도 하나의 오브젝트가 상호작용하도록 설정된 오브젝트이면, 상기 사용자의 손의 위치와 상기 적어도 하나의 오브젝트 간의 거리가 지정된 거리보다 긴지 확인하는 동작, 및상기 사용자의 손의 위치와 상기 적어도 하나의 오브젝트 간의 거리가 지정된 거리보다 길면, 상기 상호작용이 없는 것으로 결정하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>20. 제 19 항에 있어서,상기 사용자의 손의 위치와 상기 적어도 하나의 오브젝트 간의 거리가 지정된 거리보다 짧거나 같으면, 상기 상호작용이 있는 것으로 결정하는 동작을 포함하는,방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>WOO, Hyuntaek</engName><name>우현택</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Sungoh</engName><name>김성오</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Sanghun</engName><name>이상훈</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YEO, Hyungsok</engName><name>여형석</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YEOM, Donghyun</engName><name>염동현</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Dasom</engName><name>이다솜</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 금천구 가산디지털*로 *** ***호(가산동, 에이스하이엔드타워*차)</address><code>920171001812</code><country>대한민국</country><engName>YOON &amp; LEE International Patent &amp; Law Firm</engName><name>윤앤리특허법인(유한)</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.09.28</priorityApplicationDate><priorityApplicationNumber>1020220123591</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.11.07</receiptDate><receiptNumber>1-1-2022-1181680-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>접수중 (On receiving) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.29</receiptDate><receiptNumber>1-1-2025-1205430-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220147215.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9377529feb5c33440bfe1821d12ebf0fa748c1e0959fe2e02fda668116933922936b8e8749ba99b9094b7a934ebc228da5fc48e3818fc2fe36</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf00653852502c1da3147be828818c173774e3c1225a4bfe7d079f0ccb83f9502f759907121343d8bcaeed6464311e29a2ed194d003aa0558d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>