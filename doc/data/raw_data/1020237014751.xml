<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:08:20.820</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.09.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7014751</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>수술 로봇용 증강 현실 헤드셋</inventionTitle><inventionTitleEng>AUGMENTED REALITY HEADSET FOR A SURGICAL ROBOT</inventionTitleEng><openDate>2023.06.08</openDate><openNumber>10-2023-0082640</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.06.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.04.28</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>A61B 34/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>A61B 34/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2025.01.01)</ipcDate><ipcNumber>A61B 90/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>A61B 34/37</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>A61B 90/96</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>A61B 34/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>A61B 90/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 수술 전에, 수술 동안에 또는 수술 후에 수술 로봇 시스템을 구성하거나, 작동시키거나 또는 문제 해결(troubleshoot)하는 데 있어서 착용자를 안내하기 위해 수술 로봇 시스템의 공간적, 시스템적 및 시간적 상황 정보를 착용자에게 제공하는 증강 현실(AR) 헤드셋이 개시된다. 공간적 상황 정보는 수술 로봇 시스템의 실제 위치 또는 배향과 일치하는 수술 로봇 시스템의 로봇 아암들, 기구들, 베드 및 다른 구성요소들의 공간적으로 고정된 3D-생성된 가상 모델들을 AR 헤드셋의 좌표 프레임에 디스플레이하도록 렌더링될 수 있다. AR 헤드셋은 수술 로봇 시스템의 구성요소들의 실시간 상태 정보를 수신하기 위해 수술 로봇 시스템과 통신할 수 있다. AR 헤드셋은 로봇 아암과 테이블을 이들의 목표 위치 및 배향으로 조작하는 것에 대해 또는 문제 해결 목적으로 상황 감응(context-sensitive) 사용자 인터페이스 정보, 예컨대 단서(tip), 제안, 시각적 또는 청각적 큐(cue)를 디스플레이하기 위해 실시간 상태 정보를 사용할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.04.07</internationOpenDate><internationOpenNumber>WO2022070015</internationOpenNumber><internationalApplicationDate>2021.09.27</internationalApplicationDate><internationalApplicationNumber>PCT/IB2021/058785</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 수술 로봇 시스템을 위한 증강 현실(augmented reality; AR) 장치로서,상기 수술 로봇 시스템의 제1 구성요소의 이미지 데이터를 캡처하도록 구성된 센서; 상기 이미지 데이터에 기초하여 상기 AR 장치 및 상기 수술 로봇 시스템에 대한 글로벌 좌표 프레임을 확립하여 상기 AR 장치의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 가상 구성요소들이 생성되도록, 상기 수술 로봇 시스템의 공간 정보 및 실시간 시스템 상태 정보를 수신하도록, 그리고 상기 수술 로봇 시스템의 상기 공간 정보 및 상기 실시간 시스템 상태 정보에 기초하여 그리고 상기 글로벌 좌표 프레임에 기초하여 상기 AR 장치의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 제2 구성요소의 3D 가상 모델을 생성하도록 구성된 프로세서;및상기 수술 로봇 시스템의 상기 제2 구성요소의 상기 3D 가상 모델을 제시하도록 구성된 디스플레이를 포함하는, AR 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 AR 장치 및 상기 수술 로봇 시스템에 대한 상기 글로벌 좌표 프레임을 확립하도록 구성된 상기 프로세서는상기 AR 장치에 의해, 상기 제1 구성요소의 상기 이미지 데이터를 상기 수술 로봇 시스템으로 전송하여 상기 수술 로봇 시스템이 상기 AR 장치의 상기 좌표 프레임과 상기 수술 로봇 시스템의 좌표 프레임에 대한 상기 글로벌 좌표 프레임을 확립하게 하는 것을 포함하는, AR 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 수술 로봇 시스템의 상기 공간 정보는 상기 AR 장치의 상기 좌표 프레임에서 수신되는, AR 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 수술 로봇 시스템의 상기 제1 구성요소는 상기 수술 로봇 시스템의 기준 마커(fiduciary marker)이고, 상기 AR 장치 및 상기 수술 로봇 시스템에 대한 상기 글로벌 좌표 프레임을 확립하도록 구성된 상기 프로세서는상기 수술 로봇 시스템의 좌표 프레임에서 상기 기준 마커의 고정 위치에 기초하여 상기 기준 마커의 상기 이미지 데이터를 분석하여 상기 AR 장치의 상기 좌표 프레임 및 상기 수술 로봇 시스템의 상기 좌표 프레임에 대한 상기 글로벌 좌표 프레임을 확립하게 하는 것을 포함하는, AR 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 수술 로봇 시스템의 상기 공간 정보는 상기 수술 로봇 시스템의 상기 좌표 프레임에서의 상기 제2 구성요소의 공간 정보를 포함하고, 상기 AR 장치의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 상기 제2 구성요소의 상기 3D 가상 모델을 생성하도록 구성된 상기 프로세서는상기 글로벌 좌표 프레임에 기초하여 상기 수술 로봇 시스템의 상기 좌표 프레임에서의 상기 제2 구성요소의 상기 공간 정보를 상기 AR 장치의 상기 좌표 프레임으로 변환하게 하는 것을 포함하는, AR 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 AR 장치의 상기 좌표 프레임이 상기 수술 로봇 시스템의 좌표 프레임에 대해 변할 때 상기 수술 로봇 시스템의 상기 제2 구성요소의 상기 3D 가상 모델의 위치 및 배향을 유지하도록 구성된 상기 프로세서를 더 포함하는, AR 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 수술 로봇 시스템의 상기 공간 정보는 상기 제2 구성요소의 공간 정보를 포함하고, 상기 제2 구성요소의 상기 3D 가상 모델을 생성하도록 구성된 상기 프로세서는상기 제2 구성요소의 상기 공간 정보에 기초하여 상기 AR 장치의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 상기 제2 구성요소의 위치 및 배향을 생성하게 하는 것을 포함하고, 상기 AR 장치의 상기 좌표 프레임에서의 상기 제2 구성요소의 상기 위치 및 배향은 상기 제2 구성요소의 실제 위치 및 배향 또는 상기 제2 구성요소의 목표 위치 및 배향과 일치하는, AR 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 수술 로봇 시스템의 상기 실시간 시스템 상태 정보는 상기 제2 구성요소의 실시간 시스템 상태 정보를 포함하고, 상기 제2 구성요소의 상기 3D 가상 모델을 생성하도록 구성된 상기 프로세서는상기 제2 구성요소의 상기 실시간 시스템 상태 정보에 기초하여 상기 수술 로봇 시스템의 상기 제2 구성요소의 상황 감응(context-sensitive) 정보를 생성하게 하는 것을 더 포함하는, AR 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 수술 로봇 시스템의 상기 제2 구성요소는 상기 수술 로봇 시스템의 로봇 아암 또는 수술 테이블을 포함하는, AR 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 제2 구성요소의 상기 3D 가상 모델은상기 로봇 아암 또는 상기 수술 테이블의 위치 및 배향의 3D 가상 렌더링; 및상기 로봇 아암 또는 상기 수술 테이블의 상기 실시간 시스템 상태 정보의 시각적 또는 청각적 통신을 포함하는.  AR 장치.</claim></claimInfo><claimInfo><claim>11. 수술 로봇 시스템과 상호작용하기 위한 방법으로서,증강 현실(AR) 헤드셋을 사용하여 상기 수술 로봇 시스템의 제1 구성요소의 이미지 데이터를 캡처하는 단계;상기 이미지 데이터에 기초하여 그리고 상기 AR 헤드셋에 대한 그리고 상기 수술 로봇 시스템에 대한 글로벌 좌표 프레임에 기초하여 상기 AR 헤드셋의 좌표 프레임에서 상기 수술 로봇 시스템의 3차원(3D) 위치 및 배향을 확립하는 단계;상기 AR 헤드셋에 의해, 상기 수술 로봇 시스템의 공간 정보 및 실시간 시스템 상태 정보를 수신하는 단계;상기 AR 헤드셋에 의해, 상기 수술 로봇 시스템의 상기 공간 정보 및 상기 실시간 시스템 상태 정보, 상기 AR 헤드셋의 상기 좌표 프레임에서의 상기 수술 로봇 시스템의 상기 3D 위치 및 배향 및 상기 글로벌 좌표 프레임에 기초하여 상기 AR 헤드셋의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 제2 구성요소의 3D 가상 모델을 생성하는 단계; 및상기 AR 장치의 상기 좌표 프레임이 상기 수술 로봇 시스템의 좌표 프레임에 대해 변할 때 상기 수술 로봇 시스템의 상기 제2 구성요소의 상기 3D 가상 모델을 유지하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 AR 헤드셋의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 상기 3D 위치 및 배향을 확립하는 단계는상기 제1 구성요소의 상기 이미지 데이터를 상기 수술 로봇 시스템으로 전송하여, 상기 수술 로봇 시스템이 상기 AR 헤드셋의 상기 좌표 프레임과 상기 수술 로봇 시스템의 상기 좌표 프레임에 대한 상기 글로벌 좌표 프레임을 확립하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 수술 로봇 시스템의 상기 제1 구성요소는 상기 수술 로봇 시스템의 기준 마커이고, 상기 AR 헤드셋의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 상기 3D 위치 및 배향을 확립하는 단계는상기 수술 로봇 시스템의 좌표 프레임에서 상기 기준 마커의 고정 위치에 기초하여 상기 기준 마커의 상기 이미지 데이터를 분석하여 상기 AR 장치의 상기 좌표 프레임 및 상기 수술 로봇 시스템의 상기 좌표 프레임에 대한 상기 글로벌 좌표 프레임을 확립하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 수술 로봇 시스템의 상기 공간 정보는 상기 제2 구성요소의 공간 정보를 포함하고, 상기 제2 구성요소의 상기 3D 가상 모델을 생성하는 단계는상기 제2 구성요소의 상기 공간 정보에 기초하여 상기 AR 장치의 상기 좌표 프레임에서 상기 수술 로봇 시스템의 상기 제2 구성요소를 렌더링하는 단계를 포함하고, 상기 AR 장치의 상기 좌표 프레임에서 렌더링된 상기 제2 구성요소의 위치 및 배향은 상기 제2 구성요소의 실제 위치 및 배향 또는 상기 제2 구성요소의 목표 위치 및 배향과 일치하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 수술 로봇 시스템의 상기 실시간 시스템 상태 정보는 상기 제2 구성요소의 실시간 시스템 상태 정보를 포함하고, 상기 제2 구성요소의 상기 3D 가상 모델을 생성하는 단계는상기 제2 구성요소의 상기 실시간 시스템 상태 정보에 기초하여 상기 수술 로봇 시스템의 상기 제2 구성요소의 상황 감응 정보를 렌더링하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 수술 로봇 시스템의 상기 제2 구성요소는 상기 수술 로봇 시스템의 로봇 아암 또는 수술 테이블을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 수술 로봇 시스템의 상기 제2 구성요소의 상기 3D 가상 모델은 상기 수술 로봇 시스템의 상기 아암을 수동으로 또는 로봇식으로 조작하는 것에 대한 실시간 안내를 제공하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 수술 로봇 시스템의 상기 제2 구성요소의 상기 3D 가상 모델은 상기 수술 로봇 시스템의 상기 아암의 작업공간(workspace)의 실시간 렌더링을 제공하는, 방법.</claim></claimInfo><claimInfo><claim>19. 수술 로봇 시스템으로서,수술 테이블;상기 수술 테이블에 결합된 복수의 로봇 아암들; 및상기 수술 테이블, 상기 복수의 로봇 아암들 및 증강 현실(AR) 헤드셋에 통신 가능하게 결합된 프로세서를 포함하고;상기 AR 헤드셋은 상기 수술 테이블 또는 하나 이상의 상기 복수의 로봇 아암들의 이미지 데이터를 캡처하고; 상기 프로세서와 협력하여, 상기 이미지 데이터에 기초하여 상기 AR 장치에 대한 그리고 상기 수술 테이블 또는 상기 복수의 로봇 아암들에 대한 글로벌 좌표 프레임을 확립하고; 상기 프로세서로부터 상기 수술 테이블 또는 상기 복수의 로봇 아암들의 공간 정보 및 실시간 시스템 상태 정보를 수신하고; 상기 공간 정보 및 상기 실시간 시스템 상태 정보에 기초하여 그리고 상기 글로벌 좌표 프레임에 기초하여 상기 AR 장치의 좌표 프레임에서 상기 수술 테이블 또는 하나 이상의 상기 복수의 로봇 아암들의 3D 가상 모델을 생성하고; 그리고 상기 수술 테이블 또는 하나 이상의 상기 복수의 로봇 아암들의 상기 3D 가상 모델을 디스플레이하도록 구성되는, 수술 로봇 시스템.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 수술 테이블 또는 하나 이상의 상기 복수의 로봇 아암들의 상기 3D 가상 모델은 상기 수술 로봇 시스템의 사용자가 상기 수술 테이블 또는 상기 로봇 아암들을 조작하거나 또는 문제 해결(troubleshoot)하는 것을 돕기 위해 상기 수술 테이블 또는 상기 로봇 아암들의 상황 감응 실시간 정보를 포함하는, 수술 로봇 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아, 산타 클라라 그레이트 아메리카 파크웨이 ****</address><code>520160957285</code><country>미국</country><engName>Verb Surgical Inc.</engName><name>버브 서지컬 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 산...</address><code> </code><country> </country><engName>SONG, Tianyu</engName><name>송 티안유</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 산...</address><code> </code><country> </country><engName>OLSON, Blade</engName><name>올슨 블레이드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 산...</address><code> </code><country> </country><engName>FUERST, Bernhard A.</engName><name>푸어스트 번하드 에이.</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 산...</address><code> </code><country> </country><engName>FER, Danyal</engName><name>퍼 대니얼</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 세종대로 ***, **층 (세종로, 광화문빌딩)(법무법인센트럴)</address><code>919990006014</code><country>대한민국</country><engName>HOON CHANG</engName><name>장훈</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.09.30</priorityApplicationDate><priorityApplicationNumber>17/039,949</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.04.28</receiptDate><receiptNumber>1-1-2023-0481550-80</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.05.08</receiptDate><receiptNumber>1-5-2023-0073548-77</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.06.26</receiptDate><receiptNumber>1-1-2024-0690104-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.06.26</receiptDate><receiptNumber>1-1-2024-0690118-50</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237014751.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9390aaa2d85c33244bb21bb0139c4fff8ac8026d84a3fd1077738ff778821116b38302b1484d4f0db4df5ee0e2a028aaa94059bbad40e8df97</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff75e38f7437aca66ff91087387a65a0164e3ec58db58c4e2b57584900edcc814d206dd1555ba173d6c69126f901f8dbeda25cdc750971b1b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>