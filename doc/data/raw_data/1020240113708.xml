<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:36.3336</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.08.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0113708</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 편집을 위한 방법 및 이를 수행하기 위한 전자 장치</inventionTitle><inventionTitleEng>METHOD FOR IMAGE EDITING AND ELECTRONIC DEVICE FOR  PERFORMING THE SAME</inventionTitleEng><openDate>2025.11.05</openDate><openNumber>10-2025-0157916</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치가 이미지를 편집(editing)하는 방법이 제공된다. 상기 방법은, 입력 이미지의 일부 영역을 타겟 영역으로 지정하는 입력을 획득하는 단계, 상기 타겟 영역의 이미지를 편집하기 위한 사용자의 의도(intent)를 획득하는 단계, 상기 사용자의 의도에 대응하는 임베딩(embedding)을 데이터베이스로부터 획득하는 단계, 상기 획득된 임베딩을 이용하여, 생성 모델(generative model)을 통해 상기 타겟 영역에 대한 이미지를 편집하는 단계 및 상기 타겟 영역에 대한 이미지가 생성된 결과 이미지를 출력하는 단계를 포함할 수 있고, 상기 데이터베이스에는 적어도 하나 이상의 의도에 대응하는 임베딩이 미리 저장되어 있을 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 의해 수행되는 이미지를 편집(editing)하는 방법에 있어서,입력 이미지의 일부 영역을 타겟 영역으로 지정하는 입력을 획득하는 단계;상기 타겟 영역의 이미지를 편집하기 위한 사용자의 의도(intent)를 획득하는 단계;상기 사용자의 의도에 대응하는 임베딩(embedding)을 데이터베이스로부터 획득하는 단계;상기 획득한 임베딩을 이용하여, 생성 모델(generative model)을 통해 상기 타겟 영역에 대한 이미지를 편집하는 단계; 및상기 타겟 영역에 대한 이미지가 생성된 결과 이미지를 출력하는 단계를 포함하며,상기 데이터베이스에는 적어도 하나 이상의 의도에 대응하는 임베딩이 미리 저장된, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 임베딩(embedding)은,상기 사용자의 의도에 기초하여 이미지의 마스킹된 영역을 편집하는 동작에 대응하도록 사전에 학습된 것인, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 사용자의 의도는,전경(foreground)을 생성하여 상기 타겟 영역에 대한 이미지를 편집하는 전경 생성 의도 또는 배경(background)을 확장(extend)하여 상기 타겟 영역에 대한 이미지를 편집하는 전경 제거 의도를 포함하는 것인, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 임베딩(embedding)은,전경(foreground)을 생성하여 상기 타겟 영역에 대한 이미지를 편집하는 동작에 대응하도록 학습된 전경 생성 임베딩; 및배경(background)을 확장(extend)하여 상기 타겟 영역에 대한 이미지를 편집하는 동작에 대응하도록 학습된 전경 제거 임베딩을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 전경 생성 임베딩은, 전경 영역을 마스킹한 이미지 및 전경 영역을 마스킹한 마스크를 학습 데이터로 하여, 상기 이미지의 마스킹된 영역을 상기 마스크의 형태 및 상기 이미지의 맥락에 기초하여 전경을 생성하여 채우는 동작에 대응하도록 학습된 것인, 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 전경 제거 임베딩은, 배경 영역을 마스킹한 이미지 및 배경 영역을 마스킹한 마스크를 학습 데이터로 하여, 상기 이미지의 마스킹된 영역을 배경을 확장하여 채우는 동작에 대응하도록 학습된 것인, 방법. </claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 생성 모델을 통해 상기 타겟 영역에 대한 이미지를 편집하는 단계는,초기 노이즈를 생성하는 단계;상기 초기 노이즈로부터 출발하여, 시간 단계별로 노이즈 예측 및 예측된 노이즈 제거를 반복함으로써 상기 적어도 하나의 타겟 영역에 대한 이미지를 편집하는 단계를 포함하되,상기 노이즈 예측 과정은, 상기 사용자 의도에 대응하는 임베딩을 사용하는 조건부 예측 및 무조건부 예측을 사용한 가중치 결합을 이용하는 것인, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 가중치 결합은,행렬 형태의 가이던스 스케일에 기초하는 것이고,상기 조건부 예측은, 상기 적어도 하나의 타겟 영역에 대해 개별적으로 식별된 사용자 의도에 대응하는 임베딩을 사용하는 것인, 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 행렬 형태의 가이던스 스케일은,상기 타겟 영역에 대응하는 마스크 이미지(masked image)의 픽셀별 삼원(ternary) 행렬과 가중치 값의 곱인, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 타겟 영역에 대한 이미지가 생성된 결과 결과 이미지를 출력하는 단계는,상기 편집한 타겟 영역의 이미지 및 상기 타겟 영역 이외의 영역의 입력 이미지를 결합하는 단계; 및상기 결합한 결과를 상기 결과 이미지로 출력하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>11. 제3항에 있어서,상기 획득한 사용자 의도에 전경 생성 의도가 포함된 경우, 상기 생성할 전경의 클래스를 획득하는 단계; 및상기 획득한 전경의 클래스에 대응하는 임베딩을 상기 데이터베이스로부터 획득하는 단계를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 타겟 영역에 대한 이미지를 편집하는 단계는,상기 사용자의 의도에 대응하는 임베딩, 상기 전경의 클래스에 대응하는 임베딩을 이용하여, 생성 모델을 통해 상기 타겟 영역에 대한 이미지를 편집하는 단계이고, 상기 데이터베이스에는 적어도 하나 이상의 전경의 클래스에 대응하는 임베딩이 미리 저장된, 방법.</claim></claimInfo><claimInfo><claim>13. 이미지를 편집하는 전자 장치(1000)에 있어서,통신 인터페이스(1100);적어도 하나의 인스트럭션을 저장하는 메모리(1200); 및회로 장치를 포함하는 적어도 하나의 프로세서(1300)를 포함하고,상기 적어도 하나의 인스트럭션이 상기 적어도 하나의 프로세서(1300)에 의해 실행됨으로써, 상기 전자 장치(1000)는,입력 이미지의 일부 영역을 타겟 영역으로 지정하는 입력을 획득하고,상기 타겟 영역의 이미지를 편집하기 위한 사용자의 의도(intent)를 획득하고,상기 사용자의 의도에 대응하는 임베딩(embedding)을 데이터베이스로부터 획득하고,상기 획득된 임베딩을 이용하여, 생성 모델(generative model)을 통해 상기 타겟 영역에 대한 이미지를 편집하고,상기 타겟 영역에 대한 이미지가 생성된 결과 이미지를 출력하는 단계를 포함하며,상기 데이터베이스에는 적어도 하나 이상의 의도에 대응하는 임베딩이 미리 저장된, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 임베딩(embedding)은,상기 사용자의 의도에 기초하여 이미지의 마스킹된 영역을 편집하는 동작에 대응하도록 사전에 학습된 것인, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 사용자의 의도는,전경(foreground)을 생성하여 상기 타겟 영역을 편집하는 전경 생성 의도(foreground creation intent) 또는 배경(background)을 확장(extend)하여 상기 타겟 영역을 편집하는 전경 제거 의도(foreground removal intent)를 포함하는 것인, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 임베딩(embedding)은,전경(foreground)을 생성하여 상기 타겟 영역에 대한 이미지를 편집하는 동작에 대응하도록 학습된 전경 생성 임베딩; 및배경(background)을 확장(extend)하여 상기 타겟 영역에 대한 이미지를 편집하는 동작에 대응하도록 학습된 전경 제거 임베딩을 포함하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 전경 생성 임베딩은, 전경 영역을 마스킹한 이미지 및 전경 영역을 마스킹한 마스크를 학습 데이터로 하여, 상기 이미지의 마스킹된 영역을 상기 마스크의 형태 및 상기 이미지의 맥락에 기초하여 전경을 생성하여 채우는 동작에 대응하도록 학습된 것인, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 전경 제거 임베딩은, 배경 영역을 마스킹한 이미지 및 배경 영역을 마스킹한 마스크를 학습 데이터로 하여, 상기 이미지의 마스킹된 영역을 배경을 확장하여 채우는 동작에 대응하도록 학습된 것인, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>19. 제13항에 있어서,상기 적어도 하나의 인스트럭션이 상기 적어도 하나의 프로세서(1300)에 의해 실행됨으로써, 상기 전자 장치(1000)는,초기 노이즈를 생성하고,상기 초기 노이즈로부터 출발하여, 시간 단계별로 노이즈 예측 및 예측된 노이즈 제거를 반복함으로써 상기 적어도 하나의 타겟 영역에 대한 이미지를 편집하는 단계를 포함하되,상기 노이즈 예측 과정은, 상기 사용자 의도에 대응하는 임베딩을 사용하는 조건부 예측 및 무조건부 예측의 가중치 결합을 이용하는 것인, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제12항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEON, Bo Seong</engName><name>전보성</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KWON, Jung Min</engName><name>권정민</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>AHN, Beom Jin</engName><name>안범진</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Ta Mmy</engName><name>이태미</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2024.04.29</priorityApplicationDate><priorityApplicationNumber>1020240057203</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.08.23</receiptDate><receiptNumber>1-1-2024-0924747-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240113708.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937293b8b70102745be607d9350b9127b57ca96eb21aee86966d7bb653805395b43409eca7b5ecb7f955e27d8ced6bb7eb6dca9b8aebf7b848</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf747bc370f562d35e59a9daa1fdd4818b13981c454883fdf79acf5a5655dfd963aa5fb103f9ed30b81df87a071fd9f8f569065fdcd25b1b2d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>