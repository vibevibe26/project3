<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:24.124</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7015357</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>기계 학습 모델을 이용한 자기지도 3차원 위치 예측</inventionTitle><inventionTitleEng>SELF-SUPERVISED THREE-DIMENSIONAL LOCATION PREDICTION USING MACHINE LEARNING MODELS</inventionTitleEng><openDate>2024.07.18</openDate><openNumber>10-2024-0112269</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.05.08</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 17/05</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04W 4/029</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>H04W 12/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2015.01.01)</ipcDate><ipcNumber>H04B 17/309</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 특정 양태들은 다수의 이산 평면들을 포함하는 공간 환경과 같은 공간 환경에서 장치의 위치를 예측하기 위한 기계 학습 모델의 자기지도 훈련을 위한 기술 방법을 제공한다. 예시적인 방법은 일반적으로 장면 데이터의 입력 데이터 세트를 수신하는 것을 포함한다. 생성기 모델은 입력 데이터 세트 내의 장면 데이터를 3차원 공간의 점들로 매핑하도록 훈련된다. 하나 이상의 크리틱 모델들은 3차원 공간의 점들을 3차원 공간의 복수의 평면들 중 하나로 밀기 위해 생성기 모델에 기울기를 역전파하도록 훈련된다. 적어도 생성기가 배치된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.05.25</internationOpenDate><internationOpenNumber>WO2023091836</internationOpenNumber><internationalApplicationDate>2022.10.20</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/078405</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법으로서,장면 데이터의 입력 데이터 세트를 수신하는 단계;상기 입력 데이터 세트 내의 장면 데이터를 하나 이상의 다차원 공간의 점들로 매핑하는 생성기 모델을 훈련하는 단계;상기 하나 이상의 다차원 공간 내의 점들을 하나 이상의 다차원 공간 내의 복수의 평면들 중 하나로 밀기 위해 하나 이상의 크리틱 모델들에서 상기 생성기 모델로 기울기를 역전파하는 단계; 및적어도 상기 생성기 모델을 배치하는 단계를 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 장면 데이터는 공간 환경의 하나 이상의 이미지를 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 장면 데이터는 시간 경과에 따라 획득된 채널 상태 정보(CSI) 측정들과 연관된 전력 밀도 맵을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 하나 이상의 크리틱 모델들은, 상기 생성기 모델에 의해 생성된 상기 하나 이상의 다차원 공간 내의 점들의 단일 평면성을 촉진하도록 구성된 제1 크리틱 모델, 및 상기 생성기 모델의 출력들 사이에 입도를 강제하도록 구성된 제2 크리틱 모델을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제1 크리틱 모델은 장면 데이터의 입력을 위해 상기 하나 이상의 다차원 공간 내의 각각의 평면을 따르는 다수의 인라이어들에 기초하여 상기 하나 이상의 다차원 공간 내의 평면의 최상의 가설을 선택하도록 구성되는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서, 상기 제1 크리틱 모델은 상기 하나 이상의 다차원 공간 내의 매핑된 데이터에 적용하기 위한 인력 및 척력을 생성하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서, 상기 제2 크리틱 모델은 공간 환경에서 인접한 클러스터들 간의 손실을 최소화하도록 구성되는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 생성기 모델 및 상기 하나 이상의 크리틱 모델들을 초기 시점으로부터 시간적 오프셋을 갖는 값이 증가하는 장면 흐름 제약 항에 기초하여 훈련하는 것을 더 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 하나 이상의 다차원 공간은 3차원 공간 및 128차원 공간을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위해 기계 학습 모델을 훈련하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>10. 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법으로서,장면 데이터를 수신하는 단계; 및상기 장면 데이터를 생성기 모델을 통해 하나 이상의 다차원 공간 내의 점으로 매핑하는 단계 - 상기 생성기 모델은 하나 이상의 크리틱 모델들로부터 상기 생성기 모델로 역전파된 기울기를 갖고, 상기 크리틱 모델들은 상기 하나 이상의 다차원 공간의 점들을 복수의 평면들 중 하나로 분리하여 상기 하나 이상의 다차원 공간 내의 점들이 상기 하나 이상의 다차원 공간의 복수의 평면들 중 임의의 평면의 부근에 있게 하도록 구성됨 - 를 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 장면 데이터가 매핑되는 상기 하나 이상의 다차원 공간 내의 점에 기초하여 상기 수신된 장면 데이터가 위치하는 상기 하나 이상의 다차원 공간 내의 평면 상의 위치를 예측하는 단계를 더 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 장면 데이터는 공간 환경의 하나 이상의 이미지를 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 장면 데이터는 시간 경과에 따라 획득된 채널 상태 정보(CSI) 측정들과 연관된 전력 밀도 맵을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서, 상기 기울기는, 상기 하나 이상의 다차원 공간 내의 단일 평면 점들을 동일한 평면 상으로 미는 인력 항 및 상기 하나 이상의 다차원 공간 내의 서로 다른 평면들 상에 위치하는 점들을 서로에게서 멀리 밀어내는 척력을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서, 상기 기울기는 공간 환경에서 인접한 클러스터들 사이의 최소화된 손실을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>16. 제10항에 있어서, 상기 기울기는 초기 시점으로부터 시간적 오프셋에 따라 값이 증가하는 장면 흐름 제약 항을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서, 상기 하나 이상의 다차원 공간은 3차원 공간 및 128차원 공간을 포함하는, 다중 평면 공간 환경에서 객체의 위치를 예측하기 위한 컴퓨터 구현형 방법.</claim></claimInfo><claimInfo><claim>18. 프로세싱 시스템으로서,실행 가능 명령어들이 저장된 메모리; 및프로세서를 포함하고, 상기 프로세서는 상기 실행 가능 명령어들을 실행하여, 상기 프로세싱 시스템으로 하여금, 장면 데이터의 입력 데이터 세트를 수신하게 하고; 상기 입력 데이터 세트 내의 장면 데이터를 하나 이상의 다차원 공간의 점들로 매핑하도록 생성기 모델을 훈련하게 하고; 상기 하나 이상의 다차원 공간 내의 점들을 상기 하나 이상의 다차원 공간 내의 복수의 평면들 중 하나로 밀기 위해 하나 이상의 크리틱 모델들로부터 상기 생성기 모델로 기울기를 역전파하게 하고; 그리고 적어도 상기 생성기 모델을 배치하게 하도록 구성된, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 하나 이상의 크리틱 모델들은, 상기 생성기 모델에 의해 생성된 상기 하나 이상의 다차원 공간 내의 점들의 동일 평면성을 촉진하도록 구성된 제1 크리틱 모델 및 상기 생성기 모델의 출력들 사이에 입도를 강제하도록 구성된 제2 크리틱 모델을 포함하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 제1 크리틱 모델은 장면 데이터의 입력을 위해 상기 하나 이상의 다차원 공간들 내의 각각의 평면을 따르는 다수의 인라이어들에 기초하여 상기 하나 이상의 다차원 공간들 내의 평면의 최상의 가설을 선택하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>21. 제19항에 있어서, 상기 제2 크리틱 모델은 공간 환경에서 인접한 클러스터들 간의 손실을 최소화하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>22. 제18항에 있어서, 상기 프로세서는, 상기 프로세싱 시스템으로 하여금 초기 시점으로부터 시간적 오프셋을 갖는 값이 증가하는 장면 흐름 제약 항에 기초하여 상기 생성기 모델 및 상기 하나 이상의 크리틱 모델들을 훈련하게 하도록 더 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>23. 프로세싱 시스템으로서,실행 가능 명령어들이 저장된 메모리; 및프로세서를 포함하고, 상기 프로세서는 상기 실행 가능 명령어들을 실행하여, 상기 프로세싱 시스템으로 하여금, 장면 데이터를 수신하게 하고; 그리고 상기 장면 데이터를 생성기 모델을 통해 하나 이상의 다차원 공간 내의 점으로 매핑하게 하는 - 상기 생성기 모델은 하나 이상의 크리틱 모델들로부터 상기 생성기 모델로 역전파된 기울기를 갖고, 상기 크리틱 모델들은 상기 하나 이상의 다차원 공간의 점들을 복수의 평면들 중 하나로 분리하여 상기 하나 이상의 다차원 공간 내의 점들이 상기 하나 이상의 다차원 공간의 복수의 평면들 중 임의의 평면의 부근에 있게 하도록 구성됨 -, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 프로세서는, 상기 프로세싱 시스템으로 하여금, 상기 장면 데이터가 매핑되는 상기 하나 이상의 다차원 공간 내의 점에 기초하여 상기 수신된 장면 데이터가 위치되는 상기 하나 이상의 다차원 공간 내의 평면 상의 위치를 예측하게 하도록 더 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>25. 제23항에 있어서, 상기 장면 데이터는 공간 환경의 하나 이상의 이미지를 포함하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>26. 제23항에 있어서, 상기 장면 데이터는 시간 경과에 따라 획득된 채널 상태 정보(CSI) 측정들과 연관된 전력 밀도 맵을 포함하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>27. 제23항에 있어서, 상기 기울기는, 상기 하나 이상의 다차원 공간 내의 단일 평면 점들을 동일한 평면 상으로 미는 인력 항 및 상기 하나 이상의 다차원 공간 내의 상이한 평면들 상에 위치하는 점들을 서로에게서 멀리 밀어내는 척력을 포함하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>28. 제23항에 있어서, 상기 기울기는 공간 환경에서 인접한 클러스터들 간의 최소화된 손실을 포함하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>29. 제23항에 있어서, 상기 기울기는 초기 시점으로부터 시간적 오프셋에 따라 값이 증가하는 장면 흐름 제약 항을 포함하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>30. 제23항에 있어서, 상기 하나 이상의 다차원 공간은 3차원 공간 및 128차원 공간을 포함하는, 프로세싱 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>ACKERMANN, HANNO</engName><name>아커만 하노</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>KARMANOV, ILIA</engName><name>카르마노프 일리아</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>GHAZVINIAN ZANJANI, FARHAD</engName><name>가즈비니안 잔자니 파하드</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>DIJKMAN, DANIEL HENDRICUS FRANCISCUS</engName><name>데이크만 다니얼 헨드리퀴스 프란시스퀴스</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>PORIKLI, FATIH MURAT</engName><name>포리클리 파티 무라트</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.11.16</priorityApplicationDate><priorityApplicationNumber>63/264,146</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.10.19</priorityApplicationDate><priorityApplicationNumber>18/047,796</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.05.08</receiptDate><receiptNumber>1-1-2024-0499129-71</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.06.18</receiptDate><receiptNumber>1-5-2024-0099224-22</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247015357.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9302a02d0175b4ee9903bdac689133f484de4935367cd6e50645ec9a9c1259c6153b07e2273f11d27ea52463ba8764abeb554402848ae7863f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd05e72d5bf722ddd65339b61d1512e912ca945b45f4d45fd2875128154b155b5ef762e35c10d409c22d5712a4ce824e21e054712724888f4</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>