<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:05.55</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7017279</applicationNumber><claimCount>29</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>단안 깊이 추정을 이용한 세그먼트화</inventionTitle><inventionTitleEng>SEGMENTATION WITH MONOCULAR DEPTH ESTIMATION</inventionTitleEng><openDate>2024.08.02</openDate><openNumber>10-2024-0118074</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.14</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.05.23</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 깊이 필터링을 이용하여 이미지 세그먼트화를 수행하기 위한 시스템들, 방법들 및 컴퓨터 판독가능 매체들이 제공된다. 일부 예들에서, 방법은 장면을 캡처하는 프레임을 획득하는 단계; 프레임에 기초하여, 관심 타겟을 식별하는 타겟 세그먼트화 마스크 및 프레임의 하나 이상의 배경 구역들을 식별하는 하나 이상의 배경 마스크들을 포함하는 제1 세그먼트화 맵을 생성하는 단계; 및 하나 이상의 배경 마스크들이 필터링된 제1 세그먼트화 맵을 포함하는 제2 세그먼트화 맵을 생성하는 단계를 포함할 수 있고, 하나 이상의 배경 마스크들은 프레임과 연관된 깊이 맵에 기초하여 제1 세그먼트화 맵으로부터 필터링된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.06.08</internationOpenDate><internationOpenNumber>WO2023097576</internationOpenNumber><internationalApplicationDate>2021.12.01</internationalApplicationDate><internationalApplicationNumber>PCT/CN2021/134849</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 세그먼트화를 위한 장치로서,메모리; 및상기 메모리에 커플링된 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은, 장면을 캡처하는 프레임을 획득하고; 상기 프레임에 기초하여, 관심 타겟을 식별하는 타겟 세그먼트화 마스크 및 상기 프레임의 하나 이상의 배경 구역들을 식별하는 하나 이상의 배경 마스크들을 포함하는 제1 세그먼트화 맵을 생성하고; 상기 하나 이상의 배경 마스크들이 필터링된 상기 제1 세그먼트화 맵을 포함하는 제2 세그먼트화 맵을 생성하도록 구성되고, 상기 하나 이상의 배경 마스크들은 상기 프레임과 연관된 깊이 맵에 기초하여 상기 제1 세그먼트화 맵으로부터 필터링되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제2 세그먼트화 맵을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 세그먼트화 맵과 상기 깊이 맵의 비교에 기초하여, 상기 하나 이상의 배경 마스크들과 연관된 개개의 깊이 값들과 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 연관된 개개의 깊이 값들 사이의 임계 차이를 결정하도록 구성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 제2 세그먼트화 맵을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 하나 이상의 배경 마스크들과 연관된 개개의 깊이 값들과 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 연관된 개개의 깊이 값들 사이의 상기 임계 차이에 기초하여, 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 제거하도록 구성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 깊이 맵은 상기 프레임의 픽셀들에 대응하는 깊이 값들과 연관된 깊이 마스크들의 세트를 포함하고, 상기 제2 세그먼트화 맵을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 세그먼트화 맵과 상기 깊이 맵의 비교에 기초하여, 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 상기 깊이 맵에서 상기 깊이 마스크들의 세트로부터의 하나 이상의 깊이 마스크들 사이의 중첩을 결정하고;상기 중첩에 기초하여, 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크를 유지하고;상기 하나 이상의 배경 마스크들과 상기 깊이 마스크들의 세트로부터의 하나 이상의 추가적인 깊이 마스크들 사이의 추가적인 중첩에 기초하여, 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하도록 구성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제2 세그먼트화 맵을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 하나 이상의 추가적인 깊이 마스크들과 연관된 깊이 값들과 상기 하나 이상의 깊이 마스크들과 연관된 깊이 값들 사이의 차이가 임계치를 초과한다고 결정하고;상기 차이가 상기 임계치를 초과하는 것에 기초하여, 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하도록 구성되고, 상기 하나 이상의 깊이 마스크들은 상기 관심 타겟에 대응하고, 상기 하나 이상의 추가적인 깊이 마스크들은 상기 프레임의 상기 하나 이상의 배경 구역들에 대응하는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 제2 세그먼트화 맵을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 깊이 맵으로부터의 깊이 구역들과 연관된 IOU(intersection-over-union) 스코어들 및 상기 제1 세그먼트화 맵으로부터의 예측된 마스크들을 결정하고;상기 IOU 스코어들에 기초하여, 상기 깊이 맵으로부터의 깊이 구역들을 상기 제1 세그먼트화 맵으로부터의 예측된 마스크들과 매칭시키는 것으로서, 상기 예측된 마스크들은 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크 및 상기 프레임의 상기 하나 이상의 배경 구역들을 식별하는 상기 하나 이상의 배경 마스크들을 포함하는, 상기 예측된 마스크들과 매칭시키고;상기 하나 이상의 배경 마스크들과 연관된 하나 이상의 IOU 스코어들이 임계치 미만이라는 결정에 기초하여 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하도록 구성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 하나 이상의 프로세서들은,상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하기 전에, 상기 깊이 맵에 적응적 가우시안 임계치화 및 잡음 감소를 적용하도록 구성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 프레임은 단안 이미지 캡처 디바이스에 의해 생성된 단안 프레임을 포함하는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 제1 세그먼트화 맵 및 상기 제2 세그먼트화 맵은 하나 이상의 뉴럴 네트워크들을 사용하여 생성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 하나 이상의 프로세서들은 뉴럴 네트워크를 사용하여 상기 깊이 맵을 생성하도록 구성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 하나 이상의 프로세서들은,상기 프레임 및 상기 제2 세그먼트화 맵에 기초하여, 수정된 프레임을 생성하도록 구성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 수정된 프레임은, 시각적 효과, 확장 현실 효과, 이미지 프로세싱 효과, 블러링 효과, 이미지 인식 효과, 객체 검출 효과, 컴퓨터 그래픽 효과, 크로마 키잉 효과, 및 이미지 스타일화 효과 중 적어도 하나를 포함하는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 이미지 캡처 디바이스를 더 포함하고, 상기 프레임은 상기 이미지 캡처 디바이스에 의해 생성되는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 장치는 모바일 디바이스를 포함하는, 이미지 세그먼트화를 위한 장치.</claim></claimInfo><claimInfo><claim>15. 이미지 세그먼트화를 위한 방법으로서,장면을 캡처하는 프레임을 획득하는 단계;상기 프레임에 기초하여, 관심 타겟을 식별하는 타겟 세그먼트화 마스크 및 상기 프레임의 하나 이상의 배경 구역들을 식별하는 하나 이상의 배경 마스크들을 포함하는 제1 세그먼트화 맵을 생성하는 단계; 및상기 하나 이상의 배경 마스크들이 필터링된 상기 제1 세그먼트화 맵을 포함하는 제2 세그먼트화 맵을 생성하는 단계를 포함하고, 상기 하나 이상의 배경 마스크들은 상기 프레임과 연관된 깊이 맵에 기초하여 상기 제1 세그먼트화 맵으로부터 필터링되는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 제2 세그먼트화 맵을 생성하는 단계는,상기 제1 세그먼트화 맵과 상기 깊이 맵의 비교에 기초하여, 상기 하나 이상의 배경 마스크들과 연관된 개개의 깊이 값들과 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 연관된 개개의 깊이 값들 사이의 임계 차이를 결정하는 단계를 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 제2 세그먼트화 맵을 생성하는 단계는,상기 하나 이상의 배경 마스크들과 연관된 개개의 깊이 값들과 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 연관된 개개의 깊이 값들 사이의 상기 임계 차이에 기초하여, 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 제거하는 단계를 더 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 상기 깊이 맵은 상기 프레임의 픽셀들에 대응하는 깊이 값들과 연관된 깊이 마스크들의 세트를 포함하고, 상기 제2 세그먼트화 맵을 생성하는 단계는,상기 제1 세그먼트화 맵과 상기 깊이 맵의 비교에 기초하여, 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 상기 깊이 맵에서 상기 깊이 마스크들의 세트로부터의 하나 이상의 깊이 마스크들 사이의 중첩을 결정하는 단계;상기 중첩에 기초하여, 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크를 유지하는 단계; 및상기 하나 이상의 배경 마스크들과 상기 깊이 마스크들의 세트로부터의 하나 이상의 추가적인 깊이 마스크들 사이의 추가적인 중첩에 기초하여, 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하는 단계를 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 제2 세그먼트화 맵을 생성하는 단계는,상기 하나 이상의 추가적인 깊이 마스크들과 연관된 깊이 값들과 상기 하나 이상의 깊이 마스크들과 연관된 깊이 값들 사이의 차이가 임계치를 초과한다고 결정하는 단계; 및상기 차이가 상기 임계치를 초과하는 것에 기초하여, 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하는 단계를 더 포함하고, 상기 하나 이상의 깊이 마스크들은 상기 관심 타겟에 대응하고, 상기 하나 이상의 추가적인 깊이 마스크들은 상기 프레임의 상기 하나 이상의 배경 구역들에 대응하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 제2 세그먼트화 맵을 생성하는 단계는,상기 깊이 맵으로부터의 깊이 구역들과 연관된 IOU(intersection-over-union) 스코어들 및 상기 제1 세그먼트화 맵으로부터의 예측된 마스크들을 결정하는 단계;상기 IOU 스코어들에 기초하여, 상기 깊이 맵으로부터의 깊이 구역들을 상기 제1 세그먼트화 맵으로부터의 예측된 마스크들과 매칭시키는 단계로서, 상기 예측된 마스크들은 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크 및 상기 프레임의 상기 하나 이상의 배경 구역들을 식별하는 상기 하나 이상의 배경 마스크들을 포함하는, 상기 예측된 마스크들과 매칭시키는 단계; 및상기 하나 이상의 배경 마스크들과 연관된 하나 이상의 IOU 스코어들이 임계치 미만이라는 결정에 기초하여 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하는 단계를 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서,상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 필터링하기 전에, 상기 깊이 맵에 적응적 가우시안 임계치화 및 잡음 감소를 적용하는 단계를 더 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>22. 제15항에 있어서, 상기 프레임은 단안 이미지 캡처 디바이스에 의해 생성된 단안 프레임을 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>23. 제15항에 있어서, 상기 제1 세그먼트화 맵 및 상기 제2 세그먼트화 맵은 하나 이상의 뉴럴 네트워크들을 사용하여 생성되는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>24. 제15항에 있어서, 뉴럴 네트워크를 사용하여 상기 깊이 맵을 생성하는 단계를 더 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>25. 제15항에 있어서,상기 프레임 및 상기 제2 세그먼트화 맵에 기초하여, 수정된 프레임을 생성하는 단계를 더 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 수정된 프레임은, 시각적 효과, 확장 현실 효과, 이미지 프로세싱 효과, 블러링 효과, 이미지 인식 효과, 객체 검출 효과, 컴퓨터 그래픽 효과, 크로마 키잉 효과, 및 이미지 스타일화 효과 중 적어도 하나를 포함하는, 이미지 세그먼트화를 위한 방법.</claim></claimInfo><claimInfo><claim>27. 명령들이 저장된 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 명령들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금,장면을 캡처하는 프레임을 획득하게 하고;상기 프레임에 기초하여, 관심 타겟을 식별하는 타겟 세그먼트화 마스크 및 상기 프레임의 하나 이상의 배경 구역들을 식별하는 하나 이상의 배경 마스크들을 포함하는 제1 세그먼트화 맵을 생성하게 하고;상기 하나 이상의 배경 마스크들이 필터링된 상기 제1 세그먼트화 맵을 포함하는 제2 세그먼트화 맵을 생성하게 하고, 상기 하나 이상의 배경 마스크들은 상기 프레임과 연관된 깊이 맵에 기초하여 상기 제1 세그먼트화 맵으로부터 필터링되는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 제2 세그먼트화 맵을 생성하는 것은,상기 제1 세그먼트화 맵과 상기 깊이 맵의 비교에 기초하여, 상기 하나 이상의 배경 마스크들과 연관된 개개의 깊이 값들과 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 연관된 개개의 깊이 값들 사이의 임계 차이를 결정하는 것을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 제2 세그먼트화 맵을 생성하는 것은,상기 하나 이상의 배경 마스크들과 연관된 개개의 깊이 값들과 상기 관심 타겟을 식별하는 상기 타겟 세그먼트화 마스크와 연관된 개개의 깊이 값들 사이의 상기 임계 차이에 기초하여, 상기 제1 세그먼트화 맵으로부터 상기 하나 이상의 배경 마스크들을 제거하는 것을 더 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>QI, YINGYONG</engName><name>치 잉용</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>LI, XIN</engName><name>리 신</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>YING, XIAOWEN</engName><name>잉 샤오원</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>ZHANG, SHUAI</engName><name>장 솨이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.05.23</receiptDate><receiptNumber>1-1-2024-0559830-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.07.02</receiptDate><receiptNumber>1-5-2024-0107893-80</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.14</receiptDate><receiptNumber>1-1-2024-1253783-32</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.11.14</receiptDate><receiptNumber>1-1-2024-1253784-88</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247017279.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9339559129063016ad7f96d21d50528f28b7e7f5bad6fcab8ff1118dc535e94229da7300f6c779615991ee216433e804b5a62334cfa7a72ef1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfcd380b118e10091f884ac6e4ca4bc7e23b7afe9df7448d9212498fd1020459497aa49e76131bc8aef386786ba69b05f9ce54ae3ec93814a7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>