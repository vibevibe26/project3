<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:43.643</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0184961</applicationNumber><claimCount>11</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 시스템 및 그 방법</inventionTitle><inventionTitleEng>System for accelerating a distributed deep  learning with data imbalance minimization and  method thereof</inventionTitleEng><openDate>2024.07.03</openDate><openNumber>10-2024-0102684</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.10.14</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/098</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/063</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 시스템에 관한 것이다. 상기 분산 딥러닝 가속화 시스템은, 각 노드의 학습 성능을 평가하고, 각 노드의 학습 성능에 따라 각 노드에서의 데이터당 학습 시간을 예측하고, 예측된 각 노드의 데이터당 예상 학습 시간을 이용하여 노드들의 학습시간이 균일하도록 데이터를 스케줄링하고, 스케줄링된 데이터를 워커들에게 할당하는 마스터; 및 상기 마스터로부터 할당된 데이터들을 이용하여 노드에서 딥러닝 모델을 학습시키고, 학습이 완료될 때 마다 각 노드의 학습 데이터의 크기 및 학습 시간으로 이루어진 피드백을 마스터로 전송하는 하나 또는 둘 이상의 워커들;을 구비하여, 학습 데이터의 불균형을 최소화시켜 분산 딥러닝의 학습 속도를 가속화시킨다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 시스템으로 이루어진 복수 개의 노드들로 구성된 클러스터를 이용하여 딥러닝 모델을 분산 학습시키는 분산 딥러닝 가속화 시스템에 있어서, 각 노드의 학습 성능을 평가하고, 각 노드의 학습 성능에 따라 각 노드에서의 데이터당 학습 시간을 예측하고, 예측된 각 노드의 데이터당 학습 시간을 이용하여 노드들의 학습시간이 동일하도록 데이터를 스케줄링하고, 스케줄링된 데이터를 워커들에게 할당하는 마스터; 및 상기 마스터로부터 할당된 데이터들을 이용하여 노드에서 딥러닝 모델을 학습시키고, 학습이 완료될 때 마다 각 노드의 학습 데이터의 크기 및 학습 시간으로 이루어진 피드백을 마스터로 전송하는 하나 또는 둘 이상의 워커들;을 구비하여, 학습 데이터의 불균형을 최소화시켜 분산 딥러닝의 학습 속도를 가속화시키는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 시스템. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 마스터는,워커로부터 전송된 학습한 데이터의 크기와 학습 시간의 집합들을 이용하여 노드의 성능 지표를 구하고, 성능 지표를 이용하여 각 노드의 성능을 평가하는 노드 성능 평가 모듈; 및학습 데이터의 크기와 노드의 성능 지표를 이용하여, 각 노드의 데이터 당 예상 학습 시간을 계산하고, 각 노드의 데이터당 예상 학습 시간을 이용하여 각 노드가 학습할 데이터를 할당하는 데이터 스케줄링 모듈;을 구비하여, 모든 노드의 예상 학습 시간이 균등하게 분포되도록, 각 노드에 할당되는 학습 데이터를 스케줄링하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 마스터는 한 세대의 학습이 완료되면, 다음 세대에서 각 노드의 총 학습 시간이 균일하도록, 각 노드가 다음 세대에서 학습할 데이터를 섞어 재배치하는 데이터 셔플링 모듈;을 더 구비하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 시스템.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 데이터 스케줄링 모듈은, 초기 배치 학습을 위하여 처음으로 할당하는 데이터는 무작위로 데이터를 선택하여 노드에게 할당하고, 그 후의 배치 학습에는, 노드 성능 평가 모듈에 의해 제공된 학습 데이터의 크기와 노드의 성능 지표를 이용하여, 각 노드의 데이터 당 예상 학습 시간을 계산하고, 각 노드의 데이터당 예상 학습 시간을 이용하여, 모든 노드의 예상 학습 시간이 균등하게 분포되도록, 각 노드에 할당되는 학습 데이터를 스케줄링하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 마스터는 각 노드에서 학습한 데이터의 크기에 비례하도록 학습률을 조정하여 학습률 보정을 하는 학습률 보정 모듈;을 더 구비하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 시스템.</claim></claimInfo><claimInfo><claim>6. 컴퓨팅 시스템에서 실행되는 마스터와 워커로 이루어진 프로그램으로 구현된 딥러닝 모델을 분산 학습시키는 분산 딥러닝 가속화 방법에 있어서, (a) 마스터에 의해, 각 노드의 학습 성능을 평가하고, 각 노드의 학습 성능에 따라 각 노드에서의 데이터당 학습 시간을 예측하고, 예측된 각 노드의 데이터당 학습 시간을 이용하여 노드들의 학습시간이 동일하도록 데이터를 스케줄링하고, 스케줄링된 데이터를 워커들에게 할당하는 단계; 및 (b) 워커에 의해, 상기 마스터로부터 할당된 데이터들을 이용하여 노드에서 딥러닝 모델을 학습시키고, 학습이 완료될 때 마다 각 노드의 학습 데이터의 크기 및 학습 시간으로 이루어진 피드백을 마스터로 전송하는 단계;를 구비하여, 학습 데이터의 불균형을 최소화시켜 분산 딥러닝의 학습 속도를 가속화시키는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 방법. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 (a) 단계는,(a1) 워커로부터 전송된 학습한 데이터의 크기와 학습 시간의 집합들을 이용하여 노드의 성능 지표를 구하고, 성능 지표를 이용하여 각 노드의 성능을 평가하는 단계; 및(a2) 학습 데이터의 크기와 노드의 성능 지표를 이용하여, 각 노드의 데이터 당 예상 학습 시간을 계산하고, 각 노드의 데이터당 예상 학습 시간을 이용하여 각 노드가 학습할 데이터를 할당하는 단계;를 구비하여, 모든 노드의 예상 학습 시간이 균등하게 분포되도록, 각 노드에 할당되는 학습 데이터를 스케줄링하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 (a) 단계는 (a3) 한 세대의 학습이 완료되면, 다음 세대에서 각 노드의 총 학습 시간이 균일하도록, 각 노드가 다음 세대에서 학습할 데이터를 섞어 재배치하는 데이터 셔플링 단계;를 더 구비하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서, 상기 (a2) 단계는, 초기 배치 학습을 위하여 처음으로 할당하는 데이터는 무작위로 데이터를 선택하여 노드에게 할당하고, 그 후의 배치 학습에는, 노드 성능 평가 모듈에 의해 제공된 학습 데이터의 크기와 노드의 성능 지표를 이용하여, 각 노드의 데이터 당 예상 학습 시간을 계산하고, 각 노드의 데이터당 예상 학습 시간을 이용하여, 모든 노드의 예상 학습 시간이 균등하게 분포되도록, 각 노드에 할당되는 학습 데이터를 스케줄링하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 방법.</claim></claimInfo><claimInfo><claim>10. 제7항에 있어서, 상기 (a) 단계는, (a4) 각 노드에서 학습한 데이터의 크기에 비례하도록 학습률을 조정하여 학습률 보정을 하는 단계;를 더 구비하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 방법.</claim></claimInfo><claimInfo><claim>11. 제6항에 있어서, 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 방법은, (c) 마스터가 학습 데이터에 대한 불균형 정도(Data Imbalance Factor)를 아래의 수학식에 따라 측정하는 단계;를 더 구비하는 것을 특징으로 하는 데이터 불균형 최소화를 이용한 분산 딥러닝 가속화 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 마포구...</address><code>220040246082</code><country>대한민국</country><engName>Sogang University Research &amp; Business Development Foundation</engName><name>서강대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 은평구...</address><code> </code><country> </country><engName>PARK, Sung Yong</engName><name>박성용</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>MAENG, Sanha</engName><name>맹산하</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 관악구 남부순환로 ****, ***호 제니스국제특허법률사무소 (봉천동, 청동빌딩)</address><code>919990002239</code><country>대한민국</country><engName>LEE,JI-YEON</engName><name>이지연</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.26</receiptDate><receiptNumber>1-1-2022-1401041-98</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.01.10</receiptDate><receiptNumber>4-1-2024-5014264-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.14</receiptDate><receiptNumber>1-1-2025-1147911-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220184961.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9335b8f4e2bc1ba459dc6b7a524782912b859f62642d5387885dd378f66fcd6a63146cca1452bc38a748ae2383e6eba924c77c6fb5e6723c53</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf8ea533a6a168101cdb812f63dab770c5ad4cbd156ebb5b4336bcb1fe0395b8c6fde3ace1aa6d7e65c0cbd4bcd1e1d3bc4e5f3d6a6509243e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>