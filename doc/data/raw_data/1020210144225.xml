<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:47.4147</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.10.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0144225</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>평면 검출 장치 및 방법</inventionTitle><inventionTitleEng>PLANAR SURFACE DETECTION APPARATUS AND METHOD</inventionTitleEng><openDate>2023.05.04</openDate><openNumber>10-2023-0060029</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/55</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 평면 검출 장치 및 방법에 관한 것이다. 일 실시 예에 따른 평면 검출 방법은 입력 영상의 픽셀 별 평면 파라미터를 획득하는 단계, 입력 영상의 픽셀 별 세그먼트 대응 확률을 추정하는 단계, 세그먼트 별 평면 파라미터를 획득하는 단계, 및 입력 영상에 포함된 평면을 검출하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 제1 네트워크에서 추정된 입력 영상의 픽셀 별 시차(disparity)에 기초하여, 상기 입력 영상의 픽셀 별 평면 파라미터를 획득하는 단계;영상의 세그멘테이션(segmentation)을 수행하도록 학습된 제2 네트워크에 기초하여, 상기 입력 영상의 픽셀 별 세그먼트 대응 확률을 추정하는 단계;상기 픽셀 별 평면 파라미터 및 상기 픽셀 별 세그먼트 대응 확률에 기초하여, 세그먼트 별 평면 파라미터를 획득하는 단계; 및상기 세그먼트 별 평면 파라미터에 기초하여, 상기 입력 영상에 포함된 평면을 검출하는 단계를 포함하는,평면 검출 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 입력 영상에 포함된 평면을 검출하는 단계는상기 픽셀 별 세그먼트 대응 확률에 기초하여, 픽셀 별 세그먼트 클러스터링 정보를 획득하는 단계; 및상기 세그먼트 별 평면 파라미터 및 상기 픽셀 별 세그먼트 클러스터링 정보에 기초하여, 상기 입력 영상에 포함된 평면을 검출하는 단계를 포함하는,평면 검출 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 세그먼트 별 평면 파라미터를 획득하는 단계는상기 제2 네트워크에 기초한 상기 입력 영상 내 세그먼트들 각각에 대응하여, 해당 세그먼트에 대응하는 상기 픽셀 별 세그먼트 대응 확률에 기초  하여, 상기 픽셀 별 평면 파라미터를 가중 합하는 단계; 및 상기 가중 합된 평면 파라미터에 기초하여, 상기 해당 세그먼트에 대  응하는 평면 파라미터를 획득하는 단계를 포함하는,평면 검출 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제1 네트워크 및 상기 제2 네트워크는상기 제2 네트워크에 기초하여 클러스터링된 각 세그먼트에 대응하는 평면 파라미터의 확률 분포에 기초하여 계산된, 각 픽셀이 각 세그먼트에 대응될 확률로 정의되는 우도(likelihood)에 관한 제1 로스; 및제1 영상에 대응하여 상기 제1 네트워크에서 추정된 시차에 기초하여 상기 제1 영상에 대응하는 제2 영상을 변환한 영상 및 상기 제1 영상의 차이에 관한 제2 로스중 적어도 하나에 기초하여 학습된평면 검출 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 픽셀 별 평면 파라미터를 획득하는 단계는상기 제1 네트워크에 기초하여, 상기 입력 영상의 픽셀 별 시차를 추정하는 단계; 및상기 입력 영상을 촬영한 카메라의 내부 파라미터(intrinsic parameter)에 기초하여, 상기 픽셀 별 시차로부터 법선 벡터 및 거리 정보를 포함하는 상기 픽셀 별 평면 파라미터를 획득하는 단계를 포함하는,평면 검출 방법.</claim></claimInfo><claimInfo><claim>6. 학습 데이터에 포함된 제1 영상을 제1 네트워크에 인가하여 획득된 상기 제1 영상의 픽셀 별 시차에 기초하여, 상기 제1 영상의 픽셀 별 평면 파라미터를 획득하는 단계;상기 제1 영상을 제2 네트워크에 인가하여, 상기 제1 영상의 픽셀 별 세그먼트 대응 확률을 추정하는 단계; 및상기 제1 영상의 픽셀 별 평면 파라미터 및 상기 제1 영상의 픽셀 별 세그먼트 대응 확률에 기초하여 계산된, 상기 제1 영상의 각 픽셀이 각 세그먼트에 대응될 확률로 정의되는 우도(likelihood)에 관한 제1 로스에 기초하여, 상기 제1 네트워크 및 상기 제2 네트워크를 학습시키는 단계를 포함하는,평면 검출 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 제1 영상의 각 픽셀이 각 세그먼트에 대응될 확률은미리 정해진 개수의 세그먼트들 각각에 대응하는 평면 파라미터에 관한 확률 분포 및 상기 픽셀 별 평면 파라미터에 기초하여 계산되는,평면 검출 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 미리 정해진 세그먼트들 각각에 대응하는 평면 파라미터에 관한 확률 분포는상기 픽셀 별 세그먼트 대응 확률 및 상기 픽셀 별 평면 파라미터에 기초하여 계산된 상기 세그먼트들 각각에 대응하는 평면 파라미터의 대표 값; 및상기 픽셀 별 세그먼트 대응 확률, 상기 픽셀 별 평면 파라미터 및 상기 세그먼트들 각각에 대응하는 평면 파라미터의 대표 값에 기초하여 계산된, 상기 세그먼트들 각각에 대응하는 평면 파라미터의 분산을 포함하는,평면 검출 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,상기 제1 네트워크 및 상기 제2 네트워크를 학습시키는 단계는상기 제1 네트워크에서 상기 제1 영상에 대응하여 추정된 깊이에 기초하여, 상기 제1 영상과 다른 시점에서 촬영된 제2 영상을 변환하는 단계; 및상기 변환된 영상과 상기 제1 영상의 차이에 관한 제2 로스 및 상기 제1 로스에 기초하여, 상기 제1 네트워크 및 상기 제2 네트워크를 학습시키는 단계를 포함하는,평면 검출 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>10. 제6항에 있어서,상기 학습 데이터는스테레오 영상의 제1 단안 영상인 상기 제1 영상 및 상기 스테레오 영상의 제2 단안 영상인 제2 영상; 및비디오 영상의 제1 프레임인 상기 제1 영상 및 상기 비디오 영상의 제2 프레임인 제2 영상중 적어도 하나를 포함하는,평면 검출 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>11. 제6항에 있어서,상기 픽셀 별 평면 파라미터를 획득하는 단계는상기 제1 영상을 상기 제1 네트워크에 인가하여, 상기 제1 영상의 픽셀 별 시차를 추정하는 단계; 및상기 제1 영상을 촬영한 카메라의 내부 파라미터에 기초하여, 상기 픽셀 별 시차로부터 법선 벡터 및 거리 정보를 포함하는 상기 픽셀 별 평면 파라미터를 획득하는 단계를 포함하는,평면 검출 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>12. 하드웨어와 결합되어 제1항 내지 제11항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 제1 네트워크에서 추정된 입력 영상의 픽셀 별 시차(disparity)에 기초하여, 상기 입력 영상의 픽셀 별 평면 파라미터를 획득하고,영상의 세그멘테이션(segmentation)을 수행하도록 학습된 제2 네트워크에 기초하여, 상기 입력 영상의 픽셀 별 세그먼트 대응 확률을 추정하고,상기 픽셀 별 평면 파라미터 및 상기 픽셀 별 세그먼트 대응 확률에 기초하여, 세그먼트 별 평면 파라미터를 획득하며,상기 세그먼트 별 평면 파라미터에 기초하여, 상기 입력 영상에 포함된 평면을 검출하는,적어도 하나의 프로세서를 포함하는,평면 검출 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 프로세서는,상기 입력 영상에 포함된 평면을 검출함에 있어서,상기 픽셀 별 세그먼트 대응 확률에 기초하여, 픽셀 별 세그먼트 클러스터링 정보를 획득하고,상기 세그먼트 별 평면 파라미터 및 상기 픽셀 별 세그먼트 클러스터링 정보에 기초하여, 상기 입력 영상에 포함된 평면을 검출하는,평면 검출 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 프로세서는,상기 세그먼트 별 평면 파라미터를 획득함에 있어서,상기 제2 네트워크에 기초한 상기 입력 영상 내 세그먼트들 각각에 대응하여, 해당 세그먼트에 대응하는 상기 픽셀 별 세그먼트 대응 확률에 기초  하여, 상기 픽셀 별 평면 파라미터를 가중 합하고, 상기 가중 합된 평면 파라미터에 기초하여, 상기 해당 세그먼트에 대  응하는 평면 파라미터를 획득하는,평면 검출 장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 제1 네트워크 및 상기 제2 네트워크는상기 제2 네트워크에 기초하여 클러스터링된 각 세그먼트에 대응하는 평면 파라미터의 확률 분포에 기초하여 계산된, 각 픽셀이 각 세그먼트에 대응될 확률로 정의되는 우도(likelihood)에 관한 제1 로스; 및제1 영상에 대응하여 상기 제1 네트워크에서 추정된 시차에 기초하여 상기 제1 영상에 대응하는 제2 영상을 변환한 영상 및 상기 제1 영상의 차이에 관한 제2 로스중 적어도 하나에 기초하여 학습된,평면 검출 장치.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서,상기 프로세서는,상기 픽셀 별 평면 파라미터를 획득함에 있어서,상기 제1 네트워크에 기초하여, 상기 입력 영상의 픽셀 별 시차를 추정하고,상기 입력 영상을 촬영한 카메라의 내부 파라미터(intrinsic parameter)에 기초하여, 상기 픽셀 별 시차로부터 법선 벡터 및 거리 정보를 포함하는 상기 픽셀 별 평면 파라미터를 획득하는,평면 검출 장치.</claim></claimInfo><claimInfo><claim>18. 평면 검출 장치에 있어서,입력된 영상의 시차를 추정하는 제1 네트워크 및 입력된 영상의 세그멘테이션을 수행하는 제2 네트워크를 포함하는 평면 검출 모델이 기록된 메모리를 포함하고,상기 평면 검출 모델은학습 데이터에 포함된 제1 영상을 제1 네트워크에 인가하여 획득된 상기 제1 영상의 픽셀 별 시차에 기초하여, 상기 제1 영상의 픽셀 별 평면 파라미터를 획득하는 단계;상기 제1 영상을 제2 네트워크에 인가하여, 상기 제1 영상의 픽셀 별 세그먼트 대응 확률을 추정하는 단계; 및상기 제1 영상의 픽셀 별 평면 파라미터 및 상기 제1 영상의 픽셀 별 세그먼트 대응 확률에 기초하여 계산된, 상기 제1 영상의 각 픽셀이 각 세그먼트에 대응될 확률로 정의되는 우도(likelihood)에 관한 제1 로스에 기초하여, 상기 제1 네트워크 및 상기 제2 네트워크를 학습시키는 단계를 포함하는 상기 평면 검출 모델의 학습 방법에 의해 제조되는,평면 검출 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 평면 검출 모델의 학습 방법에 포함된 상기 제1 네트워크 및 상기 제2 네트워크를 학습시키는 단계는상기 제1 네트워크에서 상기 제1 영상에 대응하여 추정된 깊이에 기초하여, 상기 제1 영상과 다른 시점에서 촬영된 제2 영상을 변환하는 단계; 및상기 변환된 영상과 상기 제1 영상의 차이에 관한 제2 로스 및 상기 제1 로스에 기초하여, 상기 제1 네트워크 및 상기 제2 네트워크를 학습시키는 단계를 포함하는,평면 검출 장치.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,입력 영상을 상기 제1 네트워크에 인가하여, 상기 제1 네트워크에서 추정된 상기 입력 영상의 픽셀 별 시차(disparity)에 기초하여, 상기 입력 영상의 픽셀 별 평면 파라미터를 획득하고,상기 입력 영상을 상기 제2 네트워크에 인가하여, 상기 제2 네트워크에서 추정된 상기 입력 영상의 픽셀 별 세그먼트 대응 확률을 획득하고,상기 픽셀 별 평면 파라미터 및 상기 픽셀 별 세그먼트 대응 확률에 기초하여, 세그먼트 별 평면 파라미터를 획득하며,상기 세그먼트 별 평면 파라미터에 기초하여, 상기 입력 영상에 포함된 평면을 검출하는,적어도 하나의 프로세서를 더 포함하는,평면 검출 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420190573582</code><country>대한민국</country><engName>KIM, Seung Eon</engName><name>김승언</name></inventorInfo><inventorInfo><address>서울특별시 송파구...</address><code>420170474303</code><country>대한민국</country><engName>CHANG, Hyun Sung</engName><name>장현성</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170474144</code><country>대한민국</country><engName>LEE, Won Hee</engName><name>이원희</name></inventorInfo><inventorInfo><address>경기도 안양시 동안구...</address><code>420190614365</code><country>대한민국</country><engName>Jang, Seokhwan</engName><name>장석환</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.10.27</receiptDate><receiptNumber>1-1-2021-1232137-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.26</receiptDate><receiptNumber>1-1-2024-1050416-41</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210144225.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93849d30ec9042998696e8d6d73ffa20171c0e92d90016bfcb5c0e63a911f4c04f5de02cc957d94deda30f70a8fa8dba8c7eb0404663a9cc9f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf5befe351e29e6ebf165cea88898fedd5de1660e8f177e7baba58db86a4a995c1873aa1dbc6ef9fd260af97d718b05bef874dc8d8b6032304</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>