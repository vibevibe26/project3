<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:36:58.3658</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0168658</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지를 투사하는 로봇 및 그의 이미지 투사 방법</inventionTitle><inventionTitleEng>ROBOT FOR PROJECTING IMAGE AND METHOD FOR PROJECTING  IMAGE THEREOF</inventionTitleEng><openDate>2025.06.05</openDate><openNumber>10-2025-0080654</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 19/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2015.01.01)</ipcDate><ipcNumber>G03B 21/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 로봇이 개시된다. 본 로봇은 프로젝터, 센서 및 센서를 이용하여 사용자 주변을 센싱하여 획득한 정보에 기초하여 복수의 후보 투사 영역을 식별하고, 복수의 후보 투사 영역의 우선 순위를 식별하고, 복수의 후보 투사 영역의 위치 및 복수의 후보 투사 영역의 우선 순위에 기초하여 복수의 후보 투사 영역을 포함하는 영역에 이미지를 투사하도록 프로젝터를 제어하여, 복수의 후보 투사 영역의 우선 순위에 대한 정보를, 복수의 후보 투사 영역에 동시에 표시하거나 복수의 후보 투사 영역에 순차적으로 표시하고, 복수의 후보 투사 영역 중 사용자 입력에 기초하여 선택된 후보 투사 영역을 투사 영역인 것으로 식별하며, 프로젝터를 이용하여 투사 영역에 이미지 컨텐츠를 투사하는 하나 이상의 프로세서를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 로봇에 있어서,프로젝터;센서; 및상기 센서를 이용하여 사용자 주변을 센싱하여 획득한 정보에 기초하여 복수의 후보 투사 영역을 식별하고,상기 복수의 후보 투사 영역의 우선 순위를 식별하고,상기 복수의 후보 투사 영역의 위치 및 상기 복수의 후보 투사 영역의 우선 순위에 기초하여 상기 복수의 후보 투사 영역을 포함하는 영역에 이미지를 투사하도록 상기 프로젝터를 제어하여, 상기 복수의 후보 투사 영역의 우선 순위에 대한 정보를, 상기 복수의 후보 투사 영역에 동시에 표시하거나 상기 복수의 후보 투사 영역에 순차적으로 표시하고, 상기 복수의 후보 투사 영역 중 사용자 입력에 기초하여 선택된 후보 투사 영역을 투사 영역인 것으로 식별하며,상기 프로젝터를 이용하여 상기 투사 영역에 이미지 컨텐츠를 투사하는 하나 이상의 프로세서;를 포함하는 로봇.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 하나 이상의 프로세서는, 상기 복수의 후보 투사 영역의 위치에 기초하여 상기 영역에 투사될 이미지에서 상기 복수의 후보 투사 영역에 대응되는 복수의 영역을 식별하고,복수의 서브 이미지가 상기 복수의 영역에 포함된 상기 이미지를 투사하도록 상기 프로젝터를 제어하고, 상기 복수의 서브 이미지 각각은, 상기 복수의 후보 투사 영역 각각의 우선 순위에 대응되는 인디케이터를 포함하는 로봇. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 인디케이터는, 후보 투사 영역의 우선 순위를 나타내는 숫자를 포함하는 로봇. </claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 하나 이상의 프로세서는,후보 투사 영역 별로 후보 투사 영역의 위치에 기초하여 상기 영역에 투사될 이미지에서 상기 후보 투사 영역에 대응되는 영역을 식별하고,각 서브 이미지가 각 영역에 포함된 복수의 이미지를 순차적으로 투사하도록 상기 프로젝터를 제어하고,상기 각 서브 이미지는, 상기 복수의 후보 투사 영역 각각의 우선 순위에 대응되는 인디케이터를 포함하는 로봇. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 인디케이터는, 후보 투사 영역의 우선 순위를 나타내는 숫자를 포함하는 로봇. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 하나 이상의 프로세서는,상기 복수의 후보 투사 영역 각각의 크기 및 상기 사용자와 상기 복수의 후보 투사 영역 각각 간의 거리에 기초하여 상기 복수의 후보 투사 영역의 우선 순위를 식별하는 로봇.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 하나 이상의 프로세서는,상기 센서를 이용하여 상기 사용자 주변을 센싱하여 획득한 정보에 기초하여 상기 사용자 주변에 대한 3차원 맵을 생성하고, 상기 3차원 맵에 기초하여 상기 사용자 주변에서 평면을 식별하고,상기 식별된 평면 상에서 종횡비가 투사 이미지의 종횡비와 같은 복수의 영역을 식별하고, 상기 복수의 영역의 특성에 기초하여 상기 복수의 영역 중 상기 복수의 후보 투사 영역을 식별하는 로봇.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 하나 이상의 프로세서는,상기 복수의 영역에 포함된 포인트들의 RGB 값에 기초하여 상기 복수의 영역 중 채도가 임계값 이상인 영역이 식별되면, 상기 복수의 영역 중 상기 식별된 영역을 제외한 나머지 영역을 상기 복수의 후보 투사 영역인 것으로 식별하는 로봇.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 하나 이상의 프로세서는,상기 센서를 이용하여 이미지를 획득하고,상기 이미지에서 식별된 사용자의 위치 및 상기 센서의 시야각에 기초하여 상기 센서의 회전 각도 범위를 식별하고,상기 회전 각도 범위 내에서 상기 센서가 회전하는 동안 상기 센서를 이용하여 상기 정보를 획득하는 로봇. </claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 하나 이상의 프로세서는,상기 획득된 이미지에서 상기 사용자에 대한 바운딩 박스를 획득하고, 상기 획득된 이미지의 중심 픽셀 및 상기 바운딩 박스의 픽셀 간의 픽셀 거리를 식별하고,상기 센서의 초점 거리 및 상기 픽셀 거리에 기초하여 상기 센서의 회전 각도 범위를 식별하는 로봇.</claim></claimInfo><claimInfo><claim>11. 프로젝터를 포함하는 로봇의 이미지 투사 방법에 있어서,사용자 주변을 센싱하여 획득한 정보에 기초하여 복수의 후보 투사 영역을 식별하는 단계; 상기 복수의 후보 투사 영역의 우선 순위를 식별하는 단계;상기 복수의 후보 투사 영역의 위치 및 상기 복수의 후보 투사 영역의 우선 순위에 기초하여 상기 복수의 후보 투사 영역을 포함하는 영역에 이미지를 투사하도록 상기 프로젝터를 제어하여, 상기 복수의 후보 투사 영역의 우선 순위에 대한 정보를, 상기 복수의 후보 투사 영역에 동시에 표시하거나 상기 복수의 후보 투사 영역에 순차적으로 표시하는 단계; 상기 복수의 후보 투사 영역 중 사용자 입력에 기초하여 선택된 후보 투사 영역을 투사 영역인 것으로 식별하는 단계; 및상기 프로젝터를 이용하여 상기 투사 영역에 이미지 컨텐츠를 투사하는 단계;를 포함하는 이미지 투사 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 표시하는 단계는, 상기 복수의 후보 투사 영역의 위치에 기초하여 상기 영역에 투사될 이미지에서 상기 복수의 후보 투사 영역에 대응되는 복수의 영역을 식별하는 단계; 및 복수의 서브 이미지가 상기 복수의 영역에 포함된 상기 이미지를 투사하도록 상기 프로젝터를 제어하는 단계;를 포함하고, 상기 복수의 서브 이미지 각각은, 상기 복수의 후보 투사 영역 각각의 우선 순위에 대응되는 인디케이터를 포함하는 이미지 투사 방법. </claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 인디케이터는, 후보 투사 영역의 우선 순위를 나타내는 숫자를 포함하는 이미지 투사 방법. </claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,상기 표시하는 단계는,후보 투사 영역 별로 후보 투사 영역의 위치에 기초하여 상기 영역에 투사될 이미지에서 상기 후보 투사 영역에 대응되는 영역을 식별하는 단계; 및각 서브 이미지가 각 영역에 포함된 복수의 이미지를 순차적으로 투사하도록 상기 프로젝터를 제어하는 단계;를 포함하고, 상기 각 서브 이미지는, 상기 복수의 후보 투사 영역 각각의 우선 순위에 대응되는 인디케이터를 포함하는 이미지 투사 방법. </claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 인디케이터는, 후보 투사 영역의 우선 순위를 나타내는 숫자를 포함하는 이미지 투사 방법. </claim></claimInfo><claimInfo><claim>16. 제11항에 있어서,상기 복수의 후보 투사 영역의 우선 순위를 식별하는 단계는,상기 복수의 후보 투사 영역 각각의 크기 및 상기 사용자와 상기 복수의 후보 투사 영역 각각 간의 거리에 기초하여 상기 복수의 후보 투사 영역의 우선 순위를 식별하는 단계;를 포함하는 이미지 투사 방법.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 복수의 후보 투사 영역을 식별하는 단계는,센서를 이용하여 상기 사용자 주변을 센싱하여 획득한 정보에 기초하여 상기 사용자 주변에 대한 3차원 맵을 생성하는 단계; 상기 3차원 맵에 기초하여 상기 사용자 주변에서 평면을 식별하는 단계;상기 식별된 평면 상에서 종횡비가 투사 이미지의 종횡비와 같은 복수의 영역을 식별하는 단계; 및상기 복수의 영역의 특성에 기초하여 상기 복수의 영역 중 상기 복수의 후보 투사 영역을 식별하는 단계;를 포함하는 이미지 투사 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 복수의 영역 중 상기 복수의 후보 투사 영역을 식별하는 단계는,상기 복수의 영역에 포함된 포인트들의 RGB 값에 기초하여 상기 복수의 영역 중 채도가 임계값 이상인 영역이 식별되면, 상기 복수의 영역 중 상기 식별된 영역을 제외한 나머지 영역을 상기 복수의 후보 투사 영역인 것으로 식별하는 단계;를 포함하는 이미지 투사 방법.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서,상기 복수의 후보 투사 영역을 식별하는 단계는,센서를 이용하여 이미지를 획득하는 단계;상기 이미지에서 식별된 사용자의 위치 및 상기 센서의 시야각에 기초하여 상기 센서의 회전 각도 범위를 식별하는 단계; 및 상기 회전 각도 범위 내에서 상기 센서가 회전하는 동안 상기 센서를 이용하여 상기 정보를 획득하는 단계;를 포함하는 이미지 투사 방법. </claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 센서의 회전 각도 범위를 식별하는 단계는,상기 획득된 이미지에서 상기 사용자에 대한 바운딩 박스를 획득하는 단계;상기 획득된 이미지의 중심 픽셀 및 상기 바운딩 박스의 픽셀 간의 픽셀 거리를 식별하는 단계; 및 상기 센서의 초점 거리 및 상기 픽셀 거리에 기초하여 상기 센서의 회전 각도 범위를 식별하는 단계;를 포함하는 이미지 투사 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Jae Ha</engName><name>이재하</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Do Hoon</engName><name>김도훈</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Yeon Jun</engName><name>이연준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>MOON, Bo Seok</engName><name>문보석</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.28</receiptDate><receiptNumber>1-1-2023-1332820-86</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230168658.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9304efce1a7c3df1c670de5c0af40ce0be8c0a469c12a7c98f7336e76cad8db693c5aee4d772ffb8a1fa6e24fa27778d3da0ba62d4597a85a2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0858ab838100205e1f4605c16f6edfe2131c2c095e7f697b297a1ba2e31746d79c19cad205a9d01cdd51e0a4b4bc0282684d20e473555334</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>