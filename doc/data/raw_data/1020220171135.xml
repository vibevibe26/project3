<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:12.5112</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0171135</applicationNumber><claimCount>1</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법</inventionTitle><inventionTitleEng>CONCENTRATION MEASUREMENT SYSTEM AND METHOD THROUGH  POSTURE AND MOVEMENT RECOGNITION</inventionTitleEng><openDate>2024.06.18</openDate><openNumber>10-2024-0086017</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.12.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A61B 5/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2025.01.01)</ipcDate><ipcNumber>A61B 5/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 실시예에 따른 자세 및 움직임인식을 통한 집중력 측정 시스템 및 방법은 집중력을 평가하는 객관적인 지표를 예측 정확도 형태로 산출하여, 온라인 학습을 하는 참가자들의 집중도를 평가한다. 실시예에서는 컴퓨터비전 라이브러리를 이용해 학습자 자세의 위치 데이터를 수집하고, 교육학 이론 데이터에 따라 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표의 총 세 가지 측정 항목을 예측 정확도로서 산출한다. 일반적으로 학생들은 수업에 집중할 때 두드러지는 움직임 없이 화면을 바라보며 바르게 앉은 자세를 취하기 때문에, 실시예에서는 학생의 두 눈, 두 귀, 두 어깨, 코, 목, 척추 등을 포함하는 관측 노드의 위치데이터를 계산하고, 관측 노드의 위치 데이터를 기반으로 세 가지 측정 지표를 산출하여 집중도를 결정한다. 또한, 실시예에서는 OpenPose 신경망, DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 테스트 데이터 셋으로 학습시켜 학습 집중도 및 효율성 판단 모델을 구현한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 자세 및 움직임인식을 통한 집중력 측정 시스템에 있어서, 수업, 스터디를 포함하는 온라인 학습 중 학생의 학습 모습을 촬영한 분석 영상을 생성하여 서버로 전송하는 학생 단말;학생 별 학습 모습을 촬영한 분석 영상에서 영상에 포함된 객체의 자세 및 움직임을 인식을 위해, 학습자의 두 눈, 코, 두 어깨, 두 귀를 포함하는 관측 노드의 위치 데이터를 추출하고, 추출된 관측 노드의 위치 데이터를 기반으로 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정하여 측정 결과에 따라 학생의 집중도를 평가하는 서버; 를 포함하는 자세 및 움직임 인식을 통한 집중력 측정 시스템. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 서버; 는학생 단말로부터 학생의 학습 모습을 촬영한 분석 영상을 수집하는 영상 수집 모듈;수집된 분석 영상에서 학생 객체가 포함된 이미지를 순차 추출하고, 추출된 이미지 각각에서 두 눈, 두 귀, 코, 목, 두 어깨를 포함하는 관측 노드 각각의 위치 데이터를 추출하는 위치 데이터 추출 모듈; 추출된 관측 노드 각각의 위치 데이터를 기반으로 정면 얼굴의 관측도를 나타낸 정면 얼굴 감지 지표, 움직임 정도를 나타낸 신체 움직임 감지 지표 및 척추의 휨 정도를 나타낸 척추 측만 가능성 지표를 측정하는 지표 측정 모듈;측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표와 기 설정된 집중력 평가 기준을 비교하여 학생의 집중도를 평가하는 평가 모듈; 을 포함하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 평가 모듈; 은 정면 얼굴 관측도를 나타낸 정면 얼굴 감지 지표에 비례하여 집중도를 평가하고, 움직임 정도를 나타낸 신체 움직임 감지 지표에 반비례하도록 집중도를 평가하고, 척추 휨 정도를 나타낸 척추 측만 가능성 지표에 반비례하도록 집중도를 평가하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템.</claim></claimInfo><claimInfo><claim>4. 제 2항에 있어서, 상기 지표 측정 모듈; 은 관측 노드 각각의 위치데이터 별 이동량을 산출하고 산출된 위치데이터 각각의 이동량을 이용하여 신체 움직임 감지 지표를 측정하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서, 상기 평가모듈; 은 OpenPose 신경망, DNN(Deep Neural Network), CNN(Convolutional Neural Network) RNN(Recurrent Neural Network) 및 BRDNN(Bidirectional Recurrent Deep Neural Network) 중 적어도 하나를 포함하는 딥러닝 뉴럴 네트워크를 테스트 데이터 셋으로 학습시켜 학습 집중도 및 효율성 판단 모델을 구현하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템.      </claim></claimInfo><claimInfo><claim>6. 제2항에 있어서, 상기 지표 측정 모듈은 검출된 학생의 얼굴과 몸통의 위치를 계산하는 1단계, 얼굴과 몸통의 움직임을 계산하는 2단계, 얼굴과 몸통 사이 거리를 산출하는 3단계 및 정상화된 움직임을 계산하는 4단계를 통해 신체 움직임 감지 지표를 산출하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템.    </claim></claimInfo><claimInfo><claim>7. 제 2항에 있어서, 상기 지표 측정 모듈; 은정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 인공지능 데이터 셋을 통해 예측한 예측 정확도로서 측정하여,관측 노드들의 위치에 따라 정면 얼굴 감지 지표는 정면 얼굴일 확률, 신체 움직임 감지 지표는 움직임 확률, 척추 측만 가능성 지표는 척추 측만일 확률을 나타내는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 시스템.</claim></claimInfo><claimInfo><claim>8. 자세 및 움직임인식을 통한 집중력 측정 방법에 있어서, (A) 학생 단말에서 수업, 스터디를 포함하는 온라인 학습 중 학생의 학습 모습을 촬영한 분석 영상을 생성하여 서버로 전송하는 단계;(B) 서버에서 학생 별 학습 모습을 촬영한 분석 영상에서 영상에 포함된 객체의 자세 및 움직임을 인식을 위해, 학습자의 두 눈, 코, 두 어깨, 두 귀를 포함하는 관측 노드의 위치 데이터를 추출하고, 추출된 관측 노드의 위치 데이터를 기반으로 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표를 측정하여 측정 결과에 따라 학생의 집중도를 평가하는 단계; 를 포함하는 자세 및 움직임 인식을 통한 집중력 측정 방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 (B)의 단계; 는(B-1) 학생 단말로부터 학생의 학습 모습을 촬영한 분석 영상을 수집하는 단계;(B-2) 수집된 분석 영상에서 학생 객체가 포함된 이미지를 순차 추출하고, 추출된 이미지 각각에서 두 눈, 두 귀, 코, 목, 두 어깨를 포함하는 관측 노드 각각의 위치 데이터를 추출하는 단계; (B-3) 추출된 관측 노드 각각의 위치 데이터를 기반으로 정면 얼굴의 관측도를 나타낸 정면 얼굴 감지 지표, 움직임 정도를 나타낸 신체 움직임 감지 지표 및 척추의 휨 정도를 나타낸 척추 측만 가능성 지표를 측정하는 단계;(B-4) 측정된 정면 얼굴 감지 지표, 신체 움직임 감지 지표 및 척추 측만 가능성 지표와 기 설정된 집중력 평가 기준을 비교하여 학생의 집중도를 평가하는 단계; 를 포함하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 방법. </claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 (B-3)의 단계; 는  검출된 학생의 얼굴과 몸통의 위치를 계산하는 1단계, 얼굴과 몸통의 움직임을 계산하는 2단계, 얼굴과 몸통 사이 거리를 산출하는 3단계 및 정상화된 움직임을 계산하는 4단계를 통해 신체 움직임 감지 지표를 산출하는 것을 특징으로 하는 자세 및 움직임 인식을 통한 집중력 측정 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 고양시 일산동구...</address><code>420180462420</code><country>대한민국</country><engName>Kim, YeonJun</engName><name>김연준</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 고양시 일산동구...</address><code>420180462420</code><country>대한민국</country><engName>Kim, YeonJun</engName><name>김연준</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, **층 유니스특허법률사무소 (역삼동, 윤익빌딩)</address><code>919980003768</code><country>대한민국</country><engName>YOON, Eui Seoup</engName><name>윤의섭</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.09</receiptDate><receiptNumber>1-1-2022-1324645-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.01.05</receiptDate><receiptNumber>1-1-2023-0017134-94</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2023.10.24</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2023.11.30</receiptDate><receiptNumber>9-6-2025-0052645-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.03.21</receiptDate><receiptNumber>9-5-2025-0284289-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.05.20</receiptDate><receiptNumber>1-1-2025-0564916-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.05.20</receiptDate><receiptNumber>1-1-2025-0564886-53</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.05.30</receiptDate><receiptNumber>1-1-2025-0609821-96</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220171135.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931194c726994ccc15721fd988cfbcea7bc99e9bd46b2f486e8c54881aad27c9ec23f9713f226c28e296ea801e60618d98ad2568f6e821c7e1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe154255f5b425e9ada0bd23e90c247be5608aa35dc33568ff02ffa1482fff650c9ae4e43953d73efde3caf46b6f78d60b85ae392e7874a22</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>