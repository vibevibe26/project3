<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:16:27.1627</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.10.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2019-0121363</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>음성 인식을 수행하는 인공 지능 장치 및 그 방법</inventionTitle><inventionTitleEng>AN ARTIFICIAL INTELLIGENCE APPARATUS FOR PERFORMING  SPEECH RECOGNITION AND METHOD FOR THE SAME</inventionTitleEng><openDate>2021.04.09</openDate><openNumber>10-2021-0039049</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.08.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 실시 예는 사용자의 음성 명령을 입력 받는 마이크로폰, 소정의 텍스트 데이터에 포함된 대용어를 판별하는 대용어 인식 모델을 이용하여, 음성 명령에 대응하는 텍스트 데이터에 포함된 대용어를 판별하는 러닝 프로세서 및 인공 지능 장치로 입력되거나 인공 지능 장치를 통해 출력된 정보를 포함하는 컨텍스트 정보를 기초로 판별된 대용어가 지칭하는 지칭 대상을 특정하고, 특정된 지칭 대상을 기초로 음성 명령에 대한 응답을 판별하고, 판별된 응답에 따라 인공 지능 장치를 제어하는 프로세서를 포함하는 인공 지능 장치를 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 음성 인식을 수행하는 인공 지능 장치에 있어서,사용자의 음성 명령을 입력 받는 마이크로폰;소정의 텍스트 데이터에 포함된 대용어를 판별하는 대용어 인식 모델을 이용하여, 상기 음성 명령에 대응하는 텍스트 데이터에 포함된 대용어를 판별하는 러닝 프로세서; 및상기 인공 지능 장치로 입력되거나 상기 인공 지능 장치를 통해 출력된 정보를 포함하는 컨텍스트 정보를 기초로 상기 판별된 대용어가 지칭하는 지칭 대상을 특정하고, 상기 특정된 지칭 대상을 기초로 상기 음성 명령에 대한 응답을 판별하고, 상기 판별된 응답에 따라 상기 인공 지능 장치를 제어하는 프로세서를 포함하는,인공 지능 장치. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 컨텍스트 정보는, 상기 인공 지능 장치의 디스플레이를 통해 출력되는 출력 콘텐츠에 대한 정보 및 상기 사용자로부터 선택된 선택 콘텐츠에 대한 정보 중 적어도 하나를 포함하는 화면 컨텍스트 정보를 포함하는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 프로세서는, 상기 선택 콘텐츠가 적어도 하나 이상 존재하는 경우, 상기 선택 콘텐츠에 기초하여 상기 대용어가 지칭하는 지칭 대상을 특정하는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 프로세서는, 상기 출력 콘텐츠가 상기 디스플레이에 풀스크린으로 출력되는 풀스크린 콘텐츠인 경우, 상기 풀스크린 콘텐츠에 기초하여 상기 대용어가 지칭하는 지칭 대상을 특정하는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 컨텍스트 정보는, 상기 사용자와 상기 인공 지능 장치간 음성 명령 및 음성 명령에 대한 응답을 통한 대화 내역에 대한 정보인 대화 컨텍스트 정보를 포함하는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 대용어는, 인물 또는 사물과 인접한 대상을 지칭하는 인접 대용어 및 인물 또는 사물과 인접하지 않은 대상을 지칭하는 비인접 대용어 중 적어도 하나를 포함하고, 상기 러닝 프로세서는, 상기 대용어 인식 모델을 이용하여 상기 음성 명령에 대응하는 텍스트 데이터에 포함된 인접 대용어 또는 비인접 대용어를 판별하는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 프로세서는, 상기 화면 컨텍스트 정보를 기초로 상기 판별된 인접 대용어가 지칭하는 지칭 대상을 특정하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 프로세서는, 상기 대화 컨텍스트 정보를 기초로 상기 판별된 비인접 대용어가 지칭하는 지칭 대상을 특정하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 대화 컨텍스트 정보는, 상기 대화 내역에 포함된 각각의 음성 명령에 대응하는 텍스트 데이터에 포함된 대용어 지칭 대상 후보에 대한 정보를 포함하고, 상기 프로세서는, 상기 대용어 지칭 대상 후보를 기초로 상기 판별된 비인접 대용어가 지칭하는 지칭 대상을 특정하는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 대용어 인식 모델은,상기 소정의 텍스트 데이터가 입력 레이어에 입력되는 경우 입력된 소정의 텍스트 데이터에 포함된 문자 또는 단어 각각에 대한 대용어 태깅값을 출력하도록 기계 학습 알고리즘 또는 딥 러닝 알고리즘으로 학습된 뉴럴 네트워크인, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>11. 인공 지능 장치가 수행하는 음성 인식 방법에 있어서,사용자의 음성 명령을 입력 받는 단계;소정의 텍스트 데이터에 포함된 대용어를 판별하는 대용어 인식 모델을 이용하여, 상기 음성 명령에 대응하는 텍스트 데이터에 포함된 대용어를 판별하는 단계;상기 인공 지능 장치로 입력되거나 상기 인공 지능 장치를 통해 출력된 정보를 포함하는 컨텍스트 정보를 기초로 상기 판별된 대용어가 지칭하는 지칭 대상을 특정하는 단계;상기 특정된 지칭 대상을 기초로 상기 음성 명령에 대한 응답을 판별하는 단계; 및상기 판별된 응답에 따라 상기 인공 지능 장치를 제어하는 단계를 포함하는,음성 인식 방법. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 컨텍스트 정보는, 상기 인공 지능 장치의 디스플레이를 통해 출력되는 출력 콘텐츠에 대한 정보 및 상기 사용자로부터 선택된 선택 콘텐츠에 대한 정보 중 적어도 하나를 포함하는 화면 컨텍스트 정보를 포함하는,음성 인식 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 지칭 대상을 특정하는 단계는, 상기 선택 콘텐츠가 적어도 하나 이상 존재하는 경우, 상기 선택 콘텐츠에 기초하여 상기 대용어가 지칭하는 지칭 대상을 특정하는 단계를 포함하는,음성 인식 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 지칭 대상을 특정하는 단계는, 상기 출력 콘텐츠가 상기 디스플레이에 풀스크린으로 출력되는 풀스크린 콘텐츠인 경우, 상기 풀스크린 콘텐츠에 기초하여 상기 대용어가 지칭하는 지칭 대상을 특정하는 단계를 포함하는,음성 인식 방법.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 컨텍스트 정보는, 상기 사용자와 상기 인공 지능 장치간 음성 명령 및 음성 명령에 대한 응답을 통한 대화 내역에 대한 정보인 대화 컨텍스트 정보를 포함하는,음성 인식 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 대용어는, 인물 또는 사물과 인접한 대상을 지칭하는 인접 대용어 및 인물 또는 사물과 인접하지 않은 대상을 지칭하는 비인접 대용어 중 적어도 하나를 포함하고, 상기 대용어를 판별하는 단계는, 상기 대용어 인식 모델을 이용하여 상기 음성 명령에 대응하는 텍스트 데이터에 포함된 인접 대용어 또는 비인접 대용어를 판별하는,음성 인식 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 지칭 대상을 특정하는 단계는, 상기 화면 컨텍스트 정보를 기초로 상기 판별된 인접 대용어가 지칭하는 지칭 대상을 특정하는 단계를 포함하는, 음성 인식 방법.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 지칭 대상을 특정하는 단계는, 상기 대화 컨텍스트 정보를 기초로 상기 판별된 비인접 대용어가 지칭하는 지칭 대상을 특정하는 단계를 포함하는, 음성 인식 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 대화 컨텍스트 정보는, 상기 대화 내역에 포함된 각각의 음성 명령에 대응하는 텍스트 데이터에 포함된 대용어 지칭 대상 후보에 대한 정보를 포함하고, 상기 지칭 대상을 특정하는 단계는,상기 대용어 지칭 대상 후보를 기초로 상기 판별된 비인접 대용어가 지칭하는 지칭 대상을 특정하는 단계를 포함하는,음성 인식 방법.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서,상기 대용어 인식 모델은,상기 소정의 텍스트 데이터가 입력 레이어에 입력되는 경우 입력된 소정의 텍스트 데이터에 포함된 문자 또는 단어 각각에 대한 대용어 태깅값을 출력하도록 기계 학습 알고리즘 또는 딥 러닝 알고리즘으로 학습된 뉴럴 네트워크인, 음성 인식 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 영등포구...</address><code>120020128403</code><country>대한민국</country><engName>LG Electronics Inc.</engName><name>엘지전자 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>Kwangyong Lee</engName><name>이광용</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** 혜천빌딩 ***호(선영특허법률사무소)</address><code>919980006169</code><country>대한민국</country><engName>Haw, Yong Noke</engName><name>허용록</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2019.10.01</receiptDate><receiptNumber>1-1-2019-1002870-24</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Notification of change of applicant's information</documentEngName><documentName>출원인정보변경(경정)신고서</documentName><receiptDate>2020.05.28</receiptDate><receiptNumber>4-1-2020-5118228-40</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.08.29</receiptDate><receiptNumber>1-1-2022-0901234-63</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.04.09</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2025.05.28</receiptDate><receiptNumber>9-6-2025-0200277-46</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.30</receiptDate><receiptNumber>9-5-2025-1054474-53</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020190121363.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e8f0f871def6e43703dec5d388c49b2ce55d5bf385696f538cda64376677fbc06b4d8239056fa9dc4be0896e7eb95f616790bdcd485e767c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cffd7fd8bf61720d1fc180570c3e1b618ff8ba03f253402aacdb5ce3333beecdcb43c0b8db5fc6052b0a4a24d38ce92b193d8e83d7b196255b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>