<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:22.022</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7034564</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>적응적 사용자 상호 작용을 갖는 로봇형 컴퓨팅 디바이스</inventionTitle><inventionTitleEng>ROBOTIC COMPUTING DEVICE WITH ADAPTIVE USER-INTERACTION</inventionTitleEng><openDate>2023.11.15</openDate><openNumber>10-2023-0156929</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.10</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.10.10</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 19/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04L 12/28</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04W 4/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04W 4/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/2285</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/246</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에 설명된 구현들은 사용자의 특정 선호도에 따라 공통 공간에서 사용자 간의 통신과 같은 특정 동작을 수행할 수 있는 로봇형 컴퓨팅 디바이스에 관한 것이다. 특정 사용자와 상호작용할 때, 로봇형 컴퓨팅 디바이스는 해당 특정 사용자의 명시적 또는 묵시적 선호도에 기초하여 특정 사용자에 대해 선호되는 위치에서 동작을 수행할 수 있다. 예를 들어, 특정 유형의 동작은 방 내의 제1 위치에서 수행될 수 있고, 다른 유형의 동작은 방 내의 제2 위치에서 수행될 수 있다. 동작이 사용자를 따르거나 안내하는 것을 포함하는 경우, 로봇형 컴퓨팅 디바이스를 구동하기 위한 파라미터는 사용자의 선호도 및/또는 로봇형 컴퓨팅 디바이스가 사용자와 상호작용하는 컨텍스트(예를 들어, 컨텍스트가 어느 정도 긴급성을 나타내는지 여부)에 기초하여 선택될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.05.25</internationOpenDate><internationOpenNumber>WO2023091160</internationOpenNumber><internationalApplicationDate>2021.12.13</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/063125</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프로세서에 의한 구현 방법으로서, 상기 방법은,모바일 로봇형 컴퓨팅 디바이스에 의해 그 모바일 로봇형 컴퓨팅 디바이스의 센서 관찰에 적어도 부분적으로 기초하여 생성된 맵(map)에 기초하여, 모바일 로봇형 컴퓨팅 디바이스가 현재 구조물의 특정 영역 내에 위치하는지 결정하는 단계와;모바일 로봇형 컴퓨팅 디바이스가 특정 영역 내에 위치하는 동안: 스마트 디바이스의 제1 서브세트가 각각 하나 이상의 제1 출력을 방출하게 하는 단계와, 상기 하나 이상의 제1 출력은 청각적 및/또는 시각적이고, 그리고 상기 하나 이상의 제1 출력은 제1 시간 윈도우 동안 및/또는 스마트 디바이스의 제1 서브세트에 각각 홈 그래프의 제1 시맨틱 라벨에 할당되는 것에 응답하여 하나 이상의 제1 특성으로 방출되도록 하고; 스마트 디바이스의 제2 서브세트가 각각 하나 이상의 제2 출력을 방출하게 하는 단계와, 상기 하나 이상의 제2 출력은 청각적 및/또는 시각적이고, 그리고 상기 하나 이상의 제2 출력은 제2 시간 윈도우 동안 및/또는 스마트 디바이스의 제2 서브세트가 각각 홈 그래프의 제2 시맨틱 라벨에 할당되는 것에 응답하여 하나 이상의 제2 특성을 갖고 방출되도록 하고; 그리고 하나 이상의 제1 출력 및 하나 이상의 제2 출력의 방출 동안 센서 데이터를 획득하는 단계와, 상기 센서 데이터는 모바일 로봇형 컴퓨팅 디바이스의 하나 이상의 센서에 의해 생성되고;센서 데이터의 분석에 기초하여 스마트 디바이스의 제1 서브세트가 특정 영역에서 로봇과 같은 위치에 있다고 결정하는 단계와, 상기 스마트 디바이스의 제1 서브세트가 특정 영역에서 로봇과 같은 위치에 있다고 결정하는 단계는, 제1 시간 윈도우 동안 및/또는 하나 이상의 제1 특성과 일치하는 검출된 출력을 나타내는 분석, 및/또는 제1 시간 윈도우 동안 및/또는 하나 이상의 제1 특성과 일치하는 검출된 출력의 크기에 기초하고; 그리고스마트 디바이스의 제1 서브세트가 주어진 방에서 로봇과 같은 위치에 있다고 결정하는 것에 응답하여: 추론된 시맨틱 라벨을 상기 특정 영역에 할당하는 단계를 포함하고, 상기 추론된 시맨틱 라벨은 홈 그래프에 있는 스마트 디바이스의 제1 서브세트에 할당된 제1 시맨틱 라벨과 동일하거나 그로부터 도출되는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 하나 이상의 제1 출력은 제1 시간 윈도우 동안 방출되고, 상기 하나 이상의 제2 출력은 제2 시간 윈도우 동안 방출되며, 그리고 상기 스마트 디바이스의 제1 서브세트가 특정 영역에서 로봇과 같은 위치에 있다고 결정하는 단계는,검출된 출력이 제1 시간 윈도우 동안 발생한다고 결정하는 단계, 및 제2 시간 윈도우 동안 발생하는 검출된 출력이 없다고 결정하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 하나 이상의 제1 출력은 제1 시간 윈도우 동안 방출되고, 상기 하나 이상의 제2 출력은 제2 시간 윈도우 동안 방출되며, 그리고상기 스마트 디바이스의 제1 서브세트가 특정 영역에서 로봇과 같은 위치에 있다고 결정하는 단계는,제1 시간 윈도우 동안 발생하는 검출된 출력의 크기가 제2 시간 윈도우 동안 발생하는 추가의 검출된 출력의 추가 크기보다 크다고 결정하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 또는 제2항에 있어서,상기 하나 이상의 제1 출력은 제1 특성을 갖고, 상기 하나 이상의 제2 출력은 제2 특성을 가지며, 그리고상기 스마트 디바이스의 제1 서브세트가 특정 영역에서 로봇과 같은 위치에 있다고 결정하는 단계는,검출된 출력이 제1 특성과 일치한다고 결정하는 단계, 및 제2 특성과 일치하는 검출된 출력이 없다고 결정하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 하나 이상의 제1 특성은 제1 주파수를 포함하고, 상기 하나 이상의 제2 특성은 제2 주파수를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 제1 출력은 시각적 출력을 포함하고, 상기 제1 주파수는 제1 시각적 주파수이고;상기 제2 출력은 시각적 출력을 포함하고, 상기 제2 주파수는 제2 시각적 주파수인 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 또는 제3항에 있어서,상기 하나 이상의 제1 출력은 제1 특성을 갖고, 상기 하나 이상의 제2 출력은 제2 특성을 가지며, 그리고상기 스마트 디바이스의 제1 서브세트가 특정 영역에서 로봇과 같은 위치에 있다고 결정하는 단계는,검출된 출력의 제1 특성의 크기가 검출된 출력의 제2 특성의 추가 크기보다 크다고 결정하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 하나 이상의 제1 특성은 제1 주파수를 포함하고, 상기 하나 이상의 제2 특성은 제2 주파수를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 제1 출력은 가청 출력을 포함하고, 상기 제1 주파수는 인간의 가청 범위를 벗어난 제1 가청 주파수이고; 그리고상기 제2 출력은 가청 출력을 포함하고, 상기 제2 주파수는 인간의 가청 범위를 벗어난 제2 가청 주파수인 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>10. 임의의 선행하는 항에 있어서,상기 스마트 디바이스의 제1 서브세트는 독립형 자동화 어시스턴트 디바이스를 포함하고, 그리고 상기 하나 이상의 제1 출력은 독립형 자동화 어시스턴트 디바이스의 하드웨어 스피커를 통한 제1 가청 출력을 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서,상기 스마트 디바이스의 제1 서브세트는 독립형 자동화 어시스턴트 디바이스를 포함하고, 상기 하나 이상의 제1 출력은 자동화 어시스턴트 디바이스의 하드웨어 디스플레이 또는 자동화 어시스턴트 디바이스의 발광 다이오드를 통한 제1 시각적 출력을 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>12. 임의의 선행하는 항에 있어서,상기 스마트 디바이스의 제1 서브세트는,스마트 조명, 스마트 텔레비전, 또는 스마트 온도 조절기를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>13. 임의의 선행하는 항에 있어서,상기 홈 그래프의 제1 시맨틱 라벨은 제1 명시적인 사용자 입력에 기초하여 스마트 디바이스의 제1 서브세트에 이전에 할당되었던 구조물 내의 제1 방에 대한 제1 설명자이고; 그리고상기 홈 그래프의 제2 시맨틱 라벨은 제2 명시적인 사용자 입력에 기초하여 스마트 디바이스의 제2 서브세트에 이전에 할당되었던 구조물 내의 제2 방에 대한 제2 설명자인 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>14. 임의의 선행하는 항에 있어서,상기 추론된 시맨틱 라벨을 특정 영역에 할당하는 단계는,추론된 시맨틱 라벨을 모바일 로봇형 디바이스에 의한 사용을 위해 맵의 특정 영역에 자동으로 할당하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,추론된 시맨틱 라벨을 모바일 로봇형 디바이스에 의한 사용을 위해 맵의 특정 영역에 자동으로 할당하는 단계에 후속하여:모바일 로봇형 디바이스의 이동(navigation)을 제어할 때 추론된 시맨틱 라벨을 사용하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 모바일 로봇형 디바이스의 이동을 제어할 때 추론된 시맨틱 라벨을 사용하는 단계는,모바일 로봇형 디바이스의 하나 이상의 마이크로폰에서 검출된 음성 입력을 처리하는 것에 기초하여, 음성 입력의 하나 이상의 용어가 추론된 시맨틱 라벨과 일치하는지 결정하는 단계와; 그리고하나 이상의 용어가 추론된 시맨틱 라벨과 일치한다고 결정하는 것에 기초하고, 그리고 추론된 시맨틱 라벨이 맵의 특정 영역에 할당되는 것에 기초하여, 로봇이 특정 영역으로 이동하게 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제13항 중 어느 한 항에 있어서,상기 추론된 시맨틱 라벨을 특정 영역에 할당하는 단계는,그래픽 사용자 인터페이스의 사용자에게, 추론된 시맨틱 라벨이 모바일 로봇형 디바이스에 의한 사용을 위해 맵의 특정 영역에 할당되도록 제안하는 단계와; 그리고제안에 응답하는 사용자의 긍정적인 사용자 인터페이스 입력을 수신하는 것에 응답하여, 추론된 시맨틱 라벨을 모바일 로봇형 디바이스에 의한 사용을 위해 맵의 특정 영역에 할당하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>18. 하나 이상의 프로세서에 의한 구현 방법으로서, 상기 방법은,로봇형 컴퓨팅 디바이스에 의해, 사용자가 특정 컴퓨팅 디바이스의 위치를 확신하지 못함을 나타내는 음성 발언을 사용자가 발화했다고 결정하는 단계와, 상기 음성 발언은 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스의 위치를 식별하도록 하는 명시적인 요청을 구현하지 않으며;로봇형 컴퓨팅 디바이스에 의해, 로봇형 컴퓨팅 디바이스의 출력 인터페이스로 하여금 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스의 위치를 결정할 수 있다는 표시를 사용자에게 제공하게 하는 단계와;로봇형 컴퓨팅 디바이스에 의해, 사용자가 로봇형 컴퓨팅 디바이스가 사용자를 특정 컴퓨팅 디바이스의 위치 쪽으로 안내하도록 허용할 의향이 있는지 여부를 결정하기 위해 로봇형 컴퓨팅 디바이스의 하나 이상의 입력 인터페이스로부터 입력 데이터를 처리하는 단계와; 그리고로봇형 컴퓨팅 디바이스가 사용자가 로봇형 컴퓨팅 디바이스가 사용자를 특정 컴퓨팅 디바이스의 위치 쪽으로 안내하도록 허용할 의향이 있다고 결정한 경우: 로봇형 컴퓨팅 디바이스에 대한 특정 컴퓨팅 디바이스의 상대 위치를 추정하기 위해 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스와 통신하게 하는 단계와, 그리고 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스의 상대 위치를 향해 기동하게 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법. </claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스의 상대 위치를 향해 기동하게 하는 단계는,특정 컴퓨팅 디바이스를 통해 액세스 가능한 애플리케이션의 상태에 기초하여 선택되는 속도로 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스의 상대 위치를 향해 이동하게 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 애플리케이션은 음성 통화 애플리케이션을 포함하고, 상기 애플리케이션의 상태는 사용자가 특정 연락처로부터 걸려온 전화를 받지 못했음을 나타내는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 로봇형 컴퓨팅 디바이스에 대한 특정 컴퓨팅 디바이스의 상대 위치를 추정하기 위해 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스와 통신하게 하는 단계는,로봇형 컴퓨팅 디바이스와 특정 컴퓨팅 디바이스 사이의 통신에 기초하여 신호 메트릭을 결정하는 단계를 포함하고,상기 신호 메트릭은 로봇형 컴퓨팅 디바이스로부터 특정 컴퓨팅 디바이스의 상대적인 거리를 나타내는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,상기 신호 메트릭은,특정 컴퓨팅 디바이스에 의해 렌더링되는 오디오 출력의 오디오 진폭을 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>23. 제18항 내지 제22항 중 어느 한 항에 있어서,상기 사용자가 로봇형 컴퓨팅 디바이스가 사용자를 특정 컴퓨팅 디바이스의 위치 쪽으로 안내하도록 허용할 의향이 있는지 여부를 결정하기 위해 입력 데이터를 처리하는 단계는,로봇형 컴퓨팅 디바이스를 향한 사용자의 움직임(motion)을 나타내는 이미지 데이터를 처리하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>24. 제18항 내지 제23항 중 어느 한 항에 있어서, 상기 입력 데이터에는 로봇형 컴퓨팅 디바이스가 특정 컴퓨팅 디바이스의 상대 위치를 결정하라는 사용자로부터의 명시적인 요청을 특징짓는 오디오 데이터가 없는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>25. 하나 이상의 프로세서에 의한 구현 방법으로서, 상기 방법은,로봇형 컴퓨팅 디바이스에서, 로봇형 컴퓨팅 디바이스가 다수의 서로 다른 방을 포함하는 공간에 위치한 특정 방에서 동작을 수행하도록 사용자가 요청했다고 결정하는 단계와;로봇형 컴퓨팅 디바이스에 의해, 다수의 서로 다른 방 중 하나 이상의 방에 있는 하나 이상의 디바이스가 로봇형 컴퓨팅 디바이스에 의해 검출 가능한 하나 이상의 개별 출력을 제공하게 하는 단계와;하나 이상의 각각의 출력에 기초하여, 로봇형 컴퓨팅 디바이스의 현재 위치가 특정 방에 대응하는지 여부를 결정하는 단계와;로봇형 컴퓨팅 디바이스의 현재 위치가 특정 방에 대응하지 않는 경우: 특정 방에 대응하지 않는 로봇형 컴퓨팅 디바이스의 현재 위치에 기초하여, 로봇형 컴퓨팅 디바이스가 특정 방으로 재배치되도록 하는 단계와, 그리고 로봇형 컴퓨팅 디바이스가 특정 방에 위치할 때 로봇형 컴퓨팅 디바이스가 그 동작을 수행하도록 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법. </claim></claimInfo><claimInfo><claim>26. 제25항에 있어서,상기 로봇형 컴퓨팅 디바이스가 특정 방으로 재배치되도록 하는 단계는,동작에 해당하는 특정 유형의 동작을 수행하기 위해 사용자가 특정 방의 특정 부분을 선호한다고 결정하는 단계와, 그리고로봇형 컴퓨팅 디바이스가 특정 방의 특정 부분으로 재배치되도록 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>27. 제25항에 있어서,상기 로봇형 컴퓨팅 디바이스가 특정 방으로 재배치되도록 하는 단계는,동작에 해당하지 않는 특정 유형의 동작을 수행하기 위해 사용자가 특정 방의 특정 부분을 선호한다고 결정하는 단계와, 그리고로봇형 컴퓨팅 디바이스가 특정 방의 다른 부분으로 재배치되도록 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>28. 제25항에 있어서,로봇형 컴퓨팅 디바이스의 현재 위치가 특정 방에 해당하는 경우:로봇형 컴퓨팅 디바이스가 위치한 현재 방 내에서, 로봇형 컴퓨팅 디바이스가 동작을 수행하기 위한 선호 부분인 현재 방의 일부를 식별하게 하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>29. 제25항 내지 제28항 중 어느 한 항에 있어서, 상기 로봇형 컴퓨팅 디바이스가 동작을 수행하기 위한 방의 선호 부분인 현재 방의 일부를 식별하게 하는 단계는,사용자가 동작을 요청하는 것에 기초하여, 사용자가 이전에 로봇형 컴퓨팅 디바이스에게 방의 선호 부분에서 그 동작에 해당하는 특정 유형의 동작을 수행하도록 요청했다고 결정하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>30. 제25항 내지 제29항 중 어느 한 항에 있어서,로봇형 컴퓨팅 디바이스의 현재 위치가 특정 방에 해당하지 않는 경우:로봇형 컴퓨팅 디바이스가 동작을 수행하기 전에, 로봇형 컴퓨팅 디바이스가 로봇형 컴퓨팅 디바이스의 현재 위치가 동작을 수행하도록 승인되었는지 확인하도록 사용자에게 요청하는 출력을 렌더링하게 하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법. </claim></claimInfo><claimInfo><claim>31. 제25항 내지 제30항 중 어느 한 항에 있어서,로봇형 컴퓨팅 디바이스의 현재 위치가 특정 방에 해당하는 경우:로봇형 컴퓨팅 디바이스가 위치한 현재 방 내에서, 사용자가 특정 방의 다른 부분으로 재배치하는 동안 그 동작을 수행할 때 로봇형 컴퓨팅 디바이스 사용자를 따라갈 상대 거리를 식별하게 하는 단계를 더 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법. </claim></claimInfo><claimInfo><claim>32. 하나 이상의 프로세서에 의한 구현 방법으로서, 상기 방법은,로봇형 컴퓨팅 디바이스에 의해, 로봇형 컴퓨팅 디바이스가 있는 공간에 위치한 제1 사용자 및 제2 사용자로부터 음성 발언을 수신하는 단계와;음성 발언에 기초하여, 제1 사용자가 로봇형 컴퓨팅 디바이스에게 제2 사용자와 통신하도록 지시했다고 결정하는 단계와, 상기 제2 사용자는 제1 사용자의 제1 사용자 위치와 다른 제2 사용자 위치에 위치하고;음성 발언에 응답하여, 로봇형 컴퓨팅 디바이스가 제2 사용자 위치로 기동하여 제2 사용자에 대한 출력을 렌더링하게 하는 단계와, 상기 출력은 제1 사용자로부터의 음성 발언에 기초한 자연어 질의를 구현하고;로봇형 컴퓨팅 디바이스에 의해, 제2 사용자로부터 응답 입력을 수신하는 단계와, 상기 응답 입력은 로봇형 컴퓨팅 디바이스로부터의 출력에 구현된 자연어 질의에 응답하는 자연어 컨텐츠를 구현하고; 그리고로봇형 컴퓨팅 디바이스가 제2 사용자에 대한 출력을 제공하는 것에 후속하여, 로봇형 컴퓨팅 디바이스가 제1 사용자 위치로 기동하여 제1 사용자에 대한 다른 출력을 렌더링하게 하는 단계를 포함하고, 상기 다른 출력은 제2 사용자로부터의 응답 입력을 특징짓고, 제2 사용자로부터의 응답 입력에 구현된 자연어 컨텐츠와 상이한 다른 자연어 컨텐츠를 구현하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법. </claim></claimInfo><claimInfo><claim>33. 제32항에 있어서,상기 로봇형 컴퓨팅 디바이스가 제2 사용자 위치로 기동하게 하는 단계는,제2 사용자와 관련된 위치 선호도를 결정하는 단계와, 상기 위치 선호도는 로봇형 컴퓨팅 디바이스가 제2 사용자와 통신할 때 로봇형 컴퓨팅 디바이스에 대한 선호 위치를 나타내고, 그리고로봇형 컴퓨팅 디바이스가 위치 선호도에 의해 표시된 선호 위치에 대응하는 특정 위치로 기동하게 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서,상기 선호 위치는 제2 사용자로부터 로봇형 컴퓨팅 디바이스의 선호 거리를 나타내고, 상기 특정 위치는 적어도 제2 사용자의 제2 위치로부터 떨어진 선호 거리인 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>35. 제32항 내지 제34항 중 어느 한 항에 있어서, 상기 로봇형 컴퓨팅 디바이스가 제1 사용자 위치로 기동하게 하는 단계는,제1 사용자와 관련된 위치 선호도를 결정하는 단계와, 상기 위치 선호도는 로봇형 컴퓨팅 디바이스가 제1 사용자에 대한 특정 유형의 출력을 렌더링할 때 로봇형 컴퓨팅 디바이스에 대한 선호 위치를 나타내고, 그리고로봇형 컴퓨팅 디바이스가 위치 선호도에 의해 표시된 선호 위치에 대응하는 특정 위치로 기동하게 하는 단계를 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>36. 제32항 내지 제35항 중 어느 한 항에 있어서,상기 특정 유형의 출력은,로봇형 컴퓨팅 디바이스의 오디오 출력 인터페이스를 통해 제공되는 가청 출력, 또는 로봇형 컴퓨팅 디바이스의 디스플레이 인터페이스를 통해 제공되는 시각적 출력을 포함하는 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서,상기 특정 유형의 출력은,다른 사용자로부터의 메시지를 특징짓는 컨텐츠를 포함하는 가청 출력인 것을 특징으로 하는 하나 이상의 프로세서에 의한 구현 방법.</claim></claimInfo><claimInfo><claim>38. 컴퓨팅 시스템의 하나 이상의 프로세서에 의해 실행될 때 컴퓨팅 시스템으로 하여금 임의의 선행하는 항의 방법을 수행하게 하는 명령들을 포함한 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>39. 제1항 내지 제37항 중 어느 한 항의 방법을 수행하도록 구성된 하나 이상의 컴퓨팅 디바이스를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>40. 제39항에 있어서,하나 이상의 컴퓨팅 디바이스는 모바일 로봇형 컴퓨팅 디바이스를 포함하는 것을 특징으로 하는 시스템</claim></claimInfo><claimInfo><claim>41. 제1항 내지 제37항 중 어느 한 항의 방법을 수행하기 위해 컴퓨팅 시스템의 하나 이상의 프로세서에 의해 실행 가능한 명령들을 저장한 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>CARBUNE, Victor</engName><name>카부네 빅터</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SHARIFI, Matthew</engName><name>샤리피 매튜</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.11.19</priorityApplicationDate><priorityApplicationNumber>63/281,375</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.11.23</priorityApplicationDate><priorityApplicationNumber>17/533,873</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.10.10</receiptDate><receiptNumber>1-1-2023-1105663-45</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.10.18</receiptDate><receiptNumber>1-5-2023-0164412-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.08.14</receiptDate><receiptNumber>9-5-2025-0776694-02</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.09.24</receiptDate><receiptNumber>1-1-2025-1093076-07</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.09.24</receiptDate><receiptNumber>1-1-2025-1093077-42</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237034564.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938d7ea61169c876c575c02bab4f158e7de947f5a3597d057b7b401a6ee0c73825b5128b8316434d20465a64a8c183822095fec5ab193d6fca</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9716c75155d3285cb8397f3bc435fb74f9c94c89057d10bc0844a358b21ad7fd3a894c4757223414bc8256f73a9cbe1df7d7fae15132cf6b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>