<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:23.4023</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.21</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7031198</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신규 뷰 합성을 이용한 장면 변화 검출</inventionTitle><inventionTitleEng>SCENE CHANGE DETECTION WITH NOVEL VIEW SYNTHESIS</inventionTitleEng><openDate>2024.10.22</openDate><openNumber>10-2024-0152896</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.09.19</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/254</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 장면에서의 변화들을 검출하기 위한 방법은 증강 현실(AR) 디바이스의 제1 사용자 세션과 연관된 제1 좌표계에서 제1 이미지 세트 및 대응하는 포즈 데이터에 액세스하는 단계, 및 제2 사용자 세션과 연관된 제2 좌표계에서 제2 이미지 세트 및 대응하는 포즈 데이터에 액세스하는 단계를 포함한다. 방법은 제1 좌표계와 제2 좌표계를 정렬한 후에 제1 이미지 세트의 포즈 데이터가 제2 이미지 세트로부터의 제2 이미지의 포즈 데이터에 공간적으로 가장 가까운 것으로 결정되는 것에 기초하여 제2 이미지에 대응하는 제1 이미지 세트를 식별한다. 훈련된 신경망은 제1 이미지 세트로부터 합성 이미지를 생성한다. 제2 이미지의 특징들은 합성 이미지의 특징들로부터 감산된다. 변화들의 영역은 감산된 특징들에 기초하여 식별된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.08.31</internationOpenDate><internationOpenNumber>WO2023163937</internationOpenNumber><internationalApplicationDate>2023.02.21</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/013500</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,증강 현실(AR) 디바이스의 제1 사용자 세션과 연관된 제1 좌표계에서 제1 이미지 세트 및 대응하는 포즈 데이터에 액세스하는 단계;상기 AR 디바이스의 제2 사용자 세션과 연관된 제2 좌표계에서 제2 이미지 세트 및 대응하는 포즈 데이터에 액세스하는 단계;상기 제1 이미지 세트의 포즈 데이터를 상기 제2 이미지 세트의 포즈 데이터에 매핑하는 것에 기초하여 상기 제1 좌표계를 상기 제2 좌표계와 정렬하는 단계;상기 제1 좌표계와 상기 제2 좌표계를 정렬한 후에 상기 제1 이미지 세트의 포즈 데이터가 상기 제2 이미지 세트로부터의 제2 이미지의 포즈 데이터에 공간적으로 가장 가까운 것으로 결정되는 것에 기초하여 상기 제2 이미지에 대응하는 상기 제1 이미지 세트를 식별하는 단계;훈련된 신경망을 사용하여, 상기 제1 이미지 세트로부터 합성 이미지를 생성하는 단계;상기 합성 이미지의 특징들(features)로부터의 상기 제2 이미지의 특징들 사이의 차이들을 결정하는 단계; 및상기 차이들에 기초하여 변화들의 영역을 식별하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 이미지 세트는 상기 제1 사용자 세션 동안 상기 AR 디바이스의 광학 센서에 의해 생성되고, 상기 제2 이미지 세트는 상기 제2 사용자 세션 동안 상기 AR 디바이스의 광학 센서에 의해 생성되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 제1 사용자 세션은 상기 제2 사용자 세션 이후이고, 상기 제1 사용자 세션은 상기 AR 디바이스로부터의 라이브 스트림과 연관되고, 상기 제2 사용자 세션은 상기 AR 디바이스로부터의 보관(archiving)된 이미지들과 연관되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 제2 사용자 세션은 상기 제1 사용자 세션 이후이고, 상기 제1 사용자 세션은 상기 AR 디바이스로부터의 라이브 스트림과 연관되고, 상기 제2 사용자 세션은 상기 AR 디바이스로부터의 보관된 이미지들과 연관되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 제1 사용자 세션은 상기 AR 디바이스의 사용자가 상기 AR 디바이스를 착용하는 것에 응답하여 개시되고, 상기 AR 디바이스의 사용자가 상기 사용자의 신체의 일부로부터 상기 AR 디바이스를 제거하는 것에 응답하여 종료되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제1 이미지 세트 및 대응하는 포즈 데이터를 서버에 저장하는 단계;상기 제2 이미지 세트 및 대응하는 포즈 데이터를 상기 서버에 저장하는 단계; 및상기 서버에서 상기 훈련된 신경망을 사용하여 상기 합성 이미지를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 제2 이미지에서의 변화들의 영역에 기초하여 히트맵(heatmap)을 생성하는 단계; 및상기 제2 이미지 상에 상기 히트맵의 디스플레이를 오버레이하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 합성 이미지에서의 변화들의 영역에 기초하여 히트맵을 생성하는 단계; 및상기 합성 이미지 상에 상기 히트맵의 디스플레이를 오버레이하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 변화들의 영역에 기초하여 히트맵을 생성하는 단계; 및상기 AR 디바이스의 투명 디스플레이에 상기 히트맵을 디스플레이하는 단계를 더 포함하고, 상기 히트맵은 상기 차이들의 값들에 기초한 기울기 변화들을 표시하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 신경망은 제1 또는 제2 이미지 세트로 훈련되지 않은 NeRF 기반 신경망을 포함하고, 상기 특징들은 신경망 특징 벡터들을 포함하고, 상기 제1 이미지 세트 및 상기 제2 이미지 세트는 2차원 이미지들을 포함하고, 상기 AR 디바이스는 포즈 데이터를 생성하는 6 자유도(6DOF) 추적기를 포함하고, 상기 6DOF 추적기는 시각-관성 주행 거리 측정(visual-inertial odometry), (VIO) 시스템을 포함하고, 상기 포즈 데이터는 상기 AR 디바이스의 포지션 및 배향을 표시하는, 방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨팅 장치로서,프로세서; 및 명령어들을 저장하는 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때, 상기 장치를:증강 현실(AR) 디바이스의 제1 사용자 세션과 연관된 제1 좌표계에서 제1 이미지 세트 및 대응하는 포즈 데이터에 액세스하고;상기 AR 디바이스의 제2 사용자 세션과 연관된 제2 좌표계에서 제2 이미지 세트 및 대응하는 포즈 데이터에 액세스하고;상기 제1 이미지 세트의 포즈 데이터를 상기 제2 이미지 세트의 포즈 데이터에 매핑하는 것에 기초하여 상기 제1 좌표계를 상기 제2 좌표계와 정렬하고;상기 제1 좌표계와 상기 제2 좌표계를 정렬한 후에 상기 제1 이미지 세트의 포즈 데이터가 상기 제2 이미지 세트로부터의 제2 이미지의 포즈 데이터에 공간적으로 가장 가까운 것으로 결정되는 것에 기초하여 상기 제2 이미지에 대응하는 상기 제1 이미지 세트를 식별하고;훈련된 신경망을 사용하여, 상기 제1 이미지 세트로부터 합성 이미지를 생성하고;상기 합성 이미지의 특징들로부터의 상기 제2 이미지의 특징들 사이의 차이들을 결정하고; 상기 차이들에 기초하여 변화들의 영역을 식별하도록 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제1 이미지 세트는 상기 제1 사용자 세션 동안 상기 AR 디바이스의 광학 센서에 의해 생성되고, 상기 제2 이미지 세트는 상기 제2 사용자 세션 동안 상기 AR 디바이스의 광학 센서에 의해 생성되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제1 사용자 세션은 상기 제2 사용자 세션 이후이고, 상기 제1 사용자 세션은 상기 AR 디바이스로부터의 라이브 스트림과 연관되고, 상기 제2 사용자 세션은 상기 AR 디바이스로부터의 보관된 이미지들과 연관되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 제2 사용자 세션은 상기 제1 사용자 세션 이후이고, 상기 제1 사용자 세션은 상기 AR 디바이스로부터의 라이브 스트림과 연관되고, 상기 제2 사용자 세션은 상기 AR 디바이스로부터의 보관된 이미지들과 연관되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 제1 사용자 세션은 상기 AR 디바이스의 사용자가 상기 AR 디바이스를 착용하는 것에 응답하여 개시되고, 상기 AR 디바이스의 사용자가 상기 사용자의 신체의 일부로부터 상기 AR 디바이스를 제거하는 것에 응답하여 종료되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 명령어들은 추가로 상기 장치를:상기 제1 이미지 세트 및 대응하는 포즈 데이터를 서버에 저장하고;상기 제2 이미지 세트 및 대응하는 포즈 데이터를 상기 서버에 저장하고;상기 서버에서 상기 훈련된 신경망을 사용하여 상기 합성 이미지를 생성하도록 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 명령어들은 추가로 상기 장치를:상기 제2 이미지에서의 변화들의 영역에 기초하여 히트맵을 생성하고;상기 제2 이미지 상에 상기 히트맵의 디스플레이를 오버레이하도록 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 명령어들은 추가로 상기 장치를:상기 합성 이미지에서의 변화들의 영역에 기초하여 히트맵을 생성하고;상기 합성 이미지 상에 상기 히트맵의 디스플레이를 오버레이하도록 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 명령어들은 추가로 상기 장치를:상기 변화들의 영역에 기초하여 히트맵을 생성하고;상기 AR 디바이스의 투명 디스플레이에 상기 히트맵을 디스플레이하도록 구성하고, 상기 히트맵은 상기 차이들의 값들에 기초한 기울기 변화들을 표시하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>20. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금:증강 현실(AR) 디바이스의 제1 사용자 세션과 연관된 제1 좌표계에서 제1 이미지 세트 및 대응하는 포즈 데이터에 액세스하고;상기 AR 디바이스의 제2 사용자 세션과 연관된 제2 좌표계에서 제2 이미지 세트 및 대응하는 포즈 데이터에 액세스하고;상기 제1 이미지 세트의 포즈 데이터를 상기 제2 이미지 세트의 포즈 데이터에 매핑하는 것에 기초하여 상기 제1 좌표계를 상기 제2 좌표계와 정렬하고;상기 제1 좌표계와 상기 제2 좌표계를 정렬한 후에 상기 제1 이미지 세트의 포즈 데이터가 상기 제2 이미지 세트로부터의 제2 이미지의 포즈 데이터에 공간적으로 가장 가까운 것으로 결정되는 것에 기초하여 상기 제2 이미지에 대응하는 상기 제1 이미지 세트를 식별하고;훈련된 신경망을 사용하여, 상기 제1 이미지 세트로부터 합성 이미지를 생성하고;상기 합성 이미지의 특징들로부터의 상기 제2 이미지의 특징들 사이의 차이들을 결정하고;상기 차이들에 기초하여 변화들의 영역을 식별하도록 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MICUSIK, Branislav</engName><name>미쿠식, 브라니슬라프</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.02.22</priorityApplicationDate><priorityApplicationNumber>17/677,821</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.09.19</receiptDate><receiptNumber>1-1-2024-1020061-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.25</receiptDate><receiptNumber>1-5-2024-0156012-21</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247031198.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936073187627fa9005fd12bb86c489aae1fd4187376ca8b0b019dc5c9d0d4c64da7dfb1232aaab0c837e20de905c4572b6c82ca70300fecb44</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff2984b139b13ecd9dcee4a5e8069742a7670d795f4dda693c0c96accc1733168ed8ea7b160c213de2d6f2b3921d0df45f2dbbdbccc66f4a1</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>