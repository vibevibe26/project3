<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:32:59.3259</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0170105</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사용자의 신체 정보에 기반하여, 미디어 콘텐트를 표시할 위치를 식별하기위한 전자 장치, 방법, 및 컴퓨터 판독 가능 저장 매체</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE, METHOD, AND COMPUTER-READABLE  STORAGE MEDIA IDENTIFYING LOCATION TO DISPLAY MEDIA  CONTENT BASED ON USER'S BODY INFORMATION</inventionTitleEng><openDate>2024.06.14</openDate><openNumber>10-2024-0085067</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04842</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0481</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04W 4/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/18</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 전자 장치의 하나 이상의 프로세서들은, 통신 회로를 이용하여, 외부 전자 장치를 식별하는 것에 기반하여, 상기 전자 장치의 프로젝션 어셈블리로부터 방사된 광이 투사될 제1 평면, 및 상기 외부 전자 장치의 다른 프로젝션 어셈블리로부터 방사된 광이 투사될 제2 평면의 위치 관계를 획득할 수 있다. 상기 하나 이상의 프로세서들은, 상기 제1 평면 및 상기 제2 평면 각각이, 카메라를 이용하여 식별된 사용자의 신체 부위로부터 이격된 거리들에 기반하여, 미디어 콘텐트의 상이한 영역들을, 상기 제1 평면 및 상기 제2 평면 각각에 매칭하기 위한 정보를 획득할 수 있다. 본 문서는, 실제 객체 및 가상 객체 사이의 상호연결성을 강화하기 위한 메타버스 서비스와 관련될 수 있다. 예를 들면, 상기 메타버스 서비스는, 5G(fifth generation), 및/또는 6G(sixth generation)에 기반하는 네트워크를 통해 제공될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치(101)에 있어서,카메라(250-1);통신 회로(230-1);프로젝션 어셈블리(240-1); 및하나 이상의 프로세서들(210-1)을 포함하고, 상기 하나 이상의 프로세서들은, 상기 통신 회로를 이용하여, 외부 전자 장치(102)를 식별하는 것에 기반하여, 상기 전자 장치의 상기 프로젝션 어셈블리로부터 방사된 광이 투사될 제1 평면(110), 및 상기 외부 전자 장치의 다른 프로젝션 어셈블리(240-2)로부터 방사된 광이 투사될 제2 평면(120; 130; 140; 150)의 위치 관계를 획득하고;상기 제1 평면 및 상기 제2 평면 각각이, 상기 카메라를 이용하여 식별된 사용자(107)의 신체 부위(302; 303; 304; 305)로부터 이격된 거리들에 기반하여, 미디어 콘텐트(405; 610; 611)의 상이한 영역들(410; 420; 430; 440; 450; 615; 625; 635; 645; 655)을, 상기 제1 평면 및 상기 제2 평면 각각에 매칭하기 위한 정보를 획득하고;상기 정보에 기반하여, 상기 미디어 콘텐트의 상기 상이한 영역들 중 제1 영역(410; 615)을, 상기 제1 평면 내에 표시하고; 및상기 정보에 기반하여 상기 통신 회로를 이용하여, 상기 외부 전자 장치로, 상기 미디어 콘텐트의 상기 상이한 영역들 중 제2 영역(625; 635; 645; 655)을, 상기 제2 평면 내에 표시하기 위한 신호(514)를 송신하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 프로세서들은, 상기 미디어 콘텐트 내 포함된 적어도 하나의 객체를 식별한 것에 기반하여, 상기 미디어 콘텐트의 영역들을 구분하고, 상기 사용자의 시선(301)에 대응하는 상기 제1 평면에, 상기 영역들 중 제1 영역을, 표시하도록, 구성된,전자 장치.  </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 하나 이상의 프로세서들은상기 제1 평면 및 상기 제2 평면을 포함하는 공간(100)의 사이즈에 기반하여, 상기 프로젝션 어셈블리를 제어하여, 상기 제1 영역을 표시하도록, 구성된,전자 장치.  </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 하나 이상의 프로세서들은,상기 공간 내에 위치한 상기 외부 전자 장치의 개수에 기반하여, 상기 상이한 영역들의 개수를 획득하도록, 구성된, 전자 장치.  </claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 하나 이상의 프로세서들은,상기 카메라를 이용하여, 상기 사용자의 머리(302)를 식별한 것에 기반하여, 상기 사용자의 상기 머리와 인접한 상기 제2 평면을 식별하도록, 구성된,전자 장치.  </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 하나 이상의 프로세서들은, 상기 카메라를 이용하여, 상기 사용자의 다리(305)를 식별한 것에 기반하여, 상기 사용자의 상기 다리에 인접한 제3 평면(150), 상기 제2 평면, 및 상기 제1 평면 사이의 위치 관계를 획득하고,상기 통신 회로를 이용하여, 상기 제3 평면 내에, 상기 프로젝션 어셈블리인 제1 프로젝션 어셈블리와 상이한 제3 프로젝션 어셈블리로부터 방사된 광을 투사하는 상기 외부 전자 장치인 제1 외부 전자 장치(102)와 상이한 제2 외부 전자 장치(105)를 식별하고, 상기 상이한 영역들 중 제3 영역을, 상기 제2 외부 전자 장치로, 상기 제3 평면 내에 표시하기 위한 신호를 송신하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 하나 이상의 프로세서들은,상기 카메라를 이용하여, 상기 제1 평면으로부터 상기 제2 평면을 바라보는 상기 사용자의 시선을 식별하고,상기 사용자의 모션을 식별한 것에 기반하여, 상기 제1 영역을, 상기 제2 평면 내에 표시하도록, 구성된,전자 장치.  </claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 하나 이상의 프로세서들은,상기 사용자의 시선을 식별한 것에 기반하여, 상기 제1 평면 및 상기 제2 평면의 위치 관계를 업데이트하도록, 구성된,전자 장치.  </claim></claimInfo><claimInfo><claim>9. 전자 장치(101)의 방법에 있어서,통신 회로(230-1)를 이용하여, 외부 전자 장치(102)를 식별하는 것에 기반하여, 상기 전자 장치의 프로젝션 어셈블리(240-1)로부터 방사된 광이 투사될 제1 평면(110), 및 상기 외부 전자 장치의 다른 프로젝션 어셈블리(240-2)로부터 방사된 광이 투사될 제2 평면(120; 130; 140; 150)의 위치 관계를 획득하는 동작; 상기 제1 평면 및 상기 제2 평면 각각이, 카메라를 이용하여 식별된 사용자(107)의 신체 부위(302; 303; 304; 305)로부터 이격된 거리들에 기반하여, 미디어 콘텐트(405; 610; 611)의 상이한 영역들(410; 420; 430; 440; 450; 615; 625; 635; 645; 655)을, 상기 제1 평면 및 상기 제2 평면 각각에 매칭하기 위한 정보를 획득하는 동작;상기 정보에 기반하여, 상기 미디어 콘텐트의 상기 상이한 영역들 중 제1 영역(410; 615)을, 상기 제1 평면 내에 표시하는 동작; 및상기 정보에 기반하여 상기 통신 회로를 이용하여, 상기 외부 전자 장치로, 상기 미디어 콘텐트의 상기 상이한 영역들 중 제2 영역(625; 635; 645; 655)을, 상기 제2 평면 내에 표시하기 위한 신호(514)를 송신하는 동작을 포함하는,방법.  </claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 제1 영역을 표시하는 동작은, 상기 미디어 콘텐트 내 포함된 적어도 하나의 객체를 식별하기 위한 객체 정보를 이용하여, 상기 미디어 콘텐트의 영역들을 구분하고, 상기 사용자의 시선(301)에 대응하는 상기 제1 평면에, 상기 영역들 중 제1 영역을, 표시하는 동작을 포함하는,방법.  </claim></claimInfo><claimInfo><claim>11. 제9항에 있어서, 상기 제1 영역을 표시하는 동작은,상기 제1 평면 및 상기 제2 평면을 포함하는 공간(100)의 사이즈에 기반하여, 상기 프로젝션 어셈블리를 제어하여, 상기 제1 영역을 표시하는 동작을 포함하는,방법. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 정보를 획득하는 동작은, 상기 공간 내에 위치한 상기 외부 전자 장치의 개수에 기반하여, 상기 상이한 영역들의 개수를 획득하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>13. 제9항에 있어서, 상기 위치 관계를 획득하는 동작은,상기 카메라를 이용하여, 상기 사용자의 머리(302)를 식별한 것에 기반하여, 상기 사용자의 상기 머리와 인접한 상기 제2 평면을 식별하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>14. 제9항에 있어서, 상기 위치 관계를 획득하는 동작은, 상기 카메라를 이용하여, 상기 사용자의 다리(305)를 식별한 것에 기반하여, 상기 사용자의 상기 다리에 인접한 제3 평면(150), 상기 제2 평면, 및 상기 제1 평면 사이의 위치 관계를 획득하는 동작, 상기 통신 회로를 이용하여, 상기 제3 평면 내에, 상기 프로젝션 어셈블리인 제1 프로젝션 어셈블리와 상이한 제3 프로젝션 어셈블리로부터 방사된 광을 투사하는 상기 외부 전자 장치인 제1 외부 전자 장치(102)와 상이한 제2 외부 전자 장치(105)를 식별하는 동작, 상기 상이한 영역들 중 제3 영역을, 상기 제2 외부 전자 장치로, 상기 제3 평면 내에 표시하기 위한 신호를 송신하는 동작을 포함하는,방법.  </claim></claimInfo><claimInfo><claim>15. 제9항에 있어서, 상기 제1 영역을 표시하는 동작은,상기 카메라를 이용하여, 상기 제1 평면으로부터 상기 제2 평면을 바라보는 상기 사용자의 시선을 식별하는 동작, 상기 사용자의 모션을 식별한 것에 기반하여, 상기 제1 영역을, 상기 제2 평면 내에 표시하는 동작을 포함하는,방법.  </claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 사용자의 상기 시선을 식별하는 동작은,상기 사용자의 상기 시선을 식별한 것에 기반하여, 상기 제1 평면 및 상기 제2 평면의 위치 관계를 업데이트하는 동작을 포함하는,방법. </claim></claimInfo><claimInfo><claim>17. 하나 이상의 프로그램들을 저장하는 컴퓨터 판독 가능 저장 매체에 있어서, 상기 하나 이상의 프로그램들은, 전자 장치의 하나 이상의 프로세서들에 의해, 실행될 때에,통신 회로를 이용하여, 외부 전자 장치를 식별하는 것에 기반하여, 상기 전자 장치의 프로젝션 어셈블리로부터 방사된 광이 투사될 제1 평면, 및 상기 외부 전자 장치의 다른 프로젝션 어셈블리로부터 방사된 광이 투사될 제2 평면의 위치 관계를 획득하고;상기 제1 평면 및 상기 제2 평면 각각이, 카메라를 이용하여 식별된 사용자의 신체 부위로부터 이격된 거리들에 기반하여, 미디어 콘텐트의 상이한 영역들을, 상기 제1 평면 및 상기 제2 평면 각각에 매칭하기 위한 정보를 획득하고;상기 정보에 기반하여, 상기 미디어 콘텐트의 상기 상이한 영역들 중 제1 영역을, 상기 제1 평면 내에 표시하고; 및상기 정보에 기반하여 상기 통신 회로를 이용하여, 상기 외부 전자 장치로, 상기 미디어 콘텐트의 상기 상이한 영역들 중 제2 영역을, 상기 제2 평면 내에 표시하기 위한 신호를 송신하도록, 구성된,컴퓨터 판독 가능 저장 매체.  </claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 하나 이상의 프로그램들은, 상기 전자 장치의 상기 하나 이상의 프로세서들에 의해, 실행될 때에,상기 미디어 콘텐트 내 포함된 적어도 하나의 객체를 식별하기 위한 객체 정보를 이용하여, 상기 미디어 콘텐트의 영역들을 구분하고, 상기 사용자의 시선에 대응하는 상기 제1 평면에, 상기 영역들 중 제1 영역을, 표시하도록, 구성된,컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 하나 이상의 프로그램들은, 상기 전자 장치의 상기 하나 이상의 프로세서들에 의해, 실행될 때에,상기 제1 평면 및 상기 제2 평면을 포함하는 공간의 사이즈에 기반하여, 상기 프로젝션 어셈블리를 제어하여, 상기 제1 영역을 표시하도록, 구성된,컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 하나 이상의 프로그램들은, 상기 전자 장치의 상기 하나 이상의 프로세서들에 의해, 실행될 때에,상기 공간 내에 위치한 상기 외부 전자 장치의 개수에 기반하여, 상기 상이한 영역들의 개수를 획득하도록, 구성된, 컴퓨터 판독 가능 저장 매체.  </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Soungmin YOO</engName><name>유승민</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Yongjin SO</engName><name>소용진</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Jeongmin SON</engName><name>손정민</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구  논현로**길  **, *층, *층 (도곡동, 덕영빌딩)</address><code>920191001617</code><country>대한민국</country><engName>KWANG AND JANG PATENT LAW FIRM</engName><name>특허법인광앤장</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.07</receiptDate><receiptNumber>1-1-2022-1317895-57</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220170105.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934cab03a57645444cf2f18d4bfef1fa0abcea41ae9472ae97c524eacc7c10274338a74ca852e8d4f12783903c3f9b881578580901bebbe666</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1e0e3a3c3844bc32177a9aff92e657f916022bf560254a35a6489db68e50276f8f6ad78f69b2d56e7fada23c4da0dc2ff4c9fc7b6fadc0ae</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>