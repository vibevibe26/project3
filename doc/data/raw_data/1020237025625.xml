<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:04.564</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.01.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7025625</applicationNumber><claimCount>22</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>동적 사이트들에서의 로봇 자율성을 위한 시맨틱 모델들</inventionTitle><inventionTitleEng>SEMANTIC MODELS FOR ROBOT AUTONOMY ON DYNAMIC SITES</inventionTitleEng><openDate>2023.10.04</openDate><openNumber>10-2023-0137334</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.01.24</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.07.26</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B62D 57/032</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01C 21/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법(300)은, 로봇(100)이 건물 환경(10)을 횡단하는 동안, 로봇의 센서들(132, 132a 내지 132n)에 의해 캡처된 센서 데이터(134)를 수신하는 단계를 포함한다. 상기 방법은 환경 내의 영구적인 물체들(PO)을 식별하는 시맨틱 정보(32)를 포함하는 환경에 대한 건물 정보 모델(BIM)(30)을 수신하는 단계를 포함한다. 상기 방법은 환경의 위치추정 맵(202)에 대한 위치추정 후보들(212, 212a 내지 212n)을 생성하는 단계를 포함한다. 각각의 위치추정 후보(212)는 센서 데이터에 의해 식별된 환경의 피처에 대응하고, 잠재적인 위치추정 기준점(222)을 나타낸다. 위치추정 맵은 환경 내에서의 로봇의 위치를 추정하도록 구성된다. 각각의 위치추정 후보에 대해, 상기 방법은 개개의 위치추정 후보에 대응하는 개개의 피처가 환경 내의 영구적인 물체(PO)인지 여부를 결정하는 단계, 및 개개의 위치추정 후보를 로봇에 대한 위치추정 맵의 위치추정 기준점(222)으로서 생성하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.08.04</internationOpenDate><internationOpenNumber>WO2022164832</internationOpenNumber><internationalApplicationDate>2022.01.26</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/013777</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 데이터 처리 하드웨어(data processing hardware)(142, 162, 410)에 의해 실행될 때 상기 데이터 처리 하드웨어(142, 162, 410)가 동작들을 수행하게 하는 컴퓨터 구현 방법(300)으로서,상기 동작들은,로봇(robot)(100)이 건물 환경(10)을 횡단하는 동안, 상기 로봇(100)의 하나 이상의 센서(sensor)들(132, 132a 내지 132n)에 의해 캡처된 센서 데이터(sensor data)(134)를 수신하는 동작;상기 건물 환경(10)에 대한 건물 정보 모델(build information model; BIM)(30)을 수신하는 동작 — 상기 BIM(30)은 상기 건물 환경(10) 내의 하나 이상의 영구적인 물체들(PO)을 식별하는 시맨틱 정보(semantic information)(32)를 포함함 —;상기 건물 환경(10)의 위치추정 맵(localization map)(202)에 대한 복수의 위치추정 후보들(212, 212a 내지 212n)을 생성하는 동작 — 상기 복수의 위치추정 후보들(212, 212a 내지 212n)의 각각의 위치추정 후보(212)는 상기 센서 데이터(134)에 의해 식별된 상기 건물 환경(10)의 피처(feature)에 대응하고 상기 로봇(100)에 대한 잠재적인 위치추정 기준점(222)을 나타내며, 상기 위치추정 맵(202)은 상기 로봇(100)이 상기 건물 환경(10) 전체에 걸쳐 이동할 때 상기 건물 환경(10) 내에서의 상기 로봇(100)의 위치를 추정하도록 구성됨 —; 및각 개개의 위치추정 후보(212)에 대해, 상기 개개의 위치추정 후보(212)에 대응하는 개개의 피처가 상기 BIM(30)의 시맨틱 정보(32)에 의해 식별된 상기 건물 환경(10) 내의 영구적인 물체(PO)인지 여부를 결정하는 동작; 및 상기 개개의 위치추정 후보(212)에 대응하는 상기 개개의 피처가 상기 BIM(30)의 시맨틱 정보(32)에 의해 식별된 상기 건물 환경(10) 내의 개개의 영구적인 물체(PO)인 경우, 상기 개개의 위치추정 후보(212)를 상기 로봇(100)에 대한 위치추정 맵(202)의 위치추정 기준점(222)으로서 생성하는 동작을 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 위치추정 맵(202)은 상기 건물 환경(10)을 통해 상기 로봇(100)을 자율적으로 안내하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항 또는 제2 항에 있어서,상기 동작들은 상기 건물 환경(10)의 위치추정 맵(202)을 상기 로봇(100)의 인식 시스템(180)에 공급하는 동작을 더 포함하며, 상기 인식 시스템(180)은 상기 로봇(100)이 상기 건물 환경(10)을 내비게이션(navigation)하여 상기 건물 환경(10) 내에서 작업을 수행할 때 상기 로봇(100)에 대한 장애물 회피를 수행하도록 구성되는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1 항 내지 제3 항 중 어느 한 항에 있어서,상기 BIM(30)은 스케줄 정보(schedule information)를 더 포함하고, 상기 스케줄 정보는 새로운 영구적인 물체(PO)가 상기 건물 환경(10)에 설치되는 시간을 나타내고,상기 동작들은,상기 새로운 영구적인 물체(PO)가 상기 건물 환경(10)에 설치된 시간 이후에 상기 새로운 영구적인 물체(PO)에 대한 센서 데이터(134)를 캡처하도록 상기 로봇(100)에게 명령하는 동작; 및상기 건물 환경(10)에 설치된 상기 새로운 영구적인 물체(PO)에 대해 캡처된 상기 센서 데이터(134)에 기초하여 상기 위치추정 맵(202)을 업데이트하는 동작을 더 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항 내지 제4 항 중 어느 한 항에 있어서,상기 시맨틱 정보(32)는 상기 건물 환경(10) 내의 물체들의 디스크립터(descriptor)들을 포함하며;상기 동작들은 상기 건물 환경(10) 내의 물체들의 하나 이상의 디스크립터들에 기초하여 센서 데이터(134)를 캡처하도록 상기 로봇(100)에게 명령하는 동작을 더 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제1 항 내지 제5 항 중 어느 한 항에 있어서,상기 BIM(30)은 상기 로봇(100)에 대한 비-스텝 영역(no-step region)을 더 포함하고, 상기 비-스텝 영역은 상기 로봇(100)이 스텝을 내디디는 것을 회피해야 하는 영역을 나타내며;상기 동작들은 상기 BIM(30)으로부터 상기 로봇(100)에 대한 비-스텝 영역을 나타내기 위해 상기 위치추정 맵(202)에 상기 비-스텝 영역을 생성하는 동작을 더 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서,상기 동작들은 상기 비-스텝 영역을 스텝 플래닝 제어기(step planning controller)(176)에 통신하는 동작을 더 포함하며, 상기 스텝 플래닝 제어기(176)는 상기 로봇(100)이 상기 건물 환경(10) 내에서 작업을 실행할 때 상기 로봇(100)에 대한 발자국 배치를 조정하도록 구성되는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1 항 내지 제7 항 중 어느 한 항에 있어서,상기 동작들은 상기 로봇(100)의 조작자(12)로부터 상기 로봇(100)이 상기 건물 환경(10) 내에서 수행할 작성된 작업(22)을 수신하는 동작; 및상기 위치추정 맵(202)을 사용하여 상기 작성된 작업(22)을 수행하도록 상기 건물 환경(10)을 통해 자율적으로 내비게이션하는 동작을 더 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 한 항에 있어서,상기 동작들은,상기 로봇(100)에 의해 캡처된 상기 센서 데이터(134)로부터 식별되는 인식된 물체에 대한 위치를 결정하는 것;상기 로봇(100)에 의해 캡처된 상기 센서 데이터(134)로부터 식별되는 상기 인식된 물체의 위치에 대응하는 상기 BIM(30) 내의 개개의 위치를 식별하는 것; 및상기 BIM(30)이 상기 개개의 위치에서 영구적인 물체(PO)를 나타내지 못한다고 결정하는 것에 의해,상기 위치추정 맵(202)으로부터 비영구적인 물체들(NPO)을 제거하는 동작을 더 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 한 항에 있어서,상기 로봇(100)은 4 개의 다리들(120, 120a 내지 120d)을 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제1 항 내지 제10 항 중 어느 한 항에 있어서,상기 BIM(30)은 상기 건물 환경(10)의 3차원 표현을 포함하는,데이터 처리 하드웨어에 의해 실행될 때 상기 데이터 처리 하드웨어가 동작들을 수행하게 하는 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 로봇(100)으로서,몸체(110);상기 몸체(110)에 결합된 하나 이상의 로코모션-기반 구조물(locomotion-based structure)들(120);상기 몸체(110) 상에 적어도 부분적으로 배치된 센서 시스템(sensor system)(130);상기 센서 시스템(130)과 통신하는 데이터 처리 하드웨어(142, 162, 410); 및상기 데이터 처리 하드웨어(142, 162, 410)와 통신하는 메모리 하드웨어(memory hardware)(144, 164, 420)를 포함하며, 상기 메모리 하드웨어(144, 164, 420)는, 상기 데이터 처리 하드웨어(142, 162, 410)에서 실행될 때, 상기 데이터 처리 하드웨어(142, 162, 410)가 동작들을 수행하게 하는 명령들을 저장하고, 상기 동작들은, 상기 로봇(100)이 건물 환경(10)을 횡단하는 동안, 상기 로봇(100)의 센서 시스템(130)에 의해 캡처된 센서 데이터(134)를 수신하는 동작; 상기 건물 환경(10)에 대한 건물 정보 모델(BIM)(30)을 수신하는 동작—상기 BIM(30)은 상기 건물 환경(10) 내의 하나 이상의 영구적인 물체들(PO)을 식별하는 시맨틱 정보(32)를 포함함—; 상기 건물 환경(10)의 위치추정 맵(202)에 대한 복수의 위치추정 후보들(212, 212a 내지 212n)을 생성하는 동작 — 상기 복수의 위치추정 후보들(212, 212a 내지 212n)의 각각의 위치추정 후보(212)는 상기 센서 데이터(134)에 의해 식별된 상기 건물 환경(10)의 피처에 대응하고 상기 로봇(100)에 대한 잠재적인 위치추정 기준점(222)을 나타내며, 상기 위치추정 맵(202)은 상기 로봇(100)이 상기 건물 환경(10) 전체에 걸쳐 이동할 때 상기 건물 환경(10) 내에서의 상기 로봇(100)의 위치를 추정하도록 구성됨 — ; 및각 개개의 위치추정 후보(212)에 대해, 상기 개개의 위치추정 후보(212)에 대응하는 개개의 피처가 상기 BIM(30)의 시맨틱 정보(32)에 의해 식별된 상기 건물 환경(10) 내의 영구적인 물체(PO)인지 여부를 결정하는 동작; 및 상기 개개의 위치추정 후보(212)에 대응하는 상기 개개의 피처가 상기 BIM(30)의 시맨틱 정보(32)에 의해 식별된 상기 건물 환경(10) 내의 개개의 영구적인 물체(PO)인 경우, 상기 개개의 위치추정 후보(212)를 상기 로봇(100)에 대한 위치추정 맵(202)의 위치추정 기준점(222)으로서 생성하는 동작을 포함하는,로봇.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 위치추정 맵(202)은 상기 건물 환경(10)을 통해 상기 로봇(100)을 자율적으로 안내하는,로봇.</claim></claimInfo><claimInfo><claim>14. 제12 항 또는 제13 항에 있어서,상기 동작들은 상기 건물 환경(10)의 위치추정 맵(202)을 상기 로봇(100)의 인식 시스템(180)에 공급하는 동작을 더 포함하며, 상기 인식 시스템(180)은 상기 로봇(100)이 상기 건물 환경(10)을 내비게이션하여 상기 건물 환경(10) 내에서 작업을 수행할 때 상기 로봇(100)에 대한 장애물 회피를 수행하도록 구성되는,로봇.</claim></claimInfo><claimInfo><claim>15. 제12 항 내지 제14 항 중 어느 한 항에 있어서,상기 BIM(30)은 스케줄 정보를 더 포함하고, 상기 스케줄 정보는 새로운 영구적인 물체(PO)가 상기 건물 환경(10)에 설치되는 시간을 나타내고,상기 동작들은, 상기 새로운 영구적인 물체(PO)가 상기 건물 환경(10)에 설치된 시간 이후에 상기 새로운 영구적인 물체(PO)에 대한 센서 데이터(134)를 캡처하도록 상기 로봇(100)에게 명령하는 동작; 및 상기 건물 환경(10)에 설치된 상기 새로운 영구적인 물체(PO)에 대해 캡처된 상기 센서 데이터(134)에 기초하여 상기 위치추정 맵(202)을 업데이트하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>16. 제12 항 내지 제15 항 중 어느 한 항에 있어서,상기 시맨틱 정보(32)는 상기 건물 환경(10) 내의 물체들의 디스크립터들을 포함하며;상기 동작들은 상기 건물 환경(10) 내의 물체들의 하나 이상의 디스크립터들에 기초하여 센서 데이터(134)를 캡처하도록 상기 로봇(100)에게 명령하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>17. 제12 항 내지 제16 항 중 어느 한 항에 있어서,상기 BIM(30)은 상기 로봇(100)에 대한 비-스텝 영역을 더 포함하고, 상기 비-스텝 영역은 상기 로봇(100)이 스텝을 내디디는 것을 회피해야 하는 영역을 나타내며;상기 동작들은 상기 BIM(30)으로부터 상기 로봇(100)에 대한 비-스텝 영역을 나타내기 위해 상기 위치추정 맵(202)에 상기 비-스텝 영역을 생성하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서,상기 동작들은 상기 비-스텝 영역을 스텝 플래닝 제어기(176)에 통신하는 동작을 더 포함하며, 상기 스텝 플래닝 제어기(176)는 상기 로봇(100)이 상기 건물 환경(10) 내에서 작업을 실행할 때 상기 로봇(100)에 대한 발자국 배치를 조정하도록 구성되는,로봇.</claim></claimInfo><claimInfo><claim>19. 제12 항 내지 제18 항 중 어느 한 항에 있어서,상기 동작들은 상기 로봇(100)의 조작자(12)로부터 상기 로봇(100)이 상기 건물 환경(10) 내에서 수행할 작성된 작업(22)을 수신하는 동작; 및상기 위치추정 맵(202)을 사용하여 상기 작성된 작업(22)을 수행하도록 상기 건물 환경(10)을 통해 자율적으로 내비게이션하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>20. 제12 항 내지 제19 항 중 어느 한 항에 있어서,상기 동작들은, 상기 로봇(100)에 의해 캡처된 상기 센서 데이터(134)로부터 식별되는 인식된 물체에 대한 위치를 결정하는 것; 상기 로봇(100)에 의해 캡처된 상기 센서 데이터(134)로부터 식별되는 상기 인식된 물체의 위치에 대응하는 상기 BIM(30) 내의 개개의 위치를 식별하는 것; 및 상기 BIM(30)이 상기 개개의 위치에서 영구적인 물체(PO)를 나타내지 못한다고 결정하는 것에 의해,상기 위치추정 맵(202)으로부터 비영구적인 물체들(NPO)을 제거하는 동작을 더 포함하는,로봇.</claim></claimInfo><claimInfo><claim>21. 제12 항 내지 제20 항 중 어느 한 항에 있어서,상기 하나 이상의 로코모션-기반 구조물들(120)은 4 개의 다리들(120, 120a 내지 120d)을 포함하는,로봇.</claim></claimInfo><claimInfo><claim>22. 제12 항 내지 제21 항 중 어느 한 항에 있어서,상기 BIM(30)은 상기 건물 환경(10)의 3차원 표현을 포함하는,로봇.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매사추세츠주 월섬 스미스 스트리트 *** 유닛 ****</address><code>520200430545</code><country>미국</country><engName>Boston Dynamics, Inc.</engName><name>보스턴 다이나믹스, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 매사추세츠 ...</address><code> </code><country> </country><engName>DA SILVA, Marco</engName><name>다 실바, 마르코</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠 ...</address><code> </code><country> </country><engName>JONAK, Dom</engName><name>조낙, 돔</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠 ...</address><code> </code><country> </country><engName>KLINGENSMITH, Matthew</engName><name>클링엔스미스, 매튜</name></inventorInfo><inventorInfo><address>미국 ***** 매사추세츠 ...</address><code> </code><country> </country><engName>SEIFERT, Samuel</engName><name>세이퍼트, 사무엘</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 서소문로**(서소문동, 정안빌딩*층)</address><code>920121001826</code><country>대한민국</country><engName>NAM &amp; NAM</engName><name>특허법인 남앤남</name></agentInfo><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.01.29</priorityApplicationDate><priorityApplicationNumber>63/143,528</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.07.26</receiptDate><receiptNumber>1-1-2023-0824636-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.09.01</receiptDate><receiptNumber>1-5-2023-0139728-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.03.13</receiptDate><receiptNumber>1-1-2024-0281102-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.01.24</receiptDate><receiptNumber>1-1-2025-0103165-18</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.01.24</receiptDate><receiptNumber>1-1-2025-0103166-64</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.11.09</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237025625.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b16f0eacb18ae59be39ffafd5bb0c6cf29117e3734ee6de7fd8d6a92186532aac6782addb5571eb5ce3232fbd7053acd260222e1a8e34e02</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf037ea6e03374faffdd6e1be7f4df8c796a94ad0ca0822006fd0cd57ac625059e85935edc8feed183d575f4efc074bfec636e7575792fefb7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>