<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:14:32.1432</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7029896</applicationNumber><claimCount>29</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>점 궤적을 사용한 이미지 애니메이션화</inventionTitle><inventionTitleEng>ANIMATING IMAGES USING POINT TRAJECTORIES</inventionTitleEng><openDate>2025.09.25</openDate><openNumber>10-2025-0140624</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.09.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.09.08</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 점 궤적을 사용하여 이미지를 애니메이션화하기 위해 컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램을 포함하는 방법, 시스템 및 장치. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.09.12</internationOpenDate><internationOpenNumber>WO2024184516</internationOpenNumber><internationalApplicationDate>2024.03.08</internationalApplicationDate><internationalApplicationNumber>PCT/EP2024/056192</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 컴퓨터에 의해 수행되고, 복수의 시간 단계에 걸쳐 입력 이미지를 애니메이션화하는 비디오를 생성하는 방법으로서, 상기 방법은, 입력 이미지를 수신하는 단계; 제1 생성형 신경망을 사용하여 입력 이미지로부터 도출된 제1 입력을 프로세싱하여 입력 이미지의 하나 이상의 지점 각각에 대한 개별 점 궤적을 생성하는 단계 - 각 점 궤적은 비디오의 복수의 시간 단계 각각에 대해, 비디오 내의 시간 단계에서의 비디오 프레임 내의 대응하는 지점의 예측된 공간 위치를 포함함 -; 및 제2 생성형 신경망을 사용하여 그리고 입력 이미지와 하나 이상의 점 궤적에 기초하여 입력 이미지를 애니메이션화하는 비디오 내의 비디오 프레임 각각을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 각 점 궤적은 시간 단계 각각에 대해, (i) 시간 단계에서의 비디오 프레임 내의 대응하는 지점의 예측된 공간 위치 및 (ii) 시간 단계에서의 비디오 프레임 내의 대응하는 지점이 가려질 가능성을 추정하는 가려짐 점수를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 이미지 인코더 신경망을 사용하여 입력 이미지를 프로세싱하여 입력 이미지의 인코딩된 표현을 생성하는 단계를 더 포함하고, 제1 입력은 입력 이미지의 인코딩된 표현을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제1 생성형 신경망은 제1 입력을 조건으로 하여 대응하는 노이즈성 궤적으로부터 각 점 궤적을 생성하는 확산 신경망인, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제1 생성형 신경망은 (i) 복수의 비디오 시퀀스와 (ii) 비디오 시퀀스 각각에 대해, 비디오 시퀀스 내의 제1 프레임 내의 하나 이상의 지점 각각에 대한 개별 점 궤적을 포함하는 트레이닝 데이터 세트에 대해 트레이닝되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제4항 또는 제5항에 있어서, 상기 제1 생성형 신경망은 2차원 컨볼루션 신경망을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 2차원 컨볼루션 신경망은 U-Net인, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서, 상기 2차원 컨볼루션 신경망은 하나 이상의 셀프 어텐션 계층을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제4항 내지 제8항 중 어느 한 항에 있어서, 각 대응하는 노이즈성 궤적은 노이즈성 좌표와 노이즈성 가려짐 추정치의 연쇄를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 노이즈성 좌표는 위치 인코딩으로 증강되는, 방법.</claim></claimInfo><claimInfo><claim>11. 제5항에 있어서, 적어도 비디오 시퀀스의 서브세트에 대해, 점 궤적 중 하나 이상은 점 추적 신경망을 사용하여 제1 프레임 내의 대응하는 지점을 포함하는 입력을 프로세싱함으로써 생성되는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 점 추적 신경망은, 서브세트 내의 각 비디오 시퀀스와 비디오 내의 제1 프레임 내의 대응하는 지점에 대해:대응하는 지점에 대한 쿼리 피처를 생성하고; 쿼리 피처를 사용하여, 비디오 시퀀스 내의 복수의 프레임 각각에 대한 개별 비용 맵을 포함하는 비용 체적을 생성하고; 복수의 프레임 각각에 대해, 프레임에 대한 비용 맵을 사용하여 프레임 내 대응하는 지점의 초기 위치와 프레임 내 대응하는 지점에 대한 초기 가려짐 추정치를 생성하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 점 추적 신경망은, 복수의 프레임에 대한 초기 위치 및 초기 가려짐 추정치를 포함하는 초기 점 궤적을 사용하여, 복수의 프레임에 대한 초기 위치를 정교화하거나, 초기 가려짐 추정치를 정교화하거나, 양자 모두를 수행함으로써 대응하는 지점에 대한 점 궤적을 생성하도록 더 구성되는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 복수의 프레임에 대한 초기 위치 및 초기 가려짐 추정치를 포함하는 초기 점 궤적을 사용하여, 복수의 프레임에 대한 초기 위치 및 초기 가려짐 추정치를 정교화하는 단계는, 하나 이상의 정교화 반복 각각에서: 정교화 반복 시점의 현재 점 궤적으로부터, 프레임 내의 현재 점 궤적의 예측된 위치 주변의 피처와 쿼리 피처 사이의 유사성을 각 프레임마다 포착하는 로컬 점수 맵의 세트를 생성하는 단계; 및 정교화 신경망을 사용하여, 로컬 점수 맵의 세트를 포함하는 입력을 프로세싱하여 현재 점 궤적에 대한 업데이트를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 정교화 신경망은 깊이별 컨볼루션 계층을 사용하여 프레임에 걸쳐 정보를 전파하는 깊이별 혼합 신경망인, 방법.</claim></claimInfo><claimInfo><claim>16. 제14항 또는 제15항에 있어서, 상기 입력은 로컬 점수 맵의 세트, 쿼리 피처 및 현재 점 궤적을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 제2 생성형 신경망은 상기 입력 이미지 및 하나 이상의 점 궤적으로부터 도출된 조건화 입력을 조건으로 하여 대응하는 노이즈성 프레임으로부터 각 프레임을 생성하는 확산 신경망인, 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 각 이미지에 대해, 상기 조건화 입력은 이미지를 표현하기 위해 하나 이상의 점 궤적에 따라 워핑된(warped) 입력 이미지의 워핑된 버전을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 각 이미지에 대해, 상기 조건화 입력은 이미지를 표현하기 위해 하나 이상의 점 궤적에 따라 워핑된 입력 이미지로부터 추출된 피처의 워핑된 버전을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제18항 또는 제19항에 있어서, 상기 확산 신경망은 복수의 역 확산 반복에 걸쳐 각 프레임을 생성하고, 적어도 프레임의 서브세트에 대해, 주어진 역 확산 반복에서의 입력은 역 확산 반복 시점의 비디오 내의 하나 이상의 이전 프레임의 현재 버전을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제1항 내지 제20항 중 어느 한 항에 있어서, 상기 입력 이미지는 특정 시간의 실제 세계 환경을 묘사하고, 비디오 프레임 각각은 특정 시간 이후의 대응하는 시간의 실제 세계 환경에 대한 예측인, 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 제어 시스템을 사용하여 비디오를 프로세싱하여, 비디오에 따라, 로봇 또는 기계적 에이전트를 제어하기 위한 하나 이상의 제어 신호를 생성하여 특정 태스크를 수행함으로써 제어 시스템을 사용하여 로봇 또는 기계적 에이전트를 제어하여 특정 태스크를 수행하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제1항 내지 제22항 중 어느 한 항에 있어서, 상기 입력 이미지는 특정 시간에 자세를 취하고 있는 사람을 묘사하고, 비디오 프레임 각각은 특정 시간 이후 대응하는 시간에 그 사람이 취할 자세에 대한 예측인, 방법.</claim></claimInfo><claimInfo><claim>24. 하나 이상의 컴퓨터에 의해 수행되고, 하나 이상의 비디오 시퀀스 각각에 대해, 비디오 시퀀스 내의 제1 프레임 내의 하나 이상의 지점 각각에 대한 개별 점 궤적을 생성하는 방법으로서, 상기 방법은, 점 추적 신경망을 사용하여 제1 프레임 내의 대응하는 지점을 포함하는 입력을 프로세싱하여 점 궤적 중 하나 이상을 생성하는 단계 - 상기 점 추적 신경망은, 각 비디오 시퀀스에 대해 그리고 비디오 내의 제1 프레임 내의 대응하는 지점에 대해:  대응하는 지점에 대한 쿼리 피처를 생성하고;  쿼리 피처를 사용하여, 비디오 시퀀스 내의 복수의 프레임 각각에 대해 개별 비용 맵을 포함하는 비용 체적을 생성하고;  복수의 프레임 각각에 대해, 프레임에 대한 비용 맵을 사용하여, 프레임 내의 대응하는 지점의 초기 위치 및 프레임 내의 대응하는 지점에 대한 초기 가려짐 추정치를 생성하도록 구성됨 -; 및복수의 프레임에 대한 초기 위치 및 초기 가려짐 추정치를 포함하는 초기 점 궤적을 사용하여, 복수의 프레임에 대한 초기 위치를 정교화하거나, 초기 가려짐 추정치를 정교화하거나, 양자 모두를 수행함으로써 대응하는 지점에 대한 점 궤적을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 복수의 프레임에 대한 초기 위치 및 초기 가려짐 추정치를 포함하는 초기 점 궤적을 사용하여, 복수의 프레임에 대한 초기 위치 및 초기 가려짐 추정치를 정교화하는 단계는, 하나 이상의 정교화 반복 각각에서: 정교화 반복 시점의 현재 점 궤적으로부터, 프레임 내의 현재 점 궤적의 예측된 위치 주변의 피처와 쿼리 피처 사이의 유사성을 각 프레임마다 포착하는 로컬 점수 맵의 세트를 생성하는 단계; 및 정교화 신경망을 사용하여, 로컬 점수 맵의 세트를 포함하는 입력을 프로세싱하여 현재 점 궤적에 대한 업데이트를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 정교화 신경망은 깊이별 컨볼루션 계층을 사용하여 프레임에 걸쳐 정보를 전파하는 깊이별 혼합 신경망인, 방법.</claim></claimInfo><claimInfo><claim>27. 제25항 또는 제26항에 있어서, 상기 입력은 로컬 점수 맵의 세트, 쿼리 피처 및 현재 점 궤적을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제24항 내지 제27항 중 어느 한 항에 있어서, 상기 방법은 (i) 하나 이상의 비디오 시퀀스와 (ii) 비디오 시퀀스 각각에 대해, 비디오 시퀀스 내의 제1 프레임 내 하나 이상의 지점 각각에 대한 개별 점 궤적을 포함하는 트레이닝 데이터 세트를 생성하기 위한 것인, 방법.</claim></claimInfo><claimInfo><claim>29. 시스템으로서, 하나 이상의 컴퓨터; 및 하나 이상의 컴퓨터에 통신 가능하게 결합된 하나 이상의 저장 디바이스를 포함하고, 하나 이상의 저장 디바이스는, 하나 이상의 컴퓨터에 의해 실행될 때, 하나 이상의 컴퓨터로 하여금 제1항 내지 제28항 중 어느 한 항에 따른 개별 방법의 동작을 수행하게 하는 명령어를 저장하는, 시스템.</claim></claimInfo><claimInfo><claim>30. 명령어를 저장하는 하나 이상의 비일시적 컴퓨터 저장 매체로서, 명령어는, 하나 이상의 컴퓨터에 의해 실행될 때, 하나 이상의 컴퓨터로 하여금 제1항 내지 제28항 중 어느 한 항의 개별 방법의 동작을 수행하게 하는, 하나 이상의 비일시적 컴퓨터 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 ***** 마운틴 뷰 엠피시어터 파크웨이 ****</address><code>520250465002</code><country>미국</country><engName>GDM Holding LLC</engName><name>지디엠 홀딩 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>미국</country><engName>DOERSCH, Carl</engName><name>도에르쉬, 칼</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>중국</country><engName>YANG, Yi</engName><name>양, 이</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>슬로바키아</country><engName>VECERIK, Mel</engName><name>베세릭, 멜</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>터어키</country><engName>GOKAY, Dilara</engName><name>고카이, 딜라라</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>인도</country><engName>GUPTA, Ankush</engName><name>굽타, 안쿠시</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>터어키</country><engName>AYTAR, Yusuf</engName><name>아이타르, 유수프</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>포르투칼</country><engName>CARREIRA, Joao</engName><name>카레이라, 조아오</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>영국</country><engName>ZISSERMAN, Andrew</engName><name>지서먼, 앤드류  </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 남대문로 **, *층(소공동, 한진빌딩 본관)</address><code>920151000211</code><country>대한민국</country><engName>Lee &amp; Ko IP</engName><name>특허법인광장리앤고</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.03.08</priorityApplicationDate><priorityApplicationNumber>63/450,951</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.03.15</priorityApplicationDate><priorityApplicationNumber>63/452,405</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2024.02.01</priorityApplicationDate><priorityApplicationNumber>63/548,824</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.09.08</receiptDate><receiptNumber>1-1-2025-1028810-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.09.08</receiptDate><receiptNumber>1-1-2025-1028869-83</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.09.08</receiptDate><receiptNumber>1-1-2025-1028890-32</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[우선심사신청]심사청구서·우선심사신청서</documentName><receiptDate>2025.09.08</receiptDate><receiptNumber>1-1-2025-1029054-68</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.09.10</receiptDate><receiptNumber>1-5-2025-0154410-88</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257029896.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a2aea52fec0f9595a7a273f05be30ef29804b1274b8c4ae47e824ef8b11b65a04c6481326014250ca5009b0370a72f117fc9df4e4551539e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfef6af86810fb2d14e0bb0b13eb84b9a6a2119d2a371b96956ed13f7b527df0b0c79a12288a9b0c6943949e11636b44a0503a885947cc4c62</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>