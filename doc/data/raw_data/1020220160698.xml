<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:59.4059</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.11.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0160698</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>멀티모달 데이터 기반 사용자 성향 도출 방법</inventionTitle><inventionTitleEng>Method for deriving user propensity based on multimodal data</inventionTitleEng><openDate>2024.06.03</openDate><openNumber>10-2024-0078094</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.01.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06Q 10/1053</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A61B 5/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 실시예는, 영상 분석 장치와 영상 분석 장치의 동작 방법에 대한 것이다. 실시예에 따른 영상 분석 장치의 동작 방법은, 입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계; 영상을 분석하여 사용자의 멀티모달 데이터를 획득하는 단계; 및 학습된 신경망을 통해 멀티모달 데이터를 분석하여 사용자의 성향 정보를 분석하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 영상 분석 장치의 동작 방법에 있어서,입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계;상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계; 및학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 성향 정보를 분석하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 성향 정보를 분석하는 단계는,상기 사용자의 성향이 외향적인지 내향적인지 분석하는 단계; 및상기 사용자의 성향이 사고형인지 감정형인지 분석하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계는,카메라를 통해 입력되는 상기 사용자의 얼굴 영역을 포함하는 영상 데이터에서 상기 사용자의 적어도 하나의 신체 부위를 탐지하는 단계; 및상기 탐지된 적어도 하나의 신체 부위의 움직임을 추적하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 사용자의 적어도 하나의 신체 부위는,상기 사용자의 눈, 입술, 얼굴, 손, 어깨 중 적어도 하나를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계는,상기 사용자에게 질의를 제공하는 단계; 및상기 질의에 반응하여, 마이크를 통해 입력되는 상기 사용자의 음성 데이터를 수신하는 단계; 및상기 음성 데이터를 텍스트 데이터로 변환하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 학습된 신경망은,적어도 하나의 멀티모달 데이터 및 성향 검사를 통해 획득한 성향 정보가 레이블링된 학습 데이터 세트에 기초하여 학습되는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 분석된 성향 정보에 기초하여 상기 사용자에 적합한 직무 정보를 제공하는 단계를 더 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 신경망을 학습하는 방법에 있어서,멀티모달 데이터들 및 상기 멀티모달 데이터들에 레이블링된 성향 정보를 포함하는 학습 데이터를 획득하는 단계;적어도 하나의 신체 부위가 탐지되는 복수 개의 영상 데이터들을 분석하여 획득한 멀티모달 데이터를 상기 신경망에 입력하는 단계; 및상기 멀티모달 데이터에 대응하여 레이블링된 성향 정보가 출력되도록 상기 신경망을 학습하는 단계를 포함하는,신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 학습 데이터는,컴퓨터 환경 및 모바일 환경에 따라 각각 같은 형태로 스케일링되고,데이터 불균형의 보완을 위해 시계열 시퀀스가 조정되어 증식된,신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 적어도 하나의 신체 부위는,눈, 입술, 얼굴, 손, 어깨 중 적어도 하나를 포함하고,상기 멀티모달 데이터는, 상기 적어도 하나의 신체 부위의 움직임을 포함하는,신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 멀티모달 데이터를 추출하여 상기 신경망에 입력하는 단계는,상기 적어도 하나의 신체 부위의 움직임 정보를 상기 신경망에 입력하는 단계; 및질의에 대한 반응에 해당하는 반응 정보를 상기 신경망에 입력하는 단계를 포함하는, 신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>12. 하드웨어와 결합되어 제1항 내지 제11항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 영상 분석 장치에 있어서,하나 이상의 프로세서;메모리; 및상기 메모리에 저장되어 있으며 상기 하나 이상의 프로세서에 의하여 실행되도록 구성되는 하나 이상의 프로그램을 포함하고,상기 프로그램은,입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계;상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계; 및학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 성향 정보를 분석하는 단계를 실행하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 성향 정보를 분석하는 단계는,상기 사용자의 성향이 외향적인지 내향적인지 분석하는 단계; 및상기 사용자의 성향이 사고형인지 감정형인지 분석하는 단계를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계는,카메라를 통해 입력되는 상기 사용자의 얼굴 영역을 포함하는 영상 데이터에서 상기 사용자의 적어도 하나의 신체 부위를 탐지하는 단계; 및상기 탐지된 적어도 하나의 신체 부위의 움직임을 추적하는 단계를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 사용자의 적어도 하나의 신체 부위는,상기 사용자의 눈, 입술, 얼굴, 손, 어깨 중 적어도 하나를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서,상기 입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계는,상기 사용자에게 질의를 제공하는 단계; 및상기 질의에 반응하여, 마이크를 통해 입력되는 상기 사용자의 음성 데이터를 수신하는 단계; 및상기 음성 데이터를 텍스트 데이터로 변환하는 단계를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서,상기 학습된 신경망은,적어도 하나의 멀티모달 데이터 및 성향 검사를 통해 획득한 성향 정보가 레이블링된 학습 데이터 세트에 기초하여 학습되는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>19. 제13항에 있어서,상기 분석된 성향 정보에 기초하여 상기 사용자에 적합한 직무 정보를 제공하는 단계를 더 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>20. 제13항에 있어서,상기 신경망은,다변수 RNN(Multivariate RNNs) 및 FCN(Fully Convolutional Network)를 포함하는 구조인,영상 분석 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>부산광역시 강서구...</address><code>120170679454</code><country>대한민국</country><engName>WITHMIND</engName><name>주식회사 위드마인드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>JOO Min Sung</engName><name>주민성</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.11.25</receiptDate><receiptNumber>1-1-2022-1266578-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification for Deferment of Submission of Claims</documentEngName><documentName>청구범위 제출유예 안내서</documentName><receiptDate>2022.12.05</receiptDate><receiptNumber>1-5-2022-0182399-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName> </documentEngName><documentName>[임시명세서보정(특허)]보정서</documentName><receiptDate>2024.01.23</receiptDate><receiptNumber>1-1-2024-0090020-78</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.01.23</receiptDate><receiptNumber>1-1-2024-0090026-41</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.03.11</receiptDate><receiptNumber>4-1-2024-5088819-71</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.11.21</receiptDate><receiptNumber>4-1-2024-5339798-63</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220160698.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338e0d982468ee18e9e1c05ca2ee0687184e467f481cce0c776b394fbf06b820eba1eeadee0568e23f116eb7cba1d229979d96196e27883147fb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6a4430ef103a31f40d406b66e577b60e2153a1232534168f11a4138a40091d239d3c6dc66e885906bdedcb0b66a159ec07c371f56d092513</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>