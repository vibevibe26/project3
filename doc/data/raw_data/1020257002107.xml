<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:38:18.3818</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.11.13</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7002107</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>표면 기반 신경 합성을 사용한 이미지 생성</inventionTitle><inventionTitleEng>IMAGE GENERATION USING SURFACE-BASED NEURAL SYNTHESIS</inventionTitleEng><openDate>2025.02.03</openDate><openNumber>10-2025-0016496</openNumber><originalApplicationDate>2020.11.13</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2022-7019683</originalApplicationNumber><originalExaminationRequestDate>2025.01.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.01.21</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 17/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020227019683</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 동작들을 수행하기 위한 시스템 및 방법을 수반하며, 이 동작들은: 3차원 객체의 2차원 연속 표면 표현을 수신하는 동작 - 연속 표면은 복수의 랜드마크 로케이션을 포함함 -; 2차원 연속 표면 표현에서의 포인트들의 상대적 로케이션 및 랜드마크 로케이션들에 기초하여 제1 세트의 소프트 멤버십 함수들을 결정하는 동작; 2차원 입력 이미지를 수신하는 동작 - 입력 이미지는 객체의 이미지를 포함함 -; 피처 인식 모델을 사용하여 입력 이미지로부터 복수의 피처를 추출하는 동작; 제1 세트의 소프트 멤버십 함수들을 사용하여 추출된 피처들의 인코딩된 피처 표현을 생성하는 동작; 제2 세트의 소프트 멤버십 함수들을 사용하여 인코딩된 표현으로부터 추출된 피처들의 조밀한 피처 표현을 생성하는 동작; 및 신경 이미지 디코더 모델을 사용하여 제2 세트의 소프트 멤버십 함수들 및 조밀한 피처 표현을 처리하여 출력 이미지를 생성하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.05.20</internationOpenDate><internationOpenNumber>WO2021094526</internationOpenNumber><internationalApplicationDate>2020.11.13</internationalApplicationDate><internationalApplicationNumber>PCT/EP2020/082047</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,제1 포즈에서의 사람을 묘사하는 2차원(2D) 입력 이미지를 수신하는 단계;제2 포즈에 대응하는 타깃 이미지를 수신하는 단계;소프트 피처 풀링(soft feature pooling) 피처들을 생성하기 위해 상기 2D 입력 이미지를 처리하는 단계;타깃 소프트 고유 거리(soft intrinsic distance)들을 생성하기 위해 상기 타깃 이미지를 처리하는 단계; 및상기 제2 포즈에서의 상기 사람을 묘사하는 디코딩된 이미지를 생성하기 위해 상기 소프트 피처 풀링 피처들 및 타깃 소프트 고유 거리들의 조합에 기초하여 상기 2D 입력 이미지의 피처들을 디코딩하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,2차원 연속 표면 표현에서의 복수의 포인트와 상기 2D 입력 이미지의 랜드마크 로케이션들 사이의 거리들을 결정하는 단계; 및상기 결정된 거리들에 기초하여 상기 복수의 포인트 중 각각의 포인트를 랜드마크에 할당하는 단계에 의해 제1 세트의 소프트 멤버십 함수들을 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 랜드마크 인식 모델을 사용하여 랜드마크 로케이션들을 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 2D 입력 이미지의 2차원 연속 표면 표현을 조건으로 하는 컨볼루션 신경망을 포함하는 신경 이미지 디코더 모델에 의해 피처들을 디코딩하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 추출된 피처들의 각각의 채널에 대한 평균 및 분산의 멤버십 가중 추정(membership-weighted estimate)을 수행하는 것에 의해 제1 세트의 소프트 멤버십 함수들을 사용하여 상기 2D 입력 이미지의 상기 추출된 피처들의 인코딩된 피처 표현을 생성하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 추출된 피처들의 각각의 채널에 대한 평균 및 분산의 상기 멤버십 가중 추정에 이중 연산(dual operation)을 적용하는 것에 의해 제2 세트의 소프트 멤버십 함수들을 사용하여 상기 인코딩된 피처 표현으로부터 추출된 피처들의 조밀한 피처 표현을 생성하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 사람의 관절들을 포함하는 랜드마크들을 검출하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 피처들을 디코딩하기 위해 사용되는 제1 세트의 소프트 멤버십 함수들 및 제2 세트의 소프트 멤버십 함수들은 동일한, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 2D 입력 이미지로부터 상기 사람의 3차원(3D) 모델을 생성하는 단계; 및상기 3D 모델로부터 2D 연속 표면 표현을 생성하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 2D 입력 이미지의 조밀한 피처 표현을 생성하기 전에 상기 2D 입력 이미지의 인코딩된 표현 내의 값들을 수정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 2D 입력 이미지로부터 3차원(3D) 객체의 2D 연속 표면 표현을 생성하는 단계;추가 2D 입력 이미지를 수신하는 단계 - 상기 추가 입력 이미지는 추가 객체를 포함함 -;상기 추가 2D 입력 이미지로부터 상기 3D 객체의 추가 2D 연속 표면 표현을 생성하는 단계 - 상기 추가 연속 표면은 복수의 랜드마크 로케이션을 포함함 -; 및상기 추가 2D 연속 표면 표현에서의 포인트들의 상대적 로케이션들 및 상기 랜드마크 로케이션들에 기초하여 제2 세트의 소프트 멤버십 함수들을 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 디코딩된 이미지는 상기 2D 입력 이미지의 보이지 않는 부분들에 대응하는 부분들을 포함하고,학습된 주의 메커니즘을 사용하여 인코딩된 표현으로부터 상기 보이지 않는 부분들에 대응하는 2차원 연속 표면 표현의 부분들을 생성하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 학습된 주의 메커니즘은 제1 세트의 소프트 멤버십 함수들에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,인코더 신경망을 사용하여 소스 이미지로부터 콘텐츠 피처들의 세트를 결정하는 단계;상기 인코더 신경망을 이용하여 스타일 이미지로부터 스타일 피처들의 세트를 결정하는 단계;상기 소스 이미지의 구역들에서의 위치 및 콘텐츠 피처들의 공동 통계를 사용하여 위치 의존적 콘텐츠 피처들을 결정하는 단계;상기 스타일 이미지의 구역들에서의 위치 및 스타일 피처들의 공동 통계를 이용하여 위치 의존적 스타일 피처들을 결정하는 단계;상기 위치 및 콘텐츠 피처들의 공동 통계에 기초하여 상기 위치 의존적 콘텐츠 피처들의 세트로부터 변환된 콘텐츠 피처들의 세트를 생성하는 단계;상기 위치 및 스타일 피처들의 공동 통계에 기초하여 상기 변환된 콘텐츠 피처들의 세트로부터 변환된 스타일 피처들의 세트를 생성하는 단계; 및디코더 신경망을 사용하여 상기 스타일 피처들의 변환된 세트 및 상기 콘텐츠 피처들의 변환된 세트로부터 출력 이미지를 생성하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 조합 이미지를 생성하기 위해 상기 출력 이미지를 또 다른 출력 이미지와 조합하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서, 상기 위치 및 콘텐츠 피처들의 공동 통계는, 콘텐츠 피처 평균, 콘텐츠 위치 평균 및 콘텐츠 피처들과 콘텐츠 위치들 사이의 공분산들을 포함하고, 상기 위치 의존적 콘텐츠 피처들을 결정하는 단계는 위치를 조건으로 하는 상기 콘텐츠 피처들의 조건부 모델을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 콘텐츠 피처들의 조건부 모델은 위치 의존적 콘텐츠 평균 및 조건부 콘텐츠 공분산을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 위치 의존적 콘텐츠 피처들의 세트로부터 상기 변환된 콘텐츠 피처들의 세트를 생성하는 단계는,상기 위치 의존적 콘텐츠 평균에 기초하여 상기 위치 의존적 콘텐츠 피처들을 센터링하는 단계; 및상기 조건부 콘텐츠 공분산에 기초하여 백색화 변환을 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 신경 이미지 분석을 위한 시스템으로서,동작들을 수행하도록 구성된 프로세서를 포함하고, 상기 동작들은,제1 포즈에서의 사람을 묘사하는 2차원(2D) 입력 이미지를 수신하는 동작;제2 포즈에 대응하는 타깃 이미지를 수신하는 동작;소프트 피처 풀링 피처들을 생성하기 위해 상기 2D 입력 이미지를 처리하는 동작;타깃 소프트 고유 거리들을 생성하기 위해 상기 타깃 이미지를 처리하는 동작; 및상기 제2 포즈에서의 상기 사람을 묘사하는 디코딩된 이미지를 생성하기 위해 상기 소프트 피처 풀링 피처들 및 타깃 소프트 고유 거리들의 조합에 기초하여 상기 2D 입력 이미지의 피처들을 디코딩하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함하는 비일시적 머신 판독가능 저장 매체로서, 상기 명령어들은, 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금,제1 포즈에서의 사람을 묘사하는 2차원(2D) 입력 이미지를 수신하는 동작;제2 포즈에 대응하는 타깃 이미지를 수신하는 동작;소프트 피처 풀링 피처들을 생성하기 위해 상기 2D 입력 이미지를 처리하는 동작;타깃 소프트 고유 거리들을 생성하기 위해 상기 타깃 이미지를 처리하는 동작; 및상기 제2 포즈에서의 상기 사람을 묘사하는 디코딩된 이미지를 생성하기 위해 상기 소프트 피처 풀링 피처들 및 타깃 소프트 고유 거리들의 조합에 기초하여 상기 2D 입력 이미지의 피처들을 디코딩하는 동작을 포함하는 신경 이미지 분석을 위한 동작들을 수행하게 야기하는 비일시적 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>그리스</country><engName>KOKKINOS, Iason</engName><name>코키노스, 이아손</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>그리스</country><engName>PAPANDREOU, Georgios</engName><name>파판드레우, 게오르기오스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>터어키</country><engName>GULER, Riza, Alp</engName><name>굴러, 리자, 알프</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.11.15</priorityApplicationDate><priorityApplicationNumber>62/936,328</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.01.21</receiptDate><receiptNumber>1-1-2025-0079209-20</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257002107.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e7d4a77dfa1f64b7f587282d972c58f61128db948c40cf9cbfd63639e22566885fd199bfdc6ef35fe1c1f7f498b2671a476b800ef69bc5cf</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4935a89fef392ac96387b2dc96b9e48712ce9ad05413699041ee7d0508ab215e9f63f8613136157f1ef8156a47463a7639341369c427633e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>