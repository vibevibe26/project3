<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:37.4037</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.02.22</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7027621</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오 코딩을 위한 기계 학습 기반 플로우 결정</inventionTitle><inventionTitleEng>MACHINE LEARNING BASED FLOW DETERMINATION FOR VIDEO CODING</inventionTitleEng><openDate>2023.10.30</openDate><openNumber>10-2023-0150274</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.08.14</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/537</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/159</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/186</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/587</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/132</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 시스템들 및 기법들은 비디오 데이터를 프로세싱하기 위하여 본원에 설명된다. 일부 양태들에서, 방법은 기계 학습 시스템에 의해, 입력 비디오 데이터를 획득하는 단계를 포함할 수 있다. 입력 비디오 데이터는 현재 프레임에 대한 하나 이상의 휘도 성분들을 포함한다. 방법은 기계 학습 시스템에 의해, 현재 프레임에 대한 휘도 성분(들)을 사용하여 현재 프레임의 휘도 성분(들)에 대한 모션 정보 및 현재 프레임의 하나 이상의 색차 성분들에 대한 모션 정보를 결정하는 단계를 포함할 수 있다. 일부 경우들에서, 방법은 현재 프레임의 루마 성분(들) 및 이전 프레임의 적어도 하나의 재구성된 루마 성분에 기초하여 휘도 성분(들)에 대한 모션 정보를 결정하는 단계를 포함할 수 있다. 일부 경우들에서, 방법은 현재 프레임의 휘도 성분(들)에 대해 결정된 모션 정보를 사용하여 현재 프레임의 색차 성분(들)에 대한 모션 정보를 결정하는 단계를 더 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.09.01</internationOpenDate><internationOpenNumber>WO2022182651</internationOpenNumber><internationalApplicationDate>2022.02.22</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/017296</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 데이터를 프로세싱하는 방법으로서,기계 학습 시스템에 의해, 현재 프레임에 대한 적어도 하나의 휘도 성분을 포함하는 입력 비디오 데이터를 획득하는 단계; 및상기 기계 학습 시스템에 의해, 상기 현재 프레임에 대한 상기 적어도 하나의 휘도 성분을 사용하여, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 모션 정보 및 상기 현재 프레임의 하나 이상의 색차 성분들에 대한 모션 정보를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 추가로상기 기계 학습 시스템에 의해, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 모션 정보 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 모션 정보를 사용하여, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 하나 이상의 워핑 파라미터들을 결정하는 단계; 및상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 하나 이상의 워핑 파라미터들을 사용하여, 상기 현재 프레임에 대한 하나 이상의 인터-프레임 예측들을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 상기 하나 이상의 인터-프레임 예측들은 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 하나 이상의 워핑 파라미터들을 사용하여 보간 연산 (interpolation operation) 을 적용함으로써 적어도 부분적으로 결정되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서, 상기 보간 연산은 삼선형 보간 (trilinear interpolation) 연산을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제 2 항에 있어서, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 하나 이상의 워핑 파라미터들은 공간-스케일 플로우 (SSF) 워핑 파라미터들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서, 상기 SSF 워핑 파라미터들은 학습된 스케일-플로우 벡터들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서, 상기 현재 프레임에 대한 상기 적어도 하나의 휘도 성분을 사용하여 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 모션 정보 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보를 결정하는 단계는,상기 현재 프레임의 상기 적어도 하나의 휘도 성분 및 이전 프레임의 적어도 하나의 재구성된 루마 성분에 기초하여 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 모션 정보를 결정하는 단계; 및상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대해 결정된 상기 모션 정보를 사용하여 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제 7 항에 있어서, 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보는 상기 기계 학습 시스템의 컨볼루션 계층 (convolutional layer) 을 사용하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제 7 항에 있어서, 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보는 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대해 결정된 상기 모션 정보를 샘플링함으로써 적어도 부분적으로 결정되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제 1 항에 있어서, 상기 현재 프레임은 비디오 프레임을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서, 상기 하나 이상의 색차 성분들은 적어도 하나의 색차-청색 성분 및 색차-적색 성분을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제 1 항에 있어서, 상기 현재 프레임은 휘도-색차 (YUV) 포맷을 갖는, 방법.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서, 상기 YUV 포맷은 YUV 4:2:0 포맷인, 방법.</claim></claimInfo><claimInfo><claim>14. 비디오 데이터를 프로세싱하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은기계 학습 시스템을 사용하여, 현재 프레임에 대한 적어도 하나의 휘도 성분을 포함하는 입력 비디오 데이터를 획득하고, 그리고상기 기계 학습 시스템을 사용하여, 상기 현재 프레임에 대한 상기 적어도 하나의 휘도 성분을 사용하여, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 모션 정보 및 상기 현재 프레임의 하나 이상의 색차 성분들에 대한 모션 정보를 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서, 상기 하나 이상의 프로세서들은,상기 기계 학습 시스템을 사용하여, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 모션 정보 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 모션 정보에 기초하여, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 하나 이상의 워핑 파라미터들을 결정하고, 그리고상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 하나 이상의 워핑 파라미터들을 사용하여, 상기 현재 프레임에 대한 하나 이상의 인터-프레임 예측들을 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서, 상기 하나 이상의 인터-프레임 예측들은 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 하나 이상의 워핑 파라미터들을 사용하여 보간 연산을 적용함으로써 적어도 부분적으로 결정되는, 장치.</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서, 상기 보간 연산은 삼선형 보간 연산을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>18. 제 15 항에 있어서, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 워핑 파라미터 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 하나 이상의 워핑 파라미터들은 공간-스케일 플로우 (SSF) 워핑 파라미터들을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서, 상기 SSF 워핑 파라미터들은 학습된 스케일-플로우 벡터들을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>20. 제 14 항에 있어서, 상기 현재 프레임에 대한 상기 적어도 하나의 휘도 성분을 사용하여 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 모션 정보 및 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보를 결정하기 위해, 상기 하나 이상의 프로세서들은,상기 현재 프레임의 상기 적어도 하나의 휘도 성분 및 이전 프레임의 적어도 하나의 재구성된 루마 성분에 기초하여 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 상기 모션 정보를 결정하고, 그리고상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대해 결정된 상기 모션 정보를 사용하여 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보를 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서, 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보는 상기 기계 학습 시스템의 컨볼루션 계층을 사용하여 결정되는, 장치.</claim></claimInfo><claimInfo><claim>22. 제 20 항에 있어서, 상기 현재 프레임의 상기 하나 이상의 색차 성분들에 대한 상기 모션 정보를 결정하기 위해, 상기 하나 이상의 프로세서들은 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대해 결정된 상기 모션 정보를 샘플링하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>23. 제 14 항에 있어서, 상기 현재 프레임은 비디오 프레임을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>24. 제 14 항에 있어서, 상기 하나 이상의 색차 성분들은 적어도 하나의 색차-청색 성분 및 색차-적색 성분을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>25. 제 14 항에 있어서, 상기 현재 프레임은 휘도-색차 (YUV) 포맷을 갖는, 장치.</claim></claimInfo><claimInfo><claim>26. 제 25 항에 있어서, 상기 YUV 포맷은 YUV 4:2:0 포맷인, 장치.</claim></claimInfo><claimInfo><claim>27. 제 14 항에 있어서, 하나 이상의 프레임들을 캡처하도록 구성된 적어도 하나의 카메라를 더 포함하는, 장치.</claim></claimInfo><claimInfo><claim>28. 제 14 항에 있어서, 하나 이상의 프레임들을 디스플레이하도록 구성된 적어도 하나의 디스플레이를 더 포함하는, 장치.</claim></claimInfo><claimInfo><claim>29. 제 14 항에 있어서, 상기 장치는 모바일 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>30. 명령들이 저장된 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 명령들은, 하나 이상의 프로세서들에 의해 실행될 경우, 상기 하나 이상의 프로세서들로 하여금기계 학습 시스템을 사용하여, 현재 프레임에 대한 적어도 하나의 휘도 성분을 포함하는 입력 비디오 데이터를 획득하게 하고, 그리고상기 기계 학습 시스템을 사용하여, 상기 현재 프레임에 대한 상기 적어도 하나의 휘도 성분을 사용하여, 상기 현재 프레임의 상기 적어도 하나의 휘도 성분에 대한 모션 정보 및 상기 현재 프레임의 하나 이상의 색차 성분들에 대한 모션 정보를 결정하게 하는, 비일시적 컴퓨터 판독가능 저장 매체. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>SINGH, ANKITESH KUMAR</engName><name>싱 안키테쉬 쿠마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>EGILMEZ, HILMI ENES</engName><name>에길메즈 힐미 에네스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>COBAN, MUHAMMED ZEYD</engName><name>코반 무하메드 제이드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>KARCZEWICZ, MARTA</engName><name>카르체비츠 마르타</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.02.25</priorityApplicationDate><priorityApplicationNumber>63/153,475</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.02.21</priorityApplicationDate><priorityApplicationNumber>17/676,510</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.08.14</receiptDate><receiptNumber>1-1-2023-0893904-46</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.10.04</receiptDate><receiptNumber>1-5-2023-0155731-27</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.02.05</receiptDate><receiptNumber>1-1-2025-0132343-18</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.02.05</receiptDate><receiptNumber>1-1-2025-0132344-64</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.02.05</receiptDate><receiptNumber>1-1-2025-0132345-10</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237027621.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9345017c9bae68c2c19c433b90a0a50a8e186a8981dc4baf70d709b727265f7827fc481196124aa7a38866864c9eee1f2c72584398c3a48cee</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd007bd616f9e66629eca7f7b17c4773b321cd836e34f95233fc03e7d18ff0b688226a3a2a0e41a30d84d9f0fd105d07d819e13be554cea9a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>