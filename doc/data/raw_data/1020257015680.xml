<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:07.407</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.11.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7015680</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>텍스트-이미지 생성을 위한 멀티 리워드 강화 학습 프레임워크를 위한 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEMS AND METHODS FOR MULTI-REWARD REINFORCEMENT LEARNING FRAMEWORK FOR TEXT-TO-IMAGE GENERATION</inventionTitleEng><openDate>2025.07.22</openDate><openNumber>10-2025-0111111</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.05.13</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.05.13</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/092</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 텍스트-이미지 생성을 위한 멀티 리워드 강화 학습 프레임워크를 위한 시스템 및 방법이 개시된다. 본 방법은, 멀티 리워드(multi-reward) 강화 학습 모델을 사용하여 프롬프트 확장 모델과 이미지 생성 모델을 동시에 트레이닝하는 단계를 포함하며, 트레이닝하는 단계는, 프롬프트 확장 모델에 의해, 트레이닝 질의 및 트레이닝 컨텍스트 데이터를 프로세싱하여 확장된 트레이닝 질의를 생성하는 단계; 이미지 생성 모델에 의해, 확장된 트레이닝 질의에 기초하여 이미지 데이터의 트레이닝 세트를 생성하는 단계; 리워드 모델 세트를 사용하여 이미지 데이터의 트레이닝 세트 내의 각 이미지 데이터에 대한 리워드 점수 세트를 생성하는 단계 — 리워드 점수 세트를 생성하는 단계는 복수의 리워드 기준들 내의 각 리워드 기준에 대한 적어도 하나의 리워드 점수를 생성하는 단계를 포함함 —; 및 멀티 리워드 강화 학습 모델을 사용하여 리워드 점수 세트에 기초하여 복수의 리워드 기준들과 연관된 가중치들 및 바이어스들을 조정하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2025.07.17</internationOpenDate><internationOpenNumber>WO2025151190</internationOpenNumber><internationalApplicationDate>2024.11.13</internationalApplicationDate><internationalApplicationNumber>PCT/US2024/055734</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 구현 방법으로서,멀티 리워드 강화 학습 모델을 사용하여 프롬프트 확장 모델과 이미지 생성 모델을 동시에 트레이닝하는 단계를 포함하고, 상기 트레이닝하는 단계는, 프롬프트 확장 모델에 의해, 트레이닝 질의 및 트레이닝 컨텍스트 데이터를 프로세싱하여 확장된 트레이닝 질의를 생성하는 단계; 이미지 생성 모델에 의해, 확장된 트레이닝 질의에 기초하여 이미지 데이터의 트레이닝 세트를 생성하는 단계; 리워드 모델 세트를 사용하여 이미지 데이터의 트레이닝 세트 내의 각 이미지 데이터에 대한 리워드 점수 세트를 생성하는 단계 — 상기 리워드 점수 세트를 생성하는 단계는 복수의 리워드 기준 내의 각 리워드 기준에 대한 적어도 하나의 리워드 점수를 생성하는 단계를 포함함 —; 및 멀티 리워드 강화 학습 모델을 사용하여 리워드 점수 세트에 기초하여 복수의 리워드 기준과 연관된 가중치 및 바이어스를 조정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,컴퓨팅 시스템에 의해, 사용자 질의 및 질의 컨텍스트 데이터를 포함하는 입력 데이터를 획득하는 단계;트레이닝된 프롬프트 확장 모델 및 트레이닝된 이미지 생성 모델을 사용하여, 사용자 질의 및 질의 컨텍스트 데이터에 기초하여 이미지 데이터를 생성하는 단계를 포함하며, 상기 이미지 데이터를 생성하는 단계는, 트레이닝된 프롬프트 확장 모델에 의해, 사용자 질의 및 질의 컨텍스트 데이터를 프로세싱하여 확장된 사용자 질의를 생성하는 단계; 및 트레이닝된 이미지 생성 모델을 사용하여, 확장된 사용자 질의에 기초하여 이미지 데이터를 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 확장된 사용자 질의를 생성하는 단계는 복수의 리워드 기준을 확장된 사용자 질의에 통합시키는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 복수의 리워드 기준은 하나 이상의 텍스트-이미지 정렬 리워드 기준을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제2항 및 제4항 중 한 항에 있어서, 상기 하나 이상의 텍스트-이미지 정렬 리워드 기준은,트레이닝 질의와 연관된 제1 텍스트-이미지 정렬 리워드 기준; 및확장된 트레이닝 질의와 연관된 제2 텍스트-이미지 정렬 리워드 기준을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 복수의 리워드 기준은 하나 이상의 이미지 정서 리워드 기준을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 복수의 리워드 기준은 하나 이상의 심미적 리워드 기준을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 복수의 리워드 기준은 하나 이상의 사람 선호도 리워드 기준을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 프롬프트 확장 모델과 이미지 생성 모델을 트레이닝하는 단계는,비지배적 소팅 알고리즘(non-dominated sorting algorithm)을 사용하여 리워드 점수 세트의 함수로서 이미지 데이터의 트레이닝 세트로부터 이미지 데이터의 서브세트를 선택하는 단계; 및멀티 리워드 강화 학습 모델을 사용하여 이미지 데이터의 서브세트에 기초하여 복수의 리워드 기준과 연관된 가중치 및 바이어스를 조정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 이미지 데이터의 서브세트는 리워드 점수 세트와 연관된 파레토 최적 세트(pareto-optimal set)를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제9항 및 제10항 중 한 항에 있어서, 상기 프롬프트 확장 모델과 이미지 생성 모델을 트레이닝하는 단계는,컴퓨팅 시스템에 의해, 정책 경사(policy gradient) 업데이트를 이미지 데이터의 서브세트의 함수로서 결정하는 단계; 및정책 경사 업데이트의 함수로서 멀티 리워드 강화 학습 모델을 사용하여 복수의 리워드 기준과 연관된 가중치 및 바이어스를 조정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 정책 경사 업데이트를 결정하는 단계는 이미지 데이터의 서브세트 내에서 표현되지 않은 각 리워드 기준과 연관된 리워드 점수를 최소화하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>13. 제11항 또는 제12항 중 한 항에 있어서, 상기 정책 경사 업데이트를 결정하는 단계는 이미지 데이터의 서브세트 내에서 표현되는 각 리워드 기준과 연관된 리워드 점수를 최대화하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>14. 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 정책 경사 업데이트를 결정하는 단계는 하나 이상의 텍스트-이미지 정렬 리워드 기준을 최대화하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>15. 컴퓨팅 시스템으로서,하나 이상의 프로세서; 및하나 이상의 프로세서로 하여금 동작들을 수행하게 하기 위해 실행가능한 명령어를 저장하는 하나 이상의 일시적 또는 비일시적 컴퓨터 판독가능 매체를 포함하며, 상기 동작들은, 하나 이상의 프로세서에 의해, 사용자 질의 및 질의 컨텍스트 데이터를 포함하는 입력 데이터를 획득하는 동작; 멀티 리워드 강화 학습 모델을 사용하여 프롬프트 확장 모델과 이미지 생성 모델을 동시에 트레이닝하는 동작 — 상기 프롬프트 확장 모델과 이미지 생성 모델을 트레이닝하는 동작은,  프롬프트 확장 모델에 의해, 트레이닝 질의 및 트레이닝 컨텍스트 데이터를 프로세싱하여 확장된 트레이닝 질의를 생성하는 동작;  이미지 생성 모델을 사용하여, 확장된 트레이닝 질의에 기초하여 이미지 데이터의 트레이닝 세트를 생성하는 동작;  리워드 모델 세트를 사용하여 이미지 데이터의 트레이닝 세트 내의 각 이미지 데이터에 대한 리워드 점수 세트를 생성하는 동작 — 상기 리워드 점수 세트를 생성하는 동작은 복수의 리워드 기준 내의 각 리워드 기준에 대한 적어도 하나의 리워드 점수를 생성하는 동작을 포함함 —;  비지배적 소팅 알고리즘을 사용하여 리워드 점수 세트의 함수로서 이미지 데이터의 트레이닝 세트로부터 이미지 데이터의 서브세트를 선택하는 동작; 및  멀티 리워드 강화 학습 모델을 사용하여 이미지 데이터의 서브세트 내에서 표현되지 않는 각 리워드 기준과 연관된 가중치 및 바이어스를 최소화하는 동작을 포함함 —; 및 트레이닝된 프롬프트 확장 모델 및 트레이닝된 이미지 생성 모델을 사용하여, 사용자 질의 및 질의 컨텍스트 데이터에 기초하여 이미지 데이터를 생성하는 동작을 포함하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 이미지 데이터를 생성하는 동작은,트레이닝된 프롬프트 확장 모델에 의해, 사용자 질의 및 질의 컨텍스트 데이터를 프로세싱하여 확장된 사용자 질의를 생성하는 동작; 및트레이닝된 이미지 생성 모델에 의해, 확장된 사용자 질의에 기초하여 이미지 데이터를 생성하는 동작을 더 포함하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 확장된 사용자 질의를 생성하는 동작은 복수의 리워드 기준을 확장된 사용자 질의에 통합시키는 동작을 포함하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>18. 제15항 내지 제17항 중 어느 한 항에 있어서, 상기 프롬프트 확장 모델과 상기 이미지 생성 모델을 트레이닝하는 동작은,컴퓨팅 시스템에 의해, 정책 경사 업데이트를 이미지 데이터의 서브세트의 함수로서 결정하는 동작; 및정책 경사 업데이트의 함수로서 멀티 리워드 강화 학습 모델을 사용하여 복수의 리워드 기준과 연관된 가중치 및 바이어스를 조정하는 동작을 더 포함하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 정책 경사 업데이트를 결정하는 동작은 이미지 데이터의 서브세트 내에서 표현되는 각 리워드 기준과 연관된 리워드 점수를 최대화하는 동작을 더 포함하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>20. 컴퓨터 구현 방법으로서,멀티 리워드 강화 학습 모델을 사용하여 프롬프트 확장 모델(프롬프트 확장 모델)과 이미지 생성 모델을 동시에 트레이닝하는 단계를 포함하며, 상기 트레이닝하는 단계는, 프롬프트 확장 모델에 의해, 트레이닝 질의 및 트레이닝 컨텍스트 데이터를 프로세싱하여 확장된 트레이닝 질의를 생성하는 단계; 이미지 생성 모델에 의해, 확장된 트레이닝 질의에 기초하여 이미지 데이터의 트레이닝 세트를 생성하는 단계; 및 이미지 데이터의 트레이닝 세트에 기초하여 멀티 리워드 강화 학습 모델을 사용하여 프롬프트 확장 모델과 이미지 생성 모델을 동시에 트레이닝하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>대한민국</country><engName>LEE, Seung Hyun</engName><name>이승현</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>YANG, Feng</engName><name>양 펭</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>LI, Yinxiao</engName><name>리 인시아오</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>KE, Junjie</engName><name>케 준지</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>대한민국</country><engName>YOO, Innfarn</engName><name>유인판</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>ZHANG, Han</engName><name>장 한</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>YU, Jiahui</engName><name>유 지아후이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>WANG, Qifei</engName><name>왕 퀴페이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>DENG, Fei</engName><name>뎅 페이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>미국</country><engName>ENTIS, Glenn Michael</engName><name>엔티스 글렌 마이클</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>HE, Junfeng</engName><name>헤 준펭</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>중국</country><engName>LI, Gang</engName><name>리 강</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터...</address><code> </code><country>미국</country><engName>ESSA, Irfan Aziz</engName><name>에싸 이르판 아지즈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2024.01.10</priorityApplicationDate><priorityApplicationNumber>63/619,632</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.05.13</receiptDate><receiptNumber>1-1-2025-0533722-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.05.21</receiptDate><receiptNumber>1-5-2025-0084756-94</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257015680.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c040d70001b624f5d816ad422406a5811fa25bab3247d04299cbb54f84d47c0628bcaccc8d7ea96a54c14d6172bcacc8fc27752e7df8473f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe0c42753f4473da4be9984fe15be97753354eec7b5a981fe079f58e2c7fae64b818ee2f9e6ad20c382ab2a3b9398b62537b73ceb8ec2d98f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>