<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:28:18.2818</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2025.09.05</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-0126787</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사용자의 시선 방향에 따라 초점 영역을 조절하는 증강 현실 디바이스 및 그 동작 방법</inventionTitle><inventionTitleEng>AUGMENTED REALITY DEVICE FOR ADJUSTING A FOCUS REGION  ACCORDING TO A DIRECTION OF AN USER'S VIEW AND METHOD FOR  OPERATING THE SAME</inventionTitleEng><openDate>2025.09.19</openDate><openNumber>10-2025-0138154</openNumber><originalApplicationDate>2019.09.19</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2019-0115473</originalApplicationNumber><originalExaminationRequestDate>2025.10.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G02B 30/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/322</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/39</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/332</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/383</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020190115473</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 굴절력을 조절함으로써 초점 거리를 조절할 수 있는 가변 초점 렌즈를 포함하고, 사용자의 시선 방향에 따라 가변 초점 렌즈 내의 초점 조절 영역의 위치를 조절하는 증강 현실 디바이스 및 그 동작 방법을 제공한다. 일 실시예에서, 증강 현실 디바이스는 시선 추적기(eye tracker)를 이용하여 사용자의 시선 방향을 나타내는 시선 벡터를 획득하고, 가상 이미지가 표시되는 초점 거리를 변경하기 위하여 제1 가변 초점 렌즈의 제1 초점 조절 영역의 굴절력을 조절하고, 제2 가변 초점 렌즈의 굴절력을 제1 초점 조절 영역의 조절된 굴절력에 대하여 상보적으로(complementary) 조절하는 것을 특징으로 한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 제1 가변 초점 렌즈 및 제2 가변 초점 렌즈; 상기 제1 가변 초점 렌즈와 상기 제2 가변 초점 렌즈 사이에 배치되는(disposed) 웨이브가이드; 사용자의 시선 방향을 획득하도록 구성되는 시선 추적 센서;적어도 하나의 현실 세계 객체의 깊이 값을 획득하도록 구성되는 깊이 센서; 및적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는: 상기 시선 추적 센서에 의해 획득된 사용자의 시선 방향에 기초하여 상기 제1 가변 초점 렌즈의 제1 초점 조절 영역을 결정하고, 상기 사용자의 시선 방향에 기초하여 응시점(gaze point)을 획득하고, 상기 깊이 센서를 통해 상기 응시점의 위치에 배치된 현실 세계 객체의 깊이 값을 획득하고, 상기 획득된 깊이 값에 기초하여, 상기 제1 초점 조절 영역의 굴절력을 조절하고, 상기 제1 초점 조절 영역의 조절된 굴절력에 기초하여 상기 제2 가변 초점 렌즈의 제2 초점 조절 영역의 굴절력을 조절하는, 증강 현실 디바이스. </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 적어도 하나의 프로세서는,상기 시선 추적 센서에 의해 획득된 사용자의 시선 방향에 기초하여 상기 제2 가변 초점 렌즈의 제2 초점 조절 영역을 결정하는, 증강 현실 디바이스.</claim></claimInfo><claimInfo><claim>3. 상기 제2 항에 있어서,상기 적어도 하나의 프로세서는 상기 시선 추적 센서에 의해 획득된 시선 방향의 변화에 기초하여 상기 제1 초점 조절 영역 및 제2 초점 조절 영역의 위치를 변경하는, 증강 현실 디바이스. </claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서, 상기 적어도 하나의 프로세서는, 상기 제1 초점 조절 영역의 굴절력을 조절함으로써, 상기 웨이브가이드를 통해 출력되는 가상 객체의 초점 거리를 상기 응시점의 위치에 배치된 상기 현실 세계 객체의 깊이 값에 대응되도록 조절하는, 증강 현실 디바이스. </claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서, 상기 적어도 하나의 프로세서는, 상기 제1 초점 조절 영역의 굴절력을 조절함으로써, 상기 웨이브가이드를 통해 출력되는 가상 객체의 초점 거리를 상기 응시점의 위치에 배치된 상기 현실 세계 객체의 깊이 값에 대하여 미리 결정된 크기만큼 크거나 또는 작게 조절하는, 증강 현실 디바이스.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서, 상기 적어도 하나의 프로세서는, 상기 제2 초점 조절 영역의 굴절력을 상기 제1 초점 조절 영역의 굴절력에 대하여 상보적으로(complementarily) 조절하는, 증강 현실 디바이스.</claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 제1 초점 조절 영역의 굴절력은 제1 디옵터(diopter) 값으로 조절되고, 상기 적어도 하나의 프로세서는, 상기 제2 초점 조절 영역의 굴절력을 상기 제1 디옵터 값과 동일한 값을 갖고, 상기 제1 디옵터 값의 부호와는 반대 부호를 갖는 제2 디옵터 값으로 조절하는, 증강 현실 디바이스. </claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서, 스토리지(storage); 를 더 포함하고, 상기 깊이 센서는, 물리적 공간 또는 환경에서 상기 현실 세계 객체의 깊이 값을 측정하고, 상기 측정된 깊이 값을 3차원(3D) 좌표 값에 따라 배열하여 깊이 맵을 생성하고,상기 생성된 깊이 맵을 상기 스토리지에 저장하고, 상기 적어도 하나의 프로세서는, 상기 스토리지에서 상기 깊이 맵을 로드(load)하여 상기 응시점의 위치에 배치된 현실 세계 객체의 깊이 값을 획득하는, 증강 현실 디바이스.</claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서, 가상 이미지의 광을 상기 웨이브가이드를 향하여(toward) 투사하도록 구성된 디스플레이 모듈; 을 더 포함하고, 상기 적어도 하나의 프로세서는: 물리적 공간 또는 환경에서 복수의 현실 세계 객체를 인식하고,상기 인식된 복수의 현실 세계 객체 각각에 관련된 정보를 포함하는 복수의 가상 객체를 생성하고,상기 생성된 복수의 가상 객체의 광을 상기 웨이브가이드를 향하여 투사하여, 상기 복수의 가상 객체를 표시하도록 상기 디스플레이 모듈을 제어하는, 증강 현실 디바이스. </claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서, 상기 복수의 가상 객체는, 상기 복수의 현실 세계 객체 각각에 대한 상세 설명, 가격 정보, 할인 정보, 구매할 수 있는 웹 사이트 주소, 사용자 평점, 및 광고 중 적어도 하나와 관련된 정보를 포함하는, 증강 현실 디바이스.</claim></claimInfo><claimInfo><claim>11. 증강 현실 디바이스의 동작 방법에 있어서, 상기 증강 현실 디바이스의 시선 추적 센서를 통해, 상기 증강 현실 디바이스의 사용자의 시선 방향을 획득하는 단계;상기 시선 방향에 기초하여, 제1 가변 초점 렌즈의 제1 초점 조절 영역을 결정하는 단계;상기 시선 방향에 기초하여, 응시점을 획득하는 단계; 상기 증강 현실 디바이스의 깊이 센서를 통해, 상기 응시점의 위치에 배치된 현실 세계 객체의 깊이 값을 획득하는 단계;상기 획득된 깊이 값에 기초하여, 상기 제1 초점 조절 영역의 굴절력을 조절하는 단계; 및 상기 제1 초점 조절 영역의 조절된 굴절력에 기초하여, 제2 가변 초점 렌즈의 제2 초점 조절 영역의 굴절력을 조절하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 제2 가변 초점 렌즈의 제2 초점 조절 영역은 상기 시선 추적 센서를 통해 획득된 상기 사용자의 시선 방향에 기초하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>13. 상기 제12 항에 있어서,상기 제1 초점 조절 영역 및 제2 초점 조절 영역의 위치는 상기 시선 추적 센서에 의해 획득된 시선 방향의 변화에 기초하여 변경되는, 증강 현실 디바이스.</claim></claimInfo><claimInfo><claim>14. 제11 항에 있어서, 상기 제1 초점 조절 영역의 굴절력을 조절하는 단계는,  상기 제1 초점 조절 영역의 굴절력을 조절함으로써, 웨이브가이드를 통해 출력되는 가상 객체의 초점 거리를 상기 응시점의 위치에 배치된 상기 현실 세계 객체의 깊이 값에 대응되도록 조절하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>15. 제11 항에 있어서, 상기 제1 초점 조절 영역의 굴절력을 조절하는 단계는,  상기 제1 초점 조절 영역의 굴절력을 조절함으로써, 웨이브가이드를 통해 출력되는 가상 객체의 초점 거리를 상기 응시점의 위치에 배치된 상기 현실 세계 객체의 깊이 값에 대하여 미리 결정된 크기만큼 크거나 또는 작게 조절하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>16. 제11 항에 있어서, 상기 제2 초점 조절 영역의 굴절력을 조절하는 단계는, 상기 제2 초점 조절 영역의 굴절력을 상기 제1 초점 조절 영역의 굴절력에 대하여 상보적으로(complementarily) 조절하는, 방법. </claim></claimInfo><claimInfo><claim>17. 제16 항에 있어서, 상기 제1 초점 조절 영역의 굴절력은 제1 디옵터(diopter) 값으로 조절되고, 상기 제2 초점 조절 영역의 굴절력을 조절하는 단계는, 상기 제2 초점 조절 영역의 굴절력을 상기 제1 디옵터 값과 동일한 값을 갖고, 상기 제1 디옵터 값의 부호와는 반대 부호를 갖는 제2 디옵터 값으로 조절하는, 방법. </claim></claimInfo><claimInfo><claim>18. 제11 항에 있어서, 상기 현실 세계 객체의 깊이 값을 획득하는 단계는,상기 증강 현실 디바이스의 깊이 센서를 이용하여 물리적 공간 또는 환경에서 상기 현실 세계 객체의 깊이 값을 측정하는 단계; 상기 측정된 깊이 값을 3차원(3D) 좌표 값에 따라 배열하여 깊이 맵을 생성하는 단계; 상기 생성된 깊이 맵을 상기 증강 현실 디바이스의 스토리지에 저장하는 단계; 및상기 스토리지에서 상기 깊이 맵을 로드(load)하여 상기 응시점의 위치에 배치된 현실 세계 객체의 깊이 값을 획득하는 단계;를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>19. 제11 항에 있어서, 물리적 공간 또는 환경에서 복수의 현실 세계 객체를 인식하는 단계; 상기 인식된 복수의 현실 세계 객체 각각에 관련된 정보를 포함하는 복수의 가상 객체를 생성하는 단계; 및 상기 생성된 복수의 가상 객체의 광을 웨이브가이드를 향하여 투사함으로써, 디스플레이 모듈을 통해 상기 복수의 가상 객체를 디스플레이하는 단계;를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>20. 제19 항에 있어서, 상기 복수의 가상 객체는, 상기 복수의 현실 세계 객체 각각에 대한 상세 설명, 가격 정보, 할인 정보, 구매할 수 있는 웹 사이트 주소, 사용자 평점, 및 광고 중 적어도 하나와 관련된 정보를 포함하는, 방법.  </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>LEE, Kyookeun</engName><name>이규근</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>KWAK, Kyusub</engName><name>곽규섭</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>KOO, Bonkon</engName><name>구본곤</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>YUN, Jeonggeun</engName><name>윤정근</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>LEE, Wonjun</engName><name>이원준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>CHOI, Myongjo</engName><name>최명조</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>CHOI, Jongchul</engName><name>최종철</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.05.27</priorityApplicationDate><priorityApplicationNumber>62/853,082</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2025.09.05</receiptDate><receiptNumber>1-1-2025-1025122-82</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.02</receiptDate><receiptNumber>1-1-2025-1129274-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020250126787.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93ca4a6390016a98689790947b5f9ae8e0e96d25d75d5b455da14138915220dae385da3dc32da81c7127a3e16079a328f6a417cd991fd8c96a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbdf0409d25b10693047fe2e48ffab219aee1a1fa4e138914108ce5d613325b6af4f4620a0700f49676e8b7eaee8953aed777c1f250185f73</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>