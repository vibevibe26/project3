<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:11.511</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.22</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0163784</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사용자에 의한 유효한(valid) 터치 입력을 판단하는 증강 현실 디바이스 및 그 동작 방법</inventionTitle><inventionTitleEng>AUGMENTED REALITY DEVICE FOR DETERMINING VALID TOUCH  INPUT BY A USER AND METHOD FOR OPERATING THE SAME</inventionTitleEng><openDate>2025.05.29</openDate><openNumber>10-2025-0076284</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/041</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04W 4/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/02</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 사용자가 증강 현실 디바이스를 안전하고 편리하게 사용할 수 있도록 터치 인터페이스에 대한 유효한(valid) 터치 입력을 판단하고, 유효하지 않은 터치 입력에 의한 인터랙션이 자동으로 수행되는 것을 방지하는 증강 현실 디바이스 및 그 동작 방법을 제공한다. 본 개시의 일 실시예에 따른 증강 현실 디바이스는 손의 움직임에 관한 센싱 데이터에 기초하여 터치 인터페이스에 대한 터치 입력이 사용자의 의도(intention)에 의한 유효 입력(valid input)인지 여부를 판단하며, 판단 결과에 따라 인터랙션(interaction)을 수행할 지 여부를 결정할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 센서;터치 입력을 수신하도록 구성되는 터치 인터페이스(160); 적어도 하나의 명령어들(instructions)를 저장하는 메모리(150); 및상기 적어도 하나의 명령어들을 실행하는 적어도 하나의 프로세서(140); 를 포함하고, 상기 적어도 하나의 프로세서(140)는, 상기 적어도 하나의 센서를 통해 손의 움직임을 센싱하고, 상기 센싱된 손의 움직임에 기초하여 상기 터치 인터페이스(160)를 통해 수신된 터치 입력이 유효 입력(valid input)인지 여부를 판단하고, 상기 유효 입력에 관한 판단 결과에 기초하여 상기 터치 입력에 대응되는 인터랙션(interaction)을 수행할 지 여부를 결정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 적어도 하나의 프로세서(140)는, 판단 결과, 상기 터치 입력이 유효하지 않은 무효 입력(invalid input)으로 판단된 경우, 상기 터치 입력에 대응되는 기능 또는 동작을 수행하지 않고, 상기 터치 입력을 무시하는(ignore), 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>3. 제1 항 또는 제2 항에 있어서,상기 적어도 하나의 센서는 카메라로 구성되는 비전 센서(vision sensor)(110)를 포함하고, 상기 적어도 하나의 프로세서(140)는, 상기 카메라를 이용하여 사용자의 손을 연속적으로 촬영함으로써, 손에 관한 복수의 이미지 프레임을 획득하고, 상기 획득된 복수의 이미지 프레임을 인공지능 모델에 입력하고, 상기 인공지능 모델에 의한 비전 인식을 수행하여 상기 복수의 이미지 프레임으로부터 손의 관절에 관한 특징점을 검출하고, 상기 검출된 특징점의 시간의 흐름에 따른 이동에 기초하여 손 올리기 동작을 인식하며, 상기 손 올리기 동작이 인식된 시점으로부터 기 설정된 시간 내에 상기 터치 입력이 검출되는 경우, 상기 터치 입력을 유효 입력으로 결정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서, 상기 카메라는 상기 증강 현실 디바이스 상의 서로 다른 위치에 배치되고, 서로 다른 뷰(view)를 갖는 복수의 카메라를 포함하고, 상기 적어도 하나의 프로세서(140)는, 상기 복수의 카메라 각각을 통해 촬영된 서로 다른 시점(view point)을 갖는 복수의 이미지 프레임 각각으로부터 상기 손의 부분(part) 별 특징점을 검출하고,상기 복수의 이미지 프레임을 결합하여, 상기 복수의 이미지 프레임 각각으로부터 검출된 부분 별 특징점들 간의 시간적 및 공간적 상관 관계(temporal and spatial correlations)를 식별하고, 상기 특징점들 간의 시간적 및 공간적 상관 관계에 기초하여 상기 손 올리기 동작을 인식하는, 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>5. 제1 항 또는 제2 항에 있어서, 상기 적어도 하나의 센서는 객체의 깊이 값(depth value)을 획득하는 깊이 카메라(depth camera)로 구성되는 비전 센서(110)를 포함하고, 상기 적어도 하나의 프로세서(140)는, 상기 깊이 카메라를 통해 연속적으로 획득된 복수의 이미지 프레임으로부터 손의 깊이 값을 획득하고, 상기 획득된 깊이 값의 시간의 흐름에 따른 변화를 인식하고, 상기 깊이 값의 변화에 기초하여 손 올리기 동작을 인식하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>6. 제1 항 또는 제2 항에 있어서, 외부 디바이스와 데이터 통신을 수행하는 통신 인터페이스(170);를 더 포함하고, 상기 통신 인터페이스(170)는 사용자의 손에 착용된 웨어러블 디바이스(200)에 포함되는 센서로부터 센싱 데이터를 수신하고, 상기 적어도 하나의 프로세서(140)는, 상기 수신된 센싱 데이터에 기초하여 상기 사용자의 손과 상기 증강 현실 디바이스 간의 거리(distance), 방향(direction), 및 방위(orientation) 중 적어도 하나에 관한 정보를 포함하는 상대적 위치 관계 정보를 획득하고, 상기 획득된 상대적 위치 관계 정보에 기초하여, 상기 사용자의 손이 기 설정된 허용 가능한 영역(acceptable region) 내에 위치하는지 여부를 식별하며, 식별 결과에 기초하여 상기 터치 입력이 유효 입력인지 여부를 판단하는, 증강 현실 디바이스(100).  </claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 웨어러블 디바이스(200)는 UWB(Ultra Wide Band) 통신 모듈 및 블루투스(Bluetooth) 통신 모듈 중 적어도 하나를 포함하고, 상기 센싱 데이터는 상기 웨어러블 디바이스(200)로부터 수신된 UWB 신호에 의한 AoA(Angle of Arrival) 정보 및 BLE(Bluetooth Low Energy) 위치 정보 중 적어도 하나를 포함하는, 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>8. 제1 항 또는 제2 항에 있어서, 상기 적어도 하나의 센서는, 뇌파(brainwave)에 의한 전위 변동을 센싱하여 EEG(electroencephalogram) 신호 데이터를 획득하도록 구성되는 뇌파 센서(120);를 포함하고, 상기 적어도 하나의 프로세서(140)는, 상기 뇌파 센서(120)를 이용하여 사용자의 머리의 뇌파에 의한 전위 변동을 센싱함으로써 EEG 신호 데이터를 획득하고, 상기 획득된 EEG 신호 데이터에 기초하여 뇌파 전위의 부정적 피드백(negative feedback)을 식별하며, 식별 결과에 기초하여 상기 터치 입력이 유효 입력인지 여부를 판단하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서, 상기 적어도 하나의 프로세서(140)는, 상기 터치 입력이 수신된 시점으로부터 기 설정된 시간 동안 상기 EEG 신호 데이터의 전위 특성 변동을 모니터링함으로써, 오류 관련 부정 전위(error-related negativity, ERN)를 식별하고, 상기 오류 관련 부정 전위가 식별되는 경우, 상기 터치 입력을 유효 입력으로 결정하는, 증강 현실 디바이스(100).</claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 하나의 항에 있어서, 상기 적어도 하나의 센서는 증강 현실 디바이스(100)의 움직임을 감지하는 모션 센서(130);를 포함하고, 상기 적어도 하나의 프로세서(140)는, 상기 모션 센서(130)를 이용하여 사용자의 조정 입력(adjusting input)에 의한 상기 증강 현실 디바이스(100)의 진동(vibration) 또는 움직임(movement)을 포함하는 모션 정보를 획득하고, 상기 터치 입력이 검출된 이후에 상기 모션 정보가 획득되는 경우, 상기 터치 입력을 무효 입력으로 결정하는, 증강 현실 디바이스(100). </claim></claimInfo><claimInfo><claim>11. 증강 현실 디바이스(100)의 동작 방법에 있어서, 적어도 하나의 센서를 이용하여 손의 움직임에 관한 센싱 데이터를 획득하는 단계(S210); 상기 증강 현실 디바이스(100)의 터치 인터페이스(160)에 대한 터치 입력을 검출하는 단계(S220); 및상기 획득된 센싱 데이터에 기초하여 상기 터치 입력이 유효 입력(valid input) 인지 여부를 판단하는 단계(S230); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 유효 입력에 관한 판단 결과, 상기 터치 입력이 유효하지 않은 무효 입력(invalid input)으로 판단된 경우, 상기 터치 입력에 대응되는 기능 또는 동작을 수행하지 않고, 상기 터치 입력을 무시하는(ignore) 단계;를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>13. 제11 항 또는 제12 항에 있어서,상기 적어도 하나의 센서는 카메라로 구성되는 비전 센서(vision sensor)(110)를 포함하고, 상기 센싱 데이터를 획득하는 단계(S210)는, 상기 카메라를 이용하여 사용자의 손을 연속적으로 촬영함으로써, 손에 관한 복수의 이미지 프레임을 획득하는 단계(S610);를 포함하고, 상기 증강 현실 디바이스(100)의 동작 방법은, 상기 획득된 복수의 이미지 프레임을 인공지능 모델에 입력하고, 상기 인공지능 모델을 이용하는 추론(inferencing)을 통해 상기 복수의 이미지 프레임으로부터 손의 관절에 관한 특징점을 검출하는 단계(S620); 및상기 검출된 특징점의 시간의 흐름에 따른 이동에 기초하여 손 올리기 동작을 인식하는 단계(S630); 를 더 포함하고, 상기 터치 입력이 유효 입력인지 여부를 판단하는 단계(S230)는,상기 손 올리기 동작이 인식된 시점으로부터 기 설정된 시간 내에 상기 터치 입력이 검출되는 경우, 상기 터치 입력을 유효 입력으로 결정하는 단계(S650); 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서, 상기 카메라는 상기 증강 현실 디바이스 상의 서로 다른 위치에 배치되고, 서로 다른 뷰(view)를 갖는 복수의 카메라를 포함하고, 상기 손 올리기 동작을 인식하는 단계(S630)는,상기 복수의 카메라 각각을 통해 촬영된 서로 다른 시점(view point)을 갖는 복수의 이미지 프레임 각각으로부터 상기 손의 부분(part) 별 특징점을 검출하는 단계(S810); 상기 복수의 이미지 프레임을 결합하여, 상기 복수의 이미지 프레임 각각으로부터 검출된 부분 별 특징점들 간의 시간적 및 공간적 상관 관계(temporal and spatial correlations)를 식별하는 단계(S820); 및상기 특징점들 간의 시간적 및 공간적 상관 관계에 기초하여 상기 손 올리기 동작을 인식하는 단계(S830);를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>15. 제11 항 또는 제12 항에 있어서, 상기 적어도 하나의 센서는 객체의 깊이 값(depth value)을 획득하는 깊이 카메라(depth camera)로 구성되는 비전 센서(110)를 포함하고, 상기 증강 현실 디바이스(100)의 동작 방법은, 상기 깊이 카메라를 통해 연속적으로 획득된 복수의 이미지 프레임으로부터 손의 깊이 값을 획득하는 단계(S1220); 상기 획득된 깊이 값의 시간의 흐름에 따른 변화를 인식하는 단계(S1230); 및상기 깊이 값의 변화에 기초하여 손 올리기 동작을 인식하는 단계(S1240);를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>16. 제11 항 또는 제12 항에 있어서, 상기 센싱 데이터를 획득하는 단계(S210)는,사용자의 손에 착용된 웨어러블 디바이스(200)에 포함되는 센서로부터 상기 센싱 데이터를 수신하는 단계(S1410); 및 상기 수신된 센싱 데이터에 기초하여 사용자의 손과 상기 증강 현실 디바이스 간의 거리(distance), 방향(direction), 및 방위(orientation) 중 적어도 하나에 관한 정보를 포함하는 상대적 위치 관계 정보를 획득하는 단계(S1420); 를 포함하고, 상기 터치 입력이 유효 입력인지 여부를 판단하는 단계(S230)는,상기 획득된 상대적 위치 관계 정보에 기초하여, 상기 사용자의 손이 기 설정된 허용 가능한 영역(acceptable region) 내에 위치하는지 여부를 식별하는 단계(S1430); 및식별 결과에 기초하여 상기 터치 입력이 유효 입력인지 여부를 판단하는 단계(S1440);를 포함하는, 방법.  </claim></claimInfo><claimInfo><claim>17. 제11 항 또는 제12 항에 있어서, 상기 적어도 하나의 센서는, 뇌파(brainwave)에 의한 전위 변동을 센싱하여 EEG(electroencephalogram) 신호 데이터를 획득하도록 구성되는 EEG 센서;를 포함하고, 상기 센싱 데이터를 획득하는 단계(S210)는,상기 EEG 센서를 이용하여 사용자의 머리의 뇌파에 의한 전위 변동을 센싱함으로써, EEG 신호 데이터를 획득하는 단계(S1710); 를 포함하고, 상기 터치 입력이 유효 입력인지 여부를 판단하는 단계(S230)는, 상기 획득된 EEG 신호 데이터에 기초하여 뇌파 전위의 부정적 피드백(negative feedback)을 식별하는 단계(S1720); 및식별 결과에 기초하여, 상기 터치 입력이 유효 입력인지 여부를 판단하는 단계(S1730);를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서, 상기 뇌파 전위의 부정적인 피드백을 식별하는 단계(S1720)는,상기 터치 입력이 수신된 시점으로부터 기 설정된 시간 동안 상기 EEG 신호 데이터의 전위 특성 변동을 모니터링함으로써, 오류 관련 부정 전위(error-related negativity, ERN)를 식별하는 단계;를 포함하고, 상기 터치 입력이 유효 입력인지 여부를 판단하는 단계(S230)는,상기 오류 관련 부정 전위가 식별되는 경우, 상기 터치 입력을 유효입력으로 결정하는 단계;를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>19. 제11 항 내지 제18 항 중 어느 하나의 항에 있어서, 상기 센싱 데이터를 획득하는 단계(S210)는, 모션 센서(130)를 통해 상기 증강 현실 디바이스(100)의 움직임에 관한 모션 정보를 획득하는 단계; 및 상기 모션 센서(130)를 이용하여 사용자가 증강 현실 디바이스를 조정하는 조정 입력(adjusting input)에 의한 상기 증강 현실 디바이스의 진동(vibration) 또는 움직임(movement)에 관한 상기 모션 정보를 획득하는 단계(S1910);를 포함하고, 상기 터치 입력이 유효 입력인지 여부를 판단하는 단계(S230)는, 상기 터치 입력이 검출된 이후에 상기 모션 정보가 획득되는 경우, 상기 터치 입력을 무효 입력으로 결정하는 단계; 를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>20. 제11 항 내지 제19 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>방글라데시 다카 **** 비르 우탐 씨.알...</address><code> </code><country> </country><engName>KHAN, Md Sazzad Hissain</engName><name>칸 엠디 사자드 히사인</name></inventorInfo><inventorInfo><address>방글라데시 다카 **** 비르 우탐 씨.알...</address><code> </code><country> </country><engName>KOWSER, Aba</engName><name>코우저 아바</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.22</receiptDate><receiptNumber>1-1-2023-1306644-92</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230163784.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931792d097891e809a9364a3680364f4eb14b390dedd18796c94eb3265110934ef880faa5410ce43eaea999a9b09a49f9aa0a3b56fae16c1a2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfab33cdfc523979453af58b171253d46d577301dfb531e2647bb607f371dde703bb56bbe9b58e4919d4cb350b95a1ad103e8c060df49f265c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>