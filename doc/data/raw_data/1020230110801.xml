<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:49.4149</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0110801</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 처리 모델의 훈련 및 이미지 처리 모델을 이용한 이미지 처리 방법 및 전자 장치</inventionTitle><inventionTitleEng>METHOD AND ELECTRONIC DEVICE FOR TRAINING IMAGE  PROCESSING MODEL AND PROCESSING IMAGES USING IMAGE  PROCESSING MODEL</inventionTitleEng><openDate>2024.06.14</openDate><openNumber>10-2024-0085135</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미지 처리 방법 및 장치, 이미지 처리 모델의 훈련 방법 및 장치에 대해 개시한다. 이미지 처리 방법은, 입력 이미지 그룹을 얻는 단계, 입력 이미지 그룹의 복수의 저해상도 이미지에 각각에 대해 특징을 추출하여 저해상도 이미지의 특징을 얻는 단계, 저해상도 이미지의 특징을 융합하여 융합 잔차 특징을 얻는 단계, 및 융합 잔차 특징을 기반으로 입력 이미지 그룹에 대응하는 초해상도 이미지를 얻는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 프로세서에 의해 수행되는, 이미지 처리 모델의 이미지 처리 방법에 있어서,입력 이미지 그룹을 얻는 단계 - 상기 입력 이미지 그룹은 서로 다른 시각(viewpoints)의 복수의 저해상도 이미지를 포함함 -;상기 입력 이미지 그룹의 상기 복수의 저해상도 이미지 각각에 대해 특징을 추출하여 저해상도 이미지의 특징을 얻는 단계;상기 저해상도 이미지의 특징을 융합하여 융합 잔차 특징을 얻는 단계; 및상기 융합 잔차 특징을 기반으로 상기 입력 이미지 그룹에 대응하는 초해상도 이미지를 얻는 단계를 포함하는, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 저해상도 이미지의 특징을 융합하여 상기 융합 잔차 특징을 얻는 단계는,상기 저해상도 이미지의 특징을 정렬하여 저해상도 이미지의 정렬 특징을 얻는 단계; 및상기 이미지 처리 모델의 어텐션 기반의 잔차 특징 융합 네트워크를 통해 상기 저해상도 이미지의 정렬 특징을 융합하여 상기 융합 잔차 특징을 얻는 단계를 포함하는, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 저해상도 이미지의 정렬 특징을 융합하여 상기 융합 잔차 특징을 얻는 단계는,상기 저해상도 이미지의 정렬 특징을 기반으로 저해상도 이미지의 융합 가중치를 각각 결정하는 단계; 및상기 저해상도 이미지의 융합 가중치에 따라 상기 저해상도 이미지의 정렬 특징에 대해 가중치를 계산하여 상기 융합 잔차 특징을 얻는 단계를 포함하는, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 저해상도 이미지의 특징을 정렬하여 상기 저해상도 이미지의 정렬 특징을 얻는 단계는,상기 입력 이미지 그룹의 광류(optical flow)를 얻는 단계; 및상기 광류를 기반으로 상기 저해상도 이미지의 특징을 정렬하여 상기 저해상도 이미지의 정렬 특징을 얻는 단계를 포함하는, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 광류는 미리 계산된 광류인, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 입력 이미지 그룹의 상기 복수의 저해상도 이미지 각각에 대해 특징을 추출하는 단계는,상기 이미지 처리 모델의 특징 추출 네트워크의 이기종(heterogeneous) 컨볼루션 커널을 통해, 상기 입력 이미지 그룹의 상기 복수의 저해상도 이미지 각각에 대해 특징을 추출하는 단계를 포함하는, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 입력 이미지 그룹에 포함된 서로 다른 시각의 상기 복수의 저해상도 이미지는 동시에 수집된 서로 다른 시각의 복수의 RAW 포맷 이미지인, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 융합 잔차 특징을 기반으로 상기 입력 이미지 그룹에 대응하는 상기 초해상도 이미지를 얻는 단계는,상기 이미지 처리 모델의 특징 재구성 네트워크를 통해, 상기 융합 잔차 특징을 재구성하여 재구성 특징을 얻는 단계; 및상기 이미지 처리 모델의 특징 정제(Feature refinement) 재구성 네트워크를 통해, 상기 재구성 특징을 정제하여 상기 입력 이미지 그룹에 대응하는 상기 초해상도 이미지를 얻는 단계를 포함하는, 이미지 처리 방법.</claim></claimInfo><claimInfo><claim>9. 이미지 처리 모델의 훈련 방법에 있어서,제1 훈련 샘플을 획득하는 단계 - 상기 제1 훈련 샘플은 훈련 이미지 및 상기 훈련 이미지에 대응하는 제1 훈련 라벨을 포함하고, 상기 훈련 이미지는 저해상도 이미지를 포함하고, 상기 제1 훈련 라벨은 대응하는 훈련 이미지의 제1 고해상도 이미지를 나타냄 -;상기 제1 훈련 샘플을 기초로 초기 모델을 훈련시켜 제1 모델을 획득하는 단계;상기 제1 모델의 전이 학습 관련 정보를 획득하는 단계;제2 훈련 샘플을 획득하는 단계 - 상기 제2 훈련 샘플은 훈련 이미지 그룹 및 상기 훈련 이미지 그룹에 대응하는 제2 훈련 라벨을 포함하고, 상기 제2 훈련 라벨은 대응하는 훈련 이미지 그룹의 제2 고해상도 이미지를 나타내고, 상기 훈련 이미지 그룹은 동일한 장면에 대한 서로 다른 시각(viewpoints)의 복수의 저해상도 이미지를 포함함 -; 및상기 제2 훈련 샘플을 기초로 제2 모델을 훈련시켜 이미지 처리 모델을 얻는 단계 - 상기 제2 모델은 상기 제1 모델의 전이 학습과 관련된 정보를 기반으로 구성됨 -를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제1 훈련 샘플을 기초로 상기 초기 모델을 훈련시켜 상기 제1 모델을 획득하는 단계는,상기 훈련 이미지를 상기 초기 모델에 입력하여 제1 고해상도 예측 이미지를 얻는 단계;상기 제1 고해상도 예측 이미지 및 상기 제1 훈련 라벨에 기초하여 상기 초기 모델의 제1 예측 손실을 결정하는 단계; 및상기 제1 예측 손실을 기반으로 상기 초기 모델의 매개변수를 조정하여 상기 제1 모델을 얻는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 훈련 이미지를 상기 초기 모델에 입력하여 상기 제1 고해상도 예측 이미지를 얻는 단계는,상기 초기 모델의 특징 추출 네트워크를 통해 상기 훈련 이미지에서 특징을 추출하여 상기 훈련 이미지의 특징을 얻는 단계; 및상기 훈련 이미지의 특징을 기반으로 상기 제1 고해상도 예측 이미지를 얻는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 제2 훈련 샘플을 기초로 상기 제2 모델을 훈련시켜 상기 이미지 처리 모델을 얻는 단계는,상기 훈련 이미지 그룹을 상기 제2 모델에 입력하여 제2 고해상도 예측 이미지를 얻는 단계;상기 제2 고해상도 예측 이미지 및 상기 제2 훈련 라벨을 기반으로 상기 제2 모델의 제2 예측 손실을 결정하는 단계; 및상기 제2 예측 손실을 기반으로 상기 제2 모델의 매개변수를 조정하여 상기 이미지 처리 모델을 얻는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 훈련 이미지 그룹을 상기 제2 모델에 입력하여 상기 제2 고해상도 예측 이미지를 얻는 단계는,상기 제2 모델의 특징 추출 네트워크를 통해 상기 훈련 이미지 그룹의 각각의 이미지에 대해 특징을 추출하여 각각의 이미지의 특징을 얻는 단계; 상기 제2 모델의 어텐션 기반의 잔차 특징 융합 네트워크를 통해 상기 각각의 이미지의 특징을 융합하여 훈련 융합 잔차 특징을 얻는 단계; 및상기 훈련 융합 잔차 특징을 기반으로 상기 제2 고해상도 예측 이미지를 얻는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 훈련 이미지 그룹의 훈련 광류를 획득하는 단계; 및상기 훈련 광류를 기반으로 상기 훈련 이미지 그룹의 상기 각각의 이미지의 특징을 정렬하여 각각의 이미지의 훈련 정렬 특징을 얻는 단계를 더 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 잔차 특징 융합 네트워크를 통해 상기 각각의 이미지의 특징을 융합하여 상기 훈련 융합 잔차 특징을 얻는 단계는,상기 각각의 이미지의 훈련 정렬 특징을 기반으로 각각의 이미지의 훈련 융합 가중치를 각각 결정하는 단계; 및상기 각각의 이미지의 훈련 융합 가중치를 기반으로 상기 각각의 이미지의 훈련 정렬 특징에 가중치를 부여하여 훈련 융합 잔차 특징을 얻는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 훈련 융합 잔차 특징을 기반으로 상기 제2 고해상도 예측 이미지를 얻는 단계는,상기 제2 모델의 특징 재구성 네트워크를 통해 상기 훈련 융합 잔차 특징을 재구성하여 훈련 재구성 특징을 얻는 단계; 및상기 제2 모델의 특징 정제 네트워크를 통해 상기 훈련 재구성 특징을 정제하여 상기 제2 고해상도 예측 이미지를 얻는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>17. 제9항에 있어서,상기 제2 모델의 매개변수는 적어도 어텐션 기반의 잔차 특징 적응적 융합 가중치를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서,상기 초기 모델의 특징 추출 네트워크를 통해 상기 훈련 이미지에서 특징을 추출하는 단계는,상기 제1 모델의 특징 추출 네트워크의 이기종 컨볼루션 커널을 통해 상기 제1 훈련 샘플에 대해 특징을 추출하는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>19. 제13항에 있어서,상기 제2 모델의 특징 추출 네트워크를 통해 상기 훈련 이미지 그룹의 상기 각각의 이미지에 대해 특징을 추출하는 단계는,상기 제2 모델의 특징 추출 네트워크의 이기종 컨볼루션 커널을 통해 상기 훈련 이미지 그룹의 상기 각각의 이미지에 대해 특징을 추출하는 단계를 포함하는, 훈련 방법.</claim></claimInfo><claimInfo><claim>20. 전자 장치에 있어서,적어도 하나의 프로세서;컴퓨터 프로그램을 저장한 적어도 하나의 메모리;를 포함하고,컴퓨터 프로그램은 상기 적어도 하나의 프로세서에 의해 실행될 때 제1항 내지 제19항 중 어느 한 항에 따른 방법을 실행하는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 차오양 디스트릭트 ...</address><code> </code><country> </country><engName>Chao Zhang</engName><name>차오 장</name></inventorInfo><inventorInfo><address>중국 ****** 차오양 디스트릭트 ...</address><code> </code><country> </country><engName>Qiang Wang</engName><name>키앙 왕</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170491439</code><country>대한민국</country><engName>Heo, Jingu</engName><name>허진구</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170490362</code><country>대한민국</country><engName>Nam, Dongkyung</engName><name>남동경</name></inventorInfo><inventorInfo><address>중국 ****** 차오양 디스트릭트 ...</address><code> </code><country> </country><engName>yasi wang</engName><name>야시 왕</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2022.12.07</priorityApplicationDate><priorityApplicationNumber>202211567770.5</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.23</receiptDate><receiptNumber>1-1-2023-0930766-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2023.08.30</receiptDate><receiptNumber>9-1-2023-9009756-36</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230110801.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934cab03a57645444c4cf17569a3ac99d92bdc6f52c0bc40a962acf65742fc535abc4c7c17e720aecffbc61e06677ca7779068f403fb4328e6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1e0e3a3c3844bc321d2be01388fcea5c5646be1c92dc88d0538985ecff3bf31b7a78088cff2375641e969b54c9a05e822c5ce51a58f047bc</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>