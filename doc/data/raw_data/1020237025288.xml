<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:07.27</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7025288</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 컴포넌트들을 위한 신체 UI</inventionTitle><inventionTitleEng>BODY UI FOR AUGMENTED REALITY COMPONENTS</inventionTitleEng><openDate>2023.08.25</openDate><openNumber>10-2023-0124703</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.07.24</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.07.24</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 51/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0484</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 임의의 특정 디바이스와의 물리적 접촉 없이 활성화될 수 있는 사용자 인터페이스 요소들을 제공하는 기술적 문제는 카메라의 디지털 이미지 센서의 출력으로부터의 객체와 사용자 선택가능 요소의 충돌을 검출한 것에 응답하여 활성화될 수 있는 무터치 사용자 선택가능 요소를 디스플레이하도록 증강 현실 컴포넌트를 구성함으로써 해결된다. 증강 현실 컴포넌트는 사람 이미지로부터의 손 객체와 같은 객체와 무터치 사용자 선택가능 요소의 충돌을 검출하고, 이에 응답하여, 예를 들어, 디지털 이미지 센서의 출력의 녹화를 시작하거나 중단하는 것 또는 디지털 이미지 센서의 출력의 정지 이미지를 캡처하는 것과 같은 미리 결정된 액션을 트리거한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.07.07</internationOpenDate><internationOpenNumber>WO2022146729</internationOpenNumber><internationalApplicationDate>2021.12.17</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/064201</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서:메시징 클라이언트를 제공하는 메시징 시스템에서, 인체 이미지의 세그먼트들에 할당된 앵커 포인트들을 검출하도록 증강 현실 컴포넌트를 구성하는 단계; 클라이언트 디바이스에서의 상기 메시징 클라이언트의 카메라 뷰 사용자 인터페이스에 상기 증강 현실 컴포넌트를 로드하게 야기하는 단계 - 상기 카메라 뷰 사용자 인터페이스는 상기 클라이언트 디바이스의 카메라의 디지털 이미지 센서의 출력을 포함하고, 상기 로드는 상기 카메라 뷰 사용자 인터페이스에서 사람 이미지의 각자의 세그먼트들에 할당된 앵커 포인트들의 검출을 시작하는 것을 포함함 -;상기 검출된 앵커 포인트들이 앵커 포인트들의 전신 표시자 세트를 포함하는 것을 결정하는 단계; 및상기 결정하는 단계에 응답하여, 상기 사람 이미지로부터의 트리거 세그먼트와 무터치 사용자 선택가능 요소의 충돌에 응답하여 상기 메시징 시스템에서 액션을 트리거하도록 구성된 상기 무터치 사용자 선택가능 요소를 상기 카메라 뷰 사용자 인터페이스에 디스플레이하게 야기하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 앵커 포인트들의 전신 표시자 세트는 엉덩이 객체에 할당된 제1 앵커 포인트 및 어깨 객체에 할당된 제2 앵커 포인트를 적어도 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 사람 이미지로부터의 트리거 세그먼트와 상기 무터치 사용자 선택가능 요소의 충돌을 검출하는 단계; 및상기 메시징 시스템에서 상기 액션을 수행하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 사람 이미지로부터의 트리거 세그먼트와 상기 무터치 사용자 선택가능 요소의 충돌을 검출하는 단계는 상기 충돌의 미리 결정된 지속기간을 검출하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 사람 이미지로부터의 트리거 세그먼트는 상기 사람 이미지로부터의 손 객체인 방법.  </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 액션은 상기 클라이언트 디바이스의 카메라에 의한 비디오 녹화의 시작인 방법.  </claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 메시징 시스템에서, 상기 앵커 포인트들의 전신 표시자 세트를 정의하는 단계를 포함하는 방법.  </claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 카메라 뷰 사용자 인터페이스에서 상기 사람 이미지의 각자의 세그먼트들에 할당된 상기 앵커 포인트들을 검출하는 단계는 이미지들의 훈련 세트를 이용하여 훈련된 머신 러닝 모델을 실행하는 단계를 포함하고, 상기 머신 러닝 모델은 사람의 이미지를 입력으로서 취하고 앵커 포인트들의 세트를 출력으로서 산출하는 방법.  </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 무터치 사용자 선택가능 요소를 상기 카메라 뷰 사용자 인터페이스에 디스플레이하는 것은 상기 사람 이미지에서 신체 세그먼트 객체의 위치를 추적하는 것 및 상기 신체 세그먼트 객체의 추적된 위치에 기초하여 결정된 상기 카메라 뷰 사용자 인터페이스 내의 로케이션에 상기 무터치 사용자 선택가능 요소를 디스플레이하는 것을 포함하는 방법.  </claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 증강 현실 컴포넌트를 이용하여 콘텐츠 아이템을 캡처하는 단계; 및상기 캡처된 콘텐츠 아이템을 또 다른 클라이언트 디바이스에 전달하는 단계를 포함하는 방법.  </claim></claimInfo><claimInfo><claim>11. 시스템으로서:하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서로 하여금 동작들을 수행하게 야기하는 명령어들을 포함하는 비일시적 컴퓨터 판독가능 저장 매체를 포함하고, 상기 동작들은:메시징 클라이언트를 제공하는 메시징 시스템에서, 인체 이미지의 세그먼트들에 할당된 앵커 포인트들을 검출하도록 증강 현실 컴포넌트를 구성하는 동작; 클라이언트 디바이스에서의 상기 메시징 클라이언트의 카메라 뷰 사용자 인터페이스에 상기 증강 현실 컴포넌트를 로드하게 야기하는 동작 - 상기 카메라 뷰 사용자 인터페이스는 상기 클라이언트 디바이스의 카메라의 디지털 이미지 센서의 출력을 포함하고, 상기 로드는 상기 카메라 뷰 사용자 인터페이스에서 사람 이미지의 각자의 세그먼트들에 할당된 앵커 포인트들의 검출을 시작하는 것을 포함함 -;상기 검출된 앵커 포인트들이 앵커 포인트들의 전신 표시자 세트를 포함하는 것을 결정하는 동작; 및상기 결정하는 동작에 응답하여, 상기 사람 이미지로부터의 트리거 세그먼트와 무터치 사용자 선택가능 요소의 충돌에 응답하여 상기 메시징 시스템에서 액션을 트리거하도록 구성된 상기 무터치 사용자 선택가능 요소를 상기 카메라 뷰 사용자 인터페이스에 디스플레이하게 야기하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 앵커 포인트들의 전신 표시자 세트는 엉덩이 객체에 할당된 제1 앵커 포인트 및 어깨 객체에 할당된 제2 앵커 포인트를 적어도 포함하는 시스템.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 하나 이상의 프로세서에 의해 실행되는 명령어들에 의해 야기되는 동작들은:상기 사람 이미지로부터의 트리거 세그먼트와 상기 무터치 사용자 선택가능 요소의 충돌을 검출하는 동작; 및상기 메시징 시스템에서 상기 액션을 수행하는 동작을 추가로 포함하는 시스템.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 사람 이미지로부터의 트리거 세그먼트와 상기 무터치 사용자 선택가능 요소의 충돌을 검출하는 동작은 상기 충돌의 미리 결정된 지속기간을 검출하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 사람 이미지로부터의 트리거 세그먼트는 상기 사람 이미지로부터의 손 객체인 시스템.  </claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 액션은 상기 클라이언트 디바이스의 카메라에 의한 비디오 녹화의 시작인 시스템.  </claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 하나 이상의 프로세서에 의해 실행되는 명령어들에 의해 야기되는 동작들은 상기 메시징 시스템에서, 상기 앵커 포인트들의 전신 표시자 세트를 정의하는 동작을 추가로 포함하는 시스템.  </claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 카메라 뷰 사용자 인터페이스에서 상기 사람 이미지의 각자의 세그먼트들에 할당된 상기 앵커 포인트들을 검출하는 동작은 이미지들의 훈련 세트를 이용하여 훈련된 머신 러닝 모델을 실행하는 동작을 포함하고, 상기 머신 러닝 모델은 사람의 이미지를 입력으로서 취하고 앵커 포인트들의 세트를 출력으로서 산출하는 시스템.  </claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 무터치 사용자 선택가능 요소를 상기 카메라 뷰 사용자 인터페이스에 디스플레이하는 것은 상기 사람 이미지에서 신체 세그먼트 객체의 위치를 추적하는 것 및 상기 신체 세그먼트 객체의 추적된 위치에 기초하여 결정된 상기 카메라 뷰 사용자 인터페이스 내의 로케이션에 상기 무터치 사용자 선택가능 요소를 디스플레이하는 것을 포함하는 시스템.  </claim></claimInfo><claimInfo><claim>20. 머신에 의해 실행가능하여 상기 머신으로 하여금 동작들을 수행하게 야기하는 명령어 데이터를 갖는 머신 판독가능 비일시적 저장 매체로서, 상기 동작들은:메시징 클라이언트를 제공하는 메시징 시스템에서, 인체 이미지의 세그먼트들에 할당된 앵커 포인트들을 검출하도록 증강 현실 컴포넌트를 구성하는 동작; 클라이언트 디바이스에서의 상기 메시징 클라이언트의 카메라 뷰 사용자 인터페이스에 상기 증강 현실 컴포넌트를 로드하게 야기하는 동작 - 상기 카메라 뷰 사용자 인터페이스는 상기 클라이언트 디바이스의 카메라의 디지털 이미지 센서의 출력을 포함하고, 상기 로드는 상기 카메라 뷰 사용자 인터페이스에서 사람 이미지의 각자의 세그먼트들에 할당된 앵커 포인트들의 검출을 시작하는 것을 포함함 -;상기 검출된 앵커 포인트들이 앵커 포인트들의 전신 표시자 세트를 포함하는 것을 결정하는 동작; 및상기 결정하는 동작에 응답하여, 상기 사람 이미지로부터의 트리거 세그먼트와 무터치 사용자 선택가능 요소의 충돌에 응답하여 상기 메시징 시스템에서 액션을 트리거하도록 구성된 상기 무터치 사용자 선택가능 요소를 상기 카메라 뷰 사용자 인터페이스에 디스플레이하게 야기하는 동작을 포함하는 머신 판독가능 비일시적 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>LAVREKA, Mykhailo</engName><name>라브레카, 미카일로</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>HUSIEV, Yurii</engName><name>후시에프, 유리</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>POLUYANOV, Denys</engName><name>폴루야노프, 데니스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.12.29</priorityApplicationDate><priorityApplicationNumber>63/131,393</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.02.11</priorityApplicationDate><priorityApplicationNumber>17/248,876</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.07.24</receiptDate><receiptNumber>1-1-2023-0812250-63</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.07.26</receiptDate><receiptNumber>1-5-2023-0120172-06</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.08.21</receiptDate><receiptNumber>9-5-2025-0798040-78</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237025288.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936972dd3adfca1857b8ca0bf61ea07faa4d2cb39cb8d34afb43c8fb005859338ea87901512914b2c066b816025367b4e6547620a6d7727e13</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf203a4a3cfb7ee60d88f3860aaa35cf8abe14edd2f3352cb52868d0be8b99d84a7eae2b86a1b5455056488b427f45163a8cf18c62dafd3dc7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>