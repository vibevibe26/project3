<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:16.5316</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7024214</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>합성된 스피치 생성</inventionTitle><inventionTitleEng>SYNTHESIZED SPEECH GENERATION</inventionTitleEng><openDate>2023.09.19</openDate><openNumber>10-2023-0133295</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.07.14</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 13/047</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 13/033</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 19/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 21/007</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 21/013</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 스피치 생성을 위한 디바이스는 타겟 스피치 특성들을 표시하는 하나 이상의 제어 파라미터들을 수신하도록 구성된 하나 이상의 프로세서들을 포함한다. 하나 이상의 프로세서들은 또한, 타겟 스피치 특성들에 기초하여 스피치의 버전을 표현하는 오디오 신호에 대응하는 인코딩된 데이터를 생성하기 위해 하나 이상의 제어 파라미터들에 기초하여 스피치의 입력 표현을, 멀티-인코더를 사용하여, 프로세싱하도록 구성된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.07.28</internationOpenDate><internationOpenNumber>WO2022159256</internationOpenNumber><internationalApplicationDate>2021.12.08</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/072800</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 스피치 생성을 위한 디바이스로서,하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은, 타겟 스피치 특성들을 표시하는 하나 이상의 제어 파라미터들을 수신하고; 그리고 상기 타겟 스피치 특성들에 기초하여 스피치의 버전을 표현하는 오디오 신호에 대응하는 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들에 기초하여 상기 스피치의 입력 표현을, 멀티-인코더를 사용하여, 프로세싱하도록 구성되는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 제어 파라미터들은, 스피치 특성들이 사용될 타겟 사람, 타겟 감정, 타겟 스피치 레이트, 또는 이들의 조합을 표시하는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은 추가로, 상기 하나 이상의 제어 파라미터들에 기초하여 병합된 스타일 데이터를 생성하도록 구성되고, 상기 병합된 스타일 데이터는 상기 입력 표현의 프로세싱 동안 상기 멀티-인코더에 의해 사용되는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서, 상기 멀티-인코더는,제 1 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들과 독립적으로 상기 입력 표현을 인코딩하도록 구성된 제 1 인코더; 및제 2 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들에 기초하여 상기 입력 표현을 인코딩하도록 구성된 하나 이상의 제 2 인코더들을 포함하고,상기 인코딩된 데이터는 상기 제 1 인코딩된 데이터 및 상기 제 2 인코딩된 데이터를 포함하는, 스피치 생성을 위한 디바이스. </claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서, 상기 하나 이상의 프로세서들은 추가로, 스피치 특성 인코더에서, 인코딩된 입력 스피치 표현을 생성하기 위해 상기 하나 이상의 제어 파라미터들 중 적어도 하나에 기초하여 상기 입력 표현을 프로세싱하고;  인코더 프리-네트워크에서, 상기 인코딩된 입력 스피치 표현에 적어도 부분적으로 기초하여 병합된 스타일 데이터를 생성하고;상기 제 1 인코딩된 데이터를 생성하기 위해 상기 제 1 인코더에 상기 입력 표현을 제공하며; 그리고상기 제 2 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제 2 인코더들에 상기 병합된 스타일 데이터를 제공하도록 구성되는, 스피치 생성을 위한 디바이스. </claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서, 상기 멀티-인코더 및 디코더를 포함하는 멀티-인코더 변환기를 더 포함하고, 상기 제 1 인코더는 제 1 어텐션 네트워크를 포함하고, 상기 하나 이상의 제 2 인코더들의 각각은 제 2 어텐션 네트워크를 포함하며, 상기 디코더는 디코더 어텐션 네트워크를 포함하는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서, 상기 제 1 인코더는, 상기 제 1 어텐션 네트워크를 포함하는 제 1 계층으로서, 상기 제 1 어텐션 네트워크는 제 1 멀티-헤드 어텐션 네트워크에 대응하는, 상기 제 1 어텐션 네트워크를 포함하는 제 1 계층; 및 제 1 뉴럴 네트워크를 포함하는 제 2 계층을 포함하고,상기 하나 이상의 제 2 인코더들의 각각은,  상기 제 2 어텐션 네트워크를 포함하는 제 1 계층으로서, 상기 제 2 어텐션 네트워크는 제 2 멀티-헤드 어텐션 네트워크에 대응하는, 상기 제 2 어텐션 네트워크를 포함하는 제 1 계층; 및 제 2 뉴럴 네트워크를 포함하는 제 2 계층을 포함하는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>8. 제 4 항에 있어서,상기 멀티-인코더에 커플링된 디코더로서, 상기 디코더는 상기 제 1 인코딩된 데이터 및 상기 제 2 인코딩된 데이터에 기초하여 출력 스펙트럼 데이터를 생성하도록 구성되는 디코더 네트워크를 포함하는, 상기 디코더; 및상기 타겟 스피치 특성들에 기초하여 상기 스피치의 버전을 표현하는 상기 오디오 신호를, 상기 출력 스펙트럼 데이터에 기초하여, 생성하도록 구성된 스피치 합성기를 더 포함하는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서, 상기 디코더 네트워크는 디코더 어텐션 네트워크를 포함하고, 상기 디코더 어텐션 네트워크는,상기 제 1 인코딩된 데이터를 프로세싱하도록 구성된 제 1 멀티-헤드 어텐션 네트워크; 상기 제 2 인코딩된 데이터를 프로세싱하도록 구성된 하나 이상의 제 2 멀티-헤드 어텐션 네트워크들; 및상기 제 1 멀티-헤드 어텐션 네트워크 및 상기 하나 이상의 제 2 멀티-헤드 어텐션 네트워크들의 출력들을 결합하도록 구성된 결합기를 포함하는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 디코더는, 상기 디코더 어텐션 네트워크의 입력에 커플링된 마스킹된 멀티-헤드 어텐션 네트워크; 및상기 디코더 어텐션 네트워크의 출력에 커플링된 디코더 뉴럴 네트워크를 더 포함하는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은 추가로,상기 오디오 신호로부터 하나 이상의 추정된 제어 파라미터들을 생성하고; 그리고상기 하나 이상의 제어 파라미터들과 상기 하나 이상의 추정된 제어 파라미터들의 비교에 기초하여, 상기 멀티-인코더, 하나 이상의 스피치 특성 인코더들, 인코더 프리-네트워크, 디코더 네트워크, 또는 이들의 조합의 하나 이상의 뉴럴 네트워크 가중치들을 훈련하도록 구성되는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>12. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은 추가로,입력 스피치 신호를 수신하고; 그리고상기 입력 스피치 신호에 기초하여 상기 입력 표현을 생성하도록 구성되는, 스피치 생성을 위한 디바이스. </claim></claimInfo><claimInfo><claim>13. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은 추가로, 상기 입력 표현을 수신하도록 구성되는, 스피치 생성을 위한 디바이스. </claim></claimInfo><claimInfo><claim>14. 제 1 항에 있어서, 상기 입력 표현은 텍스트, 멜-스케일(mel-scale) 스펙트로그램들, 기본 주파수 (F0) 특징들, 또는 이들의 조합을 포함하는, 스피치 생성을 위한 디바이스.</claim></claimInfo><claimInfo><claim>15. 스피치 생성 방법으로서,디바이스에서, 타겟 스피치 특성들을 표시하는 하나 이상의 제어 파라미터들을 수신하는 단계; 및상기 타겟 스피치 특성들에 기초하여 스피치의 버전을 표현하는 오디오 신호에 대응하는 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들에 기초하여 상기 스피치의 입력 표현을, 멀티-인코더를 사용하여, 프로세싱하는 단계를 포함하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서, 상기 제어 파라미터들은, 스피치 특성들이 사용될 타겟 사람, 타겟 감정, 타겟 스피치 레이트, 또는 이들의 표시하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>17. 제 15 항에 있어서, 상기 디바이스에서, 상기 하나 이상의 제어 파라미터들에 기초하여 병합된 스타일 데이터를 생성하는 단계를 더 포함하고, 상기 병합된 스타일 데이터는 상기 입력 표현의 프로세싱 동안 상기 멀티-인코더에 의해 사용되는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>18. 제 15 항에 있어서,상기 멀티-인코더의 제 1 인코더에서, 제 1 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들과 독립적으로 상기 입력 표현을 인코딩하는 단계; 및상기 멀티-인코더의 하나 이상의 제 2 인코더들에서, 제 2 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들에 기초하여 상기 입력 표현을 인코딩하는 단계를 더 포함하고, 상기 인코딩된 데이터는 상기 제 1 인코딩된 데이터 및 상기 제 2 인코딩된 데이터를 포함하는, 스피치 생성 방법. </claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서, 스피치 특성 인코더에서, 인코딩된 입력 스피치 표현을 생성하기 위해 상기 하나 이상의 제어 파라미터들 중 적어도 하나에 기초하여 상기 입력 표현을 프로세싱하는 단계; 인코더 프리-네트워크에서, 상기 인코딩된 입력 스피치 표현에 적어도 부분적으로 기초하여 병합된 스타일 데이터를 생성하는 단계;상기 제 1 인코딩된 데이터를 생성하기 위해 상기 제 1 인코더에 상기 입력 표현을 제공하는 단계; 및상기 제 2 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제 2 인코더들에 상기 병합된 스타일 데이터를 제공하는 단계를 더 포함하는, 스피치 생성 방법. </claim></claimInfo><claimInfo><claim>20. 제 18 항에 있어서, 상기 멀티-인코더 및 디코더가 멀티-인코더 변환기에 포함되고, 상기 제 1 인코더는 제 1 어텐션 네트워크를 포함하고, 상기 하나 이상의 제 2 인코더들의 각각은 제 2 어텐션 네트워크를 포함하며, 상기 디코더는 디코더 어텐션 네트워크를 포함하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서, 상기 제 1 인코더는, 상기 제 1 어텐션 네트워크를 포함하는 제 1 계층으로서, 상기 제 1 어텐션 네트워크는 제 1 멀티-헤드 어텐션 네트워크에 대응하는, 상기 제 1 어텐션 네트워크를 포함하는 제 1 계층; 및 제 1 뉴럴 네트워크를 포함하는 제 2 계층을 포함하고,상기 하나 이상의 제 2 인코더들의 각각은, 상기 제 2 어텐션 네트워크를 포함하는 제 1 계층으로서, 상기 제 2 어텐션 네트워크는 제 2 멀티-헤드 어텐션 네트워크에 대응하는, 상기 제 2 어텐션 네트워크를 포함하는 제 1 계층; 및 제 2 뉴럴 네트워크를 포함하는 제 2 계층을 포함하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>22. 제 18 항에 있어서,디코더의 디코더 네트워크에서, 상기 제 1 인코딩된 데이터 및 상기 제 2 인코딩된 데이터에 기초하여 출력 스펙트럼 데이터를 생성하는 단계; 및스피치 합성기에서 그리고 상기 출력 스펙트럼 데이터에 기초하여, 상기 타겟 스피치 특성들에 기초하여 상기 스피치의 버전을 표현하는 상기 오디오 신호를 생성하는 단계를 더 포함하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>23. 제 22 항에 있어서,디코더 어텐션 네트워크의 제 1 멀티-헤드 어텐션 네트워크에서 상기 제 1 인코딩된 데이터를 프로세싱하는 단계로서, 상기 디코더 네트워크는 상기 디코더 어텐션 네트워크를 포함하는, 상기 제 1 인코딩된 데이터를 프로세싱하는 단계; 상기 디코더 어텐션 네트워크의 하나 이상의 제 2 멀티-헤드 어텐션 네트워크들에서 상기 제 2 인코딩된 데이터를 프로세싱하는 단계; 및결합기에서, 상기 제 1 멀티-헤드 어텐션 네트워크 및 상기 하나 이상의 제 2 멀티-헤드 어텐션 네트워크들의 출력들을 결합하는 단계를 더 포함하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>24. 제 15 항에 있어서,상기 디바이스에서, 상기 오디오 신호로부터 하나 이상의 추정된 제어 파라미터들을 생성하는 단계; 및상기 하나 이상의 제어 파라미터들과 상기 하나 이상의 추정된 제어 파라미터들의 비교에 기초하여, 상기 멀티-인코더, 하나 이상의 스피치 특성 인코더들, 인코더 프리-네트워크, 디코더 네트워크, 또는 이들의 조합의 하나 이상의 뉴럴 네트워크 가중치들을 훈련하는 단계를 더 포함하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>25. 제 15 항에 있어서,상기 디바이스에서 입력 스피치 신호를 수신하는 단계; 및상기 디바이스에서, 상기 입력 스피치 신호에 기초하여 상기 입력 표현을 생성하는 단계를 더 포함하는, 스피치 생성 방법. </claim></claimInfo><claimInfo><claim>26. 제 15 항에 있어서, 상기 디바이스에서 상기 입력 표현을 수신하는 단계를 더 포함하는, 스피치 생성 방법.</claim></claimInfo><claimInfo><claim>27. 명령들을 저장하는 비일시적 컴퓨터 판독가능 저장 매체로서,상기 명령들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금,타겟 스피치 특성들을 표시하는 하나 이상의 제어 파라미터들을 수신하게 하고; 그리고상기 타겟 스피치 특성들에 기초하여 스피치의 버전을 표현하는 오디오 신호에 대응하는 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들에 기초하여 상기 스피치의 입력 표현을, 멀티-인코더를 사용하여, 프로세싱하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>28. 제 27 항에 있어서, 상기 입력 표현은 텍스트, 멜-스케일(mel-scale) 스펙트로그램들, 기본 주파수 (F0) 특징들, 또는 이들의 조합을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>29. 장치로서,타겟 스피치 특성들을 표시하는 하나 이상의 제어 파라미터들을 수신하는 수단; 및상기 타겟 스피치 특성들에 기초하여 스피치의 버전을 표현하는 오디오 신호에 대응하는 인코딩된 데이터를 생성하기 위해 상기 하나 이상의 제어 파라미터들에 기초하여 상기 스피치의 입력 표현을, 멀티-인코더를 사용하여, 프로세싱하는 수단을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>30. 제 29 항에 있어서, 상기 수신하는 수단 및 상기 프로세싱하는 수단은 가상 어시스턴트, 홈 어플라이언스, 스마트 디바이스, 사물 인터넷 (IoT) 디바이스, 통신 디바이스, 헤드셋, 차량, 컴퓨터, 디스플레이 디바이스, 텔레비전, 게이밍 콘솔, 뮤직 플레이어, 라디오, 비디오 플레이어, 엔터테인먼트 유닛, 개인용 미디어 플레이어, 디지털 비디오 플레이어, 카메라, 또는 내비게이션 디바이스 중 적어도 하나에 통합되는, 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BYUN, KYUNGGUEN</engName><name>변 경근</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MOON, SUNKUK</engName><name>문 선국</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ZHANG, SHUHUA</engName><name>장 슈화</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MONTAZERI, VAHID</engName><name>몬타제리 바히드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>KIM, LAE-HOON</engName><name>김 래훈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>VISSER, ERIK</engName><name>비제르 에릭</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.01.21</priorityApplicationDate><priorityApplicationNumber>17/154,372</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.07.14</receiptDate><receiptNumber>1-1-2023-0778851-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.08.24</receiptDate><receiptNumber>1-5-2023-0135647-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.20</receiptDate><receiptNumber>1-1-2024-1279925-27</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.11.20</receiptDate><receiptNumber>1-1-2024-1279926-73</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237024214.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9385a8eb56bf292fb664d27a24734d157c74a9a75aea1abc5bfe2f2f2de0502e0c03f06d3b9b8ca79a0cf1b7ad793a7c27a575793c83c6ef6c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf837aba7ed4929e88dc6b2a7ea1b07c621a53b9c64ea852b57ab96db29e8830babedadf885c28002f05c9e8277ce6488a1dee9ce82bfe17bc</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>