<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:26:39.2639</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.12.23</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2024-0194530</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>반려동물 행동 분석을 위한 멀티모달 인공지능 모델 학습 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>MULTIMODAL ARTIFICIAL INTELLIGENCE MODEL TRAINING DEVICE FOR  PET BEHAVIOR ANALYSIS, AND OPERATING METHOD THEREOF</inventionTitleEng><openDate>2025.10.31</openDate><openNumber>10-2025-0156000</openNumber><originalApplicationDate>2024.05.15</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2024-0063507</originalApplicationNumber><originalExaminationRequestDate>2024.12.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020240063507</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시에 의하면, 행동 데이터 세트를 인코딩하고, 제1 및 제2 인코딩된 데이터를 출력하는 인코더, 및 인스트럭션 및 제2 인코딩된 데이터를 기반으로 생성된 임베딩 벡터, 및 제1 인코딩된 데이터를 기초로 멀티-헤드 어텐션을 계산하고, 멀티-헤드 어텐션의 어텐션 스코어들을 기초로 반려 동물을 해석한 텍스트를 나타내는 해석 데이터를 출력으로 예측하는 대규모 언어 모델 디코더를 포함하는 전자 장치 및 그 동작 방법을 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 반려 동물의 오디오를 나타내는 제1 오디오 데이터, 상기 반려 동물의 반려자의 목소리를 나타내는 제2 오디오 데이터, 상기 반려 동물이 촬영된 비디오를 나타내는 비디오 데이터, 및 상기 반려 동물의 행동 패턴에 대응되는 관성 센싱 결과를 나타내는 IMU 데이터를 포함하는 행동 데이터 세트를 수신하고, 상기 행동 데이터 세트를 인코딩하고, 상기 비디오 데이터, 상기 IMU 데이터, 및 상기 제1 오디오 데이터 각각의 피처를 포함하는 제1 인코딩된 데이터, 및 상기 제1 오디오 데이터 및 상기 제2 오디오 데이터 각각의 피처를 포함하는 제2 인코딩된 데이터를 출력하는 인코더; 및인스트럭션, 상기 제1 인코딩된 데이터, 및 상기 제2 인코딩된 데이터를 수신하고, 상기 인스트럭션 및 상기 제2 인코딩된 데이터를 기반으로 생성된 임베딩 벡터, 및 상기 제1 인코딩된 데이터를 기초로 멀티-헤드 어텐션을 계산하고, 상기 멀티-헤드 어텐션의 어텐션 스코어들을 기초로 상기 반려 동물을 해석한 텍스트를 나타내는 해석 데이터를 출력으로 예측하는 대규모 언어 모델 디코더를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 인코더는,상기 비디오 데이터, 상기 IMU 데이터, 상기 제1 오디오 데이터의 LFA(Low Frequency Audio) 데이터를 인코딩하여, 상기 제1 인코딩된 데이터를 상기 대규모 언어 모델 디코더에 제공하는 디미너 인코더; 및상기 LFA 데이터, 상기 제2 오디오 데이터, 상기 제1 오디오 데이터의 HFA(High Frequency Audio) 데이터를 인코딩하여, 상기 제2 인코딩된 데이터를 출력하는 오디오 인코더를 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,상기 디미너 인코더는,상기 비디오 데이터를 인코딩하여, 상기 비디오에 관한 피처에 해당되는 적어도 하나의 비디오 피처를 생성하는 비디오 인코더;상기 IMU 데이터를 인코딩하여, 상기 IMU에 관한 피처에 해당되는 IMU 피처를 생성하는 IMU 인코더;상기 LFA 데이터를 인코딩하여, LFA에 관한 피처에 해당되는 LFA 피처를 생성하는 LFA 인코더; 상기 IMU 피처 및 상기 LFA 피처를 합성하여, 합성된 IMU 및 LFA 피처를 생성하는 합성부; 및상기 적어도 하나의 비디오 피처 및 상기 합성된 IMU 및 LFA 피처를 수신하고, 상기 합성된 IMU 및 LFA 피처와 가장 가까운 비디오 피처를 상기 대규모 언어 모델 디코더에 제공하는 바인드 네트워크를 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,상기 바인드 네트워크는, 학습 과정에서 얻은 비디오 피처들을 저장하고, 상기 합성된 IMU 및 LFA 피처가 입력되면 저장된 비디오 피처들 중 상기 합성된 IMU 및 LFA 피처와 가장 가까운 비디오 피처를 상기 대규모 언어 모델 디코더에 제공하는 캐시 모델을 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제2 항에 있어서,상기 오디오 인코더는,상기 LFA 데이터 및 상기 제2 오디오 데이터를 수신하고, 상기 LFA 데이터의 음성이 상기 제2 오디오 데이터의 상기 반려자의 목소리에 해당하는지 아닌지 여부를 식별하는 보이스 식별자;상기 LFA 데이터를 수신하고, 상기 LFA 데이터를 인코딩함으로써 상기 LFA 데이터의 음성을 분석하는 스피치 인코더; 및상기 LFA 데이터 및 상기 HFA 데이터를 수신하고, 상기 HFA 데이터의 HFA를 LFA로 변환하고, 상기 LFA로부터 환경 소리 및 반려 동물의 소리를 분석하는 사운드 인코더를 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 보이스 식별자의 분석 결과, 상기 스피치 인코더의 분석 결과, 및 상기 사운드 인코더의 분석 결과와, 러너블 쿼리들(learnable queries)을 기초로, 상기 대규모 언어 모델 디코더에 입력되는 텍스트 토큰을 생성하는 큐-포머(Q-Former)를 더 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 대규모 언어 모델 디코더는,상기 제2 인코딩된 데이터 및 상기 인스트럭션의 합성을 기초로, 입력 토크를 생성하고,상기 입력 토크에 대해 임베딩을 수행하여, 임베딩 벡터를 생성하고,상기 임베딩 벡터에 대해 제1 RMS Norm(Root Mean Square Layer Normalization)을 수행하고, 상기 제1 RMS Norm이 수행된 벡터에 대해 RoPE(Rotary Positional Embeddings)를 수행하고,상기 RoPE이 수행된 임베딩에 대해 마스크드 셀프 어텐션을 계산하고,상기 마스크드 셀프 어텐션의 어텐션 스코어들과, 상기 임베딩 벡터, 및 상기 제1 인코딩된 데이터에서 합성된 IMU 및 LFA 피처에 가장 가까운 비디오 피처를 기초로, 상기 멀티-헤드 어텐션을 계산하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 대규모 언어 모델 디코더는,상기 마스크드 셀프 어텐션의 상기 어텐션 스코어들과, 상기 임베딩 벡터, 및 상기 비디오 피처를 합성하고,합성된 결과에 대해 제2 RMS Norm를 수행하고,상기 제2 RMS Norm이 수행된 임베딩과, 상기 임베딩의 키, 쿼리, 및 밸류에 대해 상기 멀티-헤드 어텐션을 계산하고,상기 멀티-헤드 어텐션의 어텐션 스코어들과 상기 제2 RMS Norm이 수행된 상기 임베딩을 합성하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서,상기 대규모 언어 모델 디코더는,상기 멀티-헤드 어텐션의 어텐션 스코어들과 상기 제2 RMS Norm이 수행된 상기 임베딩이 합성된 결과에 제3 RMS Norm를 수행하고,상기 제3 RMS Norm이 수행된 임베딩에 대해 피드포워드를 수행하고,상기 피드포워드의 결과와 상기 제3 RMS Norm이 수행된 상기 임베딩을 합성하고, 상기 피드포워드의 결과와 상기 제3 RMS Norm이 수행된 상기 임베딩이 합성된 결과에 제4 RMS Norm를 수행하고,상기 제4 RMS Norm이 수행된 임베딩에 대해 선형화하고, 선형화된 결과 및 소프트맥스를 이용하여 상기 해석 데이터를 출력하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 반려 동물의 오디오를 나타내는 제1 오디오 데이터, 상기 반려 동물의 반려자의 목소리를 나타내는 제2 오디오 데이터, 상기 반려 동물이 촬영된 비디오를 나타내는 비디오 데이터, 및 상기 반려 동물의 행동 패턴에 대응되는 관성 센싱 결과를 나타내는 IMU 데이터를 포함하는 행동 데이터 세트를 인코딩하는 단계;상기 비디오 데이터, 상기 IMU 데이터, 및 상기 제1 오디오 데이터 각각의 피처를 포함하는 제1 인코딩된 데이터, 및 상기 제1 오디오 데이터 및 상기 제2 오디오 데이터 각각의 피처를 포함하는 제2 인코딩된 데이터를 대규모 언어 모델 디코더에 제공하는 단계;인스트럭션, 및 상기 제2 인코딩된 데이터를 기반으로 생성된 임베딩 벡터, 상기 제1 인코딩된 데이터를 기초로 멀티-헤드 어텐션을 계산하는 단계; 및상기 멀티-헤드 어텐션의 어텐션 스코어들을 기초로 상기 반려 동물을 해석한 텍스트를 나타내는 해석 데이터를 예측하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강동구...</address><code>420240278468</code><country>대한민국</country><engName>SO YOUNG JEONG</engName><name>정소영</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강동구...</address><code>420240278468</code><country>대한민국</country><engName>SO YOUNG JEONG</engName><name>정소영</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로**길 ** (역삼동) *층(마일스톤특허법률사무소)</address><code>920210005810</code><country>대한민국</country><engName>Koo Minsik</engName><name>구민식</name></agentInfo><agentInfo><address>서울특별시 강남구 테헤란로**길 ** (역삼동) *층(마일스톤특허법률사무소)</address><code>920210004367</code><country>대한민국</country><engName>DONGHYUN KIM</engName><name>김동현</name></agentInfo><agentInfo><address>서울특별시 강남구 테헤란로**길 ** (역삼동) *층(마일스톤특허법률사무소)</address><code>920200004077</code><country>대한민국</country><engName>HWANG In Jin</engName><name>황인진</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2024.04.24</priorityApplicationDate><priorityApplicationNumber>1020240054546</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2024.12.23</receiptDate><receiptNumber>1-1-2024-1430479-19</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240194530.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930a127b47f7316c99c22ca7a12e7178e456a98907019c079ed15fdfc7be1edfa2eae09c1e22b31bebcbba2a8f7e8fc7fd711db39541b7a924</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf97c7089caac7e3462ef4df4f05300c0b7d49f476f1b65bfbfcd10af76bc2ffac4cdfa9dbb442e07d1c6991ab4ec3a3862eed2c2dbd7768fb</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>