<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:18.5618</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2025.08.19</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-0114592</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>반려동물 및 그 주변의 데이터를 이용한 데이터 학습 방법 및 장치</inventionTitle><inventionTitleEng>DATA LEARNING METHOD AND DEVICE USING DATA OF PET AND ITS  SURROUNDINGS</inventionTitleEng><openDate>2025.10.31</openDate><openNumber>10-2025-0156035</openNumber><originalApplicationDate>2024.05.15</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2024-0063506</originalApplicationNumber><originalExaminationRequestDate>2025.08.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020240063506</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시에 의하면, 행동 데이터 세트를 획득하고, 상기 행동 데이터 세트에서 데이터의 일 카테고리가 다른 카테고리에 미치는 영향도를 기초로 상기 행동 데이터 세트를 전처리함으로써, 카테고리별 추론 데이터를 생성하고, 상기 카테고리별 추론 데이터를 기초로 트레이닝 데이터 세트를 생성하는 전처리부, 및 상기 트레이닝 데이터 세트를 기반으로 훈련된 멀티 모달 인공지능 언어 모델을 이용하여, 새로 입력된 행동 데이터 세트를 입력으로 상기 반려 동물을 해석한 텍스트를 나타내는 해석 데이터를 출력으로 예측하는 예측부를 포함하는 전자 장치 및 그 동작 방법을 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 반려 동물 및 주변환경과 관련된 소리데이터, 냄새데이터, 영상데이터, 행동데이터, 상기 반려 동물의 생체데이터, 상기 반려 동물과 관련된 텍스트데이터를 포함하는 행동 데이터 세트를 획득하되, 상기 소리데이터 중 적어도 일부에 대해 주파수분석을 수행함으로써 가청 및 비가청대역 각각에 대한 스펙트로그램 데이터를 생성하고, 상기 영상데이터에 대한 객체인식을 수행하고, 상기 행동데이터에 대한 신호처리를 수행하고, 상기 행동 데이터 세트에서 데이터의 일 카테고리가 다른 카테고리에 미치는 영향도를 기초로 상기 소리데이터 중 적어도 일부에 대한 라벨링을 수행함으로써 전처리 데이터를 생성하고, 상기 전처리 데이터에 기초해 학습됨으로써 카테고리별 임의 입력에 대한 컨텍스트 정보를 포함하는 카테고리별 추론 데이터를 생성하고, 상기 카테고리별 추론 데이터를 기초로 트레이닝 데이터 세트를 생성하는 전처리부; 및상기 트레이닝 데이터 세트를 기반으로 훈련된 멀티 모달 인공지능 언어 모델을 이용하여, 새로 입력된 행동 데이터 세트를 입력으로 상기 반려 동물을 해석한 텍스트를 나타내는 해석 데이터를 출력으로 예측하는 예측부를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 전처리부는,상기 반려 동물에 부착된 제1 센싱 장치로부터 상기 소리데이터, 상기 냄새데이터, 및 상기 행동데이터를 수신하고, 상기 반려 동물의 주변에 위치하는 제2 센싱 장치로부터 상기 영상데이터를 수신하고, 외부 장치로부터 상기 생체데이터, 상기 텍스트데이터를 수신하거나, 미리 저장하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 전처리부는,상기 냄새데이터, 상기 생체데이터, 상기 텍스트데이터 각각에 대한 추론 데이터를 생성하고, 상기 소리데이터, 상기 영상데이터, 상기 행동데이터 간의 영향도를 분석하고, 상기 영향도를 기반으로 상기 소리데이터, 상기 영상데이터, 상기 행동데이터 각각의 추론 데이터를 생성하고, 생성된 모든 추론 데이터를 합성함으로써, 상기 트레이닝 데이터 세트를 생성하는 컨텍스트 파서를 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 컨텍스트 파서는,주파수 분석 결과 및 객체인식 결과를 합성함으로써, 합성 데이터를 생성하고, 상기 소리데이터, 상기 합성 데이터 각각에 대해 라벨링 동작을 수행함으로써, 복수의 라벨링 데이터를 생성하고, 상기 신호처리된 데이터 및 상기 복수의 라벨링 데이터를 합성함으로써, 상기 행동데이터에 대응되는 행동 추론 데이터를 생성하고, 상기 생성된 모든 행동 추론 데이터를 합성함으로써, 상기 트레이닝 데이터 세트를 생성하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 해석 데이터는,상기 반려 동물의 자세, 행동, 및 표정을 포함하는 반려 동물의 모습을 설명하는 텍스트, 및 상기 반려 동물에 대해 예상되는 상황을 설명하는 상황텍스트를 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 해석 데이터는,상기 반려 동물의 현재 감정을 설명하는 감정텍스트, 및 상기 반려 동물이 취할 다음 행동을 설명하는 예상행동텍스트를 더 포함하는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 멀티 모달 인공지능 언어 모델은, 생성형 언어 모델이고,상기 해석 데이터의 텍스트는, 프롬프트에 입력된 인스트럭션 텍스트에 대해, 상기 반려 동물을 해석한 텍스트를 하나 이상의 완성된 문장 형식으로 서술하는 디스크립티브 형식으로 출력되는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 멀티 모달 인공지능 언어 모델은, 생성형 언어 모델이고,상기 해석 데이터의 텍스트는, 프롬프트에 입력된 질문 텍스트에 대해, 상기 반려 동물을 해석한 상기 텍스트들을 상기 질문 텍스트에 대한 답변으로 매칭하는 질문-답변 형식으로 출력되는 것을 특징으로 하는, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 반려동물 및 주변환경과 관련된 소리데이터, 냄새데이터, 영상데이터, 행동데이터, 생체데이터, 및 텍스트데이터를 포함하는 행동 데이터 세트를 획득하는 단계;상기 소리데이터 중 적어도 일부에 대해 주파수분석을 수행함으로써 가청 및 비가청대역 각각에 대한 스펙트로그램 데이터를 생성하는 단계;상기 행동 데이터 세트에서 데이터의 일 카테고리가 다른 카테고리에 미치는 영향도를 기초로 소리데이터 중 적어도 하나에 대한 라벨링을 수행함으로써 전처리 데이터를 생성하는 단계;상기 전처리 데이터에 기초해 학습됨으로써 카테고리별 임의 입력에 대한 컨텍스트 정보를 포함하는 카테고리별 추론 데이터를 생성하는 단계; 및상기 카테고리별 추론 데이터를 기초로 트레이닝 데이터 세트를 생성하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 하드웨어와 결합하여 제9항의 방법을 실행하는 기록매체에 저장된, 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강동구...</address><code>420240278468</code><country>대한민국</country><engName>SO YOUNG JEONG</engName><name>정소영</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강동구...</address><code>420240278468</code><country>대한민국</country><engName>SO YOUNG JEONG</engName><name>정소영</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로**길 ** (역삼동) *층(마일스톤특허법률사무소)</address><code>920210005810</code><country>대한민국</country><engName>Koo Minsik</engName><name>구민식</name></agentInfo><agentInfo><address>서울특별시 강남구 테헤란로**길 ** (역삼동) *층(마일스톤특허법률사무소)</address><code>920210004367</code><country>대한민국</country><engName>DONGHYUN KIM</engName><name>김동현</name></agentInfo><agentInfo><address>서울특별시 강남구 테헤란로**길 ** (역삼동) *층(마일스톤특허법률사무소)</address><code>920200004077</code><country>대한민국</country><engName>HWANG In Jin</engName><name>황인진</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2024.04.24</priorityApplicationDate><priorityApplicationNumber>1020240054546</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2025.08.19</receiptDate><receiptNumber>1-1-2025-0941333-15</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020250114592.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930a127b47f7316c99e6e3ae7ac3868539082c6666206a6fb45146a18ebd0b4af07cf08e835c37909326e37fc458c294cd6038ddc71cba1ed9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf97c7089caac7e3465ee4835c9a7a0c01b7924aa9bafca4f5da2986f30dc781e4d3746c204313ec332ddfd730a2fcd30fb93c197f1d3ecabc</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>