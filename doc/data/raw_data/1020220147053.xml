<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:12.5612</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.11.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0147053</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다중 화자 음성 합성 서비스를 제공하는 음성 합성 서버, 방법 및 프로그램</inventionTitle><inventionTitleEng>SERVER AND METHOD FOR PROVIDING MULTI-SPEAKER SPEECH  SYNTHESIS SERVICE</inventionTitleEng><openDate>2024.05.14</openDate><openNumber>10-2024-0065841</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.11.04</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 13/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 15/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G10L 17/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 화자의 음성에 대응하는 텍스트를 주파수 스펙트로그램으로 변환하는 미리 학습된 제 1 딥러닝 모델 및 상기 주파수 스펙트로그램으로부터 합성 음성을 생성하는 미리 학습된 제 2 딥러닝 모델을 저장하는 제 1 저장부와, 각 화자마다 상기 제 1 딥러닝 모델에 업데이트될 제 1 가중치 정보 및 상기 제 2 딥러닝 모델에 업데이트될 제 2 가중치 정보를 저장하는 제 2 저장부와, 제 1 화자의 음성을 수신하는 음성 수신부와, 상기 제 2 저장부로부터 상기 제 1 화자에 대응하는 상기 제 1 가중치 정보 및 상기 제 1 화자에 대응하는 상기 제 2 가중치 정보를 선택하는 가중치 선택부와, 상기 선택된 제 1 가중치 정보를 이용하여 상기 제 1 딥러닝 모델을 업데이트하고, 상기 선택된 제 2 가중치 정보를 이용하여 상기 제 2 딥러닝 모델을 업데이트하는 모델 업데이트부 및 상기 업데이트된 제 1 딥러닝 모델 및 상기 업데이트된 제 2 딥러닝 모델을 이용하여 상기 제 1 화자의 음성에 대응하는 합성 음성을 생성하는 합성 음성 생성부를 포함하는 음성 합성 서버를 제공할 수 있다 </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 다중 화자 음성 합성 서비스를 제공하는 음성 합성 서버에 있어서,화자의 음성에 대응하는 텍스트를 주파수 스펙트로그램으로 변환하는 미리 학습된 제 1 딥러닝 모델 및 상기 주파수 스펙트로그램으로부터 합성 음성을 생성하는 미리 학습된 제 2 딥러닝 모델을 저장하는 제 1 저장부;각 화자마다 상기 제 1 딥러닝 모델에 업데이트될 제 1 가중치 정보 및 상기 제 2 딥러닝 모델에 업데이트될 제 2 가중치 정보를 저장하는 제 2 저장부;제 1 화자의 음성을 수신하는 음성 수신부;상기 제 2 저장부로부터 상기 제 1 화자에 대응하는 상기 제 1 가중치 정보 및 상기 제 1 화자에 대응하는 상기 제 2 가중치 정보를 선택하는 가중치 선택부; 상기 선택된 제 1 가중치 정보를 이용하여 상기 제 1 딥러닝 모델을 업데이트하고, 상기 선택된 제 2 가중치 정보를 이용하여 상기 제 2 딥러닝 모델을 업데이트하는 모델 업데이트부; 및상기 업데이트된 제 1 딥러닝 모델 및 상기 업데이트된 제 2 딥러닝 모델을 이용하여 상기 제 1 화자의 음성에 대응하는 합성 음성을 생성하는 합성 음성 생성부를 포함하는 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제 1 저장부는 상기 제 1 딥러닝 모델을 구성하는 복수의 레이어 및 상기 제 2 딥러닝 모델을 구성하는 복수의 레이어를 저장하는 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 제 2 저장부는 각 화자마다 상기 제 1 딥러닝 모델을 구성하는 복수의 레이어 중 적어도 하나의 제 1 특징 레이어에 대한 정보, 상기 제 2 딥러닝 모델을 구성하는 복수의 레이어 중 적어도 하나의 제 2 특징 레이어에 대한 정보, 상기 적어도 하나의 제 1 특징 레이어에 업데이트될 상기 제 1 가중치 정보 및 상기 적어도 하나의 제 2 특징 레이어에 업데이트될 상기 제 2 가중치 정보를 저장하는 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 가중치 선택부는 상기 제 2 저장부로부터 상기 제 1 화자에 대응하는 상기 적어도 하나의 제 1 특징 레이어, 상기 적어도 하나의 제 2 특징 레이어, 상기 적어도 하나의 제 1 특징 레이어에 업데이트될 상기 제 1 가중치 정보 및 상기 적어도 하나의 제 2 특징 레이어에 업데이트될 상기 제 2 가중치 정보를 선택하는 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,상기 모델 업데이트부는 상기 선택된 제 1 가중치 정보를 이용하여 상기 적어도 하나의 제 1 특징 레이어를 업데이트하고, 상기 선택된 제 2 가중치 정보를 이용하여 상기 적어도 하나의 제 2 특징 레이어를 업데이트하는 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,상기 음성 생성부는 상기 업데이트된 적어도 하나의 제 1 특징 레이어를 포함하는 상기 제 1 딥러닝 모델 및 상기 업데이트된 적어도 하나의 제 2 특징 레이어를 포함하는 상기 제 2 딥러닝 모델을 이용하여 상기 제 1 화자의 음성에 대응하는 합성 음성을 생성하는 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서,상기 주파수 스펙트로그램은 멜 스펙트로그램(Mel spectrogram)인 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>8. 제 3 항에 있어서,각 화자마다 상기 적어도 하나의 제 1 특징 레이어의 종류, 상기 하나의 제 2 특징 레이어의 종류가 상이한 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>9. 제 3 항에 있어서,각 화자마다 상기 적어도 하나의 제 1 특징 레이어에 업데이트될 상기 제 1 가중치 정보 및 상기 적어도 하나의 제 2 특징 레이어에 업데이트될 상기 제 2 가중치 정보가 상이한 것인, 음성 합성 서버.</claim></claimInfo><claimInfo><claim>10. 화자의 음성에 대응하는 텍스트를 주파수 스펙트로그램으로 변환하는 미리 학습된 제 1 딥러닝 모델 및 상기 주파수 스펙트로그램으로부터 합성 음성을 생성하는 미리 학습된 제 2 딥러닝 모델을 저장하는 제 1 저장부; 및 각 화자마다 상기 제 1 딥러닝 모델에 업데이트될 제 1 가중치 정보 및 상기 제 2 딥러닝 모델에 업데이트될 제 2 가중치 정보를 저장하는 제 2 저장부를 포함하는 음성 합성 서버에 의해 수행되는 다중 화자 음성 합성 방법에 있어서,상기 제 2 저장부로부터 제 1 화자에 대응하는 상기 제 1 가중치 정보 및 상기 제 1 화자에 대응하는 상기 제 2 가중치 정보를 선택하는 단계;상기 선택된 제 1 가중치 정보를 이용하여 상기 제 1 딥러닝 모델을 업데이트하고, 상기 선택된 제 2 가중치 정보를 이용하여 상기 제 2 딥러닝 모델을 업데이트하는 단계; 및상기 업데이트된 제 1 딥러닝 모델 및 상기 업데이트된 제 2 딥러닝 모델을 이용하여 상기 제 1 화자의 음성에 대응하는 합성 음성을 생성하는 단계를 포함하는 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서,상기 제 1 저장부는 상기 제 1 딥러닝 모델을 구성하는 복수의 레이어 및 상기 제 2 딥러닝 모델을 구성하는 복수의 레이어를 저장하는 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 제 2 저장부는 각 화자마다 상기 제 1 딥러닝 모델을 구성하는 복수의 레이어 중 적어도 하나의 제 1 특징 레이어에 대한 정보, 상기 제 2 딥러닝 모델을 구성하는 복수의 레이어 중 적어도 하나의 제 2 특징 레이어에 대한 정보, 상기 적어도 하나의 제 1 특징 레이어에 업데이트될 상기 제 1 가중치 정보 및 상기 적어도 하나의 제 2 특징 레이어에 업데이트될 상기 제 2 가중치 정보를 저장하는 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서,상기 선택하는 단계는 상기 제 2 저장부로부터 상기 제 1 화자에 대응하는 상기 적어도 하나의 제 1 특징 레이어, 상기 적어도 하나의 제 2 특징 레이어, 상기 적어도 하나의 제 1 특징 레이어에 업데이트될 상기 제 1 가중치 정보 및 상기 적어도 하나의 제 2 특징 레이어에 업데이트될 상기 제 2 가중치 정보를 선택하는 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 업데이트하는 단계는 상기 선택된 제 1 가중치 정보를 이용하여 상기 적어도 하나의 제 1 특징 레이어를 업데이트하고, 상기 선택된 제 2 가중치 정보를 이용하여 상기 적어도 하나의 제 2 특징 레이어를 업데이트하는 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서,상기 합성 음성을 생성하는 단계는 상기 업데이트된 적어도 하나의 제 1 특징 레이어를 포함하는 상기 제 1 딥러닝 모델 및 상기 업데이트된 적어도 하나의 제 2 특징 레이어를 포함하는 상기 제 2 딥러닝 모델을 이용하여 상기 제 1 화자의 음성에 대응하는 합성 음성을 생성하는 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>16. 제 10 항에 있어서,상기 주파수 스펙트로그램은 멜 스펙트로그램(Mel spectrogram)인 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>17. 제 12 항에 있어서,각 화자마다 상기 적어도 하나의 제 1 특징 레이어의 종류, 상기 하나의 제 2 특징 레이어의 종류가 상이한 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>18. 제 12 항에 있어서,각 화자마다 상기 적어도 하나의 제 1 특징 레이어에 업데이트될 상기 제 1 가중치 정보 및 상기 적어도 하나의 제 2 특징 레이어에 업데이트될 상기 제 2 가중치 정보가 상이한 것인, 다중 화자 음성 합성 방법.</claim></claimInfo><claimInfo><claim>19. 다중 화자 음성 합성 서비스를 제공하는 명령어들의 시퀀스를 포함하는 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램은 컴퓨팅 장치에 의해 실행될 경우,화자의 음성에 대응하는 텍스트를 주파수 스펙트로그램으로 변환하는 미리 학습된 제 1 딥러닝 모델 및 상기 주파수 스펙트로그램으로부터 합성 음성을 생성하는 미리 학습된 제 2 딥러닝 모델을 저장하고,각 화자마다 상기 제 1 딥러닝 모델에 업데이트될 제 1 가중치 정보 및 상기 제 2 딥러닝 모델에 업데이트될 제 2 가중치 정보를 저장하고,제 1 화자의 음성을 수신하고,상기 저장된 제 2 가중치 정보로부터 상기 제 1 화자에 대응하는 상기 제 1 가중치 정보 및 상기 제 1 화자에 대응하는 상기 제 2 가중치 정보를 선택하고,상기 선택된 제 1 가중치 정보를 이용하여 상기 제 1 딥러닝 모델을 업데이트하고, 상기 선택된 제 2 가중치 정보를 이용하여 상기 제 2 딥러닝 모델을 업데이트하고상기 업데이트된 제 1 딥러닝 모델 및 상기 업데이트된 제 2 딥러닝 모델을 이용하여 상기 제 1 화자의 음성에 대응하는 합성 음성을 생성하는 명령어들의 시퀀스를 포함하는, 컴퓨터 판독가능 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>219980054563</code><country>대한민국</country><engName>KT Corporation</engName><name>주식회사 케이티</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>KWON, Soon Gu</engName><name>권순구</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로*길 **, *층 (역삼동, 한동빌딩)</address><code>920111000019</code><country>대한민국</country><engName>MAPS Intellectual Property Law Firm</engName><name>특허법인엠에이피에스</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.11.07</receiptDate><receiptNumber>1-1-2022-1180535-67</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>4-1-2025-5080836-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.11.04</receiptDate><receiptNumber>1-1-2025-1226870-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220147053.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93cf39531982f407da8d2b18e4deb753729a66737ba42de3b51574f86dbdb9ffd8a69a0e98e50190340c0227a7bf6146254353e9eddab06167</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf078069f921410a6fa09aabeb9161cf9ba533b8da9bf02e3a43f7e8436d2d771fe5521850058c49227edf06b6a09b3ff2f49797ab29b0e556</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>