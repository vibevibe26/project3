<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:26.4126</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.05.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0060826</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>음성 인식 방법, 인코딩 및 디코딩 방법, 장치, 전자 기기 및 기록 매체</inventionTitle><inventionTitleEng>VOICE PROCESSING METHOD, ENCODING AND DECODING  METHOD AND DEVICE, EQUIPMENT AND COMPUTER  STORAGE MEDIUM</inventionTitleEng><openDate>2023.03.21</openDate><openNumber>10-2023-0039505</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.05.18</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 스마트 음성, 딥 러닝 및 자연 언어 처리 등의 인공 지능 분야에 관한 음성 인식 방법, 인코딩 및 디코딩 방법, 장치, 전자 기기 및 기록 매체를 제공하고, 음성 인식 방법은 인식할 음성의 오디오 특징을 획득하는 단계; 획득된 오디오 특징을 인코딩하여, 인코딩 특징을 획득하는 단계; 획득된 인코딩 특징에 대해 절단 처리를 수행하여, 연속된 N개의 특징 세그먼트를 획득하는 단계 - N은 1보다 큰 양의 정수 -; 임의의 특징 세그먼트에 대해, 대응하는 이력 특징 추상 정보를 획득하고, 이력 특징 추상 정보와 결합하여 당해 특징 세그먼트를 인코딩하고, 인코딩 결과를 디코딩하여, 당해 특징 세그먼트에 대응하는 인식 결과를 획득하는 단계;를 포함할 수 있고, 이력 특징 추상 정보는 이미 인식된 이력 특징 세그먼트에 대해 특징 추상을 수행하여 획득한 정보이다. 본 발명에 기재된 방안을 적용하면, 인식 결과의 정확성과 인식 효율 등을 향상시킬 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 음성 인식 방법에 있어서, 인식할 음성의 오디오 특징을 획득하는 단계; 상기 오디오 특징을 인코딩하여, 인코딩 특징을 획득하는 단계; 상기 인코딩 특징에 대해 절단 처리(truncation processing)를 수행하여, 연속된 N개의 특징 세그먼트를 획득하는 단계 - N은 1보다 큰 양의 정수임 -; 및 임의의 특징 세그먼트에 대해, 대응하는 이력 특징 추상 정보(historical feature abstract information)를 획득하고, 상기 이력 특징 추상 정보와 결합하여 상기 특징 세그먼트를 인코딩하고, 인코딩 결과를 디코딩하여, 상기 특징 세그먼트에 대응하는 인식 결과를 획득하는 단계- 상기 이력 특징 추상 정보는 이미 인식된 이력 특징 세그먼트에 대해 특징 추상화를 수행하여 획득한 정보임-;를 포함하는, 음성 인식 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 오디오 특징에 대해 콘볼루션 다운 샘플링(convolution downsampling)을 수행하고, 상기 다운 샘플링 후의 오디오 특징을 인코딩하는 단계를 추가 포함하는, 음성 인식 방법. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 오디오 특징에 대해 수행하는 인코딩과 연결 시퀀스 분류 손실을 결합하여, 상기 인코딩 특징에 대응하는 피크 정보를 결정하는 단계를 추가 포함하고, 상기 인코딩 특징에 대해 절단 처리를 수행하는 단계는, 상기 피크 정보에 따라 상기 인코딩 특징에 대해 절단 처리를 수행하는 단계를 포함하는, 음성 인식 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 피크 정보에 따라 상기 인코딩 특징에 대해 절단 처리를 수행하는 단계는, 각각의 2개의 인접한 피크 사이에 위치하는 인코딩 특징을 각각 하나의 특징 세그먼트로 하는 단계를 포함하는, 음성 인식 방법. </claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 오디오 특징을 인코딩하는 단계는, 제1 인코더를 사용하여 상기 오디오 특징을 인코딩하는 단계를 포함하고, 상기 제1 인코더는 M층의 인과적 Conformer 모델(M-layer causal convolution-enhanced converter Conformer model)을 포함하고, M은 양의 정수이며, 상기 인과적 Conformer 모델은 시간 마스크에 기반한 주의력 모델과 인과적 콘볼루션 모델을 공동 융합하여 얻은 것인, 음성 인식 방법. </claim></claimInfo><claimInfo><claim>6. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 이력 특징 추상 정보와 결합하여 상기 특징 세그먼트를 인코딩하는 단계는, 상기 이력 특징 추상 정보와 결합하여, 제2 인코더를 사용하여 상기 특징 세그먼트를 인코딩하는 단계를 포함하고, 상기 인코딩 결과를 디코딩하는 단계는, 제1 디코더를 사용하여 상기 인코딩 결과를 디코딩하는 단계를 포함하고, 상기 이력 특징 추상 정보는 상기 디코더의 출력 정보에 따라 생성되는, 음성 인식 방법. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 제2 인코더는 P층의 Conformer 모델(P-layer convolution-enhanced converter Conformer model)을 포함하고, P는 양의 정수이며, 상기 제1 디코더의 수는 Q개이며, Q는 양의 정수이며, Q개의 제1 디코더는 순서대로 연결되는, 음성 인식 방법. </claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,임의의 Conformer 모델에 대해, 각각 하기 처리를 수행하는 단계를 추가 포함하는 음성 인식 방법: 임의의 제1 디코더로부터 획득된 은닉층 특징을 사용하여, 상기 Conformer 모델에서의 현재 처리중인 특징 세그먼트에 대해 특징 추상화를 수행하여, 미리 설정된 길이의 특징 벡터를 획득하고, 상기 특징 벡터를 상기 현재 처리중인 특징 세그먼트의 상기 Conformer 모델에 대응하는 이력 특징 벡터로 하는 단계,상기 대응하는 이력 특징 추상 정보를 획득하는 단계는, 임의의 Conformer 모델에 대해, 각 이력 특징 세그먼트의 상기 Conformer 모델에 대응하는 이력 특징 벡터를 각각 스플라이싱하고, 상기 스플라이싱 결과를 상기 이력 특징 추상 정보로 사용하는 단계를 포함함. </claim></claimInfo><claimInfo><claim>9. 인코딩 및 디코딩 방법에 있어서, 처리할 대상에 대응하는 특징을 획득하는 단계 - 상기 특징은 적어도, 디코더의 이력 출력 정보에 따라 획득되는 특징을 포함함 -; 인코더를 사용하여 상기 특징을 인코딩하여, 인코딩 결과를 획득하는 단계; 및 상기 디코더를 사용하여 상기 인코딩 결과를 디코딩하여, 상기 처리할 대상에 대응하는 처리 결과를 획득하는 단계;를 포함하는, 인코딩 및 디코딩 방법. </claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 출력 정보는 상기 디코더에 의해 출력된 은닉층 특징을 포함하는, 인코딩 및 디코딩 방법. </claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 처리할 대상에 대응하는 특징을 획득하는 단계는, 상기 처리할 대상에 대응하는 이력 특징 추상 정보를 획득하는 단계를 포함하고, 상기 이력 특징 추상 정보는 이력 처리 대상에 대해 특징 추상화를 수행하여 획득된 정보인, 인코딩 및 디코딩 방법. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 디코더로부터 획득된 상기 은닉층 특징을 사용하여, 상기 처리할 대상에 대해 특징 추상화를 수행하여, 미리 설정된 길이의 특징 벡터를 획득하고, 상기 특징 벡터를 상기 처리할 대상에 대응하는 이력 특징 벡터로 하는 단계를 추가 포함하고, 상기 처리할 대상에 대응하는 이력 특징 추상 정보를 획득하는 단계는, 각 이력 처리 대상에 대응하는 이력 특징 벡터를 각각 스플라이싱하고, 상기 스플라이싱 결과를 상기 이력 특징 추상 정보로 사용하는 단계를 포함하는, 인코딩 및 디코딩 방법. </claim></claimInfo><claimInfo><claim>13. 제9항 내지 제12항 중 어느 한 항에 있어서,상기 처리할 대상은 인식할 음성에 대응하는 인코딩 특징에 대해 절단 처리를 수행한 후에 획득한 연속된 N개의 특징 세그먼트 중의 임의의 특징 세그먼트를 포함하고, N은 1보다 큰 양의 정수이며, 상기 인코딩 특징은 상기 인식할 음성의 오디오 특징을 인코딩한 후에 획득한 특징이며, 상기 처리 결과는 상기 특징 세그먼트에 대응하는 인식 결과를 포함하는, 인코딩 및 디코딩 방법. </claim></claimInfo><claimInfo><claim>14. 음성 인식 장치에 있어서, 특징 획득 모듈, 특징 인코딩 모듈, 세그먼트 획득 모듈, 및 세그먼트 인코딩 및 디코딩 모듈을 포함하고, 상기 특징 획득 모듈은 인식할 음성의 오디오 특징을 획득하는데 사용되고, 상기 특징 인코딩 모듈은 상기 오디오 특징을 인코딩하여, 인코딩 특징을 획득하는데 사용되고, 상기 세그먼트 획득 모듈은 상기 인코딩 특징에 대해 절단 처리를 수행하고, 연속된 N개의 특징 세그먼트를 획득하는데 사용되고, N은 1보다 큰 양의 정수이며, 상기 세그먼트 인코딩 및 디코딩 모듈은 임의의 특징 세그먼트에 대해, 대응하는 이력 특징 추상 정보를 획득하고, 상기 이력 특징 추상 정보와 결합하여 상기 특징 세그먼트를 인코딩하고, 인코딩 결과를 디코딩하여, 상기 특징 세그먼트에 대응하는 인식 결과를 획득하는데 사용되고, 상기 이력 특징 추상 정보는 이미 인식된 이력 특징 세그먼트에 대해 특징 추상화를 수행하여 획득한 정보인, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 특징 획득 모듈은, 상기 오디오 특징에 대해 콘볼루션 다운 샘플링을 수행하는데 사용되는, 음성 인식 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 특징 인코딩 모듈은 나아가, 상기 오디오 특징에 대해 수행하는 인코딩과 연결 시퀀스 분류 손실을 결합하여, 상기 인코딩 특징에 대응하는 피크 정보를 결정하는데 사용되고, 상기 세그먼트 획득 모듈은 상기 피크 정보에 따라 상기 인코딩 특징에 대해 절단 처리를 수행하는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 세그먼트 획득 모듈은 각각의 2개의 인접한 피크 사이에 위치하는 인코딩 특징을 각각 하나의 특징 세그먼트로 하는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>18. 제14항 내지 제17항 중 어느 한 항에 있어서,상기 특징 인코딩 모듈은 제1 인코더를 사용하여 상기 오디오 특징을 인코딩하고, 상기 제1 인코더는 M층의 인과적Conformer 모델을 포함하고, M은 양의 정수이며, 상기 인과적 Conformer 모델은 시간 마스크에 기반한 주의력 모델과 인과적 콘볼루션 모델을 공동 융합하여 얻은 것인, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>19. 제14항 내지 제17항 중 어느 한 항에 있어서,상기 세그먼트 인코딩 및 디코딩 모듈은 상기 이력 특징 추상 정보와 결합하여, 제2 인코더를 사용하여 상기 특징 세그먼트를 인코딩하고, 제1 디코더를 사용하여 상기 인코딩 결과를 디코딩하여, 상기 이력 특징 추상 정보는 상기 디코더의 출력 정보에 따라 생성되는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 제2 인코더는 P층의 Conformer 모델을 포함하고, P는 양의 정수이며, 상기 제1 디코더의 수는 Q개이며, Q는 양의 정수이며, Q개의 제1 디코더는 순서대로 연결되는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>21. 제20항에 있어서,상기 세그먼트 인코딩 및 디코딩 모듈은 나아가, 임의의 Conformer 모델에 대해, 각각 하기 처리를 수행하는데 사용되고: 임의의 제1 디코더로부터 획득된 은닉층 특징을 사용하여, 상기 Conformer 모델에서의 현재 처리하는 특징 세그먼트에 대해 특징 추상을 수행하여, 미리 설정된 길이의 특징 벡터를 획득하고, 상기 특징 벡터를 상기 현재 처리하는 특징 세그먼트의 상기 Conformer 모델에 대응하는 이력 특징 벡터로 사용하고, 상기 세그먼트 인코딩 및 디코딩 모듈은 임의의 특징 세그먼트에 대해, 각각 하기 방식으로 대응하는 이력 특징 추상 정보를 획득하고: 임의의 Conformer 모델에 대해, 각 이력 특징 세그먼트의 상기 Conformer 모델에 대응하는 이력 특징 벡터를 각각 스플라이싱하고, 스플라이싱 결과를 상기 이력 특징 추상 정보로 사용하는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>22. 인코딩 및 디코딩 장치에 있어서, 획득 모듈, 인코딩 모듈 및 디코딩 모듈을 포함하고, 상기 획득 모듈은 처리할 대상에 대응하는 특징을 획득하는데 사용되고, 상기 특징은 적어도, 디코더의 이력출력 정보에 따라 획득되는 특징을 포함하고, 상기 인코딩 모듈은 인코더를 사용하여 상기 특징을 인코딩하여, 인코딩 결과를 획득하는데 사용되고, 상기 디코딩 모듈은 상기 디코더를 사용하여 상기 인코딩 결과를 디코딩하여, 상기 처리할 대상에 대응하는 처리 결과를 획득하는데 사용되는, 인코딩 및 디코딩 장치. </claim></claimInfo><claimInfo><claim>23. 제22항에 있어서,상기 출력 정보는 상기 디코더에 의해 출력된 은닉층 특징을 포함하는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 처리할 대상에 대응하는 특징을 획득하는 것은, 상기 처리할 대상에 대응하는 이력 특징 추상 정보를 획득하는 것을 포함하고, 상기 이력 특징 추상 정보는 이력 처리 대상에 대해 특징 추상화를 수행하여 획득된 정보인, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>25. 제24항에 있어서,상기 획득 모듈은 상기 디코더로부터 획득된 상기 은닉층 특징을 사용하여, 상기 처리할 대상에 대해 특징 추상화를 수행하여, 미리 설정된 길이의 특징 벡터를 획득하고, 상기 특징 벡터를 상기 처리할 대상에 대응하는 이력 특징 벡터로 하고, 상기 획득 모듈은 각 이력 처리 대상에 대응하는 이력 특징 벡터를 각각 스플라이싱하고, 상기 스플라이싱 결과를 상기 이력 특징 추상 정보로 사용하는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>26. 제22항 내지 제25항 중 어느 한 항에 있어서,상기 처리할 대상은 인식할 음성에 대응하는 인코딩 특징에 대해 절단 처리를 수행한 후에 획득한 연속된 N개의 특징 세그먼트 중의 임의의 특징 세그먼트를 포함하고, N은 1보다 큰 양의 정수이며, 상기 인코딩 특징은 상기 인식할 음성의 오디오 특징을 인코딩한 후에 획득한 특징이며, 상기 처리 결과는 상기 특징 세그먼트에 대응하는 인식 결과를 포함하는, 음성 인식 장치. </claim></claimInfo><claimInfo><claim>27. 전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리;를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서에 의해 제1항 내지 제13항 중 어느 한 항의 방법이 수행되도록 하는, 전자 기기. </claim></claimInfo><claimInfo><claim>28. 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제13항 중 어느 한 항의 방법을 수행하도록 하는, 비일시적 컴퓨터 판독 가능 기록 매체. </claim></claimInfo><claimInfo><claim>29. 비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램은 상기 컴퓨터가 제1항 내지 제13항 중 어느 한 항의 방법을 수행하도록 하는, 비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국, 베이징 ******, 하이뎬 디...</address><code> </code><country> </country><engName>FU, Xiaoyin</engName><name>푸, 시아오인</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디...</address><code> </code><country> </country><engName>CHEN, Zhijie</engName><name>천, 즈지에</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디...</address><code> </code><country> </country><engName>LIANG, Mingxin</engName><name>리앙, 밍씬</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디...</address><code> </code><country> </country><engName>YANG, Mingshun</engName><name>양, 밍슌</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디...</address><code> </code><country> </country><engName>JIA, Lei</engName><name>지아, 레이</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디...</address><code> </code><country> </country><engName>WANG, Haifeng</engName><name>왕, 하이펑</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 사평대로 ***, *층 (반포동)</address><code>920161000615</code><country>대한민국</country><engName>Jipyong Intellectual Property Law Firm</engName><name>특허법인지평</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2021.09.13</priorityApplicationDate><priorityApplicationNumber>202111069754.9</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.05.18</receiptDate><receiptNumber>1-1-2022-0526306-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2022.05.23</receiptDate><receiptNumber>9-1-2022-9005905-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.01.08</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2025.01.21</receiptDate><receiptNumber>9-6-2025-0094330-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.05.21</receiptDate><receiptNumber>9-5-2025-0482788-22</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.07.09</receiptDate><receiptNumber>1-1-2025-0774056-00</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.07.09</receiptDate><receiptNumber>1-1-2025-0774055-54</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220060826.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93844fee695ba925f371d00e5d44e224e85cc44f6bfcbfc47204db197f44fab12789e2ebff2d50684e9a8a5887a9089c0306b44c44e3971fc5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf761d7c683fa103b22c2b2929fc5ab2608d35a839d5d584e921491152c5cdf93cd92e7785ce5064042bf88c2fd452dfbd406f48409d28894a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>