<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:32.3732</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0087216</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 분류 장치 및 그 방법</inventionTitle><inventionTitleEng>APPARATUS FOR OBJECT CLASSIFICATION, AND METHOD THEREOF</inventionTitleEng><openDate>2025.01.14</openDate><openNumber>10-2025-0007284</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 객체 분류 장치, 및 그 방법에 관한 것으로, 본 발명의 실시 예에 의한 객체 분류 장치는 이미지를 획득하는 카메라, 및 이미지를 딥러닝 학습하는 프로세서를 포함할 수 있다. 프로세서는 객체 분류 모델을 이용하여 이미지를 학습한 것을 바탕으로 제1 깊이값을 획득하고, 이미지의 일부 영역을 마스킹한 부분 이미지를 획득하며, 객체 분류 모델을 이용하여 부분 이미지를 학습한 것을 바탕으로 제2 깊이값을 획득하고, 제1 깊이값 및 제2 깊이값의 편차를 줄이도록 객체 분류 모델을 학습할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지를 획득하는 카메라; 및상기 이미지를 딥러닝 학습하는 프로세서;를 포함하고, 상기 프로세서는객체 분류 모델을 이용하여, 이미지를 학습한 것을 바탕으로 제1 깊이값을 획득하고,상기 이미지의 일부 영역을 마스킹한 부분 이미지를 획득하며,상기 객체 분류 모델을 이용하여, 상기 부분 이미지를 학습한 것을 바탕으로 제2 깊이값을 획득하고,상기 제1 깊이값 및 상기 제2 깊이값의 편차를 줄이도록 상기 객체 분류 모델을 학습하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 프로세서는 상기 이미지의 차원 변환 또는 상기 이미지의 계조 변환을 바탕으로 확장된 학습 데이터를 학습하여 상기 제1 깊이값을 획득하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,상기 프로세서는상기 이미지를 패치 단위로 분할하고, 상기 복수의 패치들을 상기 객체 분류 모델의 인코더에 제공하며, 상기 인코더를 이용하여 제1 특징값을 출력하고, 상기 제1 특징값을 상기 객체 분류 모델의 디코더에 제공하며, 상기 디코더를 이용하여 상기 제1 깊이값을 획득하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 프로세서는마스크를 이용하여 상기 패치 단위로 분할된 상기 이미지의 일부 영역을 샘플링하여, 상기 부분 이미지들을 획득하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,상기 프로세서는상기 부분 이미지들 각각에서 샘플링 된 상기 패치들이 서로 중복되지 않도록 설정된 상기 마스크들을 이용하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서,상기 프로세서는상기 부분 이미지들을 상기 인코더에 제공하고, 상기 인코더를 이용하여 상기 부분 이미지들에 대한 부분 특징값을 추출하며, 상기 부분 특징값들을 결합하여 제2 특징값을 추출하고, 상기 제2 특징값을 상기 디코더에 제공하며, 상기 디코더를 이용하여 상기 제2 깊이값을 획득하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,상기 프로세서는상기 제1 특징값과 상기 제2 특징값의 편차에 비례하는 제1 손실함수의 크기를 계산하고, 상기 제1 손실함수의 크기를 줄이도록 상기 인코더의 파라미터를 조절하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서,상기 프로세서는상기 제1 깊이값과 상기 제2 깊이값의 편차에 비례하는 제2 손실함수의 크기를 계산고, 상기 제2 손실함수의 크기를 줄이도록 상기 객체 분류 모델의 파라미터를 조절하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 프로세서는상기 제2 손실함수를 바탕으로 상기 파라미터가 조절된 상기 객체 분류 모델의 불확실 정도를 판단하고, 상기 불확실 정도를 바탕으로 상기 제2 손실함수의 가중치를 조절하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>10. 제 1 항에 있어서,상기 프로세서는상기 이미지를 학습한 것을 바탕으로 제1 클래스를 획득하고, 상기 부분 이미지를 학습한 것을 바탕으로 제2 클래스를 획득하며, 상기 제2 클래스와 상기 제2 클래스의 편차를 줄이도록 상기 객체 분류 모델의 파라미터를 조절하는 것을 특징으로 하는 객체 분류 장치.</claim></claimInfo><claimInfo><claim>11. 객체 분류 모델을 이용하여, 이미지를 학습한 것을 바탕으로 제1 깊이값을 획득하는 단계;상기 이미지의 일부 영역을 마스킹한 부분 이미지들을 획득하는 단계;상기 객체 분류 모델을 이용하여, 상기 부분 이미지를 학습한 것을 바탕으로 제2 깊이값을 획득하는 단계; 및상기 제1 깊이값 및 상기 제2 깊이값의 편차를 줄이도록 상기 객체 분류 모델을 학습하는 단계;를 포함하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 제1 깊이값을 획득하는 단계는상기 이미지의 차원 변환 또는 상기 이미지의 계조 변환을 바탕으로 확장된 학습 데이터를 학습하는 단계를 더 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>13. 제 11 항에 있어서,상기 제1 깊이값을 획득하는 단계는 상기 이미지를 패치 단위로 분할하는 단계; 상기 복수의 패치들을 상기 객체 분류 모델의 인코더에 제공하는 단계; 상기 인코더를 이용하여 제1 특징값을 출력하는 단계;상기 제1 특징값을 상기 객체 분류 모델의 디코더에 제공하는 단계; 및상기 디코더를 이용하여 상기 제1 깊이값을 획득하는 단계;를 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 부분 이미지들을 획득하는 단계는마스크를 이용하여, 상기 패치 단위로 분할된 상기 이미지의 일부 영역을 샘플링하는 단계를 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서, 상기 부분 이미지들을 획득하는 단계는상기 부분 이미지들 각각에서 샘플링 된 상기 패치들이 서로 중복되지 않도록 설정된 상기 마스크들을 이용하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>16. 제 14 항에 있어서,상기 제2 깊이값을 획득하는 단계는상기 부분 이미지들을 상기 인코더에 제공하는 단계; 상기 인코더를 이용하여 상기 부분 이미지들에 대한 부분 특징값을 추출하는 단계; 상기 부분 특징값들을 결합하여, 제2 특징값을 출력하는 단계;상기 제2 특징값을 상기 디코더에 제공하는 단계; 및상기 디코더를 이용하여 상기 제2 깊이값을 획득하는 단계;를 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서,상기 객체 분류 모델을 학습하는 단계는상기 제1 특징값과 상기 제2 특징값의 편차에 비례하는 제1 손실함수의 크기를 계산하는 단계; 및상기 제1 손실함수의 크기를 줄이도록 상기 인코더의 파라미터를 조절하는 단계;를 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>18. 제 11 항에 있어서,상기 객체 분류 모델을 학습하는 단계는상기 제1 깊이값과 상기 제2 깊이값의 편차에 비례하는 제2 손실함수의 크기를 계산하는 단계; 및상기 제2 손실함수의 크기를 줄이도록 상기 객체 분류 모델의 파라미터를 조절하는 단계;를 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서,상기 제2 손실함수를 바탕으로 상기 파라미터가 조절된 상기 객체 분류 모델의 불확실 정도를 판단하는 단계; 및상기 불확실 정도를 바탕으로 상기 제2 손실함수의 가중치를 조절하는 단계;를 더 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo><claimInfo><claim>20. 제 11 항에 있어서,상기 이미지를 학습한 것을 바탕으로 제1 클래스를 획득하는 단계; 상기 부분 이미지를 학습한 것을 바탕으로 제2 클래스를 획득하는 단계; 및상기 제2 클래스와 상기 제2 클래스의 편차를 줄이도록 상기 객체 분류 모델의 파라미터를 조절하는 단계;를 더 포함하는 것을 특징으로 하는 객체 분류 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서초구...</address><code>119980045675</code><country>대한민국</country><engName>HYUNDAI MOTOR COMPANY</engName><name>현대자동차주식회사</name></applicantInfo><applicantInfo><address>서울특별시 서초구...</address><code>119980003181</code><country>대한민국</country><engName>Kia Corporation</engName><name>기아 주식회사</name></applicantInfo><applicantInfo><address>서울특별시 성북구...</address><code>220040170680</code><country>대한민국</country><engName>Korea University Research and Business Foundation</engName><name>고려대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강동구...</address><code> </code><country> </country><engName>PARK, Jin Ho</engName><name>박진호</name></inventorInfo><inventorInfo><address>경기도 화성시...</address><code> </code><country> </country><engName>KIM, Jin Sol</engName><name>김진솔</name></inventorInfo><inventorInfo><address>서울특별시 강동구...</address><code> </code><country> </country><engName>KIM, Jang Yoon</engName><name>김장윤</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM, Seung Ryong</engName><name>김승룡</name></inventorInfo><inventorInfo><address>서울특별시 동대문구...</address><code> </code><country> </country><engName>BAEK, Jong Beom</engName><name>백종범</name></inventorInfo><inventorInfo><address>서울특별시 노원구...</address><code> </code><country> </country><engName>PARK, Seong Hoon</engName><name>박성훈</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM, Gyeong Nyeon</engName><name>김경년</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 사임당로 **, **층 (서초동, 재우빌딩)(마루특허법률사무소)</address><code>920030001993</code><country>대한민국</country><engName>Sung Byung Kee</engName><name>성병기</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.07.05</receiptDate><receiptNumber>1-1-2023-0740362-56</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[출원서 등 보완]보정서</documentName><receiptDate>2023.08.22</receiptDate><receiptNumber>1-1-2023-0924914-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[공지예외적용 보완 증명서류]서류제출서</documentName><receiptDate>2023.08.22</receiptDate><receiptNumber>1-1-2023-0924915-65</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.04.23</receiptDate><receiptNumber>1-1-2025-0458541-19</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230087216.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937264fa64521c39ea0773ccb2a1b690ac4b5d4284494e6d3e9e85aaa68376a27f36a086312f0bf8be2321d18bd73d077da9aca1c600fc3250</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf925c59a54655e70e478bb0323d4ea7d1f72393ff3beb86f34d5a5c689c80e74dcc8d55ac84cfebfbdcab01cf2f22766bed41e4a6ca425b43</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>