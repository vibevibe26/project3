<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:09.409</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7000700</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>깊이 예측들을 사용하는 고속 AR 디바이스 페어링</inventionTitle><inventionTitleEng>FAST AR DEVICE PAIRING USING DEPTH PREDICTIONS</inventionTitleEng><openDate>2025.02.13</openDate><openNumber>10-2025-0021550</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.01.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.01.08</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 별개의 증강 현실(AR) 디바이스들로부터 좌표계들을 정렬하기 위한 방법이 설명된다. 일 양태에서, 본 방법은 제1 증강 현실(AR) 디바이스의 제1 단안 카메라에 의해 생성된 제1 단일 이미지, 및 제1 AR 디바이스에서 제1 SLAM 시스템에 의해 생성된 제1 희소 3D 포인트들에 미리 훈련된 모델을 적용함으로써 제1 포인트 클라우드의 예측된 깊이들을 생성하는 단계, 제2 AR 디바이스의 제2 단안 카메라에 의해 생성된 제2 단일 이미지, 및 제2 AR 디바이스에서 제2 SLAM 시스템에 의해 생성된 제2 희소 3D 포인트들에 미리 훈련된 모델을 적용함으로써 제2 포인트 클라우드의 예측된 깊이들을 생성하는 단계, 및 제1 포인트 클라우드를 제2 포인트 클라우드에 등록함으로써 제1 AR 디바이스와 제2 AR 디바이스 사이의 상대적 자세를 결정하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.12.14</internationOpenDate><internationOpenNumber>WO2023239776</internationOpenNumber><internationalApplicationDate>2023.06.07</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/024688</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,제1 증강 현실(AR) 디바이스의 제1 단안 카메라에 의해 생성된 제1 단일 이미지, 및 상기 제1 AR 디바이스에서 제1 SLAM 시스템에 의해 생성된 제1 희소 3D 포인트들에 미리 훈련된 모델을 적용함으로써 제1 포인트 클라우드의 예측된 깊이들을 생성하는 단계;제2 AR 디바이스의 제2 단안 카메라에 의해 생성된 제2 단일 이미지, 및 상기 제2 AR 디바이스에서 제2 SLAM 시스템에 의해 생성된 제2 희소 3D 포인트들에 상기 미리 훈련된 모델을 적용함으로써 제2 포인트 클라우드의 예측된 깊이들을 생성하는 단계;대응하는 예측된 깊이들에 기초하여 상기 제1 포인트 클라우드를 상기 제2 포인트 클라우드에 등록함으로써 상기 제1 AR 디바이스의 제1 기준 좌표 프레임과 상기 제2 AR 디바이스의 제2 기준 좌표 프레임 사이의 상대적 자세를 결정하는 단계; 및상기 상대적 자세를 상기 제1 AR 디바이스 또는 상기 제2 AR 디바이스 중 적어도 하나에 제공하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 상대적 자세에 기초하여 상기 제1 AR 디바이스의 제1 디스플레이에 제1 가상 객체를 렌더링하는 단계; 및상기 상대적 자세에 기초하여 상기 제2 AR 디바이스의 제2 디스플레이에 제2 가상 객체를 렌더링하는 단계를 추가로 포함하고,상기 제2 가상 객체는 상기 제1 가상 객체에 대응하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제1 AR 디바이스의 6자유도(6DOF) 추적기로부터 상기 제1 희소 3D 포인트들에 액세스하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 6DOF 추적기는 VI-SLAM(Visual Inertial-Simultaneous Localization and Mapping) 시스템을 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 미리 훈련된 모델은 복수의 카메라 디바이스에 의해 캡처된 이미지들로 훈련된 머신 학습 모델인 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 서버는:상기 제1 AR 디바이스 및 상기 제2 AR 디바이스와 통신하고;상기 제1 포인트 클라우드 및 상기 제2 포인트 클라우드의 중첩 영역들을 등록함으로써 상기 상대적 자세를 결정하고;상기 상대적 자세를 상기 제1 AR 디바이스 또는 상기 제2 AR 디바이스 중 적어도 하나에 제공하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 제1 AR 디바이스는 상기 제2 AR 디바이스와 통신하고, 상기 제1 AR 디바이스는 상기 제2 AR 디바이스로부터 상기 제2 포인트 클라우드를 수신하고, 상기 상대적 자세를 결정하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,제3 AR 디바이스의 제3 단안 카메라에 의해 생성된 제3 단일 이미지, 및 상기 제3 AR 디바이스에서 제3 SLAM 시스템에 의해 생성된 제3 희소 3D 포인트들에 상기 미리 훈련된 모델을 적용함으로써 제3 포인트 클라우드의 예측된 깊이들을 생성하는 단계;상기 제1 포인트 클라우드를 상기 제2 포인트 클라우드에 등록함으로써 상기 제1 AR 디바이스의 제1 기준 좌표 프레임과 상기 제2 AR 디바이스의 제2 기준 좌표 프레임 사이의 제1 상대적 자세를 결정하는 단계;상기 제1 포인트 클라우드를 상기 제3 포인트 클라우드에 등록함으로써 상기 제1 AR 디바이스의 상기 제1 기준 좌표 프레임과 상기 제3 AR 디바이스의 제3 기준 좌표 프레임 사이의 제2 상대적 자세를 결정하는 단계;상기 제1 상대적 자세를 상기 제2 AR 디바이스에 제공하는 단계; 및상기 제2 상대적 자세를 상기 제3 AR 디바이스에 제공하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,제3 AR 디바이스의 제3 단안 카메라에 의해 생성된 제3 단일 이미지, 및 상기 제3 AR 디바이스에서 제3 SLAM 시스템에 의해 생성된 제3 희소 3D 포인트들에 상기 미리 훈련된 모델을 적용함으로써 제3 포인트 클라우드의 예측된 깊이들을 생성하는 단계; 및새로운 기준 좌표 프레임에 대해 상기 제1 포인트 클라우드, 상기 제2 포인트 클라우드, 및 상기 제3 포인트 클라우드의 중첩 영역들을 등록함으로써, 상기 제1 AR 디바이스, 상기 제2 AR 디바이스, 및 상기 제3 AR 디바이스에 공통인 상기 새로운 기준 좌표 프레임을 사용하여, 상기 제1 포인트 클라우드의 깊이들에 기초한 상기 제1 AR 디바이스의 제1 자세, 상기 제2 포인트 클라우드의 깊이들에 기초한 상기 제2 AR 디바이스의 제2 자세, 및 상기 제3 포인트 클라우드의 깊이들에 기초한 상기 제3 AR 디바이스의 제3 자세를 식별하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 제1 AR 디바이스는 상기 제1 단일 이미지 및 제1 희소 3D 포인트들로부터 상기 제1 포인트 클라우드를 생성하도록 구성되고, 상기 제1 포인트 클라우드는 상기 제1 희소 3D 포인트들보다 더 조밀한 방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨팅 장치로서,프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때,제1 증강 현실(AR) 디바이스의 제1 단안 카메라에 의해 생성된 제1 단일 이미지, 및 상기 제1 AR 디바이스에서 제1 SLAM 시스템에 의해 생성된 제1 희소 3D 포인트들에 미리 훈련된 모델을 적용함으로써 제1 포인트 클라우드의 예측된 깊이들을 생성하고;제2 AR 디바이스의 제2 단안 카메라에 의해 생성된 제2 단일 이미지, 및 상기 제2 AR 디바이스에서 제2 SLAM 시스템에 의해 생성된 제2 희소 3D 포인트들에 상기 미리 훈련된 모델을 적용함으로써 제2 포인트 클라우드의 예측된 깊이들을 생성하고;대응하는 예측된 깊이들에 기초하여 상기 제1 포인트 클라우드를 상기 제2 포인트 클라우드에 등록함으로써 상기 제1 AR 디바이스의 제1 기준 좌표 프레임과 상기 제2 AR 디바이스의 제2 기준 좌표 프레임 사이의 상대적 자세를 결정하고;상기 상대적 자세를 상기 제1 AR 디바이스 또는 상기 제2 AR 디바이스 중 적어도 하나에 제공하도록 상기 장치를 구성하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 명령어들은:상기 상대적 자세에 기초하여 상기 제1 AR 디바이스의 제1 디스플레이에 제1 가상 객체를 렌더링하고;상기 상대적 자세에 기초하여 상기 제2 AR 디바이스의 제2 디스플레이에 제2 가상 객체를 렌더링하도록 상기 장치를 추가로 구성하고,상기 제2 가상 객체는 상기 제1 가상 객체에 대응하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 명령어들은:상기 제1 AR 디바이스의 6자유도(6DOF) 추적기로부터 상기 제1 희소 3D 포인트들에 액세스하도록 상기 장치를 추가로 구성하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 6DOF 추적기는 VI-SLAM(Visual Inertial-Simultaneous Localization and Mapping) 시스템을 포함하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 미리 훈련된 모델은 복수의 카메라 디바이스에 의해 캡처된 이미지들로 훈련된 머신 학습 모델인 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 서버는:상기 제1 AR 디바이스 및 상기 제2 AR 디바이스와 통신하고;상기 제1 포인트 클라우드 및 상기 제2 포인트 클라우드의 중첩 영역들을 등록함으로써 상기 상대적 자세를 결정하고;상기 상대적 자세를 상기 제1 AR 디바이스 또는 상기 제2 AR 디바이스 중 적어도 하나에 제공하도록 구성되는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 제1 AR 디바이스는 상기 제2 AR 디바이스와 통신하고, 상기 제1 AR 디바이스는 상기 제2 AR 디바이스로부터 상기 제2 포인트 클라우드를 수신하고, 상기 상대적 자세를 결정하도록 구성되는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 명령어들은:제3 AR 디바이스의 제3 단안 카메라에 의해 생성된 제3 단일 이미지, 및 상기 제3 AR 디바이스에서 제3 SLAM 시스템에 의해 생성된 제3 희소 3D 포인트들에 상기 미리 훈련된 모델을 적용함으로써 제3 포인트 클라우드의 예측된 깊이들을 생성하고;상기 제1 포인트 클라우드를 상기 제2 포인트 클라우드에 등록함으로써 상기 제1 AR 디바이스의 제1 기준 좌표 프레임과 상기 제2 AR 디바이스의 제2 기준 좌표 프레임 사이의 제1 상대적 자세를 결정하고;상기 제1 포인트 클라우드를 상기 제3 포인트 클라우드에 등록함으로써 상기 제1 AR 디바이스의 상기 제1 기준 좌표 프레임과 상기 제3 AR 디바이스의 제3 기준 좌표 프레임 사이의 제2 상대적 자세를 결정하고;상기 제1 상대적 자세를 상기 제2 AR 디바이스에 제공하고;상기 제2 상대적 자세를 상기 제3 AR 디바이스에 제공하도록 상기 장치를 추가로 구성하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 명령어들은:제3 AR 디바이스의 제3 단안 카메라에 의해 생성된 제3 단일 이미지, 및 상기 제3 AR 디바이스에서 제3 SLAM 시스템에 의해 생성된 제3 희소 3D 포인트들에 상기 미리 훈련된 모델을 적용함으로써 제3 포인트 클라우드의 예측된 깊이들을 생성하고;새로운 기준 좌표 프레임에 대해 상기 제1 포인트 클라우드, 상기 제2 포인트 클라우드, 및 상기 제3 포인트 클라우드의 중첩 영역들을 등록함으로써, 상기 제1 AR 디바이스, 상기 제2 AR 디바이스, 및 상기 제3 AR 디바이스에 공통인 상기 새로운 기준 좌표 프레임을 사용하여, 상기 제1 포인트 클라우드의 깊이들에 기초한 상기 제1 AR 디바이스의 제1 자세, 상기 제2 포인트 클라우드의 깊이들에 기초한 상기 제2 AR 디바이스의 제2 자세, 및 상기 제3 포인트 클라우드의 깊이들에 기초한 상기 제3 AR 디바이스의 제3 자세를 식별하도록 상기 장치를 추가로 구성하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>20. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금:제1 증강 현실(AR) 디바이스의 제1 단안 카메라에 의해 생성된 제1 단일 이미지, 및 상기 제1 AR 디바이스에서 제1 SLAM 시스템에 의해 생성된 제1 희소 3D 포인트들에 미리 훈련된 모델을 적용함으로써 제1 포인트 클라우드의 예측된 깊이들을 생성하고;제2 AR 디바이스의 제2 단안 카메라에 의해 생성된 제2 단일 이미지, 및 상기 제2 AR 디바이스에서 제2 SLAM 시스템에 의해 생성된 제2 희소 3D 포인트들에 상기 미리 훈련된 모델을 적용함으로써 제2 포인트 클라우드의 예측된 깊이들을 생성하고;대응하는 예측된 깊이들에 기초하여 상기 제1 포인트 클라우드를 상기 제2 포인트 클라우드에 등록함으로써 상기 제1 AR 디바이스의 제1 기준 좌표 프레임과 상기 제2 AR 디바이스의 제2 기준 좌표 프레임 사이의 상대적 자세를 결정하고;상기 상대적 자세를 상기 제1 AR 디바이스 또는 상기 제2 AR 디바이스 중 적어도 하나에 제공하게 하는 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>그리스</country><engName>EVANGELIDIS, Georgios</engName><name>에반겔리디스, 게오르기오스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>슬로바키아</country><engName>MICUSIK, Branislav</engName><name>미쿠식, 브라니슬라프</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>오스트리아</country><engName>ZILLNER, Jakob</engName><name>질너, 제이콥</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>미국</country><engName>LITKE, Nathan Jacob</engName><name>리트케, 나단 제이콥</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.23</priorityApplicationDate><priorityApplicationNumber>17/893,723</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>그리스</priorityApplicationCountry><priorityApplicationDate>2022.06.08</priorityApplicationDate><priorityApplicationNumber>20220100478</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.01.08</receiptDate><receiptNumber>1-1-2025-0027509-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.01.10</receiptDate><receiptNumber>1-5-2025-0007820-80</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257000700.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b76ed8472ef5b352c93a9d383946966391157856b65ac2ca414129ef9fc168d6a779256449c75842390378d02fcf88d762a9566924b09e6e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2c361656378076a6100df3492de959f2eafed3a448384fa9f6a44ffb41af939c1b3be7860dd04002f9a272cc2fe6a7e29eecc04e86fe4d34</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>