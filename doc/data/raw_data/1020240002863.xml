<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:34:59.3459</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0002863</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공지능을 이용한 오디오 캡션을 생성하는 방법 및 그 장치</inventionTitle><inventionTitleEng>A METHOD AND APPARATUS FOR GENERATING AUDIO CAPTION USING  ARTIFICIAL INTELLIGENCE</inventionTitleEng><openDate>2025.07.15</openDate><openNumber>10-2025-0108291</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.01.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 실시 예에 따른 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서, 오디오 신호를 수신하는 단계; 상기 오디오 신호를 기반으로 제1 인공지능 알고리즘 모듈을 통해 예측 캡션 및 잠재 표현을 생성하는 단계; 상기 오디오 신호에 대한 참조 캡션과 상기 예측 캡션을 기반으로 제1 손실을 결정하는 단계; 상기 참조 캡션을 기반으로 기학습된 제2 인공지능 알고리즘 모듈을 통해 시간 캡션을 도출하는 단계; 상기 시간 캡션을 기반으로 제1 샘플 및 제2 샘플을 생성하는 단계; 상기 잠재 표현을 상기 제1 샘플 및 제2 샘플과 대조하여 제2 손실을 결정하는 단계; 및 상기 제1 손실 및 상기 제2 손실을 기반으로 상기 제1 인공지능 알고리즘 모듈을 학습시킬 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 인공지능을 이용하여 전자 장치에 의해 수행되는 방법에 있어서,오디오 신호를 수신하는 단계;상기 오디오 신호를 기반으로 제1 인공지능 알고리즘 모듈을 통해 예측 캡션 및 잠재 표현(hidden representation)을 생성하는 단계;상기 오디오 신호에 대한 참조 캡션과 상기 예측 캡션을 기반으로 제1 손실을 결정하는 단계;상기 참조 캡션을 기반으로 기학습된 제2 인공지능 알고리즘 모듈을 통해 시간 캡션(temporal caption)을 도출하는 단계;상기 시간 캡션을 기반으로 제1 샘플 및 제2 샘플을 생성하는 단계;상기 잠재 표현을 상기 제1 샘플 및 제2 샘플과 대조하여 제2 손실을 결정하는 단계; 및상기 제1 손실 및 상기 제2 손실을 기반으로 상기 제1 인공지능 알고리즘 모듈을 학습시키는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 시간 캡션은 사운드 이벤트 및 배경 사운드 정보를 포함하고,상기 사운드 이벤트 및 배경 사운드 정보는 사운드 정보 및 순서 정보를 포함하도록 구성되고,상기 사운드 이벤트는 제1 사운드 이벤트 및 제2 사운드 이벤트를 포함하고,상기 제1 사운드 이벤트는 상기 제2 사운드 이벤트보다 시간적으로 앞선 사운드 정보를 포함하고, 및상기 배경 사운드 정보는 상기 제1 사운드 이벤트 및 상기 제2 사운드 이벤트와 동시에 나타나는 사운드를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제1 샘플은 긍정적 샘플(positive sample)이고, 상기 제2 샘플은 부정적 샘플(negative sample)이고,상기 긍정적 샘플은 상기 시간 캡션과 동일한 정보를 포함하고,상기 부정적 샘플은 상기 시간 캡션과 다른 정보를 포함하도록 생성되는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 시간 캡션을 기반으로 상기 제2 샘플을 생성하는 단계는:상기 제1 사운드 이벤트, 상기 제2 사운드 이벤트 및 상기 배경 사운드 정보에 대하여 상기 순서 정보를 셔플링하여 상기 제2 샘플을 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 시간 캡션을 기반으로 상기 제2 샘플을 생성하는 단계는:상기 제1 사운드 이벤트, 상기 제2 사운드 이벤트 및 상기 배경 사운드 중 적어도 하나에 대하여 마스킹을 수행하여 상기 사운드 정보를 변경하고, 상기 제1 사운드 이벤트, 상기 제2 사운드 이벤트 및 상기 배경 사운드에 포함된 상기 순서 정보를 셔플링하여 상기 제2 샘플을 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제1 손실은 교차 엔트로피(cross entropy) 손실이고,상기 제2 손실은 InfoNCE(noise contrastive estimation) 손실인 방법.</claim></claimInfo><claimInfo><claim>7. 제2항에 있어서,상기 시간 캡션은 &quot;사운드 정보: 순서 정보&quot; 형태로 표현되고,상기 사운드 정보는 사운드를 문자로 표현한 정보를 포함하고,상기 순서 정보는 제n 이벤트 및 배경을 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 전자 장치에 있어서,메모리;모뎀; 및상기 모뎀 및 상기 메모리에 연결되는 프로세서를 포함하고,상기 프로세서는:오디오 신호를 수신하고,상기 오디오 신호를 기반으로 제1 인공지능 알고리즘 모듈을 통해 예측 캡션 및 잠재 표현(hidden representation)을 생성하고,상기 오디오 신호에 대한 참조 캡션과 상기 예측 캡션을 기반으로 제1 손실을 결정하고,상기 참조 캡션을 기반으로 기학습된 제2 인공지능 알고리즘 모듈을 통해 시간 캡션(temporal caption)을 도출하고,상기 시간 캡션을 기반으로 제1 샘플 및 제2 샘플을 생성하고,상기 잠재 표현을 상기 제1 샘플 및 제2 샘플과 대조하여 제2 손실을 결정하고,상기 제1 손실 및 상기 제2 손실을 기반으로 상기 제1 인공지능 알고리즘 모듈을 학습시키도록 구성되는 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 시간 캡션은 사운드 이벤트 및 배경 사운드 정보를 포함하고,상기 사운드 이벤트 및 배경 사운드 정보는 사운드 정보 및 순서 정보를 포함하도록 구성되고,상기 사운드 이벤트는 제1 사운드 이벤트 및 제2 사운드 이벤트를 포함하고,상기 제1 사운드 이벤트는 상기 제2 사운드 이벤트보다 시간적으로 앞선 사운드 정보를 포함하고, 및상기 배경 사운드 정보는 상기 제1 사운드 이벤트 및 상기 제2 사운드 이벤트와 동시에 나타나는 사운드를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제1 샘플은 긍정적 샘플(positive sample)이고, 상기 제2 샘플은 부정적 샘플(negative sample)이고,상기 긍정적 샘플은 상기 시간 캡션과 동일한 정보를 포함하고,상기 부정적 샘플은 상기 시간 캡션과 다른 정보를 포함하도록 생성되는 전자 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 프로세서는:상기 제1 사운드 이벤트, 상기 제2 사운드 이벤트 및 상기 배경 사운드 정보에 대하여 상기 순서 정보를 셔플링하여 상기 제2 샘플을 생성하도록 구성되는 전자 장치.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 제1 사운드 이벤트, 상기 제2 사운드 이벤트 및 상기 배경 사운드 중 적어도 하나에 대하여 마스킹을 수행하여 상기 사운드 정보를 변경하고, 상기 제1 사운드 이벤트, 상기 제2 사운드 이벤트 및 상기 배경 사운드에 포함된 상기 순서 정보를 셔플링하여 상기 제2 샘플을 생성하도록 구성되는 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제8항에 있어서,상기 제1 손실은 교차 엔트로피(cross entropy) 손실이고,상기 제2 손실은 InfoNCE 손실인 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제9항에 있어서,상기 시간 캡션은 &quot;사운드 정보: 순서 정보&quot; 형태로 표현되고,상기 사운드 정보는 사운드를 문자로 표현한 정보를 포함하고,상기 순서 정보는 제n 이벤트 및 배경을 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>15. 프로세서(processor)에 의해 실행 가능한 인공지능 알고리즘을 통해 오디오 캡셔닝을 수행하기 위한 매체에 저장된 프로그램으로서,오디오 신호를 수신하는 단계;상기 오디오 신호를 기반으로 제1 인공지능 알고리즘 모듈을 통해 예측 캡션 및 잠재 표현(hidden representation)을 생성하는 단계;상기 오디오 신호에 대한 참조 캡션과 상기 예측 캡션을 기반으로 제1 손실을 결정하는 단계;상기 참조 캡션을 기반으로 기학습된 제2 인공지능 알고리즘 모듈을 통해 시간 캡션(temporal caption)을 도출하는 단계;상기 시간 캡션을 기반으로 제1 샘플 및 제2 샘플을 생성하는 단계;상기 잠재 표현을 상기 제1 샘플 및 제2 샘플과 대조하여 제2 손실을 결정하는 단계; 및상기 제1 손실 및 상기 제2 손실을 기반으로 상기 제1 인공지능 알고리즘 모듈을 학습시키는 단계를 포함하는 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성동구...</address><code>220040114276</code><country>대한민국</country><engName>IUCF-HYU (Industry-University Cooperation Foundation Hanyang University)</engName><name>한양대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>JANG, Joon Hyuk</engName><name>장준혁</name></inventorInfo><inventorInfo><address>서울특별시 성동구...</address><code> </code><country> </country><engName>CHOI, Ho Yeong</engName><name>최호영</name></inventorInfo><inventorInfo><address>서울특별시 성동구...</address><code> </code><country> </country><engName>CHO, Jae Heung</engName><name>조재흥</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서초구 서초대로 *** (서초동) ***호(모티버스특허법률사무소)</address><code>920140005853</code><country>대한민국</country><engName>YOON JONGWON</engName><name>윤종원</name></agentInfo><agentInfo><address>서울 서초구 서초대로 *** (서초동) ***호(모티버스특허법률사무소)</address><code>920100003859</code><country>대한민국</country><engName>Chung Sungjoon</engName><name>정성준</name></agentInfo><agentInfo><address>서울 서초구 서초대로 *** (서초동) ***호(모티버스특허법률사무소)</address><code>920120011733</code><country>대한민국</country><engName>Choi Young Soo</engName><name>최영수</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.01.08</receiptDate><receiptNumber>1-1-2024-0025184-33</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240002863.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9366f162581ea5e2a35dea60ca3df1326e6677f894d30ea7edcb41e4d46c2319d10e42ca1bc74a71d7245377e2d08b20eb4987a36593808b66</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf10656c342785203de5b98f896ab8c27ac11079eaf33d5552991cff2e9ccc97fb193857bb1738226a7cfb26975ed2853be7f70686c0752453</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>