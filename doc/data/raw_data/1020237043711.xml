<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:44.144</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.06.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7043711</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>뉴럴 네트워크들에 대한 계층적 지도 훈련</inventionTitle><inventionTitleEng>HIERARCHICAL SUPERVISED TRAINING FOR NEURAL NETWORKS</inventionTitleEng><openDate>2024.02.27</openDate><openNumber>10-2024-0025522</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.06.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.12.18</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/2431</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/23</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 특정 양태들은 계층적 지도를 사용하여 뉴럴 네트워크들을 훈련시키기 위한 기법들을 제공한다. 예시적인 방법은 일반적으로 훈련 데이터 세트 및 훈련 데이터 세트 내의 데이터가 분류될 수 있는 초기 수의 분류 클러스터들을 사용하여 복수의 스테이지들을 갖는 뉴럴 네트워크를 훈련시키는 단계를 포함한다. 클러스터-검증 세트 성능 메트릭이 초기 수의 분류 클러스터들에 비해 감소된 수의 분류 클러스터들 및 검증 데이터 세트에 기초하여 각각의 스테이지에 대해 생성된다. 각각의 스테이지에서 구현할 분류 클러스터들의 수는 클러스터-검증 세트 성능 메트릭 및 뉴럴 네트워크의 마지막 스테이지에 대한 클러스터-검증 세트 성능 메트릭에 대해 선택된 각도에 기초하여 선택된다. 뉴럴 네트워크는 훈련 데이터 세트 및 각각의 스테이지에 대한 선택된 수의 분류 클러스터들에 기초하여 재훈련되고, 훈련된 뉴럴 네트워크가 배치된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.12.29</internationOpenDate><internationOpenNumber>WO2022272311</internationOpenNumber><internationalApplicationDate>2022.06.25</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/073173</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 기계 학습 모델을 사용하여 추론을 생성하기 위한 컴퓨터 구현 방법으로서,분류를 위한 입력을 수신하는 단계;복수의 스테이지들을 갖는 뉴럴 네트워크를 사용하여 상기 입력을 분류하는 단계로서, 상기 복수의 스테이지들의 각각의 스테이지는 상이한 수의 분류 클러스터들을 사용하여 상기 입력을 분류하는, 상기 입력을 분류하는 단계; 및상기 입력의 분류에 기초하여 하나 이상의 액션들을 수행하는 단계를 포함하는, 기계 학습 모델을 사용하여 추론을 생성하기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 출력을 분류하는 단계는 상기 복수의 스테이지들의 이전 스테이지에 의해 생성된 추론에 기초하여 상기 복수의 스테이지들 중의 일 스테이지에서 상기 입력을 분류하는 단계를 포함하는, 기계 학습 모델을 사용하여 추론을 생성하기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 뉴럴 네트워크는 뉴럴 네트워크의 각각의 스테이지에 세그먼트화 트랜스포머(segmentation transformer)들을 포함하는 상기 뉴럴 네트워크를 포함하고,상기 뉴럴 네트워크의 최종 스테이지 이외의 상기 뉴럴 네트워크의 각각의 스테이지의 출력이 어그리게이팅되고(aggregated),어그리게이팅된 상기 출력은 상기 뉴럴 네트워크의 최종 스테이지와 연관된 세그먼트화 트랜스포머에 입력되어 상기 입력의 분류를 생성하는, 기계 학습 모델을 사용하여 추론을 생성하기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 복수의 스테이지들의 각각의 스테이지는 상기 복수의 스테이지들의 선행 스테이지보다 더 많은 수의 분류 클러스터들을 사용하여 상기 입력을 분류하는, 기계 학습 모델을 사용하여 추론을 생성하기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법으로서,훈련 데이터 세트 및 상기 훈련 데이터 세트 내의 데이터가 분류될 수 있는 초기 수의 분류 클러스터를 사용하여 복수의 스테이지들을 갖는 뉴럴 네트워크를 훈련시키는 단계;상기 초기 수의 분류 클러스터들에 비해 감소된 수의 분류 클러스터들 및 상기 훈련 데이터 세트와 별개인 검증 데이터 세트에 기초하여 상기 뉴럴 네트워크의 상기 복수의 스테이지들의 각각의 스테이지에 대한 클러스터-검증 세트 성능 메트릭을 생성하는 단계;상기 클러스터-검증 세트 성능 메트릭 및 상기 뉴럴 네트워크의 마지막 스테이지에 대한 클러스터-검증 세트 성능 메트릭에 대해 선택된 각도에 기초하여 상기 뉴럴 네트워크의 상기 복수의 스테이지들의 각각의 스테이지에서 구현할 분류 클러스터들의 수를 선택하는 단계;상기 훈련 데이터 세트 및 상기 복수의 스테이지들의 각각의 스테이지에 대한 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 재훈련시키는 단계; 및훈련된 상기 뉴럴 네트워크를 배치하는 단계를 포함하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 복수의 스테이지들의 각각의 스테이지에 대해,상기 훈련 데이터 세트에 대한 혼동 매트릭스(confusion matrix) 및 상기 검증 데이터 세트에 대한 혼동 매트릭스를 계산하는 단계로서, 상기 혼동 매트릭스들의 일 차원(one dimension)에 있는 개별 엘리먼트(discrete element)들이 복수의 분류 클러스터들 중 하나를 표현하는, 상기 혼동 매트릭스를 계산하는 단계;상기 훈련 데이터 세트에 대해 계산된 혼동 매트릭스 및 상기 검증 데이터 세트에 대해 계산된 혼동 매트릭스에 기초하여 인접 매트릭스(adjacency matrix)를 계산하는 단계; 및복수의 이웃 클러스터들이 상기 복수의 이웃 클러스터들 각각보다 더 폭넓은 데이터 분류를 표현하는 단일 클러스터로 감소되도록 계산된 상기 인접 매트릭스에서 이웃 클러스터들의 응집 클러스터링(agglomerative clustering)을 사용하여 상기 감소된 수의 분류 클러스터들을 생성하는 단계를 추가로 포함하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서, 상기 클러스터-검증 세트 성능 메트릭을 생성하는 단계는 상기 초기 수의 분류 클러스터들을 포함하여 그 분류 클러스터들까지의 클러스터 크기들에 대한 상기 복수의 스테이지들에서의 각각의 스테이지에 대한 성능 메트릭을 계산하는 단계를 포함하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 성능 메트릭은 상기 뉴럴 네트워크 내의 상기 복수의 스테이지들의 각각의 스테이지 내의 클러스터들의 수의 함수로서 계산된 mIoU(mean intersection over union) 메트릭을 포함하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제5항에 있어서,상기 선택된 각도는 0도 각도를 포함하고,상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 훈련시키는 단계는 직접 지도(direct supervision)를 사용하여 상기 뉴럴 네트워크 내의 상기 복수의 스테이지들을 훈련시키는 단계를 포함하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제5항에 있어서,상기 선택된 각도는 90도 각도를 포함하고,상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 훈련시키는 단계는 상기 뉴럴 네트워크의 각각의 스테이지의 성능이 임계 값 내의 성능 레벨로 수렴하도록 상기 뉴럴 네트워크 내의 상기 복수의 스테이지들을 훈련시키는 단계를 포함하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제5항에 있어서, 상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 재훈련시키는 단계는 총 손실 함수를 최소화하는 단계를 포함하고,상기 총 손실 함수는 상기 복수의 스테이지들의 각각의 개별 스테이지와 연관된 값에 의해 가중된 상기 복수의 스테이지들의 각각의 개별 스테이지에 대한 손실 함수의 합을 포함하고,상기 복수의 스테이지들의 상기 개별 스테이지에 대한 손실 함수는 상기 개별 스테이지에 대해 선택된 분류 클러스터들의 수에 기초하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 제5항에 있어서, 상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 재훈련시키는 단계는,상기 뉴럴 네트워크의 최종 스테이지 이외의 상기 복수의 스테이지들의 각각의 스테이지의 출력을 어그리게이팅하는 단계; 및상기 뉴럴 네트워크의 최종 스테이지와 연관된 세그먼트화 트랜스포머 모듈로의 상기 뉴럴 네트워크의 최종 스테이지 이외의 상기 복수의 스테이지들의 어그리게이팅된 상기 출력의 입력에 기초하여 상기 뉴럴 네트워크의 최종 스테이지를 훈련시키는 단계를 포함하는, 기계 학습 모델을 훈련시키기 위한 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>13. 프로세싱 시스템으로서,컴퓨터 실행가능 명령들이 저장된 메모리; 및프로세서를 포함하고, 상기 프로세서는 상기 컴퓨터 실행가능 명령들을 실행하여, 상기 프로세싱 시스템으로 하여금,분류를 위한 입력을 수신하게 하고;복수의 스테이지들을 갖는 뉴럴 네트워크를 사용하여 상기 입력을 분류하게 하는 것으로서, 상기 복수의 스테이지들의 각각의 스테이지는 상이한 수의 분류 클러스터들을 사용하여 상기 입력을 분류하는, 상기 입력을 분류하게 하고; 그리고상기 입력의 분류에 기초하여 하나 이상의 액션들을 수행하게 하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 출력을 분류하기 위해, 상기 프로세서는 상기 프로세싱 시스템으로 하여금, 상기 복수의 스테이지들의 이전 스테이지에 의해 생성된 추론에 기초하여 상기 복수의 스테이지들 중의 일 스테이지에서 상기 입력을 분류하게 하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 뉴럴 네트워크는 뉴럴 네트워크의 각각의 스테이지에 세그먼트화 트랜스포머들을 포함하는 상기 뉴럴 네트워크를 포함하고,상기 뉴럴 네트워크의 최종 스테이지 이외의 상기 뉴럴 네트워크의 각각의 스테이지의 출력이 어그리게이팅되고,어그리게이팅된 상기 출력은 상기 뉴럴 네트워크의 최종 스테이지와 연관된 세그먼트화 트랜스포머에 입력되어 상기 입력의 분류를 생성하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서, 상기 복수의 스테이지들의 각각의 스테이지는 상기 복수의 스테이지들의 선행 스테이지보다 더 많은 수의 분류 클러스터들을 사용하여 상기 입력을 분류하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>17. 프로세싱 시스템으로서,컴퓨터 실행가능 명령들이 저장된 메모리; 및프로세서를 포함하고, 상기 프로세서는 상기 컴퓨터 실행가능 명령들을 실행하여, 상기 프로세싱 시스템으로 하여금,훈련 데이터 세트 및 상기 훈련 데이터 세트 내의 데이터가 분류될 수 있는 초기 수의 분류 클러스터를 사용하여 복수의 스테이지들을 갖는 뉴럴 네트워크를 훈련시키게 하고;상기 초기 수의 분류 클러스터들에 비해 감소된 수의 분류 클러스터들 및 상기 훈련 데이터 세트와 별개인 검증 데이터 세트에 기초하여 상기 뉴럴 네트워크의 상기 복수의 스테이지들의 각각의 스테이지에 대한 클러스터-검증 세트 성능 메트릭을 생성하게 하고;상기 클러스터-검증 세트 성능 메트릭 및 상기 뉴럴 네트워크의 마지막 스테이지에 대한 클러스터-검증 세트 성능 메트릭에 대해 선택된 각도에 기초하여 상기 뉴럴 네트워크의 상기 복수의 스테이지들의 각각의 스테이지에서 구현할 분류 클러스터들의 수를 선택하게 하고;상기 훈련 데이터 세트 및 상기 복수의 스테이지들의 각각의 스테이지에 대한 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 재훈련시키게 하고; 그리고훈련된 상기 뉴럴 네트워크를 배치하게 하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 프로세서는 상기 프로세싱 시스템으로 하여금,상기 훈련 데이터 세트에 대한 혼동 매트릭스 및 상기 검증 데이터 세트에 대한 혼동 매트릭스를 계산하게 하는 것으로서, 상기 혼동 매트릭스들의 일 차원에 있는 개별 엘리먼트들이 복수의 분류 클러스터들 중 하나를 표현하는, 상기 혼동 매트릭스를 계산하게 하고;상기 훈련 데이터 세트에 대해 계산된 혼동 매트릭스 및 상기 검증 데이터 세트에 대해 계산된 혼동 매트릭스에 기초하여 인접 매트릭스를 계산하게 하고; 그리고복수의 이웃 클러스터들이 상기 복수의 이웃 클러스터들 각각보다 더 폭넓은 데이터 분류를 표현하는 단일 클러스터로 감소되도록 계산된 상기 인접 매트릭스에서 이웃 클러스터들의 응집 클러스터링을 사용하여 상기 감소된 수의 분류 클러스터들을 생성하게 하도록 추가로 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 클러스터-검증 세트 성능 메트릭을 생성하기 위해, 상기 프로세서는 상기 프로세싱 시스템으로 하여금, 상기 초기 수의 분류 클러스터들을 포함하여 그 분류 클러스터들까지의 클러스터 크기들에 대한 상기 복수의 스테이지들에서의 각각의 스테이지에 대한 성능 메트릭을 계산하게 하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 성능 메트릭은 상기 뉴럴 네트워크 내의 상기 복수의 스테이지들의 각각의 스테이지 내의 클러스터들의 수의 함수로서 계산된 mIoU (mean intersection over union) 메트릭을 포함하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>21. 제17항에 있어서,상기 선택된 각도는 0도 각도를 포함하고,상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 훈련시키기 위해, 상기 프로세서는 상기 프로세싱 시스템으로 하여금, 직접 지도를 사용하여 상기 뉴럴 네트워크 내의 상기 복수의 스테이지들을 훈련시키게 하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>22. 제17항에 있어서,상기 선택된 각도는 90도 각도를 포함하고,상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 훈련시키기 위해, 상기 프로세서는 상기 프로세싱 시스템으로 하여금, 상기 뉴럴 네트워크의 각각의 스테이지의 성능이 임계 값 내의 성능 레벨로 수렴하도록 상기 뉴럴 네트워크 내의 상기 복수의 스테이지들을 훈련시키게 하도록 구성되는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>23. 제17항에 있어서, 상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 재훈련시키기 위해, 상기 프로세서는 상기 프로세싱 시스템으로 하여금, 총 손실 함수를 최소화하게 하도록 구성되고,상기 총 손실 함수는 상기 복수의 스테이지들의 각각의 개별 스테이지와 연관된 값에 의해 가중된 상기 복수의 스테이지들의 각각의 개별 스테이지에 대한 손실 함수의 합을 포함하고,상기 복수의 스테이지들의 상기 개별 스테이지에 대한 손실 함수는 상기 개별 스테이지에 대해 선택된 분류 클러스터들의 수에 기초하는, 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>24. 제17항에 있어서, 상기 훈련 데이터 세트 및 각각의 스테이지에서의 상기 선택된 수의 분류 클러스터들에 기초하여 상기 뉴럴 네트워크를 재훈련시키기 위해, 상기 프로세서는 상기 프로세싱 시스템으로 하여금,상기 뉴럴 네트워크의 최종 스테이지 이외의 상기 복수의 스테이지들의 각각의 스테이지의 출력을 어그리게이팅하게 하고; 그리고상기 뉴럴 네트워크의 최종 스테이지와 연관된 세그먼트화 트랜스포머 모듈로의 상기 뉴럴 네트워크의 최종 스테이지 이외의 상기 복수의 스테이지들의 어그리게이팅된 상기 출력의 입력에 기초하여 상기 뉴럴 네트워크의 최종 스테이지를 훈련시키게 하도록 구성되는, 프로세싱 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>BORSE, SHUBHANKAR MANGESH</engName><name>보르세 슈반카르 망게쉬 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>CAI, HONG</engName><name>차이 홍 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>ZHANG, YIZHE</engName><name>장 이제</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>PORIKLI, FATIH MURAT</engName><name>포리클리 파티 무라트</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.06.25</priorityApplicationDate><priorityApplicationNumber>63/214,940</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.06.24</priorityApplicationDate><priorityApplicationNumber>17/808,949</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.12.18</receiptDate><receiptNumber>1-1-2023-1417925-97</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.01.26</receiptDate><receiptNumber>1-5-2024-0017780-96</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.06.09</receiptDate><receiptNumber>1-1-2025-0637103-23</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.06.09</receiptDate><receiptNumber>1-1-2025-0637104-79</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237043711.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93432cad8630d3cd166469ccb26e4f2793cc01ec8c2a2311f6788c9c0e10f9e24e74dc7966e5be7842a81a65fa6f8a736af1cc6d6a1f9537ee</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4a66c6f6b16f8606bfa838907ea9c407b071f639acdeb667600a39b86e2f2614eb34e7037481e493e032fd80401eeeeed7f9d7ac65a59410</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>