<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:11:03.113</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0024463</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 복원을 위한 심층 모듈식 시스템</inventionTitle><inventionTitleEng>DEEP MODULAR SYSTEMS FOR IMAGE RESTORATION</inventionTitleEng><openDate>2024.08.29</openDate><openNumber>10-2024-0130635</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미지 복원 테스크(예: 디모자이크 동작)을 위해 신경망(예: CNN(컨볼루션 신경망))을 활용하는 이미지 처리 시스템 및 이미지 처리 기술이 설명된다. 특정 실시예에서, 문제 공간(예를 들어, 이미지 재구성 테스크)을 동질적인 영역으로 나누기 위해 다수의 서로 다른 엑스퍼트 네트워크가 사용되는 엑스퍼트 네트워크 혼합(Mixture of Experts; MoE) 기술이 사용될 수 있다. 예를 들어, 각 MoE 모듈은 이미지의 특정 문제를 재구성할 수 있으며 게이팅 구성 요소는 특정 MoE 모듈을 활성화하여 재구성되는 이미지를 제공할 수 있다. 일부 실시예에서, 개별 성능을 높이기 위해 MoE 아키텍처의 각 엑스퍼트 네트워크에 대해 트레이닝 및 최적화 기술이 설명된다(예를 들어, 이미지 처리 시스템의 각 엑스퍼트 네트워크에 대한 하위 테스크가 잔여 방식으로 부과될 수 있고, 게이팅 기능이 트레이닝될 수 있는 등). 따라서 이미지 처리 시스템은 MoE 아키텍처를 활용하여 향상된 이미지 재구성 애플리케이션을 위한 다수의 신경망 매개변수를 지원할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컬러 필터 어레이를 포함하는 이미지 센서로부터 센서 데이터를 획득하는 단계; 제1 디모자이크 엑스퍼트(demosaicing expert)에 의해, 상기 센서 데이터에 기초하여 제1 디모자이크 이미지를 획득하기 위한 제1 디모자이크 동작을 수행하는 단계; 제2 디모자이크 엑스퍼트에 의해, 상기 센서 데이터에 기초하여 제2 디모자이크 이미지를 획득하기 위한 제2 디모자이크 동작을 수행하는 단계; 및 상기 제1 디모자이크 이미지와 상기 제2 디모자이크 이미지를 결합하여 출력 이미지를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 컬러 필터 어레이는 베이어(Bayer) 컬러 필터 어레이를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제1 디모자이크 동작은 일반적인 디모자이크 동작을 포함하고,상기 제2 디모자이크 동작은 하나 이상의 이미지 아티팩트(artifact)를 정정하는 잔여(residual) 디모자이크 동작을 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제2 디모자이크 동작은,상기 센서 데이터의 녹색 색상에 대해 제1 부분 디모자이크 동작을 수행하여 녹색 이미지 데이터를 획득하는 단계; 및상기 녹색 이미지 데이터에 기초하여 제2 부분 디모자이크 동작을 수행하여 적색 이미지 데이터 및 청색 이미지 데이터를 획득하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,하나 이상의 색상 상관 계수를 계산하는 단계를 더 포함하고,상기 제2 부분 디모자이크 동작은 상기 하나 이상의 색상 상관 계수에 기초하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,정제된 이미지를 얻기 위해 상기 출력 이미지에 대해 이미지 정제(image refinement)를 수행하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,제3 디모자이크 엑스퍼트에 의해, 상기 센서 데이터에 기초하여 제3 디모자이크 이미지를 획득하도록 제3 디모자이크 동작을 수행하는 단계를 더 포함하고,상기 출력 이미지는 상기 제3 디모자이크 이미지에 기초하여 생성되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제1 디모자이크 이미지와 상기 제2 디모자이크 이미지의 각각의 픽셀에 대한 가중치 매개변수를 포함하는 가중치 맵을 계산하는 단계를 더 포함하고,상기 출력 이미지는 상기 가중치 맵에 기초하여 생성되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>9. 이미지를 처리하는 장치에 있어서,적어도 하나의 프로세서; 명령어를 저장하고 상기 적어도 하나의 프로세서와 통신하는 적어도 하나의 메모리; 컬러 필터 어레이를 포함하는 이미지 센서; 상기 적어도 하나의 메모리에 저장된 파라미터들을 포함하고, 상기 이미지 센서로부터의 센서 데이터에 기초하여 제1 디모자이크 이미지를 획득하기 위해 제1 디모자이크 동작을 수행하도록 구성되는 제1 디모자이크 엑스퍼트; 상기 적어도 하나의 메모리에 저장된 파라미터들을 포함하고, 상기 센서 데이터에 기초하여 제2 디모자이크 이미지를 획득하기 위해 제2 디모자이크 동작을 수행하도록 구성되는 제2 디모자이크 엑스퍼트; 및 출력 이미지를 획득하기 위해 상기 제1 디모자이크 이미지와 상기 제2 디모자이크 이미지를 결합하도록 구성되는 게이팅 구성요소를 포함하는 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 컬러 필터 어레이는 베이어(Bayer) 컬러 필터 어레이를 포함하는 것을 특징으로 하는 장치.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 제1 디모자이크 엑스퍼트는 일반 디모자이크 동작을 수행하도록 트레이닝된 제1 신경망(neural network)을 포함하고,상기 제2 디모자이크 엑스퍼트는 하나 이상의 이미지 아티팩트를 정정하는 잔여 디모자이크 동작을 수행하도록 트레이닝된 제2 신경망을 포함하는 것을 특징으로 하는 장치.</claim></claimInfo><claimInfo><claim>12. 제9항에 있어서,상기 게이팅 구성요소는 상기 제1 디모자이크 이미지와 상기 제2 디모자이크 이미지를 결합하도록 트레이닝된 신경망을 포함하는 것을 특징으로 하는 장치.</claim></claimInfo><claimInfo><claim>13. 제9항에 있어서,상기 제2 디모자이크 엑스퍼트는,상기 센서 데이터의 녹색 색상에 대해 제1 부분 디모자이크 동작을 수행하여 녹색 이미지 데이터를 획득하도록 구성되는 제1 구성요소; 및상기 그린 이미지 데이터에 기초하여 제2 부분 디모자이킹 동작을 수행하여 적색 이미지 데이터 및 청색 이미지 데이터를 획득하도록 구성되는 제2 구성요소를 포함하는 것을 특징으로 하는 장치.</claim></claimInfo><claimInfo><claim>14. 제9항에 있어서,개선된 이미지를 획득하기 위해 상기 출력 이미지를 개선하도록 구성되는 이미지 개선 컴포넌트를 더 포함하는 것을 특징으로 하는 장치.</claim></claimInfo><claimInfo><claim>15. 제9항에 있어서,상기 적어도 하나의 메모리에 저장된 파라미터들을 포함하고, 상기 센서 데이터에 기초하여 제3 디모자이크 이미지를 획득하기 위해 제3 디모자이크 동작을 수행하도록 구성되는 제3 디모자이크 엑스퍼트를 더 포함하고,상기 출력 이미지는 제3 디모자이크 이미지에 기초하여 획득되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>16. 실측(ground truth) 디모자이크 이미지와 컬러 필터 어레이로부터 얻은 센서 데이터를 포함하는 트레이닝 데이터를 획득하는 단계; 이미지 아티팩트의 존재에 적어도 부분적으로 기초하여 상기 트레이닝 데이터를 제1 카테고리와 제2 카테고리로 나누는 단계; 상기 트레이닝 데이터의 상기 제1 카테고리에 기초하여 제1 단계에서 디모자이크를 수행하도록 신경망을 트레이닝시키는 제1 트레이닝 단계; 및 상기 트레이닝 데이터의 상기 제2 카테고리에 기초하여 제2 단계에서 디모자이크를 수행하도록 상기 신경망을 트레이닝시키는 제2 트레이닝 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 제1 트레이닝 단계는, 상기 트레이닝 데이터의 상기 제1 카테고리를 제외한 특정 데이터세트에 기초하고,상기 제2 트레이닝 단계는, 상기 트레이닝 데이터의 상기 제1 카테고리와 상기 트레이닝 데이터의 상기 제2 카테고리를 포함하는 일반 데이터 세트에 기초하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 트레이닝 데이터의 상기 제1 카테고리에 기초하여 제3 단계에서 디모자이크를 수행하도록 상기 신경망을 트레이닝하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서,상기 이미지 센서로부터의 상기 센서 데이터에 기초하여 제1 디모자이크 이미지를 획득하기 위한 제1 디모자이크 동작을 수행하도록 상기 신경망의 제1 디모자이크 엑스퍼트를 트레이닝시키는 단계; 및 상기 센서 데이터에 기초하여 제2 디모자이크 이미지를 획득하기 위한 제2 디모자이크 동작을 수행하도록 상기 신경망의 제2 디모자이크 엑스퍼트를 트레이닝시키는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 신경망의 게이팅 구성 요소는 제1 디모자이크 엑스퍼트와 제2 디모자이크 엑스퍼트를 트레이닝시킨 후 제1 단계와 제2 단계에서 트레이닝되는 것을 특징으로 하는 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>NOSSEK, Raz</engName><name>노섹 라즈</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>BECKER, Yuval</engName><name>베커 유발</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PELEG, Tomer</engName><name>펠레그 토머</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>DUBINCHIK, Stas</engName><name>두빈치크 스타스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.02.22</priorityApplicationDate><priorityApplicationNumber>63/447,467</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.10.23</priorityApplicationDate><priorityApplicationNumber>18/491,872</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.02.20</receiptDate><receiptNumber>1-1-2024-0196961-68</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2024.02.25</receiptDate><receiptNumber>9-1-2024-9002131-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2024.02.25</receiptDate><receiptNumber>9-1-2024-9002134-85</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240024463.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d26470aab544a6c6ad1690a98faa19ad7cdac36a6c414ca647825054685d0520d6a367592ff5e30579d2cabcd6671e99dab41f339585479b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa484949845b9ab8c0fb0b947cff687fe8ff55245684c19da8dd47254f9397d15e8325039dfe257ddf857127624bbe55ba46a992e32d5b86e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>