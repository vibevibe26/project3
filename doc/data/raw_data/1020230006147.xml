<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:16:04.164</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0006147</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 인식기 학습 방법 및 그 장치</inventionTitle><inventionTitleEng>APPARATUS AND METHOD FOR LEARNING OBJECT  DETECTOR</inventionTitleEng><openDate>2024.05.17</openDate><openNumber>10-2024-0068032</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/89</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 아래의 개시는 객체 인식기 학습 장치에 관한 것이다. 객체 인식기 학습 장치는 입력 데이터를 획득 데이터 증강을 통해 추가 입력 데이터를 획득하고, 입력 데이터 및 추가 입력 데이터로부터 특징 벡터들을 추출하여 결정된 손실 함수를 이용하여 대조 학습을 수행할 수 있다. 객체 인식기 학습 장치는 대조 학습 결과를 통해 객체 인식기를 업데이트할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 대상 객체에 관한 제1 입력 데이터 및 제2 입력 데이터를 획득하는 단계;상기 제2 입력 데이터에 대하여 데이터 증강을 수행하여 제2 추가 입력 데이터를 획득하는 단계;상기 제1 입력 데이터를 제1 인코더에 입력하여 공유 임베딩 스페이스에 제1 특징(feature)을 추출하는 단계;상기 제2 입력 데이터를 제2 인코더에 입력하여 상기 공유 임베딩 스페이스에 제2 특징을 추출하는 단계;상기 제2 추가 입력 데이터를 상기 제2 인코더에 입력하여 상기 공유 임베딩 스페이스에 제2 추가 특징을 추출하는 단계;상기 제1 특징, 상기 제2 특징 및 상기 제2 추가 특징에 기초하여 제1 손실 함수를 결정하는 단계;상기 제2 특징 및 상기 제2 추가 특징에 기초하여 제2 손실 함수를 결정하는 단계; 및상기 제1 손실 함수 및 상기 제2 손실 함수에 기초하여 상기 제2 인코더의 가중치(weight)를 업데이트하는 단계를 포함하는객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 손실 함수를 결정하는 단계는상기 제1 특징과 상기 제2 특징 및 상기 제2 추가 특징 사이의 제1 긍정/부정 쌍(positive/negative pair) 정보를 획득하는 단계; 및상기 제1 긍정/부정 쌍 정보에 기초하여 상기 제1 손실 함수를 결정하는 단계를 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제1 긍정/부정 쌍 정보를 획득하는 단계는상기 제1 특징과 상기 제2 특징 및 상기 제2 추가 특징 사이의 유사도를 획득하는 단계; 및상기 유사도에 기초하여 상기 제1 긍정/부정 쌍 정보를 획득하는 단계를 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 제1 긍정/부정 쌍 정보를 획득하는 단계는상기 제1 특징, 상기 제2 특징 및 상기 제2 추가 특징 각각에 대응하는 클래스 정보를 획득하는 단계; 및상기 클래스 정보에 기초하여 상기 제1 긍정/부정 쌍 정보를 획득하는 단계를 포함하는객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 제2 손실 함수를 결정하는 단계는상기 제2 특징과 상기 제2 추가 특징 사이의 제2 긍정/부정 쌍 정보를 획득하는 단계; 및상기 제2 긍정/부정 쌍 정보에 기초하여 상기 제2 손실 함수를 결정하는 단계를 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 제2 긍정/부정 쌍 정보를 획득하는 단계는상기 제2 특징과 상기 제2 추가 특징 사이의 유사도를 획득하는 단계; 및상기 유사도에 기초하여 상기 제2 긍정/부정 쌍 정보를 획득하는 단계를 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 제1 손실 함수를 결정하는 단계는상기 제2 특징 및 상기 제2 추가 특징에 적용하기 위한 상기 제1 특징의 의미(semantic) 정보를 추출하는 상기 제1 손실 함수를 결정하는 단계를 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제2 손실 함수를 결정하는 단계는상기 제1 특징에 포함된 노이즈(noise)를 억제하는 상기 제2 손실 함수를 결정하는, 객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 입력 데이터는상기 대상 객체에 관한 이미지를 포함하고,상기 제1 입력 데이터에 대하여 데이터 증강을 수행하여 제1 추가 입력 데이터를 획득하는 단계를 더 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제1 추가 입력 데이터를 획득하는 단계는상기 제1 입력 데이터에 대하여 랜덤 파라미터 왜곡(Random Parameter Distortion, RPD)을 적용하는 단계를 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 랜덤 파라미터 왜곡은상기 이미지의 스케일, 파라미터 및 바운딩 박스(bounding box) 중 적어도 하나 이상을 임의로 변형하는 방법을 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 제2 입력 데이터는상기 대상 객체에 관한 라이다 포인트 세트(LiDAR point set)를 포함하고,제2 추가 입력 데이터를 획득하는 단계는상기 제2 입력 데이터에 대하여 RPS(Random Point Sparsity)를 적용하여 상기 제2 추가 입력 데이터를 획득하는 단계를 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 RPS는상기 라이다 포인트 세트에 보간법(interpolation)을 적용하는 방법을 포함하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>14. 대상 객체에 관한 제1 입력 데이터 및 제2 입력 데이터를 획득하고, 상기 제2 입력 데이터에 대하여 데이터 증강을 수행하여 제2 추가 입력 데이터를 획득하는 데이터 증강 모듈;상기 제1 입력 데이터에서 공유 임베딩 스페이스에 제1 특징(feature)을 추출하고, 상기 제2 입력 데이터에서 상기 공유 임베딩 스페이스에 제2 특징을 추출하고, 상기 제2 추가 입력 데이터에서 상기 공유 임베딩 스페이스에 제2 추가 특징을 추출하는 인코딩 모듈; 및상기 제1 특징, 상기 제2 특징 및 상기 제2 추가 특징에 기초하여 제1 손실 함수를 결정하고, 상기 제2 특징 및 상기 제2 추가 특징에 기초하여 제2 손실 함수를 결정하고, 상기 제1 손실 함수 및 상기 제2 손실 함수에 기초하여 상기 제2 인코더의 가중치(weight)를 업데이트하는 크로스 모달 대조 학습 모듈을 포함하는, 객체 인식기 학습 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 크로스 모달 대조 학습 모듈은상기 제1 특징과 상기 제2 특징 및 상기 제2 추가 특징 사이의 제1 긍정/부정 쌍(positive/negative pair) 정보를 획득하고,상기 제1 긍정/부정 쌍 정보에 기초하여 상기 제1 손실 함수를 결정하는,객체 인식기 학습 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 크로스 모달 대조 학습 모듈은상기 제1 특징과 상기 제2 특징 및 상기 제2 추가 특징 사이의 유사도를 획득하고,상기 유사도에 기초하여 상기 제1 긍정/부정 쌍 정보를 획득하는,객체 인식기 학습 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 크로스 모달 대조 학습 모듈은상기 제1 특징, 상기 제2 특징 및 상기 제2 추가 특징 각각에 대응하는 클래스 정보를 획득하고,상기 클래스 정보에 기초하여 상기 제1 긍정/부정 쌍 정보를 획득하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>18. 제14항에 있어서,상기 크로스 모달 대조 학습 모듈은상기 제2 특징과 상기 제2 추가 특징 사이의 제2 긍정/부정 쌍 정보를 획득하고,상기 제2 긍정/부정 쌍 정보에 기초하여 상기 제2 손실 함수를 결정하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 크로스 모달 대조 학습 모듈은상기 제2 특징과 상기 제2 추가 특징 사이의 유사도를 획득하고,상기 유사도에 기초하여 상기 제2 긍정/부정 쌍 정보를 획득하는,객체 인식기 학습 방법.</claim></claimInfo><claimInfo><claim>20. 대상 객체에 관한 타겟 라이다 포인트 세트(LiDAR point set)를 센싱하는 라이다 센서; 및프로세서를 포함하고,상기 프로세서는상기 타겟 라이다 포인트 세트를 인공 신경망 모델에 입력하여, 상기 대상 객체에 대응하는 특징 벡터를 획득하고,상기 특징 벡터를 상기 인공 신경망 모델의 디텍션 헤드(detection head)에 입력하여 상기 대상 객체를 추정하고,상기 인공 신경망 모델은상기 타겟 라이다 포인트 세트와 상이한 도메인을 갖는 소스 라이다 포인트 세트와 이미지 데이터에 기초하여 학습되는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo><applicantInfo><address>서울특별시 성북구...</address><code>220040170680</code><country>대한민국</country><engName>Korea University Research and Business Foundation</engName><name>고려대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 화성...</address><code>420210366401</code><country>대한민국</country><engName>JANG, Sujin</engName><name>장수진</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM Sang Pil</engName><name>김상필</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM Jin Kyu</engName><name>김진규</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>ROH Won Seok</engName><name>노원석</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>CHANG Gyu Sam</engName><name>장규삼</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170730324</code><country>대한민국</country><engName>LEE, Dong Wook</engName><name>이동욱</name></inventorInfo><inventorInfo><address>경기도 화성...</address><code>420170728003</code><country>대한민국</country><engName>JI, DAEHYUN</engName><name>지대현</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.11.07</priorityApplicationDate><priorityApplicationNumber>1020220147333</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.01.16</receiptDate><receiptNumber>1-1-2023-0057084-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230006147.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936ce9252219f791d09aa8a931c3e623651f8e27f9d5d6ed39fd81112e0bc78ddca12eb5c9fc7b4cf507a4311f889adbefedf858f948a9b8be</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf92fabec18568e917100f3e8836726248b7a5294988811016059eff5ab25b7f1ffdf39d2404aab77c5e710d3807039d655847d2368ba70275</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>