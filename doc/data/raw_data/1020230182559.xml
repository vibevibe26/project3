<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:23.1023</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0182559</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전자 장치 및 전자 장치의 동작 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE AND OPERATING METHOD THEREOF</inventionTitleEng><openDate>2025.04.29</openDate><openNumber>10-2025-0057964</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0484</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 3D 모델을 이용하여 2D 이미지를 편집하는 전자 장치를 개시한다. 전자 장치는 제1 피사체와 배경을 포함하는 입력 2D 이미지를 식별하고, 입력 2D 이미지를 제1 피사체를 포함하는 제1 피사체 이미지와 배경을 포함하는 제1 배경 이미지로 분리하고, 제1 피사체에 대한 3D 모델을 이용하여 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하고, 제1 배경 이미지 내의 피사체 제외 영역 또는 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에 대한 이미지 처리를 수행함으로써 변경된 배경을 포함하는 제2 배경 이미지를 생성하고, 제2 피사체 이미지와 제2 배경 이미지를 합성하여 출력 2D 이미지를 생성하도록 설정될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치(101)에 있어서,메모리(130); 및프로세서(120)를 포함하며, 상기 프로세서(120)는:제1 피사체(subject)와 배경(background)을 포함하는 입력 2차원(2D) 이미지를 식별하고,상기 입력 2D 이미지를 상기 제1 피사체를 포함하는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)하고,상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하고,상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성하고, 상기 확장 영역은 상기 제1 피사체의 변경과 연관되며,상기 제2 피사체 이미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 프로세서(120)는: 상기 제1 피사체 이미지에 기초하여, 상기 제1 피사체에 대한 이미 생성된 3D 모델을 변형(deform)시키고,상기 변형된 3D 모델을 상기 제1 피사체에 대한 상기 3D 모델로 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 상기 변경된 제1 피사체를 포함하는 상기 제2 피사체 이미지를 생성하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 제1 배경 이미지 내의 상기 피사체 제외 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 피사체 제외 영역에 배경을 추가하기 위한 인-페인팅(in-painting) 처리를 포함하는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 프로세서(120)는:상기 제1 피사체를 이동(translation)시키기 위한 사용자 입력을 획득하고,상기 사용자 입력이 획득되는 것에 응답하여, 상기 3D 모델을 이용하여 상기 위치 및 상기 방향을 변경하기 위한 이미지 처리를 수행함으로써, 상기 위치 및 상기 방향이 변경된 제1 피사체를 포함하는 상기 제2 피사체 이미지를 생성하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 제1 배경 이미지 외부의 상기 확장 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 변경된 제1 피사체의 위치와 연관된 확장 영역에 배경을 추가하기 위한 아웃-페인팅(out-painting) 처리를 포함하는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 프로세서(120)는:상기 전자 장치(101)의 내부 저장 장치 또는 상기 전자 장치(101)에 연결된 외부 저장 장치 중 적어도 하나로부터 2D 이미지들을 획득하고,상기 2D 이미지들에 기초하여, 3D 모델이 생성될 적어도 하나의 피사체를 식별하고, 상기 적어도 하나의 피사체는 상기 제1 피사체를 포함하고,상기 2D 이미지들을 상기 식별된 피사체 별로 클러스터링하고,상기 제1 피사체의 클러스터에 속하는 2D 이미지들에서 상기 제1 피사체와 상기 배경을 분리함으로써, 상기 배경이 제외된 상기 제1 피사체를 포함하는 2D 이미지들을 획득하고,상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 상기 제1 피사체에 대한 상기 3D 모델을 생성하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들은, 제1 시점부터 상기 제1 시점 이후의 제2 시점까지의 2D 이미지들에 해당하고,상기 프로세서는: 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들에 포함된 시간 정보를 이용하여, 상기 제1 시점에서 상기 제2 시점까지의 기간을 식별하고, 상기 제1 시점에서 상기 제2 시점까지의 기간을 복수의 시간 구간으로 나누고,각 시간 구간에 속하는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 시간 구간 별로 상기 제1 피사체에 대한 3D 모델을 각각 생성하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 프로세서는:상기 시간 구간 별로 생성된 상기 제1 피사체에 대한 복수의 3D 모델 간의 3D 특징점을 매칭함으로써, 상기 제1 피사체의 시간에 따라 변화하는 모습을 3차원으로 제공하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 프로세서는:상기 제1 피사체에 대한 상기 3D 모델의 완성도가 임계 값을 만족하는지 여부를 식별하고,상기 3D 모델의 완성도가 임계 값 미만인 것으로 식별되는 경우, 상기 3D 모델의 완성도를 높이기 위하여 상기 제1 피사체에 대한 추가 2D 이미지의 획득을 위한 촬영 가이드를 사용자에게 제공하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 프로세서는:상기 제1 피사체에 대한 상기 3D 모델을 디스플레이 상에 표시하고, 상기 3D 모델의 상기 완성도와 연관된 사용자 입력을 수신하고,상기 사용자 입력에 기초하여 상기 3D 모델의 완성도가 미리 설정된 기준을 만족하는지 여부를 식별하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 프로세서는:상기 제1 피사체에 대한 적어도 하나의 추가 2D 이미지가 획득되는 것에 기초하여, 상기 제1 피사체에 대한 상기 3D 모델을 업데이트 하도록 설정되는, 전자 장치(101).</claim></claimInfo><claimInfo><claim>12. 전자 장치(101)의 방법에 있어서,제1 피사체(subject)와 배경(background)을 포함하는 입력 2차원(2D) 이미지를 식별하는 동작;상기 입력 2D 이미지를 상기 제1 피사체를 포함하는 제1 피사체 이미지와 상기 배경을 포함하는 제1 배경 이미지로 분리(separate)하는 동작;상기 제1 피사체에 대한 3차원(3D) 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작;상기 제1 배경 이미지 내의 피사체 제외 영역 또는 상기 제1 배경 이미지 외부의 확장 영역 중 적어도 하나에 대한 이미지 처리를 수행함으로써, 변경된 배경을 포함하는 제2 배경 이미지를 생성하는 동작, 상기 확장 영역은 상기 제1 피사체의 변경과 연관되며; 및상기 제2 피사체 이미지와 상기 제2 배경 이미지를 합성하여, 출력 2D 이미지를 생성하도록 설정되는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 방법은:상기 제1 피사체 이미지에 기초하여, 상기 제1 피사체에 대한 이미 생성된 3D 모델을 변형(deform)시키는 동작을 더 포함하고,상기 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작은: 상기 변형된 3D 모델을 이용하여 상기 제1 피사체의 크기, 위치 또는 방향 중 적어도 하나를 변경하기 위한 이미지 처리를 수행함으로써, 상기 변경된 제1 피사체를 포함하는 상기 제2 피사체 이미지를 생성하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제12항 또는 제13항에 있어서, 상기 제1 배경 이미지 내의 상기 피사체 제외 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 피사체 제외 영역에 배경을 추가하기 위한 인-페인팅(in-painting) 처리를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제12항 내지 제14항 중 어느 한 항에 있어서, 상기 방법은:상기 제1 피사체를 이동(translation)시키기 위한 사용자 입력을 획득하는 동작; 및상기 사용자 입력이 획득되는 것에 응답하여, 상기 3D 모델을 이용하여 상기 위치 및 상기 방향을 변경하기 위한 이미지 처리를 수행함으로써, 상기 위치 및 상기 방향이 변경된 제1 피사체를 포함하는 제2 피사체 이미지를 생성하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제12항 내지 제15항 중 어느 한 항에 있어서, 상기 제1 배경 이미지 외부의 상기 확장 영역에 대한 이미지 처리는, 상기 제1 배경 이미지에 포함된 정보를 기초로 상기 변경된 피사체의 위치와 연관된 확장 영역에 배경을 추가하기 위한 아웃-페인팅(out-painting) 처리를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제12항 내지 제16항 중 어느 한 항에 있어서, 상기 방법은:상기 전자 장치(101)의 내부 저장 장치 또는 상기 전자 장치(101)에 연결된 외부 저장 장치 중 적어도 하나로부터 2D 이미지들을 획득하는 동작;상기 2D 이미지들에 기초하여, 3D 모델이 생성될 적어도 하나의 피사체를 식별하는 동작, 상기 적어도 하나의 피사체는 상기 제1 피사체를 포함하고;상기 2D 이미지들을 상기 식별된 피사체 별로 클러스터링하는 동작; 및상기 제1 피사체의 클러스터에 속하는 2D 이미지들에서 상기 제1 피사체와 상기 배경을 분리함으로써, 상기 배경이 제외된 상기 제1 피사체를 포함하는 2D 이미지들을 획득하는 동작; 및상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 상기 제1 피사체에 대한 상기 3D 모델을 생성하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제12항 내지 제17항 중 어느 한 항에 있어서,상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들은, 제1 시점부터 상기 제1 시점 이후의 제2 시점까지의 2D 이미지들에 해당하고,상기 방법은: 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들에 포함된 시간 정보를 이용하여, 상기 제1 시점에서 상기 제2 시점까지의 기간을 식별하는 동작;상기 제1 시점에서 상기 제2 시점까지의 기간을 복수의 시간 구간으로 나누는 동작; 및각 시간 구간에 속하는 상기 배경이 제외된 제1 피사체를 포함하는 2D 이미지들을 이용하여, 시간 구간 별로 상기 제1 피사체에 대한 3D 모델을 각각 생성하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제12항 내지 제18항 중 어느 한 항에 있어서, 상기 방법은:상기 시간 구간 별로 생성된 상기 제1 피사체에 대한 복수의 3D 모델 간의 3D 특징점을 매칭함으로써, 상기 제1 피사체의 시간에 따라 변화하는 모습을 3차원으로 제공하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제12항 내지 제19항 중 어느 한 항에 있어서, 상기 방법은:상기 제1 피사체에 대한 상기 3D 모델의 완성도가 임계 값을 만족하는지 여부를 식별하는 동작; 및상기 3D 모델의 완성도가 임계 값 미만인 것으로 식별되는 경우, 상기 3D 모델의 완성도를 높이기 위하여 상기 제1 피사체에 대한 추가 2D 이미지의 획득을 위한 촬영 가이드를 사용자에게 제공하는 동작을 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Sungtae</engName><name>김성태</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>MUN, Jihun</engName><name>문지훈</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Jiyoon</engName><name>박지윤</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YOO, Nagyeom</engName><name>유나겸</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HYUN, Daeyoung</engName><name>현대영</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 강남대로*길 **, *층(양재동)</address><code>920201001816</code><country>대한민국</country><engName>PENTAS INTELLECTUAL PROPERTY LAW FIRM</engName><name>특허법인펜타스</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.10.21</priorityApplicationDate><priorityApplicationNumber>1020230141592</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.15</receiptDate><receiptNumber>1-1-2023-1406862-51</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230182559.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c38f4be1cc5394474b0d9059fc65d535e2bf8ac787f5b0134fdbccaa8a65b732857abf80d02d318497ad934d2b7bc5736db206b9a66a5fa8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd9dac0fa2f848056e980da5174ecc6d16194279ee6ab828b3e90610c328194ccfd33e2f90d795fa253b94d679a675d1825053e2511b158a6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>