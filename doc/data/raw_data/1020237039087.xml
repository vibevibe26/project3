<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:34.4034</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.05.12</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7039087</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>기계 학습 모델을 사용한 시각적 쇠약 지수 결정</inventionTitle><inventionTitleEng>DETERMINING VISUAL FRAILTY INDEX USING MACHINE LEARNING MODELS</inventionTitleEng><openDate>2024.01.15</openDate><openNumber>10-2024-0006558</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.05.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.11.13</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2025.01.01)</ipcDate><ipcNumber>A61B 5/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 50/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G16H 30/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본원에 기술된 시스템 및 방법은 객체의 비디오 데이터를 처리함으로써 시각적 쇠약 점수를 결정하기 위한 기술을 제공한다. 척추 이동성 특징, 보행 측정, 행동 특징, 및 체성분 데이터를 포함하지만 이에 한정되지 않는, 다양한 특징이 시각적 쇠약 점수를 결정하는 데 사용될 수 있다. 다양한 특징은 상이한 기술을 사용하여 비디오 데이터로부터 추출될 수 있다. 다양한 특징은 시각적 쇠약 점수를 결정하기 위해 하나 이상의 기계 학습 모델을 사용하여 처리될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.11.17</internationOpenDate><internationOpenNumber>WO2022241112</internationOpenNumber><internationalApplicationDate>2022.05.12</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/028986</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 구현 방법으로서,객체의 움직임을 캡처한 비디오를 나타내는 비디오 데이터를 수신하는 단계;상기 비디오 데이터를 사용하여, 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하는 단계; 및적어도 하나의 기계 학습 모델을 사용하여, 적어도 상기 척추 이동성 특징을 처리하여 상기 객체에 대한 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하는 단계는:복수의 척추 측정치를 결정하되, 상기 복수의 척추 측정치의 각각의 척추 측정치는 상기 비디오 데이터의 하나의 비디오 프레임에 해당하는 단계; 및상기 복수의 척추 측정치를 사용하여 상기 척추 이동성 특징을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하는 단계는:상기 비디오 데이터의 각각의 비디오 프레임에 대해:상기 객체의 머리와 상기 객체의 꼬리 사이의 제1 거리를 결정하는 단계;상기 머리와 상기 꼬리 사이의 중간 지점과 상기 객체의 등 중간 사이의 제2 거리를 결정하는 단계;상기 객체의 머리, 꼬리 및 등 중간 사이에 형성된 각도를 결정하는 단계; 및상기 제1 거리, 상기 제2 거리 및 상기 각도를 포함하는 비디오 프레임에 대한 상기 척추 이동성 특징을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하는 단계는:상기 비디오 데이터의 각각의 비디오 프레임에 대해, 상기 객체의 머리와 상기 객체의 꼬리 사이의 중간 지점과 상기 객체의 등 중간 사이의 거리를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 추가로:적어도 추가 기계 학습 모델을 사용하여, 상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 적어도 상기 객체의 머리, 상기 객체의 꼬리, 및 상기 객체의 등 중간의 위치를 추적하는 포즈 추정 데이터를 결정하는 단계; 및상기 포즈 추정 데이터를 사용하여 상기 척추 이동성 특징을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 적어도 12개의 신체 부위의 위치를 추적하는 포즈 추정 데이터를 결정하는 단계;상기 포즈 추정 데이터를 사용하여, 상기 객체에 대한 특징을 결정하는 단계; 및상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 특징을 처리하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 추가로:상기 객체에 대한 신체 특징을 결정하되, 상기 신체 특징은 상기 객체의 길이, 상기 객체의 폭, 및 상기 객체의 뒷발 사이의 거리 중 적어도 하나에 해당하는 단계;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 신체 특징을 처리하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 추가로:상기 비디오의 지속시간 동안 후족립(rearing) 이벤트가 발생하는 횟수를 결정하는 단계;각각의 후족립 이벤트에 대한 후족립 길이를 결정하는 단계;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 후족립 이벤트가 발생하는 횟수 및 각각의 후족립 이벤트에 대한 상기 후족립 길이를 처리하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 추가로:상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 비디오 데이터를 처리하여 상기 비디오의 지속시간 동안 상기 객체에 대한 타원 정합 데이터를 결정하는 단계;상기 타원 정합 데이터를 사용하여, 상기 객체에 대한 특징을 결정하는 단계; 및 상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 특징을 처리하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하는 단계는:상기 객체에 의한 보행 움직임을 나타내는 제1 비디오 프레임 세트를 결정하는 단계;상기 제1 비디오 프레임 세트에 대한 제1 척추 이동성 특징 세트를 결정하는 단계;상기 객체에 의한 비보행 움직임을 나타내는 제2 비디오 프레임 세트를 결정하는 단계; 및상기 제2 비디오 프레임 세트에 대한 제2 척추 이동성 특징 세트를 결정하는 단계를 포함하고;상기 척추 이동성 특징은 상기 제1 척추 이동성 특징 세트 및 상기 제2 척추 이동성 특징 세트를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 제1 척추 이동성 특징 세트는 상기 객체의 머리와 꼬리 사이의 중간 지점과 상기 객체의 등 중간 사이의 거리에 해당하고, 상기 제2 척추 이동성 특징 세트는 상기 객체의 머리, 꼬리 및 등 중간 사이에 형성된 각도에 해당하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 추가로:상기 비디오 데이터를 사용하여, 상기 비디오의 지속시간 동안 상기 객체의 보행 측정치를 결정하는 단계; 및상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 보행 특징을 처리하여 상기 객체에 대한 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계;상기 포인트 데이터를 사용하여, 상기 비디오 데이터에 나타난 복수의 입각기 및 복수의 유각기를 결정하는 단계;상기 복수의 입각기 및 상기 복수의 유각기에 기초하여, 상기 비디오 데이터에 나타난 복수의 활보 간격을 결정하는 단계; 및상기 포인트 데이터를 사용하여, 상기 복수의 활보 간격 중 각각의 활보 간격에 기초하여 상기 보행 측정치를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 추가로:상기 객체의 좌측 뒷발 또는 상기 객체의 우측 뒷발의 발끝 이벤트에 기초하여 상기 복수의 입각기의 제1 입각기 및 상기 복수의 유각기의 제1 유각기로부터 제1 전이를 결정하는 단계;상기 좌측 뒷발 또는 상기 우측 뒷발의 발 구름 이벤트에 기초하여 상기 복수의 유각기 중 제2 유각기로부터 상기 복수의 입각기 중 제2 입각기로의 제2 전이를 결정하는 단계; 및상기 제1 전이 및 상기 제2 전이를 사용하여 상기 보행 측정치를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 좌측 뒷발 및 우측 뒷발을 포함하고, 상기 보행 측정치를 결정하는 단계는:상기 포인트 데이터를 사용하여, 활보 간격에 대한 걸음 길이를 결정하되, 상기 걸음 길이는 상기 우측 뒷발이 이전의 좌측 뒷발 구름을 지나 이동하는 거리를 나타내는 단계; 상기 포인트 데이터를 사용하여, 상기 활보 간격을 위해 사용한 활보 길이를 결정하되, 상기 활보 길이는 상기 각 활보 간격 동안 상기 좌측 뒷발이 이동하는 거리를 나타내는 단계;상기 포인트 데이터를 사용하여, 상기 활보 간격에 대한 걸음 폭을 결정하되, 상기 걸음 폭은 상기 좌측 뒷발과 상기 우측 뒷발 사이의 거리를 나타내는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 꼬리 기부를 포함하고,상기 보행 측정치를 결정하는 단계는, 상기 포인트 데이터를 사용하여, 활보 간격 동안 상기 꼬리 기부의 움직임에 기초하여 상기 객체의 속도 데이터를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 꼬리 기부를 포함하고,상기 보행 측정치를 결정하는 단계는:상기 포인트 데이터를 사용하여, 상기 복수의 활보 간격 중 하나의 활보 간격을 나타내는 프레임 세트 동안 상기 꼬리 기부의 움직임에 기초하여 상기 객체의 속도 데이터 세트를 결정하는 단계; 및상기 속도 데이터 세트를 평균하여, 상기 활보 간격 동안 활보 속도를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 우측 뒷발 및 좌측 뒷발을 포함하고,상기 보행 측정치를 결정하는 단계는:상기 포인트 데이터를 사용하여, 상기 우측 뒷발이 활보 간격 동안 지면과 접촉하는 시간의 양을 나타내는 제1 입각 지속시간을 결정하는 단계;상기 제1 입각 지속시간 및 상기 활보 간격의 지속시간에 기초하여 제1 충격 계수를 결정하는 단계;상기 포인트 데이터를 사용하여, 상기 좌측 뒷발이 상기 활보 간격 동안 지면과 접촉하는 시간의 양을 나타내는 제2 입각 지속시간을 결정하는 단계;상기 제2 입각 지속시간 및 상기 활보 간격의 지속시간에 기초하여 제2 충격 계수를 결정하는 단계; 및상기 제1 충격 계수 및 상기 제2 충격 계수에 기초하여 상기 활보 간격에 대한 평균 충격 계수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>19. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 꼬리 기부 및 목 기부를 포함하고,상기 보행 측정치를 결정하는 단계는:상기 포인트 데이터를 사용하여, 상기 복수의 활보 간격 중 하나의 활보 간격을 나타내는 프레임 세트 동안 상기 꼬리 기부와 상기 목 기부를 연결하는 벡터 세트를 결정하는 단계; 및상기 벡터 세트를 사용하여, 상기 활보 간격에 대한 상기 객체의 각속도를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>20. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 상기 객체의 척추 중심을 포함하고,활보 간격은 상기 비디오 데이터의 프레임 세트와 연관되고,상기 보행 측정치를 결정하는 단계는, 상기 포인트 데이터를 사용하여, 상기 활보 간격에 대한 변위 벡터를 결정하되, 상기 변위 벡터는 상기 프레임 세트의 제1 프레임에 표시된 상기 척추 중심과 상기 프레임 세트의 마지막 프레임에 표시된 상기 척추 중심을 연결하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 신체 부위 세트는 상기 객체의 코를 추가로 포함하고, 상기 메트릭 데이터를 결정하는 단계는:상기 포인트 데이터를 사용하여, 상기 프레임 세트 내의 각 프레임에 대한 상기 변위 벡터로부터 상기 코의 수직 거리에 기초하여 상기 활보 간격에 대한 상기 코의 측방향 변위 세트를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 코의 측방향 변위는 추가로 상기 객체의 신체 길이에 기초하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>23. 제21항에 있어서, 상기 보행 측정치를 결정하는 단계는 추가로:상기 코의 측방향 변위 세트를 사용하여 보간을 수행하여 상기 활보 간격에 대한 상기 코의 매끄러운 곡선 측방향 변위를 생성하고;상기 코의 매끄러운 곡선 측방향 변위를 사용하여, 상기 활보 간격 동안 상기 코의 최대 변위가 언제 발생하는지 결정하고;상기 코의 최대 변위가 발생할 때에 완료된 상기 활보 간격의 백분율을 나타내는 백분율 활보 위치를 결정함으로써, 꼬리 끝 변위 위상 오프셋을 결정하게 하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>24. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 추가로 상기 객체의 꼬리 기부를 포함하고,상기 보행 측정치를 결정하는 단계는, 상기 포인트 데이터를 사용하여, 상기 프레임 세트 내의 각 프레임에 대한 상기 변위 벡터로부터 상기 꼬리 기부의 수직 거리에 기초하여 상기 활보 간격에 대한 상기 꼬리 기부의 측방향 변위 세트를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 보행 측정치를 결정하는 단계는 추가로:상기 꼬리 기부의 측방향 변위 세트를 사용하여 보간을 수행하여 상기 활보 간격에 대한 상기 꼬리 기부의 매끄러운 곡선 측방향 변위를 생성하고;상기 꼬리 기부의 매끄러운 곡선 측방향 변위를 사용하여, 상기 활보 간격 동안 상기 꼬리 기부의 최대 변위가 언제 발생하는지 결정하고;상기 꼬리 기부의 최대 변위가 발생할 때 완료되는 상기 활보 간격의 백분율을 나타내는 백분율 활보 위치를 결정함으로써, 꼬리 기부 변위 위상 오프셋을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>26. 제12항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하는 단계를 포함하되, 상기 신체 부위 세트는 상기 객체의 꼬리 끝을 포함하고,상기 보행 측정치를 결정하는 단계는:상기 포인트 데이터를 사용하여, 상기 프레임 세트 내의 각 프레임에 대한 상기 변위 벡터로부터 상기 꼬리 끝의 수직 거리에 기초하여 상기 활보 간격에 대한 상기 꼬리 끝의 측방향 변위 세트를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 보행 측정치를 결정하는 단계는 추가로:상기 꼬리 끝의 측방향 변위 세트를 사용하여 보간을 수행하여 상기 활보 간격에 대한 상기 꼬리 끝의 매끄러운 곡선 측방향 변위를 생성하고;상기 꼬리 끝의 매끄러운 곡선 측방향 변위를 사용하여, 상기 활보 간격 동안 상기 꼬리 끝의 최대 변위가 언제 발생하는지 결정하고;상기 꼬리 끝의 최대 변위가 발생할 때 완료되는 상기 활보 간격의 백분율을 나타내는 백분율 활보 위치를 결정함으로써, 꼬리 끝 변위 위상 오프셋을 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>28. 제1항에 있어서, 추가로:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하되, 상기 신체 부위 세트는: 상기 코, 목 기부, 중간 척추, 좌측 뒷발, 우측 뒷발, 꼬리 기부, 꼬리 중간 및 꼬리 끝 중 하나 이상을 포함하는 단계;상기 포인트 데이터를 사용하여, 상기 객체에 대한 특징을 결정하는 단계; 및상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 특징을 처리하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>29. 제1항에 있어서, 추가로:추가 기계 학습 모델을 사용하여 상기 비디오 데이터를 처리하여, 상기 객체가 상기 비디오 데이터의 복수의 비디오 프레임 동안 그루밍 행동을 나타낼 가능성을 식별하는 단계; 및상기 객체가 상기 그루밍 행동을 나타낼 가능성을 사용하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>30. 제1항에 있어서, 추가로:추가 기계 학습 모델을 사용하여 상기 비디오 데이터를 처리하여, 상기 객체가 상기 비디오 데이터의 복수의 비디오 프레임 동안 소정의 행동을 나타낼 가능성을 식별하는 단계; 및상기 객체가 상기 소정의 행동을 나타낼 가능성을 사용하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>31. 제1항에 있어서, 추가로:상기 비디오 데이터의 제1 비디오 프레임 세트를 회전시킴으로써 회전된 비디오 프레임 세트를 결정하는 단계;상기 객체가 소정의 행동 동작을 나타낼 가능성을 식별하도록 구성된 제1 기계 학습 모델을 사용하여 상기 제1 비디오 프레임 세트를 처리하는 단계;상기 제1 기계 학습 모델에 의한 상기 제1 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제1 비디오 프레임 세트의 제1 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제1 확률을 결정하되, 상기 제1 비디오 프레임은 상기 비디오 데이터의 제1 지속시간에 해당하는 단계;상기 제1 기계 학습 모델을 사용하여 상기 회전된 프레임 세트를 처리하는 단계;상기 제1 기계 학습 모델에 의한 상기 회전된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 회전된 비디오 프레임 세트의 제2 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제2 확률을 결정하되, 상기 제2 비디오 프레임은 상기 비디오 데이터의 제1 지속시간에 해당하는 단계; 및상기 제1 확률 및 상기 제2 확률을 사용하여, 상기 제1 비디오 프레임에 대한 제1 라벨을 식별하되, 상기 제1 라벨은 상기 객체가 상기 소정의 행동 동작을 나타냄을 표시하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서, 추가로:상기 객체가 상기 소정의 행동 동작을 나타낼 가능성을 식별하도록 구성된 제2 기계 학습 모델을 사용하여 상기 제1 비디오 프레임 세트를 처리하는 단계;상기 제2 기계 학습 모델에 의한 상기 제1 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제1 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제3 확률을 결정하는 단계;상기 제2 기계 학습 모델을 사용하여 상기 회전된 비디오 프레임 세트를 처리하는 단계;상기 제2 기계 학습 모델에 의한 상기 회전된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제2 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제4 확률을 결정하는 단계; 및상기 제1 확률, 상기 제2 확률, 상기 제3 확률 및 상기 제4 확률을 사용하여 상기 제1 라벨을 식별하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>33. 제31항에 있어서, 추가로:상기 제1 비디오 프레임 세트를 반사하여 반사된 비디오 프레임 세트를 결정하는 단계;상기 제1 기계 학습 모델을 사용하여 상기 회전된 비디오 프레임 세트를 처리하는 단계;상기 제1 기계 학습 모델에 의한 상기 반사된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 반사된 프레임 세트의 제3 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제3 확률을 결정하되, 상기 제3 비디오 프레임은 상기 제1 비디오 프레임에 해당하는 단계; 및상기 제1 확률, 상기 제2 확률, 및 상기 제3 확률을 사용하여 상기 제1 라벨을 식별하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>34. 제31항에 있어서, 상기 객체는 마우스이고, 상기 소정의 행동은: 발 핥기, 한쪽 얼굴 씻기, 양쪽 얼굴 씻기, 및 옆구리 핥기 중 적어도 하나를 포함하는 그루밍 행동을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>35. 제31항에 있어서, 상기 제1 비디오 프레임 세트는 일정 기간 동안 상기 비디오 데이터의 일부를 나타내고, 상기 제1 비디오 프레임은 상기 기간의 마지막 시간 프레임인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>36. 제31항에 있어서, 추가로:상기 비디오 데이터로부터 제2 비디오 프레임 세트를 식별하는 단계;상기 제2 비디오 프레임 세트를 회전시켜 제2 회전된 비디오 프레임 세트를 결정하는 단계;상기 제1 기계 학습 모델을 사용하여 상기 제2 비디오 프레임 세트를 처리하는 단계;상기 제1 기계 학습 모델에 의한 상기 제2 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제2 비디오 프레임 세트의 제3 프레임에서 상기 소정의 행동 동작을 나타낼 제3 확률을 결정하는 단계;상기 제1 기계 학습 모델을 사용하여 상기 제2 회전된 비디오 프레임 세트를 처리하는 단계;상기 제1 기계 학습 모델에 의한 상기 제2 회전된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 회전된 프레임 세트의 제4 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제4 확률을 결정하되, 상기 제4 비디오 프레임은 상기 제3 비디오 프레임에 해당하는 단계; 및상기 제3 확률 및 상기 제4 확률을 사용하여, 상기 제3 프레임에 대한 제2 라벨을 식별하되, 상기 제2 라벨은 상기 객체가 상기 소정의 행동 동작을 나타냄을 표시하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>37. 제31항에 있어서, 상기 제1 기계 학습 모델은 기계 학습 분류기인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>38. 제1항에 있어서, 추가로:상기 비디오 데이터를 처리하여 상기 비디오의 지속시간 동안 상기 객체에 대한 보행 측정치를 결정하는 단계;상기 비디오 데이터를 처리하여 상기 객체가 소정의 행동을 나타내는 상기 비디오의 일부를 식별하는 행동 데이터를 결정하는 단계; 및상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 척추 이동성 특징, 상기 보행 측정치 및 상기 행동 데이터를 처리하여 상기 시각적 쇠약 점수를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>39. 제1항에 있어서, 상기 비디오는 개방 필드 영역에서 상기 객체의 움직임을 캡처하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>40. 제1항에 있어서, 추가로:상기 시각적 쇠약 점수를 사용하여 상기 객체의 신체 병태를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>41. 제40항에 있어서, 상기 신체 병태는 쇠약한, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>42. 제40항에 있어서, 상기 신체 병태는 쇠약 전 병태인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>43. 제1항에 있어서, 상기 객체는 포유류이고, 선택적으로 마우스인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>44. 객체의 신체 병태를 평가하는 방법으로서, 제1항의 컴퓨터 구현 방법으로 상기 객체에 대한 시각적 쇠약 점수를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>45. 제44항에 있어서, 상기 신체 병태는 쇠약한, 방법.</claim></claimInfo><claimInfo><claim>46. 제44항에 있어서, 상기 신체 병태는 쇠약 전 병태인, 방법.</claim></claimInfo><claimInfo><claim>47. 제44항에 있어서, 상기 객체는 포유류이고, 선택적으로 마우스인, 방법.</claim></claimInfo><claimInfo><claim>48. 쇠약 병태에 대한 후보 화합물의 효과 존재를 결정하는 방법으로서,객체에 대한 제1 시각적 쇠약 점수를 획득하되, 상기 획득을 위한 수단은 제1항의 컴퓨터 구현 방법을 포함하고, 상기 객체는 쇠약 병태를 갖고 있거나 상기 쇠약 병태에 대한 동물 모델인 단계;상기 후보 화합물을 상기 객체에게 투여하는 단계;상기 객체에 대한 투여 후 시각적 쇠약 점수를 획득하는 단계;상기 제1 및 상기 투여 후 시각적 쇠약 점수를 비교하되, 상기 제1 및 투여 후 시각적 쇠약 점수의 차이는 상기 쇠약 병태에 대한 상기 후보 화합물의 효과를 식별하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>49. 제48항에 있어서, 쇠약이 덜함을 나타내는 상기 시각적 쇠약 점수의 개선은 쇠약 병태의 퇴행을 향상시키는 것으로 상기 후보 화합물을 식별하는, 방법.</claim></claimInfo><claimInfo><claim>50. 제48항에 있어서, 상기 제1 시각적 쇠약 점수와 통계적으로 동등한 투여 후 시각적 쇠약 점수는 상기 객체에서 상기 쇠약 병태의 진행을 억제하는 것으로 상기 후보 화합물을 식별하는, 방법.</claim></claimInfo><claimInfo><claim>51. 제48항에 있어서, 추가로 상기 쇠약 병태의 치료에 있어서 상기 화합물의 효과에 대한 추가 테스트하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>52. 제48항에 있어서, 상기 객체는 포유류이고, 선택적으로 마우스인, 방법.</claim></claimInfo><claimInfo><claim>53. 쇠약 병태에 대한 후보 화합물의 효과의 존재를 식별하는 방법으로서, 상기 방법은:상기 쇠약 병태를 가지고 있거나 상기 쇠약 병태에 대한 동물 모델인 객체에게 상기 후보 화합물을 투여하는 단계;상기 객체에 대한 시각적 쇠약 점수를 획득하되, 상기 획득을 위한 수단은 제1항의 컴퓨터 구현 방법을 포함하는 단계;상기 획득된 시각적 쇠약 점수를 대조군 시각적 쇠약 점수와 비교하되, 상기 획득된 시각적 쇠약 점수 및 상기 대조군 시각적 쇠약 점수의 차이는 상기 후보 화합물이 상기 쇠약 병태에 미치는 효과의 존재를 식별하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>54. 제53항에 있어서, 상기 대조군 쇠약 점수와 비교하여 상기 후보 화합물이 투여된 상기 객체에서 쇠약이 덜함을 나타내는 상기 시각적 쇠약 점수의 개선은 상기 객체에서 상기 쇠약 병태의 퇴행을 향상시키는 것으로 상기 후보 화합물을 식별하는, 방법.</claim></claimInfo><claimInfo><claim>55. 제53항에 있어서, 상기 대조군 쇠약 점수와 통계적으로 동등한 상기 후보 화합물을 투여한 상기 객체에서 획득된 시각적 쇠약 점수는 상기 객체에서 상기 쇠약 병태의 진행을 억제하는 것으로 상기 후보 화합물을 식별하는, 방법.</claim></claimInfo><claimInfo><claim>56. 제53항에 있어서, 상기 객체는 포유류이고, 선택적으로 마우스인, 방법.</claim></claimInfo><claimInfo><claim>57. 시스템으로서,적어도 하나의 프로세서; 및명령얼ㄹ 포함하는 적어도 하나의 메모리를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:객체의 움직임을 캡처한 비디오를 나타내는 비디오 데이터를 수신하게 하고;상기 비디오 데이터를 사용하여, 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하게 하고;적어도 하나의 기계 학습 모델을 사용하여, 적어도 상기 척추 이동성 특징을 처리하여 상기 객체에 대한 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>58. 제57항에 있어서, 상기 시스템으로 하여금 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금: 복수의 척추 측정치를 결정하게 하되, 상기 복수의 척추 측정치의 각각의 척추 측정치는 상기 비디오 데이터의 하나의 비디오 프레임에 해당하고;상기 복수의 척추 측정치를 사용하여 상기 척추 이동성 특징을 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>59. 제57항에 있어서, 상기 시스템으로 하여금 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금: 상기 비디오 데이터의 각각의 비디오 프레임에 대해:상기 객체의 머리와 상기 객체의 꼬리 사이의 제1 거리를 결정하게 하고;상기 머리와 상기 꼬리 사이의 중간 지점과 상기 객체의 등 중간 사이의 제2 거리를 결정하게 하고;상기 객체의 머리, 꼬리 및 등 중간 사이에 형성된 각도를 결정하게 하고;상기 제1 거리, 상기 제2 거리 및 상기 각도를 포함하는 비디오 프레임에 대한 상기 척추 이동성 특징을 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>60. 제57항에 있어서, 상기 시스템으로 하여금 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금:상기 비디오 데이터의 각각의 비디오 프레임에 대해, 상기 객체의 머리와 상기 객체의 꼬리 사이의 중간 지점과 상기 객체의 등 중간 사이의 거리를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>61. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 적어도 상기 객체의 머리, 상기 객체의 꼬리, 및 상기 객체의 등 중간의 위치를 추적하는 포즈 추정 데이터를 결정하게 하고;상기 포즈 추정 데이터를 사용하여 상기 척추 이동성 특징을 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>62. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 적어도 12개의 신체 부위의 위치를 추적하는 포즈 추정 데이터를 결정하게 하고;상기 포즈 추정 데이터를 사용하여, 상기 객체에 대한 특징을 결정하게 하고;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 특징을 처리하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>63. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 객체에 대한 신체 특징을 결정하게 하되, 상기 신체 특징은 상기 객체의 길이, 상기 객체의 폭, 및 상기 객체의 뒷발 사이의 거리 중 적어도 하나에 해당하고;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 신체 특징을 처리하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>64. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오의 지속시간 동안 후족립 이벤트가 발생하는 횟수를 결정하게 하고;각각의 후족립 이벤트에 대한 후족립 길이를 결정하게 하고;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 후족립 이벤트가 발생하는 횟수 및 각각의 후족립 이벤트에 대한 상기 후족립 길이를 처리하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>65. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:적어도 추가 기계 학습 모델을 사용하여, 상기 비디오 데이터를 처리하여 상기 비디오의 지속시간 동안 상기 객체에 대한 타원 정합 데이터를 결정하게 하고;상기 타원 정합 데이터를 사용하여, 상기 객체에 대한 특징을 결정하게 하고;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 특징을 처리하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>66. 제57항에 있어서, 상기 시스템으로 하여금 상기 비디오의 지속시간 동안 상기 객체의 척추 이동성 특징을 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금:상기 객체에 의한 보행 움직임을 나타내는 제1 비디오 프레임 세트를 결정하게 하고;상기 제1 비디오 프레임 세트에 대한 제1 척추 이동성 특징 세트를 결정하게 하고;상기 객체에 의한 비보행 움직임을 나타내는 제2 비디오 프레임 세트를 결정하게 하고;상기 제2 비디오 프레임 세트에 대한 제2 척추 이동성 특징 세트를 결정하게 하고;상기 척추 이동성 특징은 상기 제1 척추 이동성 특징 세트 및 상기 제2 척추 이동성 특징 세트를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>67. 제66항에 있어서, 상기 제1 척추 이동성 특징 세트는 상기 객체의 머리와 꼬리 사이의 중간 지점과 상기 객체의 등 중간 사이의 거리에 해당하고, 상기 제2 척추 이동성 특징 세트는 상기 객체의 머리, 꼬리 및 등 중간 사이에 형성된 각도에 해당하는, 시스템.</claim></claimInfo><claimInfo><claim>68. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 사용하여, 상기 비디오의 지속시간 동안 상기 객체의 보행 측정치를 결정하게 하고;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 보행 특징을 처리하여 상기 객체에 대한 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>69. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하고;상기 포인트 데이터를 사용하여, 상기 비디오 데이터에 나타난 복수의 입각기 및 복수의 유각기를 결정하게 하고;상기 복수의 입각기 및 상기 복수의 유각기에 기초하여, 상기 비디오 데이터에 표시되는 복수의 활보 간격을 결정하게 하고;상기 포인트 데이터를 사용하여, 상기 복수의 활보 간격 중 각각의 활보 간격에 기초하여 상기 보행 측정치를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>70. 제69항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 객체의 좌측 뒷발 또는 상기 객체의 우측 뒷발의 발끝 이벤트에 기초하여 상기 복수의 입각기의 제1 입각기 및 상기 복수의 유각기의 제1 유각기로부터 제1 전이를 결정하게 하고;상기 좌측 뒷발 또는 상기 우측 뒷발의 발 구름 이벤트에 기초하여 상기 복수의 유각기의 제2 유각기로부터 상기 복수의 입각기의 제2 입각기로의 제2 전이를 결정하게 하고;상기 제1 전이 및 상기 제2 전이를 사용하여 상기 보행 측정치를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>71. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 좌측 뒷발 및 우측 뒷발을 포함하고, 상기 보행 측정치를 결정하는 단계는:상기 포인트 데이터를 사용하여, 활보 간격에 대한 걸음 길이를 결정하게 하되, 상기 걸음 길이는 상기 우측 뒷발이 이전의 좌측 뒷발 구름을 지나 이동하는 거리를 나타내고; 상기 포인트 데이터를 사용하여, 상기 활보 간격에 대한 활보 길이를 결정하게 하되, 상기 활보 길이는 상기 각 활보 간격 동안 상기 좌측 뒷발이 이동하는 거리를 나타내고;상기 포인트 데이터를 사용하여, 상기 활보 간격에 대한 걸음 폭을 결정하게 하되, 상기 걸음 폭은 상기 좌측 뒷발과 상기 우측 뒷발 사이의 거리를 나타내는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>72. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 꼬리 기부를 포함하고,상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금, 상기 포인트 데이터를 사용하여, 활보 간격 동안 상기 꼬리 기부의 이동에 기초하여 상기 객체의 속도 데이터를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>73. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 꼬리 기부를 포함하고,상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금:상기 포인트 데이터를 사용하여, 상기 복수의 활보 간격 중 하나의 활보 간격을 나타내는 프레임 세트 동안 상기 꼬리 기부의 움직임에 기초하여 상기 객체의 속도 데이터 세트를 결정하게 하고;상기 속도 데이터 세트를 평균하여, 상기 활보 간격에 대한 활보 속도를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>74. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 우측 뒷발 및 좌측 뒷발을 포함하고,상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금:상기 포인트 데이터를 사용하여, 상기 우측 뒷발이 활보 간격 동안 지면과 접촉하는 시간의 양을 나타내는 제1 입각 지속시간을 결정하게 하고;상기 제1 입각 지속시간 및 상기 활보 간격의 지속시간에 기초하여 제1 충격 계수를 결정하게 하고;상기 포인트 데이터를 사용하여, 상기 좌측 뒷발이 상기 활보 간격 동안 지면과 접촉하는 시간의 양을 나타내는 제2 입각 지속시간을 결정하게 하고;상기 제2 입각 지속시간 및 상기 활보 간격의 지속시간에 기초하여 제2 충격 계수를 결정하게 하고;상기 제1 충격 계수 및 상기 제2 충격 계수에 기초하여 상기 활보 간격에 대한 평균 충격 계수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>75. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 꼬리 기부 및 목 기부를 포함하고,상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금:상기 포인트 데이터를 사용하여, 상기 복수의 활보 간격의 활보 간격을 나타내는 프레임 세트 동안 상기 꼬리 기부와 상기 목 기부를 연결하는 벡터 세트를 결정하게 하고;상기 벡터 세트를 사용하여, 상기 활보 간격에 대한 상기 객체의 각속도를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>76. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 상기 객체의 척추 중심을 포함하고,활보 간격은 상기 비디오 데이터의 프레임 세트와 연관되고,상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금, 상기 포인트 데이터를 사용하여, 상기 활보 간격에 대한 변위 벡터를 결정하게 하되, 상기 변위 벡터는 상기 프레임 세트의 제1 프레임에 표시된 상기 척추 중심과 상기 프레임 세트의 마지막 프레임에 표시된 상기 척추 중심을 연결하는, 시스템.</claim></claimInfo><claimInfo><claim>77. 제76항에 있어서, 상기 신체 부위 세트는 추가로 상기 객체의 코를 포함하고, 상기 시스템으로 하여금 상기 메트릭 데이터를 결정하게 하는 상기 명령어는, 추가로 상기 시스템으로 하여금:상기 포인트 데이터를 사용하여, 상기 프레임 세트 내의 각 프레임에 대한 상기 변위 벡터로부터 상기 코의 수직 거리에 기초하여 상기 활보 간격에 대한 상기 코의 측방향 변위 세트를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>78. 제77항에 있어서, 상기 코의 측방향 변위는 추가로 상기 객체의 신체 길이에 기초하는, 시스템.</claim></claimInfo><claimInfo><claim>79. 제77항에 있어서, 상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는, 추가로 상기 시스템으로 하여금:상기 코의 측방향 변위 세트를 사용하여 보간을 수행하여 상기 활보 간격에 대한 상기 코의 매끄러운 곡선 측방향 변위를 생성하고;상기 코의 매끄러운 곡선 측방향 변위를 사용하여, 상기 활보 간격 동안 상기 코의 최대 변위가 언제 발생하는지 결정하고;상기 코의 최대 변위가 발생할 때에 완료된 상기 활보 간격의 백분율을 나타내는 백분율 활보 위치를 결정함으로써, 꼬리 끝 변위 위상 오프셋을 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>80. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 추가로 상기 객체의 꼬리 기부를 포함하고,상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금, 상기 포인트 데이터를 사용하여, 상기 프레임 세트의 각 프레임에 대한 상기 변위 벡터로부터 상기 꼬리 기부의 수직 거리에 기초하여 상기 활보 간격에 대한 상기 꼬리 기부의 측방향 변위 세트를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>81. 제80항에 있어서, 상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는, 추가로 상기 시스템으로 하여금:상기 꼬리 기부의 측방향 변위 세트를 사용하여 보간을 수행하여 상기 활보 간격에 대한 상기 꼬리 기부의 매끄러운 곡선 측방향 변위를 생성하고;상기 꼬리 기부의 매끄러운 곡선 측방향 변위를 사용하여, 상기 활보 간격 동안 상기 꼬리 기부의 최대 변위가 언제 발생하는지 결정하고;상기 꼬리 기부의 최대 변위가 발생할 때 완료되는 상기 활보 간격의 백분율을 나타내는 백분율 활보 위치를 결정함으로써, 꼬리 기부 변위 위상 오프셋을 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>82. 제68항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 상기 객체의 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는 상기 객체의 꼬리 끝을 포함하고,상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는 추가로 상기 시스템으로 하여금:상기 포인트 데이터를 사용하여, 상기 프레임 세트의 각 프레임에 대해 상기 변위 벡터로부터 상기 꼬리 끝의 수직 거리에 기초하여 상기 활보 간격에 대한 상기 꼬리 끝의 측방향 변위 세트를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>83. 제82항에 있어서, 상기 시스템으로 하여금 상기 보행 측정치를 결정하게 하는 상기 명령어는, 추가로 상기 시스템으로 하여금:상기 꼬리 끝의 측방향 변위 세트를 사용하여 보간을 수행하여 상기 활보 간격에 대한 상기 꼬리 끝의 매끄러운 곡선 측방향 변위를 생성하고;상기 꼬리 끝의 매끄러운 곡선 측방향 변위를 사용하여, 상기 활보 간격 동안 상기 꼬리 끝의 최대 변위가 언제 발생하는지 결정하고;상기 꼬리 끝의 최대 변위가 발생할 때 완료되는 상기 활보 간격의 백분율을 나타내는 백분율 활보 위치를 결정함으로써, 꼬리 끝 변위 위상 오프셋을 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>84. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여, 상기 비디오의 지속시간 동안, 신체 부위 세트의 움직임을 추적하는 포인트 데이터를 결정하게 하되, 상기 신체 부위 세트는: 상기 코, 목 기부, 중간 척추, 좌측 뒷발, 우측 뒷발, 꼬리 기부, 꼬리 중간 및 꼬리 끝 중 하나 이상을 포함하고;상기 포인트 데이터를 사용하여, 상기 객체에 대한 특징을 결정하게 하고;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 특징을 처리하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>85. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:추가 기계 학습 모델을 사용하여 상기 비디오 데이터를 처리하여, 상기 객체가 상기 비디오 데이터의 복수의 비디오 프레임 동안 그루밍 행동을 나타낼 가능성을 식별하게 하고;상기 객체가 상기 그루밍 행동을 나타낼 가능성을 사용하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>86. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:추가 기계 학습 모델을 사용하여 상기 비디오 데이터를 처리하여, 상기 객체가 상기 비디오 데이터의 복수의 비디오 프레임 동안 소정의 행동을 나타낼 가능성을 식별하게 하고;상기 객체가 상기 소정의 행동을 나타낼 가능성을 사용하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>87. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터의 제1 비디오 프레임 세트를 회전시킴으로써 회전된 비디오 프레임 세트를 결정하게 하고;상기 객체가 소정의 행동 동작을 나타낼 가능성을 식별하도록 구성된 제1 기계 학습 모델을 사용하여 상기 제1 비디오 프레임 세트를 처리하게 하고;상기 제1 기계 학습 모델에 의한 상기 제1 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제1 비디오 프레임 세트의 제1 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제1 확률을 결정하게 하되, 상기 제1 비디오 프레임은 상기 비디오 데이터의 제1 지속시간에 해당하고;상기 제1 기계 학습 모델을 사용하여 상기 회전된 프레임 세트를 처리하게 하고;상기 제1 기계 학습 모델에 의한 상기 회전된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 회전된 비디오 프레임 세트의 제2 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제2 확률을 결정하게 하되, 상기 제2 비디오 프레임은 상기 비디오 데이터의 제1 지속시간에 해당하고;상기 제1 확률 및 상기 제2 확률을 사용하여, 상기 제1 비디오 프레임에 대한 제1 라벨을 식별하게 하되, 상기 제1 라벨은 상기 객체가 상기 소정의 행동 동작을 나타냄을 표시하는, 시스템.</claim></claimInfo><claimInfo><claim>88. 제87항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 객체가 상기 소정의 행동 동작을 나타낼 가능성을 식별하도록 구성된 제2 기계 학습 모델을 사용하여 상기 제1 비디오 프레임 세트를 처리하게 하고;상기 제2 기계 학습 모델에 의한 상기 제1 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제1 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제3 확률을 결정하게 하고;상기 제2 기계 학습 모델을 사용하여 상기 회전된 비디오 프레임 세트를 처리하게 하고;상기 제2 기계 학습 모델에 의한 상기 회전된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제2 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제4 확률을 결정하게 하고;상기 제1 확률, 상기 제2 확률, 상기 제3 확률 및 상기 제4 확률을 사용하여 상기 제1 라벨을 식별하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>89. 제87항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 제1 비디오 프레임 세트를 반사하여 반사된 비디오 프레임 세트를 결정하게 하고;상기 제1 기계 학습 모델을 사용하여 상기 회전된 비디오 프레임 세트를 처리하게 하고;상기 제1 기계 학습 모델에 의한 상기 반사된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 반사된 프레임 세트의 제3 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제3 확률을 결정하게 하되, 상기 제3 비디오 프레임은 상기 제1 비디오 프레임에 해당하고;상기 제1 확률, 상기 제2 확률, 및 상기 제3 확률을 사용하여 상기 제1 라벨을 식별하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>90. 제87항에 있어서, 상기 객체는 마우스이고, 상기 소정의 행동은: 발 핥기, 한쪽 얼굴 씻기, 양쪽 얼굴 씻기, 및 옆구리 핥기 중 적어도 하나를 포함하는 그루밍 행동을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>91. 제87항에 있어서, 상기 제1 비디오 프레임 세트는 일정 기간 동안 상기 비디오 데이터의 일부를 나타내고, 상기 제1 비디오 프레임은 상기 기간의 마지막 시간 프레임인, 시스템.</claim></claimInfo><claimInfo><claim>92. 제87항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터로부터 제2 비디오 프레임 세트를 식별하게 하고;상기 제2 비디오 프레임 세트를 회전시켜 제2 회전된 비디오 프레임 세트를 결정하게 하고;상기 제1 기계 학습 모델을 사용하여 상기 제2 비디오 프레임 세트를 처리하게 하고;상기 제1 기계 학습 모델에 의한 상기 제2 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 제2 비디오 프레임 세트의 제3 프레임에서 상기 소정의 행동 동작을 나타낼 제3 확률을 결정하게 하고;상기 제1 기계 학습 모델을 사용하여 상기 제2 회전된 비디오 프레임 세트를 처리하게 하고;상기 제1 기계 학습 모델에 의한 상기 제2 회전된 비디오 프레임 세트의 처리에 기초하여, 상기 객체가 상기 회전된 프레임 세트의 제4 비디오 프레임에서 상기 소정의 행동 동작을 나타낼 제4 확률을 결정하게 하되, 상기 제4 비디오 프레임은 상기 제3 비디오 프레임에 해당하고;상기 제3 확률 및 상기 제4 확률을 사용하여, 상기 제3 프레임에 대한 제2 라벨을 식별하게 하되, 상기 제2 라벨은 상기 객체가 상기 소정의 행동 동작을 나타냄을 표시하는, 시스템.</claim></claimInfo><claimInfo><claim>93. 제87항에 있어서, 상기 제1 기계 학습 모델은 기계 학습 분류기인, 시스템.</claim></claimInfo><claimInfo><claim>94. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 비디오 데이터를 처리하여 상기 비디오의 지속시간 동안 상기 객체에 대한 보행 측정치를 결정하게 하고;상기 비디오 데이터를 처리하여 상기 객체가 소정의 행동을 나타내는 상기 비디오의 일부를 식별하는 행동 데이터를 결정하게 하고;상기 적어도 하나의 기계 학습 모델을 사용하여, 상기 척추 이동성 특징, 상기 보행 측정치 및 상기 행동 데이터를 처리하여 상기 시각적 쇠약 점수를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>95. 제57항에 있어서, 상기 비디오는 개방 필드 영역에서 상기 객체의 움직임을 캡처하는, 시스템.</claim></claimInfo><claimInfo><claim>96. 제57항에 있어서, 상기 적어도 하나의 메모리는 추가로 명령어를 포함하되, 상기 명령어는, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 시스템으로 하여금:상기 시각적 쇠약 점수를 사용하여 상기 객체의 신체 병태를 결정하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>97. 제96항에 있어서, 상기 신체 병태는 쇠약한, 시스템.</claim></claimInfo><claimInfo><claim>98. 제96항에 있어서, 상기 신체 병태는 쇠약 전 병태인, 시스템.</claim></claimInfo><claimInfo><claim>99. 제57항에 있어서, 상기 객체는 포유류이고, 선택적으로 마우스인, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 메인(우편번호 *****) 바 하버 메인 스트리트 ***</address><code>520120146723</code><country>미국</country><engName>The Jackson Laboratory</engName><name>더 잭슨 래보라토리</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 메인 ***** 바 하버...</address><code> </code><country> </country><engName>KUMAR, Vivek</engName><name>쿠마르, 비벡</name></inventorInfo><inventorInfo><address>미국 메인 ***** 바 하버...</address><code> </code><country> </country><engName>HESSION, Leinani</engName><name>헤시온, 레이나니</name></inventorInfo><inventorInfo><address>미국 메인 ***** 바 하버...</address><code> </code><country> </country><engName>SABNIS, Gautam</engName><name>사브니스, 고탐</name></inventorInfo><inventorInfo><address>미국 메인 ***** 바 하버...</address><code> </code><country> </country><engName>CHURCHILL, Gary</engName><name>처칠, 게리</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 송파구  올림픽로  *** ,*층 (신천동, 대한제당)</address><code>920131000018</code><country>대한민국</country><engName>Envision Patent &amp; Law Firm</engName><name>인비전특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.05.12</priorityApplicationDate><priorityApplicationNumber>63/187,892</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.11.13</receiptDate><receiptNumber>1-1-2023-1252132-27</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.12.13</receiptDate><receiptNumber>1-5-2023-0201756-82</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.05.12</receiptDate><receiptNumber>1-1-2025-0524726-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.05.12</receiptDate><receiptNumber>1-1-2025-0524752-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237039087.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93349c79a445023f5c87a4c5e4d7e50a7cdc27f0ab068b866d346cef72c6aef5c753451254ccfe2eed2ab6680f20ea2d20941a3ebf2140c07b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf101517ca25514b83802d17587a76845eb755eac86bb073302ff6dea1dc05e1e77dd552435d35f29e779f2ebb419e10c26e40509c9fa300c0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>