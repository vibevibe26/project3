<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:14:47.1447</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.10</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7007915</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>라디오 주파수 감지로 보조되는 음성 사용자 인터페이스</inventionTitle><inventionTitleEng>VOICE USER INTERFACE ASSISTED WITH RADIO FREQUENCY SENSING</inventionTitleEng><openDate>2025.05.20</openDate><openNumber>10-2025-0069865</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.10</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/24</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 15/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 무선 주파수(RF) 감지에 의해 보조되는 음성 인식을 위한 시스템들 및 기술들이 제공된다. 예를 들어, 라디오 주파수(RF) 감지에 의해 보조되는 음성 인식을 위한 프로세스는, 음성 사용자 인터페이스(UI) 디바이스에서, 스피킹 엔티티로부터의 음성 커맨드를 포함하는 오디오 데이터를 획득하는 단계; 상기 오디오 데이터에 대응하는 RF 감지 데이터를 획득하는 단계; 오디오 음성 커맨드 출력을 결정하기 위해 상기 오디오 데이터를 프로세싱하는 단계; RF 감지 음성 커맨드 출력을 결정하기 위해 상기 RF 감지 데이터를 프로세싱하는 단계; 상기 오디오 음성 커맨드 출력 및 상기 RF 감지 음성 커맨드 출력에 기초하여 상기 음성 커맨드를 결정하는 단계; 및 상기 음성 UI 디바이스에서, 상기 음성 커맨드에 기초한 동작을 수행하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.28</internationOpenDate><internationOpenNumber>WO2024064468</internationOpenNumber><internationalApplicationDate>2023.08.10</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/072015</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 라디오 주파수(RF) 감지에 의해 보조되는 음성 인식을 위한 방법으로서, 상기 방법은:음성 사용자 인터페이스(UI) 디바이스에서, 스피킹 엔티티로부터의 음성 커맨드를 포함하는 오디오 데이터를 획득하는 단계;상기 오디오 데이터에 대응하는 RF 감지 데이터를 획득하는 단계;오디오 음성 커맨드 출력을 결정하기 위해 상기 오디오 데이터를 프로세싱하는 단계;RF 감지 음성 커맨드 출력을 결정하기 위해 상기 RF 감지 데이터를 프로세싱하는 단계;상기 오디오 음성 커맨드 출력 및 상기 RF 감지 음성 커맨드 출력에 기초하여 상기 음성 커맨드를 결정하는 단계; 및상기 음성 UI 디바이스에서, 상기 음성 커맨드에 기초한 동작을 수행하는 단계를 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 음성 UI 디바이스로부터 상기 스피킹 엔티티로의 방향을 포함하고,상기 음성 커맨드를 결정하는 단계는 상기 방향에 기초하여 상기 음성 UI 디바이스의 오디오 캡처 컴포넌트에 대한 빔포밍을 수행하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 음성 UI 디바이스와 상기 스피킹 엔티티 사이의 거리를 포함하고;상기 음성 커맨드를 결정하는 단계는 상기 거리에 기초하여 상기 음성 UI 디바이스의 오디오 캡처 컴포넌트에 대한 게인 레벨을 조정하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 스피킹 엔티티의 스피치 특성들을 포함하고,상기 음성 커맨드를 결정하는 단계는 상기 음성 UI 디바이스의 스피치 인식 동작을 향상시키기 위해 상기 스피치 특성들을 사용하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 RF 감지 데이터는 상기 스피킹 엔티티를 포함하는 환경에 대한 깊이 맵 정보를 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 RF 감지 데이터는 상기 스피킹 엔티티의 입(mouth) 영역에 대응하는 입 영역 데이터를 포함하고;상기 RF 감지 데이터를 프로세싱하는 단계는 상기 입 영역의 특징의 포지션에 대응하는 특징 정보를 획득하기 위해 상기 깊이 맵 정보를 프로세싱하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 특징 정보는 상기 스피킹 엔티티의 혀(tongue)에 적어도 부분적으로 대응하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서, 상기 특징 정보는 상기 스피킹 엔티티의 립들(lips)에 적어도 부분적으로 대응하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서, 추가로 상기 RF 감지 데이터를 프로세싱하기 전에, 필터링된 RF 감지 데이터를 획득하기 위해 상기 RF 감지 데이터를 필터링하는 단계를 포함하고, 상기 필터링된 RF 감지 데이터는 환경으로부터의 다른 RF 감지 환경 데이터 없이 상기 입 영역 데이터를 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 음성 커맨드를 결정하는 단계는 수행할 하나 이상의 동작들을 결정하기 위해 상기 음성 커맨드의 누락된 부분을 제공하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 스피킹 엔티티에 의해 행해진 제스처에 대응하는 제스처 데이터를 포함하고;상기 음성 커맨드를 결정하는 단계는 수행할 동작을 결정하기 위해 상기 제스처 데이터 및 상기 오디오 음성 커맨드 출력을 사용하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 RF 감지 데이터를 프로세싱하는 단계는 상기 RF 감지 음성 커맨드 출력을 결정하기 위해 상기 RF 감지 데이터를 트레이닝된 기계 학습(ML) 모델에 제공하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 추가로, 상기 RF 감지 데이터를 프로세싱하기 전에, 상이한 스피치 패턴들에 대응하는 복수의 트레이닝된 ML 모델들로부터 상기 트레이닝된 ML 모델을 선택하는 단계를 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 트레이닝된 ML 모델은 복수의 음성 커맨드 키워드들을 포함하는 음성 커맨드 데이터 세트를 사용하여 트레이닝되는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 추가로, 상기 RF 감지 데이터를 획득하기 전에, 상기 스피킹 엔티티를 포함하는 환경을 향해 RF 신호를 송신하는 단계를 포함하고, 상기 RF 신호는 RF 감지 컴포넌트에 의해 송신되고, 상기 RF 감지 데이터는 상기 스피킹 엔티티로부터의 송신된 상기 RF 신호의 하나 이상의 반사들에 기초하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 스피킹 엔티티는 상기 RF 감지 컴포넌트의 관점으로부터 폐색되는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 음성 UI 디바이스는 상기 RF 감지 컴포넌트를 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>18. 제1항에 있어서, 추가로,부가적인 RF 감지 데이터를 획득하는 단계로서, 상기 부가적인 RF 감지 데이터는 상기 스피킹 엔티티가 상기 음성 UI 디바이스로 가청적인 사운드를 방출하지 않으면서 획득되는, 상기 부가적인 RF 감지 데이터를 획득하는 단계;상기 스피킹 엔티티를 포함하는 환경의 깊이 맵 정보를 획득하기 위해 상기 RF 감지 데이터를 프로세싱하는 단계로서, 상기 깊이 맵 정보는 상기 스피킹 엔티티의 입 영역에 대응하는 입 영역 데이터를 포함하는, 상기 RF 감지 데이터를 프로세싱하는 단계;상기 입 영역에서의 특징의 포지션에 대응하는 특징 정보를 획득하기 위해 상기 입 영역 데이터를 프로세싱하는 단계; 및상기 음성 UI 디바이스에 의해, 상기 특징 정보에 기초한 제2 동작을 수행하는 단계를 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>19. 제1항에 있어서, 상기 RF 감지 데이터는 깊이 맵 정보를 포함하고, 상기 RF 감지 데이터를 프로세싱하는 단계는:2차원 데이터를 사용하여, 상기 스피킹 엔티티의 입 영역에 대응하는 입 영역 데이터에서의 특징들의 위치를 결정하는 것; 및상기 깊이 맵 정보에서의 특징들의 위치를 식별하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 2차원 데이터는 상기 깊이 맵 정보를 플랫화(flattening)함으로써 획득되는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>21. 제19항에 있어서, 상기 2차원 데이터는 카메라로부터 획득되는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>22. 제1항에 있어서, 상기 RF 감지 데이터를 프로세싱하는 단계는,관심 깊이 범위를 결정하기 위해 초기 프로세싱를 수행하는 것;상기 관심 깊이 범위 밖의 데이터를 배제하고 필터링된 RF 감지 데이터를 획득하기 위해 상기 RF 감지 데이터를 필터링하는 것; 및상기 RF 감지 음성 커맨드 출력을 획득하기 위해 상기 필터링된 RF 감지 데이터를 트레이닝된 기계 학습(ML) 모델에 제공하는 것을 포함하는, 음성 인식을 위한 방법.</claim></claimInfo><claimInfo><claim>23. 라디오 주파수(RF) 감지에 의해 보조되는 음성 인식을 위한 장치로서, 상기 장치는:적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 음성 사용자 인터페이스(UI) 디바이스를 통해, 스피킹 엔티티로부터의 음성 커맨드를 포함하는 오디오 데이터를 획득하도록; 상기 오디오 데이터에 대응하는 RF 감지 데이터를 획득하도록; 오디오 음성 커맨드 출력을 결정하기 위해 상기 오디오 데이터를 프로세싱하도록; RF 감지 음성 커맨드 출력을 결정하기 위해 상기 RF 감지 데이터를 프로세싱하도록; 상기 오디오 음성 커맨드 출력 및 상기 RF 감지 음성 커맨드 출력에 기초하여 상기 음성 커맨드를 결정하도록; 그리고 상기 음성 UI 디바이스에서, 상기 음성 커맨드에 기초한 동작을 수행하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 음성 UI 디바이스로부터 상기 스피킹 엔티티로의 방향을 포함하고,상기 적어도 하나의 프로세서는 추가로, 상기 음성 커맨드가 상기 방향에 기초하여 상기 음성 UI 디바이스의 오디오 캡처 컴포넌트에 대한 빔포밍을 수행하는 것을 포함하는 것을 결정하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>25. 제23항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 음성 UI 디바이스와 상기 스피킹 엔티티 사이의 거리를 포함하고;상기 적어도 하나의 프로세서는 추가로 상기 음성 커맨드가 상기 거리에 기초하여 상기 음성 UI 디바이스의 오디오 캡처 컴포넌트에 대한 게인 레벨을 조정하는 것을 포함하는 것을 결정하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>26. 제23항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 스피킹 엔티티의 스피치 특성들을 포함하고,상기 적어도 하나의 프로세서는 추가로, 상기 음성 커맨드가 상기 음성 UI 디바이스의 스피치 인식 동작을 향상시키기 위해 상기 스피치 특성들을 사용하는 것을 포함하는 것을 결정하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>27. 제23항에 있어서, 상기 RF 감지 데이터는 상기 스피킹 엔티티를 포함하는 환경에 대한 깊이 맵 정보를 포함하는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서,상기 RF 감지 데이터는 상기 스피킹 엔티티의 입(mouth) 영역에 대응하는 입 영역 데이터를 포함하고;상기 적어도 하나의 프로세서는 추가로, 상기 입 영역의 특징의 포지션에 대응하는 특징 정보를 획득하기 위해 상기 깊이 맵 정보를 프로세싱함으로써 상기 RF 감지 데이터를 프로세싱하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 특징 정보는 상기 스피킹 엔티티의 혀(tongue)에 적어도 부분적으로 대응하는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>30. 제28항에 있어서, 상기 특징 정보는 상기 스피킹 엔티티의 립들(lips)에 적어도 부분적으로 대응하는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>31. 제28항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 상기 RF 감지 데이터를 프로세싱하기 전에, 필터링된 RF 감지 데이터를 획득하기 위해 상기 RF 감지 데이터를 필터링하도록 구성되고, 상기 필터링된 RF 감지 데이터는 환경으로부터의 다른 RF 감지 환경 데이터 없이 상기 입 영역 데이터를 포함하는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>32. 제23항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 수행할 하나 이상의 동작들을 결정하기 위해 상기 음성 커맨드의 누락된 부분을 제공함으로써 상기 음성 커맨드를 결정하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>33. 제23항에 있어서,상기 RF 감지 음성 커맨드 출력은 상기 스피킹 엔티티에 의해 행해진 제스처에 대응하는 제스처 데이터를 포함하고;상기 적어도 하나의 프로세서는 추가로, 수행할 동작을 결정하기 위해 상기 제스처 데이터 및 상기 오디오 음성 커맨드 출력을 사용함으로써 상기 음성 커맨드를 결정하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>34. 제23항에 있어서, 상기 RF 감지 데이터를 프로세싱하기 위해, 상기 적어도 하나의 프로세서는 추가로, 상기 RF 감지 음성 커맨드 출력을 결정하기 위해 상기 RF 감지 데이터를 트레이닝된 기계 학습(ML) 모델에 제공하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>35. 제34항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 상기 RF 감지 데이터를 프로세싱하기 전에, 상이한 스피치 패턴들에 대응하는 복수의 트레이닝된 ML 모델들로부터 상기 트레이닝된 ML 모델을 선택하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>36. 제34항에 있어서, 상기 트레이닝된 ML 모델은 복수의 음성 커맨드 키워드들을 포함하는 음성 커맨드 데이터 세트를 사용하여 트레이닝되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>37. 제23항에 있어서, 상기 적어도 하나의 프로세서는 추가로, 상기 RF 감지 데이터를 획득하기 전에, 상기 스피킹 엔티티를 포함하는 환경을 향해 RF 신호를 송신하도록 구성되고, 상기 RF 신호는 RF 감지 컴포넌트에 의해 송신되고, 상기 RF 감지 데이터는 상기 스피킹 엔티티로부터의 송신된 상기 RF 신호의 하나 이상의 반사들에 기초하는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>38. 제37항에 있어서, 상기 스피킹 엔티티는 상기 RF 감지 컴포넌트의 관점으로부터 폐색되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>39. 제37항에 있어서, 상기 음성 UI 디바이스는 상기 RF 감지 컴포넌트를 포함하는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>40. 제23항에 있어서, 상기 적어도 하나의 프로세서는 추가로:부가적인 RF 감지 데이터를 획득하는 것으로서, 상기 부가적인 RF 감지 데이터는 상기 스피킹 엔티티가 상기 음성 UI 디바이스로 가청적인 사운드를 방출하지 않으면서 획득되는, 상기 부가적인 RF 감지 데이터를 획득하는 것;상기 스피킹 엔티티를 포함하는 환경의 깊이 맵 정보를 획득하기 위해 상기 RF 감지 데이터를 프로세싱하는 것으로서, 상기 깊이 맵 정보는 상기 스피킹 엔티티의 입 영역에 대응하는 입 영역 데이터를 포함하는, 상기 RF 감지 데이터를 프로세싱하는 것;상기 입 영역에서의 특징의 포지션에 대응하는 특징 정보를 획득하기 위해 상기 입 영역 데이터를 프로세싱하는 것; 및상기 특징 정보에 기초하여 제2 동작을 수행하는 것을 행하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>41. 제23항에 있어서,상기 RF 감지 데이터는 깊이 맵 정보를 포함하고;상기 RF 감지 데이터를 프로세싱하기 위해, 상기 프로세서는 추가로:2차원 데이터를 사용하여, 상기 스피킹 엔티티의 입 영역에 대응하는 입 영역 데이터에서의 특징들의 위치를 결정하도록; 그리고상기 깊이 맵 정보에서의 특징들의 위치를 식별하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>42. 제41항에 있어서, 상기 2차원 데이터는 상기 깊이 맵 정보를 플랫화함으로써 획득되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>43. 제41항에 있어서, 상기 2차원 데이터는 카메라로부터 획득되는, 음성 인식을 위한 장치.</claim></claimInfo><claimInfo><claim>44. 제23항에 있어서, 상기 RF 감지 데이터를 프로세싱하기 위해, 상기 프로세서는 추가로:관심 깊이 범위를 결정하기 위해 초기 프로세싱를 수행하도록;상기 관심 깊이 범위 밖의 데이터를 배제하고 필터링된 RF 감지 데이터를 획득하기 위해 상기 RF 감지 데이터를 필터링하도록; 그리고상기 RF 감지 음성 커맨드 출력을 획득하기 위해 상기 필터링된 RF 감지 데이터를 트레이닝된 기계 학습(ML) 모델에 제공하도록 구성되는, 음성 인식을 위한 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>RAMASAMY, BALA</engName><name>라마사미 발라</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>그리스</country><engName>FILOS, JASON</engName><name>필로스 제이슨</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>PARK, EDWIN CHONGWOO</engName><name>박 에드윈 청우</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>ZHANG, XIAOXIN</engName><name>장 샤오신</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>그리스</priorityApplicationCountry><priorityApplicationDate>2022.09.20</priorityApplicationDate><priorityApplicationNumber>20220100764</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.10</receiptDate><receiptNumber>1-1-2025-0269523-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.04.23</receiptDate><receiptNumber>1-5-2025-0068189-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.25</receiptDate><receiptNumber>1-1-2025-0474710-04</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257007915.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9372a0444bb10194dc695dff0177b6f0a412daead32ef9d3ef3893ec23bdc944ff2bb9c76084031a6f73257f2abbe445ae8acdbb1c9c79daff</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb64526f5b1ad5d341b9599b63059f67eb48a603bbd98a9bd30b9fabd34c735493849bfaf4baa3c90e1c0e959121b0cad217f39ee3218a81b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>