<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:53.553</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0114261</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 영상을 이용하여 정보를 표시하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR DISPLAYING INFORMATION  USING AUGMENTED REALITY VIDEO</inventionTitleEng><openDate>2024.12.10</openDate><openNumber>10-2024-0172643</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 증강 현실 장치가 다른 디바이스에 대한 정보를 표시하는 방법을 제공한다. 증강 현실 장치의 동작 방법은, 정보를 표시하기 위한 관심 디바이스를 식별하는 단계를 포함할 수 있다. 증강 현실 장치의 동작 방법은, 관심 디바이스에 대한 정보를 표시할지 여부를 결정하는 단계를 포함할 수 있다. 증강 현실 장치의 동작 방법은, 관심 디바이스에 대한 정보를 포함하는 증강 현실 영상을 디스플레이하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 증강 현실 장치(100)가 정보를 표시하는 방법에 있어서,관심 디바이스(200)를 식별하는 단계;상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계; 및상기 관심 디바이스(200)에 대한 정보를 포함하는 증강 현실 영상을 디스플레이하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계는,상기 관심 디바이스(200)로부터 디바이스 식별 정보 및 알림 정보를 수신하는 단계;상기 디바이스 식별 정보에 기초하여 상기 관심 디바이스(200)가 디스플레이 화면을 포함하는지 여부를 식별하는 단계; 및상기 관심 디바이스(200)가 디스플레이 화면을 포함하지 않는 경우, 상기 알림 정보를 표시하기로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계는, 상기 관심 디바이스(200)가 디스플레이 화면을 포함하는 경우, 상기 디스플레이 화면의 페이싱(facing) 방향에 기초하여 상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 디스플레이 화면의 페이싱(facing) 방향에 기초하여 상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계는, 상기 디스플레이 화면의 페이싱(facing) 방향 및 상기 관심 디바이스(200)로부터 상기 증강 현실 장치(100)의 방향의 차이가 기 설정된 임계 각도보다 큰 경우, 상기 관심 디바이스(200)에 대한 정보를 표시하기로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계는, 상기 관심 디바이스(200)가 디스플레이 화면을 포함하는 경우, 상기 증강 현실 장치(100)와 상기 관심 디바이스(200) 간의 거리를 측정하는 단계; 및상기 증강 현실 장치(100)와 상기 관심 디바이스(200) 간의 거리에 기초하여 상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 증강 현실 장치(100)와 상기 관심 디바이스(200) 간의 거리에 기초하여 상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는 단계는,상기 증강 현실 장치(100)와 상기 관심 디바이스(200) 간의 거리가 기 설정된 임계 값보다 큰 경우, 상기 관심 디바이스(200)에 대한 정보를 표시하기로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 관심 디바이스(200)는, 상기 증강 현실 장치(100)에 연결된 디바이스들 중 이벤트가 발생된 디바이스, 상기 증강 현실 장치(100)에 연결된 디바이스들 중 사용자가 선택한 디바이스, 또는 상기 증강 현실 장치(100)에 새로 연결되는 디바이스 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 관심 디바이스(200)를 식별하는 단계는,시선 추적 센서를 통해 사용자가 주시(gazing)하는 디바이스를 식별하는 단계;상기 사용자가 주시하는 디바이스가 상기 증강 현실 장치(100)에 연결되어 있는지 식별하는 단계; 및상기 사용자가 주시하는 디바이스가 상기 증강 현실 장치(100)에 연결되어 있는 경우, 상기 사용자가 주시하는 디바이스를 상기 관심 디바이스(200)로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,시선 추적 센서를 통해 상기 사용자가 주시하는 디바이스를 식별하는 단계는,상기 시선 추적 센서를 통해 사용자의 주시 방향을 획득하는 단계;카메라(120)를 통해 현실 장면(real-world scene) 이미지를 획득하는 단계;상기 현실 장면 이미지로부터 적어도 하나의 디바이스를 식별하는 단계; 및상기 현실 장면 이미지 내 상기 적어도 하나의 디바이스의 위치 및 상기 사용자의 주시 방향에 기초하여, 상기 사용자가 주시하는 디바이스를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 관심 디바이스(200)에 대한 정보를 포함하는 증강 현실 영상을 디스플레이하는 단계는,카메라(120)를 통해 현실 장면(real-world scene) 이미지를 획득하는 단계;상기 현실 장면 이미지로부터 상기 관심 디바이스(200)를 식별하는 단계;상기 관심 디바이스(200)의 위치에 기초하여, 상기 증강 현실 영상을 디스플레이 할 영역을 결정하는 단계; 및상기 결정된 영역에 상기 증강 현실 영상을 디스플레이하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 연결된 디바이스에 대한 정보를 표시하는 증강 현실 장치(100)에 있어서,현실 장면 이미지(real-world scene)를 획득하도록 구성되는 카메라(120);디스플레이부(162);적어도 하나의 명령어(instruction)를 포함하는 프로그램을 저장하는 메모리(150); 및적어도 하나의 프로세서(140)를 포함하고,상기 적어도 하나의 프로세서(140)는,관심 디바이스(200)를 식별하고,상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하고,상기 디스플레이부(162)를 통해 상기 관심 디바이스(200)에 대한 정보를 포함하는 증강 현실 영상을 디스플레이하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 관심 디바이스(200)로부터 디바이스 식별 정보 및 알림 정보를 수신하고,상기 디바이스 식별 정보에 기초하여 상기 관심 디바이스(200)가 디스플레이 화면을 포함하는지 여부를 식별하고,상기 관심 디바이스(200)가 디스플레이 화면을 포함하지 않는 경우, 상기 알림 정보를 표시하기로 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>13. 제11항 또는 제12항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 관심 디바이스(200)가 디스플레이 화면을 포함하는 경우, 상기 디스플레이 화면의 페이싱(facing) 방향에 기초하여 상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 디스플레이 화면의 페이싱(facing) 방향 및 상기 관심 디바이스(200)로부터 상기 증강 현실 장치(100)의 방향의 차이가 기 설정된 임계 각도보다 큰 경우, 상기 관심 디바이스(200)에 대한 정보를 표시하기로 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>15. 제11항 내지 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 관심 디바이스(200)가 디스플레이 화면을 포함하는 경우, 상기 증강 현실 장치(100)와 상기 관심 디바이스(200) 간의 거리를 측정하고,상기 증강 현실 장치(100)와 상기 관심 디바이스(200) 간의 거리에 기초하여 상기 관심 디바이스(200)에 대한 정보를 표시할지 여부를 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 증강 현실 장치(100)와 상기 관심 디바이스(200) 간의 거리가 기 설정된 임계 값보다 큰 경우, 상기 관심 디바이스(200)에 대한 정보를 표시하기로 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>17. 제11항 내지 제16항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,시선 추적 센서를 통해 사용자가 주시(gazing)하는 디바이스를 식별하고,상기 사용자가 주시하는 디바이스가 상기 증강 현실 장치(100)에 연결되어 있는지 식별하고,상기 사용자가 주시하는 디바이스가 상기 증강 현실 장치에 연결되어 있는 경우, 상기 사용자가 주시하는 디바이스를 상기 관심 디바이스(200)로 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 시선 추적 센서를 통해 사용자의 주시 방향을 획득하고,카메라(120)를 통해 현실 장면(real-world scene) 이미지를 획득하고,상기 현실 장면 이미지로부터 적어도 하나의 디바이스를 식별하고,상기 현실 장면 이미지 내 상기 적어도 하나의 디바이스의 위치 및 상기 사용자의 주시 방향에 기초하여, 상기 사용자가 주시하는 디바이스를 식별하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>19. 제11항 내지 제18항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,카메라(120)를 통해 현실 장면(real-world scene) 이미지를 획득하고,상기 현실 장면 이미지로부터 상기 관심 디바이스(200)를 식별하고,상기 관심 디바이스(200)의 위치에 기초하여, 상기 증강 현실 영상을 디스플레이 할 영역을 결정하고,상기 결정된 영역에 상기 증강 현실 영상을 디스플레이하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YOO, Byeong Wook</engName><name>유병욱</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Se Young</engName><name>이세영</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HAN, In Sun</engName><name>한인선</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.06.01</priorityApplicationDate><priorityApplicationNumber>1020230071181</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.30</receiptDate><receiptNumber>1-1-2023-0955842-46</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230114261.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c77104924888ba895126d1ad8b7485f8c500e63be74aa3cf0b951f9d2b27bf97926881728e0a6f4bd780a0265ebff4497eff0d831acde89d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf5d2dd6f4b82256526c53857249964e1c228a20c704e8f28f1de2edb0d399b352a7a5b6f8ae8e1c7e9f49197dede57eafdeb832271d38eeed</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>