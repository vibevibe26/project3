<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:43.543</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0179973</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>복수의 카메라를 이용하여 촬영된 손의 3차원 골격 데이터를 획득하는 전자 장치 및 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE AND METHOD FOR ACQUIRING  THREE-DIMENSIONAL SKELETON DATA OF USER HAND CAPTURED  USING PLURALITY OF CAMERAS</inventionTitleEng><openDate>2023.06.22</openDate><openNumber>10-2023-0090852</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.16</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/593</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/174</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치가 복수의 카메라를 이용하여 촬영된 손의 3차원 골격 데이터를 획득하는 방법이 제공된다. 방법은, 제1 카메라를 통해 제1 이미지를 획득하고 제2 카메라를 통해 제2 이미지를 획득하는 단계, 제1 이미지로부터 손이 포함된 제1 관심 영역(region of interest, ROI)을 획득하는 단계, 제1 관심 영역으로부터, 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하는 단계, 제1 골격 데이터, 및 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 제2 이미지로부터 제2 관심 영역을 획득하는 단계, 제2 관심 영역으로부터, 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하는 단계, 및 제1 골격 데이터 및 제2 골격 데이터에 기초하여, 손의 3차원 골격 데이터를 획득하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치가 복수의 카메라를 이용하여 촬영된 손의 3차원 골격 데이터(skeleton data)를 획득하는 방법에 있어서,제1 카메라를 통해 제1 이미지를 획득하고 제2 카메라를 통해 제2 이미지를 획득하는 단계;상기 제1 이미지로부터 상기 손이 포함된 제1 관심 영역(region of interest, ROI)을 획득하는 단계;상기 제1 관심 영역으로부터, 상기 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하는 단계;상기 제1 골격 데이터, 및 상기 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 상기 제2 이미지로부터 제2 관심 영역을 획득하는 단계;상기 제2 관심 영역으로부터 상기 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하는 단계; 및상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여, 상기 손의 3차원 골격 데이터를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 이미지로부터 상기 제1 관심 영역을 획득하는 단계는, 상기 제1 이미지를 입력 값으로 하여 상기 손이 포함된 이미지 영역을 상기 제1 관심 영역으로 출력하도록 훈련된, 제1 딥러닝(deep learning) 모델을 이용하는 것인, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제1 관심 영역으로부터 상기 제1 골격 데이터를 획득하는 단계는, 상기 제1 관심 영역을 입력 값으로 하여 상기 손의 적어도 하나의 특징점을 조인트(joint)로 포함하는 그래프를 상기 제1 골격 데이터로 출력하도록 훈련된, 제2 딥러닝 모델을 이용하는 것인, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제1 골격 데이터, 및 상기 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 상기 제2 이미지로부터 제2 관심 영역을 획득하는 단계는,상기 제1 골격 데이터에 포함된 적어도 하나의 특징점의 3차원 위치 좌표를 상기 제2 이미지 상의 2차원 위치 좌표로 투영(projection) 시키는 단계;상기 제2 이미지로부터, 상기 제1 골격 데이터에 포함된 특징점의 상기 2차원 위치 좌표를 포함하는 블록을 식별하는 단계; 및상기 식별된 블록을 상기 제2 관심 영역으로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제2 골격 데이터는 상기 적어도 하나의 특징점의 상기 제2 이미지 평면 상 기 설정된 원점에 대한 2차원 위치 좌표를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 제2 관심 영역으로부터 상기 제2 골격 데이터를 획득하는 단계는, 상기 제2 관심 영역을 입력 값으로 하여 상기 손의 적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제2 골격 데이터로 출력하도록 훈련된 제3 딥러닝 모델을 이용하는 것인, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여 상기 손의 3차원 골격 데이터를 획득하는 단계는,상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 3차원 위치 좌표를 상기 제1 이미지 평면 상 2차원 위치 좌표로 투영(projection) 시키는 단계; 및상기 제1 이미지 평면 상에 투영된 2차원 위치 좌표 및 상기 제2 골격 데이터에 포함된 2차원 위치 좌표에 기초하여, 3차원 위치 좌표를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제2 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제2 관심 영역으로부터 상기 제2 골격 데이터를 획득하는 단계는, 상기 제2 관심 영역을 입력 값으로 하여 상기 손의 적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제2 골격 데이터로 출력하도록 훈련된 제2 딥러닝 모델을 이용하는 것인, 방법.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여 상기 손의 3차원 골격 데이터를 획득하는 단계는, 상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 3차원 위치 좌표 및 상기 제2 골격 데이터에 포함된 3차원 위치 좌표의 평균(average)값에 기초하여, 3차원 위치 좌표를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여 상기 손의 3차원 골격 데이터를 획득하는 단계는, 상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 위치 좌표 및 상기 제2 골격 데이터에 포함된 위치 좌표의 가중치 결합에 기초하여, 3차원 위치 좌표를 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 전자 장치에 있어서,제1 카메라;제2 카메라;적어도 하나의 명령어(instruction)를 저장하는 저장부; 및상기 저장부에 저장된 적어도 하나의 명령어를 실행하는 적어도 하나의 프로세서를 포함하고,상기 프로세서는 상기 적어도 하나의 명령어를 실행함으로써,상기 제1 카메라를 통해 제1 이미지를 획득하고 상기 제2 카메라를 통해 제2 이미지를 획득하고,상기 제1 이미지로부터, 손이 포함된 제1 관심 영역(region of interest, ROI)을 획득하고,상기 제1 관심 영역으로부터, 상기 손의 적어도 하나의 특징점을 포함하는 제1 골격 데이터를 획득하고,상기 제1 골격 데이터, 및 상기 제1 카메라 및 제2 카메라의 상대적 위치 정보에 기초하여 상기 제2 이미지로부터 제2 관심 영역을 획득하고,상기 제2 관심 영역으로부터 상기 손의 적어도 하나의 특징점을 포함하는 제2 골격 데이터를 획득하고,상기 제1 골격 데이터 및 상기 제2 골격 데이터에 기초하여, 상기 손의 3차원 골격 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여, 상기 제1 이미지를 입력 값으로 하여 상기 손이 포함된 이미지 영역을 상기 제1 관심 영역으로 출력하도록 훈련된, 제1 딥러닝(deep learning) 모델을 이용하여, 상기 제1 이미지로부터 상기 제1 관심 영역을 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여, 상기 제1 관심 영역을 입력 값으로 하여 상기 손의 적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제1 골격 데이터로 출력하도록 훈련된, 제2 딥러닝 모델을 이용하여, 상기 제1 관심 영역으로부터 상기 제1 골격 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여,상기 제1 골격 데이터에 포함된 적어도 하나의 특징점의 3차원 위치 좌표를 상기 제2 이미지 상의 2차원 위치 좌표로 투영(projection) 시키고,상기 제2 이미지로부터, 상기 제1 골격 데이터에 포함된 특징점들의 상기 2차원 위치 좌표를 포함하는 블록을 식별하고,상기 식별된 블록을 상기 제2 관심 영역으로 결정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서,상기 제2 골격 데이터는 상기 적어도 하나의 특징점의 상기 제2 이미지 평면 상 기 설정된 원점에 대한 2차원 위치 좌표를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여, 상기 제2 관심 영역을 입력 값으로 하여 상기 손의 적어도 하나의 특징점을 조인트로 포함하는 그래프를 상기 제2 골격 데이터로 출력하도록 훈련된 제3 딥러닝 모델을 이용하여, 상기 제2 관심 영역으로부터 상기 제2 골격 데이터를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서,상기 제1 골격 데이터는 상기 적어도 하나의 특징점의 공간 내 기 설정된 원점에 대한 3차원 위치 좌표를 포함하고,상기 프로세서는 상기 적어도 하나의 명령어들을 실행하여,상기 적어도 하나의 특징점에 대해, 상기 제1 골격 데이터에 포함된 3차원 위치 좌표를 상기 제1 이미지 평면 상 2차원 위치 좌표로 투영(projection) 시키고,상기 제1 이미지 평면 상에 투영된 2차원 위치 좌표 및 상기 제2 골격 데이터에 포함된 2차원 위치 좌표에 기초하여, 3차원 위치 좌표를 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제12항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Deok Ho</engName><name>김덕호</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KWON, Tae Hyuk</engName><name>권태혁</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Hwang Pil</engName><name>박황필</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JEONG, Ji Won</engName><name>정지원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.12.15</receiptDate><receiptNumber>1-1-2021-1455522-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.12.16</receiptDate><receiptNumber>1-1-2024-1391715-41</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210179973.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f35ca745d0db985343ddbb19d0d27a25a93aa8ea4eb716968995945ad5c93f9c7f6b147db9c153f5633745276e2d1d34ecc963ba211ab4b0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0c3318538ad1a020d11fdfede691b852917fc516f86f694561f76d7bd38477c255f59017ddd150945375502092737687c52bf4756d1e46ad</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>