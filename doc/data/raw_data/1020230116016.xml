<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:17.4117</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0116016</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>동적 제스처 인식 장치 및 방법</inventionTitle><inventionTitleEng>APPARATUS AND METHOD FOR RECOGNIZING DYNAMIC GESTURE</inventionTitleEng><openDate>2025.03.10</openDate><openNumber>10-2025-0033620</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.09.01</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01P 15/18</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 일 실시예에 따르면, 동적 제스처 인식 시스템은 적어도 하나의 센서를 이용하여 사용자의 움직임에 따른 변화를 측정하도록 구성되는 센싱 장치, 및 상기 센싱 장치로부터 수신되는 1차원의 시퀀스 신호를 기반으로 2차원의 이미지를 생성하고, 상기 이미지를 기반으로 인공 신경망을 이용하여 상기 사용자의 동적 제스처(dynamic gesture)를 인식하도록 구성되는 동적 제스처 인식 장치를 포함하되, 상기 인공 신경망은 2D CNN(2 Dimension Convolutional Neural Network)을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 동적 제스처 인식 시스템에 있어서,적어도 하나의 센서를 이용하여 사용자의 움직임에 따른 변화를 측정하도록 구성되는 센싱 장치; 및상기 센싱 장치로부터 수신되는 1차원의 시퀀스 신호를 기반으로 2차원의 이미지를 생성하고, 상기 이미지를 기반으로 인공 신경망을 이용하여 상기 사용자의 동적 제스처(dynamic gesture)를 인식하도록 구성되는 동적 제스처 인식 장치를 포함하되,상기 인공 신경망은,2D CNN(2 Dimension Convolutional Neural Network)를 포함하는, 동적 제스처 인식 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 센싱 장치는,상기 사용자의 움직임에 따른 속도의 변화를 측정하여 가속도 정보를 생성하도록 구성되는 복수개의 가속도 센서들;상기 복수개의 가속도 센서들에서 생성되는 가속도 정보를 다중화하도록 구성되는 다중화기; 및상기 다중화된 정보를 기반으로 상기 시퀀스 신호를 생성하도록 구성되는 제어기를 포함하는, 동적 제스처 인식 시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 동적 제스처 인식 장치는,상기 센싱 장치로부터 상기 시퀀스 신호를 수신하도록 구성되는 통신부;상기 시퀀스 신호에 대해 CWT(Continuous Wavelet Transform) 및 STFT(Short Time Fourier Transform) 중 적어도 하나를 수행하여 상기 시퀀스 신호를 상기 이미지로 변환하도록 구성되는 변환부; 및상기 이미지를 기반으로 상기 인공 신경망을 이용하여 상기 동적 제스처를 예측하도록 구성되는 예측부를 포함하는, 동적 제스처 인식 시스템.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 변환부는,상기 시퀀스 신호의 채널별로 평균값을 계산하고 상기 평균값을 기반으로 상기 CWT 및 상기 STFT 중 적어도 하나를 수행하여 채널별 이미지를 생성하고, 상기 채널별 이미지를 병합하여 상기 복수개의 가속도 센서들에 대한 단일 이미지를 생성하는, 동적 제스처 인식 시스템.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 변환부는,상기 시퀀스 신호의 채널별로 FN(Frobenius Norm) 및 임계값을 적용하여 채널별 이미지를 생성하고, 상기 채널별 이미지를 병합하여 상기 복수개의 가속도 센서들에 대한 단일 이미지를 생성하는, 동적 제스처 인식 시스템.</claim></claimInfo><claimInfo><claim>6. 제3항에 있어서,상기 예측부는,상기 이미지의 크기를 이중선형 보간(bilinear interpolation)을 수행하여 미리 설정된 크기로 조정한 후 전처리하여 상기 인공 신경망에 입력하고, 상기 인공 신경망의 출력값을 분류하여 상기 동적 제스처를 예측하는, 동적 제스처 인식 시스템.</claim></claimInfo><claimInfo><claim>7. 동적 제스처를 인식하는 장치에 있어서,적어도 하나의 센서를 포함하는 센싱 장치로부터 1차원의 시퀀스 신호를 수신하도록 구성되는 통신부;상기 1차원의 시퀀스 신호를 2차원 이미지로 변환하도록 구성되는 변환부; 및상기 2차원 이미지를 기반으로 인공 신경망을 이용하여 동적 제스처(dynamic gesture)를 예측하도록 구성되는 예측부를 포함하되,상기 인공 신경망은,2D CNN(2 Dimension Convolutional Neural Network)을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 시퀀스 신호는,복수개의 가속도 센서들로부터 측정되는 가속도 정보를 기반으로 생성되는, 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 변환부는,상기 시퀀스 신호에 대해 CWT(Continuous Wavelet Transform) 및 STFT(Short Time Fourier Transform) 중 적어도 하나를 수행하여 상기 시퀀스 신호를 상기 이미지로 변환하는, 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 변환부는,상기 시퀀스 신호의 채널별로 평균값을 계산하고 상기 평균값을 기반으로 상기 CWT 및 상기 STFT 중 적어도 하나를 수행하여 채널별 이미지를 생성하고, 상기 채널별 이미지를 병합하여 상기 복수개의 가속도 센서들에 대한 단일 이미지를 생성하는, 장치.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서,상기 변환부는,상기 시퀀스 신호의 채널별로 FN(Frobenius Norm) 및 임계값을 적용하여 채널별 이미지를 생성하고, 상기 채널별 이미지를 병합하여 상기 복수개의 가속도 센서들에 대한 단일 이미지를 생성하는, 장치.</claim></claimInfo><claimInfo><claim>12. 제7항에 있어서,상기 예측부는,상기 이미지의 크기를 이중선형 보간(bilinear interpolation)을 수행하여 미리 설정된 크기로 조정한 후 전처리하여 상기 인공 신경망에 입력하고, 상기 인공 신경망의 출력값을 분류하여 상기 동적 제스처를 예측하는, 장치.</claim></claimInfo><claimInfo><claim>13. 동적 제스처 인식 장치가 동적 제스처를 인식하는 방법에 있어서,적어도 하나의 센서를 포함하는 센싱 장치로부터 1차원의 시퀀스 신호를 수신하는 단계;상기 시퀀스 신호를 기반으로 2차원의 이미지를 생성하는 단계; 및상기 이미지를 기반으로 인공 신경망을 이용하여 동적 제스처(dynamic gesture)를 인식하는 단계를 포함하되,상기 인공 신경망은,2D CNN(2 Dimension Convolutional Neural Network)을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 시퀀스 신호는,복수개의 가속도 센서들로부터 측정되는 가속도 정보를 기반으로 생성되는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 생성하는 단계는,상기 시퀀스 신호에 대해 CWT(Continuous Wavelet Transform) 및 STFT(Short Time Fourier Transform) 중 적어도 하나를 수행하여 상기 시퀀스 신호를 상기 이미지로 변환하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 생성하는 단계는,상기 시퀀스 신호의 채널별로 평균값을 계산하고 상기 평균값을 기반으로 상기 CWT 및 STFT 중 적어도 하나를 수행하여 채널별 이미지를 생성하는 단계; 및상기 채널별 이미지를 병합하여 상기 복수개의 가속도 센서들에 대한 단일 이미지를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 생성하는 단계는,상기 시퀀스 신호의 채널별로 FN(Frobenius Norm) 및 임계값을 적용하여 채널별 이미지를 생성하는 단계; 및상기 채널별 이미지를 병합하여 상기 복수개의 가속도 센서들에 대한 단일 이미지를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서,상기 예측하는 단계는,상기 이미지의 크기를 이중선형 보간(bilinear interpolation)을 수행하여 미리 설정된 크기로 조정한 후 전처리하여 상기 인공 신경망에 입력하는 단계; 및상기 인공 신경망의 출력값을 분류하여 상기 동적 제스처를 예측하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 컴퓨터 판독 가능한 기록매체에 저장되는 컴퓨터 프로그램으로서,상기 컴퓨터 프로그램은, 프로세서에 의해 실행되면,적어도 하나의 센서를 포함하는 센싱 장치로부터 1차원의 시퀀스 신호를 수신하는 단계와,상기 시퀀스 신호를 기반으로 2차원의 이미지를 생성하는 단계와,상기 이미지를 기반으로 인공 신경망을 이용하여 동적 제스처(dynamic gesture)를 인식하는 단계를 포함하는 동적 제스처 인식 방법을 상기 프로세서가 수행하도록 하기 위한 명령어를 포함하되,상기 인공 신경망은,2D CNN(2 Dimension Convolutional Neural Network)을 포함하는, 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 동작구...</address><code>220040385305</code><country>대한민국</country><engName>CHUNG ANG University Industry Academic Cooperation Foundation</engName><name>중앙대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>Seo, Sang Hyun</engName><name>서상현</name></inventorInfo><inventorInfo><address>서울특별시 마포구...</address><code> </code><country> </country><engName>KIM, BUMSOO</engName><name>김범수</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서대문구 경기대로 **,  진양빌딩 *층(충정로*가)</address><code>920191001412</code><country>대한민국</country><engName>WeThePeople IP &amp; Law Firm</engName><name>특허법인위더피플</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.09.01</receiptDate><receiptNumber>1-1-2023-0966981-31</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.09.04</receiptDate><receiptNumber>1-1-2023-0972467-71</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.09.04</receiptDate><receiptNumber>1-1-2023-0977120-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.08.07</receiptDate><receiptNumber>4-1-2024-5236660-34</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.05.15</receiptDate><receiptNumber>4-1-2025-5130684-12</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230116016.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930b842e71cbd0231665f0ab5942f73c56e46052d96857d8f7f7095b8f7d59bd423afea70346a791e0c32bdb726607fc38ed75e921a4b30983</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf884750a544b7f42f2d6b881542c81b56b59664e086a015fe85909dd65746921f35fcffb1f88bc40d69fb9fb7a7ba53e5821e5ee688365cc7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>