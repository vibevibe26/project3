<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:36.5636</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2025.02.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-0021539</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>동영상을 처리하는 방법 및 이를 수행하기 위한 전자 장치</inventionTitle><inventionTitleEng>METHOD FOR PROCESSING VIDEO AND ELECTRONIC DEVICE FOR  PERFORMING THE SAME</inventionTitleEng><openDate>2025.11.06</openDate><openNumber>10-2025-0158631</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/269</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4053</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 제1 프레임 및 제1 프레임과 인접한 제2 프레임을 포함하는 입력 영상을 획득하고, 제1 프레임 및 상기 제2 프레임 간의 모션 정보를 획득하고, 제1 프레임에 대응하는 제1 프레임 특징 및 제2 프레임에 대응하는 제2 프레임 특징을 인공지능 모델에 입력하여, 제1 프레임 특징과 제2 프레임 특징 간의 레지듀얼(residual)에 대응하는 오프셋(offset)을 획득하고, 모션 정보 및 오프셋(offset)에 기초하여, 제2 프레임 특징에서 제1 프레임 특징의 각 픽셀의 위치에 대응하는 각 포인트를 결정하고, 제2 프레임 특징의 각 포인트를 중심으로 한 커널 영역과 제1 프레임 특징의 각 픽셀 간의 유사도를 이용하여, 제1 프레임의 화질을 개선하는 방법이 제공될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치(1000)가 동영상을 처리하는 방법에 있어서,제1 프레임 및 상기 제1 프레임과 인접한 제2 프레임을 포함하는 입력 영상을 획득하는 단계(S210);상기 제1 프레임 및 상기 제2 프레임 간의 모션 정보를 획득하는 단계(S220);상기 제1 프레임에 대응하는 제1 프레임 특징 및 상기 제2 프레임에 대응하는 제2 프레임 특징을 인공지능 모델에 입력하여, 상기 제1 프레임 특징과 상기 제2 프레임 특징 간의 레지듀얼(residual)에 대응하는 오프셋(offset)을 획득하는 단계(S230);상기 모션 정보 및 상기 오프셋(offset)에 기초하여, 상기 제2 프레임 특징에서 상기 제1 프레임 특징의 각 픽셀의 위치에 대응하는 각 포인트를 결정하는 단계(S240); 및상기 제2 프레임 특징의 상기 각 포인트를 중심으로 한 커널 영역과 상기 제1 프레임 특징의 상기 각 픽셀 간의 유사도를 이용하여, 상기 제1 프레임의 화질을 개선하는 단계(S250)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 방법은,상기 제1 프레임 및 상기 제2 프레임 각각으로부터 상기 제1 프레임 특징 및 상기 제2 프레임 특징을 추출하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항 또는 제2 항에 있어서,상기 모션 정보는, 상기 제1 프레임 및 상기 제2 프레임 간의 옵티컬 플로우(optical flow)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1 항 내지 제3 항 중 어느 한 항에 있어서,상기 각 포인트를 결정하는 단계는,상기 모션 정보에 블러(blur) 처리를 수행하는 단계; 및상기 블러(blur) 처리된 모션 정보 및 상기 오프셋(offset)에 기초하여, 상기 제2 프레임 특징에서 상기 제1 프레임 특징의 상기 각 픽셀의 위치에 대응하는 상기 각 포인트를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항 내지 제4 항 중 어느 한 항에 있어서,상기 제1 프레임의 화질을 개선하는 단계는,상기 제1 프레임 특징의 상기 각 픽셀을 쿼리(query)로 이용하고, 상기 제2 프레임 특징의 상기 각 커널 영역을 키(key)로 이용하여, 상기 제2 프레임 특징의 상기 각 커널 영역과 상기 제1 프레임 특징의 상기 각 픽셀 간의 유사도를 결정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 제1 프레임의 화질을 개선하는 단계는,상기 결정된 유사도에 상기 각 커널 영역의 밸류(value)를 적용하여, 상기 제1 프레임 특징에 대해 보정된 값을 획득하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제5 항에 있어서,상기 유사도는, 상기 쿼리(query)와 상기 키(key) 간의 문맥적 유사도(contextual similarity)를 가중치로 표현한 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1 항 내지 제7 항 중 어느 한 항에 있어서,상기 제1 프레임의 화질을 개선하는 단계는,상기 제1 프레임의 화질을 원본 영상의 화질로 복원하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1 항 내지 제8 항 중 어느 한 항에 있어서,상기 제2 프레임 특징에서 상기 제1 프레임 특징의 각 픽셀의 위치에 대응하는 각 포인트를 결정하는 단계는,상기 제2 프레임 특징에서 상기 제1 프레임 특징의 제1 패치(patch)의 위치에 대응하는 적어도 하나의 제2 패치(patch)를 결정하는 단계를 포함하고,상기 제1 프레임의 화질을 개선하는 단계는,상기 적어도 하나의 제2 패치(patch)와 상기 제1 패치(patch) 간의 유사도를 이용하여, 상기 제1 프레임의 화질을 개선하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 한 항에 있어서,상기 방법은,상기 모션 정보 및 상기 오프셋(offset)에 기초하여, 상기 제2 프레임 특징의 키(key) 및 밸류(value)를 상기 제1 프레임 특징의 쿼리(query)에 대응시키는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 동영상을 처리하는 전자 장치에 있어서,프로세싱 회로(processing circuitry)를 포함하는 적어도 하나의 프로세서(1300); 및인스트럭션들을 저장하는 메모리(1700)를 포함하고,상기 인스트럭션들이 상기 적어도 하나의 프로세서(1300)에 의해 개별적으로(individually) 또는 집합적으로(collectively) 실행됨으로써, 상기 전자 장치(1000)는,제1 프레임 및 상기 제1 프레임과 인접한 제2 프레임을 포함하는 입력 영상을 획득하고,상기 제1 프레임 및 상기 제2 프레임 간의 모션 정보를 획득하고,상기 제1 프레임에 대응하는 제1 프레임 특징 및 상기 제2 프레임에 대응하는 제2 프레임 특징을 인공지능 모델에 입력하여, 상기 제1 프레임 특징과 상기 제2 프레임 특징 간의 레지듀얼(residual)에 대응하는 오프셋(offset)을 획득하고,상기 모션 정보 및 상기 오프셋(offset)에 기초하여, 상기 제2 프레임 특징에서 상기 제1 프레임 특징의 각 픽셀의 위치에 대응하는 각 포인트를 결정하고,상기 제2 프레임 특징의 상기 각 포인트를 중심으로 한 커널 영역과 상기 제1 프레임 특징의 상기 각 픽셀 간의 유사도를 이용하여, 상기 제1 프레임의 화질을 개선하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 전자 장치(1000)는,상기 제1 프레임 및 상기 제2 프레임 각각으로부터 상기 제1 프레임 특징 및 상기 제2 프레임 특징을 추출하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>13. 제11 항 또는 제12 항에 있어서,상기 모션 정보는, 상기 제1 프레임 및 상기 제2 프레임 간의 옵티컬 플로우(optical flow) 정보를 포함하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>14. 제11 항 내지 제13 항 중 어느 한 항에 있어서,상기 전자 장치(1000)는,상기 모션 정보에 블러(blur) 처리를 수행하고,상기 블러(blur) 처리된 모션 정보 및 상기 오프셋(offset)에 기초하여, 상기 제2 프레임 특징에서 상기 제1 프레임 특징의 상기 각 픽셀의 위치에 대응하는 상기 각 포인트를 결정하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>15. 제11 항 내지 제14 항 중 어느 한 항에 있어서,상기 전자 장치(1000)는,상기 제1 프레임 특징의 상기 각 픽셀을 쿼리(query)로 이용하고, 상기 제2 프레임 특징의 상기 각 커널 영역을 키(key)로 이용하여, 상기 제1 프레임 특징의 상기 각 픽셀과 상기 제2 프레임 특징의 상기 각 커널 영역 간의 유사도를 결정하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서,상기 전자 장치(1000)는,상기 결정된 유사도에 상기 각 커널 영역의 밸류(value)를 적용하여, 상기 제1 프레임 특징에 대해 보정된 값을 획득하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>17. 제15 항에 있어서,상기 유사도는, 상기 쿼리(query)와 상기 키(key) 간의 문맥적 유사도(contextual similarity)를 가중치로 표현한 것을 포함하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>18. 제11 항 내지 제17 항 중 어느 한 항에 있어서,상기 전자 장치(1000)는,상기 제1 프레임의 화질을 원본 영상의 화질로 복원하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>19. 제11 항 내지 제18 항 중 어느 한 항에 있어서,상기 전자 장치(1000)는,상기 제2 프레임 특징에서 상기 제1 프레임 특징의 제1 패치(patch)의 위치에 대응하는 적어도 하나의 제2 패치(patch)를 결정하고,상기 적어도 하나의 제2 패치(patch)와 상기 제1 패치(patch) 간의 유사도를 이용하여, 상기 제1 프레임의 화질을 개선하는, 전자 장치(1000).</claim></claimInfo><claimInfo><claim>20. 제1 항 내지 제10 항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>PARK, Jae Yeon</engName><name>박재연</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>PARK, Kwan Woo</engName><name>박관우</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>AHN, Il Jun</engName><name>안일준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country>대한민국</country><engName>KIM, Sang Hun</engName><name>김상훈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2024.04.30</priorityApplicationDate><priorityApplicationNumber>1020240058161</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2025.02.19</receiptDate><receiptNumber>1-1-2025-0193150-77</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020250021539.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c939956ce5ed44ff2a32cd5793d58a66a103c4542a4b164d80391e5dc8a6d522a9053ad919d5c26b2ca273f922bbf14bc629544441f53836cb3</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf54055e23745caed2349a44a15c5472860802919421d3e3c0c40f73ea1609e022764fcfdb3073747a14e74c9944c48db30fe54b4eef785132</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>