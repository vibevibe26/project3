<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:26.026</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.09.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0123805</applicationNumber><claimCount>32</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>강화된 시각적 관성 주행 거리 측정을 위한 방법 및 장치</inventionTitle><inventionTitleEng>METHODS AND APPARATI FOR INTENSIFIED VISUAL-INERTIAL  ODOMETRY</inventionTitleEng><openDate>2023.04.04</openDate><openNumber>10-2023-0045587</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.09.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/521</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/141</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01P 15/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 25/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G02B 5/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양상은, 제1 이미지를 수신하고, 제2 이미지를 생성하기 위해 제1 이미지의 광도를 증폭시키고, 제2 이미지를 디지털 방식으로 캡처하고, 제1 이미지를 수신하는 것 또는 제2 이미지를 캡처하는 것과 연관된 제1 시간을 식별하고, 이미징 시스템의 공간 정보를 획득하고, 공간 정보를 획득하는 것과 연관된 제2 시간을 식별하고, 제1 시간이 제2 시간과 실질적으로 동시에 발생하는 것에 기반하여 제2 이미지를 공간 정보와 연관시키고, 그리고 제2 이미지 및 공간 정보에 기반하여 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하기 위한 방법 및 시스템을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미징 시스템에 의해 구현되는 방법으로서,제1 이미지를 수신하는 단계;제2 이미지를 생성하기 위해 상기 제1 이미지의 광도(luminous intensity)를 증폭시키는 단계;상기 제2 이미지를 디지털 방식으로 캡처하는 단계;상기 제1 이미지를 수신하는 단계 또는 상기 제2 이미지를 캡처하는 단계와 동시에, 상기 이미징 시스템의 공간 정보를 획득하는 단계;상기 제2 이미지를 상기 공간 정보와 연관시키는 단계; 및 상기 제2 이미지 및 상기 공간 정보에 기반하여 상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하는 단계를 포함하는,이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 광도를 증폭시키는 단계 전에 상기 제1 이미지와 연관된 광을 시준하는 단계를 더 포함하는,이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 제2 이미지를 디지털 방식으로 캡처하는 단계 전에 상기 제2 이미지를 포커싱하는 단계를 더 포함하는,이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제1 이미지를 수신하는 단계 또는 상기 제2 이미지를 캡처하는 단계와 연관된 제1 시간을 식별하는 단계;상기 공간 정보를 획득하는 단계와 연관된 제2 시간을 식별하는 단계;상기 제1 시간을 표시하는 제1 타임 스탬프를 상기 제1 이미지 또는 상기 제2 이미지에 첨부하는 단계; 및 상기 제2 시간을 표시하는 제2 타임 스탬프를 상기 공간 정보에 첨부하는 단계를 더 포함하며,상기 제2 이미지를 상기 공간 정보와 연관시키는 단계는, 상기 제1 시간이 상기 제2 시간과 실질적으로 동시에 발생하는 것에 기반하여 상기 제2 이미지를 상기 공간 정보와 연관시키는 단계를 포함하는,이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 이미징 시스템을 둘러싸는 환경의 포인트의 3-차원 위치를 결정하는 단계를 더 포함하는, 이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하는 단계는, 동시 로컬화 및 맵핑 알고리즘, 시각적 주행 거리 측정 알고리즘 또는 시각적 관성 주행 거리 측정 알고리즘 중 하나 이상을 사용하여 생성하는 단계를 포함하는, 이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 공간 정보를 수신하는 것은, 상기 이미징 시스템의 선속도, 상기 이미징 시스템의 각속도, 상기 이미징 시스템의 선가속도, 상기 이미징 시스템의 각가속도, 자기장 또는 자기 쌍극자 모멘트 중 하나 이상을 측정하는 것을 포함하는, 이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제1 이미지와 연관된 제3 이미지를 수신하는 단계;제4 이미지를 생성하기 위해 상기 제3 이미지의 제2 광도를 증폭시키는 단계;상기 제4 이미지를 디지털 방식으로 캡처하는 단계; 상기 제3 이미지를 수신하는 단계 또는 상기 제4 이미지를 캡처하는 단계와 동시에, 상기 이미징 시스템의 추가 공간 정보를 획득하는 단계 —상기 공간 정보와 상기 추가 공간 정보는 동일하거나 또는 상이함—; 및 상기 제4 이미지를 상기 추가 공간 정보와 연관시키는 단계를 더 포함하며,상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하는 단계는, 상기 제2 이미지, 상기 제4 이미지, 상기 공간 정보 및 상기 추가 공간 정보에 기반하여 생성하는 단계를 포함하는,이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 이미지와 연관된 제1 복수의 이미지를 수신하는 단계;제2 복수의 이미지를 생성하기 위해 상기 제1 복수의 이미지의 복수의 광도를 증폭시키는 단계;상기 제2 복수의 이미지를 디지털 방식으로 캡처하는 단계; 상기 제1 복수의 이미지를 수신하는 단계 또는 상기 제2 복수의 이미지를 캡처하는 단계와 동시에, 상기 이미징 시스템의 추가 공간 정보를 획득하는 단계 —상기 공간 정보와 상기 추가 공간 정보는 동일하거나 또는 상이함—; 및 상기 제2 복수의 이미지를 상기 추가 공간 정보와 연관시키는 단계를 더 포함하며,상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하는 단계는, 상기 제2 이미지, 상기 제2 복수의 이미지, 상기 공간 정보 및 상기 추가 공간 정보에 기반하여 생성하는 단계를 포함하는,이미징 시스템에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>10. 이미징 시스템으로서, 제1 이미지를 수신하고; 그리고 제2 이미지를 생성하기 위해 상기 제1 이미지의 광도를 증폭시키도록 구성된 증배기(multiplier);상기 제2 이미지를 디지털 방식으로 캡처하도록 구성된 이미지 센서;상기 제1 이미지를 수신하는 것 또는 상기 제2 이미지를 캡처하는 것과 동시에, 상기 이미징 시스템의 공간 정보를 획득하도록 구성된 관성 측정 유닛;명령을 저장하는 메모리; 및 상기 제2 이미지를 상기 공간 정보와 연관시키고; 그리고 상기 제2 이미지 및 상기 공간 정보에 기반하여 상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하기 위해 상기 명령을 실행하도록 구성된 프로세서를 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 광도를 증폭시키기 전에 상기 제1 이미지와 연관된 광을 시준하도록 구성된 제1 광학 필터를 더 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제2 이미지를 디지털 방식으로 캡처하기 전에 상기 제2 이미지를 포커싱하도록 구성된 제2 광학 필터를 더 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,상기 프로세서는 추가로,상기 제1 이미지를 수신하는 것 또는 상기 제2 이미지를 캡처하는 것과 연관된 제1 시간을 식별하고;상기 공간 정보를 획득하는 것과 연관된 제2 시간을 식별하고;상기 제1 시간을 표시하는 제1 타임 스탬프를 상기 제1 이미지 또는 상기 제2 이미지에 첨부하고; 그리고 상기 제2 시간을 표시하는 제2 타임 스탬프를 상기 공간 정보에 첨부하도록 구성되며,상기 제2 이미지를 상기 공간 정보와 연관시키는 것은, 상기 제1 시간이 상기 제2 시간과 실질적으로 동시에 발생하는 것에 기반하여 상기 제2 이미지를 상기 공간 정보와 연관시키는 것을 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서, 상기 프로세서는 추가로, 상기 이미징 시스템을 둘러싸는 환경의 포인트의 3-차원 위치를 결정하도록 구성되는, 이미징 시스템.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서, 상기 프로세서는 추가로, 동시 로컬화 및 맵핑 알고리즘, 시각적 주행 거리 측정 알고리즘 또는 시각적 관성 주행 거리 측정 알고리즘 중 하나 이상을 사용하여 상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하도록 구성되는, 이미징 시스템.</claim></claimInfo><claimInfo><claim>16. 제10항에 있어서, 상기 프로세서는 추가로, 상기 이미징 시스템의 선속도, 상기 이미징 시스템의 각속도, 상기 이미징 시스템의 선가속도, 상기 이미징 시스템의 각가속도, 자기장 또는 자기 쌍극자 모멘트 중 하나 이상을 측정함으로써 상기 공간 정보를 수신하도록 구성되는, 이미징 시스템.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서,상기 프로세서는 추가로,상기 제1 이미지와 연관된 제3 이미지를 수신하고;제4 이미지를 생성하기 위해 상기 제3 이미지의 제2 광도를 증폭시키고;상기 제4 이미지를 디지털 방식으로 캡처하고; 상기 제3 이미지를 수신하는 것 또는 상기 제4 이미지를 캡처하는 것과 동시에, 상기 이미징 시스템의 추가 공간 정보를 획득하고 —상기 공간 정보와 상기 추가 공간 정보는 동일하거나 또는 상이함—; 그리고 상기 제4 이미지를 상기 추가 공간 정보와 연관시키도록 구성되며,상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하는 것은, 상기 제2 이미지, 상기 제4 이미지, 상기 공간 정보 및 상기 추가 공간 정보에 기반하여 생성하는 것을 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>18. 제10항에 있어서,상기 프로세서는 추가로,상기 제1 이미지와 연관된 제1 복수의 이미지를 수신하고;제2 복수의 이미지를 생성하기 위해 상기 제1 복수의 이미지의 복수의 광도를 증폭시키고;상기 제2 복수의 이미지를 디지털 방식으로 캡처하고; 상기 제1 복수의 이미지를 수신하는 것 또는 상기 제2 복수의 이미지를 캡처하는 것과 동시에, 상기 이미징 시스템의 추가 공간 정보를 획득하고 —상기 공간 정보와 상기 추가 공간 정보는 동일하거나 또는 상이함—; 그리고 상기 제2 복수의 이미지를 상기 추가 공간 정보와 연관시키도록 구성되며,상기 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하는 것은, 상기 제2 이미지, 상기 제2 복수의 이미지, 상기 공간 정보 및 상기 추가 공간 정보에 기반하여 생성하는 것을 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>19. 제10항에 있어서, 상기 관성 측정 유닛은 적어도 하나 이상의 가속도계, 자이로스코프 및/또는 자력계를 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>20. 제10항에 있어서, 상기 이미지 센서는 CCD(charged coupled device) 센서 또는 CMOS(complimentary metal-oxide-semiconductor) 센서를 포함하는, 이미징 시스템.</claim></claimInfo><claimInfo><claim>21. 제10항에 있어서, 상기 증배기는 강화기 튜브, 광음극, 광전자 증배기, 애벌랜치(avalanche) 광다이오드 또는 양자 우물(quantum well) 다이오드를 포함하는,이미징 시스템.</claim></claimInfo><claimInfo><claim>22. 나이트 비전 헬멧으로서, 제1 이미지를 수신하고; 그리고 제2 이미지를 생성하기 위해 상기 제1 이미지의 제1 광도를 증폭시키도록 구성된 제1 증배기;상기 제2 이미지를 디지털 방식으로 캡처하도록 구성된 제1 이미지 센서; 상기 제1 이미지를 수신하는 것과 동시에 제3 이미지를 수신하고; 그리고 제4 이미지를 생성하기 위해 상기 제3 이미지의 제2 광도를 증폭시키도록 구성된제2 증배기;상기 제4 이미지를 디지털 방식으로 캡처하도록 구성된 제2 이미지 센서;상기 제1 이미지를 수신하는 것 또는 상기 제2 이미지를 캡처하는 것과 동시에, 상기 나이트 비전 헬멧의 공간 정보를 획득하도록 구성된 관성 측정 유닛;명령을 저장하는 메모리;  상기 제2 이미지 및 상기 제4 이미지를 상기 공간 정보와 연관시키고; 그리고 상기 제2 이미지, 상기 제4 이미지 및 상기 공간 정보에 기반하여 상기 나이트 비전 헬멧의 포지션 또는 배향 중 적어도 하나를 생성하기 위해 상기 명령을 실행하도록 구성된 프로세서; 및상기 나이트 비전 헬멧의 포지션 또는 배향 중 적어도 하나, 제2 이미지 또는 제4 이미지 중 적어도 하나를 디스플레이하도록 구성된 디스플레이를 포함하는,나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 제1 광도를 증폭시키기 전에 상기 제1 이미지와 연관된 광을 시준하도록 구성된 제1 광학 필터; 및 상기 제2 광도를 증폭시키기 전에 상기 제3 이미지와 연관된 광을 시준하도록 구성된 제2 광학 필터를 더 포함하는,나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 제2 이미지를 디지털 방식으로 캡처하기 전에 상기 제2 이미지를 포커싱하도록 구성된 제3 광학 필터; 및 상기 제4 이미지를 디지털 방식으로 캡처하기 전에 상기 제4 이미지를 포커싱하도록 구성된 제4 광학 필터를 더 포함하는,나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>25. 제22항에 있어서,상기 프로세서는 추가로,상기 제1 이미지를 수신하는 것 또는 상기 제2 이미지를 캡처하는 것과 연관된 제1 시간을 식별하고;상기 제3 이미지를 수신하는 것 또는 상기 제4 이미지를 캡처하는 것과 연관된 제2 시간을 식별하고;상기 공간 정보를 획득하는 것과 연관된 제3 시간을 식별하고;상기 제1 시간을 표시하는 제1 타임 스탬프를 상기 제1 이미지, 상기 제2 이미지, 상기 제3 이미지 또는 상기 제4 이미지 중 적어도 하나에 첨부하고; 그리고 상기 제3 시간을 표시하는 제2 타임 스탬프를 상기 공간 정보에 첨부하도록 구성되며,상기 제2 이미지 및 상기 제4 이미지를 상기 공간 정보와 연관시키는 것은, 상기 제1 시간 및 상기 제2 시간이 상기 제3 시간과 실질적으로 동시에 발생하는 것에 기반하여 상기 제2 이미지 및 상기 제4 이미지를 상기 공간 정보와 연관시키는 것을 포함하는,나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>26. 제22항에 있어서, 상기 프로세서는 추가로, 이미징 시스템을 둘러싸는 환경의 포인트의 3-차원 위치를 결정하도록 구성되는, 나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>27. 제22항에 있어서, 상기 프로세서는 추가로, 동시 로컬화 및 맵핑 알고리즘, 시각적 주행 거리 측정 알고리즘 또는 시각적 관성 주행 거리 측정 알고리즘 중 하나 이상을 사용하여 이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하도록 구성되는, 나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>28. 제22항에 있어서, 상기 프로세서는 추가로, 이미징 시스템의 선속도, 상기 이미징 시스템의 각속도, 상기 이미징 시스템의 선가속도, 상기 이미징 시스템의 각가속도, 자기장 또는 자기 쌍극자 모멘트 중 하나 이상을 측정함으로써 상기 공간 정보를 수신하도록 구성되는, 나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>29. 제22항에 있어서,상기 프로세서는 추가로,상기 제1 이미지와 연관된 제1 복수의 이미지를 수신하고;제2 복수의 이미지를 생성하기 위해 상기 제1 복수의 이미지의 복수의 광도를 증폭시키고;상기 제2 복수의 이미지를 디지털 방식으로 캡처하고; 상기 제1 복수의 이미지를 수신하는 것 또는 상기 제2 복수의 이미지를 캡처하는 것과 동시에, 상기 나이트 비전 헬멧의 추가 공간 정보를 획득하고 —상기 공간 정보와 상기 추가 공간 정보는 동일하거나 또는 상이함—; 그리고 상기 제2 복수의 이미지를 상기 추가 공간 정보와 연관시키도록 구성되며,이미징 시스템의 포지션 또는 배향 중 적어도 하나를 생성하는 것은, 상기 제2 이미지, 상기 제2 복수의 이미지, 상기 공간 정보 및 상기 추가 공간 정보에 기반하여 생성하는 것을 포함하는,나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>30. 제22항에 있어서, 상기 관성 측정 유닛은 적어도 하나 이상의 가속도계, 자이로스코프 및/또는 자력계를 포함하는,나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>31. 제22항에 있어서, 상기 이미지 센서는 CCD(charged coupled device) 센서 또는 CMOS(complimentary metal-oxide-semiconductor) 센서를 포함하는, 나이트 비전 헬멧.</claim></claimInfo><claimInfo><claim>32. 제22항에 있어서, 상기 증배기는 강화기 튜브, 광음극, 광전자 증배기, 애벌랜치 광다이오드 또는 양자 우물 다이오드를 포함하는,나이트 비전 헬멧.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 메릴랜드 클라크스버그 게이트웨이 센터 드라이브 *****</address><code>520180272385</code><country>미국</country><engName>THALES DEFENSE &amp; SECURITY, INC.</engName><name>탈레스 디펜스 앤드 시큐리티, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국, 엠에이 ****...</address><code> </code><country> </country><engName>RICHARD, MADISON</engName><name>리처드, 메디슨</name></inventorInfo><inventorInfo><address>미국, 엠에이 *****...</address><code> </code><country> </country><engName>OLEGS, MISE</engName><name>올레그, 마이즈</name></inventorInfo><inventorInfo><address>미국, 엔에이치 **...</address><code> </code><country> </country><engName>BRIAN, HAIGHT</engName><name>브라이언, 헤이트</name></inventorInfo><inventorInfo><address>미국, 아이엘 *****,...</address><code> </code><country> </country><engName>ROBERT, ATAC</engName><name>로버트, 애택</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 영동대로 *** (삼성동) **층 ****,****,****호(국제특허바른)</address><code>919980001635</code><country>대한민국</country><engName>Ho-Hyun Nahm</engName><name>남호현</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.26</priorityApplicationDate><priorityApplicationNumber>17/935,383</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.09.28</priorityApplicationDate><priorityApplicationNumber>63/249,379</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.09.28</receiptDate><receiptNumber>1-1-2022-1025353-18</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName> </documentEngName><documentName>외국어특허출원의 국어번역문 제출 안내서</documentName><receiptDate>2022.10.07</receiptDate><receiptNumber>1-5-2022-0149693-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2022.10.07</receiptDate><receiptNumber>1-5-2022-0149691-68</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장 증명서류 제출기한 안내문</documentName><receiptDate>2022.10.07</receiptDate><receiptNumber>1-5-2022-0149692-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName> </documentEngName><documentName>[특허법 제42조의3제2항,제42조의3제3항에 따른 국어번역문]서류제출서</documentName><receiptDate>2022.10.31</receiptDate><receiptNumber>1-1-2022-1150036-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2022.10.31</receiptDate><receiptNumber>1-1-2022-1150010-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName> </documentEngName><documentName>[명세서등보정서(외국어출원의요약서보정)]보정서</documentName><receiptDate>2022.10.31</receiptDate><receiptNumber>1-1-2022-1150018-26</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2022.10.31</receiptDate><receiptNumber>1-1-2022-1150027-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.11.09</receiptDate><receiptNumber>9-1-2022-9012854-49</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.11.17</receiptDate><receiptNumber>9-1-2022-9013203-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.09.02</receiptDate><receiptNumber>1-1-2025-1005953-37</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220123805.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930e6a7ffeb6727e989922f9ba09bb9b56b256e3281ab2282e854aa1152081aef94909f9d58e0ed8d7799a025686f3a76cd500ed44af5f381e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf46a557639437e7b851211aa42c6cd6fd770247297660d116ce58c345d6b88da070468773d1c0e273c645ff42b61f5b71bb0e2b5517a5f277</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>