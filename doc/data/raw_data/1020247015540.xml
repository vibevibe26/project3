<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:12.112</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7015540</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>디지털 신호 프로세서 기반 연속 대화</inventionTitle><inventionTitleEng>DIGITAL SIGNAL PROCESSOR-BASED CONTINUED CONVERSATION</inventionTitleEng><openDate>2024.06.21</openDate><openNumber>10-2024-0090400</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.05.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.05.09</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/78</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/9032</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 15/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법(600)은 올웨이즈-온 제1 프로세서(200)에게 후속 쿼리 검출 모드(220)에서 동작하도록 지시하는 단계, 및 올웨이즈-온 제1 프로세서가 후속 쿼리 검출 모드에서 동작하는 동안: 어시스턴트 지원 디바이스(102)에 의해 캡처된 후속 오디오 데이터(127)를 수신하는 단계; 올웨이즈-온 제1 프로세서 상에서 실행되는 목소리 활동 검출(VAD) 모델(222)을 사용하여, VAD 모델이 후속 오디오 데이터에서 목소리 활동을 검출하는지 여부를 결정하는 단계; 올웨이즈-온 제1 프로세서 상에서 실행되는 화자 식별(SID) 모델(410)을 사용하여, 후속 오디오 데이터가 동일 사용자에 의해 말해진 발화를 포함하는지를 결정하기 위해 후속 오디오 데이터에 대한 화자 검증을 수행하는 단계를 포함한다. 방법은 또한 발화가 후속 쿼리(129)를 포함하는지를 결정하기 위해 제2 프로세서(300)에서 웨이크업 프로세스를 개시하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.04.20</internationOpenDate><internationOpenNumber>WO2023063965</internationOpenNumber><internationalApplicationDate>2021.12.15</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/063470</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 어시스턴트 지원 디바이스(assistant-enabled device)(AED)(102)의 데이터 프로세싱 하드웨어(103) 상에서 실행될 때 상기 데이터 프로세싱 하드웨어(103)로 하여금 동작들을 수행하게 하는 컴퓨터로 구현되는 방법(computer-implemented method)으로서, 상기 동작들은상기 AED(102)의 사용자(10)에 의해 디지털 어시스턴트(109)에 제출된 초기 쿼리(117)에 대한 응답(192)을 수신하는 것에 응답하여, 상기 데이터 프로세싱 하드웨어(103)의 올웨이즈-온 제1 프로세서(always-on first processor)(200)에게 후속 쿼리 검출 모드(220)에서 동작하도록 지시하는 동작; 및상기 올웨이즈-온 제1 프로세서(200)가 상기 후속 쿼리 검출 모드(220)에서 동작하는 동안: 상기 올웨이즈-온 제1 프로세서(200)에서, 상기 AED(102)의 환경에서 상기 AED(102)에 의해 캡처된 후속 오디오 데이터(127)를 수신하는 동작; 상기 올웨이즈-온 제1 프로세서(200) 상에서 실행되는 목소리 활동 검출(voice activity detection)(VAD) 모델(222)을 사용하여, 상기 VAD 모델(222)이 상기 후속 오디오 데이터(127)에서 목소리 활동을 검출하는지 여부를 결정하는 동작; 상기 올웨이즈-온 제1 프로세서(200) 상에서 실행되는 화자 식별(speaker identification)(SID) 모델(410)을 사용하여, 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 상기 디지털 어시스턴트(109)에 제출한 동일 사용자(10)에 의해 말해진 발화(utterance)를 포함하는지를 결정하기 위해 상기 후속 오디오 데이터(127)에 대한 화자 검증을 수행하는 동작; 및 상기 VAD 모델(222)이 상기 후속 오디오 데이터(127)에서 목소리 활동을 검출하고 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 발화를 포함할 때, 상기 발화가 상기 디지털 어시스턴트(109)를 향한 후속 쿼리(129)를 포함하는지를 결정하기 위해 상기 데이터 프로세싱 하드웨어(103)의 제2 프로세서(300)에서 웨이크업 프로세스를 개시하는 동작을 포함하는, 컴퓨터로 구현되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 데이터 프로세싱 하드웨어(103)의 올웨이즈-온 제1 프로세서(200)에게 후속 쿼리 검출 모드(220)에서 동작하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 후속 쿼리 검출 모드(220)에서의 동작 동안 상기 올웨이즈-온 제1 프로세서(200) 상에서 상기 VAD 및 SID 모델들(222, 410)의 실행을 개시하게 하는, 컴퓨터로 구현되는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 데이터 프로세싱 하드웨어(103)의 올웨이즈-온 제1 프로세서(200)에게 후속 쿼리 검출 모드(220)에서 동작하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 후속 쿼리 검출 모드(220)에서의 동작 동안 핫워드 검출 모델(212)을 디스에이블하게 하는, 컴퓨터로 구현되는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제2 프로세서(300)에서 웨이크업 프로세스를 개시하는 동작은 상기 제2 프로세서(300)로 하여금:상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 상기 발화의 트랜스크립션(transcription)을 생성하기 위해 상기 후속 오디오 데이터(127)를 프로세싱하는 동작; 및상기 발화가 상기 디지털 어시스턴트(109)를 향한 상기 후속 쿼리(129)를 포함하는지 여부를 결정하기 위해 상기 트랜스크립션에 대한 쿼리 해석을 수행하는 동작을 포함하는 동작들을 수행하게 하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 동작들은, 상기 발화가 상기 디지털 어시스턴트(109)를 향한 상기 후속 쿼리(129)를 포함할 때:상기 후속 쿼리(129)에 의해 지정된 동작을 수행하도록 상기 디지털 어시스턴트(109)에게 지시하는 동작;상기 디지털 어시스턴트(109)로부터, 상기 후속 쿼리(129)에 의해 지정된 동작의 수행을 나타내는 후속 응답(193)을 수신하는 동작; 및상기 AED(102)로부터의 출력을 위해 상기 후속 응답(193)을 제시하는 동작을 더 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 제2 프로세서(300)에서 웨이크업 프로세스를 개시하는 동작은 상기 제2 프로세서(300)로 하여금 상기 후속 오디오 데이터(127)를 네트워크를 통해 원격 서버에 송신하게 하고, 상기 원격 서버에 의해 수신될 때의 상기 후속 오디오 데이터(127)는 상기 원격 서버(110)로 하여금:상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 상기 발화의 트랜스크립션을 생성하기 위해 상기 후속 오디오 데이터(127)를 프로세싱하는 동작;상기 발화가 상기 디지털 어시스턴트(109)를 향한 후속 쿼리(129)를 포함하는지 여부를 결정하기 위해 상기 트랜스크립션에 대한 쿼리 해석을 수행하는 동작; 및상기 발화가 상기 디지털 어시스턴트(109)를 향한 후속 쿼리(129)를 포함할 때, 상기 후속 쿼리(129)에 의해 지정된 동작을 수행하도록 상기 디지털 어시스턴트(109)에게 지시하는 동작을 포함하는 동작들을 수행하게 하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 동작들은 상기 후속 쿼리(129)에 의해 지정된 동작을 수행하도록 상기 디지털 어시스턴트(109)에게 지시한 후에:상기 디지털 어시스턴트(109)로부터, 상기 후속 쿼리(129)에 의해 지정된 동작의 수행을 나타내는 후속 응답(193)을 수신하는 동작; 및상기 AED(102)로부터의 출력을 위해 상기 후속 응답(193)을 제시하는 동작을 더 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 동작들은:상기 사용자(10)에 의해 말해지고 상기 디지털 어시스턴트(109)에 제출된 초기 쿼리(117)에 대응하는 초기 오디오 데이터(120)를 수신한 후:상기 초기 오디오 데이터(120)로부터, 상기 사용자(10)에 의해 말해진 상기 초기 쿼리(117)의 특성들을 나타내는 제1 화자 구별 벡터(speaker-discriminative vector)(411)를 추출하는 동작을 더 포함하고, 상기 후속 오디오 데이터(127)에 대한 화자 검증을 수행하는 동작은:상기 후속 오디오 데이터(127)로부터, 상기 SID 모델을 이용하여, 상기 후속 오디오 데이터(127)의 특성들을 나타내는 제1 화자 구별 벡터(412)를 추출하는 동작; 및상기 제1 화자 구별 벡터(411)가 상기 제1 화자 구별 벡터(412)와 일치할 때, 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 상기 디지털 어시스턴트(109)에 제출한 동일 사용자(10)에 의해 말해진 발화를 포함한다고 결정하는 동작을 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 동작들은 사용자(10)에 의해 말해지고 상기 디지털 어시스턴트(109)에 제출된 초기 쿼리(117)에 대응하는 초기 오디오 데이터(120)를 수신한 후:상기 초기 오디오 데이터(120)로부터, 상기 사용자(10)에 의해 말해진 상기 초기 쿼리(117)의 특성들을 나타내는 제1 화자 구별 벡터(411)를 추출하는 동작;상기 제1 화자 구별 벡터(411)가 상기 AED(102)에 저장된 임의의 등록된 화자 벡터들과 일치하는지를 결정하는 동작 - 각각의 등록된 화자 벡터는 상기 AED(102)의 상이한 각자의 등록된 사용자(10)에 연관됨 -; 및상기 제1 화자 구별 벡터(411)가 상기 등록된 화자 벡터들 중 하나와 일치할 때, 상기 초기 쿼리(117)를 말한 사용자(10)를, 상기 제1 화자 구별 벡터(411)와 일치하는 상기 등록된 화자 벡터들 중 하나에 연관된 각자의 등록된 사용자(10)로서 식별하는 동작을 더 포함하고, 상기 후속 오디오 데이터(127)에 대한 화자 검증을 수행하는 동작은:상기 후속 오디오 데이터(127)로부터, 상기 SID 모델을 이용하여, 상기 후속 오디오 데이터(127)의 특성들을 나타내는 제1 화자 구별 벡터(412)를 추출하는 동작; 및상기 제1 화자 구별 벡터(412)가 상기 초기 쿼리(117)를 말한 각자의 등록된 사용자(10)에 연관된 상기 등록된 화자 벡터들 중 하나와 일치할 때, 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 상기 디지털 어시스턴트(109)에 제출한 동일 사용자(10)에 의해 말해진 발화를 포함한다고 결정하는 동작을 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 SID 모델은 상기 후속 오디오 데이터(127)로부터 텍스트-독립적 화자 구별 벡터(text-independent speaker-discriminative vector)를 추출하도록 구성된 텍스트-독립적 SID 모델을 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 동작들은 상기 VAD 모델(222)이 상기 후속 오디오 데이터(127)에서 목소리 활동을 검출하지 못한다는 것, 또는 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 발화를 포함하지 못한다는 것 중 적어도 하나를 결정하는 것에 응답하여, 상기 올웨이즈-온 제1 프로세서(200)에게 상기 후속 쿼리 검출 모드(220)에서의 동작을 중단하고 핫워드 검출 모드(210)에서의 동작을 시작하도록 지시하는 동작을 더 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 올웨이즈-온 제1 프로세서(200)에게 상기 후속 쿼리 검출 모드(220)에서의 동작을 중단하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 올웨이즈-온 제1 프로세서(200) 상에서의 상기 VAD 및 SID 모델들(222, 410)의 실행을 디스에이블 또는 비활성화하게 하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>13. 제11항 또는 제12항에 있어서, 상기 올웨이즈-온 제1 프로세서(200)에게 핫워드 검출 모드(210)에서의 동작을 시작하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 올웨이즈-온 제1 프로세서(200) 상에서의 핫워드 검출 모델(212)의 실행을 개시하게 하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 상기 올웨이즈-온 제1 프로세서(200)는 디지털 신호 프로세서(digital signal processor)(DSP)를 포함하고; 상기 제2 프로세서(300)는 애플리케이션 프로세서를 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 AED(102)는 상기 초기 쿼리(117)에 대응하는 초기 오디오 데이터(120) 및 상기 후속 오디오 데이터(127)를 캡처하도록 구성된 상기 하나 이상의 마이크로폰과 통신하는 배터리 구동 디바이스를 포함하는, 컴퓨터로 구현되는 방법(600).</claim></claimInfo><claimInfo><claim>16. 어시스턴트 지원 디바이스(AED)(102)로서,데이터 프로세싱 하드웨어(103); 및상기 데이터 프로세싱 하드웨어(103)와 통신하고, 상기 데이터 프로세싱 하드웨어(103) 상에서 실행될 때 상기 데이터 프로세싱 하드웨어(103)로 하여금 동작들을 수행하게 하는 명령어들을 저장하는 메모리 하드웨어(105)를 포함하고, 상기 동작들은:상기 AED(102)의 사용자(10)에 의해 디지털 어시스턴트(109)에 제출된 초기 쿼리(117)에 대한 응답(192)을 수신하는 것에 응답하여, 상기 데이터 프로세싱 하드웨어(103)의 올웨이즈-온 제1 프로세서(200)에게 후속 쿼리 검출 모드(220)에서 동작하도록 지시하는 동작; 및상기 올웨이즈-온 제1 프로세서(200)가 상기 후속 쿼리 검출 모드(220)에서 동작하는 동안: 상기 올웨이즈-온 제1 프로세서(200)에서, 상기 AED(102)의 환경에서 상기 AED(102)에 의해 캡처된 후속 오디오 데이터(127)를 수신하는 동작; 상기 올웨이즈-온 제1 프로세서(200) 상에서 실행되는 목소리 활동 검출(VAD) 모델을 사용하여, 상기 VAD 모델(222)이 상기 후속 오디오 데이터(127)에서 목소리 활동을 검출하는지 여부를 결정하는 동작; 상기 올웨이즈-온 제1 프로세서(200) 상에서 실행되는 화자 식별(SID) 모델(410)을 사용하여, 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 상기 디지털 어시스턴트(109)에 제출한 동일 사용자(10)에 의해 말해진 발화를 포함하는지를 결정하기 위해 상기 후속 오디오 데이터(127)에 대한 화자 검증을 수행하는 동작; 및 상기 VAD 모델(222)이 상기 후속 오디오 데이터(127)에서 목소리 활동을 검출하고 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 발화를 포함할 때, 상기 발화가 상기 디지털 어시스턴트(109)를 향한 후속 쿼리(129)를 포함하는지를 결정하기 위해 상기 데이터 프로세싱 하드웨어(103)의 제2 프로세서(300)에서 웨이크업 프로세스를 개시하는 동작을 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 데이터 프로세싱 하드웨어(103)의 올웨이즈-온 제1 프로세서(200)에게 후속 쿼리 검출 모드(220)에서 동작하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 후속 쿼리 검출 모드(220)에서의 동작 동안 상기 올웨이즈-온 제1 프로세서(200) 상에서 상기 VAD 및 SID 모델들(222, 410)의 실행을 개시하게 하는, AED(102).</claim></claimInfo><claimInfo><claim>18. 제16항 또는 제17항에 있어서, 상기 데이터 프로세싱 하드웨어(103)의 올웨이즈-온 제1 프로세서(200)에게 후속 쿼리 검출 모드(220)에서 동작하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 후속 쿼리 검출 모드(220)에서의 동작 동안 핫워드 검출 모델(212)을 디스에이블하게 하는, AED(102).</claim></claimInfo><claimInfo><claim>19. 제16항 내지 제18항 중 어느 한 항에 있어서, 상기 제2 프로세서(300)에서 웨이크업 프로세스를 개시하는 동작은 상기 제2 프로세서(300)로 하여금:상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 상기 발화의 트랜스크립션을 생성하기 위해 상기 후속 오디오 데이터(127)를 프로세싱하는 동작; 및상기 발화가 상기 디지털 어시스턴트(109)를 향한 상기 후속 쿼리(129)를 포함하는지 여부를 결정하기 위해 상기 트랜스크립션에 대한 쿼리 해석을 수행하는 동작을 포함하는 동작들을 수행하게 하는, AED(102).</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 동작들은, 상기 발화가 상기 디지털 어시스턴트(109)를 향한 상기 후속 쿼리(129)를 포함할 때:상기 후속 쿼리(129)에 의해 지정된 동작을 수행하도록 상기 디지털 어시스턴트(109)에게 지시하는 동작;상기 디지털 어시스턴트(109)로부터, 상기 후속 쿼리(129)에 의해 지정된 동작의 수행을 나타내는 후속 응답(193)을 수신하는 동작; 및상기 AED(102)로부터의 출력을 위해 상기 후속 응답(193)을 제시하는 동작을 더 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>21. 제16항 내지 제18항 중 어느 한 항에 있어서, 상기 제2 프로세서(300)에서 웨이크업 프로세스를 개시하는 동작은 상기 제2 프로세서(300)로 하여금 상기 후속 오디오 데이터(127)를 네트워크를 통해 원격 서버에 송신하게 하고, 상기 원격 서버에 의해 수신될 때의 상기 후속 오디오 데이터(127)는 상기 원격 서버로 하여금:상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 상기 발화의 트랜스크립션을 생성하기 위해 상기 후속 오디오 데이터(127)를 프로세싱하는 동작;상기 발화가 상기 디지털 어시스턴트(109)를 향한 후속 쿼리(129)를 포함하는지 여부를 결정하기 위해 상기 트랜스크립션에 대한 쿼리 해석을 수행하는 동작; 및상기 발화가 상기 디지털 어시스턴트(109)를 향한 후속 쿼리(129)를 포함할 때, 상기 후속 쿼리(129)에 의해 지정된 동작을 수행하도록 상기 디지털 어시스턴트(109)에게 지시하는 동작을 포함하는 동작들을 수행하게 하는, AED(102).</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 동작들은 상기 후속 쿼리(129)에 의해 지정된 동작을 수행하도록 상기 디지털 어시스턴트(109)에게 지시한 후에:상기 디지털 어시스턴트(109)로부터, 상기 후속 쿼리(129)에 의해 지정된 동작의 수행을 나타내는 후속 응답(193)을 수신하는 동작; 및상기 AED(102)로부터의 출력을 위해 상기 후속 응답(193)을 제시하는 동작을 더 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>23. 제16항 내지 제22항 중 어느 한 항에 있어서, 상기 동작들은:상기 사용자(10)에 의해 말해지고 상기 디지털 어시스턴트(109)에 제출된 초기 쿼리(117)에 대응하는 초기 오디오 데이터(120)를 수신한 후:상기 초기 오디오 데이터(120)로부터, 상기 사용자(10)에 의해 말해진 상기 초기 쿼리(117)의 특성들을 나타내는 제1 화자 구별 벡터(411)를 추출하는 동작을 더 포함하고, 상기 후속 오디오 데이터(127)에 대한 화자 검증을 수행하는 동작은:상기 후속 오디오 데이터(127)로부터, 상기 SID 모델을 이용하여, 상기 후속 오디오 데이터(127)의 특성들을 나타내는 제1 화자 구별 벡터(412)를 추출하는 동작; 및상기 제1 화자 구별 벡터(411)가 상기 제1 화자 구별 벡터(412)와 일치할 때, 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 상기 디지털 어시스턴트(109)에 제출한 동일 사용자(10)에 의해 말해진 발화를 포함한다고 결정하는 동작을 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>24. 제16항 내지 제23항 중 어느 한 항에 있어서, 상기 동작들은 사용자(10)에 의해 말해지고 상기 디지털 어시스턴트(109)에 제출된 초기 쿼리(117)에 대응하는 초기 오디오 데이터(120)를 수신한 후:상기 초기 오디오 데이터(120)로부터, 상기 사용자(10)에 의해 말해진 상기 초기 쿼리(117)의 특성들을 나타내는 제1 화자 구별 벡터(411)를 추출하는 동작;상기 제1 화자 구별 벡터(411)가 상기 AED(102)에 저장된 임의의 등록된 화자 벡터들과 일치하는지를 결정하는 동작 - 각각의 등록된 화자 벡터는 상기 AED(102)의 상이한 각자의 등록된 사용자(10)에 연관됨 -; 및상기 제1 화자 구별 벡터(411)가 상기 등록된 화자 벡터들 중 하나와 일치할 때, 상기 초기 쿼리(117)를 말한 사용자(10)를, 상기 제1 화자 구별 벡터(411)와 일치하는 상기 등록된 화자 벡터들 중 하나에 연관된 각자의 등록된 사용자(10)로서 식별하는 동작을 더 포함하고, 상기 후속 오디오 데이터(127)에 대한 화자 검증을 수행하는 동작은:상기 후속 오디오 데이터(127)로부터, 상기 SID 모델을 이용하여, 상기 후속 오디오 데이터(127)의 특성들을 나타내는 제1 화자 구별 벡터(412)를 추출하는 동작; 및상기 제1 화자 구별 벡터(412)가 상기 초기 쿼리(117)를 말한 각자의 등록된 사용자(10)에 연관된 상기 등록된 화자 벡터들 중 하나와 일치할 때, 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 상기 디지털 어시스턴트(109)에 제출한 동일 사용자(10)에 의해 말해진 발화를 포함한다고 결정하는 동작을 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>25. 제16항 내지 제24항 중 어느 한 항에 있어서, 상기 SID 모델은 상기 후속 오디오 데이터(127)로부터 텍스트-독립적 화자 구별 벡터를 추출하도록 구성된 텍스트-독립적 SID 모델을 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>26. 제16항 내지 제25항 중 어느 한 항에 있어서, 상기 동작들은 상기 VAD 모델(222)이 상기 후속 오디오 데이터(127)에서 목소리 활동을 검출하지 못한다는 것, 또는 상기 후속 오디오 데이터(127)가 상기 초기 쿼리(117)를 제출한 동일 사용자(10)에 의해 말해진 발화를 포함하지 못한다는 것 중 적어도 하나를 결정하는 것에 응답하여, 상기 올웨이즈-온 제1 프로세서(200)에게 상기 후속 쿼리 검출 모드(220)에서의 동작을 중단하고 핫워드 검출 모드(210)에서의 동작을 시작하도록 지시하는 동작을 더 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 올웨이즈-온 제1 프로세서(200)에게 상기 후속 쿼리 검출 모드(220)에서의 동작을 중단하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 올웨이즈-온 제1 프로세서(200) 상에서의 상기 VAD 및 SID 모델들(222, 410)의 실행을 디스에이블 또는 비활성화하게 하는, AED(102).</claim></claimInfo><claimInfo><claim>28. 제26항 또는 제27항에 있어서, 상기 올웨이즈-온 제1 프로세서(200)에게 핫워드 검출 모드(210)에서의 동작을 시작하도록 지시하는 동작은 상기 올웨이즈-온 제1 프로세서(200)로 하여금 상기 올웨이즈-온 제1 프로세서(200) 상에서의 핫워드 검출 모델(212)의 실행을 개시하게 하는, AED(102).</claim></claimInfo><claimInfo><claim>29. 제16항 내지 제28항 중 어느 한 항에 있어서,상기 올웨이즈-온 제1 프로세서(200)는 디지털 신호 프로세서(DSP)를 포함하고; 상기 제2 프로세서(300)는 애플리케이션 프로세서를 포함하는, AED(102).</claim></claimInfo><claimInfo><claim>30. 제16항 내지 제29항 중 어느 한 항에 있어서, 상기 AED(102)는 상기 초기 쿼리(117)에 대응하는 초기 오디오 데이터(120) 및 상기 후속 오디오 데이터(127)를 캡처하도록 구성된 상기 하나 이상의 마이크로폰과 통신하는 배터리 구동 디바이스를 포함하는, AED(102).</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>SHARIFI, Matthew</engName><name>샤리피, 매튜</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>CARBUNE, Victor</engName><name>카르부네, 빅토르</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.13</priorityApplicationDate><priorityApplicationNumber>63/262,447</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.05.09</receiptDate><receiptNumber>1-1-2024-0505339-49</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.05.09</receiptDate><receiptNumber>1-1-2024-0505669-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.05.13</receiptDate><receiptNumber>1-5-2024-0079053-53</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247015540.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930e3df87762206cf6e6e8ea84d1eab478e59a5f4e55d2a74c545c65a8bb376003a466a08efef2b505e32e1716f06d0dfe3b878794926a4620</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2aeac9f833dc818394264d432bd4f77d0a0a4e08a2f6f87bcef2e16697644bd39061ac5ebc8767c90df74d9cc90dca9caf429902b8a36629</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>