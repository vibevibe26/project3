<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:39.539</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0111894</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>복수의 영상 프레임들 간의 변환 정보를 결정하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR DETERMINING TRANSFORMATION  INFORMATION BETWEEN A PLURALITY OF IMAGE FRAMES</inventionTitleEng><openDate>2025.03.05</openDate><openNumber>10-2025-0030660</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/269</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/776</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치는, 제1 영상 프레임으로부터, 정적 랜드마크가 보이는 영역(visible region) 및 상기 정적 랜드마크가 가려진 영역(occluded region)을 포함하는 제1 에이모달 영역(amodal region)을 결정하고, 상기 제1 에이모달 영역에 기초하여, 상기 제1 에이모달 영역 중 상기 가려진 영역에 대한 신뢰도 정보(confidence information)를 결정하며, 상기 제1 영상 프레임에 시간적으로 후속하는(temporally subsequent) 제2 영상 프레임으로부터 상기 정적 랜드마크에 대응하는 제2 에이모달 영역을 결정하고, 상기 제1 에이모달 영역, 상기 제2 에이모달 영역, 및 상기 결정된 신뢰도 정보에 기초하여 상기 제1 영상 프레임 및 상기 제2 영상 프레임 간의 변환 정보(transformation information)를 결정하며, 상기 변환 정보에 기초하여, 상기 전자 장치의 측위 정보(localization information)를 결정하는 프로세서를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 의하여 수행되는 방법에 있어서,제1 영상 프레임으로부터, 정적 랜드마크가 보이는 영역(visible region) 및 상기 정적 랜드마크가 가려진 영역(occluded region)을 포함하는 제1 에이모달 영역(amodal region)을 결정하는 단계;상기 제1 에이모달 영역에 기초하여, 상기 제1 에이모달 영역 중 상기 가려진 영역에 대한 신뢰도 정보(confidence information)를 결정하는 단계;상기 제1 영상 프레임에 시간적으로 후속하는(temporally subsequent) 제2 영상 프레임으로부터 상기 정적 랜드마크에 대응하는 제2 에이모달 영역을 결정하는 단계;상기 제1 에이모달 영역, 상기 제2 에이모달 영역, 및 상기 결정된 신뢰도 정보에 기초하여 상기 제1 영상 프레임 및 상기 제2 영상 프레임 간의 변환 정보(transformation information)를 결정하는 단계; 및상기 변환 정보에 기초하여, 상기 전자 장치의 측위 정보(localization information)를 결정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 신뢰도 정보를 결정하는 단계는,상기 제1 에이모달 영역 중 상기 가려진 영역의 픽셀에 대하여, 상기 픽셀의 주변 영역(surrounding region)에 포함된 픽셀들 중 상기 제1 에이모달 영역 중 상기 보이는 영역에 포함된 픽셀의 개수에 대응하는 제1 픽셀 카운트 및 상기 제1 에이모달 영역 중 상기 가려진 영역에 포함된 픽셀의 개수에 대응하는 제2 픽셀 카운트에 기초하여, 상기 픽셀에 대한 신뢰도 정보를 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 픽셀에 대한 신뢰도 정보를 결정하는 단계는,상기 제1 픽셀 카운트 및 상기 제2 픽셀 카운트의 합에 대한 상기 제1 픽셀 카운트의 비율에 기초하여 상기 픽셀에 대한 신뢰도 정보를 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 신뢰도 정보를 결정하는 단계는,상기 제1 에이모달 영역으로부터 구분된 클러스터에 대하여, 상기 클러스터에 포함된 픽셀들에 대한 주 성분 분석(principal component analysis; PCA)에 기초하여, 상기 클러스터에 대한 신뢰도 정보를 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 클러스터에 대한 신뢰도 정보를 결정하는 단계는,상기 주 성분 분석에 따른 제1 고유 값(eigen value) 및 상기 제1 고유 값보다 작거나 같은 제2 고유 값을 획득하는 단계; 및상기 제1 고유 값 및 상기 제2 고유 값의 합에 대한 상기 제1 고유 값의 비율에 기초하여 상기 클러스터에 포함된 각 픽셀에 대한 신뢰도 정보를 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 변환 정보를 결정하는 단계는,상기 제1 에이모달 영역 및 상기 제2 에이모달 영역 간의 변환을 위한 변환 정보에 대하여, 상기 제1 에이모달 영역 중 상기 가려진 영역의 변환에 상기 신뢰도 정보를 적용함으로써 손실 값을 계산하는 단계; 및상기 계산된 손실 값에 기초하여 상기 변환 정보를 업데이트하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 신뢰도 정보를 결정하는 단계는,상기 제1 에이모달 영역 중 상기 가려진 영역에 대한 제1 신뢰도 정보를 결정하는 단계를 포함하고,상기 방법은,상기 제2 에이모달 영역에 기초하여, 상기 제2 에이모달 영역 중 가려진 영역에 대한 제2 신뢰도 정보를 결정하는 단계를 더 포함하고,상기 변환 정보를 결정하는 단계는,상기 제1 에이모달 영역, 상기 제2 에이모달 영역, 및 상기 제1 신뢰도 정보, 및 상기 제2 신뢰도 정보에 기초하여, 상기 변환 정보를 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 변환 정보를 결정하는 단계는,상기 제1 에이모달 영역의 제1 픽셀 및 상기 제2 에이모달 영역의 제2 픽셀 간의 변환을 위한 상기 변환 정보에 대하여, 상기 제1 픽셀이 상기 제1 에이모달 영역 중 상기 가려진 영역에 포함되는 것에 기초하여 상기 제1 픽셀 및 상기 제2 픽셀 간의 변환에 상기 제1 신뢰도 정보를 적용함으로써 손실 값을 계산하는 단계; 및상기 제2 픽셀이 상기 제2 에이모달 영역 중 상기 가려진 영역에 포함되는 것에 기초하여, 상기 제1 픽셀 및 상기 제2 픽셀 간의 변환에 상기 제2 신뢰도 정보를 적용함으로써 상기 손실 값을 계산하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 에이모달 영역을 결정하는 단계는,상기 제1 영상 프레임으로부터 상기 정적 랜드마크가 보이는 영역을 검출하는 단계; 및상기 정적 랜드마크가 보이는 영역에 기계 학습 모델을 적용함으로써, 상기 제1 영상 프레임 중에서 상기 정적 랜드마크가 가려진 영역을 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 기계 학습 모델은,정적 랜드마크가 보이는 제1 이미지에 객체를 추가함으로써 생성된 제2 이미지에 기초한 트레이닝 입력 및 트레이닝 출력과, 상기 제1 이미지 중 상기 정적 랜드마크가 보이는 영역을 이용하여 지도 학습(supervised learning)으로 트레이닝된,방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 전자 장치는,이동체에 탑재되고,상기 방법은,상기 결정된 측위 정보에 기초하여, 상기 이동체의 주행(driving)을 제어하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항의 방법을 수행하기 위한 명령어를 포함하는 하나 이상의 컴퓨터 프로그램을 저장한 컴퓨터 판독 가능 기록 매체.</claim></claimInfo><claimInfo><claim>13. 전자 장치에 있어서,제1 영상 프레임으로부터, 정적 랜드마크가 보이는 영역(visible region) 및 상기 정적 랜드마크가 가려진 영역(occluded region)을 포함하는 제1 에이모달 영역(amodal region)을 결정하고, 상기 제1 에이모달 영역에 기초하여, 상기 제1 에이모달 영역 중 상기 가려진 영역에 대한 신뢰도 정보(confidence information)를 결정하며, 상기 제1 영상 프레임에 시간적으로 후속하는(temporally subsequent) 제2 영상 프레임으로부터 상기 정적 랜드마크에 대응하는 제2 에이모달 영역을 결정하고, 상기 제1 에이모달 영역, 상기 제2 에이모달 영역, 및 상기 결정된 신뢰도 정보에 기초하여 상기 제1 영상 프레임 및 상기 제2 영상 프레임 간의 변환 정보(transformation information)를 결정하며, 상기 변환 정보에 기초하여, 상기 전자 장치의 측위 정보(localization information)를 결정하는 프로세서를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 프로세서는,상기 제1 에이모달 영역 중 상기 가려진 영역의 픽셀에 대하여, 상기 픽셀의 주변 영역(surrounding region)에 포함된 픽셀들 중 상기 제1 에이모달 영역 중 상기 보이는 영역에 포함된 픽셀의 개수에 대응하는 제1 픽셀 카운트 및 상기 제1 에이모달 영역 중 상기 가려진 영역에 포함된 픽셀의 개수에 대응하는 제2 픽셀 카운트에 기초하여, 상기 픽셀에 대한 신뢰도 정보를 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 프로세서는,상기 제1 픽셀 카운트 및 상기 제2 픽셀 카운트의 합에 대한 상기 제1 픽셀 카운트의 비율에 기초하여 상기 픽셀에 대한 신뢰도 정보를 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 프로세서는,상기 제1 에이모달 영역으로부터 구분된 클러스터에 대하여, 상기 클러스터에 포함된 픽셀들에 대한 주 성분 분석(principal component analysis; PCA)에 기초하여, 상기 클러스터에 대한 신뢰도 정보를 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 프로세서는,상기 주 성분 분석에 따른 제1 고유 값(eigen value) 및 상기 제1 고유 값보다 작거나 같은 제2 고유 값을 획득하고,상기 제1 고유 값 및 상기 제2 고유 값의 합에 대한 상기 제1 고유 값의 비율에 기초하여 상기 클러스터에 포함된 각 픽셀에 대한 신뢰도 정보를 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서,상기 프로세서는,상기 제1 에이모달 영역 및 상기 제2 에이모달 영역 간의 변환을 위한 변환 정보에 대하여, 상기 제1 에이모달 영역 중 상기 가려진 영역의 변환에 상기 신뢰도 정보를 적용함으로써 손실 값을 계산하고,상기 계산된 손실 값에 기초하여 상기 변환 정보를 업데이트하는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제13항에 있어서,상기 프로세서는,상기 제1 에이모달 영역 중 상기 가려진 영역에 대한 제1 신뢰도 정보를 결정하고,상기 제2 에이모달 영역에 기초하여, 상기 제2 에이모달 영역 중 가려진 영역에 대한 제2 신뢰도 정보를 결정하며,상기 제1 에이모달 영역, 상기 제2 에이모달 영역, 및 상기 제1 신뢰도 정보, 및 상기 제2 신뢰도 정보에 기초하여, 상기 변환 정보를 결정하는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제13항에 있어서,상기 전자 장치는,이동체에 탑재되고,상기 프로세서는,상기 결정된 측위 정보에 기초하여, 상기 이동체의 주행(driving)을 제어하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420220818811</code><country>대한민국</country><engName>CHOI, HO-IK</engName><name>최호익</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420210372023</code><country>대한민국</country><engName>Park, Yongkonjong</engName><name>박용곤종</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170726841</code><country>대한민국</country><engName>LEE, JAE WOO</engName><name>이재우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.08.25</receiptDate><receiptNumber>1-1-2023-0939316-77</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230111894.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e2460cc43c4912a94f9a6d3cc5587ef796fe1fef7779ddf10e1e839a1feaaa44f53f5efbabfd44e049a460c94ee96c965715a91e7dc68ba5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1a92421762e336f9f92f14343031384e279e0e1ad3876142d445bcddcf89b9bd64c06fb4b3f7135259944f80d4c5453cc7518f23aaedafb4</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>