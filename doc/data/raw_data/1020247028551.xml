<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:12.112</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.02</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7028551</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>준의사 라벨들을 사용하는 신경망 트레이닝 방법</inventionTitle><inventionTitleEng>NEURAL NETWORK TRAINING METHOD USING SEMI-PSEUDO-LABELS</inventionTitleEng><openDate>2024.10.02</openDate><openNumber>10-2024-0144251</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.26</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/214</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/2413</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/72</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 데이터포인트들을 포함하는 데이터세트 및 데이터세트의 데이터포인트들 중 적어도 일부에 대한 실측 자료 라벨들에 기초하여 복잡한 머신 학습 모델을 트레이닝하기 위한 방법을 제공하고, 여기서, 데이터포인트들은 이미지들을 포함하고, 방법은: - 데이터세트에 대한 의사 라벨들을 예측하기 위해, 복잡도가 감소된 머신 학습 모델을 사용하는 단계; 및 - 출력으로서 의사 라벨들 및 실측 자료 라벨들을 포함하는 확장된 데이터세트를 사용하여 복잡한 머신 학습 모델을 트레이닝하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.08.10</internationOpenDate><internationOpenNumber>WO2023148285</internationOpenNumber><internationalApplicationDate>2023.02.02</internationalApplicationDate><internationalApplicationNumber>PCT/EP2023/052594</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 데이터포인트들을 포함하는 데이터세트 및 상기 데이터세트의 상기 데이터포인트들 중 적어도 일부에 대한 실측 자료 라벨(ground truth label)들에 기초하여 복잡한 머신 학습 모델을 트레이닝하기 위한 방법으로서,상기 데이터포인트들은 이미지들을 포함하고,상기 방법은,- 상기 데이터세트에 대한 의사 라벨(pseudo label)들을 예측하기 위해, 복잡도가 감소된 머신 학습 모델을 사용하는 단계(210); 및- 출력으로서 상기 의사 라벨들 및 상기 실측 자료 라벨들을 포함하는 확장된 데이터세트를 사용하여 상기 복잡한 머신 학습 모델을 트레이닝하는 단계(220)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,- 실측 자료 라벨은 3D 바운딩 박스(bounding box)의 좌표, 치수 및/또는 배향을 포함하고/하거나,- 의사 라벨은 2D 바운딩 박스의 좌표, 치수 및/또는 배향을 포함하고/하거나,- 실측 자료 라벨 및/또는 의사 라벨은 객체 카테고리들의 세트에 대한 확률들 및/또는 객체성 스코어를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 실측 자료 라벨들은 상기 데이터세트의 주석부기된 영역(110a, 110b, 110c) 내의 객체들의 라벨들이고, 상기 데이터세트는 상기 데이터세트의 상기 주석부기된 영역 외부에 있는 객체들에 대한 라벨링되지 않은 데이터포인트들을 포함하고, 바람직하게는, 상기 주석부기된 영역은 카메라의 근거리 필드(130)에 대응하고, 주석부기되지 않은 영역(112a, 112b, 112c)은 상기 카메라의 원거리 필드(132)에 대응하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,- 3D 데이터를 획득하는 단계; 및- 상기 3D 데이터를 가상적으로 캡처하는 가상 카메라에 기초하여 가상 이미지들로 상기 데이터세트를 확장하는 단계를 더 포함하고,상기 이미지들을 획득하는 것은 상기 가상 카메라의 포지션을 이동시켜서 이동된 카메라 포지션으로부터 시프트된 그리고/또는 줌된 이미지들을 획득하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 이동된 카메라 포지션으로부터 이미지들을 획득하는 것은 2D 이미지로의 상기 3D 데이터에서의 포지션들의 맵핑을 설명하는 카메라 매트릭스를 조정하는 것을 포함하고, 바람직하게는, 상기 카메라 매트릭스를 조정하는 것은 원래의 카메라 매트릭스 및 2D 스케일링에 기초하여 주점 및 초점 거리를 조정하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,- 상기 이미지들에 기초하여, 의사 라벨들이 예측될 필요가 있는 객체들을 검출하는 초기 단계; 및/또는- 상기 데이터세트가 이미 실측 자료 라벨들을 포함하는 의사 라벨들을 제거하기 위해 중복 제거를 수행하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 중복 제거를 수행하는 단계는,- 실측 자료 라벨의 3D 바운딩 박스의 2D 투영 및 의사 라벨의 2D 바운딩 박스의 합집합에 대한 교집합의 비율을 결정하는 단계; 및- 상기 비율이 미리 결정된 임계치 초과인 경우, 상기 확장된 데이터세트로부터 상기 의사 라벨을 제거하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 복잡한 머신 학습 모델을 트레이닝하는 단계는 어떠한 실측 자료 라벨도 이용가능하지 않은 경우 3D 특성들에 대응하는 에러 기여들에 페널티를 주지 않는 손실 함수를 사용하는 단계를 포함하고, 바람직하게는, 라벨이 실측 자료 라벨인지 또는 예측된 의사 라벨인지를 상기 확장된 데이터세트에서 표시하기 위해 불 플래그(Boolean flag)가 사용되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,자율 주행에서 객체들을 검출하기 위해 상기 복잡한 머신 학습 모델을 사용하는 단계를 더 포함하고, 상기 라벨들은 바람직하게는 차량들, 이륜차들, 보행자들, 교통 표지들 및 신호등들 중 하나 이상을 포함하는 객체 클래스들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 복잡한 머신 학습 모델은 예측된 깊이 및 3D 직육면체의 2D 투영의 예측에 기초하여 상기 3D 직육면체의 중심 포인트를 예측하기 위해 사용되는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 깊이는 카메라 베이스라인, 초점 거리 및 깊이에 기초하여 계산되는 디스패리티(disparity)에 기초하여 예측되고/되거나, 예측된 깊이는 현재의 카메라의 초점 거리에 기초하여 조정되는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서,상기 복잡한 머신 학습 모델은 제1 태스크 및 제2 태스크를 병렬로 해결하도록 구성된 다중 태스크 머신 학습 모델이고, 상기 복잡도가 감소된 머신 학습 모델은 상기 제1 태스크를 해결하도록 구성되고, 바람직하게는, 상기 제1 태스크는 2D 바운딩 박스의 예측을 포함하고, 상기 제2 태스크는 3D 바운딩 박스의 예측을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서,상기 복잡한 머신 학습 모델을 트레이닝하는 단계는,- 3D 직육면체의 3D 투영에 기초하는 투영 손실 항;- 좌측 및 우측 스테레오 이미지들 상의 2D 투영된 3D 바운딩 박스의 중심 포인트 사이의 디스패리티에 기초하는 디스패리티 손실 항; 및- 좌측 및 우측 스테레오 이미지들 상의 3D 바운딩 박스들의 2D 투영의 폭 사이의 차이에 기초하는 폭 손실 항중 하나 이상을 포함하는 손실 항들을 사용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항의 방법을 수행하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>15. 프로그램 코드를 저장하는 컴퓨터 판독가능 저장 매체로서,상기 프로그램 코드는 프로세서에 의해 실행될 때 제1항 내지 제13항 중 어느 한 항의 방법을 수행하는 명령어들을 포함하는, 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>헝가리, 에이치-**** 부다페스트, 셉볼지 우트 **</address><code>520200013853</code><country>헝가리</country><engName>AImotive Kft.</engName><name>에이아이모티브 케이에프티.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>헝가리 **** 부다페...</address><code> </code><country> </country><engName>KOZMA, Daniel Akos</engName><name>코즈마, 다니엘 아코스</name></inventorInfo><inventorInfo><address>헝가리 **** 부다...</address><code> </code><country> </country><engName>MATUSZKA, Tamas</engName><name>마투스카, 타마스</name></inventorInfo><inventorInfo><address>헝가리 **** 괴드...</address><code> </code><country> </country><engName>UTASI, Akos</engName><name>우타시, 아코스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2022.02.03</priorityApplicationDate><priorityApplicationNumber>22154927.2</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.26</receiptDate><receiptNumber>1-1-2024-0927959-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.04</receiptDate><receiptNumber>1-5-2024-0145071-57</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247028551.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338e54db4fefe572d9f0901da6aab434a103151fdff0d9e3f1e08bee821d07a6725b0128e919b55eda7ee43e92685c3fd9369f8a4613ded44f56</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf01b9c66b4f51952382ff28908ba9a7304b32ce200e9e4977d143ae4d3e2d8bc100b28757239c6fc9a12a5c40c4dc8d368879039aa3177b3b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>