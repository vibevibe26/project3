<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:08:11.811</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.07.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7004477</applicationNumber><claimCount>25</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>시력 검사 시스템 및 방법과 그 용도</inventionTitle><inventionTitleEng>SYSTEMS AND METHODS FOR VISION TEST AND USES THEREOF</inventionTitleEng><openDate>2024.03.08</openDate><openNumber>10-2024-0032107</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.04</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.02.06</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A61B 3/032</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A61B 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/136</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/60</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 시력 검사를 위한 시스템 및 방법과 그 용도가 개시된다. 방법은 적어도 프로세서, 카메라 및 디스플레이 화면을 갖는 모바일 장치에서 구현될 수 있다. 방법은 모바일 장치의 카메라를 이용하여 사용자의 적어도 하나의 이미지를 캡처하는 단계, 적어도 하나의 이미지에 기초하여, 사용자를 모바일 장치의 디스플레이 화면으로부터 사전결정된 거리까지 상호작용식으로 안내하는 단계, 사용자가 디스플레이 화면으로부터 사전결정된 거리에 있다고 결정될 때 디스플레이 화면에 자료를 제시하는 단계, 디스플레이 화면에 제시된 자료에 응답하여 사용자로부터 입력을 수신하는 단계를 포함할 수 있다. 디스플레이 화면에 제시되는 자료는 사용자의 시력의 적어도 하나의 특성을 평가하기 위한 것일 수 있다. 모바일 장치 및 사용자의 시력을 평가하기 위한 머신 실행가능 명령어가 구현된 비일시적 머신 판독가능 매체도 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.01.12</internationOpenDate><internationOpenNumber>WO2023283217</internationOpenNumber><internationalApplicationDate>2022.07.06</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/036180</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 프로세서, 카메라 및 디스플레이 화면을 갖는 모바일 장치에서 구현되는 사용자의 시력을 평가하기 위한 방법으로서,상기 사용자와 상기 모바일 장치의 디스플레이 화면이 모두 거울을 향하고 있도록 상기 사용자에게 상기 모바일 장치를 홀딩하도록 안내하는 단계와,상기 모바일 장치의 카메라를 사용하여, 상기 거울에 반사된 상기 모바일 장치의 적어도 하나의 이미지를 캡처하는 단계와,상기 적어도 하나의 이미지에 기초하여 상기 사용자를 상기 거울로부터 사전결정된 거리까지 상호작용식으로 안내하는 단계와,상기 사용자가 상기 거울로부터 상기 사전결정된 거리에 있다고 결정할 때 상기 디스플레이 화면에 자료를 제시하는 단계 - 상기 디스플레이 화면에 제시되는 상기 자료는 상기 사용자의 시력의 적어도 하나의 특성을 평가하기 위한 것임 - 와,상기 디스플레이 화면에 제시되고 상기 거울에 반사된 상기 자료에 응답하여 상기 사용자로부터 입력을 수신하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 모바일 장치는 상기 사용자에 의해 대략 수직, 수평 또는 대각선 방향으로 홀딩되고 상기 거울과 대략 평행하며,상기 카메라와 상기 디스플레이 화면은 상기 모바일 장치의 같은 쪽에 위치되는,방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 적어도 하나의 이미지를 캡처하고 상기 사용자가 상기 거울로부터 현재 거리에 있을 때 상기 디스플레이 화면에 참조 패턴을 제시하는 단계와,상기 카메라의 초점 거리, 상기 적어도 하나의 이미지 및 상기 참조 패턴의 사전결정된 물리적 크기에 기초하여 상기 사용자와 상기 거울 사이의 현재 거리를 결정하는 단계를 더 포함하되,상기 사용자는 상기 현재 거리에 기초하여 상기 거울로부터 상기 사전결정된 거리까지 상호작용식으로 안내되는,방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 현재 거리를 결정하는 단계는,상기 참조 패턴을 전처리하여 상기 참조 패턴의 적어도 하나의 후보 형상을 포함하는 이진 이미지를 생성하는 단계와,상기 적어도 하나의 이미지에서 상기 참조 패턴의 위치 파악을 수행하는 단계와,상기 적어도 하나의 이미지로부터 상기 참조 패턴의 분할을 수행하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 참조 패턴은 고정된 참조 색상을 갖는 정적 단색 패턴을 포함하고,상기 적어도 하나의 이미지는 상기 거울에 반사된 상기 참조 패턴의 이미지를 포함하며,상기 참조 패턴을 전처리하는 것은, 상기 이미지와 상기 고정된 참조 색상 간의 픽셀 단위 차이를 계산하여 차이 이미지를 생성하는 것과, 상기 차이 이미지를 사전결정된 값으로 역임계값화하여 상기 참조 패턴의 적어도 하나의 후보 형상을 포함하는 상기 이진 이미지를 생성하는 것을 포함하는,방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 참조 패턴은 RGB 성분이 (0, 255, 255)인 청록색을 가지며, 검은색 경계로 둘러싸인,방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 참조 패턴은 사전결정된 방식으로 시변하는 참조 색상을 갖는 동적 단색 패턴을 포함하고,상기 참조 패턴은 사전결정된 프레임 레이트로 각각 상이한 색상을 갖는 복수의 이미지 프레임을 순환하며,상기 적어도 하나의 이미지는 상기 참조 패턴의 이미지 프레임의 전체 사이클을 포함하고,상기 이미지 프레임 각각은 각각의 시간 프레임 동안 상기 거울에 반사된 상기 참조 패턴의 이미지이며,현재 이미지 프레임에서 상기 참조 패턴을 전처리하는 것은, 상기 현재 이미지 프레임의 색상과 보색인 색상을 가진 과거 이미지 프레임을 결정하는 것과, 상기 현재 이미지 프레임의 색조 채널과 상기 과거 이미지 프레임의 색조 채널을 비교하여 색조 차이를 계산하는 것과, 상기 색조 차이와 상기 현재 이미지 프레임의 강도 채널을 곱하여 차이 이미지를 생성하는 것과, 상기 차이 이미지를 사전결정된 값으로 임계값화하여 상기 참조 패턴의 적어도 하나의 후보 형상을 포함하는 상기 이진 이미지를 생성하는 것을 포함하는,방법.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서,상기 참조 패턴의 위치 파악을 수행하는 단계는,상기 적어도 하나의 이미지로부터 상기 참조 패턴의 상기 적어도 하나의 후보 형상을 분리하는 단계와,상기 디스플레이 화면에 제시된 상기 참조 패턴의 형상과 관련된 적어도 하나의 기준에 기초하여 상기 적어도 하나의 후보 형상을 필터링하는 단계와,상기 필터링에 기초하여, 상기 적어도 하나의 이미지 각각에서, 상기 참조 패턴의 형상 및 상기 형상을 둘러싸는 경계를 포함하는 관심 영역(&quot;ROI&quot;)을 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 적어도 하나의 기준은,둘러싸는 직사각형에 대한 상기 참조 패턴의 형상은 사전결정된 면적 범위 내의 면적을 갖는 것과,상기 둘러싸는 직사각형의 종횡비는 1/3과 3 사이인 것과,상기 둘러싸는 직사각형에 대한 상기 형상의 충진율은 적어도 95%인 것을 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 참조 패턴의 분할을 수행하는 단계는,상기 적어도 하나의 이미지의 강도 채널의 수평 및 수직 기울기를 계산하는 단계와,상기 ROI를 왼쪽 서브영역, 오른쪽 서브영역, 위쪽 서브영역 및 아래쪽 서브영역인 4개의 중첩 서브영역으로 나누는 단계와,상기 왼쪽 및 오른쪽 서브영역의 각 행에 대해, 상기 수평 기울기의 크기가 가장 큰 열을 결정하여 크기 임계값에 기초하여 왼쪽 및 오른쪽 경계 지점을 생성하는 단계와,상기 위쪽 및 아래쪽 서브영역의 각 열에 대해, 상기 수직 기울기의 크기가 가장 큰 행을 결정하여 상기 크기 임계값에 기초하여 위쪽 및 아래쪽 경계 지점을 생성하는 단계와,상기 참조 패턴의 에지를 결정하기 위해 상기 경계 지점을 선으로 맞추는 단계와,상기 맞취진 선의 교차점을 기반으로 상기 참조 패턴의 코너를 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 현재 거리를 결정하는 단계는,상기 참조 패턴의 상기 결정된 에지 및 코너에 기초하여 상기 참조 패턴의 크기를 픽셀 단위로 측정하는 단계와,상기 카메라의 초점 거리(픽셀 단위), 상기 참조 패턴의 측정된 크기(픽셀 단위) 및 상기 참조 패턴의 사전결정된 물리적 크기를 기반으로 상기 사용자와 상기 거울 사이의 상기 현재 거리를 계산하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 참조 패턴의 상기 사전결정된 물리적 크기는 상기 모바일 장치의 디스플레이 화면의 물리적 크기에 기초하여 사전결정되는,방법.</claim></claimInfo><claimInfo><claim>13. 제3항에 있어서,상기 적어도 하나의 이미지는 상기 사용자가 상기 거울로부터 상기 현재 거리에 있을 때 하나의 시간 프레임 동안 모두 캡처된 복수의 이미지를 포함하고,상기 현재 거리를 결정하는 단계는, 상기 복수의 이미지 각각에서 상기 참조 패턴을 전처리하는 단계와, 상기 복수의 이미지 각각에서 상기 참조 패턴의 위치 파악을 수행하는 단계와, 상기 복수의 이미지 각각으로부터 상기 참조 패턴의 분할을 수행하여 복수의 분할된 참조 패턴을 생성하는 단계와, 각각의 분할된 참조 패턴의 크기를 픽셀 단위로 측정하는 단계와, 각각의 분할된 참조 패턴에 대해, 상기 카메라의 초점 거리(픽셀 단위), 상기 분할된 참조 패턴의 측정된 크기(픽셀 단위) 및 상기 참조 패턴의 사전결정된 물리적 크기에 기초하여 상기 사용자와 상기 거울 사이의 추정된 현재 거리를 결정하여 복수의 추정된 현재 거리를 생성하는 단계와, 상기 복수의 추정된 현재 거리의 집계에 기초하여 상기 사용자와 상기 거울 사이의 상기 현재 거리를 계산하는 단계 - 상기 집계는 상기 복수의 추정된 현재 거리에 기초하여 평균, 가중 평균 또는 중앙값을 계산하는 것을 포함함 - 를 포함하는,방법.</claim></claimInfo><claimInfo><claim>14. 제3항에 있어서,상기 사용자를 상호작용식으로 안내하는 단계는,상기 사용자와 상기 거울 사이의 상기 현재 거리의 제1 표시를 상기 디스플레이 화면에 제시하는 단계와,상기 사전결정된 거리에 도달했을 때 상기 사용자에게 제2 표시를 제공하는 단계와,상기 사용자에게 상기 거울을 기준으로 한 방향으로 이동하라는 명령을 제공하는 단계와,상기 참조 패턴의 적어도 일부가 상기 사용자에 의해 차단되는 경우 상기 사용자에게 명령을 제공하는 단계와,상기 참조 패턴의 적어도 일부가 상기 사용자에 의해 차단되면 상기 디스플레이 화면에 제시되는 상기 참조 패턴의 크기를 자동으로 조정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서,상기 입력이 상기 사용자의 손 제스처를 포함하는 경우 상기 카메라를 이용하여 상기 사용자로부터의 상기 입력의 비디오를 기록하는 단계와,상기 입력이 상기 사용자의 음성을 포함하는 경우, 상기 모바일 장치의 마이크를 이용하여 상기 사용자로부터의 상기 입력의 오디오를 기록하는 단계와,상기 기록된 비디오 및 오디오를 기반으로 상기 사용자의 시력의 적어도 하나의 특성을 평가하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서,상기 사전결정된 거리는 사전결정된 거리 범위 내의 거리인,방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 사전결정된 거리는 상기 사전결정된 거리 범위에서 공칭 거리와 다른,방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 사용자로부터 수신된 입력에 기초하여 상기 사용자에 대한 제1 시력 점수를 결정하는 단계와,상기 공칭 거리와 상기 사전결정된 거리의 비율에 적어도 부분적으로 기초하여 상기 사용자에 대한 시력 교정 계산을 결정하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>19. 모바일 장치로서,카메라와,디스플레이 화면과,명령어를 포함하는 메모리와,상기 카메라에 결합된 프로세서를 포함하되, 상기 프로세서는 상기 명령어를 실행하여, 사용자와 상기 모바일 장치의 디스플레이 화면이 모두 상기 사용자 앞의 거울을 향하고 있도록 상기 사용자에게 상기 모바일 장치를 홀딩하도록 안내하고, 상기 카메라를 사용하여, 상기 거울에 반사된 상기 모바일 장치의 적어도 하나의 이미지를 캡처하며, 상기 적어도 하나의 이미지에 기초하여 상기 사용자를 상기 거울로부터 사전결정된 거리까지 상호작용식으로 안내하고, 상기 사용자가 상기 거울로부터 상기 사전결정된 거리에 있다고 결정할 때 상기 디스플레이 화면에 자료를 제시하며 - 상기 디스플레이 화면에 제시되는 상기 자료는 상기 사용자의 시력의 적어도 하나의 특성을 평가하기 위한 것임 - , 상기 디스플레이 화면에 제시되고 상기 거울에 반사된 상기 자료에 응답하여 상기 사용자로부터 입력을 수신하도록 구성되는,모바일 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 모바일 장치는 상기 사용자에 의해 대략 수직, 수평 또는 대각선 방향으로 홀딩되고 상기 거울과 대략 평행하며,상기 카메라와 상기 디스플레이 화면은 상기 모바일 장치의 같은 쪽에 위치되는,모바일 장치.</claim></claimInfo><claimInfo><claim>21. 제19항에 있어서,상기 프로세서는 또한 상기 명령어를 실행하여,상기 적어도 하나의 이미지를 캡처하고 상기 사용자가 상기 거울로부터 현재 거리에 있을 때 상기 디스플레이 화면에 참조 패턴을 제시하고,상기 카메라의 초점 거리, 상기 적어도 하나의 이미지 및 상기 참조 패턴의 사전결정된 물리적 크기에 기초하여 상기 사용자와 상기 거울 사이의 현재 거리를 결정하도록 구성되되,상기 사용자는 상기 현재 거리에 기초하여 상기 거울로부터 상기 사전결정된 거리까지 상호작용식으로 안내되는,모바일 장치.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,상기 참조 패턴은 고정된 참조 색상을 갖는 정적 단색 패턴을 포함하고,상기 적어도 하나의 이미지는 상기 거울에 반사된 상기 참조 패턴의 이미지를 포함하며,상기 현재 거리는, 차이 이미지를 생성하도록 상기 이미지와 상기 고정된 참조 색상 간의 픽셀 단위 차이와, 상기 참조 패턴의 적어도 하나의 후보 형상을 포함하는 이진 이미지를 생성하도록 상기 차이 이미지를 사전결정된 값으로 역임계값화하는 것에 기초하여 결정되는,모바일 장치.</claim></claimInfo><claimInfo><claim>23. 제21항에 있어서,상기 참조 패턴은 사전결정된 방식으로 시변하는 참조 색상을 갖는 동적 단색 패턴을 포함하고,상기 참조 패턴은 사전결정된 프레임 레이트로 각각 상이한 색상을 갖는 복수의 이미지 프레임을 순환하며,상기 적어도 하나의 이미지는 상기 참조 패턴의 이미지 프레임의 전체 사이클을 포함하고,상기 이미지 프레임 각각은 각각의 시간 프레임 동안 상기 거울에 반사된 상기 참조 패턴의 이미지이며,상기 현재 거리는 현재 이미지 프레임에서, 상기 현재 이미지 프레임의 색상과 보색인 색상을 가진 과거 이미지 프레임과, 상기 현재 이미지 프레임의 색조 채널과 상기 과거 이미지 프레임의 색조 채널의 비교에 기초한 색조 차이와, 상기 색조 차이와 상기 현재 이미지 프레임의 강도 채널의 곱셈으로서 계산된 차이 이미지와, 상기 차이 이미지를 사전결정된 값으로 임계값화한 것에 기초하여 생성된, 상기 참조 패턴의 적어도 하나의 후보 형상을 포함하는 이진 이미지에 기초하여 결정되는,모바일 장치.</claim></claimInfo><claimInfo><claim>24. 제19항에 있어서,상기 사전결정된 거리는 사전결정된 거리 범위 내의 거리인,모바일 장치.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서,상기 사전결정된 거리는 상기 사전결정된 거리 범위에서 공칭 거리와 다른,모바일 장치.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서,상기 프로세서는 상기 명령어를 실행하여,상기 사용자로부터 수신된 입력에 기초하여 상기 사용자에 대한 제1 시력 점수를 결정하고,상기 공칭 거리와 상기 사전결정된 거리의 비율에 적어도 부분적으로 기초하여 상기 사용자에 대한 시력 교정 계산을 결정하도록 구성되는,모바일 장치.</claim></claimInfo><claimInfo><claim>27. 머신 실행가능 명령어가 구현된 비일시적 머신 판독가능 매체로서,상기 머신 실행가능 명령어는, 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 방법을 수행하게 하되, 상기 방법은,상기 사용자와 모바일 장치의 디스플레이 화면이 모두 거울을 향하고 있도록 상기 사용자에게 상기 모바일 장치를 홀딩하도록 안내하는 단계와,상기 모바일 장치의 카메라를 사용하여, 상기 거울에 반사된 상기 모바일 장치의 적어도 하나의 이미지를 캡처하는 단계와,상기 적어도 하나의 이미지에 기초하여 상기 사용자를 상기 거울로부터 사전결정된 거리까지 상호작용식으로 안내하는 단계와,상기 사용자가 상기 거울로부터 상기 사전결정된 거리에 있다고 결정할 때 상기 디스플레이 화면에 자료를 제시하는 단계 - 상기 디스플레이 화면에 제시되는 상기 자료는 상기 사용자의 시력의 적어도 하나의 특성을 평가하기 위한 것임 - 와,상기 디스플레이 화면에 제시되고 상기 거울에 반사된 상기 자료에 응답하여 상기 사용자로부터 입력을 수신하는 단계를 포함하는,비일시적 머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서,상기 사전결정된 거리는 사전결정된 거리 범위 내의 거리이고 공칭 거리와 다르며,상기 방법은,상기 사용자로부터 수신된 입력에 기초하여 상기 사용자에 대한 제1 시력 점수를 결정하는 단계와,상기 공칭 거리와 상기 사전결정된 거리의 비율에 적어도 부분적으로 기초하여 상기 사용자에 대한 시력 교정 계산을 결정하는 단계를 포함하는,비일시적 머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>29. 방법으로서,모바일 장치의 카메라를 이용하여 사용자의 적어도 하나의 이미지를 캡처하는 단계와,상기 적어도 하나의 이미지에 기초하여 상기 사용자를 상기 모바일 장치의 디스플레이 화면으로부터 사전결정된 거리까지 상호작용식으로 안내하는 단계와,상기 사용자가 상기 디스플레이 화면으로부터 사전결정된 거리에 있다고 결정할 때 상기 디스플레이 화면에 자료를 제시하는 단계와,상기 디스플레이 화면에 제시된 자료에 응답하여 상기 사용자로부터 입력을 수신하는 단계를 포함하되,상기 디스플레이 화면에 제시된 자료는 상기 사용자의 시력의 적어도 하나의 특성을 평가하기 위한 것인,방법.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서,상기 모바일 장치는 대략 수직인 표면에 대해 홀딩되고,상기 카메라와 상기 디스플레이 화면은 상기 모바일 장치의 같은 쪽에 위치되는,방법.</claim></claimInfo><claimInfo><claim>31. 제29항에 있어서,상기 사용자의 적어도 하나의 물리적 길이 특징을 추정하는 단계와,상기 카메라의 초점 거리, 상기 적어도 하나의 이미지 및 상기 적어도 하나의 물리적 길이 특징에 기초하여 상기 사용자로부터 상기 모바일 장치의 디스플레이 화면까지의 현재 거리를 결정하는 단계를 더 포함하되,상기 사용자는 상기 현재 거리에 기초하여 상기 디스플레이 화면으로부터 상기 사전결정된 거리까지 상호작용식으로 안내되는,방법.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서,상기 적어도 하나의 물리적 길이 특징은 상기 사용자의 물리적 동공 거리(&quot;PD&quot;)를 포함하는,방법.</claim></claimInfo><claimInfo><claim>33. 제32항에 있어서,상기 사용자의 상기 물리적 PD는,모집단의 물리적 PD에 기초한 사전결정된 상수 값,모집단의 물리적 홍채 직경, 상기 적어도 하나의 이미지에서 측정된 홍채 직경(픽셀 단위) 및 상기 적어도 하나의 이미지에서 상기 사용자의 측정된 PD에 기초한 사전결정된 물리적 홍채 직경의 조합,상기 사용자의 상기 적어도 하나의 이미지와 정렬된 깊이 맵, 또는상기 적어도 하나의 이미지에 있고 크기 참조로서 알려진 물리적 크기를 갖는 물체중 적어도 하나에 기초하여 추정되는,방법.</claim></claimInfo><claimInfo><claim>34. 제32항에 있어서,상기 적어도 하나의 이미지는 상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 이미지를 포함하고,상기 현재 거리를 결정하는 단계는, 상기 이미지에서 상기 사용자의 동공 사이의 픽셀 PD(픽셀 단위)를 결정하는 단계와, 상기 카메라의 초점 거리(픽셀 단위), 상기 픽셀 PD(픽셀 단위) 및 상기 물리적 PD를 기반으로 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>35. 제32항에 있어서,상기 적어도 하나의 이미지는 각각 상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 복수의 이미지를 포함하고,상기 현재 거리를 결정하는 단계는, 상기 복수의 이미지 각각에서, 상기 사용자의 동공 사이의 픽셀 PD(픽셀 단위)를 결정하는 단계와, 상기 카메라의 초점 거리(픽셀 단위), 상기 픽셀 PD(픽셀 단위) 및 상기 물리적 PD를 기반으로 상기 사용자로부터 상기 디스플레이 화면까지의 추정된 현재 거리를 결정하여 복수의 추정된 현재 거리를 생성하는 단계와, 상기 복수의 추정된 현재 거리의 집계에 기초하여 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 단계 - 상기 집계는 상기 복수의 추정된 현재 거리에 기초하여 평균, 가중 평균 또는 중앙값을 계산하는 것을 포함함 - 를 포함하는,방법.</claim></claimInfo><claimInfo><claim>36. 제31항에 있어서,상기 적어도 하나의 물리적 길이 특징은 상기 사용자의 물리적 어깨 너비(&quot;SW&quot;)를 포함하는,방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서,상기 사용자의 상기 물리적 SW는,모집단의 물리적 SW에 기초한 사전결정된 상수 값,상기 사용자의 상기 적어도 하나의 이미지와 정렬된 깊이 맵, 또는상기 적어도 하나의 이미지에 있고 상기 물리적 SW에 대한 크기 참조로서 알려진 물리적 크기를 갖는 물체중 적어도 하나에 기초하여 추정되는,방법.</claim></claimInfo><claimInfo><claim>38. 제36항에 있어서,상기 적어도 하나의 이미지는 상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 이미지를 포함하고,상기 현재 거리를 결정하는 단계는, 상기 이미지에서 상기 사용자의 픽셀 SW(픽셀 단위)를 결정하는 단계와 상기 카메라의 초점 거리(픽셀 단위), 상기 픽셀 SW(픽셀 단위) 및 상기 물리적 SW를 기반으로 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>39. 제36항에 있어서,상기 적어도 하나의 이미지는 각각 상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 복수의 이미지를 포함하고,상기 현재 거리를 결정하는 단계는, 상기 복수의 이미지 각각에서, 상기 사용자의 픽셀 SW(픽셀 단위)를 결정하는 단계와, 상기 복수의 이미지 각각에 대해, 상기 카메라의 초점 거리(픽셀 단위), 상기 픽셀 SW(픽셀 단위) 및 상기 물리적 SW에 기초하여 상기 사용자로부터 상기 디스플레이 화면까지의 추정된 현재 거리를 결정하여 복수의 추정된 현재 거리를 생성하는 단계와, 상기 복수의 추정된 현재 거리의 집계에 기초하여 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 단계 - 상기 집계는 상기 복수의 추정된 현재 거리에 기초하여 평균, 가중 평균 또는 중앙값을 계산하는 것을 포함함 - 를 포함하는,방법.</claim></claimInfo><claimInfo><claim>40. 제31항에 있어서,상기 적어도 하나의 이미지는,상기 사용자가 상기 디스플레이 화면으로부터 초기 거리에 있을 때 캡처된 제1 이미지, 및상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 제2 이미지 - 상기 현재 거리는 상기 초기 거리보다 크고, 상기 초기 거리보다 상기 사전결정된 거리에 더 가까움 - 를 포함하고,상기 현재 거리를 결정하는 단계는, 상기 제1 이미지에서, 상기 사용자의 제1 특징의 제1 길이(픽셀 단위) 및 상기 사용자의 제2 특징의 제2 길이(픽셀 단위)를 결정하는 단계와, 상기 제2 길이와 상기 제1 길이 사이의 제1 비율을 계산하는 단계와, 상기 제2 이미지에서, 상기 사용자의 상기 제2 특징의 제3 길이(픽셀 단위)를 결정하는 단계와, 상기 카메라의 초점 거리(픽셀 단위), 상기 제1 비율, 상기 제3 길이(픽셀 단위) 및 상기 제1 특징의 물리적 길이에 기초하여 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>41. 제31항에 있어서,상기 적어도 하나의 이미지는,상기 사용자가 디스플레이 화면으로부터 초기 거리에 있을 때 캡처된 제1 이미지, 및상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 제2 이미지 - 상기 현재 거리는 상기 초기 거리보다 크고, 상기 초기 거리보다 사전결정된 거리에 더 가까움 - 를 포함하되,상기 현재 거리를 결정하는 단계는, 상기 제1 이미지에서, 상기 사용자의 제1 특징의 제1 길이(픽셀 단위) 및 상기 사용자의 제2 특징 중 각각의 제2 특징의 복수의 제2 길이(각각 픽셀 단위)를 결정하는 단계와, 상기 복수의 제2 길이 각각과 상기 제1 길이 사이의 각각의 비율을 계산하는 단계와, 상기 제2 이미지에서, 상기 사용자의 각각의 제2 특징의 각각의 제3 길이(픽셀 단위)를 결정하는 단계와, 각각의 제2 특징과 관련하여, 상기 카메라의 초점 거리(픽셀 단위), 상기 각각의 비율, 상기 각각의 제3 길이(픽셀 단위), 및 상기 제1 특징의 물리적 길이에 기초하여 상기 사용자로부터 상기 디스플레이 화면까지의 추정된 현재 거리를 결정하여 복수의 추정된 현재 거리를 생성하는 단계와, 상기 복수의 추정된 현재 거리의 집계에 기초하여 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 단계 - 상기 집계는 상기 복수의 추정된 현재 거리에 기초하여 평균, 가중 평균, 또는 중앙값을 계산하는 것을 포함함 - 를 포함하는,방법.</claim></claimInfo><claimInfo><claim>42. 제41항에 있어서,상기 제1 특징은 상기 사용자의 동공 거리(&quot;PD&quot;)를 포함하고,상기 제2 특징은 상기 사용자의 어깨 너비, 상기 사용자의 머리 너비, 상기 사용자의 머리 높이, 또는 사용자의 신장 중 적어도 하나를 포함하는,방법.</claim></claimInfo><claimInfo><claim>43. 제31항에 있어서,상기 카메라의 초점 거리는 상기 디스플레이 화면으로부터 알려진 거리에 있는 참조 물체의 이미지에 기초하여 사전결정되는,방법.</claim></claimInfo><claimInfo><claim>44. 제31항에 있어서,상기 사용자를 상호작용식으로 안내하는 단계는,상기 사용자와 상기 모바일 장치 사이의 상기 현재 거리의 제1 표시를 디스플레이 화면에 제시하는 단계와,상기 사전결정된 거리에 도달했을 때 상기 사용자에게 제2 표시를 제공하는 단계와,상기 사용자에게 상기 디스플레이 화면을 기준으로 한 방향으로 이동하라는 명령을 제공하는 단계와,상기 적어도 하나의 이미지에서 상기 사용자의 상기 적어도 하나의 물리적 길이 특징이 차단되면 상기 사용자에게 명령을 제공하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>45. 제29항에 있어서,상기 사전결정된 거리는 사전결정된 거리 범위 내의 거리이고 공칭 거리와는 다르며,상기 방법은,상기 사용자로부터 수신된 입력에 기초하여 상기 사용자에 대한 제1 시력 점수를 결정하는 단계와,상기 공칭 거리와 상기 사전결정된 거리의 비율에 적어도 부분적으로 기초하여 상기 사용자에 대한 시력 교정 계산을 결정하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>46. 모바일 장치로서,카메라와,디스플레이 화면과,명령어를 포함하는 메모리와,상기 카메라에 결합된 프로세서를 포함하되, 상기 프로세서는 상기 명령어를 실행하여, 상기 카메라를 이용하여 사용자의 적어도 하나의 이미지를 캡처하고, 상기 적어도 하나의 이미지에 기초하여 상기 사용자를 상기 디스플레이 화면으로부터 사전결정된 거리까지 상호작용식으로 안내하며, 상기 사용자가 상기 디스플레이 화면으로부터 상기 사전결정된 거리에 있다고 결정할 때 상기 디스플레이 화면에 상기 사용자의 시력의 적어도 하나의 특성을 평가하기 위한 자료를 제시하고, 상기 디스플레이 화면에 제시된 자료에 응답하여 상기 사용자로부터 입력을 수신하도록 구성되는,모바일 장치.</claim></claimInfo><claimInfo><claim>47. 제46항에 있어서,상기 모바일 장치는 대략 수직인 표면에 대해 홀딩되고,상기 카메라와 상기 디스플레이 화면은 상기 모바일 장치의 같은 쪽에 위치되며,상기 사전결정된 거리는 약 10 피트인,모바일 장치.</claim></claimInfo><claimInfo><claim>48. 제46항에 있어서,상기 프로세서는 또한 상기 명령어를 실행하여,상기 사용자의 적어도 하나의 물리적 길이 특징을 추정하고,상기 카메라의 초점 거리, 상기 적어도 하나의 이미지 및 상기 적어도 하나의 물리적 길이 특징에 기초하여 상기 사용자로부터 상기 모바일 장치의 디스플레이 화면까지의 현재 거리를 결정하도록 구성되되,상기 사용자는 상기 현재 거리에 기초하여 상기 디스플레이 화면으로부터 상기 사전결정된 거리까지 상호작용식으로 안내되는,모바일 장치.</claim></claimInfo><claimInfo><claim>49. 제46항에 있어서,상기 적어도 하나의 물리적 길이 특징은 상기 사용자의 동공 거리(&quot;PD&quot;)를 포함하는,모바일 장치.</claim></claimInfo><claimInfo><claim>50. 제49항에 있어서,상기 적어도 하나의 이미지는 상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 이미지를 포함하고,상기 현재 거리는, 상기 이미지에서 상기 사용자의 동공 사이의 픽셀 PD(픽셀 단위)를 결정하는 것과, 상기 카메라의 초점 거리(픽셀 단위), 상기 픽셀 PD(픽셀 단위) 및 상기 물리적 PD를 기반으로 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 것에 기초하여 결정되는,모바일 장치.</claim></claimInfo><claimInfo><claim>51. 제48항에 있어서,상기 적어도 하나의 이미지는,상기 사용자가 상기 디스플레이 화면으로부터 초기 거리에 있을 때 캡처된 제1 이미지, 및상기 사용자가 상기 디스플레이 화면으로부터 상기 현재 거리에 있을 때 캡처된 제2 이미지 - 상기 현재 거리는 상기 초기 거리보다 크고, 상기 초기 거리보다 상기 사전결정된 거리에 더 가까움 - 를 포함하고,상기 현재 거리는, 상기 제1 이미지에서, 상기 사용자의 제1 특징의 제1 길이(픽셀 단위) 및 상기 사용자의 제2 특징의 제2 길이(픽셀 단위)를 결정하는 것과, 상기 제2 길이와 상기 제1 길이 사이의 제1 비율을 계산하는 것과, 상기 제2 이미지에서, 상기 사용자의 상기 제2 특징의 제3 길이(픽셀 단위)를 결정하는 것과, 상기 카메라의 초점 거리(픽셀 단위), 상기 제1 비율, 상기 제3 길이(픽셀 단위) 및 상기 제1 특징의 물리적 길이에 기초하여 상기 사용자로부터 상기 디스플레이 화면까지의 상기 현재 거리를 계산하는 것에 기초하여 결정되는,모바일 장치.</claim></claimInfo><claimInfo><claim>52. 제46항에 있어서,상기 사전결정된 거리는 사전결정된 거리 범위 내의 거리이고 공칭 거리와는 다르며,상기 프로세서는 명령어를 실행하여,상기 사용자로부터 수신된 입력에 기초하여 상기 사용자에 대한 제1 시력 점수를 결정하고,상기 공칭 거리와 상기 사전결정된 거리의 비율에 적어도 부분적으로 기초하여 상기 사용자에 대한 시력 교정 계산을 결정하도록 구성되는,모바일 장치.</claim></claimInfo><claimInfo><claim>53. 머신 실행가능 명령어가 구현된 비일시적 머신 판독가능 매체로서,상기 머신 실행가능 명령어는, 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 방법을 수행하게 하되, 상기 방법은,모바일 장치의 카메라를 이용하여 사용자의 적어도 하나의 이미지를 캡처하는 단계와,상기 적어도 하나의 이미지에 기초하여 상기 사용자를 상기 모바일 장치의 디스플레이 화면으로부터 사전결정된 거리까지 상호작용식으로 안내하는 단계와,상기 사용자가 상기 디스플레이 화면으로부터 사전결정된 거리에 있다고 결정할 때 상기 디스플레이 화면에 상기 사용자의 시력의 적어도 하나의 특성을 평가하기 위한 자료를 제시하는 단계와,상기 디스플레이 화면에 제시된 자료에 응답하여 상기 사용자로부터 입력을 수신하는 단계를 포함하는,비일시적 머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>54. 제53항에 있어서,상기 사전결정된 거리는 사전결정된 거리 범위 내의 거리이고 공칭 거리와는 다르며,상기 방법은,상기 사용자로부터 수신된 입력에 기초하여 상기 사용자에 대한 제1 시력 점수를 결정하는 단계와,상기 공칭 거리와 상기 사전결정된 거리의 비율에 적어도 부분적으로 기초하여 상기 사용자에 대한 시력 교정 계산을 결정하는 단계를 포함하는,비일시적 머신 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 뉴욕주 ***** 뉴욕 이스트 * 플로어 스프링 스트리트 ***</address><code>520110442691</code><country>미국</country><engName>Warby Parker Inc.</engName><name>와비 파커 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 뉴욕주 ***** 뉴욕 ...</address><code> </code><country> </country><engName>GOLDBERG, David H.</engName><name>골드버그 데이비드 에이치</name></inventorInfo><inventorInfo><address>미국 뉴저지주 ****...</address><code> </code><country> </country><engName>DUFFY, Taylor Alexandra</engName><name>더피 테일러 알렉산드라</name></inventorInfo><inventorInfo><address>미국 뉴저지주 ****...</address><code> </code><country> </country><engName>DESHAZER, David J.</engName><name>데샤저 데이비드 제이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.07.07</priorityApplicationDate><priorityApplicationNumber>63/219,327</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.02.06</receiptDate><receiptNumber>1-1-2024-0148508-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.02.08</receiptDate><receiptNumber>1-5-2024-0025499-03</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.07.04</receiptDate><receiptNumber>1-1-2025-0756390-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.07.04</receiptDate><receiptNumber>1-1-2025-0756408-56</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247004477.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c933767138308abd9a84f9fc47b1c55ef06b0e20da587c366ed133bf9e5f21956ff182e146ebc2f64a471b043f918c0c92f290bf9d16bad1d87</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf3b4ce4f435de46fc5f37c89de8f4f4e5121ac9c41b49cec90b95c6ad54f1aa7d04de98e8ab0858c0096f0a055a2b3ed1d358989c6a6ca1c2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>