<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:07.407</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7010120</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>직관적인 설계에 기반한 오브젝트들과의 물리적 제스처 상호작용</inventionTitle><inventionTitleEng>PHYSICAL GESTURE INTERACTION WITH OBJECTS BASED ON INTUITIVE DESIGN</inventionTitleEng><openDate>2025.04.25</openDate><openNumber>10-2025-0056250</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/03</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 협업 오브젝트 및 추가된 가상 콘텐츠에 대한 액세스가 참여자들/사용자들에게 선택적으로 제공되는 협업 세션(예컨대, 가상 시간 캡슐). 협업 세션의 일 예에서, 사용자는 손 제스처들을 사용하여 협업 오브젝트와 상호작용한다. 협업 오브젝트와 연관된 가상 콘텐츠는 여는 손 제스처를 이용하여 액세스될 수 있고, 가상 콘텐츠는 닫는 손 제스처를 이용하여 숨겨질 수 있다. 손 제스처들은 사용자에 의해 사용되는 클라이언트 디바이스의 카메라들에 의해 검출된다. 협업 오브젝트는 포인팅 제스처를 사용하여 이동 및 조작될 수 있으며, 여기서 협업 오브젝트의 포지션은 사용자의 클라이언트 디바이스를 기울임으로써 새로운 포지션으로 확인될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.07</internationOpenDate><internationOpenNumber>WO2024049579</internationOpenNumber><internationalApplicationDate>2023.07.25</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/028537</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 상호작용형 증강 현실 방법을 수행하도록 구성된 프로세서를 갖는 시스템으로서,상기 프로세서는, 개개의 물리적으로 원격인 디바이스를 사용하여 협업 오브젝트에 대한 액세스를 수신하고 — 상기 물리적으로 원격인 디바이스는 디스플레이 및 이미지들을 캡처하도록 구성된 카메라를 포함함 —; 상기 디스플레이 상에서 상기 협업 오브젝트를 제시하고; 캡처된 이미지들에서 손을 검출하고; 상기 캡처된 이미지들에서 손을 이용하여 만들어진 일련의 손 형상들을 검출하고; 상기 일련의 손 형상들이 복수의 미리 정의된 손 제스처들 중 미리 정의된 손 제스처와 매칭하는지 여부를 결정하고; 그리고 매칭된 미리 정의된 손 제스처에 따라 상기 디스플레이 상에서 제시된 상기 협업 오브젝트를 수정하도록구성되는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 프로세서는, 오브젝트 포지션에서 협업 오브젝트에 대한 액세스를 사용자들에게 제공하고; 그리고 상기 사용자들로부터 수신된 가상 콘텐츠를 상기 협업 오브젝트와 연관시키도록추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 협업 오브젝트는 가상 용기(vessel)이고, 상기 미리 정의된 손 제스처는 상기 손이 주먹으로부터 열린 손바닥으로 열리는 것이고, 상기 협업 오브젝트를 수정하는 것은 상기 협업 오브젝트의 연관된 가상 콘텐츠에 대한 액세스를 제공하는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 프로세서는, 상기 캡처된 이미지들에서 다른 일련의 손 형상들을 검출하고; 상기 다른 일련의 손 형상들이 상기 복수의 미리 정의된 손 제스처들 중 다른 미리 정의된 손 제스처와 매칭하는지 여부를 결정하고; 그리고 상기 다른 미리 정의된 손 제스처와 매칭하는 것에 따라 상기 디스플레이 상에서 제시된 상기 협업 오브젝트를 수정하도록추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 다른 미리 정의된 손 제스처는 상기 손이 상기 열린 손바닥으로부터 상기 주먹으로 닫히는 것이고, 상기 협업 오브젝트를 수정하는 것은 상기 협업 오브젝트의 연관된 가상 콘텐츠에 대한 액세스를 금지하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서,상기 손 제스처는 상기 손의 검지 손가락(index finger)이 상기 디스플레이에 대한 상기 오브젝트 포지션으로 펼쳐지는 것이고, 상기 수정하는 것은 상기 협업 오브젝트의 일부를 선택하는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 프로세서는, 상기 오브젝트 포지션을 손 포지션에 매칭시키고 — 상기 오브젝트 포지션은 상기 손 포지션이 변경될 때 상기 손 포지션을 따르도록 구성됨 —; 그리고 상기 물리적으로 원격인 디바이스가 기울어질 때 상기 오브젝트 포지션을 확인하도록추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 손 제스처는 열린 손이 상기 카메라에 더 가깝게 이동되는 것이고, 상기 수정하는 것은 사용자에게 더 가깝게 나타나도록 상기 협업 오브젝트를 수정하는, 시스템.</claim></claimInfo><claimInfo><claim>9. 프로세서에 의해 수행되는 상호작용형 증강 현실 방법으로서,개개의 물리적으로 원격인 디바이스를 사용하여 협업 오브젝트에 대한 액세스를 수신하는 단계 — 상기 물리적으로 원격인 디바이스는 이미지들을 캡처하도록 구성된 디스플레이 및 카메라를 포함함 —;상기 디스플레이 상에서 상기 협업 오브젝트를 제시하는 단계;캡처된 이미지들에서 손을 검출하는 단계;상기 캡처된 이미지들에서 손을 이용하여 만들어진 일련의 손 형상들을 검출하는 단계;상기 일련의 손 형상들이 복수의 미리 정의된 손 제스처들 중 미리 정의된 손 제스처와 매칭하는지 여부를 결정하는 단계; 및매칭된 미리 정의된 손 제스처에 따라 상기 디스플레이 상에서 제시된 상기 협업 오브젝트를 수정하는 단계를 포함하는, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,오브젝트 포지션에서 협업 오브젝트에 대한 액세스를 사용자들에게 제공하는 단계; 및상기 사용자들로부터 수신된 가상 콘텐츠를 상기 협업 오브젝트와 연관시키는 단계를 더 포함하는, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 협업 오브젝트는 가상 용기이고, 상기 미리 정의된 손 제스처는 상기 손이 주먹으로부터 열린 손바닥으로 열리는 것이고, 상기 협업 오브젝트를 수정하는 단계는 상기 협업 오브젝트의 상기 연관된 가상 콘텐츠에 대한 액세스를 제공하는, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 캡처된 이미지들에서 다른 일련의 손 형상들을 검출하는 단계;상기 다른 일련의 손 형상들이 상기 복수의 미리 정의된 손 제스처들 중 다른 미리 정의된 손 제스처와 매칭하는지 여부를 결정하는 단계; 및상기 다른 미리 정의된 손 제스처와 매칭하는 것에 따라 상기 디스플레이 상에서 제시된 상기 협업 오브젝트를 수정하는 단계를 더 포함하는, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 다른 미리 정의된 손 제스처는 상기 손이 상기 열린 손바닥으로부터 상기 주먹으로 닫히는 것이고, 상기 협업 오브젝트를 수정하는 단계는 상기 협업 오브젝트의 연관된 가상 콘텐츠에 대한 액세스를 금지하는, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,상기 손 제스처는 상기 손의 검지 손가락이 상기 디스플레이에 대한 상기 오브젝트 포지션으로 펼쳐지는 것이고, 상기 수정하는 단계는 상기 협업 오브젝트의 일부를 선택하는 단계인, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 오브젝트 포지션을 손 포지션에 매칭시키는 단계 — 상기 오브젝트 포지션은 상기 손 포지션이 변경될 때 상기 손 포지션을 따르도록 구성됨 —; 및상기 물리적으로 원격인 디바이스가 기울어질 때 상기 오브젝트 포지션을 확인하는 단계를 더 포함하는, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>16. 제9항에 있어서,상기 손 제스처는 열린 손이 상기 카메라에 더 가깝게 이동되는 것이고, 상기 수정하는 단계는 사용자에게 더 가깝게 나타나도록 상기 협업 오브젝트를 수정하는, 상호작용형 증강 현실 방법.</claim></claimInfo><claimInfo><claim>17. 프로그램 코드를 저장하는 비-일시적인 컴퓨터-판독가능 매체로서,상기 프로그램 코드는, 프로세서에 의해 실행될 때, 개개의 물리적으로 원격인 디바이스를 사용하여 협업 오브젝트에 대한 액세스를 수신하고 — 상기 물리적으로 원격인 디바이스는 디스플레이 및 이미지들을 캡처하도록 구성된 카메라를 포함함 —; 상기 디스플레이 상에서 상기 협업 오브젝트를 제시하고; 캡처된 이미지들에서 손을 검출하고; 상기 캡처된 이미지들에서 손을 이용하여 만들어진 일련의 손 형상들을 검출하고; 상기 일련의 손 형상들이 복수의 미리 정의된 손 제스처들 중 미리 정의된 손 제스처와 매칭하는지 여부를 결정하고; 그리고 매칭된 미리 정의된 손 제스처에 따라 상기 디스플레이 상에서 제시된 상기 협업 오브젝트를 수정하도록상기 프로세서를 구성하는, 비-일시적인 컴퓨터-판독가능 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서에 의해 실행될 때, 협업 오브젝트에 대한 액세스를 사용자들에게 제공하고; 그리고 상기 사용자들로부터 수신된 가상 콘텐츠를 상기 협업 오브젝트와 연관시키도록상기 프로세서를 추가로 구성하는 프로그램 코드를 저장하는, 비-일시적인 컴퓨터-판독가능 매체.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 협업 오브젝트는 가상 용기이고, 상기 미리 정의된 손 제스처는 상기 손이 주먹으로부터 열린 손바닥으로 열리는 것이고, 상기 협업 오브젝트를 수정하는 것은 상기 협업 오브젝트의 연관된 가상 콘텐츠에 대한 액세스를 제공하는, 비-일시적인 컴퓨터-판독가능 매체.</claim></claimInfo><claimInfo><claim>20. 제17항에 있어서,상기 프로세서에 의해 실행될 때, 상기 캡처된 이미지들에서 다른 일련의 손 형상들을 검출하고; 상기 다른 일련의 손 형상들이 상기 복수의 미리 정의된 손 제스처들 중 다른 미리 정의된 손 제스처와 매칭하는지 여부를 결정하고; 그리고 상기 다른 미리 정의된 손 제스처와 매칭하는 것에 따라 상기 디스플레이 상에서 제시된 상기 협업 오브젝트를 수정하도록상기 프로세서를 추가로 구성하는 프로그램 코드를 저장하는, 비-일시적인 컴퓨터-판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>대한민국</country><engName>CHO, Youjean</engName><name>조, 유진</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>중국</country><engName>JI, Chen</engName><name>지, 첸</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>LIU, Fannie</engName><name>리우, 패니</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>멕시코</country><engName>MONROY-HERNANDEZ, Andres</engName><name>몬로이-에르난데스, 안드레스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>대만</country><engName>TSAI, Tsung-Yu</engName><name>차이, 정-유</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>인도</country><engName>VAISH, Rajan</engName><name>바이쉬, 라잔</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.31</priorityApplicationDate><priorityApplicationNumber>17/900,817</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.27</receiptDate><receiptNumber>1-1-2025-0347673-56</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.04.01</receiptDate><receiptNumber>1-5-2025-0054265-30</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257010120.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9394bba7dc0958ae506f4c830fb1da12f663dfe94e6a176c04b59d021d94f6311e8aa5f2fe78678abc58ada36f68a3f74cf3525beccaf65161</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0a7545679e173d3131f11cbded193f72f7aaeda682fd8eb61b5e2cba92106c2a6fa666c52d95ab086c553fecb0526f5e4f0c392ce80338f7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>