<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:59.459</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.07.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7045364</applicationNumber><claimCount>34</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다수의 관심 영역들을 갖는 장면들에서 선택적으로 증가하는 피사계 심도</inventionTitle><inventionTitleEng>SELECTIVELY INCREASING DEPTH-OF-FIELD IN SCENES WITH MULTIPLE REGIONS OF INTEREST</inventionTitleEng><openDate>2024.03.07</openDate><openNumber>10-2024-0031246</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.06.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.12.28</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/959</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/92</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/68</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용은 이미지 프레임을 캡처하는 데 사용되는 카메라의 큰 조리개 크기 또는 다른 특성들로 인해 블러링될 수 있는 배경 면들과 같은 배경 관심 영역(region of interest, ROI)들에 대한 다중 프레임 피사계 심도(multi-frame depth-of-field, MF-DOF)를 지원하는 시스템들, 장치, 방법들, 및 컴퓨터 판독가능 매체를 제공한다. 프로세싱은 이미지 프레임 내의 다수의 ROI들에 대응하는 2개의 상이한 포커스 포인트들에서 획득된 2개의 이미지 프레임들의 사용을 포함할 수 있다. 보정된 이미지 프레임은 AI 기반 모델 및/또는 로컬 그레이디언트(local gradient) 정보를 사용하여 제1 이미지 프레임의 하나 이상의 ROI들을 디블러링함으로써 결정될 수 있다. MF-DOF는 이미지의 피사계 심도(DOF)를 선택적으로 증가시키는 것이, 사진촬영에 요구될 수 있는 배경 블러 또는 조리개(및 후속적으로 사진촬영에 이용가능한 광의 양)의 감소를 야기하지 않고서, 다수의 관심 영역들의 포커싱된 캡처를 제공하게 할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.01.12</internationOpenDate><internationOpenNumber>WO2023283540</internationOpenNumber><internationalApplicationDate>2022.07.01</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/073395</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,제1 포커스 거리에서 캡처된 장면을 나타내는 제1 이미지 프레임을 수신하는 단계;상기 제1 포커스 거리와는 상이한 제2 포커스 거리에서 캡처된 상기 장면을 나타내는 제2 이미지 프레임을 수신하는 단계;상기 제1 이미지 프레임 내의 제1 관심 영역 및 상기 제2 이미지 프레임 내의 제2 관심 영역을 포함하는 대응하는 세트의 관심 영역들을 결정하는 단계;상기 제1 관심 영역과 상기 제2 관심 영역의 비교에 기초하여 값을 결정하는 단계; 및상기 제1 이미지 프레임 및 상기 값에 기초하여 보정된 제1 이미지 프레임을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 관심 영역 및 상기 제2 관심 영역 내에서 제1 면을 결정하는 단계; 및제3 관심 영역 내에서 제2 면을 결정하는 단계를 추가로 포함하고,상기 보정된 제1 이미지 프레임을 결정하는 단계는 상기 제1 면 및 상기 제2 면이 상기 보정된 제1 이미지 프레임 내에서 인-포커스(in-focus)로 보이도록 상기 제1 면의 디테일을 증가시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 값을 결정하는 단계는 상기 제1 관심 영역과 상기 제2 관심 영역 사이의 로컬 그레이디언트(local gradient) 차이를 결정하는 단계를 포함하고;상기 보정된 제1 이미지 프레임을 결정하는 단계는 상기 로컬 그레이디언트 차이에 기초하여 상기 제1 이미지 프레임의 상기 제1 관심 영역에 대해 콘트라스트 동작을 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 콘트라스트 동작을 수행하는 단계는 상기 제1 이미지 프레임의 밝기를 보존하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 보정된 제1 이미지 프레임을 결정하는 단계는 인공 지능 기반 동작을 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제1 관심 영역과 상기 제2 관심 영역 사이의 정렬 차이를 결정하는 단계를 추가로 포함하고,상기 값을 결정하는 단계는 상기 정렬 차이에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 정렬 차이를 결정하는 단계는 상기 제1 이미지 프레임 내의 제1 위치로부터 상기 제2 이미지 프레임 내의 제2 위치로의 상기 제1 이미지 프레임 내에서 인식되는 객체의 모션을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제1 이미지 프레임 내의 관심 영역들의 수를 결정하는 단계를 추가로 포함하고,상기 제2 이미지 프레임을 수신하는 단계, 상기 값을 결정하는 단계, 및 상기 보정된 제1 이미지 프레임을 결정하는 단계를 수행하는 것은 상기 관심 영역들의 수가 1 초과인 것에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 제1 이미지 프레임 내의 상기 관심 영역들의 수를 결정하는 단계는 상기 제1 이미지 프레임 내에서 면들을 검출하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 제1 포커스 거리는 상기 제1 관심 영역 및 상기 제2 관심 영역 내의 제1 면과 연관되고;상기 제2 포커스 거리는 제3 관심 영역 내의 상이한 제2 면과 연관되는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 제1 포커스 거리는 상기 제1 관심 영역 내의 상기 제1 면과 상기 제3 관심 영역 내의 상기 제2 면 사이의 위치이고, 상기 제2 포커스 거리는 상기 제2 면의 포커스 거리인, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 보정된 제1 이미지 프레임을 결정하는 단계는 상기 제2 이미지 프레임의 임의의 부분을 상기 제1 이미지 프레임과 조합하는 것에 기초하지 않는, 방법.</claim></claimInfo><claimInfo><claim>13. 장치로서,프로세서 판독가능 코드를 저장하는 메모리; 및상기 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는 상기 프로세서 판독가능 코드를 실행시켜 상기 적어도 하나의 프로세서로 하여금 동작들을 수행하게 하도록 구성되고, 상기 동작들은, 제1 포커스 거리에서 캡처된 장면을 나타내는 제1 이미지 프레임을 수신하는 동작; 상기 제1 포커스 거리와는 상이한 제2 포커스 거리에서 캡처된 상기 장면을 나타내는 제2 이미지 프레임을 수신하는 동작; 상기 제1 이미지 프레임 내의 제1 관심 영역 및 상기 제2 이미지 프레임 내의 제2 관심 영역을 포함하는 대응하는 세트의 관심 영역들을 결정하는 동작; 상기 제1 관심 영역과 상기 제2 관심 영역의 비교에 기초하여 값을 결정하는 동작; 및 상기 제1 이미지 프레임 및 상기 값에 기초하여 보정된 제1 이미지 프레임을 결정하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 적어도 하나의 프로세서는 상기 프로세서 판독가능 코드를 실행시켜 상기 적어도 하나의 프로세서로 하여금 동작들을 수행하게 하도록 추가로 구성되고, 상기 동작들은,상기 제1 관심 영역 및 상기 제2 관심 영역 내에서 제1 면을 결정하는 동작; 및제3 관심 영역 내에서 제2 면을 결정하는 동작을 포함하고,상기 보정된 제1 이미지 프레임을 결정하는 동작은 상기 제1 면 및 상기 제2 면이 상기 보정된 제1 이미지 프레임 내에서 인-포커스로 보이도록 상기 제1 면의 디테일을 증가시키는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 값을 결정하는 동작은 상기 제1 관심 영역과 상기 제2 관심 영역 사이의 로컬 그레이디언트 차이를 결정하는 동작을 포함하고;상기 보정된 제1 이미지 프레임을 결정하는 동작은 상기 로컬 그레이디언트 차이에 기초하여 상기 제1 이미지 프레임의 상기 제1 관심 영역에 대해 콘트라스트 동작을 수행하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 콘트라스트 동작을 수행하는 동작은 상기 제1 이미지 프레임의 밝기를 보존하는, 장치.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서, 상기 보정된 제1 이미지 프레임을 결정하는 동작은 인공 지능 기반 동작을 수행하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서, 상기 적어도 하나의 프로세서는 상기 프로세서 판독가능 코드를 실행시켜 상기 적어도 하나의 프로세서로 하여금 추가 동작들을 수행하게 하도록 구성되고, 상기 추가 동작들은,상기 제1 관심 영역과 상기 제2 관심 영역 사이의 정렬 차이를 결정하는 동작을 포함하고,값을 결정하는 동작은 상기 정렬 차이에 기초하는, 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 정렬 차이를 결정하는 동작은 상기 제1 이미지 프레임 내의 제1 위치로부터 상기 제2 이미지 프레임 내의 제2 위치로의 상기 제1 이미지 프레임 내에서 인식되는 객체의 모션을 결정하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>20. 제13항에 있어서, 상기 적어도 하나의 프로세서는 상기 프로세서 판독가능 코드를 실행시켜 상기 적어도 하나의 프로세서로 하여금 추가 동작들을 수행하게 하도록 구성되고, 상기 추가 동작들은,상기 제1 이미지 프레임 내의 관심 영역들의 수를 결정하는 동작을 포함하고,상기 제2 이미지 프레임을 수신하는 동작, 상기 값을 결정하는 동작, 및 상기 보정된 제1 이미지 프레임을 결정하는 동작을 수행하는 것은 상기 관심 영역들의 수가 1 초과인 것에 기초하는, 장치.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 제1 이미지 프레임 내의 상기 관심 영역들의 수를 결정하는 동작은 상기 제1 이미지 프레임 내에서 면들을 검출하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>22. 제13항에 있어서,상기 제1 포커스 거리는 상기 제1 관심 영역 및 상기 제2 관심 영역 내의 제1 면과 연관되고;상기 제2 포커스 거리는 제3 관심 영역 내의 상이한 제2 면과 연관되는, 장치.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 제1 포커스 거리는 상기 제1 관심 영역 내의 상기 제1 면과 상기 제3 관심 영역 내의 상기 제2 면 사이의 위치이고, 상기 제2 포커스 거리는 상기 제2 면의 포커스 거리인, 장치.</claim></claimInfo><claimInfo><claim>24. 제13항에 있어서, 상기 보정된 제1 이미지 프레임을 결정하는 동작은 상기 제2 이미지 프레임의 임의의 부분을 상기 제1 이미지 프레임과 조합하는 것에 기초하지 않는, 장치.</claim></claimInfo><claimInfo><claim>25. 제13항에 있어서,이미지 센서 및 렌즈를 포함하는 카메라를 추가로 포함하고,상기 적어도 하나의 프로세서는 상기 카메라에 커플링되고 동작들을 수행하도록 구성되며, 상기 동작들은, 상기 제1 포커스 거리에서 상기 제1 이미지 프레임을 캡처하도록 상기 카메라를 제어하는 동작; 상기 제1 이미지 프레임 내에서 제1 면 및 제2 면의 존재를 결정하는 동작; 및 상기 제1 이미지 프레임 내에서 상기 제1 면 및 상기 제2 면의 존재를 결정하는 것에 기초하여 상기 제2 포커스 거리에서 상기 제2 이미지 프레임을 캡처하도록 상기 카메라를 제어하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>26. 제13항에 있어서, 상기 적어도 하나의 프로세서는 이미지 신호 프로세서(image signal processor, ISP)를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>27. 명령들을 저장하는 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 명령들은, 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하고, 상기 동작들은,제1 포커스 거리에서 캡처된 장면을 나타내는 제1 이미지 프레임을 수신하는 동작;상기 제1 포커스 거리와는 상이한 제2 포커스 거리에서 캡처된 상기 장면을 나타내는 제2 이미지 프레임을 수신하는 동작;상기 제1 이미지 프레임 내의 제1 관심 영역 및 상기 제2 이미지 프레임 내의 제2 관심 영역을 포함하는 대응하는 세트의 관심 영역들을 결정하는 동작;상기 제1 관심 영역과 상기 제2 관심 영역의 비교에 기초하여 값을 결정하는 동작; 및상기 제1 이미지 프레임 및 상기 값에 기초하여 보정된 제1 이미지 프레임을 결정하는 동작을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 명령들은, 상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 추가 동작들을 수행하게 하고, 상기 추가 동작들은,상기 제1 관심 영역 및 상기 제2 관심 영역 내에서 제1 면을 결정하는 동작; 및제3 관심 영역 내에서 제2 면을 결정하는 동작을 포함하고,상기 보정된 제1 이미지 프레임을 결정하는 동작은 상기 제1 면 및 상기 제2 면이 상기 보정된 제1 이미지 프레임 내에서 인-포커스로 보이도록 상기 제1 면의 디테일을 증가시키는 동작을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>29. 제27항에 있어서,상기 값을 결정하는 동작은 상기 제1 관심 영역과 상기 제2 관심 영역 사이의 로컬 그레이디언트 차이를 결정하는 동작을 포함하고;상기 보정된 제1 이미지 프레임을 결정하는 동작은 상기 로컬 그레이디언트 차이에 기초하여 상기 제1 이미지 프레임의 상기 제1 관심 영역에 대해 콘트라스트 동작을 수행하는 동작을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>30. 제27항에 있어서, 상기 명령들은, 상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 추가 동작들을 수행하게 하고, 상기 추가 동작들은,상기 제1 이미지 프레임 내의 관심 영역들의 수를 결정하는 동작을 포함하고,상기 제2 이미지 프레임을 수신하는 동작, 상기 값을 결정하는 동작, 및 상기 보정된 제1 이미지 프레임을 결정하는 동작을 수행하는 것은 상기 관심 영역들의 수가 1 초과인 것에 기초하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>31. 장치로서,이미지 센서 및 렌즈를 포함하는 카메라;프로세서 판독가능 코드를 저장하는 메모리; 및상기 메모리 및 상기 카메라에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는 상기 프로세서 판독가능 코드를 실행시켜 상기 적어도 하나의 프로세서로 하여금 동작들을 수행하게 하도록 구성되고, 상기 동작들은, 제1 포커스 거리에서 캡처된 장면을 나타내는 제1 이미지 프레임을 획득하도록 상기 카메라를 제어하는 동작; 상기 제1 이미지 프레임이 상기 제1 포커스 거리와 연관된 제1 면 및 제2 포커스 거리와 연관된 제2 면을 포함하는 것으로 결정하는 동작; 상기 제1 포커스 거리와 상기 제2 포커스 거리 사이의 제3 포커스 거리에서 캡처된 상기 장면을 나타내는 제2 이미지 프레임을 획득하도록 상기 카메라를 제어하는 동작; 상기 제2 포커스 거리에서 캡처된 상기 장면을 나타내는 제3 이미지 프레임을 획득하도록 상기 카메라를 제어하는 동작; 상기 제1 면과 연관된 상기 제2 이미지 프레임 내의 제1 관심 영역 및 상기 제1 면과 연관된 상기 제3 이미지 프레임 내의 제2 관심 영역을 포함하는 대응하는 세트의 관심 영역들을 결정하는 동작; 상기 제1 관심 영역과 상기 제2 관심 영역의 비교에 기초하여 값을 결정하는 동작; 및 상기 제2 이미지 프레임 및 상기 값에 기초하여 보정된 이미지 프레임을 결정하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서, 상기 보정된 이미지 프레임을 결정하는 동작은 상기 제2 이미지 프레임의 제1 관심 영역에 대해 콘트라스트 향상 동작을 수행하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>33. 제32항에 있어서, 상기 제2 이미지 프레임의 상기 제1 관심 영역에 대해 상기 콘트라스트 향상 동작을 수행하는 동작은 상기 값에 대응하는 세기에 기초하는, 장치.</claim></claimInfo><claimInfo><claim>34. 제31항에 있어서, 상기 보정된 이미지 프레임을 결정하는 동작은 상기 제2 이미지 프레임의 제1 관심 영역에 대해 인공 지능 기반 동작을 수행하는 동작을 포함하는, 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>FENG, WEN-CHUN</engName><name>펑 원-춘 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>LAI, YU-REN</engName><name>라이 위-런 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>CHANG, HSIN YUEH</engName><name>창 신 웨 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.07.06</priorityApplicationDate><priorityApplicationNumber>63/218,804</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.22</priorityApplicationDate><priorityApplicationNumber>17/645,688</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.12.28</receiptDate><receiptNumber>1-1-2023-1471806-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.02.07</receiptDate><receiptNumber>1-5-2024-0024897-93</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.06.12</receiptDate><receiptNumber>1-1-2025-0658075-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.06.12</receiptDate><receiptNumber>1-1-2025-0658076-14</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237045364.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937f60d2d3ea56994529845192adee8438b815e2e079341e92a0ed3152ed2306194a6ca750a9b1de00587f4f1fb0536e74f38e8a6c56b7fc3a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf38c564fa27b2e9bd7a025a54b264a497877fcdfd969d4eb5592369e9d10f557a30361e4f8eb6b910f3ae79126211fb388166446ca677ef68</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>