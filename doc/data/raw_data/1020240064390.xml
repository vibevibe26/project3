<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:01.331</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.05.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0064390</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>머신 비전에서의 예제-기반 자동 파라미터 추정, 방법 및 시스템</inventionTitle><inventionTitleEng>Methods and Systems and Automatic Example-Based Parameter  Estimation in Machine Vision</inventionTitleEng><openDate>2025.10.24</openDate><openNumber>10-2025-0153055</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 요구되는 사용자 상호 작용을 최소화하여 런타임, 정확성 및 로버스트함을 최적화하는 동안 객체 인식 모델의 다양한 파라미터들을 추정하거나 개선하여 런타임, 정확성 및 로버스트함을 개선하기 위한 방법을 제공한다. 본 발명의 일 양태에서, 상기 방법은 정의되어 개선된 윤곽을 갖는 객체 인식 모델을 생성한다. 추가적인 방법은 본 발명에 의해 정의되어 객체 인식 알고리즘들에 대한 레벨 특정(level-specific) 파라미터들을 추정한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 객체 인식 모델의 파라미터들을 로버스트(robust)하게 업데이트하기 위한 방법에 있어서, a. 객체 인식 모델 - 상기 객체 인식 모델은 복수의 모델 포인트들을 포함하고, 상기 모델 포인트 각각은 좌표 및 방향 벡터로 증강됨 - 을 제공하는 단계;b. 적어도 하나의 디지털 이미지 - 상기 디지털 이미지 각각은 적어도 하나의 객체 인스턴스를 포함함 - 을 제공하는 단계;c. 상기 디지털 이미지 각각에 대해, 상기 디지털 이미지 내의 픽셀 각각에 대한 방향 벡터를 획득하는 단계;d. 상기 디지털 이미지 각각의 상기 객체 인스턴스 각각에 대해, 상기 객체 인식 모델을 상기 객체 인스턴스와 정렬하는 변환 파라미터들을 획득하는 단계;e. 상기 객체 인스턴스 각각에 대해, 상기 객체 인스턴스의 상기 변환 파라미터들을 적용함으로써 모델 포인트 좌표를 이미지 픽셀 좌표로 변환하는 단계;f. 모델 포인트 각각에 대해, 서로 다른 객체 인스턴스들에 대해 상기 모델 포인트 각각이 변환된 모든 픽셀들에 대한 상기 방향 벡터의 세트를 수집하는 단계;g. 상기 모델 포인트 각각에 대해, 상기 모델 포인트 각각의 모든 수집된 상기 방향 벡터의 세트 상에 결합 함수를 적용하여 신규 대표 방향 벡터를 생성하는 단계;h. 수집된 상기 방향 벡터 및 상기 대표 방향 벡터에 결정 함수를 적용하여 어떤 모델 포인트들이 안정적인 것으로 판단되어야 하는지 결정하는 단계; 및i. 안정적이라고 판단되는 상기 모델 포인트들의 상기 방향 벡터를 상기 대표 방향 벡터로 교체하고 안정적이라고 판단되지 않는 상기 모델 포인트들을 제거하여, 상기 객체 인식 모델을 업데이트하는 단계;를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 결합 함수는 모든 상기 방향 벡터들, 평균 전체 방향 벡터들 또는 모든 방향 벡터들의 로버스트한 추정기의 추가를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 결정 함수는 상기 대표 방향 벡터의 길이에 대한 임계값을 포함하는 것을 특징으로 하는 방법</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 결합 함수는 상기 모델 포인트 각각의 모든 수집된 상기 방향 벡터의 세트의 분산을 추가로 계산하고, 상기 결정 함수는 상기 분산에 대한 임계값을 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>5. 객체 인식 모델을 로버스트하게 생성하기 위한 방법에 있어서,a. 타겟 형상의 최대 범위를 제공하는 단계;b. 적어도 두 개의 디지털 이미지 - 상기 디지털 이미지 각각은 적어도 하나의 객체 인스턴스를 포함함 - 를 제공하는 단계;c. 상기 디지털 이미지 각각의 픽셀 각각에 대해, 방향 벡터를 포함하는 특징 벡터를 획득하는 단계;d. 상기 디지털 이미지 각각의 객체 인스턴스 각각에 대해, 공통 좌표 프레임에서 상기 객체 인스턴스를 정렬하는 변환 파라미터들을 획득하는 단계; e. 상기 타겟 형상의 상기 최대 범위 내에 있는 픽셀 각각에 대해, 서로 다른 객체 인스턴스들에 대해 상기 픽셀 각각이 변환된 모든 픽셀들에 대한 상기 특징 벡터의 세트를 수집하는 단계;f. 상기 타겟 형상의 상기 최대 범위 내에 있는 상기 픽셀 각각에 대해, 상기 픽셀 각각의 모든 수집된 상기 특징 벡터의 세트 상에 결합 함수를 적용하여 신규 대표 특징 벡터를 생성하는 단계;g. 수집된 상기 특징 벡터 및 상기 대표 특징 벡터에 결정 함수를 적용하여 어떤 픽셀들이 안정적인 것으로 판단되어야 하는지 결정하는 단계; 및h. 대응되는 상기 대표 특징 벡터와 함께할 때 안정적이라고 판단되는 상기 픽셀들을 사용하여 객체 인식 모델을 생성하는 단계;를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 결합 함수는 모든 상기 방향 벡터들, 평균 전체 방향 벡터들 또는 모든 상기 방향 벡터들의 로버스트한 추정기의 추가를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 또는 제6항에 있어서, 상기 결정 함수는 상기 대표 방향 벡터의 길이에 대한 임계값을 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항, 제6항 또는 제7항에 있어서, 상기 결합 함수는 상기 모델 포인트 각각의 모든 수집된 상기 방향 벡터의 세트의 분산을 추가로 계산하고, 상기 결정 함수는 상기 분산에 대한 임계값을 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 단계 c에서 계산된 상기 특징 벡터는, 대응하는 상기 픽셀의 회색 값을 추가적으로 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>10. 객체 인식 모델의 레벨 특정 파라미터들을 로버스트하게 업데이트하기 위한 방법에 있어서, a. 객체 인식 모델을 제공하는 단계;b. 적어도 하나의 디지털 이미지 - 상기 디지털 이미지 각각은 적어도 하나의 객체 인스턴스를 포함함 - 을 제공하는 단계;c. 최적화되기 위한 파라미터들의 세트를 제공하는 단계;d. 상기 디지털 이미지 각각에 대해, (i) 적어도 두 개의 다른 이산화(discretization) 레벨들이 사용되는, 개략적 레벨부터 정밀 레벨까지의 이산화 레벨들에 대응하는 상기 디지털 이미지의 다중 레벨 표현을 생성하는 세부 단계;(ii) 상기 개략적 레벨부터 정밀 레벨까지의 상기 이산화 레벨들에 대응하는 상기 디지털 이미지의 상기 다중 레벨 표현에 대한 상기 객체 인식 모델을 검색하여 검출된 인스턴스의 세트를 생성하는 세부 단계; (iii) 상기 검출된 인스턴스 각각에 대해, 각각 상기 객체 인스턴스에 대응하는지 식별하는 세부 단계;(iv) 상기 객체 인스턴스에 대응하는 것으로 식별된 상기 검출된 인스턴스 각각에 대해, 모든 상기 이산화 레벨들에 대해 상기 최적화되기 위한 파라미터들의 중간값들을 수집하는 세부 단계; 를 포함하는 단계; 및e. 상기 이산화 레벨들 각각 및 상기 최적화되기 위한 파라미터들 각각에 대해, 상기 피라미드 레벨에 대한 상기 파라미터들의 수집된 상기 중간값들에 결합 함수를 적용하여 상기 파라미터들의 로버스트한 추정치를 얻고, 상기 로버스트한 추정치를 상기 객체 인식 모델의 신규 파라미터로서 설정하는 단계;를 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 최적화되기 위한 파라미터들의 세트는 최소 점수, 최소 대비, 두 개의 매치(match)들의 최대 중첩, 회전들의 범위, 스케일들의 범위 또는 검색 영역 중 적어도 하나를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 또는 제11항에 있어서, 상기 변환 파라미터들은 상기 객체 인스턴스 각각에 대해 제공되고, 상기 변환 파라미터들은 세부 단계 (iii)에서 어떤 검출된 인스턴스가 상기 객체 인스턴스에 대응하는지를 식별하기 위해 사용되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항, 제11항 또는 제12항에 있어서, 상기 객체 인스턴스 각각에 대해 대략적인 위치들이 제공되고, 상기 대략적인 위치들은 세부 단계 (iii)에서 어떤 검출된 인스턴스가 상기 객체 인스턴스에 대응하는지를 식별하기 위해 사용되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 상기 객체 인스턴스의 수는 상기 디지털 이미지 각각에 대해 제공되고, 상기 객체 인스턴스의 수는 세부 단계 (iii)에서 어떤 검출된 인스턴스가 상기 객체 인스턴스에 대응하는지를 식별하기 위해 사용되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서,세부 단계 (iii)에서 어떤 검출된 인스턴스가 상기 객체 인스턴스에 대응하는지를 식별하기 위해 추가적인 사용자 입력이 사용되는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 결합 함수는 수집된 상기 중간값들의 분위수(quantile)이거나, 수집된 상기 중간값들에 기반하여 로버스트한 파라미터를 추정하기 위하여 확률론적 모델을 이용하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제4항 중 어느 한 항의 방법에 따라 객체 인식 모델의 파라미터들을 로버스트하게 업데이트하기 위한 방법을 실행하도록 구성되는 프로세서를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>18. 제5항 내지 제9항 중 어느 한 항의 방법에 따라 객체 인식 모델을 로버스트하게 생성하기 위한 방법을 실행하도록 구성되는 프로세서를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>19. 제10항 내지 제16항 중 어느 한 항의 방법에 따라,객체 인식 모델의 레벨 특정 파라미터들을 로버스트하게 업데이트하기 위한 방법을 실행하도록 구성되는 프로세서를 포함하는 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>독일 뮌헨 ***** 아르눌프스트라쎄 ***</address><code>520200344011</code><country>독일</country><engName>MVTec Software GmbH</engName><name>엠브이테크 소프트웨어 게엠베하</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>독일, ***** 퓌르스텐펠...</address><code> </code><country> </country><engName>Andreas Hofhauser</engName><name>안드레아스 호프하우저</name></inventorInfo><inventorInfo><address>독일, ***** 올칭...</address><code> </code><country> </country><engName>Ayah Haidar</engName><name>아야 하이다르</name></inventorInfo><inventorInfo><address>독일, ***** 비...</address><code> </code><country> </country><engName>Maximilian Meyer</engName><name>막시밀리안 메이어</name></inventorInfo><inventorInfo><address>독일, ***** 뮌...</address><code> </code><country> </country><engName>Florian Senn</engName><name>플로리안 센</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로**길 **, *층(역삼동, 케이앤와이빌딩)</address><code>920121001621</code><country>대한민국</country><engName>SU Intellectual Property</engName><name>특허법인수</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2024.04.17</priorityApplicationDate><priorityApplicationNumber>24170681.1</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.05.17</receiptDate><receiptNumber>1-1-2024-0533642-70</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(EPO)</documentEngName><documentName>우선권주장증명서류제출서(EPO)</documentName><receiptDate>2024.06.02</receiptDate><receiptNumber>9-1-2024-9005653-84</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240064390.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936fa875c21a4ac1ed5deda3fb62db8cce304c5afa001ada058215b6179a2f870862cd58c3125780765eadd0541fe1c660ea0e9f129b96c1ed</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf307354338259fa885c94545119f2bf90a1dd6061d678d4dcd1f9c71b4fa54301fed9b27c9b44765c547ff85c20cdf30bc9352c080fa8b9b7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>