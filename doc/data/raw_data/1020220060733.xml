<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:10.510</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.05.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0060733</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>깊이 보조 시각적 관성 주행 거리 측정을 위한 방법 및 장치</inventionTitle><inventionTitleEng>Method and apparayus for depth-aided visual  inertial odometry</inventionTitleEng><openDate>2022.12.01</openDate><openNumber>10-2022-0158628</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.05.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01C 21/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01C 22/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 시각적 관성 주행 거리 측정(VIO)을 수행하기 위한 방법 및 장치가 제공된다. 상기 UE의 관성 측정 유닛(IMU), 카메라 및 깊이 센서로부터 측정이 처리된다. 상기 처리된 측정에 기초하여 적어도 깊이 잔차를 포함하는 키프레임 잔차가 결정된다. 슬라이딩 윈도우 그래프가 상기 키프레임 잔차로부터 유도된 인자에 기초하여 생성 및 최적화된다. 상기 최적화된 슬라이딩 윈도우 그래프에 기초하여 상기 UE의 개체 포즈가 추정된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 사용자 장치(UE)에서 시각적 관성 주행 거리 측정(VIO; Visual Inertial Odometry)을 수행하는 방법에 있어서,상기 UE의 관성 측정 유닛(IMU), 카메라 및 깊이 센서로부터 측정을 처리하는 단계;상기 처리된 측정에 기초하여 적어도 깊이 잔차(residue)를 포함하는 키프레임 잔차를 결정하는 단계;상기 키프레임 잔차로부터 유도된 인자에 기초하여 슬라이딩 윈도우 그래프를 생성 및 최적화하는 단계; 및상기 최적화된 슬라이딩 윈도우 그래프에 기초하여 상기 UE의 개체 포즈(object pose)를 추정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 측정을 처리하는 단계는:상기 IMU로부터 데이터 스트림을 수신하고 상기 데이터 스트림에 대한 사전 통합을 수행하여 IMU 사전 통합 항을 생성하는 단계;상기 카메라를 통해 프레임을 캡처하고 상기 캡처된 프레임에 대해 특징 감지 및 추적을 수행하여 2차원(2D) 특징 트랙을 생성하는 단계; 및상기 깊이 센서를 통해 상기 캡처된 프레임의 감지된 특징에 대해 깊이 측정값을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 상기 키프레임 잔차를 결정하는 단계는:상기 IMU 사전 통합 항을 사용하여 IMU 잔차를 결정하는 단계;상기 2D 특징 트랙으로부터 2D 특징 잔차를 결정하는 단계; 및상기 깊이 측정으로부터 상기 깊이 잔차를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서, 상기 슬라이딩 윈도우 그래프를 생성 및 최적화하는 단계는:상기 IMU 잔차에 기초하여 IMU 인자를 결정하는 단계;상기 캡처된 프레임이 앵커 프레임인 경우, 적어도 상기 깊이 잔차에 기초하여 앵커 프레임 비전 인자를 결정하는 단계;상기 캡처된 프레임이 비 앵커 프레임인 경우, 상기 2차원 특징 잔차 및 상기 깊이 잔차에 기초하여 비앵커 프레임 비전 인자를 결정하는 단계; 및상기 IMU 인자와 상기 앵커 프레임 비전 인자 및 상기 비앵커 프레임 비전 인자 중 하나에 기초하여 상기 슬라이딩 윈도우 그래프를 최적화하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서, 상기 앵커 프레임 비전 인자는 상기 2D 특징 잔차 및 상기 깊이 잔차에 기초하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서, 상기 앵커 프레임 비전 인자 및 상기 비앵커 프레임 비전 인자는 상기 카메라, 상기 깊이 센서, 및 상기 IMU의 타임 스탬프와 등가인 시간 오프셋에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제 2 항에 있어서, 상기 IMU 사전 통합 항 및 상기 2D 기능 트랙을 사용하여 키프레임 초기화를 수행하여 초기 키프레임을 생성하는 단계를 더 포함하고, 상기 슬라이딩 윈도우 그래프는 상기 초기 키프레임에 기초하여 생성되는, 방법.</claim></claimInfo><claimInfo><claim>8. 제 2 항에 있어서, 상기 캡처된 프레임에 대한 특징 감지 및 추적을 상기 감지된 특징의 깊이 측정과 동기화하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제 2 항에 있어서, 상기 특징 감지 및 추적 및 상기 깊이 측정에 기초하여 이미지 및 깊이 도메인에서 특징 속도를 계산하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제 4 항에 있어서, 상기 슬라이딩 윈도우 그래프를 최적화는 단계는:상기 캡처된 프레임에서 랜드마크의 주변화를 수행하는 단계; 및키프레임 포즈, 속도 및 바이어스 항의 주변화를 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 사용자 장치(UE)에 있어서, 상기 사용자 장치는,관성 측정 장치(IMU);카메라;깊이 센서;프로세서; 및명령을 저장하는 비 일시적 컴퓨터 판독 가능 저장 매체를 포함하고,상기 명령은, 상기 프로세서로 하여금, 실행시:상기 IMU, 상기 카메라, 및 상기 깊이 센서로부터 측정을 처리하고,상기 처리된 측정에 기초하여 적어도 깊이 잔차를 포함하는 키프레임 잔차를 결정하고,상기 키프레임 잔차로부터 유도된 인자에 기초하여 슬라이딩 윈도우 그래프를 생성 및 최적화하고,상기 최적화된 슬라이딩 윈도우 그래프에 기초하여 상기 UE의 개체 포즈를 추정하도록 하는, 사용자 장치.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서, 상기 측정의 처리시, 상기 명령은 상기 프로세서로 하여금 더욱:상기 IMU로부터 데이터 스트림을 수신하고 상기 데이터 스트림에 대한 사전 통합을 수행하여 IMU 사전 통합 항을 생성하고,상기 카메라를 통해 프레임을 캡처하고 상기 캡처된 프레임에 대해 특징 감지 및 추적을 수행하여 2차원(2D) 특징 트랙을 생성하고, 상기 깊이 센서를 통해 상기 캡처된 프레임의 감지된 특징에 대해 깊이 측정값을 생성하도록 하는, 사용자 장치.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서, 상기 키프레임 잔차의 결정시, 상기 명령은 상기 프로세서로 하여금 더욱:상기 IMU 사전 통합 항을 사용하여 IMU 잔차를 결정하고,상기 2D 특징 트랙으로부터 2D 특징 잔차를 결정하고,상기 깊이 측정으로부터 상기 깊이 잔차를 결정하도록 하는, 사용자 장치.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서, 상기 슬라이딩 윈도우 그래프의 생성 및 최적화시, 상기 명령은 상기 프로세서로 하여금 더욱:상기 IMU 잔차에 기초하여 IMU 인자를 결정하고,상기 캡처된 프레임이 앵커 프레임인 경우, 적어도 상기 깊이 잔차에 기초하여 앵커 프레임 비전 인자를 결정하고,상기 캡처된 프레임이 비 앵커 프레임인 경우, 상기 2차원 특징 잔차 및 상기 깊이 잔차에 기초하여 비앵커 프레임 비전 인자를 결정하고,상기 IMU 인자와 상기 앵커 프레임 비전 인자 및 상기비앵커 프레임 비전 인자 중 하나에 기초하여 상기 슬라이딩 윈도우 그래프를 최적화하도록 하는, 장치.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서, 상기 앵커 프레임 비전 인자는 상기 2D 특징 잔차 및 상기 깊이 잔차에 기초하여 결정되는, 사용자 장치.</claim></claimInfo><claimInfo><claim>16. 제 14 항에 있어서, 상기 앵커 프레임 비전 인자 및 상기 비앵커 프레임 비전 인자는 상기 카메라, 상기 깊이 센서, 및 상기 IMU의 타임 스탬프와 등가인 시간 오프셋에 기초하는, 사용자 장치.</claim></claimInfo><claimInfo><claim>17. 제 12 항에 있어서, 상기 명령은 상기 프로세서로 하여금 더욱 상기 IMU 사전 통합 항 및 상기 2D 기능 트랙을 사용하여 키프레임 초기화를 수행하여 초기 키프레임을 생성하도록 하고, 상기 슬라이딩 윈도우 그래프는 상기 초기 키프레임에 기초하여 생성되는, 사용자 장치.</claim></claimInfo><claimInfo><claim>18. 제 12 항에 있어서, 상기 명령은 상기 프로세서로 하여금 더욱 상기 캡처된 프레임에 대한 특징 감지 및 추적을 상기 감지된 특징의 깊이 측정과 동기화하도록 하는, 사용자 장치. </claim></claimInfo><claimInfo><claim>19. 제 12 항에 있어서, 상기 명령은 상기 프로세서로 하여금 더욱 상기 특징 감지 및 추적 및 상기 깊이 측정에 기초하여 이미지 및 깊이 도메인에서 특징 속도를 계산하도록 하는, 사용자 장치.</claim></claimInfo><claimInfo><claim>20. 제 14 항에 있어서, 상기 슬라이딩 윈도우 그래프의 최적화시, 상기 명령은 상기 프로세서로 하여금 더욱:상기 캡처된 프레임에서 랜드마크의 주변화를 수행하고,키프레임 포즈, 속도 및 바이어스 항의 주변화를 수행하도록 하는, 사용자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>**** 노스 *번가, 새...</address><code> </code><country> </country><engName>TYAGI, Abhishek</engName><name>트야기 압히쉑</name></inventorInfo><inventorInfo><address>**** 노스 *번가, 새...</address><code> </code><country> </country><engName>BAI, Dong Woon</engName><name>배동운 </name></inventorInfo><inventorInfo><address>**** 노스 *번가, 새...</address><code> </code><country> </country><engName>WANG, Shuangquan</engName><name>왕 슈앙콴</name></inventorInfo><inventorInfo><address>**** 노스 *번가, 새...</address><code> </code><country> </country><engName>LIANG, Yangwen</engName><name>리앙 양웬 </name></inventorInfo><inventorInfo><address>**** 노스 *번가, 새...</address><code> </code><country> </country><engName>SETHURAMAN, Vignesh</engName><name>세수라만 비네시</name></inventorInfo><inventorInfo><address>**** 노스 *번가, 새...</address><code> </code><country> </country><engName>LI, Xue</engName><name>리 슈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서초구 남부순환로 ****, *층(서초동, 한원빌딩)</address><code>920071001019</code><country>대한민국</country><engName>KASAN IP &amp; LAW FIRM</engName><name>특허법인가산</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.05.24</priorityApplicationDate><priorityApplicationNumber>63/192,488</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.04.21</priorityApplicationDate><priorityApplicationNumber>17/726,124</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.05.18</receiptDate><receiptNumber>1-1-2022-0525388-65</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.05.24</receiptDate><receiptNumber>9-1-2022-9005975-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.05.24</receiptDate><receiptNumber>9-1-2022-9005976-46</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.05.24</receiptDate><receiptNumber>9-1-2022-9005985-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.05.24</receiptDate><receiptNumber>9-1-2022-9005986-03</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.05.02</receiptDate><receiptNumber>1-1-2025-0497056-24</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220060733.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93720fe62d1958467d9cd87195065c0d7e389da3a1fb06cad03336ddf78c57ae5d027a0d912fafadf291640daad4b3448375b66dda85a00bcd</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa93231519735e885e1d6cb19d24fed87f01a14a1e20e0dcc187f1638a6956899f4b5de499b350b864f1ec5cab13587f4bf83f3d799b6a8b6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>