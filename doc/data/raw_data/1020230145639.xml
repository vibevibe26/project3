<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:50.750</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0145639</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>오프라인 공간에서 사람과 사물 간 인터랙션 분석 장치 및 방법</inventionTitle><inventionTitleEng>Apparatus and method for analyzing interaction between  people and things in offline space</inventionTitleEng><openDate>2025.05.08</openDate><openNumber>10-2025-0061322</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 오프라인 공간에서 사람과 사물 간 인터랙션 분석 장치 및 방법에 관한 것으로, 오프라인 공간을 촬영한 동영상에서 인터랙션 대상인 사물의 위치 정보를 획득하는 사물 정보 획득부와, 동영상에 등장하는 사람의 위치 정보와 자세 정보를 상기 동영상의 프레임마다 검출하여 사람 검출 데이터를 생성하고, 동일한 사람에 해당하는 트랙렛(tracklet)을 추적하는 사람 동적 정보 검출부와, 사물 정보 획득부에서 획득된 사물의 위치 정보와 사람 동적 정보 검출부에서 생성된 사람 검출 데이터를 이용하여, 사물과 사람 사이에 발생한 인터랙션 정보(이하, '트랙렛 인터랙션 정보'라 한다)를 트랙렛 별로 분석하여 획득하는 인터랙션 분석부를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 오프라인 공간을 촬영한 동영상에서 인터랙션 대상인 사물의 위치 정보를 획득하는 사물 정보 획득부; 상기 동영상에 등장하는 사람의 위치 정보와 자세 정보를 상기 동영상의 프레임마다 검출하여 사람 검출 데이터를 생성하고, 동일한 사람에 해당하는 트랙렛(tracklet)을 추적하는 사람 동적 정보 검출부; 및 상기 사물 정보 획득부에서 획득된 사물의 위치 정보와 상기 사람 동적 정보 검출부에서 생성된 사람 검출 데이터를 이용하여, 상기 동영상에 위치하는 사물과 사람 사이에 발생한 인터랙션 정보(이하, '트랙렛 인터랙션 정보'라 한다)를 상기 트랙렛 별로 분석하여 획득하는 인터랙션 분석부;를 포함하고, 상기 인터랙션은, 상기 사람이 상기 오프라인 공간에 존재하는 사물에 대해 취한 특정 동작이고, 상기 트랙렛 인터랙션 정보는, 상기 인터랙션의 종류와 스코어, 인터랙션의 시작 프레임 정보와 종료 프레임 정보를 포함하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 장치. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 사물 정보 획득부는,사람과 사물 간 인터랙션 분석을 위해 상기 동영상의 프레임에 위치하는 사물을 지정한 후 상기 지정된 사물에 바운딩 박스를 설정하고, 상기 설정된 바운딩 박스의 좌표에 기반하여 상기 사물의 위치 정보를 획득하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 장치. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 사람 동적 정보 검출부는, 상기 동영상의 프레임들에 등장하는 사람들에게 각각 바운딩 박스를 설정하여 사람의 위치 정보를 프레임마다 검출하고, 상기 사람들의 자세 정보를 프레임마다 검출하는 사람 인식부; 및상기 사람들 각각에 대해 설정된 바운딩 박스의 위치 정보와 상기 자세 정보를 기반으로 동일한 사람마다 트랙렛을 설정하여 추적하는 사람 추적부; 를 포함하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 인터랙션 분석부는, 상기 사물의 위치 정보와 사람 검출 데이터를 이용하여, 상기 동영상의 프레임 별로 단일 인터랙션 정보를 획득하는 프레임 인터랙션 획득부; 및 상기 프레임 별로 획득된 단일 인터랙션 정보를 프레임 시퀀스 단위로 취합한 후 상기 트랙렛 별로 트랙렛 인터랙션 정보를 획득하는 트랙렛 인터랙션 획득부;를 포함하고,상기 단일 인터랙션 정보는, 프레임에서 획득된 인터랙션의 종류와 스코어, 사람과 사물의 정보를 포함하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 장치. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 트랙렛 인터랙션 획득부는, 상기 트랙렛 별로 연속하는 적어도 3개의 프레임들에서 획득된 단일 인터랙션 정보들을 취합하고, 상기 취합된 적어도 3개의 단일 인터랙션 정보로부터 하나의 인터랙션이 발생한 것으로 판단되면, 상기 적어도 3개의 프레임들에서 각각 발생한 인터랙션 중 발생 빈도가 가장 큰 인터랙션을 상기 적어도 3개의 프레임들에서 발생한 인터랙션으로 추정하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 장치. </claim></claimInfo><claimInfo><claim>6. 컴퓨팅 장치에서 수행되는 오프라인 공간에서 사람과 사물 간 인터랙션 분석 방법에 있어서,(A) 오프라인 공간을 촬영한 동영상에서 인터랙션 대상인 사물의 위치 정보를 획득하는 단계; (B) 상기 동영상에 등장하는 사람의 위치 정보와 자세 정보를 상기 동영상의 프레임마다 검출하여 사람 검출 데이터를 생성하고, 동일한 사람에 해당하는 트랙렛(tracklet)을 추적하는 단계; 및 (C) 상기 (A) 단계에서 획득된 사물의 위치 정보와 상기 (B) 단계에서 생성된 사람 검출 데이터를 이용하여, 상기 동영상에 위치하는 사물과 사람 사이에 발생한 인터랙션 정보(이하, '트랙렛 인터랙션 정보'라 한다)를 상기 트랙렛 별로 분석하여 획득하는 단계;를 포함하고, 상기 인터랙션은, 상기 사람이 상기 오프라인 공간에 존재하는 사물에 대해 취한 특정 동작이고, 상기 트랙렛 인터랙션 정보는, 상기 인터랙션의 종류와 스코어, 인터랙션의 시작 프레임 정보와 종료 프레임 정보를 포함하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 방법. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 (A) 단계는,사람과 사물 간 인터랙션 분석을 위해 상기 동영상의 프레임에 위치하는 사물을 지정한 후 상기 지정된 사물에 바운딩 박스를 설정하고, 상기 설정된 바운딩 박스의 좌표에 기반하여 상기 사물의 위치 정보를 획득하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 방법. </claim></claimInfo><claimInfo><claim>8. 제6항에 있어서, 상기 (B) 단계는, (B1) 상기 동영상의 프레임들에 등장하는 사람들에게 각각 바운딩 박스를 설정하여 사람의 위치 정보를 프레임마다 검출하는 단계;(B2) 상기 사람들의 자세 정보를 프레임마다 검출하는 단계;(B3) 상기 사람들 각각에 대해 설정된 바운딩 박스의 위치 정보와 상기 자세 정보를 기반으로 동일한 사람마다 트랙렛을 설정하여 추적하는 단계; 및(B4) 상기 동일한 사람마다 추적된 트랙렛 별로 각 프레임에서 검출된 사람 검출 데이터를 기록하는 단계;를 포함하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 방법. </claim></claimInfo><claimInfo><claim>9. 제6항에 있어서, 상기 (C) 단계는, (C1) 상기 사물의 위치 정보와 사람 검출 데이터를 이용하여, 상기 동영상의 프레임 별로 단일 인터랙션 정보를 획득하는 단계; 및 (C2) 상기 (C1) 단계에서 프레임 별로 획득된 단일 인터랙션 정보를 프레임 시퀀스 단위로 취합한 후 상기 트랙렛 별로 트랙렛 인터랙션 정보를 획득하는 단계;를 포함하고,상기 단일 인터랙션 정보는, 프레임에서 획득된 인터랙션의 종류와 스코어, 사람과 사물의 정보를 포함하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 방법. </claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 (C2) 단계는, (C21) 상기 트랙렛 별로 연속하는 적어도 3개의 프레임들에서 획득된 단일 인터랙션 정보들을 취합하는 단계; 및(C22) 상기 (C21) 단계에서 취합된 적어도 3개의 단일 인터랙션 정보로부터 하나의 단일 인터랙션이 발생한 것으로 판단되면, 상기 적어도 3개의 프레임들에서 각각 발생한 인터랙션 중 발생 빈도가 가장 큰 인터랙션을 상기 적어도 3개의 프레임들에서 발생한 인터랙션으로 추정하는 단계;를 포함하는, 오프라인 공간에서 사람과 사물 간 인터랙션 분석 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강남구...</address><code>120190675376</code><country>대한민국</country><engName>mAy-I Inc.</engName><name>주식회사 메이아이</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강남구...</address><code>420150621530</code><country>대한민국</country><engName>ParkJunHyuk</engName><name>박준혁</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 금천구 가산디지털*로 *** (가산동) 가산어반워크*동 ****,****호(어반국제특허법률사무소)</address><code>920150016219</code><country>대한민국</country><engName>Lee Chang Jae</engName><name>이창재</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.27</receiptDate><receiptNumber>1-1-2023-1185404-91</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Change of Applicant] Report on Change of Proprietary Status</documentEngName><documentName>[출원인변경]권리관계변경신고서</documentName><receiptDate>2023.12.18</receiptDate><receiptNumber>1-1-2023-1420811-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.02</receiptDate><receiptNumber>9-5-2025-0961580-91</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230145639.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93036444d076c976119a1e75cee10acf7eaa97c5570e8a037a87e5079ae500961185f8486607cf0fa9a2574124674834a9d33658d6ee105201</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf79c7f827b03b71df533052fe73ce8c3cf47233c58996b103bdbcaa3f3b0fe38510d942a4e4841368e3950fffcfb914d986a03ee74e195fcb</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>