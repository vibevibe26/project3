<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:42.642</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0192590</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이벤트 카메라를 이용한 비디오 프레임 보간 장치 및 방법</inventionTitle><inventionTitleEng>VIDEO FRAME INTERPOLATION DEVICE AND METHOD USING EVENT CAMERA</inventionTitleEng><openDate>2025.07.04</openDate><openNumber>10-2025-0101194</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이벤트 카메라를 이용한 비디오 프레임 보간 장치 및 방법이 개시된다. 본 발명의 일 실시예에 따른, 이벤트 카메라를 이용한 비디오 프레임 보간 장치는, 프레임 기반 카메라로부터의 이미지 데이터와 이벤트 카메라로부터의 이벤트 데이터를 수신하여 처리하는 데이터 전처리부, 상기 데이터 전처리부에서 준비된 데이터를 기초로, 상기 이벤트 데이터와 상기 프레임 데이터를 융합하여, 2개의 프레임 사이의 중간 모션을 추정하는 중간 모션 추정부, 및 상기 중간 모션 추정부의 산출 데이터를 기초로 2개의 상기 프레임 사이의 중간 프레임을 생성하는 프레임 합성 네트워크부를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이벤트 카메라를 이용한 비디오 프레임 보간 장치로서,프레임 기반 카메라로부터의 이미지 데이터와 이벤트 카메라로부터의 이벤트 데이터를 수신하여 처리하는 데이터 전처리부;상기 데이터 전처리부에서 준비된 데이터를 기초로, 상기 이벤트 데이터와 상기 프레임 데이터를 융합하여, 2개의 프레임 사이의 중간 모션을 추정하는 중간 모션 추정부; 및상기 중간 모션 추정부의 산출 데이터를 기초로 2개의 상기 프레임 사이의 중간 프레임을 생성하는 프레임 합성 네트워크부;를 포함하는 것인, 비디오 프레임 보간 장치. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 중간 모션 추정부는,상기 이미지 데이터의 피쳐(feature)와, 상기 이벤트 데이터의 피처를 합성하는 앵커 프레임 피처 합성 모듈;이벤트 레벨의 중간 프레임을 추정하는 이벤트 기반 모션 추정 모듈;상기 앵커 프레임 피처 합성 모듈의 결과값을 이용하여, 이미지 레벨의 중간 프레임을 추정하는 이미지 기반 모션 추정 모듈; 및상기 이벤트 기반 모션 추정 모듈과 상기 이미지 기반 모션 추정 모듈의 결과를 융합하여 상기 중간 모션을 추정하는 융합 모션 추정 모듈;를 포함하는 것인, 비디오 프레임 보간 장치. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 중간 모션 추정 모듈은,제0 프레임(I0) 이미지 데이터, 제1 프레임(I1) 이미지 데이터, 시간 t 시점을 기준으로 한 2개의 이벤트(E0-003e#t, Et-003e#1)의 복셀 그리드(voxel grid) 데이터(G0-003e#t, Gt-003e#1), 및 이벤트(Et-003e#0)에 대응하는 복셀 그리드 데이터(Gt-003e#0)를 이용하는 것인, 비디오 프레임 보간 장치.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 융합 모션 추정 모듈은, 상기 이벤트 기반 모션 추정 모듈의 결과와 상기 이미지 기반 모션 추정 모듈의 결과에 대해 각각 가중치를 부여하여 융합 모션 데이터를 생성하는 것인, 비디오 프레임 보간 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 프레임 합성 네트워크부는, 상호 어텐션 기반 프레임 합성 (interactive attention-based frame synthesis)을 이용하는 것인, 비디오 프레임 보간 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 프레임 합성 네트워크부는, 워핑된 이미지 피처와 이벤트 피처로 인코딩한 워핑 기반 피처부와, 이미지 피처와 이벤트 피처를 인코딩한 합성 기반 피처부를 포함하고,상기 워핑 기반 이미지 피처부와 상기 합성 기반 피처부의 교차 어텐션(cross-attention)을 기반으로 프레임을 합성하는 것인, 비디오 프레임 보간 장치. </claim></claimInfo><claimInfo><claim>7. 이벤트 카메라를 이용한 비디오 프레임 보간 방법으로서,프레임 기반 카메라로부터의 이미지 데이터와 이벤트 카메라로부터의  이벤트 데이터를 수신하여 처리하는 데이터 전처리 단계;상기 데이터 전처리 단계에서 준비된 데이터를 기초로, 상기 이벤트 데이터와 상기 프레임 데이터를 융합하여, 상기 프레임 사이의 중간 모션을 추정하는 중간 모션 추정 단계; 및상기 중간 모션 추정 단계의 산출 데이터를 2개의 상기 프레임 사이의 중간 프레임을 생성하는 프레임 합성 네트워크 단계;를 포함하는 것인, 비디오 프레임 보간 방법. </claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 중간 모션 추정 단계는,상기 이미지 데이터의 피쳐와, 상기 이벤트 데이터의 피처를 합성하는 앵커 프레임 피처 합성 단계;이벤트 레벨의 중간 프레임을 추정하는 이벤트 기반 모션 추정 단계;상기 앵커 프레임 피처 합성 모듈의 결과값을 이용하여, 이미지 레벨의 중간 프레임을 추정하는 이미지 기반 모션 추정 단계; 및상기 이벤트 기반 모션 추정 단계와 상기 이미지 기반 모션 추정 단계의 결과를 융합하여 상기 중간 모션을 추정하는 융합 모션 추정 단계;를 포함하는 것인, 비디오 프레임 보간 방법. </claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 중간 모션 추정 단계는,제0 프레임(I0) 이미지 데이터, 제1 프레임(I1) 이미지 데이터, 시간 t 시점을 기준으로 한 2개의 이벤트(E0-003e#t, Et-003e#1)의 복셀 그리드(voxel grid) 데이터(G0-003e#t, Gt-003e#1), 및 이벤트(Et-003e#0)에 대응하는 복셀 그리드 데이터(Gt-003e#0)를 이용하는 것인, 비디오 프레임 보간 방법.</claim></claimInfo><claimInfo><claim>10. 제7항에 있어서,상기 프레임 합성 네트워크 단계, 상호 어텐션 기반 프레임 합성 (interactive attention-based frame synthesis)을 이용하는 것인, 비디오 프레임 보간 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980988661</code><country>대한민국</country><engName>Korea Advanced Institute of Science and Technology</engName><name>한국과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>YOON, Kuk Jin</engName><name>윤국진</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>KIM, Tae woo</engName><name>김태우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>경기도 고양시 덕양구 향동동 *** 디엠씨스타비즈 *st ****호(인벤트고특허법률사무소)</address><code>920090006813</code><country>대한민국</country><engName>Ryu, Won Rim</engName><name>류원림</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.27</receiptDate><receiptNumber>1-1-2023-1461338-72</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>1-1-2025-0342070-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.11.05</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230192590.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93662e3a8b4644c13eb2c2047433436868f2d5d04ef14c3c1d1a638c499a67ab69c88cc46a9fa964ae8f3bb192403d64b8c389e2e7814b5fcf</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4d2c3b86128be890338773f8999fbe15446a8fd7fb9c28274cb07dda429dd4a6e43cfc10173a2f1a57098e1e84553547828c7c40abe712eb</path></imagePathInfo><rndInfoArray><rndInfo><rndDepartmentName>과학기술정보통신부</rndDepartmentName><rndDuration>2020.04.01 ~ 2023.12.31</rndDuration><rndManagingInstituteName>한국과학기술원</rndManagingInstituteName><rndProjectName>정보통신.방송 연구개발사업</rndProjectName><rndSpecialInstituteName>한국전자기술연구원</rndSpecialInstituteName><rndTaskContribution>1/1</rndTaskContribution><rndTaskName>딥러닝 기반의 5G 서비스 실시간 홀로그램 획득 및 전처리 기술 개발</rndTaskName><rndTaskNumber>1711117036</rndTaskNumber></rndInfo></rndInfoArray></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>