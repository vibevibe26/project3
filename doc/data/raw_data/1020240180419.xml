<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:09:46.946</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.12.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0180419</applicationNumber><claimCount>12</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEM AND METHOD FOR AUTOMATICALLY GENERATING IMAGE AND  POSE DATA OF AN OBJECT USING A GRIP AND KINEMATIC  CHARACTERISTICS OF A ROBOT</inventionTitleEng><openDate>2025.06.17</openDate><openNumber>10-2025-0088400</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.06.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은, 베이스, 상기 베이스에 연결되며 복수의 관절로 이루어지는 로봇 암, 상기 로봇 암의 단부에 연결되는 엔드 이펙터 및 상기 엔드 이펙터에 연결되며 상기 객체를 파지하는 그리퍼를 포함하는 로봇과, 상기 그리퍼에 파지된 상기 객체를 촬영하여 이미지 데이터를 생성하는 카메라와, 상기 로봇을 제어하여 상기 객체의 포즈를 변경하는 컨트롤러와, 상기 카메라의 좌표계에 대한 상기 객체의 좌표계의 제1 변환 행렬을 산출하며, 상기 제1 변환 행렬을 벡터로 변환한 상기 객체의 포즈 데이터를 생성하는 프로세서를 포함하는 로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템을 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 베이스, 상기 베이스에 연결되며 복수의 관절로 이루어지는 로봇 암, 상기 로봇 암의 단부에 연결되는 엔드 이펙터 및 상기 엔드 이펙터에 연결되며 상기 객체를 파지하는 그리퍼를 포함하는 로봇; 및상기 그리퍼에 파지된 상기 객체를 촬영하여 이미지 데이터를 생성하는 카메라;상기 로봇을 제어하여 상기 객체의 포즈를 변경하는 컨트롤러; 및상기 카메라의 좌표계에 대한 상기 객체의 좌표계의 제1 변환 행렬을 산출하며, 상기 제1 변환 행렬을 벡터로 변환한 상기 객체의 포즈 데이터를 생성하는 프로세서를 포함하는 로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 프로세서는상기 객체의 상기 이미지 데이터 및 상기 포즈 데이터를 포함하는 학습 데이터 셋을 생성하는로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,상기 제1 변환 행렬은제1-1 변환 행렬 및 제1-2 변환 행렬을 포함하고,상기 프로세서는ICP(Iterative Closest Point) 알고리즘을 이용해 상기 제1-1 변환 행렬 산출하는로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 프로세서는상기 베이스의 좌표계에 대한 상기 엔드 이펙터의 좌표계의 제2 변환 행렬을 산출하거나 상기 컨트롤러로부터 입력 받으며,상기 객체의 복수의 포즈 마다 산출된 상기 제1-1 변환 행렬 및 상기 제2 변환 행렬을 기초로 상기 엔드 이펙터의 좌표계에 대한 상기 객체의 좌표계의 제3 변환 행렬을 산출하는로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,상기 프로세서는상기 제1-1 변환 행렬, 상기 제2 변환 행렬 및 상기 제3 변환 행렬을 기초로 상기 베이스의 좌표계에 대한 상기 카메라의 좌표계의 복수의 제4-1 변환 행렬을 산출하는로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,상기 프로세서는상기 복수의 제4-1 변환 행렬을 평균하여 제4-2 변환 행렬을 산출하는로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,상기 프로세서는상기 제4-2 변환 행렬을 기초로 제1-2 변환 행렬을 산출하는로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 시스템.</claim></claimInfo><claimInfo><claim>8. 프로세서에 의해 로봇의 파지 및 기구학적 특성을 활용하여 객체의 이미지 및 포즈 데이터를 자동으로 생성하는 방법으로서,카메라의 좌표계에 대한 객체의 좌표계의 제1-1 변환 행렬을 산출하는 단계;로봇의 베이스의 좌표계에 대한 상기 로봇의 엔드 이펙터의 좌표계의 제2 변환 행렬을 산출하거나 로봇의 컨트롤러로부터 입력 받는 단계;상기 객체의 복수의 포즈 마다 산출된 상기 제1-1 변환 행렬 및 상기 제2 변환 행렬을 기초로 상기 엔드 이펙터의 좌표계에 대한 상기 객체의 좌표계의 제3 변환 행렬을 산출하는 단계;상기 제1-1 변환 행렬, 상기 제2 변환 행렬 및 상기 제3 변환 행렬을 기초로 상기 베이스의 좌표계에 대한 상기 카메라의 좌표계의 복수의 제4-1 변환 행렬을 산출하는 단계;상기 복수의 제4-1 변환 행렬을 평균하여 제4-2 변환 행렬을 산출하는 단계;상기 제4-2 변환 행렬을 기초로 제1-2 변환 행렬을 산출하는 단계; 및상기 제1-2 변환 행렬을 벡터로 변환한 상기 객체의 포즈 데이터를 생성하는 단계를 포함하는 로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 방법.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 객체의 포즈 데이터를 생성하는 단계는상기 로봇의 그리퍼가 상기 객체를 파지한 상태에서 상기 객체의 포즈를 변경하면서 상기 객체의 포즈 데이터를 생성하는 단계인로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 방법.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 카메라가 상기 그리퍼에 파지된 상기 객체를 촬영하여 이미지 데이터를 생성하는 단계를 더 포함하는 로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 방법.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서,상기 객체의 이미지 데이터를 생성하는 단계는상기 로봇의 그리퍼가 상기 객체를 파지한 상태에서 상기 객체의 포즈를 변경하면서 상기 객체의 이미지 데이터를 생성하는 단계인로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 방법.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 객체의 상기 이미지 데이터 및 상기 포즈 데이터를 포함하는 학습 데이터 셋을 생성하는 단계를 더 포함하는 로봇의 파지 및 기구학적 특성을 활용한 객체의 이미지 및 포즈 데이터 자동 생성 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>319990193847</code><country>대한민국</country><engName>KOREA ELECTRONICS TECHNOLOGY INSTITUTE</engName><name>한국전자기술연구원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 부천시 원미구...</address><code> </code><country>대한민국</country><engName>LEE SEUNG WON</engName><name>이승원</name></inventorInfo><inventorInfo><address>서울특별시 중구 청구로 ...</address><code> </code><country>대한민국</country><engName>Park Jongbum</engName><name>박종범</name></inventorInfo><inventorInfo><address>서울특별시 구...</address><code> </code><country>대한민국</country><engName>MINGI JUNG</engName><name>정민기</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code> </code><country>대한민국</country><engName>Sunme Park</engName><name>박선미</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 사평대로 ***, *층 (반포동)</address><code>920161000615</code><country>대한민국</country><engName>Jipyong Intellectual Property Law Firm</engName><name>특허법인지평</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.12.08</priorityApplicationDate><priorityApplicationNumber>1020230177524</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.12.06</receiptDate><receiptNumber>1-1-2024-1354403-00</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.06.26</receiptDate><receiptNumber>1-1-2025-0722040-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240180419.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e4cfc6b23ee32e8dff91729b5407cf979e9d0aa9fd328f98a4303a65b935a29dbd59a1449ed72965ddcf4ed889e70ece8e898ff8eb5f259b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf13625c5f0dd6e1aa55571e92971da8952fe25ffe205b05f83526fb6ccc1a33fe75c252ca9356b3aabdc014043a8474d919739745d5a0657c</path></imagePathInfo><rndInfoArray><rndInfo><rndDepartmentName>산업통상자원부</rndDepartmentName><rndDuration>2022.04.01 ~ 2026.12.31</rndDuration><rndManagingInstituteName>한국전자기술연구원</rndManagingInstituteName><rndProjectName>로봇산업기술개발</rndProjectName><rndSpecialInstituteName>한국산업기술기획평가원</rndSpecialInstituteName><rndTaskContribution> </rndTaskContribution><rndTaskName>시촉각 센싱기반 모방학습에 의한 자율조작파지 기술개발</rndTaskName><rndTaskNumber>2410004676</rndTaskNumber></rndInfo></rndInfoArray></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>