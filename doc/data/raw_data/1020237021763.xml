<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:55:08.558</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.01.03</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7021763</applicationNumber><claimCount>32</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오 코딩 동안의 필터링을 위한 다수의 신경망 모델들</inventionTitle><inventionTitleEng>MULTIPLE NEURAL NETWORK MODELS FOR FILTERING DURING VIDEO CODING</inventionTitleEng><openDate>2023.09.05</openDate><openNumber>10-2023-0129015</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.06.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/86</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/117</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/157</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/176</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 디코딩된 비디오 데이터를 필터링하기 위한 일 예의 디바이스는 하나 이상의 프로세서들을 포함하고, 하나 이상의 프로세서들은: 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하는 것으로서, 디바이스의 하나 이상의 다른 유닛들로부터의 데이터는 비디오 데이터의 디코딩된 픽처에 대한 데이터와는 상이하고, 그리고 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하기 위해, 하나 이상의 프로세서들은 디바이스의 디블록킹 유닛으로부터 바운더리 강도 데이터를 수신하기 위해 신경망 필터링 유닛을 실행하도록 구성되는, 상기 데이터를 수신하고; 디코딩된 픽처의 부분을 필터링하는데 사용될 하나 이상의 신경망 모델들을 결정하고; 그리고 바운더리 강도 데이터를 포함한, 디바이스의 하나 이상의 다른 유닛들로부터의 데이터 및 하나 이상의 신경망 모델들을 사용하여 디코딩된 픽처의 부분을 필터링하기 위해 신경망 필터링 유닛을 실행하도록 구성된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.07.07</internationOpenDate><internationOpenNumber>WO2022147494</internationOpenNumber><internationalApplicationDate>2022.01.03</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/011021</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디코딩된 비디오 데이터를 필터링하는 방법으로서,비디오 디코딩 디바이스의 신경망 필터링 유닛에 의해, 비디오 데이터의 디코딩된 픽처에 대한 데이터를 수신하는 단계; 상기 신경망 필터링 유닛에 의해, 상기 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하는 단계로서, 상기 하나 이상의 다른 유닛들로부터의 상기 데이터는 상기 디코딩된 픽처에 대한 상기 데이터와는 상이하고, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터 상기 데이터를 수신하는 단계는 상기 비디오 디코딩 디바이스의 디블록킹 유닛으로부터 바운더리 강도 데이터를 수신하는 단계를 포함하는, 상기 하나 이상의 다른 유닛들로부터 데이터를 수신하는 단계;상기 신경망 필터링 유닛에 의해, 상기 디코딩된 픽처의 부분을 필터링하는데 사용될 하나 이상의 신경망 모델들을 결정하는 단계; 및상기 신경망 필터링 유닛에 의해, 상기 바운더리 강도 데이터를 포함한, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터의 상기 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하는 단계는,  상기 비디오 디코딩 디바이스의 인트라-예측 유닛;  상기 비디오 디코딩 디바이스의 인터-예측 유닛;  상기 비디오 디코딩 디바이스의 변환 프로세싱 유닛;  상기 비디오 디코딩 디바이스의 양자화 유닛;  상기 비디오 디코딩 디바이스의 루프 필터 유닛;  상기 비디오 디코딩 디바이스의 프리-프로세싱 유닛; 또는  상기 비디오 디코딩 디바이스의 제 2 신경망 필터링 유닛중 하나 이상으로부터 데이터를 수신하는 단계를 더 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 상기 루프 필터 유닛은 SAO (Sample Adaptive Offset) 필터링 유닛, ALF (Adaptive Loop Filtering) 유닛 중 적어도 하나를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서, 상기 데이터를 수신하는 단계는 CU (coding unit) 파티셔닝 데이터, PU (prediction unit) 파티셔닝 데이터, TU (transform unit) 파티셔닝 데이터, 디블록킹 필터링 데이터, 양자화 파라미터 (QP) 데이터, 인트라-예측 데이터, 인터-예측 데이터, 디코딩된 픽처와 하나 이상의 레퍼런스 픽처들 사이의 거리를 나타내는 데이터 또는 디코딩된 픽처의 하나 이상의 디코딩된 블록들에 대한 모션 정보 중 하나 이상을 수신하는 단계를 더 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서, 상기 디블록킹 필터링 데이터는 긴 또는 짧은 필터들이 디블록킹에 사용되었는지 여부 또는 강한 또는 약한 필터들이 디블록킹에 사용되었는지 여부 중 하나 이상을 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서, 상기 인트라 예측 데이터는 인트라 예측 모드를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>7. 제 4 항에 있어서, 상기 거리를 나타내는 데이터는 디코딩된 픽처에 대한 POC (picture order count) 값과 상기 디코딩된 픽처의 블록을 예측하는데 사용된 레퍼런스 픽처에 대한 POC 값 사이의 차이를 나타내는 데이터를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.  </claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서, 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 디코딩된 픽처의 부분을 필터링하는 단계는 상기 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터의 데이터를 CNN (convolutional neural network) 에 대한 하나 이상의 추가적인 입력 평면들로서 제공하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 디코딩된 픽처의 부분을 필터링하는 단계는:복수의 입력 평면들을 결합된 입력 평면으로 결합하는 단계로서, 상기 복수의 입력 평면들의 각각의 포지션 (i, j) 에 대해, 상기 결합된 입력 평면의 포지션 (i, j) 에 대한 값을 상기 복수의 입력 평면들의 포지션 (i, j) 에서의 값들의 최대값과 동일하게 설정하는 것을 포함한, 상기 결합된 입력 평면으로 결합하는 단계; 및 상기 결합된 입력 평면을 CNN (convolutional neural network) 에 제공하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>10. 제 1 항에 있어서, 상기 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 디코딩된 픽처의 부분을 필터링하는 단계는, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터의 데이터를 사용하여 상기 하나 이상의 신경망 모델들의 출력을 조정하는 단계를 포함하는, 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서, 디코딩된 픽처의 부분을 필터링하기 전에 상기 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터의 데이터를 조정하는 단계를 더 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.  </claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서, 상기 데이터를 조정하는 단계는 상기 데이터의 값들을 정수 표현과 부동 소수점 표현 사이에서 변환하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>13. 제 11 항에 있어서, 상기 데이터를 조정하는 단계는 하나 이상의 신경망 모델들에 적합한 값들의 범위 내에 있도록 상기 데이터의 값들을 스케일링하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>14. 제 1 항에 있어서, 상기 데이터를 수신하는 단계는 상기 디코딩된 픽처에 대한 파티션 데이터를 수신하는 단계를 포함하고, 상기 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 디코딩된 픽처의 부분을 필터링하는 단계는:상기 파티션 데이터에 의해 표시된, 상기 디코딩된 픽처에서의 파티션 바운더리들을 정의하는 바운더리 샘플들의 포지션들과 병치된 입력 평면에서의 포지션들에서의 값들을 제 1 값으로 설정하는 단계;비-바운더리 샘플들인 내부 샘플들의 포지션들과 병치된 입력 평면에서의 포지션들에서의 값들을 제 2 값으로 설정하는 단계; 및상기 하나 이상의 신경망 모델들 중 적어도 하나에 대한 입력으로서 상기 입력 평면을 사용하여 상기 디코딩된 픽처의 부분을 필터링하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서, 상기 제 1 값은 1 을 포함하고, 상기 제 2 값은 0 을 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>16. 제 14 항에 있어서, 상기 파티션 데이터는 코딩 유닛 (CU) 파티션 데이터를 포함하고, 상기 입력 평면은 제 1 파티션 평면을 포함하며, 상기 방법은:PU (prediction unit) 파티션 데이터를 수신하는 단계;상기 PU 파티션 데이터를 사용하여 제 2 입력 평면을 형성하는 단계;TU (transform unit) 파티션 데이터를 수신하는 단계; 및상기 TU 파티션 데이터를 사용하여 제 3 입력 평면을 형성하는 단계를 더 포함하고,비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 디코딩된 픽처의 부분을 필터링하는 단계는, 상기 하나 이상의 신경망 모델들 중 적어도 하나에 대한 입력들로서 제 1 입력 평면, 제 2 입력 평면 및 제 3 입력 평면을 사용하여 디코딩된 픽처의 부분을 필터링하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>17. 제 1 항에 있어서, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 디코딩된 픽처의 부분을 필터링하는 단계는:상기 디블록킹 유닛으로부터 상기 디코딩된 픽처에 대한 디블록킹 필터 데이터를 상기 하나 이상의 신경망 모델들 중 적어도 하나에 대한 하나 이상의 입력 평면들로 변환하는 단계; 및상기 하나 이상의 신경망 모델들 중 적어도 하나에 대한 입력들로서 상기 하나 이상의 입력 평면들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>18. 제 1 항에 있어서,현재 픽처를 인코딩하는 단계; 및디코딩된 픽처를 형성하기 위해 상기 현재 픽처를 디코딩하는 단계를 더 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법. </claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서, 상기 하나 이상의 신경망 모델들을 결정하는 단계는 레이트-왜곡 계산에 따라 하나 이상의 신경망 모델들을 결정하는 단계를 포함하는, 디코딩된 비디오 데이터를 필터링하는 방법.  </claim></claimInfo><claimInfo><claim>20. 제 1 항에 있어서, 상기 바운더리 강도 데이터는 바운더리 강도 값이 0임을 나타내는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>21. 제 1 항에 있어서, 상기 바운더리 강도 데이터는 바운더리 강도 값이 1 또는 2 임을 나타내는, 디코딩된 비디오 데이터를 필터링하는 방법.</claim></claimInfo><claimInfo><claim>22. 디코딩된 비디오 데이터를 필터링하기 위한 디바이스로서,비디오 데이터의 디코딩된 픽처를 저장하도록 구성된 메모리; 및회로부로 구현되는 하나 이상의 프로세서들을 포함하고,상기 하나 이상의 프로세서들은: 상기 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하는 것으로서, 상기 디바이스의 하나 이상의 다른 유닛들로부터의 데이터는 디코딩된 픽처에 대한 데이터와는 상이하고, 그리고 상기 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하기 위해, 상기 하나 이상의 프로세서들은 디바이스의 디블록킹 유닛으로부터 바운더리 강도 데이터를 수신하기 위해 신경망 필터링 유닛을 실행하도록 구성되는, 상기 데이터를 수신하고; 상기 디코딩된 픽처의 부분을 필터링하는데 사용될 하나 이상의 신경망 모델들을 결정하고; 그리고 상기 바운더리 강도 데이터를 포함한, 상기 디바이스의 하나 이상의 다른 유닛들로부터의 상기 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위해상기 신경망 필터링 유닛을 실행하도록 구성되는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>23. 제 22 항에 있어서, 상기 디바이스의 하나 이상의 다른 유닛들로부터 상기 데이터를 수신하기 위해, 상기 하나 이상의 프로세서들은 또한:  상기 디바이스의 인트라-예측 유닛;  상기 디바이스의 인터-예측 유닛;  상기 디바이스의 변환 프로세싱 유닛;  상기 디바이스의 양자화 유닛;  상기 디바이스의 루프 필터 유닛;  상기 디바이스의 프리-프로세싱 유닛; 또는  상기 디바이스의 제 2 신경망 필터링 유닛중 하나 이상으로부터 상기 데이터를 수신하기 위해 상기 신경망 필터링 유닛을 실행하도록 구성되는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>24. 제 22 항에 있어서, 상기 디바이스의 하나 이상의 다른 유닛들로부터 상기 데이터를 수신하기 위해, 상기 하나 이상의 프로세서들은 또한: CU (coding unit) 파티셔닝 데이터, PU (prediction unit) 파티셔닝 데이터, TU (transform unit) 파티셔닝 데이터, 디블록킹 필터링 데이터, 양자화 파라미터 (QP) 데이터, 인트라-예측 데이터, 인터-예측 데이터, 디코딩된 픽처와 하나 이상의 레퍼런스 픽처들 사이의 거리를 나타내는 데이터 또는 디코딩된 픽처의 하나 이상의 디코딩된 블록들에 대한 모션 정보 중 하나 이상을 수신하기 위해 상기 신경망 필터링 유닛을 실행하도록 구성되는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>25. 제 22 항에 있어서, 상기 디바이스의 하나 이상의 다른 유닛들로부터의 상기 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위해 상기 하나 이상의 프로세서들은, 컨볼루션 신경망 (CNN) 에 대한 하나 이상의 추가적인 입력 평면들로서 상기 디바이스의 상기 하나 이상의 다른 유닛들로부터의 상기 데이터를 제공하기 위해 상기 신경망 필터링 유닛을 실행하도록 구성되는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>26. 제 22 항에 있어서, 상기 디바이스의 하나 이상의 다른 유닛들로부터의 상기 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위해 상기 하나 이상의 프로세서들은, 상기 디바이스의 상기 하나 이상의 다른 유닛들로부터의 상기 데이터를 사용하여 상기 하나 이상의 신경망 모델들의 출력을 조정하기 위해 상기 신경망 필터링 유닛을 실행하도록 구성되는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>27. 제 22 항에 있어서, 상기 디바이스의 하나 이상의 다른 유닛들로부터의 상기 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위해 상기 하나 이상의 프로세서들은, 상기 디코딩된 픽처의 부분을 필터링하기 전에 상기 디바이스의 상기 하나 이상의 다른 유닛들로부터의 상기 데이터를 조정하기 위해 상기 신경망 필터링 유닛을 실행하도록 구성되는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.  </claim></claimInfo><claimInfo><claim>28. 제 22 항에 있어서, 상기 디바이스의 하나 이상의 다른 유닛들로부터의 상기 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위해 상기 하나 이상의 프로세서들은:  디블록킹 유닛으로부터 디코딩된 픽처에 대한 디블록킹 필터 데이터를 상기 하나 이상의 신경망 모델들 중 적어도 하나에 대한 하나 이상의 입력 평면들로 변환하고; 그리고 상기 하나 이상의 신경망 모델들 중 적어도 하나에 대한 입력들로서 상기 하나 이상의 입력 평면들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위해신경망 필터링 유닛을 실행하도록 구성되는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>29. 제 22 항에 있어서, 상기 비디오 데이터의 디코딩된 픽처를 디스플레이하도록 구성되는 디스플레이를 더 포함하는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>30. 제 22 항에 있어서,상기 디바이스는 카메라, 컴퓨터, 모바일 디바이스, 브로드캐스트 수신기 디바이스 또는 셋-톱 박스 중 하나 이상을 포함하는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo><claimInfo><claim>31. 명령들이 저장된 컴퓨터 판독가능 저장 매체로서,상기 명령들은 실행될 때, 비디오 디코딩 디바이스의 프로세서로 하여금:  비디오 데이터의 디코딩된 픽처에 대한 데이터를 수신하고;  상기 비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하는 것으로서, 상기  비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터의 상기 데이터는 상기 디코딩된 픽처에 대한 상기 데이터와는 상이하고, 상기 프로세서로 하여금 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터 상기 데이터를 수신하게 하는 명령들은 상기 프로세서로 하여금 상기 비디오 디코딩 디바이스의 디블록킹 유닛으로부터 바운더리 강도 데이터를 수신하게 하는 명령들을 포함하는, 상기 하나 이상의 다른 유닛들로부터 데이터를 수신하고; 상기 디코딩된 픽처의 부분을 필터링하는데 사용될 하나 이상의 신경망 모델들을 결정하고; 그리고 상기 바운더리 강도 데이터를 포함한, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위해 신경망 필터링 유닛을 실행하게 하는, 명령들이 저장된 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>32. 디코딩된 비디오 데이터를 필터링하기 위한 디바이스로서,상기 디바이스는 필터링 유닛을 포함하고,상기 필터링 유닛은: 비디오 데이터의 디코딩된 픽처에 대한 데이터를 수신하기 위한 수단;  비디오 디코딩 디바이스의 하나 이상의 다른 유닛들로부터 데이터를 수신하기 위한 수단으로서, 상기 하나 이상의 다른 유닛들로부터의 상기 데이터는 상기 디코딩된 픽처에 대한 상기 데이터와는 상이하고, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터 상기 데이터를 수신하기 위한 수단은 상기 비디오 디코딩 디바이스의 디블록킹 유닛으로부터 바운더리 강도 데이터를 수신하기 위한 수단을 포함하는, 상기 하나 이상의 다른 유닛들로부터 데이터를 수신하기 위한 수단; 상기 디코딩된 픽처의 부분을 필터링하는데 사용될 하나 이상의 신경망 모델들을 결정하기 위한 수단; 및 상기 바운더리 강도 데이터를 포함한, 상기 비디오 디코딩 디바이스의 상기 하나 이상의 다른 유닛들로부터의 데이터 및 상기 하나 이상의 신경망 모델들을 사용하여 상기 디코딩된 픽처의 부분을 필터링하기 위한 수단을 포함하는, 디코딩된 비디오 데이터를 필터링하기 위한 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>WANG, HONGTAO</engName><name>왕 홍타오</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>KOTRA, VENKATA MEHER SATCHIT ANAND</engName><name>코트라 벤카타 메헤르 사트칫 아난드</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>CHEN, JIANLE</engName><name>천 지안레</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>KARCZEWICZ, MARTA</engName><name>카르체비츠 마르타</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.01.04</priorityApplicationDate><priorityApplicationNumber>63/133,733</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.30</priorityApplicationDate><priorityApplicationNumber>17/566,282</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.06.27</receiptDate><receiptNumber>1-1-2023-0708829-25</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.08.08</receiptDate><receiptNumber>1-5-2023-0126503-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.12.17</receiptDate><receiptNumber>1-1-2024-1401730-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.12.17</receiptDate><receiptNumber>1-1-2024-1401731-52</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237021763.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93da6e2d1e635397a9c6ddb41152b90a6f3c9a92642cbb8981b78eb872f9fdd2796ec230bf5d7ea72108abe7158afec937d837394cc054e838</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf89f47133f07bfbb9f0b4a800400e3eb42e9181ac2563fa153a6058e0f294538217c3fe45051aa033afdcbcd09f4ccb7c15ea65b14c07abdc</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>