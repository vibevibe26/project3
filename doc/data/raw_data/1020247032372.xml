<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:43.5143</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.08.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7032372</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비전 기반 감지 시스템</inventionTitle><inventionTitleEng>VISION-BASED PERCEPTION SYSTEM</inventionTitleEng><openDate>2024.11.08</openDate><openNumber>10-2024-0160136</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.09.27</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/86</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/778</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/762</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 물리적 환경을 모니터링하는 비전 기반 감지 시스템이 제공되는데, 이 시스템은 환경을 나타내는 포인트 클라우드 데이터 세트의 시간적 시퀀스를 획득하도록 구성된 LIDAR 디바이스와, 환경의 이미지의 시간적 시퀀스를 캡처하도록 구성된 카메라 디바이스와, 제1 신경망 및 제1 신경망과는 상이한 제2 신경망을 포함하는 처리 유닛을 포함한다. 처리 유닛은 제1 신경망을 통해 이미지의 시간적 시퀀스에 존재하는 객체를 인식하고, 이미지의 시간적 시퀀스에 존재하는 미인식 객체를 결정하며, 결정된 미인식 객체에 대한 경계 상자를 결정하고, 제2 신경망을 통해 결정된 경계 상자에 기초해서 미인식 객체의 신경망 표현을 획득하고, 획득된 신경망 표현에 기초해서 미인식 객체의 인식을 위해 제1 신경망을 트레이닝하도록 구성된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.07</internationOpenDate><internationOpenNumber>WO2024044887</internationOpenNumber><internationalApplicationDate>2022.08.29</internationalApplicationDate><internationalApplicationNumber>PCT/CN2022/115508</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 자신의 물리적 환경을 모니터링하는 비전 기반 감지 시스템(100)으로서,상기 환경을 나타내는 포인트 클라우드 데이터 세트의 시간적 시퀀스(temporal sequence)를 획득하도록 구성된 광 검출 및 거리 측정(LIDAR, Light Detection and Ranging) 디바이스(110)와,상기 환경의 이미지의 시간적 시퀀스를 캡처하도록 구성된 카메라 디바이스(120)와,제1 신경망(132) 및 상기 제1 신경망과는 상이한 제2 신경망(138)을 포함하는 처리 유닛(130)을 포함하되, 상기 처리 유닛(130)은, 상기 제1 신경망(132)을 통해 상기 이미지의 시간적 시퀀스에 존재하는 객체를 인식하고,상기 이미지의 시간적 시퀀스에 존재하는 미인식 객체를 결정하며,상기 포인트 클라우드 데이터 세트 중 적어도 하나에 기초해서, 결정된 상기 미인식 객체에 대한 경계 상자(bounding box)를 결정하고,상기 제2 신경망(138)을 통해, 상기 이미지의 시간적 시퀀스 및 결정된 상기 경계 상자에 기초해서, 상기 미인식 객체의 신경망 표현을 획득하며,획득된 상기 미인식 객체의 신경망 표현에 기초해서 상기 미인식 객체의 인식을 위해 상기 제1 신경망(132)을 트레이닝하도록 구성되는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 처리 유닛(130)은, 상기 포인트 클라우드 데이터 세트 각각에 대한 포인트를 클러스터링해서, 상기 포인트 클라우드 데이터 세트 각각의 포인트 클러스터를 획득하고,상기 포인트 클라우드 데이터 세트 중 적어도 일부에 대해, 상기 포인트 클러스터 중 하나가 상기 제1 신경망(132)을 통해 인식된 어느 객체에도 대응하지 않는다고 결정함으로써, 상기 미인식 객체를 결정하도록 더 구성되는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 처리 유닛(130)은, 상기 포인트 클라우드 데이터 세트에 기초해서 지면(ground)을 결정하는 지면 분할(ground segmentation)을 수행하고,상기 미인식 객체가 결정된 상기 지면에 위치된다고 결정함으로써 상기 미인식 객체를 결정하도록 더 구성되는, 비전 기반 감지 시스템(100). </claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 처리 유닛(130)은,카메라 디바이스(120)에 의해 캡처된 복수의 사전 저장된 이미지 및 LIDAR 디바이스(110)에 의해 캡처된 대응하는 사전 저장된 LIDAR 포인트 클라우드 데이터 세트 각각에 대해서, 결정된 상기 미인식 객체에 대해 상기 처리 유닛(130)에 의해 결정된 상기 경계 상자와 사전 결정된 임계치 내에서 동일한 치수를 갖는 상기 대응하는 사전 저장된 LIDAR 포인트 클라우드 데이터 중 적어도 하나에 기초해서, 상기 처리 유닛(130)에 의해 결정된 대응하는 경계 상자를 갖는 적어도 하나의 다른 객체를 결정하고, 결정된 상기 적어도 하나의 다른 객체를, 상기 복수의 사전 저장된 이미지 각각에서 상기 미인식 객체의 상기 신경망 표현으로 대체하여, 상기 미인식 객체의 인식을 위해 상기 제1 신경망(132)을 트레이닝하기 위한 복수의 트레이닝 이미지를 획득하도록 더 구성되는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 처리 유닛(130)은,상기 카메라 디바이스(120)에 의해 캡처된 상기 복수의 사전 저장된 이미지 각각에 대해 상기 적어도 하나의 다른 객체에 대한 제1 광 방향을 결정하고, 결정된 상기 미인식 객체에 대한 제2 광 방향을 결정하며,상기 제1 광 방향과 상기 제2 광 방향이 사전 결정된 조명 각도 미만만큼 서로 벗어나 있는 경우, 결정된 상기 적어도 하나의 다른 객체를, 상기 복수의 사전 저장된 이미지 각각에서 상기 미인식 객체의 상기 신경망 표현으로 대체하도록 더 구성되는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 제2 신경망(138)은, 신경 복사 필드(Neural Radiance Field) 기법에 기초해서 트레이닝된 제1 다층 퍼셉트론(MLP, Multilayer Perceptron) 및 상기 제1 MLP와는 상기 상이한 신경 복사 필드 기법에 기초해서 트레이닝된 제2 MLP를 포함하고, 상기 제1 MLP는 상기 미인식 객체의 상기 신경망 표현을 획득하도록 구성되고, 상기 제2 MLP는 상기 미인식 객체의 배경의 신경망 표현을 획득하도록 구성되는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 제1 MLP는, 상기 경계 상자에 대응하는 영역을 통과하는 카메라 광선의 일부에 기초해서 상기 미인식 객체의 상기 신경망 표현을 획득하도록 구성되고, 상기 제2 MLP는 상기 경계 상자에 대응하는 상기 영역을 통과하지 않는 카메라 광선의 일부에 기초해서 상기 미인식 객체의 상기 배경의 상기 신경망 표현을 획득하도록 구성되는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서, 상기 제1 MLP는 카메라 포즈에 기초해서 상기 미인식 객체의 상기 신경망 표현을 획득하도록 구성되고, 상기 처리 유닛(130)은, 상기 카메라 포즈로부터 사전 결정된 임계치 미만만큼 벗어나 있는 렌더링 포즈에 기초해서, 상기 미인식 객체의 상기 신경망 표현을 상기 사전 저장된 복수의 이미지 각각으로 렌더링함으로써, 결정된 상기 적어도 하나의 다른 객체를 상기 미인식 객체의 상기 신경망 표현으로 대체하도록 더 구성되는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 비전 기반 감지 시스템(100)은 차량에 설치되도록 구성되고, 상기 포인트 클라우드 데이터 세트의 시간적 시퀀스 및 상기 이미지의 시간적 시퀀스는 상기 차량의 주행 장면을 나타내는, 비전 기반 감지 시스템(100).</claim></claimInfo><claimInfo><claim>10. 객체 인식을 위해 비전 기반 감지 시스템(100)의 제1 신경망(132)을 트레이닝하는 방법(200)으로서, 상기 비전 기반 감지 시스템(100)의 환경을 나타내는 포인트 클라우드 데이터 세트의 시간적 시퀀스를 상기 비전 기반 감지 시스템(100)의 광 검출 및 거리 측정(LIDAR, Light Detection and Ranging) 디바이스에 의해 획득하는 단계(S210)와,상기 비전 기반 감지 시스템(100)의 카메라 디바이스(120)에 의해 상기 환경의 이미지의 시간적 시퀀스를 캡처하는 단계(S220)와, 상기 비전 기반 감지 시스템(100)의 처리 유닛(130)에 의해 상기 이미지의 시간적 시퀀스에서 미인식 객체를 결정하는 단계(S230)와,상기 처리 유닛(130)에 의해 상기 포인트 클라우드 데이터 세트 중 적어도 하나에 기초해서, 결정된 상기 미인식 객체에 대한 경계 상자를 결정하는 단계(S240)와,상기 비전 기반 감지 시스템(100)의 제2 신경망(138)을 통해, 상기 이미지의 시간적 시퀀스 및 결정된 상기 경계 상자에 기초해서, 상기 미인식 객체의 신경망 표현을 획득하는 단계(S250)와,획득된 상기 미인식 객체의 신경망 표현에 기초해서 상기 미인식 객체의 인식을 위해 상기 제1 신경망(132)을 트레이닝하는 단계(S260)를 포함하는 방법(200).</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 처리 유닛(130)에 의해, 상기 포인트 클라우드 데이터 세트 각각에 대한 포인트를 클러스터링해서, 상기 포인트 클라우드 데이터 세트 각각의 포인트 클러스터를 획득하는 단계를 더 포함하고,상기 미인식 객체는, 상기 포인트 클라우드 데이터 세트 중 적어도 일부에 대해, 상기 포인트 클러스터 중 하나가 상기 제1 신경망(132)을 통해 인식된 어느 객체에도 대응하지 않는다고 결정함으로써, 결정되는(S230), 방법(200).</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 처리 유닛(130)에 의해, 상기 포인트 클라우드 데이터 세트에 기초해서 지면을 결정하는 지면 분할을 수행하는 단계를 더 포함하고,상기 미인식 객체는, 상기 미인식 객체가 결정된 상기 지면에 위치된다고 결정함으로써, 결정되는(S230), 방법(200). </claim></claimInfo><claimInfo><claim>13. 제10항 내지 제12항 중 어느 한 항에 있어서,상기 처리 유닛(130)에 의해, 카메라 디바이스(120)에 의해 캡처된 복수의 사전 저장된 이미지 및 LIDAR 디바이스(110)에 의해 캡처된 대응하는 사전 저장된 LIDAR 포인트 클라우드 데이터 세트 각각에 대해서, 사전 결정된 임계치 내에서, 결정된 상기 미인식 객체에 대해 상기 처리 유닛(130)에 의해 결정된 상기 경계 상자와 동일한 치수를 갖는 상기 대응하는 사전 저장된 LIDAR 포인트 클라우드 데이터 중 적어도 하나에 기초해서, 상기 처리 유닛(130)에 의해 결정된 대응하는 경계 상자를 갖는 적어도 하나의 다른 객체를 결정하는 단계와, 결정된 상기 적어도 하나의 다른 객체를, 상기 복수의 사전 저장된 이미지 각각에서 상기 미인식 객체의 상기 신경망 표현으로 대체하여, 상기 미인식 객체의 인식을 위해 상기 제1 신경망(132)을 트레이닝하기 위한 복수의 트레이닝 이미지를 획득하는 단계를 더 포함하는 방법(200).</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 처리 유닛(130)에 의해, 상기 카메라 디바이스(120)에 의해 캡처된 상기 복수의 사전 저장된 이미지 각각에 대해 상기 적어도 하나의 다른 객체에 대한 제1 광 방향을 결정하고, 결정된 상기 미인식 객체에 대한 제2 광 방향을 결정하는 단계를 더 포함하며,상기 제1 광 방향과 상기 제2 광 방향이 사전 결정된 조명 각도 미만만큼 서로 벗어나 있는 경우, 결정된 상기 적어도 하나의 다른 객체는, 상기 복수의 사전 저장된 이미지 각각에서 상기 미인식 객체의 상기 신경망 표현으로 대체되는, 방법(200).</claim></claimInfo><claimInfo><claim>15. 제10항 내지 제14항 중 어느 한 항에 있어서, 상기 제2 신경망은, 신경 복사 필드 기법에 기초해서 트레이닝된 제1 다층 퍼셉트론(MLP, Multilayer Perceptron) 및 상기 제1 MLP와는 상기 상이한 신경 복사 필드 기법에 기초해서 트레이닝된 제2 MLP를 포함하고, 상기 미인식 객체의 상기 신경망 표현은 상기 제1 MLP에 의해 획득되며(S250), 상기 방법은,상기 제2 MLP에 의해, 상기 미인식 객체의 배경의 신경망 표현을 획득하는 단계를 더 포함하는, 방법(200).</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 미인식 객체의 상기 신경망 표현은 상기 경계 상자에 대응하는 영역을 통과하는 카메라 광선의 일부에 기초해서 획득되고(S250), 상기 미인식 객체의 상기 배경의 상기 신경망 표현은 상기 경계 상자에 대응하는 상기 영역을 통과하지 않는 카메라 광선의 일부에 기초해서 획득되는, 방법(200).</claim></claimInfo><claimInfo><claim>17. 제15항 또는 제16항에 있어서, 상기 미인식 객체의 상기 신경망 표현은 카메라 포즈에 기초해서 획득되고(S250), 상기 카메라 포즈로부터 사전 결정된 임계치 미만만큼 벗어나 있는 렌더링 포즈에 기초해서, 상기 미인식 객체의 상기 신경망 표현을 상기 사전 저장된 복수의 이미지 각각으로 렌더링함으로써, 결정된 상기 적어도 하나의 다른 객체가 상기 미인식 객체의 상기 신경망 표현으로 대체되는, 방법(200).</claim></claimInfo><claimInfo><claim>18. 컴퓨터 판독 가능 명령어를 포함하는 컴퓨터 프로그램 제품으로서, 컴퓨터 판독 가능 명령어는 컴퓨터에서 실행될 때, 제10항 내지 제17항 중 어느 한 항에 따른 방법(200)의 단계를 수행 혹은 제어하는, 컴퓨터 프로그램 제품.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 ****** 광동 셴젠 룽화 디스트릭트 푸청 스트리트 주룽산 커뮤니티 징웨 로드 넘버 * 빌딩 에이* 룸 ***</address><code>520240791375</code><country>중국</country><engName>SHENZHEN YINWANG INTELLIGENT TECHNOLOGIES CO., LTD.</engName><name>셴젠 인왕 인텔리전트 테크놀러지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>독일 ***** 뮌헨 리스스트라세...</address><code> </code><country> </country><engName>SABATINI, Stefano</engName><name>사바티니 스테파노</name></inventorInfo><inventorInfo><address>독일 ***** 뮌헨 리스스트라세...</address><code> </code><country> </country><engName>PIASCO, Nathan</engName><name>피아스코 나단</name></inventorInfo><inventorInfo><address>독일 ***** 뮌헨 리스스트라세...</address><code> </code><country> </country><engName>BENNEHAR, Moussab</engName><name>벤네하르 무사브</name></inventorInfo><inventorInfo><address>중국 ******...</address><code> </code><country> </country><engName>QIU, Weichao</engName><name>퀴우 웨이차오</name></inventorInfo><inventorInfo><address>독일 ***** 뮌헨 리스스트라세...</address><code> </code><country> </country><engName>TSISHKOU, Dzmitry</engName><name>치슈코우 디즈미트리</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.09.27</receiptDate><receiptNumber>1-1-2024-1056190-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.09.27</receiptDate><receiptNumber>1-1-2024-1057605-82</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.10.07</receiptDate><receiptNumber>1-5-2024-0160473-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Change of Applicant] Report on Change of Proprietary Status</documentEngName><documentName>[출원인변경]권리관계변경신고서</documentName><receiptDate>2024.11.18</receiptDate><receiptNumber>1-1-2024-1265199-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.09.16</receiptDate><receiptNumber>4-1-2025-5260432-84</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247032372.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936ab9086ad1ffe850a45de329ec5532bb6e0faf44194cda50329a598d6848e97f7d750e6cfc5a16e144ae937b754093208cd08d499f0bc756</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2df24bb3b89ce6e1a8e52a8b0026ce25277279cff7bc8826343ad3ad42c55d921886c06965e5aa1b3f649fc31b2d66481438ec928cb6ba16</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>