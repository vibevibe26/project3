<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:02.412</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.03.21</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-7037713</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>서열분석 메타데이터의 인공 지능 기반 생성</inventionTitle><inventionTitleEng>ARTIFICIAL INTELLIGENCE-BASED GENERATION OF SEQUENCING METADATA</inventionTitleEng><openDate>2021.11.25</openDate><openNumber>10-2021-0142529</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.03.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2020.12.28</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G16B 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G16B 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/23211</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/24</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 개시된 기술은 신경 네트워크들을 사용하여, (i) 신경 네트워크를 통해 이미지 세트들의 시퀀스로부터 도출된 입력 이미지 데이터를 프로세싱하고, 분석물들 및 그들의 주변 배경을 묘사하는 유닛들의 어레이를 갖는 입력 이미지 데이터의 대안적 표현을 생성함으로써, (ii) 출력 층을 통해 대안적 표현을 프로세싱하고, 어레이 내의 각각의 유닛에 대한 출력 값을 생성함으로써, (iii) 유닛들의 출력 값들을 임계화하고, 유닛들의 제1 서브세트를 주변 배경을 묘사하는 배경 유닛들로서 분류함으로써, 그리고 (iv) 유닛들의 출력 값들에서 피크들을 위치확인하고, 유닛들의 제2 서브세트를 분석물들의 중심들을 포함하는 중심 유닛들로서 분류함으로써 분석물 메타데이터를 결정한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2020.10.08</internationOpenDate><internationOpenNumber>WO2020205296</internationOpenNumber><internationalApplicationDate>2020.03.21</internationalApplicationDate><internationalApplicationNumber>PCT/US2020/024087</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 클러스터(cluster)에 기초하여 생성된 이미지 데이터로부터, 클러스터 배경, 클러스터 중심들, 및 클러스터 형상들을 포함하는 클러스터 메타데이터를 결정하는 신경 네트워크 구현 방법으로서,이미지들의 시퀀스로부터 도출되는 입력 이미지 데이터를 수신하는 단계로서, 상기 이미지들의 시퀀스 내의 각각의 이미지는 이미징된 영역을 표현하고, 서열분석 런(sequencing run)의 복수의 서열분석 사이클의 각자의 사이클에서의 상기 하나 이상의 클러스터 및 그들의 주변 배경의 세기 방출물들을 묘사하며, 상기 입력 이미지 데이터는 상기 이미지들의 시퀀스 내의 각각의 이미지로부터 추출된 이미지 패치(patch)들을 포함하는, 상기 입력 이미지 데이터를 수신하는 단계;상기 입력 이미지 데이터를 신경 네트워크를 통해 프로세싱하여 상기 입력 이미지 데이터의 대안적 표현을 생성하는 단계로서, 상기 신경 네트워크는 클러스터 배경, 클러스터 중심들, 및 클러스터 형상들을 결정하는 것을 포함하는 클러스터 메타데이터 결정 태스크(task)에 대해 트레이닝되는, 상기 입력 이미지 데이터의 대안적 표현을 생성하는 단계;상기 이미징된 영역의 각자의 부분들의 특성들을 나타내는 출력을 생성하도록 출력 층을 통해 상기 대안적 표현을 프로세싱하는 단계;상기 출력의 출력 값들을 임계화하고, 상기 이미징된 영역의 각자의 부분들의 제1 서브세트를 상기 주변 배경을 묘사하는 배경 부분들로서 분류하는 단계;상기 출력의 출력 값들에서 피크들을 위치확인하고, 상기 이미징된 영역의 각자의 부분들의 제2 서브세트를 상기 클러스터들의 중심들을 포함하는 중심 부분들로서 분류하는 단계; 및상기 출력의 출력 값들에 세그먼터(segmenter)를 적용하고, 상기 클러스터들의 형상들을 상기 이미징된 영역의 인접 부분들의 비-중첩 영역들로서 결정하는 단계를 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 특성들은,일부분이 배경을 표현하는지 또는 클러스터를 표현하는지의 여부, 및일부분이 동일한 클러스터를 각각 표현하는 복수의 인접 이미지 부분의 중심을 표현하는지의 여부를 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 출력은,세기 방출물들이 상기 입력 이미지 데이터에 의해 묘사되는 상기 하나 이상의 클러스터들을 맞닿은 유닛들의 분리 영역들로서 식별하고,상기 하나 이상의 클러스터들의 중심들을 상기 분리 영역들의 각자의 분리 영역들의 질량 중심들에서의 중심 유닛들로서 식별하고,그들의 주변 배경을 상기 분리 영역들 중 임의의 분리 영역에 속하지 않는 배경 유닛들로서 식별하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 분리 영역들의 각자의 분리 영역들 내의 상기 맞닿은 유닛들은 맞닿은 유닛이 속하는 분리 영역 내의 중심 유닛으로부터의 상기 맞닿은 유닛의 거리에 따라 가중된 세기 값들을 갖는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 출력은 각각의 부분을 클러스터 또는 배경으로서 분류하는 2원 맵인, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 출력은 각각의 부분을 클러스터, 배경, 또는 중심으로서 분류하는 3원 맵인, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 출력에서 피크 세기들을 찾기 위해 피크 로케이터(locator)를 상기 출력에 적용하는 단계;상기 피크 세기들에 기초하여 상기 클러스터들의 중심들의 위치 좌표들을 결정하는 단계;상기 입력 이미지 데이터를 준비하는 데 사용되는 업샘플링 인자(upsampling factor)에 의해 상기 위치 좌표들을 다운스케일링(downscaling)하는 단계; 및상기 클러스터들을 염기 호출(base calling)하는 데 사용하기 위해 상기 다운스케일링된 위치 좌표들을 메모리에 저장하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,분리 영역들의 각자의 분리 영역들 내의 맞닿은 유닛들을 동일한 클러스터에 속하는 클러스터 내부 유닛들로서 카테고리화하는 단계; 및상기 클러스터들을 염기 호출하는 데 사용하기 위해 클러스터별 단위로 상기 클러스터 내부 유닛들의 카테고리화된 것 및 다운스케일링된 위치 좌표들을 메모리에 저장하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,상기 신경 네트워크를 트레이닝시키기 위한 트레이닝 데이터를 획득하는 단계로서, 상기 트레이닝 데이터는 복수의 트레이닝 예 및 대응하는 실측 자료(ground truth) 데이터를 포함하고, 각각의 트레이닝 예는 이미지 세트들의 시퀀스로부터의 이미지 데이터를 포함하고,  상기 이미지 세트들의 시퀀스 내의 각각의 이미지는 플로우 셀(flow cell)의 타일(tile)을 표현하고, 상기 플로우 셀에 대해 수행되는 서열분석 런의 복수의 서열분석 사이클 중 특정 사이클에서, 특정 이미지 채널에 대해 캡처된 상기 타일 상의 클러스터들 및 그들의 주변 배경의 세기 방출물들을 묘사하며,  각각의 실측 자료 데이터는 상기 트레이닝 예들의 각자의 부분들의 특성들을 식별하는, 상기 트레이닝 데이터를 획득하는 단계; 및하기를 반복적으로 포함하여, 상기 신경 네트워크를 트레이닝시키기 위해 경사 하강 트레이닝 기법(gradient descent training technique)을 사용하고 상기 실측 자료 데이터와 점진적으로 매칭되는 상기 트레이닝 예들에 대한 출력들을 생성하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법: 상기 출력들과 상기 실측 자료 데이터 사이의 에러를 최소화하는 손실 함수를 최적화하는 단계, 및 상기 에러에 기초하여 상기 신경 네트워크의 파라미터들을 업데이트하는 단계.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 특성들은,세기 방출물들이 대응하는 트레이닝 예의 이미지 데이터에 의해 묘사되는 클러스터들을 맞닿은 유닛들의 분리 영역들로서 포함하고,상기 클러스터들의 중심들을 분리 영역들의 각자의 분리 영역들의 질량 중심들에서의 중심 유닛들로서 포함하고,그들의 주변 배경을 상기 분리 영역들 중 임의의 분리 영역에 속하지 않는 배경 유닛들로서 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 특성들은 유닛이 중심인지 또는 비-중심인지를 식별하는 것을 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>12. 제9항에 있어서,최종 반복 후 에러 수렴 시, 추가 신경 네트워크 기반 템플릿(template) 생성 및 염기 호출에 적용되도록 상기 신경 네트워크의 업데이트된 파라미터들을 메모리에 저장하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>13. 제9항 내지 제12항 중 어느 한 항에 있어서, 상기 실측 자료 데이터에서, 상기 분리 영역들의 각자의 분리 영역들 내의 맞닿은 유닛들은 맞닿은 유닛이 속하는 분리 영역 내의 중심 유닛으로부터의 상기 맞닿은 유닛의 거리에 따라 가중된 세기 값들을 갖는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>14. 제9항 내지 제13항 중 어느 한 항에 있어서, 상기 실측 자료 데이터에서, 상기 중심 유닛들은 상기 분리 영역들의 각자의 분리 영역들 내에서 최고 세기 값들을 갖는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>15. 제9항 내지 제14항 중 어느 한 항에 있어서, 상기 손실 함수는 평균 제곱 에러(mean squared error)이고, 상기 에러는 상기 실측 자료 데이터와 상기 출력들 내의 대응하는 유닛들의 정규화된 세기 값들 사이에서 유닛 단위로 최소화되는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>16. 제9항 내지 제15항 중 어느 한 항에 있어서, 상기 트레이닝 데이터에서, 다수의 트레이닝 예들은 동일한 타일의 이미지 세트들의 시퀀스 내의 각각의 이미지와 상이한 이미지 패치들을 이미지 데이터로서 각각 포함하고,상기 상이한 이미지 패치들 중 적어도 일부는 서로 중첩하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>17. 제9항 내지 제16항 중 어느 한 항에 있어서, 상기 실측 자료 데이터에서,클러스터 중심들로서 분류된 유닛들은 모두 동일한 제1 미리결정된 클래스 스코어(class score)를 할당받고,비-중심들로서 분류된 유닛들은 모두 동일한 제2 미리결정된 클래스 스코어를 할당받는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>18. 제9항 내지 제17항 중 어느 한 항에 있어서, 상기 손실 함수는 맞춤 가중된 이진 교차 엔트로피 손실이고, 상기 에러는 상기 실측 자료 데이터와 상기 출력들 내의 대응하는 유닛들의 클래스 스코어들과 예측 스코어들 사이에서 유닛 단위로 최소화되는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>19. 제9항 내지 제18항 중 어느 한 항에 있어서, 상기 실측 자료 데이터에서,배경으로서 분류된 유닛들은 모두 동일한 제1 미리결정된 클래스 스코어를 할당받고,클러스터 중심들로서 분류된 유닛들은 모두 동일한 제2 미리결정된 클래스 스코어를 할당받고,클러스터 내부로서 분류된 유닛들은 모두 동일한 제3 미리결정된 클래스 스코어를 할당받는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제19항 중 어느 한 항에 있어서,유닛들의 출력 값들을 임계화하고, 상기 유닛들의 제1 서브세트를 상기 주변 배경을 묘사하는 배경 유닛들로서 분류하는 단계;상기 유닛들의 출력 값들에서 피크들을 위치확인하고, 상기 유닛들의 제2 서브세트를 상기 클러스터들의 중심들을 포함하는 중심 유닛들로서 분류하는 단계; 및상기 유닛들의 출력 값들에 세그먼터를 적용하고, 상기 배경 유닛들에 의해 분리되고 상기 중심 유닛들에 중심을 두는 인접 유닛들의 비-중첩 영역들로서 상기 클러스터의 형상들을 결정하는 단계로서, 상기 세그먼터는 상기 중심 유닛들로 시작하고, 각각의 중심 유닛에 대해, 상기 중심 유닛에 포함되는 중심을 갖는 동일한 클러스터를 묘사하는 연속 인접 유닛들의 그룹을 결정하는, 상기 상기 클러스터의 형상들을 결정하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>21. 제1항 내지 제20항 중 어느 한 항에 있어서, 상기 비-중첩 영역들은 불규칙한 윤곽들을 갖고, 상기 유닛들은 유닛들이고,주어진 클러스터의 클러스터 세기를, 상기 주어진 클러스터의 형상을 식별하는 인접 유닛들의 대응하는 비-중첩 영역에 기초하여 상기 주어진 클러스터의 클러스터 세기에 기여하는 유닛들을 식별함으로써; 현재 서열분석 사이클에서 하나 이상의 이미지 채널들에 대해 생성된 하나 이상의 광학 픽셀 해상도 이미지들에서 상기 식별된 유닛들을 위치확인함으로써; 상기 이미지들 각각에서, 상기 식별된 유닛들의 세기들을 보간하고 상기 보간된 세기들을 조합하고 상기 조합된 보간된 세기들을 정규화하여 상기 이미지들 각각에서 상기 주어진 클러스터에 대한 이미지별 클러스터 세기를 생성함으로써; 그리고 상기 이미지들 각각에 대한 상기 이미지별 클러스터 세기를 조합하여 상기 현재 서열분석 사이클에서 상기 주어진 클러스터의 클러스터 세기를 결정함으로써, 결정하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>22. 제1항 내지 제21항 중 어느 한 항에 있어서, 상기 비-중첩 영역들은 불규칙한 윤곽들을 갖고, 상기 유닛들은 유닛들이고,주어진 클러스터의 클러스터 세기를, 상기 주어진 클러스터의 형상을 식별하는 인접 유닛들의 대응하는 비-중첩 영역에 기초하여 상기 주어진 클러스터의 클러스터 세기에 기여하는 유닛들을 식별함으로써; 현재 서열분석 사이클에서 하나 이상의 이미지 채널들에 대해 생성된 대응하는 광학 픽셀 해상도 이미지들로부터 업샘플링된 하나 이상의 유닛 해상도 이미지들에서 상기 식별된 유닛들을 위치확인함으로써; 상기 업샘플링된 이미지들 각각에서, 상기 식별된 유닛들의 세기들을 조합하고 상기 조합된 세기들을 정규화하여 상기 업샘플링된 이미지들 각각에서 상기 주어진 클러스터에 대한 이미지별 클러스터 세기를 생성함으로써; 그리고 상기 업샘플링된 이미지들 각각에 대한 상기 이미지별 클러스터 세기를 조합하여 상기 현재 서열분석 사이클에서 상기 주어진 클러스터의 클러스터 세기를 결정함으로써, 결정하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>23. 제1항 내지 제22항 중 어느 한 항에 있어서, 정규화는 정규화 인자에 기초하고,상기 정규화 인자는 식별된 유닛들의 수인, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>24. 제1항 내지 제23항 중 어느 한 항에 있어서, 상기 현재 서열분석 사이클에서 상기 클러스터 세기에 기초하여 상기 주어진 클러스터를 염기 호출하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>25. 플로우 셀 상의 클러스터들에 관한 메타데이터를 결정하는 신경 네트워크 구현 방법으로서,상기 클러스터들의 세기 방출물을 묘사하는 이미지 데이터에 액세스하는 단계;신경 네트워크의 하나 이상의 층들을 통해 상기 이미지 데이터를 프로세싱하고 상기 이미지 데이터의 대안적 표현을 생성하는 단계; 및출력 층을 통해 상기 대안적 표현을 프로세싱하고, 상기 클러스터들의 중심들 및/또는 상기 클러스터들의 형상들 및 크기들 중 적어도 하나를 식별하는 출력을 생성하는 단계를 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 이미지 데이터는 상기 클러스터들의 주변 배경의 세기 방출물들을 추가로 묘사하고,상기 출력이, 상기 주변 배경 및 상기 클러스터들 사이의 경계들을 포함하는, 상기 플로우 셀 상의 상기 클러스터들의 공간 분포를 식별하는 단계를 추가로 포함하는, 신경 네트워크 구현 방법.</claim></claimInfo><claimInfo><claim>27. 컴퓨터 구현 방법으로서,신경 네트워크를 통해 이미지 데이터를 프로세싱하고 상기 이미지 데이터의 대안적 표현을 생성하는 단계로서, 상기 이미지 데이터는 클러스터들의 세기 방출물들을 묘사하는, 상기 이미지 데이터의 대안적 표현을 생성하는 단계; 및출력 층을 통해 상기 대안적 표현을 프로세싱하고, 상기 클러스터들의 공간 분포, 상기 클러스터들의 형상들, 상기 클러스터들의 중심들, 및/또는 상기 클러스터들 사이의 경계들 중 적어도 하나를 포함하는, 상기 클러스터들에 관한 메타데이터를 식별하는 출력을 생성하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 ***** 샌디에고 일루미나 웨이 ****</address><code>520000356236</code><country>미국</country><engName>ILLUMINA, INC.</engName><name>일루미나, 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아주 ****...</address><code> </code><country> </country><engName>DUTTA, Anindita</engName><name>두타 아닌디타</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ****...</address><code> </code><country> </country><engName>KASHEFHAGHIGHI, Dorna</engName><name>카셰프하기기 도르나</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ****...</address><code> </code><country> </country><engName>KIA, Amirali</engName><name>키아 아미르알리</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로***, **,**층(역삼동, 동희빌딩)</address><code>920161001010</code><country>대한민국</country><engName>AJU Kim Chang &amp; Lee</engName><name>특허법인아주김장리</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.03.21</priorityApplicationDate><priorityApplicationNumber>62/821,602</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.03.21</priorityApplicationDate><priorityApplicationNumber>62/821,618</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.03.21</priorityApplicationDate><priorityApplicationNumber>62/821,681</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.03.21</priorityApplicationDate><priorityApplicationNumber>62/821,724</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.03.21</priorityApplicationDate><priorityApplicationNumber>62/821,766</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>네덜란드</priorityApplicationCountry><priorityApplicationDate>2019.06.14</priorityApplicationDate><priorityApplicationNumber>2023310</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>네덜란드</priorityApplicationCountry><priorityApplicationDate>2019.06.14</priorityApplicationDate><priorityApplicationNumber>2023311</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>네덜란드</priorityApplicationCountry><priorityApplicationDate>2019.06.14</priorityApplicationDate><priorityApplicationNumber>2023312</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>네덜란드</priorityApplicationCountry><priorityApplicationDate>2019.06.14</priorityApplicationDate><priorityApplicationNumber>2023314</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>네덜란드</priorityApplicationCountry><priorityApplicationDate>2019.06.14</priorityApplicationDate><priorityApplicationNumber>2023316</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.03.20</priorityApplicationDate><priorityApplicationNumber>16/825,987</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.03.20</priorityApplicationDate><priorityApplicationNumber>16/825,991</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.03.20</priorityApplicationDate><priorityApplicationNumber>16/826,126</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.03.20</priorityApplicationDate><priorityApplicationNumber>16/826,134</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.03.21</priorityApplicationDate><priorityApplicationNumber>16/826,168</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2020.12.28</receiptDate><receiptNumber>1-1-2020-1423039-31</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2021.10.26</receiptDate><receiptNumber>1-5-2021-0167551-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2021.11.09</receiptDate><receiptNumber>1-1-2021-1293317-03</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.03.20</receiptDate><receiptNumber>1-1-2023-0316408-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.03.20</receiptDate><receiptNumber>1-1-2023-0316409-24</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020207037713.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937cc3d4242a7e16422ab758cb8795f6b3218b368ab3333b46c6a0aeecdf2a868296a44c046508a8bc2600f04732ef46244b8ee3d5248037ce</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf934b92c949ff773b49412577c140c32d3c35caab42c13f0fcfb68d824c6dad240e63b6ab12ac30a9a695dd0d83bd26950b6f69ebd75e7cf7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>