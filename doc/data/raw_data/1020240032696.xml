<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:12.4112</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0032696</applicationNumber><claimCount>27</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신경망 모델을 활용하여 객체를 추출하는 방법</inventionTitle><inventionTitleEng>METHOD FOR UTILIZING NEURAL NETWORK MODELS TO EXTRACT OBJECTS</inventionTitleEng><openDate>2025.09.16</openDate><openNumber>10-2025-0136097</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.07</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 실시예에 따라 컴퓨팅 장치에 의해 수행되는, 신경망 모델을 활용하여 객체를 추출하는 방법이 개시된다. 상기 방법은, 배경이 존재하는 상황에서 객체를 촬영한 카메라의 포즈 정보를 획득하는 단계, 상기 신경망 모델을 활용하여, 상기 카메라의 포즈 정보에 기초하여 복원(reconstruction)된 배경 이미지를 생성하는 단계 및 상기 객체가 촬영된 이미지와 상기 복원된 배경 이미지를 활용하여 상기 객체를 추출하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 장치에 의해 수행되는, 신경망 모델을 활용하여 객체를 추출하는 방법으로서, 배경이 존재하는 상황에서 객체를 촬영한 카메라의 포즈 정보를 획득하는 단계;상기 신경망 모델을 활용하여, 상기 카메라의 포즈 정보에 기초하여 복원(reconstruction)된 배경 이미지를 생성하는 단계; 및상기 객체가 촬영된 이미지와 상기 복원된 배경 이미지를 활용하여 상기 객체를 추출하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 객체가 촬영된 이미지는,단색의 배경이 표시되는 상황에서 상기 객체를 촬영한 이미지; 또는디스플레이에 배경이 출력되는 상황에서 상기 객체를 촬영한 이미지를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 객체는, 투명 객체(transparent object)를 포함하고,상기 객체를 추출하는 단계는,상기 객체에 대한 알파 마스크(Alpha mask) 정보를 추출하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,상기 신경망 모델은,학습용 카메라의 포즈 정보를 포함하는 제 1 입력, 및 학습용 배경에 대한 정보를 포함하는 제 2 입력에 기초하여, 복원된 학습용 배경 이미지를 생성하도록 학습된 신경망 모델인, 방법.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,상기 복원된 학습용 배경 이미지는, 상기 학습용 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 학습용 배경을 촬영한 이미지를 예측한 이미지이고,상기 복원된 학습용 배경 이미지는, 어떠한 객체도 포함하지 않는 이미지인, 방법.</claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서,상기 신경망 모델은,상기 학습용 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 학습용 배경을 실제 촬영하여 생성된 실제 촬영 이미지; 및상기 복원된 학습용 배경 이미지사이에 산출되는 손실 함수를 활용하여 학습된 신경망 모델인, 방법.</claim></claimInfo><claimInfo><claim>7. 제 4 항에 있어서,상기 신경망 모델은,추론(Inference) 단계에서, 타겟 카메라의 포즈 정보 및 타겟 배경 이미지를 모두 수신하여, 상기 타겟 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 타겟 배경 이미지를 촬영한 이미지를 예측하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제 4 항에 있어서,상기 신경망 모델은,추론 단계에서, 타겟 카메라의 포즈 정보만을 수신하고, 상기 타겟 카메라의 포즈 정보와 연관된 촬영 시점으로 디폴트(Default) 배경 이미지를 촬영한 이미지를 예측하고,상기 디폴트 배경 이미지는, 상기 학습용 배경에 대응되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서,상기 카메라의 포즈 정보는, 카메라 트래커(tracker)를 활용하여 획득되는 것인, 방법. </claim></claimInfo><claimInfo><claim>10. 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 하나 이상의 프로세서에서 실행되는 경우, 상기 하나 이상의 프로세서로 하여금 신경망 모델을 활용하여 객체를 추출하기 위한 이하의 동작들을 수행하도록 하며, 상기 동작들은:배경이 존재하는 상황에서 객체를 촬영한 카메라의 포즈 정보를 획득하는 동작;상기 신경망 모델을 활용하여, 상기 카메라의 포즈 정보에 기초하여 복원(reconstruction)된 배경 이미지를 생성하는 동작; 및상기 객체가 촬영된 이미지와 상기 복원된 배경 이미지를 활용하여 상기 객체를 추출하는 동작을 포함하는, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서,상기 객체가 촬영된 이미지는,단색의 배경이 표시되는 상황에서 상기 객체를 촬영한 이미지; 또는디스플레이에 배경이 출력되는 상황에서 상기 객체를 촬영한 이미지를 포함하는, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 객체는, 투명 객체(transparent object)를 포함하고,상기 객체를 추출하는 동작은,상기 객체에 대한 알파 마스크(Alpha mask) 정보를 추출하는 동작을 포함하는, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 제 10 항에 있어서,상기 신경망 모델은,학습용 카메라의 포즈 정보를 포함하는 제 1 입력, 및 학습용 배경에 대한 정보를 포함하는 제 2 입력에 기초하여, 복원된 학습용 배경 이미지를 생성하도록 학습된 신경망 모델인, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 복원된 학습용 배경 이미지는, 상기 학습용 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 학습용 배경을 촬영한 이미지를 예측한 이미지이고,상기 복원된 학습용 배경 이미지는, 어떠한 객체도 포함하지 않는 이미지인, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 제 13 항에 있어서,상기 신경망 모델은,상기 학습용 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 학습용 배경을 실제 촬영하여 생성된 실제 촬영 이미지; 및상기 복원된 학습용 배경 이미지사이에 산출되는 손실 함수를 활용하여 학습된 신경망 모델인, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 제 13 항에 있어서,상기 신경망 모델은,추론(Inference) 동작에서, 타겟 카메라의 포즈 정보 및 타겟 배경 이미지를 모두 수신하여, 상기 타겟 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 타겟 배경 이미지를 촬영한 이미지를 예측하는, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>17. 제 13 항에 있어서,상기 신경망 모델은,추론 동작에서, 타겟 카메라의 포즈 정보만을 수신하고, 상기 타겟 카메라의 포즈 정보와 연관된 촬영 시점으로 디폴트(Default) 배경 이미지를 촬영한 이미지를 예측하고,상기 디폴트 배경 이미지는, 상기 학습용 배경에 대응되는, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>18. 제 10 항에 있어서,상기 카메라의 포즈 정보는, 카메라 트래커(tracker)를 활용하여 획득되는 것인, 컴퓨터 판독가능 저장매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>19. 컴퓨팅 장치로서, 적어도 하나의 프로세서; 및메모리를 포함하고, 상기 적어도 하나의 프로세서는, 배경이 존재하는 상황에서 객체를 촬영한 카메라의 포즈 정보를 획득하고;신경망 모델을 활용하여, 상기 카메라의 포즈 정보에 기초하여 복원(reconstruction)된 배경 이미지를 생성하고; 그리고상기 객체가 촬영된 이미지와 상기 복원된 배경 이미지를 활용하여 상기 객체를 추출하도록 구성되는, 장치. </claim></claimInfo><claimInfo><claim>20. 제 19 항에 있어서,상기 객체가 촬영된 이미지는,단색의 배경이 표시되는 상황에서 상기 객체를 촬영한 이미지; 또는디스플레이에 배경이 출력되는 상황에서 상기 객체를 촬영한 이미지를 포함하는, 장치. </claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서,상기 객체는, 투명 객체(transparent object)를 포함하고,상기 적어도 하나의 프로세서는, 상기 객체에 대한 알파 마스크(Alpha mask) 정보를 추출하도록 구성되는, 장치. </claim></claimInfo><claimInfo><claim>22. 제 20 항에 있어서,상기 신경망 모델은,학습용 카메라의 포즈 정보를 포함하는 제 1 입력, 및 학습용 배경에 대한 정보를 포함하는 제 2 입력에 기초하여, 복원된 학습용 배경 이미지를 생성하도록 학습된 신경망 모델인, 장치. </claim></claimInfo><claimInfo><claim>23. 제 22 항에 있어서,상기 복원된 학습용 배경 이미지는, 상기 학습용 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 학습용 배경을 촬영한 이미지를 예측한 이미지이고,상기 복원된 학습용 배경 이미지는, 어떠한 객체도 포함하지 않는 이미지인,  장치. </claim></claimInfo><claimInfo><claim>24. 제 22 항에 있어서,상기 신경망 모델은,상기 학습용 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 학습용 배경을 실제 촬영하여 생성된 실제 촬영 이미지; 및상기 복원된 학습용 배경 이미지사이에 산출되는 손실 함수를 활용하여 학습된 신경망 모델인, 장치. </claim></claimInfo><claimInfo><claim>25. 제 22 항에 있어서,상기 신경망 모델은,추론(Inference) 단계에서, 타겟 카메라의 포즈 정보 및 타겟 배경 이미지를 모두 수신하여, 상기 타겟 카메라의 포즈 정보와 연관된 촬영 시점으로 상기 타겟 배경 이미지를 촬영한 이미지를 예측하는, 장치. </claim></claimInfo><claimInfo><claim>26. 제 22 항에 있어서,상기 신경망 모델은,추론 단계에서, 타겟 카메라의 포즈 정보만을 수신하고, 상기 타겟 카메라의 포즈 정보와 연관된 촬영 시점으로 디폴트(Default) 배경 이미지를 촬영한 이미지를 예측하고,상기 디폴트 배경 이미지는, 상기 학습용 배경에 대응되는, 장치. </claim></claimInfo><claimInfo><claim>27. 제 19 항에 있어서,상기 카메라의 포즈 정보는, 카메라 트래커(tracker)를 활용하여 획득되는 것인, 장치. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강남구...</address><code>120170248261</code><country>대한민국</country><engName>VIVE STUDIOS Co.,Ltd</engName><name>주식회사 비브스튜디오스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강서구...</address><code> </code><country> </country><engName>HONG, Yohan</engName><name>홍요한</name></inventorInfo><inventorInfo><address>경기도 하남시 위례중앙로 ***,...</address><code> </code><country> </country><engName>LEE, Kwanghee</engName><name>이광희</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920090037635</code><country>대한민국</country><engName>LEE, Dae Ho</engName><name>이대호</name></agentInfo><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920120001378</code><country>대한민국</country><engName>Park, Gun Hong</engName><name>박건홍</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.07</receiptDate><receiptNumber>1-1-2024-0260497-19</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240032696.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c36a90f6218edad0926340e7bcc794cc6c90028de1ce6d55bab77990b3ea8771e20217c468f573984b4272dddf110639f9d3c682bcbc632b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa86d01f579aa2bab0b8b8e8e01041847558cbb9004189070c7c8a078fdbd5de33163565ce0a4fd564ab7fe656bfa68ce19d71a11e11ef786</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>