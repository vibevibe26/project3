<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:57.757</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7028640</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>시선 검출에 기초한 이미지 프로세싱 시스템들 및 방법들</inventionTitle><inventionTitleEng>SYSTEMS AND METHODS OF IMAGE PROCESSING BASED ON GAZE DETECTION</inventionTitleEng><openDate>2024.11.04</openDate><openNumber>10-2024-0158244</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.26</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>H04N 7/15</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>H04N 21/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/094</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미징 시스템들 및 기법들이 설명된다. 이미징 시스템은 제1 이미지 센서에 의해 캡처된 바와 같은 제1 사용자의 적어도 일부(예컨대, 얼굴)를 표현하는 이미지 데이터를 수신한다. 이미징 시스템은 이미지 데이터에서 표현된 바와 같은 제1 사용자의 시선이 제2 사용자의 적어도 일부(예컨대, 얼굴)의 디스플레이된 표현을 향해 지향된다는 것을 식별한다. 이미징 시스템은 출력을 위한 사용자들의 표현들의 어레인지먼트를 식별한다. 이미징 시스템은, 적어도 부분적으로, 시선 및 어레인지먼트에 기초하여 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 이미지 데이터 내의 제1 사용자의 적어도 일부를 수정하기 위해 이미지 데이터를 수정함으로써 시선 및 어레인지먼트에 기초하여, 수정된 이미지 데이터를 생성한다. 이미징 시스템은 어레인지먼트에 따라 배열된 수정된 이미지 데이터를 출력한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.09.07</internationOpenDate><internationOpenNumber>WO2023167788</internationOpenNumber><internationalApplicationDate>2023.02.16</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/013237</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미징을 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 하나 이상의 프로세서들을 포함하며,상기 하나 이상의 프로세서들은, 제1 이미지 센서에 의해 캡처된 제1 사용자의 적어도 일부를 표현하는 이미지 데이터를 수신하고; 상기 이미지 데이터에서 표현된 상기 제1 사용자의 시선이 제2 사용자의 적어도 일부의 디스플레이된 표현을 향해 지향된다는 것을 식별하고; 출력을 위한 사용자들의 표현들의 어레인지먼트(arrangement)를 식별하고; 적어도 부분적으로, 상기 시선 및 상기 어레인지먼트에 기초하여 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해 상기 이미지 데이터를 수정함으로써 상기 시선 및 상기 어레인지먼트에 기초하여, 수정된 이미지 데이터를 생성하고; 그리고 상기 어레인지먼트에 따라 배열된 상기 수정된 이미지 데이터를 출력하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해, 상기 하나 이상의 프로세서들은 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 하나의 눈의 눈 포즈를 수정하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해, 상기 하나 이상의 프로세서들은 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 머리의 적어도 일부의 머리 포즈를 수정하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해, 상기 하나 이상의 프로세서들은 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 신체의 적어도 일부의 신체 포즈를 수정하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 사용자들의 표현들의 어레인지먼트는 상기 수정된 이미지 데이터, 및 상기 제2 사용자의 적어도 일부를 표현하는 제2 이미지 데이터를 포함하고, 상기 제2 사용자에 대응하는 방향은 상기 어레인지먼트 내의 상기 수정된 이미지 데이터의 포지션으로부터 상기 어레인지먼트 내의 상기 제2 이미지 데이터의 포지션으로의 방향이고, 상기 제2 사용자에 대응하는 방향의 적어도 컴포넌트는 상기 어레인지먼트의 이미지 평면에 평행한, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제2 사용자는 상기 어레인지먼트에 따른 출력으로서의 상기 수정된 이미지 데이터의 뷰어이고, 상기 제2 사용자에 대응하는 방향은 상기 뷰어를 향하는 방향이고, 상기 제2 사용자에 대응하는 방향의 적어도 컴포넌트는 상기 어레인지먼트의 이미지 평면에 수직인, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 수정된 이미지 데이터를 생성하기 위해, 상기 하나 이상의 프로세서들은, 적어도 부분적으로, 상기 이미지 데이터 및 상기 시선 및 상기 어레인지먼트를 입력들로서 하나 이상의 트레이닝된 기계 학습 모델들에 제공함으로써 상기 수정된 이미지 데이터를 생성하기 위해 상기 하나 이상의 트레이닝된 기계 학습 모델들을 사용하는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 하나 이상의 트레이닝된 기계 학습 모델들은 생성적 적대 네트워크(generative adversarial network)를 포함하는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 하나 이상의 프로세서들은,제2 이미지 센서에 의해 캡처된 상기 제2 사용자의 적어도 일부를 표현하는 제2 이미지 데이터를 수신하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 하나 이상의 프로세서들은,상기 제2 이미지 데이터에서 표현된 상기 제2 사용자의 제2 시선이 제2 시선 영역을 향해 지향된다는 것을 식별하고;적어도 부분적으로, 상기 제2 시선 및 상기 어레인지먼트에 기초하여 상기 제2 시선 영역에 대응하는 방향을 향해 시각적으로 지향되도록 상기 제2 이미지 데이터 내의 상기 제2 사용자의 적어도 일부를 수정하기 위해 상기 제2 이미지 데이터를 수정함으로써 상기 제2 시선 및 상기 어레인지먼트에 기초하여, 수정된 제2 이미지 데이터를 생성하고; 그리고상기 어레인지먼트에 따라 배열된 상기 수정된 제2 이미지 데이터를 출력하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 수정된 제2 이미지 데이터를 생성하기 위해, 상기 하나 이상의 프로세서들은, 적어도 부분적으로, 상기 제2 이미지 데이터 및 상기 제2 시선 및 상기 어레인지먼트를 입력들로서 하나 이상의 트레이닝된 기계 학습 모델들에 제공함으로써 상기 수정된 제2 이미지 데이터를 생성하기 위해 상기 하나 이상의 트레이닝된 기계 학습 모델들을 사용하는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 제2 시선 영역은 상기 제1 사용자의 적어도 일부의 디스플레이된 표현을 포함하고, 상기 제2 시선 영역에 대응하는 방향은 상기 어레인지먼트 내의 상기 수정된 제2 이미지 데이터의 포지션으로부터 상기 어레인지먼트 내의 상기 수정된 이미지 데이터의 포지션으로의 방향이고, 상기 제2 시선 영역에 대응하는 방향의 적어도 컴포넌트는 상기 어레인지먼트의 이미지 평면에 평행한, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,상기 제2 시선 영역은 제3 사용자의 적어도 일부의 디스플레이된 표현을 포함하고, 상기 제2 시선 영역에 대응하는 방향은 상기 어레인지먼트 내의 상기 수정된 제2 이미지 데이터의 포지션으로부터 상기 어레인지먼트 내의 상기 제3 사용자를 표현하는 제3 이미지 데이터의 포지션으로의 방향이고, 상기 제2 시선 영역에 대응하는 방향의 적어도 컴포넌트는 상기 어레인지먼트의 이미지 평면에 평행한, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,상기 수정된 이미지 데이터를 생성하기 위해, 상기 하나 이상의 프로세서들은,적어도 부분적으로, 중간 이미지 데이터의 이미지 평면에 수직인 전방 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해 상기 이미지 데이터를 수정함으로써 상기 중간 이미지 데이터를 생성하고; 그리고적어도 부분적으로, 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 중간 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해 상기 중간 이미지 데이터를 수정함으로써 상기 수정된 이미지 데이터를 생성하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서,상기 이미지 데이터에서 표현된 상기 제1 사용자의 시선이 상기 제2 사용자의 적어도 일부의 상기 디스플레이된 표현을 향해 지향된다는 것을 식별하기 위해, 상기 하나 이상의 프로세서들은 상기 제2 사용자의 적어도 일부의 상기 디스플레이된 표현의 알려진 포지션과 비교하여 상기 이미지 데이터를 분석하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서,상기 하나 이상의 프로세서들은,상기 제1 사용자의 적어도 일부 및 상기 제1 사용자의 제2 부분을 표현하는 이전의 이미지 데이터를 수신하도록 구성되며, 상기 이전의 이미지 데이터는 상기 제1 이미지 센서에 의한 상기 이미지 데이터의 캡처 전에 상기 제1 이미지 센서에 의해 캡처되고, 상기 수정된 이미지 데이터를 생성하기 위해, 상기 하나 이상의 프로세서들은 상기 제1 사용자의 제2 부분을 표현하는 상기 이전의 이미지 데이터의 적어도 일부를 상기 수정된 이미지 데이터에 통합하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서,상기 수정된 이미지 데이터를 생성하기 위해, 상기 하나 이상의 프로세서들은 상기 제1 사용자의 적어도 일부를 사실적인 형태로부터 아바타 형태로 수정하기 위해 상기 이미지 데이터를 수정하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 제1 사용자는 상기 이미지 데이터에서 표현된 얼굴 표정을 가지며, 상기 수정된 이미지 데이터를 생성하기 위해, 상기 하나 이상의 프로세서들은 상기 얼굴 표정의 표시자를 상기 아바타 형태에 적용하기 위해 상기 아바타 형태를 수정하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>19. 제1항에 있어서,상기 제1 사용자는 상기 이미지 데이터에서 표현된 얼굴 표정을 가지며, 상기 수정된 이미지 데이터를 생성하기 위해, 상기 하나 이상의 프로세서들은 상기 얼굴 표정을 마스킹하도록 상기 제1 사용자의 적어도 일부를 수정하기 위해 상기 이미지 데이터를 수정하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>20. 제1항에 있어서,디스플레이를 더 포함하며, 상기 어레인지먼트에 따라 배열된 상기 수정된 이미지 데이터를 출력하기 위해, 상기 하나 이상의 프로세서들은 상기 디스플레이를 사용하여 상기 수정된 이미지 데이터를 디스플레이하도록 구성되는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>21. 제1항에 있어서,통신 인터페이스를 더 포함하며, 상기 어레인지먼트에 따라 배열된 상기 수정된 이미지 데이터를 출력하기 위해, 상기 하나 이상의 프로세서들은 상기 통신 인터페이스를 사용하여 상기 수정된 이미지 데이터를 수신자 디바이스에 전송하도록 구성되고, 상기 수신자 디바이스는 상기 어레인지먼트에 따라 배열된 상기 수정된 이미지 데이터를 렌더링하는, 이미징을 위한 장치.</claim></claimInfo><claimInfo><claim>22. 이미징을 위한 방법으로서,제1 이미지 센서에 의해 캡처된 제1 사용자의 적어도 일부를 표현하는 이미지 데이터를 수신하는 단계;상기 이미지 데이터에서 표현된 상기 제1 사용자의 시선이 제2 사용자의 적어도 일부의 디스플레이된 표현을 향해 지향된다는 것을 식별하는 단계;출력을 위한 사용자들의 표현들의 어레인지먼트를 식별하는 단계;적어도 부분적으로, 상기 시선 및 상기 어레인지먼트에 기초하여 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해 상기 이미지 데이터를 수정함으로써 상기 시선 및 상기 어레인지먼트에 기초하여, 수정된 이미지 데이터를 생성하는 단계; 및상기 어레인지먼트에 따라 배열된 상기 수정된 이미지 데이터를 출력하는 단계를 포함하는, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서,상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하는 것은, 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 하나의 눈의 눈 포즈를 수정하는 것, 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 머리의 적어도 일부의 머리 포즈를 수정하는 것, 또는 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 신체의 적어도 일부의 신체 포즈를 수정하는 것 중 적어도 하나를 포함하는, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>24. 제22항에 있어서,상기 사용자들의 표현들의 어레인지먼트는 상기 수정된 이미지 데이터, 및 상기 제2 사용자의 적어도 일부를 표현하는 제2 이미지 데이터를 포함하고, 상기 제2 사용자에 대응하는 방향은 상기 어레인지먼트 내의 상기 수정된 이미지 데이터의 포지션으로부터 상기 어레인지먼트 내의 상기 제2 이미지 데이터의 포지션으로의 방향이고, 상기 제2 사용자에 대응하는 방향의 적어도 컴포넌트는 상기 어레인지먼트의 이미지 평면에 평행한, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>25. 제22항에 있어서,상기 제2 사용자는 상기 어레인지먼트에 따른 출력으로서의 상기 수정된 이미지 데이터의 뷰어이고, 상기 제2 사용자에 대응하는 방향은 상기 뷰어를 향하는 방향이고, 상기 제2 사용자에 대응하는 방향의 적어도 컴포넌트는 상기 어레인지먼트의 이미지 평면에 수직인, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>26. 제22항에 있어서,상기 수정된 이미지 데이터를 생성하는 단계는, 적어도 부분적으로, 상기 이미지 데이터 및 상기 시선 및 상기 어레인지먼트를 입력들로서 하나 이상의 트레이닝된 기계 학습 모델들에 제공함으로써 상기 수정된 이미지 데이터를 생성하기 위해 상기 하나 이상의 트레이닝된 기계 학습 모델들을 사용하는 단계를 포함하는, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>27. 제22항에 있어서,제2 이미지 센서에 의해 캡처된 상기 제2 사용자의 적어도 일부를 표현하는 제2 이미지 데이터를 수신하는 단계;상기 제2 이미지 데이터에서 표현된 상기 제2 사용자의 제2 시선이 제2 시선 영역을 향해 지향된다는 것을 식별하는 단계;적어도 부분적으로, 상기 제2 시선 및 상기 어레인지먼트에 기초하여 상기 제2 시선 영역에 대응하는 방향을 향해 시각적으로 지향되도록 상기 제2 이미지 데이터 내의 상기 제2 사용자의 적어도 일부를 수정하기 위해 상기 제2 이미지 데이터를 수정함으로써 상기 제2 시선 및 상기 어레인지먼트에 기초하여, 수정된 제2 이미지 데이터를 생성하는 단계; 및상기 어레인지먼트에 따라 배열된 상기 수정된 제2 이미지 데이터를 출력하는 단계를 더 포함하는, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>28. 제22항에 있어서,상기 수정된 이미지 데이터를 생성하는 단계는,적어도 부분적으로, 중간 이미지 데이터의 이미지 평면에 수직인 전방 방향을 향해 시각적으로 지향되도록 상기 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해 상기 이미지 데이터를 수정함으로써 상기 중간 이미지 데이터를 생성하는 단계; 및적어도 부분적으로, 상기 제2 사용자에 대응하는 방향을 향해 시각적으로 지향되도록 상기 중간 이미지 데이터 내의 상기 제1 사용자의 적어도 일부를 수정하기 위해 상기 중간 이미지 데이터를 수정함으로써 상기 수정된 이미지 데이터를 생성하는 단계를 포함하는, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>29. 제22항에 있어서,상기 이미지 데이터에서 표현된 상기 제1 사용자의 시선이 상기 제2 사용자의 적어도 일부의 상기 디스플레이된 표현을 향해 지향된다는 것을 식별하는 단계는 상기 제2 사용자의 적어도 일부의 상기 디스플레이된 표현의 알려진 포지션과 비교하여 상기 이미지 데이터를 분석하는 단계를 포함하는, 이미징을 위한 방법.</claim></claimInfo><claimInfo><claim>30. 제22항에 있어서,상기 어레인지먼트에 따라 배열된 상기 수정된 이미지 데이터를 출력하는 단계는 통신 인터페이스를 사용하여 상기 수정된 이미지 데이터를 수신자 디바이스에 전송하는 단계를 포함하며, 상기 수신자 디바이스는 상기 어레인지먼트에 따라 배열된 상기 수정된 이미지 데이터를 렌더링하는, 이미징을 위한 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>PARK, HYUNSIN</engName><name>박 현신</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>LEE, JUNTAE</engName><name>이 준태</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>CHANG, SIMYUNG</engName><name>장 심영</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>KIM, BYEONGGEUN</engName><name>김 병근</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>CHOI, JAEWON</engName><name>최 재원</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>HWANG, KYU WOONG</engName><name>황 규웅</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.02</priorityApplicationDate><priorityApplicationNumber>17/685,278</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.26</receiptDate><receiptNumber>1-1-2024-0930942-18</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.10.04</receiptDate><receiptNumber>1-5-2024-0159634-24</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247028640.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93909ef5947da54cd72346d96d083b3aaecf2503b6121ffc3b792772beee66d5f3e7d3588b7205e80a1ec8f1580a1f673e86f63deb77919ecc</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfc7a6c0b5744e3531fe58eb0439814d33c7c8e2d6fe23bb0484e8b534202a23ad5596e1ea5d8e98094e01f58465f5b5f962817e0b486963eb</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>