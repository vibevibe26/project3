<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:13:50.1350</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.08.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0115577</applicationNumber><claimCount>29</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>디지털 휴먼의 표정 이전 방법, 장치, 전자 기기 및 기록 매체</inventionTitle><inventionTitleEng>EXPRESSION MIGRATION METHOD AND DEVICE OF DIGITAL HUMAN,  ELECTRONIC EQUIPMENT AND STORAGE MEDIUM</inventionTitleEng><openDate>2024.09.19</openDate><openNumber>10-2024-0136891</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.28</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/53</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 디지털 휴먼의 표정 이전 방법, 장치, 전자 기기 및 기록 매체를 제공하고, 증강 현실, 가상 현실, 컴퓨터 시각, 딥 러닝 등 기술 분야에 관한 것으로, 메타 우주, 가상 디지털 휴먼 등의 장면에 적용할 수 있다. 구체적인 구현 방안은, 미리 설정된 참조 모델 라이브러리로부터 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계로서, 상기 참조 모델 라이브러리는 복수의 참조 모델을 포함하는 단계; 상기 타겟 참조 모델의 식별자에 기반하여, 상기 타겟 참조 모델의 표정 라이브러리를 획득하는 단계; 상기 타겟 참조 모델의 표정 라이브러리 중의 표정의 최종 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 최종 프레임을 획득하는 단계를 포함한다. 본 개시의 기술은 디지털 휴먼의 표정 이전을 자동적으로 구현할 수 있고, 전체의 표정 이전 프로세스는 시간과 노력을 줄여, 이전된 표정의 정확성을 효과적으로 확보할 수 있을 뿐만 아니라, 나아가 디지털 휴먼 표정의 이전 효율을 효과적으로 향상시킬 수 있어, 디지털 휴먼 이미지의 생성 효율을 향상시킬 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디지털 휴먼의 표정 이전 방법에 있어서,미리 설정된 참조 모델 라이브러리로부터 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계 - 상기 참조 모델 라이브러리는 복수의 참조 모델을 포함함 -;상기 타겟 참조 모델의 식별자에 기반하여, 상기 타겟 참조 모델의 표정 라이브러리를 획득하는 단계; 및상기 타겟 참조 모델의 표정 라이브러리 중의 표정의 최종 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 최종 프레임을 획득하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,미리 설정된 참조 모델 라이브러리로부터 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계는,상기 오브젝트 모델의 속성 정보와 상기 참조 모델 라이브러리 중의 각 상기 참조 모델의 속성 정보에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 상기 타겟 참조 모델의 식별자를 선별하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,미리 설정된 참조 모델 라이브러리로부터 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계는,상기 참조 모델 라이브러리 중의 각 상기 참조 모델의 속성 정보를 사용자에게 전시하는 단계; 및상기 사용자에 의해 선택된 상기 오브젝트 모델에 매칭하는 상기 타겟 참조 모델을 수신하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,미리 설정된 참조 모델 라이브러리로부터 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계는,상기 오브젝트 모델로부터 미리 설정된 부위의 제1 특징 곡선을 획득하는 단계;각 상기 참조 모델로부터 상기 미리 설정된 부위의 제2 특징 곡선을 획득하는 단계;상기 제1 특징 곡선과 각 상기 제2 특징 곡선에 기반하여, 상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리를 계산하는 단계; 및상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제1 특징 곡선과 상기 제2 특징 곡선에 기반하여, 상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리를 계산하는 단계는,상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 각 포인트의 좌표를 각각 획득하는 단계;상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 각 포인트의 좌표에 기반하여, 상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 같은 포인트 식별자의 포인트 거리를 계산하는 단계;상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 각 포인트 식별자의 포인트 거리를 가산하여, 포인트 거리의 합을 획득하는 단계; 및상기 포인트 거리의 합과 상기 제1 특징 곡선에 포함된 포인트의 수에 기반하여, 상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리를 획득하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계는,상기 참조 모델 라이브러리중의 복수의 참조 모델로부터 상기 미리 설정된 부위의 오프셋 거리가 가장 작은 참조 모델의 식별자를, 상기 오브젝트 모델에 매칭하는 상기 타겟 참조 모델의 식별자로 선별하는 단계를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계는,상기 미리 설정된 부위가 2개 이상이 포함될 경우, 사전에 설정된 각 상기 미리 설정된 부위의 가중치와 각 상기 미리 설정된 부위에 대응하는 오프셋 거리에 기반하여, 상기 오브젝트 모델과 각 상기 참조 모델 사이의 종합 오프셋 거리를 계산하는 단계; 및상기 오브젝트 모델과 각 상기 참조 모델 사이의 종합 오프셋 거리에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 타겟 참조 모델의 표정 라이브러리중의 표정의 최종 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 최종 프레임을 획득하는 단계는,상기 타겟 참조 모델과 상기 오브젝트 모델에 대해 전체 레지스트레이션을 수행하는 단계;상기 타겟 참조 모델의 표정에 대응하는 키 특징과 상기 오브젝트 모델의 키 특징에 대해 레지스트레이션을 수행하는 단계;상기 타겟 참조 모델의 상기 표정의 최종 프레임에 대응하는 키 특징의 점군 데이터와, 상기 타겟 참조 모델의 자연 상태에서의 키 특징의 점군 데이터에 기반하여, 표정의 제1 사이즈 비율을 획득하는 단계; 및상기 표정의 제1 사이즈 비율과 상기 오브젝트 모델의 자연 상태에서의 키 특징의 점군 데이터에 기반하여, 상기 오브젝트 모델이 이전할 상기 표정의 최종 프레임에 대응하는 키 특징의 점군 데이터를 획득하고, 상기 오브젝트 모델의 상기 표정의 최종 프레임을 획득하는 단계를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 표정의 사이즈 비율과 상기 오브젝트 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터에 기반하여, 상기 오브젝트 모델이 이전할 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터를 획득한 후, 상기 오브젝트 모델의 상기 표정의 최종 프레임을 획득하는 단계의 전에, 상기 방법은,상기 오브젝트 모델이 이전할 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터를, 상기 오브젝트 모델로 이전하는 단계;상기 오브젝트 모델로 이전한 후, 상기 표정의 최종 프레임에 대응하는 제3 특징 곡선과 상기 타겟 참조 모델에서의 상기 표정의 최종 프레임에 대응하는 제4 특징 곡선을 획득하는 단계;상기 제4 특징 곡선을 제약 조건으로 하여, 상기 제3 특징 곡선을 조정하는 단계;상기 오브젝트 모델로 이전한 후의 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드와, 상기 오브젝트 모델의 원래 포인트 클라우드의 이음매에 대해 스무드 처리를 수행하는 단계;를 더 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>10. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 타겟 참조 모델의 표정 라이브러리 중의 표정의 최종 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 최종 프레임을 획득하는 단계의 후에, 상기 방법은,상기 표정 라이브러리에 상기 표정의 중간 프레임이 더 포함되는 경우, 상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 중간 프레임을 획득하는 단계를 더 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 중간 프레임을 획득하는 단계는,상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임에 대응하는 키 특징의 포인트 클라우드 데이터, 상기 타겟 참조 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터, 및 상기 타겟 참조 모델의 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터에 기반하여, 상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율을 획득하는 단계; 및상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율과, 상기 오브젝트 모델의 상기 표정의 최종 프레임에 기반하여, 상기 오브젝트 모델의 표정의 중간 프레임을 획득하는 단계를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임에 대응하는 키 특징의 포인트 클라우드 데이터, 상기 타겟 참조 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터, 및 상기 타겟 참조 모델의 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터에 기반하여, 상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율을 획득하는 단계는,상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임에 대응하는 키 특징의 포인트 클라우드 데이터, 상기 타겟 참조 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터 및 상기 타겟 참조 모델의 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터에 기반하여, 상기 타겟 참조 모델의 상기 표정의 최종 프레임에 대응하는 제4 특징 곡선, 상기 표정의 중간 프레임에 대응하는 제5 특징 곡선 및 상기 자연 상태에서의 제6 특징 곡선을 획득하는 단계; 및상기 제4 특징 곡선, 상기 제5 특징 곡선 및 상기 제6특징 곡선 중의 키 포인트의 좌표에 기반하여, 상기 표정의 중간 프레임의 최종 프레임에 대한 제2사이즈 비율을 획득하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율과 상기 오브젝트 모델의 상기 표정의 최종 프레임에 기반하여, 상기 오브젝트 모델의 표정의 중간 프레임을 획득하는 단계는,상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율과, 상기 오브젝트 모델의 표정의 최종 프레임의 대응하는 제3 특징 곡선에 기반하여, 오브젝트 모델의 표정의 중간 프레임의 대응하는 참조 특징 곡선을 획득하는 단계;상기 타겟 참조 모델의 상기 표정의 중간 프레임에 대응하는 키 특징의 포인트 클라우드 데이터를 상기 오브젝트 모델로 이전하는 단계;상기 오브젝트 모델로 이전한 후, 상기 표정의 중간 프레임에 대응하는 제7 특징 곡선을 획득하는 단계; 및상기 참조 특징 곡선을 제약 조건으로 하여, 상기 제7 특징 곡선을 조정하는 단계;를 포함하는,디지털 휴먼의 표정 이전 방법. </claim></claimInfo><claimInfo><claim>14. 디지털 휴먼의 표정 이전 장치에 있어서,미리 설정된 참조 모델 라이브러리로부터 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하기 위한 선별 모듈 - 상기 참조 모델 라이브러리는 복수의 참조 모델을 포함함 -;상기 타겟 참조 모델의 식별자에 기반하여, 상기 타겟 참조 모델의 표정 라이브러리를 획득하기 위한 획득 모듈; 및상기 타겟 참조 모델의 표정 라이브러리 중의 표정의 최종 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 최종 프레임을 획득하기 위한 최종 프레임 이전 모듈;을 포함하는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 선별 모듈은,상기 오브젝트 모델의 속성 정보와 상기 참조 모델 라이브러리 중의 각 상기 참조 모델의 속성 정보에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 상기 타겟 참조 모델의 식별자를 선별하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 선별 모듈은,상기 참조 모델 라이브러리 중의 각 상기 참조 모델의 속성 정보를 사용자에게 전시하고,상기 사용자에 의해 선택된 상기 오브젝트 모델에 매칭하는 상기 타겟 참조 모델을 수신하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 선별 모듈은,상기 오브젝트 모델로부터 미리 설정된 부위의 제1 특징 곡선을 획득하고,각 상기 참조 모델로부터 상기 미리 설정된 부위의 제2 특징 곡선을 획득하고,상기 제1 특징 곡선과 각 상기 제2 특징 곡선에 기반하여, 상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리를 계산하고,상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 선별 모듈은,상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 각 포인트의 좌표를 각각 획득하고,상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 각 포인트의 좌표에 기반하여, 상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 같은 포인트 식별자의 포인트 거리를 계산하고,상기 제1 특징 곡선과 각 상기 제2 특징 곡선 중의 각 포인트 식별자의 포인트 거리를 가산하여, 포인트 거리의 합을 획득하고,상기 포인트 거리의 합과 상기 제1 특징 곡선에 포함된 포인트의 수에 기반하여, 상기 오브젝트 모델과 각 상기 참조 모델 사이의 상기 미리 설정된 부위의 오프셋 거리를 획득하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 선별 모듈은,상기 참조 모델 라이브러리 중의 복수의 참조 모델로부터 상기 미리 설정된 부위의 오프셋 거리가 가장 작은 참조 모델의 식별자를, 상기 오브젝트 모델에 매칭하는 상기 타겟 참조 모델의 식별자로 선별하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 선별 모듈은,상기 미리 설정된 부위가 2개 이상이 포함될 경우, 사전에 설정된 각 상기 미리 설정된 부위의 가중치와 각 상기 미리 설정된 부위에 대응하는 오프셋 거리에 기반하여, 상기 오브젝트 모델과 각 상기 참조 모델 사이의 종합 오프셋 거리를 계산하고,상기 오브젝트 모델과 각 상기 참조 모델 사이의 종합 오프셋 거리에 기반하여, 상기 참조 모델 라이브러리로부터 상기 오브젝트 모델에 매칭하는 타겟 참조 모델의 식별자를 선별하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>21. 제14항 내지 제20항 중 어느 한 항에 있어서,상기 최종 프레임 이전 모듈은,상기 타겟 참조 모델과 상기 오브젝트 모델에 대해 전체 레지스트레이션을 수행하고,상기 타겟 참조 모델의 표정에 대응하는 키 특징과 상기 오브젝트 모델의 키 특징에 대해 레지스트레이션을 수행하고,상기 타겟 참조 모델의 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터와, 상기 타겟 참조 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터에 기반하여, 표정의 제1 사이즈 비율을 획득하고,상기 표정의 제1 사이즈 비율과 상기 오브젝트 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터에 기반하여, 상기 오브젝트 모델이 이전할 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터를 획득하고, 상기 오브젝트 모델의 상기 표정의 최종 프레임을 획득하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,상기 최종 프레임 이전 모듈은 또한,상기 오브젝트 모델이 이전할 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터를, 상기 오브젝트 모델로 이전하고,상기 오브젝트 모델로 이전한 후, 상기 표정의 최종 프레임에 대응하는 제3 특징 곡선과 상기 타겟 참조 모델에서의 상기 표정의 최종 프레임에 대응하는 제4 특징 곡선을 획득하고,상기 제4 특징 곡선을 제약 조건으로 하여, 상기 제3 특징 곡선을 조정하고,상기 오브젝트 모델로 이전한 후의 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드와, 상기 오브젝트 모델의 원래 포인트 클라우드의 이음매에 대해 스무드 처리를 수행하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>23. 제14항 내지 제20항 중 어느 한 항에 있어서,상기 장치는,상기 표정 라이브러리에 상기 표정의 중간 프레임이 더 포함되는 경우, 상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임을 상기 오브젝트 모델로 이전하여, 상기 오브젝트 모델의 표정의 중간 프레임을 획득하기 위한 중간 프레임 이전 모듈을 더 포함하는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 중간 프레임 이전 모듈은,상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임에 대응하는 키 특징의 포인트 클라우드 데이터, 상기 타겟 참조 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터, 및 상기 타겟 참조 모델의 상기 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터에 기반하여, 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율을 획득하고,상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율과, 상기 오브젝트 모델의 상기 표정의 최종 프레임에 기반하여, 상기 오브젝트 모델의 표정의 중간 프레임을 획득하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>25. 제24항에 있어서,상기 중간 프레임 이전 모듈은,상기 타겟 참조 모델의 표정 라이브러리 중의 상기 표정의 중간 프레임에 대응하는 키 특징의 포인트 클라우드 데이터, 상기 타겟 참조 모델의 자연 상태에서의 키 특징의 포인트 클라우드 데이터 및 상기 타겟 참조 모델의 표정의 최종 프레임에 대응하는 키 특징의 포인트 클라우드 데이터에 기반하여, 상기 타겟 참조 모델의 상기 표정의 최종 프레임에 대응하는 제4 특징 곡선, 상기 표정의 중간 프레임에 대응하는 제5 특징 곡선 및 상기 자연 상태에서의 제6 특징 곡선을 획득하고,상기 제4 특징 곡선, 상기 제5 특징 곡선 및 상기 제6 특징 곡선중의 키 포인트의 좌표에 기반하여, 상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율을 획득하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>26. 제24항에 있어서,상기 중간 프레임 이전 모듈은,상기 표정의 중간 프레임의 최종 프레임에 대한 제2 사이즈 비율과, 상기 오브젝트 모델의 표정의 최종 프레임의 대응하는 제3 특징 곡선에 기반하여, 오브젝트 모델의 표정의 중간 프레임의 대응하는 참조 특징 곡선을 획득하고,상기 타겟 참조 모델의 상기 표정의 중간 프레임에 대응하는 키 특징의 포인트 클라우드 데이터를 상기 오브젝트 모델로 이전하고,상기 오브젝트 모델로 이전한 후, 상기 표정의 중간 프레임에 대응하는 제7 특징 곡선을 획득하고,상기 참조 특징 곡선을 제약 조건으로 하여 상기 제7 특징 곡선을 조정하는데 사용되는,디지털 휴먼의 표정 이전 장치. </claim></claimInfo><claimInfo><claim>27. 전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리;를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서에 의해 제1항 내지 제13항 중 어느 한 항의 방법이 수행되도록 하는,전자 기기. </claim></claimInfo><claimInfo><claim>28. 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제13항 중 어느 한 항의 방법을 수행하도록 하는,비일시적 컴퓨터 판독 가능 기록 매체. </claim></claimInfo><claimInfo><claim>29. 비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행될 때, 제1항 내지 제13항 중 어느 한 항의 방법을 구현하는,컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국, 베이징 ******, 하이뎬 디스트...</address><code> </code><country> </country><engName>WANG, Lei</engName><name>왕, 레이</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디스트...</address><code> </code><country> </country><engName>ZHANG, Xiaodong</engName><name>장, 씨아오동</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디스트...</address><code> </code><country> </country><engName>LI, Shiyan</engName><name>리, 시옌</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 사평대로 ***, *층 (반포동)</address><code>920161000615</code><country>대한민국</country><engName>Jipyong Intellectual Property Law Firm</engName><name>특허법인지평</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2023.10.16</priorityApplicationDate><priorityApplicationNumber>202311339427.X</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.08.28</receiptDate><receiptNumber>1-1-2024-0940589-83</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.09.03</receiptDate><receiptNumber>9-1-2024-9009476-92</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240115577.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338e61703986b59c14dd7a978f716ce0e11ac5959cb386686590ce953a5e4639785de74e0bd61ffe9332cab7d4a6bea091f5a1f70f85e34c54d8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf7696784467b677848ff1ee37d1eed4c0f12d329321d856c1aa2f2a359eac0fd5182e5a01a1c04b1b5e9830917825539ee6f1bdc7d33e71cc</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>