<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:42.1042</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.01.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0008000</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>도로망 모델을 사용한 궤적 생성</inventionTitle><inventionTitleEng>TRAJECTORY GENERATION USING ROAD NETWORK MODEL</inventionTitleEng><openDate>2022.04.01</openDate><openNumber>10-2022-0041701</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.13</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>B60W 60/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2012.01.01)</ipcDate><ipcNumber>B60W 30/095</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G08G 1/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 도로망 모델을 사용한 궤적 생성에 대한 실시예가 개시되어 있다. 일 실시예에서, 방법은: 차량의 적어도 하나의 프로세서를 사용하여, 차량의 위치를 획득하는 단계; 적어도 하나의 프로세서를 사용하여, 해당 위치에서 수집된 센서 데이터를 획득하는 단계; 적어도 하나의 프로세서를 사용하여, 해당 위치에 대한 맵 데이터를 획득하는 단계; 하나 이상의 프로세서를 사용하여, 해당 위치에서 적어도 하나의 대상체에 대한 적어도 하나의 가능한 궤적을 생성하는 단계 — 가능한 궤적은 맵 데이터에 따라 제약됨 —; 및 머신 러닝 모델을 사용하여, 적어도 하나의 궤적에 대한 점수를 예측하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법에 있어서,적어도 하나의 프로세서를 사용하여, 장면 데이터 — 상기 장면 데이터는 차량의 현재 위치를 포함함 —, 상기 위치에서 캡처된 센서 데이터, 및 상기 위치에 대한 도로 맵 데이터를 획득하는 단계;상기 적어도 하나의 프로세서를 사용하여, 상기 장면 데이터에 기초하여 상기 위치에 적어도 하나의 에이전트에 대한 적어도 하나의 가능한 궤적 템플릿을 생성하는 단계 — 상기 적어도 하나의 가능한 궤적 템플릿은 상기 도로 맵 데이터에 따라 제약됨 —; 및상기 적어도 하나의 프로세서를 사용하여, 머신 러닝 모델을 사용하여 상기 적어도 하나의 가능한 궤적 템플릿에 대한 점수를 예측하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 궤적 템플릿을 상기 도로 맵 데이터에서의 특정 차선 또는 커넥터(connector)로 제약하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,머신 러닝 모델을 사용하여, 상기 적어도 하나의 가능한 궤적 템플릿에 대한 점수를 예측하는 단계는: 상기 센서 데이터 및 상기 도로 맵 데이터의 이미지 임베딩을 생성하는 단계; 컨볼루션 신경 네트워크를 사용하여, 상기 이미지 임베딩을 프로세싱하여 특징 맵 및 글로벌 특징 벡터(global feature vector)를 제공하는 단계; 상기 적어도 하나의 프로세서를 사용하여, 공간 어텐션 메커니즘(spatial attention mechanism)을 사용하여 상기 특징 맵을 상기 적어도 하나의 궤적 템플릿과 결합시키는 것에 의해 로컬 특징 벡터(local feature vector)를 생성하는 단계; 상기 적어도 하나의 프로세서를 사용하여, 상기 궤적 템플릿 위치 좌표, 상기 로컬 특징 벡터, 상기 글로벌 특징 벡터 및 에이전트 상태 벡터를 결합시키는 것에 의해 입력 데이터를 생성하는 단계; 상기 입력 데이터를, 상기 머신 러닝 모델에 입력하는 단계; 및 상기 머신 러닝 모델을 사용하여, 상기 적어도 하나의 가능한 궤적 템플릿에 대한 상기 점수를 예측하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 특징 맵은 상기 센서 데이터의 공간적 변동을 인코딩하는 픽셀당 하나의 특징 벡터를 갖는 이미지인, 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 글로벌 특징 벡터는 상기 위치에 대한 상기 센서 데이터를 요약하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 적어도 하나의 궤적 템플릿에 대한 조정을 출력하는 미세 조정 모델(refinement model)에 상기 입력 데이터를 제공하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 조정은 상기 위치에서 하나 이상의 에이전트의 속력을 증가 또는 감소시키는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 조정은 상기 위치에서 하나 이상의 에이전트를 도로의 중심선으로부터 측방향으로 변위시키는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 센서 데이터는 상기 위치에서 캡처된 카메라 이미지 또는 LiDAR(light detection and ranging) 센서로부터의 포인트 클라우드 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 센서 데이터는 상기 차량의 인지 모듈에 의해 출력된 데이터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 적어도 하나의 에이전트는 적어도 한 명의 보행자를 포함하고, 상기 도로 맵 데이터는 인도 또는 횡단보도 데이터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,둘 이상의 에이전트가 있고, 궤적은 공유 데이터에 기초하여 병렬로 생성되는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,상기 적어도 하나의 궤적 템플릿은 상기 도로 맵 데이터에 기초하여 상기 적어도 하나의 에이전트의 모든 가능한 의도된 거동을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,상기 적어도 하나의 프로세서를 사용하여, 상기 적어도 하나의 에이전트에 대한 상기 적어도 하나의 궤적 템플릿을 생성하는 단계는: 상기 위치로부터 고정 반경 내에 있는 도로망의 차선 및 커넥터에 대해 상기 도로 맵 데이터를 탐색하는 단계; 기본 간격(default spacing)을 사용하여 상기 탐색에서 찾아진 각각의 차선 또는 커넥터를 이산화하는 단계; 및 각각의 차선 및 커넥터에 대해, 상기 적어도 하나의 에이전트의 시작 자세로부터 시작하여 상기 차선 또는 커넥터에 합류하고 이어서 상기 차선 또는 커넥터를 따라가는 상기 적어도 하나의 에이전트에 대한 경로를 드로잉하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서,상기 적어도 하나의 궤적 템플릿은 Dubins 곡선을 사용하여 드로잉되는, 방법.</claim></claimInfo><claimInfo><claim>16. 시스템에 있어서,적어도 하나의 프로세서;상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금 동작들을 수행하게 하는 명령어들을 저장하는 메모리를 포함하며, 상기 동작들은: 장면 데이터 — 상기 장면 데이터는 차량의 현재 위치를 포함함 —, 상기 위치에서 캡처된 센서 데이터, 및 상기 위치에 대한 도로 맵 데이터를 획득하는 동작; 상기 장면 데이터에 기초하여 상기 위치에 적어도 하나의 에이전트에 대한 적어도 하나의 가능한 궤적 템플릿을 생성하는 동작 — 상기 적어도 하나의 가능한 궤적 템플릿은 상기 도로 맵 데이터에 따라 제약됨 —; 및 머신 러닝 모델을 사용하여 상기 적어도 하나의 가능한 궤적 템플릿에 대한 점수를 예측하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 동작들은, 상기 궤적 템플릿을 상기 도로 맵 데이터에서의 특정 차선 또는 커넥터로 제약하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,머신 러닝 모델을 사용하여, 상기 적어도 하나의 가능한 궤적 템플릿에 대한 점수를 예측하는 동작은: 상기 센서 데이터 및 상기 도로 맵 데이터의 이미지 임베딩을 생성하는 동작; 컨볼루션 신경 네트워크를 사용하여, 상기 이미지 임베딩을 프로세싱하여 특징 맵 및 글로벌 특징 벡터를 제공하는 동작; 상기 적어도 하나의 프로세서를 사용하여, 공간 어텐션 메커니즘을 사용하여 상기 특징 맵을 상기 적어도 하나의 궤적 템플릿과 결합시키는 것에 의해 로컬 특징 벡터를 생성하는 동작; 상기 적어도 하나의 프로세서를 사용하여, 상기 궤적 템플릿 위치 좌표, 상기 로컬 특징 벡터, 상기 글로벌 특징 벡터 및 에이전트 상태 벡터를 결합시키는 것에 의해 입력 데이터를 생성하는 동작;상기 입력 데이터를, 상기 머신 러닝 모델에 입력하는 동작; 및상기 머신 러닝 모델을 사용하여, 상기 적어도 하나의 가능한 궤적 템플릿에 대한 상기 점수를 예측하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서,상기 동작들은, 상기 적어도 하나의 궤적 템플릿에 대한 조정을 출력하는 미세 조정 모델에 상기 입력 데이터를 제공하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서,상기 적어도 하나의 프로세서를 사용하여, 상기 적어도 하나의 에이전트에 대한 상기 적어도 하나의 궤적 템플릿을 생성하는 동작은: 상기 위치로부터 고정 반경 내에 있는 도로망의 차선 및 커넥터에 대해 상기 도로 맵 데이터를 탐색하는 동작; 기본 간격을 사용하여 상기 탐색에서 찾아진 각각의 차선 또는 커넥터를 이산화하는 동작; 및 각각의 차선 및 커넥터에 대해, 상기 적어도 하나의 에이전트의 시작 자세로부터 시작하여 상기 차선 또는 커넥터에 합류하고 이어서 상기 차선 또는 커넥터를 따라가는 상기 적어도 하나의 에이전트에 대한 경로를 드로잉하는 동작을 더 포함하는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매사추세츠주 보스턴 노던 애비뉴 ***</address><code>520200342330</code><country>미국</country><engName>Motional AD LLC</engName><name>모셔널 에이디 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 매사추세츠주 **...</address><code> </code><country> </country><engName>WOLFF, Eric</engName><name>울프 에릭</name></inventorInfo><inventorInfo><address>미국 매사추세츠주 **...</address><code> </code><country> </country><engName>BEAUDOIN, Robert</engName><name>보두인 로버트</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.09.25</priorityApplicationDate><priorityApplicationNumber>17/033,615</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.01.20</receiptDate><receiptNumber>1-1-2021-0075690-26</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2021.01.21</receiptDate><receiptNumber>9-1-2021-9000661-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.11.13</receiptDate><receiptNumber>1-1-2023-1251060-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.11.13</receiptDate><receiptNumber>1-1-2023-1251061-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210008000.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e385739107ee7585343ee96a2a4ae871d8d746de77eb9a0d4df6ff81c0654f0876135da079d5ab9e82e8a217b0a4c77987150665f3981b06</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa8bec6a9acd32a4faea77bec86460d7ea2d896198ebc3d4c77084194ffff3647de60be7241d59d0d62dd6deb91e2793d94531a4cc3e3c9ee</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>