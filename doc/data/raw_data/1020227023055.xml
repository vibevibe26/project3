<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:03.333</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.12.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7023055</applicationNumber><claimCount>17</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이전 프레임들을 이용한 골격 추적</inventionTitle><inventionTitleEng>SKELETAL TRACKING USING PREVIOUS FRAMES</inventionTitleEng><openDate>2022.08.03</openDate><openNumber>10-2022-0108812</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.07.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.07.05</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/269</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 51/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/4402</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 사용자의 자세를 검출하기 위한 프로그램 및 방법을 저장하는 컴퓨터 판독가능 저장 매체를 포함하는 시스템을 수반한다. 프로그램 및 방법은 동작들을 포함하고, 동작들은 사용자의 신체의 묘사를 포함하는 단안 이미지를 수신하는 동작; 단안 이미지에 기초하여 신체의 복수의 골격 관절을 검출하는 동작; 단안 이미지 전에 수신된 복수의 단안 이미지를 포함하는 비디오 피드(video feed)에 액세스하는 동작; 비디오 피드를 이용하여, 단안 이미지에 기초하여 검출된 신체의 복수의 골격 관절을 필터링하는 동작; 및 신체의 필터링된 복수의 골격 관절에 기초하여 단안 이미지에 묘사된 신체에 의해 표현되는 자세를 결정하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.06.17</internationOpenDate><internationOpenNumber>WO2021119408</internationOpenNumber><internationalApplicationDate>2020.12.11</internationalApplicationDate><internationalApplicationNumber>PCT/US2020/064476</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서:하나 이상의 프로세서에 의해, 사용자의 신체의 묘사를 포함하는 단안 이미지를 수신하는 단계;상기 하나 이상의 프로세서에 의해, 상기 단안 이미지에 기초하여 상기 신체의 복수의 골격 관절을 검출하는 단계;상기 단안 이미지 전에 수신된 복수의 단안 이미지를 포함하는 비디오 피드(video feed)에 액세스하는 단계;상기 비디오 피드를 이용하여, 상기 단안 이미지에 기초하여 검출된 상기 신체의 복수의 골격 관절을 필터링하는 단계; 및상기 신체의 필터링된 복수의 골격 관절에 기초하여 상기 단안 이미지에 묘사된 상기 신체에 의해 표현되는 자세를 결정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 하나 이상의 프로세서에 의해, 상기 신체의 필터링된 복수의 골격 관절에 기초하여 아바타의 리그의 골격 관절들의 세트를 조정함으로써 상기 단안 이미지에 묘사된 상기 신체에 의해 표현된 자세와 일치하도록 아바타의 자세를 수정하는 단계; 및상기 하나 이상의 프로세서에 의한 디스플레이를 위해, 상기 단안 이미지에 묘사된 상기 신체에 의해 표현된 자세와 일치하는 상기 수정된 자세를 갖는 아바타를 생성하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 단안 이미지는 제1 비디오 프레임이고, 상기 방법은:제1 머신 러닝 기법을 사용하여 상기 단안 이미지의 복수의 골격 관절 특징을 식별하는 단계 - 상기 복수의 골격 관절의 위치들은 상기 식별된 복수의 골격 관절 특징에 기초하여 검출됨 - 를 추가로 포함하는 방법.  </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제1 머신 러닝 기법은 제1 심층 신경망을 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 동작들을 수행함으로써 상기 제1 심층 신경망을 훈련하는 단계를 추가로 포함하고, 상기 동작들은:복수의 훈련 단안 이미지 및 상기 복수의 훈련 단안 이미지 각각에 대한 실측 골격 관절 정보를 포함하는 훈련 데이터를 수신하는 동작 - 상기 복수의 훈련 단안 이미지 각각은 상이한 신체 자세를 묘사함 -;상기 복수의 훈련 단안 이미지 중 제1 훈련 단안 이미지에 상기 제1 심층 신경망을 적용하여 상기 제1 훈련 단안 이미지에 묘사된 상기 신체의 골격 관절들을 추정하는 동작;상기 신체의 추정된 골격 관절들과 상기 제1 훈련 단안 이미지와 연관된 상기 실측 골격 관절 정보 사이의 편차를 계산하는 동작;상기 계산된 편차에 기초하여 상기 제1 심층 신경망의 파라미터들을 업데이트하는 동작; 및상기 복수의 훈련 단안 이미지 각각에 대해 상기 적용, 상기 계산 및 상기 업데이트 동작들을 반복하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 복수의 골격 관절을 필터링하는 단계는 상기 비디오 피드를 제2 머신 러닝 기법에 적용하여 골격 관절 위치들을 추정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 제2 머신 러닝 기법은 제2 심층 신경망을 포함하고, 상기 필터링은 상기 제2 심층 신경망에 의해 제공되는 상기 단안 이미지에 대한 골격 관절 위치들의 예측을 제1 머신 러닝 기술을 사용하여 식별되는 상기 단안 이미지의 복수의 골격 관절 특징과 비교하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 동작들을 수행함으로써 상기 제2 심층 신경망을 훈련하는 단계를 추가로 포함하고, 상기 동작들은:복수의 훈련 비디오 및 상기 복수의 훈련 비디오 각각에 대한 실측 골격 관절 정보를 포함하는 훈련 데이터를 수신하는 동작 - 상기 복수의 훈련 비디오 각각은 상이한 신체 자세를 묘사함 -;상기 복수의 훈련 비디오 중 제1 훈련 비디오에 상기 제2 심층 신경망을 적용하여 상기 제1 훈련 비디오에 후속하는 프레임에서 상기 신체의 골격 관절들을 예측하는 동작;상기 신체의 예측된 골격 관절들과 상기 제1 훈련 비디오와 연관된 상기 실측 골격 관절 정보 사이의 편차를 계산하는 동작;상기 계산된 편차에 기초하여 상기 제2 심층 신경망의 파라미터들을 업데이트하는 동작; 및상기 복수의 훈련 비디오 각각에 대해 상기 적용, 상기 계산 및 상기 업데이트 동작들을 반복하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 복수의 단안 이미지는 상기 단안 이미지를 수신하기 전에 임계 수의 초 동안 수신된 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 하나 이상의 프로세서에 의해, 복수의 아바타로부터 리그(rig)와 연관된 아바타를 선택하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 사용자의 신체의 묘사를 포함하는 복수의 단안 이미지를 포함하는 제2 비디오를 수신하는 단계;상기 복수의 단안 이미지에 걸쳐 상기 복수의 골격 관절에서의 변화들을 추적하는 단계;상기 복수의 골격 관절에서의 변화들을 추적한 것에 기초하여 상기 신체에 의해 표현되는 상기 자세에 대한 변화들을 검출하는 단계; 및상기 신체에 의해 표현된 자세에 상기 변화들을 일치시키기 위해 상기 아바타의 자세들을 연속적으로 또는 주기적으로 수정하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 아바타로 하여금 상기 결정된 자세에 기초하여 주어진 이미지에 묘사된 가상 객체와 상호작용하게 야기하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 검출, 상기 필터링, 및 상기 결정 단계들은 깊이 센서로부터의 깊이 정보에 액세스하지 않고 수행되는 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 신체의 상기 복수의 골격 관절을 검출하는 단계는 오른쪽 손목, 오른쪽 팔꿈치, 오른쪽 어깨, 상기 사용자의 얼굴 상의 코, 왼쪽 어깨, 왼쪽 팔꿈치, 및 왼쪽 손목과 제각기 연관된 포인트들을 식별하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 상기 복수의 골격 관절이 검출되는 레이트는 이미지 캡처 디바이스에 대한 상기 사용자의 위치에 기초하여 조정되는 방법.</claim></claimInfo><claimInfo><claim>16. 시스템으로서:동작들을 수행하도록 구성된 프로세서를 포함하고, 상기 동작들은: 사용자의 신체의 묘사를 포함하는 단안 이미지를 수신하는 동작; 상기 단안 이미지에 기초하여 상기 신체의 복수의 골격 관절을 검출하는 동작; 상기 단안 이미지 전에 수신된 복수의 단안 이미지를 포함하는 비디오 피드(video feed)에 액세스하는 동작; 상기 비디오 피드를 이용하여, 상기 단안 이미지에 기초하여 검출된 상기 신체의 복수의 골격 관절을 필터링하는 동작; 및 상기 신체의 필터링된 복수의 골격 관절에 기초하여 상기 단안 이미지에 묘사된 상기 신체에 의해 표현되는 자세를 결정하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 동작들은 상기 비디오 피드를 머신 러닝 기법에 적용함으로써 상기 복수의 골격 관절을 필터링하여 골격 관절 위치들을 추정하는 동작을 추가로 포함하는 시스템.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 머신 러닝 기법은 심층 신경망을 포함하고, 상기 동작들은: 복수의 훈련 비디오 및 상기 복수의 훈련 비디오 각각에 대한 실측 골격 관절 정보를 포함하는 훈련 데이터를 수신하는 동작 - 상기 복수의 훈련 비디오 각각은 상이한 신체 자세를 묘사함 -;상기 복수의 훈련 비디오 중 제1 훈련 비디오에 상기 심층 신경망을 적용하여 상기 제1 훈련 비디오에 묘사된 상기 신체의 골격 관절들을 추정하는 동작;상기 신체의 추정된 골격 관절들과 상기 제1 훈련 비디오와 연관된 상기 실측 골격 관절 정보 사이의 편차를 계산하는 동작;상기 계산된 편차에 기초하여 상기 심층 신경망의 파라미터들을 업데이트하는 동작; 및상기 복수의 훈련 비디오 각각에 대해 상기 적용, 상기 계산 및 상기 업데이트하는 동작들을 반복함으로써 상기 머신 러닝 기법을 훈련하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>19. 명령어들을 포함하는 비-일시적인 머신-판독가능 저장 매체로서, 상기 명령어들은 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금:사용자의 신체의 묘사를 포함하는 단안 이미지를 수신하는 동작;상기 단안 이미지에 기초하여 상기 신체의 복수의 골격 관절을 검출하는 동작;상기 단안 이미지 전에 수신된 복수의 단안 이미지를 포함하는 비디오 피드(video feed)에 액세스하는 동작;상기 비디오 피드를 이용하여, 상기 단안 이미지에 기초하여 검출된 상기 신체의 복수의 골격 관절을 필터링하는 동작; 및상기 신체의 필터링된 복수의 골격 관절에 기초하여 상기 단안 이미지에 묘사된 상기 신체에 의해 표현되는 자세를 결정하는 동작을 포함하는 동작들을 수행하게 야기하는 비일시적 머신 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 동작들은 상기 비디오 피드를 머신 러닝 기법에 적용함으로써 상기 복수의 골격 관절을 필터링하여 골격 관절 위치들을 추정하는 동작을 추가로 포함하는 비일시적 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ASSOULINE, Avihay</engName><name>아술린, 아비하이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BERGER, Itamar</engName><name>버거, 이타마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>DUDOVITCH, Gal</engName><name>두도비치, 갈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ZOHAR, Matan</engName><name>조하르, 마탄</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.12.11</priorityApplicationDate><priorityApplicationNumber>16/710,980</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.07.05</receiptDate><receiptNumber>1-1-2022-0700048-63</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.07.07</receiptDate><receiptNumber>1-5-2022-0101563-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.04.18</receiptDate><receiptNumber>9-5-2025-0380105-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.06.12</receiptDate><receiptNumber>1-1-2025-0656039-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.06.12</receiptDate><receiptNumber>1-1-2025-0656056-65</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227023055.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9327062f2baf75f4449123d186c9a38a58e4f7770af3b61361adf7d80f87d27c19d6b65c7a1ebcdb6a87ac1f25f7ee459d8b5a8b506875c5b1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb6ec55628460c46340b078d223e9e4065cc5367ca29090f31bdeb3d5c41436f09edacaac2d93cbe505da317a30ffe790a6161cd6ce9c1aa6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>