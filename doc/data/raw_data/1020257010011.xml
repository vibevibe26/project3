<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:51.051</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7010011</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>터치 기반 증강 현실 경험</inventionTitle><inventionTitleEng>TOUCH-BASED AUGMENTED REALITY EXPERIENCE</inventionTitleEng><openDate>2025.04.25</openDate><openNumber>10-2025-0056240</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.26</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용은 터치 기반 증강 현실(AR) 경험을 제공하기 위한 방법들 및 시스템들에 관한 것이다. 캡처 페이즈 동안, 제1 사용자가 객체를 그립할 수 있다. 그립에서 객체에 가해지는 힘의 강도 및/또는 그립의 지속기간이 기록될 수 있다. 객체를 잡고 있는 제1 사용자의 체적 표현이 또한 캡처될 수 있다. 경험 페이즈 동안, 제2 사용자가 객체를 터치할 수 있으며, 객체는 객체에 가해지는 힘의 강도 및 객체의 그립의 지속기간에 대응하는 강도 및 지속기간으로 햅틱 피드백(예를 들어, 진동)을 제2 사용자에게 제공할 수 있다. 객체를 잡고 있는 제1 사용자의 체적 표현이 캡처되면, 객체를 터치하는 것은 또한 객체를 잡고 있는 제1 사용자의 체적 신체의 프레젠테이션을 야기할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.07</internationOpenDate><internationOpenNumber>WO2024050259</internationOpenNumber><internationalApplicationDate>2023.08.23</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/072701</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,제1 사용자에 의한 객체의 그립(grip)을 설명하는 데이터에 액세스하는 단계;제2 사용자가 상기 객체를 터치하는 것을 검출하는 단계; 및상기 제2 사용자가 상기 객체를 터치하는 것을 검출한 것에 응답하여, 상기 제1 사용자에 의한 상기 객체의 그립을 설명하는 데이터에 기초하여 상기 객체가 상기 제2 사용자와의 상호작용을 제공하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 데이터는 상기 객체의 제1 영역에 대한 상기 사용자의 그립을 표시하고;상기 제2 사용자가 상기 객체를 터치하는 것을 검출하는 단계는 상기 제2 사용자가 터치한 상기 객체의 제2 영역이 상기 제1 영역과 적어도 부분적으로 중첩하는 것을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 객체가 상기 제2 사용자와의 상호작용을 제공하게 하는 단계는 상기 객체가 상기 제2 사용자에게 햅틱 피드백을 제공하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 객체의 그립과 관련된 데이터는 상기 그립에 의해 상기 객체에 가해지는 힘의 측정치(measure)를 포함하고,상기 객체에 의한 상기 햅틱 피드백의 강도는 상기 그립에 의해 상기 객체에 가해지는 상기 힘의 측정치에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 객체의 그립과 관련된 데이터는 상기 그립의 지속기간을 추가로 포함하고;상기 객체에 의해 제공되는 상기 햅틱 피드백의 지속기간은 상기 그립의 지속기간에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 객체의 그립과 관련된 데이터는 상기 제1 사용자에 의한 상기 객체의 그립 동안 기록된 오디오 신호를 추가로 포함하고;상기 객체가 상기 제2 사용자와의 상호작용을 제공하게 하는 단계는:오디오 디바이스가 상기 오디오 신호를 제시(present)하게 하는 단계를 포함하고, 상기 오디오 디바이스는 상기 객체에 통신가능하게 결합되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 제2 사용자가 상기 객체를 터치하는 것을 검출한 것에 응답하여 상기 제2 사용자의 디스플레이 디바이스에 의해 상기 객체 상에 오버레이된 상기 그립 상에 시각적 표현의 프레젠테이션(presentation)을 야기하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 시각적 표현은 지문-유사 표현(fingerprint-like representation)을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 객체의 그립과 연관된 체적 콘텐츠에 액세스하는 단계 - 상기 체적 콘텐츠는 상기 객체를 그립하는 상기 제1 사용자의 체적 표현을 포함함 -; 및상기 객체의 검출에 응답하여 상기 제2 사용자의 디스플레이 디바이스에 의한 상기 체적 콘텐츠의 프레젠테이션을 야기하는 단계를 추가로 포함하고, 상기 체적 콘텐츠의 프레젠테이션을 야기하는 단계는 상기 디스플레이 디바이스가 상기 제2 사용자의 시야에서 현실 세계 환경 상에 오버레이된 상기 객체를 그립하는 상기 제1 사용자의 상기 체적 표현을 제시하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 객체는 제1 객체이고;상기 방법은:제3 사용자가 제2 객체를 터치하는 것을 검출하는 단계; 및상기 제3 사용자가 상기 제2 객체를 터치하는 것을 검출한 것에 응답하여, 상기 제2 객체가 상기 제3 사용자에게 상기 상호작용을 제공하게 하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 제3 사용자가 상기 제2 객체를 터치하는 것을 검출한 것에 응답하여, 상기 제1 객체가 상기 제2 사용자와의 제2 상호작용을 제공하게 하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 시스템으로서,하나 이상의 프로세서; 및상기 하나 이상의 프로세서에 의해 실행될 때, 동작들을 수행하도록 상기 시스템을 구성하는 명령어들을 저장한 적어도 하나의 메모리를 포함하고, 상기 동작들은:제1 사용자에 의한 객체의 그립(grip)을 설명하는 데이터에 액세스하는 것;제2 사용자가 상기 객체를 터치하는 것을 검출하는 것; 및상기 제2 사용자가 상기 객체를 터치하는 것을 검출한 것에 응답하여, 상기 제1 사용자에 의한 상기 객체의 그립을 설명하는 데이터에 기초하여 상기 객체가 상기 제2 사용자와의 상호작용을 제공하게 하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 데이터는 상기 객체의 제1 영역에 대한 상기 사용자의 그립을 표시하고;상기 제2 사용자가 상기 객체를 터치하는 것을 검출하는 것은 상기 제2 사용자가 터치한 상기 객체의 제2 영역이 상기 제1 영역과 적어도 부분적으로 중첩하는 것을 결정하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 객체가 상기 제2 사용자와의 상호작용을 제공하게 하는 것은 상기 객체가 상기 제2 사용자에게 햅틱 피드백을 제공하게 하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 객체의 그립과 관련된 데이터는 상기 그립에 의해 상기 객체에 가해지는 힘의 측정치를 포함하고,상기 객체에 의한 상기 햅틱 피드백의 강도는 상기 그립에 의해 상기 객체에 가해지는 상기 힘의 측정치에 기초하는, 시스템.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 객체의 그립과 관련된 데이터는 상기 그립의 지속기간을 추가로 포함하고;상기 객체에 의해 제공되는 상기 햅틱 피드백의 지속기간은 상기 그립의 지속기간에 기초하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서,상기 객체의 그립과 관련된 데이터는 상기 제1 사용자에 의한 상기 객체의 그립 동안 기록된 오디오 신호를 추가로 포함하고;상기 객체가 상기 제2 사용자와의 상호작용을 제공하게 하는 것은:오디오 디바이스가 상기 오디오 신호를 제시하게 하는 것을 포함하고, 상기 오디오 디바이스는 상기 객체에 통신가능하게 결합되는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서,상기 제2 사용자가 상기 객체를 터치하는 것을 검출한 것에 응답하여 상기 제2 사용자의 디스플레이 디바이스에 의해 상기 객체 상에 오버레이된 상기 그립 상에 시각적 표현의 프레젠테이션을 야기하는 것을 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 시각적 표현은 지문-유사 표현을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금 동작들을 수행하게 하는 명령어들을 포함하고, 상기 동작들은:제1 사용자에 의한 객체의 그립을 설명하는 데이터에 액세스하는 것;제2 사용자가 상기 객체를 터치하는 것을 검출하는 것; 및상기 제2 사용자가 상기 객체를 터치하는 것을 검출한 것에 응답하여, 상기 제1 사용자에 의한 상기 객체의 그립을 설명하는 데이터에 기초하여 상기 객체가 상기 제2 사용자와의 상호작용을 제공하게 하는 것을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>인도</country><engName>VAISH, Rajan</engName><name>바이쉬, 라잔</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>독일</country><engName>KRATZ, Sven</engName><name>크라츠, 스벤</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>멕시코</country><engName>MONROY-HERNANDEZ, Andres</engName><name>몬로이-헤르난데즈, 안드레스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>SMITH, Brian Anthony</engName><name>스미스, 브라이언 안토니</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.31</priorityApplicationDate><priorityApplicationNumber>63/402,905</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.11.16</priorityApplicationDate><priorityApplicationNumber>18/056,142</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>1-1-2025-0343680-83</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.04.01</receiptDate><receiptNumber>1-5-2025-0054086-64</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257010011.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9394bba7dc0958ae506f4c830fb1da12f663dfe94e6a176c0448c91daa0c3f3751ad8ed5acfe90fdd20ede04cd64c2c4f96090d5fe5bd534e8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0a7545679e173d3131f11cbded193f72f7aaeda682fd8eb66162f1b3066f6116b92944e8d0039388a58b8336d0d262bf310f402768b436b8</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>