<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:43.243</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.04.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7021248</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사람 관절들을 이용한 무인 항공기들 상의 카메라들의 교정</inventionTitle><inventionTitleEng>CALIBRATION OF CAMERAS ON UNMANNED AERIAL VEHICLES USING HUMAN JOINTS</inventionTitleEng><openDate>2022.07.25</openDate><openNumber>10-2022-0104025</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.06.22</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.06.22</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/17</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B64C 39/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>B64U 101/30</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 무인 항공기들(UAV들) 상의 카메라들의 교정을 위한 시스템 및 방법이 제공된다. 시스템은 앵커 카메라들의 세트로부터 사람 대상체의 앵커 이미지들의 세트를 수신하고, UAV들의 그룹 상의 카메라들의 그룹으로부터 3차원(3D) 공간에서의 복수의 시점으로부터의 사람 대상체의 이미지들의 그룹을 수신한다. 시스템은 앵커 이미지들의 세트로부터 사람 관절들의 제1 세트의 2차원(2D) 위치들을 결정하고, 이미지들의 그룹으로부터 사람 관절들의 제2 세트의 2D 위치들을 결정한다. 시스템은 제1 세트의 2D 위치들을 이용한 삼각측량에 기반하여 사람 관절들의 3D 위치들을 3D 키포인트들로서 계산하고, 3D 키포인트들과 제2 세트의 2D 위치들 사이의 2D 재투영 에러를 결정한다. 그 후, 2D 재투영 에러를 최소화함으로써, 시스템은 카메라들의 그룹의 각각의 카메라를 교정한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.10.28</internationOpenDate><internationOpenNumber>WO2021216948</internationOpenNumber><internationalApplicationDate>2021.04.23</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/028762</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 시스템으로서,무인 항공기들(Unmanned Aerial Vehicles)(UAV들)의 그룹 상에 장착되거나 이와 통합된 카메라들의 그룹 및 앵커 카메라 디바이스들의 세트에 통신가능하게 결합된 회로를 포함하며, 상기 회로는,상기 앵커 카메라 디바이스들의 세트로부터, 사람 대상체(human subject)의 앵커 이미지들의 세트를 수신하고;상기 카메라들의 그룹으로부터, 3차원(3D) 공간에서의 복수의 시점으로부터의 상기 사람 대상체의 이미지들의 그룹을 수신하고;수신된 앵커 이미지들의 세트의 각각의 앵커 이미지에서의 상기 사람 대상체에 대해, 사람 관절들(human joints)의 제1 세트의 2차원(2D) 위치들을 결정하고;수신된 이미지들의 그룹의 각각의 이미지에서의 상기 사람 대상체에 대해, 상기 사람 관절들의 제2 세트의 2D 위치들을 결정하고;상기 사람 관절들의 결정된 제1 세트의 2D 위치들을 이용한 삼각측량에 기반하여 상기 3D 공간에서의 상기 사람 관절들의 3D 위치들을 3D 키포인트들로서 계산하고;상기 3D 키포인트들과 결정된 제2 세트의 2D 위치들 사이의 2D 재투영 에러를 결정하고;결정된 2D 재투영 에러를 최소화함으로써 상기 카메라들의 그룹의 각각의 카메라를 교정하도록구성되는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 3D 공간은 실외 공간, 실내 공간, 또는 볼류메트릭 캡처(volumetric capture)를 위한 스튜디오 셋업 중 하나와 연관되는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 회로는,상기 UAV들의 그룹을 제어하여 상기 3D 공간에서의 상기 복수의 시점에서 상기 UAV들의 그룹을 이동시키고;상기 UAV들의 그룹 상에 장착되거나 이와 통합된 상기 카메라들의 그룹을 제어하여 상기 복수의 시점으로부터의 상기 사람 대상체의 상기 이미지들의 그룹을 획득하도록추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 앵커 카메라 디바이스들의 세트는 UAV 상에 장착되거나 이와 통합되고 상기 카메라들의 그룹이 고정된 포즈에 대해 이동하도록 제어되어 상기 이미지들의 그룹을 획득하는 동안 상기 고정된 포즈를 유지하도록 구성되는 적어도 하나의 카메라를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 앵커 카메라 디바이스들의 세트는 상기 카메라들의 그룹이 제어되어 상기 이미지들의 그룹을 획득하는 동안 상기 3D 공간에서의 위치에 고정되는 적어도 하나의 미리 교정된 카메라를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제3항에 있어서,상기 앵커 카메라 디바이스들의 세트는 원격 제어 카메라 이동 조립체에 이동가능하게 결합된 적어도 하나의 미리 교정된 카메라를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 회로는 상기 3D 공간에서 상기 앵커 카메라 디바이스들의 세트를 제어하여 상기 앵커 이미지들의 세트를 획득하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 회로는 상기 수신된 앵커 이미지들의 세트의 각각의 앵커 이미지에 기계 학습(ML) 모델을 적용함으로써 상기 사람 관절들의 제1 세트의 2D 위치들을 결정하도록 구성되고, 상기 ML 모델은, 사람 관절 검출 프레임워크로서, 2D 사람 관절 검출 작업에 대해 훈련된 신경망을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 회로는 상기 수신된 이미지들의 그룹의 각각의 이미지에 ML 모델을 적용함으로써 상기 사람 관절들의 제2 세트의 2D 위치들을 결정하도록 구성되고, 상기 ML 모델은, 사람 관절 검출 프레임워크로서, 2D 사람 관절 검출 작업에 대해 훈련된 신경망을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 카메라들의 그룹의 각각의 카메라들의 교정은 대응하는 카메라의 3D 포즈의 추정에 대응하고,상기 3D 포즈는 상기 3D 공간에서의 상기 대응하는 카메라의 3D 위치 및 배향을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 UAV들의 그룹 중 적어도 하나의 UAV는 위치 센서를 포함하고,상기 위치 센서는 전역적 내비게이션 위성 시스템(Global Navigation Satellite System)(GNSS) 수신기, 관성 측정 유닛(Inertial Measurement Unit)(IMU), 감지 카메라, 적외선 마커 센서, 또는 패턴 코드 스캐너 중 하나인, 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 회로는 대응하는 UAV의 상기 위치 센서로부터 획득된 절대 위치 정보에 추가로 기반하여 상기 카메라들의 그룹의 각각의 카메라를 교정하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,상기 회로는 대응하는 카메라에 대한 고유 교정 파라미터들의 값들에 추가로 기반하여 상기 카메라들의 그룹의 각각의 카메라를 교정하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>14. 방법으로서,앵커 카메라 디바이스들의 세트로부터, 사람 대상체의 앵커 이미지들의 세트를 수신하는 단계;UAV들의 그룹 상에 장착되거나 이와 통합된 카메라들의 그룹으로부터, 3차원(3D) 공간에서의 복수의 시점으로부터의 상기 사람 대상체의 이미지들의 그룹을 수신하는 단계;수신된 앵커 이미지들의 세트의 각각의 앵커 이미지에서의 상기 사람 대상체에 대해, 사람 관절들의 제1 세트의 2차원(2D) 위치들을 결정하는 단계;수신된 이미지들의 그룹의 각각의 이미지에서의 상기 사람 대상체에 대해, 상기 사람 관절들의 제2 세트의 2D 위치들을 결정하는 단계;상기 사람 관절들의 결정된 제1 세트의 2D 위치들을 이용한 삼각측량에 기반하여 상기 3D 공간에서의 상기 사람 관절들의 3D 위치들을 3D 키포인트들로서 계산하는 단계;상기 3D 키포인트들과 결정된 제2 세트의 2D 위치들 사이의 2D 재투영 에러를 결정하는 단계; 및결정된 2D 재투영 에러를 최소화함으로써 상기 카메라들의 그룹의 각각의 카메라를 교정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 UAV들의 그룹을 제어하여 상기 3D 공간에서의 상기 복수의 시점에서 상기 UAV들의 그룹을 이동시키는 단계; 및상기 UAV들의 그룹 상에 장착되거나 이와 통합된 상기 카메라들의 그룹을 제어하여 상기 복수의 시점으로부터의 상기 사람 대상체의 상기 이미지들의 그룹을 획득하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 수신된 앵커 이미지들의 세트의 각각의 앵커 이미지에 기계 학습(ML) 모델을 적용함으로써 상기 사람 관절들의 제1 세트의 2D 위치들을 결정하는 단계; 및상기 수신된 이미지들의 그룹의 각각의 이미지에 상기 ML 모델을 적용함으로써 상기 사람 관절들의 제2 세트의 2D 위치들을 결정하는 단계를 추가로 포함하며,상기 ML 모델은, 사람 관절 검출 프레임워크로서, 2D 사람 관절 검출 작업에 대해 훈련된 신경망을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,각각의 카메라의 교정은 대응하는 UAV의 3D 포즈의 추정에 대응하고,상기 3D 포즈는 상기 3D 공간에서의 상기 대응하는 UAV의 3D 위치 및 배향을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제14항에 있어서,상기 UAV들의 그룹 중 적어도 하나의 UAV는 위치 센서를 포함하고,상기 위치 센서는 전역적 내비게이션 위성 시스템(GNSS) 수신기, 관성 측정 유닛(IMU), 감지 카메라, 적외선 마커 센서, 또는 패턴 코드 스캐너 중 하나인, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,대응하는 카메라 피팅된 UAV의 상기 위치 센서로부터 획득된 절대 위치 정보에 추가로 기반하여 상기 UAV들의 그룹의 각각의 UAV를 교정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 시스템 내의 컴퓨터에 의해 실행될 때, 상기 시스템으로 하여금 동작들을 실행하게 하는 컴퓨터 구현 명령어들을 저장한 비일시적 컴퓨터 판독가능한 매체로서,상기 동작들은,앵커 카메라 디바이스들의 세트로부터, 사람 대상체의 앵커 이미지들의 세트를 수신하는 것;UAV들의 그룹 상에 장착되거나 이와 통합된 카메라들의 그룹으로부터, 3차원(3D) 공간에서의 복수의 시점으로부터의 상기 사람 대상체의 이미지들의 그룹을 수신하는 것;수신된 앵커 이미지들의 세트의 각각의 앵커 이미지에서의 상기 사람 대상체에 대해, 사람 관절들의 제1 세트의 2차원(2D) 위치들을 결정하는 것;수신된 이미지들의 그룹의 각각의 이미지에서의 상기 사람 대상체에 대해, 상기 사람 관절들의 제2 세트의 2D 위치들을 결정하는 것;상기 사람 관절들의 결정된 제1 세트의 2D 위치들을 이용한 삼각측량에 기반하여 상기 3D 공간에서의 상기 사람 관절들의 3D 위치들을 3D 키포인트들로서 계산하는 것;상기 3D 키포인트들과 결정된 제2 세트의 2D 위치들 사이의 2D 재투영 에러를 결정하는 것; 및결정된 2D 재투영 에러를 최소화함으로써 상기 카메라들의 그룹의 각각의 카메라를 교정하는 것을 포함하는, 비일시적 컴퓨터 판독가능한 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>일본국 도쿄도 미나토쿠 코난 *-*-*</address><code>519980961547</code><country>일본</country><engName>Sony Group Corporation</engName><name>소니그룹주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아주 산 호세 노...</address><code> </code><country> </country><engName>TAHARA, Daisuke</engName><name>다하라 다이스케</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주 산 호세 노...</address><code> </code><country> </country><engName>BERESTOV, Alexander</engName><name>베레스토브 알렉산더</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990002028</code><country>대한민국</country><engName>LEE, JUNG HEE</engName><name>이중희</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980004828</code><country>대한민국</country><engName>CHANG, Soo Kil</engName><name>장수길</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.04.23</priorityApplicationDate><priorityApplicationNumber>16/856,511</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.06.22</receiptDate><receiptNumber>1-1-2022-0651313-29</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.06.28</receiptDate><receiptNumber>1-5-2022-0095918-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.05.09</receiptDate><receiptNumber>9-5-2025-0444187-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.07.08</receiptDate><receiptNumber>1-1-2025-0767316-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.07.08</receiptDate><receiptNumber>1-1-2025-0767318-03</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227021248.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d5280a6ea8dce91e45608c7f02fe0a50936a3808c8e91a19941a4de275459ae405a84639b2829a057e379595b1fc1ce11e1153e6bd0f7cac</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf15410d9bb9b2f67f1e9f994292fda40a5fa7b7e45ed8fc085c23326d76e4a1830acc56a8cdd90f81d0ec1319825a6a178508f9e8423e5f60</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>