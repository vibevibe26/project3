<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:17.3917</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0153939</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>트레이닝 시스템 및 그 동작 방법</inventionTitle><inventionTitleEng>TRAINING SYSTEMS AND OPERATION METHOD THEREOF</inventionTitleEng><openDate>2024.07.09</openDate><openNumber>10-2024-0108239</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/098</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/063</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 9/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 트레이닝 시스템 및 그 동작 방법이 제공된다. 트레이닝 시스템은 신경망 모델에 대응하는 트레이닝 잡(training job)을 복수의 논리 작업자에 의해 실행되는 복수의 마이크로서비스(a plurality of microservices)로 분할하는 잡 프록시(job proxy), 및 상기 복수의 마이크로서비스를 복수의 프로세싱 유닛(a plurality of processing units)에 스케줄링하는 스케줄러(scheduler)를 포함하고, 상기 복수의 마이크로서비스는 상기 복수의 논리 작업자 중 제1 논리 작업자에 의해 실행되는 복수의 제1 마이크로서비스 및 상기 복수의 논리 작업자 중 제2 논리 작업자에 의해 실행되는 복수의 제2 마이크로서비스를 포함하고, 상기 스케줄러는, 상기 복수의 프로세싱 유닛의 가용 상태에 기초하여, 상기 복수의 제1 마이크로서비스 및 상기 복수의 제2 마이크로서비스를 상기 복수의 프로세싱 유닛 중 어느 하나의 프로세싱 유닛에 스케줄링한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 신경망 모델에 대응하는 트레이닝 잡(training job)을 복수의 논리 작업자에 의해 실행되는 복수의 마이크로서비스(a plurality of microservices)로 분할하는 잡 프록시(job proxy); 및상기 복수의 마이크로서비스를 복수의 프로세싱 유닛(a plurality of processing units)에 스케줄링하는 스케줄러(scheduler)를 포함하고,상기 복수의 마이크로서비스는 상기 복수의 논리 작업자 중 제1 논리 작업자에 의해 실행되는 복수의 제1 마이크로서비스 및 상기 복수의 논리 작업자 중 제2 논리 작업자에 의해 실행되는 복수의 제2 마이크로서비스를 포함하고, 상기 스케줄러는, 상기 복수의 프로세싱 유닛의 가용 상태에 기초하여, 상기 복수의 제1 마이크로서비스 및 상기 복수의 제2 마이크로서비스를 상기 복수의 프로세싱 유닛 중 어느 하나의 프로세싱 유닛에 스케줄링하는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 스케줄러는, 가용 프로세싱 유닛(available processing unit)의 개수가 상기 복수의 논리 작업자의 개수보다 적음에 따라, 상기 복수의 제1 마이크로서비스 및 상기 복수의 제2 마이크로서비스를 상기 어느 하나의 프로세싱 유닛에 순차적으로 스케줄링하는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 스케줄러는, 상기 복수의 제1 마이크로서비스와 상기 복수의 제2 마이크로서비스를 동일한 컨테이너(container)에 스케줄링하는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,상기 복수의 마이크로서비스는, 상기 트레이닝 잡에 대한 트레이닝 데이터가 분할된 복수의 미니 배치(minibatch)를 처리하는 함수를 포함하고, 상기 스케줄러는 상기 어느 하나의 프로세싱 유닛에서 상기 복수의 제1 마이크로서비스 중 어느 하나의 미니 배치 처리와 상기 복수의 제2 마이크로서비스 중 어느 하나의 미니 배치 처리가 복수의 단계(multiple phases)로 실행되도록 스케줄링하는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,자원 관리자를 더 포함하고, 상기 자원 관리자는, 상기 신경망 모델에 대응하는 상기 트레이닝 잡에 상기 복수의 프로세싱 유닛을 2n 단위로 할당하는, 트레이닝 시스템(n은 0 또는 자연수).</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,자원 관리자를 더 포함하고, 상기 자원 관리자는, 상기 신경망 모델에 대응하는 상기 트레이닝 잡이 2k개의 논리 작업자를 포함하는 경우, 상기 복수의 프로세싱 유닛을 2k의 약수 중 어느 하나의 단위로 할당하고, 상기 트레이닝 잡이 2k-1개의 논리 작업자를 포함하는 경우, 상기 복수의 프로세싱 유닛을 2k-1의 약수 중 어느 하나 또는 2k의 약수 중 1과 2k을 제외한 어느 하나의 단위로 할당하는, 트레이닝 시스템(k는 자연수).</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서, 복수의 신경망 모델에 대응하는 복수의 트레이닝 잡 각각에 상기 복수의 프로세싱 유닛을 할당하는 자원 관리자를 더 포함하고, 상기 자원 관리자는, 최단 잔여 서비스 시간(shortest remaining service time)을 갖는 트레이닝 잡부터 순서대로 클러스터에 존재하는 프로세싱 유닛을 할당하고, 상기 클러스터에 잔여 프로세싱 유닛(remaining processing unit)이 존재함에 따라, 필요한 프로세싱 유닛의 수보다 적은 수의 프로세싱 유닛이 할당된 트레이닝 잡에 상기 잔여 프로세싱 유닛을 할당하는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서,복수의 신경망 모델에 대응하는 복수의 트레이닝 잡 각각에 상기 복수의 프로세싱 유닛을 할당하는 자원 관리자를 더 포함하고, 상기 자원 관리자는, 상기 복수의 트레이닝 잡 각각에 프로세싱 유닛을 할당하고, 큐(queue)에 저장된 대기 트레이닝 잡(queuing training job)이 존재함에 따라, 대기 트레이닝 잡의 대기 시간(queuing time)이 하나 이상의 트레이닝 잡이 복수의 단계(multiple phases)로 실행됨에 따른 예상 증가 시간(expected increase time)보다 긴 경우, 상기 대기 트레이닝 잡에 상기 프로세싱 유닛을 재할당하는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,상기 복수의 마이크로서비스는, 복수의 미니 배치 각각에 대한 가중치를 계산하는 계산 함수; 및상기 복수의 미니 배치 각각 대한 가중치를 총합한 글로벌 파라미터를 계산하는 집계 함수를 포함하는, 트레이닝 시스템. </claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,상기 복수의 제1 마이크로서비스의 제1 계산 함수와 상기 복수의 제2 마이크로서비스의 제2 계산 함수가 동일한 이터레이션에서 순차적으로 실행되는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>11. 제9 항에 있어서,상기 복수의 제1 마이크로서비스의 제1 계산 함수는, 상기 글로벌 파라미터(global parameter)를 읽고, 상기 글로벌 파라미터를 상기 복수의 제2 마이크로서비스의 제2 계산 함수에 전달하는, 트레이닝 시스템. </claim></claimInfo><claimInfo><claim>12. 제1 항에 있어서,상기 복수의 마이크로서비스는, 상기 복수의 논리 작업자 중 제3 논리 작업자에 의해 실행되는 복수의 제3 마이크로서비스 및 상기 복수의 논리 작업자 중 제4 논리 작업자에 의해 실행되는 복수의 제4 마이크로서비스를 포함하고,상기 스케줄러는, 상기 복수의 제3 마이크로서비스 및 상기 복수의 제4 마이크로서비스를 상기 복수의 프로세싱 유닛 중 다른 하나의 프로세싱 유닛에 스케줄링하고,상기 복수의 제3 마이크로서비스는 상기 복수의 제1 마이크로서비스와 병렬적으로 실행되는, 트레이닝 시스템.</claim></claimInfo><claimInfo><claim>13. 신경망 모델에 대응하는 트레이닝 잡을 복수의 논리 작업자 각각에 의해 실행되는 복수의 마이크로서비스로 분할하는 단계; 및 상기 복수의 마이크로서비스를 복수의 프로세싱 유닛에 스케줄링하는 단계를 포함하고,상기 스케줄링하는 단계는, 상기 복수의 프로세싱 유닛의 가용 상태에 기초하여, 상기 복수의 논리 작업자 중 제1 논리 작업자에 의해 실행되는 복수의 제1 마이크로서비스 및 상기 복수의 논리 작업자 중 제2 논리 작업자에 의해 실행되는 복수의 제2 마이크로서비스를 상기 복수의 프로세싱 유닛 중 어느 하나의 프로세싱 유닛에 스케줄링하는 단계를 포함하는, 트레이닝 시스템의 동작 방법.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 스케줄링하는 단계는, 가용 프로세싱 유닛의 개수가 상기 복수의 논리 작업자의 개수보다 적다고 판단된 것에 기초하여, 상기 복수의 제1 마이크로서비스 및 상기 복수의 제2 마이크로서비스를 상기 어느 하나의 프로세싱 유닛에 순차적으로 스케줄링하는 단계를 포함하는, 트레이닝 시스템의 동작 방법.</claim></claimInfo><claimInfo><claim>15. 제13 항에 있어서,상기 스케줄링하는 단계는, 상기 복수의 제1 마이크로서비스와 상기 복수의 제2 마이크로서비스를 동일한 컨테이너에 스케줄링하는 단계를 포함하는, 트레이닝 시스템의 동작 방법.</claim></claimInfo><claimInfo><claim>16. 제13 항에 있어서,상기 어느 하나의 프로세싱 유닛에서 상기 복수의 제1 마이크로서비스 중 어느 하나의 미니 배치 처리와 상기 복수의 제2 마이크로서비스 중 어느 하나의 미니 배치 처리가 복수의 단계(multiple phases)로 실행되도록 스케줄링하는 단계를 더 포함하는, 트레이닝 시스템의 동작 방법.</claim></claimInfo><claimInfo><claim>17. 제13 항에 있어서,상기 신경망 모델에 대응하는 상기 트레이닝 잡에 상기 복수의 프로세싱 유닛을 2n 단위로 할당하는 단계를 더 포함하는, 트레이닝 시스템의 동작 방법(n은 0 또는 자연수).</claim></claimInfo><claimInfo><claim>18. 제13 항에 있어서,복수의 신경망 모델에 대응하는 복수의 트레이닝 잡 각각에 상기 복수의 프로세싱 유닛을 할당하는 단계를 더 포함하고, 상기 복수의 트레이닝 잡 각각에 상기 복수의 프로세싱 유닛을 할당하는 단계는, 최단 잔여 서비스 시간(shortest remaining service time)을 갖는 트레이닝 잡부터 순서대로 클러스터에 존재하는 프로세싱 유닛을 할당하는 단계; 및상기 클러스터에 잔여 프로세싱 유닛(remaining processing unit)이 존재함에 따라, 필요한 프로세싱 유닛의 수보다 적은 수의 프로세싱 유닛이 할당된 트레이닝 잡에 상기 잔여 프로세싱 유닛을 할당하는 단계를 포함하는, 트레이닝 시스템의 동작 방법.</claim></claimInfo><claimInfo><claim>19. 제13 항에 있어서,복수의 신경망 모델에 대응하는 복수의 트레이닝 잡 각각에 상기 복수의 프로세싱 유닛을 할당하는 단계; 및 큐(queue)에 저장된 대기 트레이닝 잡(queuing training job)이 존재함에 따라, 대기 트레이닝 잡의 대기 시간(queuing time)이 하나 이상의 트레이닝 잡이 복수의 단계(multiple phases)로 실행됨에 따른 예상 증가 시간(expected increase time)보다 긴 경우, 상기 대기 트레이닝 잡에 상기 프로세싱 유닛을 재할당하는 단계를 더 포함하는, 트레이닝 시스템의 동작 방법. </claim></claimInfo><claimInfo><claim>20. 제13 항에 있어서,상기 복수의 마이크로서비스는, 상기 복수의 논리 작업자 중 제3 논리 작업자에 의해 실행되는 복수의 제3 마이크로서비스 및 상기 복수의 논리 작업자 중 제4 논리 작업자에 의해 실행되는 복수의 제4 마이크로서비스를 포함하되,상기 스케줄링하는 단계는, 상기 복수의 제3 마이크로서비스 및 상기 복수의 제4 마이크로서비스를 상기 복수의 프로세싱 유닛 중 다른 하나의 프로세싱 유닛에 스케줄링하는 단계; 및상기 복수의 제3 마이크로서비스는 상기 복수의 제1 마이크로서비스와 병렬적으로 실행되는 단계를 포함하는, 트레이닝 시스템의 동작 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>울산광역시 울주군...</address><code>120150812047</code><country>대한민국</country><engName>UNIST(ULSAN NATIONAL INSTITUTE OF SCIENCE AND TECHNOLOGY)</engName><name>울산과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>CHOI, Young Ri</engName><name>최영리</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>JEONG, Yeon Hyeok</engName><name>정연혁</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>LEE, Seung Min</engName><name>이승민</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>JUE, Seong Hyeon</engName><name>주성현</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.12.30</priorityApplicationDate><priorityApplicationNumber>1020220191027</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.08</receiptDate><receiptNumber>1-1-2023-1236675-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.01.25</receiptDate><receiptNumber>4-1-2024-5044479-73</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230153939.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938826990045ec5c6dd7bda74d7ddcc29bdc94a64758cd829424e9e81e43f0a19e6d94db3bdb9557a1b0c896d5101f12c7f93a8b72a833fdca</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf66b532a156c4392b3352611b24bdac2bb0212e55d700ca4d62f8e651504c4175ac6bde0e019a40e92d771a4b685942d0392306c5d71d19c7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>