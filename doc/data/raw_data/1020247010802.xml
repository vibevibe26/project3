<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:32.4032</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.08.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7010802</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 프로프 상호작용</inventionTitle><inventionTitleEng>AUGMENTED REALITY PROP INTERACTIONS</inventionTitleEng><openDate>2024.04.18</openDate><openNumber>10-2024-0050437</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.06.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.03.29</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 가상 또는 물리적 프로프 객체들과의 상호작용들을 포함하여 AR 경험들을 생성하기 위한 증강 현실(AR) 시스템들, 디바이스들, 매체들 및 방법들이 설명된다. AR 경험들은 카메라 시스템을 통해 장면의 이미지들을 캡처하며, 장면 내 객체 수용 표면 및 대응 표면 좌표들을 식별하며, AR 주 객체 및 프로프 객체(물리적 또는 가상적)를 식별하며, AR 주 객체와 프로프 객체 사이의 논리적 연결을 설정하며, 장면 내 주 객체 좌표들 및 표면 좌표들에 대한 응답으로 객체 수용 표면에 인접하게 AR 주 객체를 포지셔닝하고 논리적 연결에 따라 AR 주 객체 및 프로프 객체를 서로에 대해 포지셔닝하는, 사용자 입력 시스템을 통해 수신된 커맨드들에 대한 응답으로 AR 주 객체와 연관된 액션들을 포함하는 AR 오버레이들을 생성하며; 그리고 디스플레이 시스템을 통해 생성된 AR 오버레이들을 제시함으로써 생성된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.03.09</internationOpenDate><internationOpenNumber>WO2023034017</internationOpenNumber><internationalApplicationDate>2022.08.16</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/040443</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. AR 경험을 생성하기 위한 증강 현실(AR) 디바이스로서,시야 내의 장면의 이미지들을 캡처하도록 구성된 카메라 시스템;디스플레이 상에 AR 오버레이들을 제시하도록 구성된 디스플레이 시스템 — 상기 디스플레이는 카메라 시스템 시야에 대응하는 뷰잉 영역(viewing area)을 가짐 —;사용자로부터의 입력을 수신하도록 구성된 사용자 입력 시스템; 및상기 카메라 시스템, 상기 디스플레이 시스템, 및 상기 사용자 입력 시스템에 커플링된 프로세서를 포함하며, 상기 프로세서는, 상기 카메라 시스템을 통해 상기 장면의 이미지들을 캡처하며; 상기 장면 내 객체 수용 표면 및 대응 표면 좌표들을 식별하며; 상기 사용자 입력 시스템을 통해 수신된 입력에 대한 응답으로, AR 주 객체(primary object) 및 프로프 객체(prop object)를 식별하며 — 상기 AR 주 객체는 주 객체 좌표들의 적어도 하나의 세트와 연관됨 —; 상기 AR 주 객체와 상기 프로프 객체 사이의 논리적 연결을 설정하며; 상기 장면 내 상기 주 객체 좌표들 및 상기 표면 좌표들에 대한 응답으로 상기 객체 수용 표면에 인접하게 상기 AR 주 객체를 포지셔닝하고 상기 논리적 연결에 따라 상기 AR 주 객체 및 상기 프로프 객체를 서로에 대해 포지셔닝하는, 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 대한 응답으로 상기 AR 주 객체와 연관된 액션(action)들을 포함하는 AR 오버레이들을 생성하며; 그리고 상기 디스플레이 시스템을 통해 상기 생성된 AR 오버레이들을 제시하도록 구성되는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 프로세서는,상기 AR 오버레이들을 기록하며; 상기 기록된 오버레이들을 포함하는 AR 파일을 생성하며; 그리고상기 AR 파일을 송신하도록 추가로 구성되는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서, 상기 프로프 객체는 상기 장면 내의 물리적 객체이며, 상기 물리적 객체를 식별하기 위해, 상기 프로세서는 상기 사용자 입력 시스템을 통해 상기 물리적 객체의 선택을 수신하도록 구성되는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,상기 프로세서는,상기 선택된 물리적 객체에 대한 카테고리를 식별하며; 그리고상기 식별된 카테고리에 대한 응답으로 상기 물리적 객체에 대한 로직을 선택하도록 추가로 구성되며, 상기 선택된 로직은 상기 AR 주 객체와 상기 물리적 객체 사이의 미리 정의된 상호작용들을 특정하며;상기 설정된 논리적 연결은 상기 선택된 로직에 기반하며, 상기 생성된 AR 오버레이들은 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 응답하는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서, 상기 프로프 객체는 AR 보조 객체이며, 상기 AR 보조 객체를 식별하기 위해, 상기 프로세서는 상기 사용자 입력 시스템을 통해 상기 AR 보조 객체의 선택을 수신하도록 구성되는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서, 상기 선택된 AR 보조 객체는 상기 AR 주 객체와 상기 AR 보조 객체 사이의 미리 정의된 상호작용들을 특정하는 로직과 연관되는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 미리 정의된 상호작용들은 상기 AR 보조 객체가 상기 AR 주 객체의 움직임을 미러링하는 미러링 액션을 포함하는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서, 상기 프로프 객체는 AR 보조 객체이며, 상기 AR 보조 객체를 식별하기 위해, 상기 프로세서는 상기 사용자 입력 시스템을 통해 입력을 수신하며 상기 사용자 입력에 대한 응답으로 상기 AR 보조 객체를 생성하도록 구성되는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서,상기 프로세서는, 상기 생성된 AR 보조 객체에 대한 카테고리를 식별하며; 그리고 상기 식별된 카테고리에 대한 응답으로 상기 생성된 보조 객체에 대한 로직을 선택하도록 추가로 구성되며, 상기 선택된 로직은 상기 AR 주 객체와 상기 AR 보조 객체 사이의 미리 정의된 상호작용들을 특정하며; 상기 설정된 논리적 연결은 상기 선택된 로직에 기반하며, 상기 생성된 AR 오버레이들은 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 응답하는, AR 경험을 생성하기 위한 증강 현실(AR) 디바이스.</claim></claimInfo><claimInfo><claim>10. AR 경험을 생성하기 위한 증강 현실(AR) 방법으로서,카메라 시스템을 통해 장면의 이미지들을 캡처하는 단계;상기 장면 내 객체 수용 표면 및 대응 표면 좌표들을 식별하는 단계;사용자 입력 시스템을 통해 수신된 입력에 대한 응답으로, AR 주 객체 및 프로프 객체를 식별하는 단계 — 상기 AR 주 객체는 주 객체 좌표들의 적어도 하나의 세트와 연관됨 —;상기 AR 주 객체와 상기 프로프 객체 사이의 논리적 연결을 설정하는 단계;상기 장면 내 상기 주 객체 좌표들 및 상기 표면 좌표들에 대한 응답으로 상기 객체 수용 표면에 인접하게 상기 AR 주 객체를 포지셔닝하고 상기 논리적 연결에 따라 상기 AR 주 객체 및 상기 프로프 객체를 서로에 대해 포지셔닝하는, 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 대한 응답으로 상기 AR 주 객체와 연관된 액션들을 포함하는 AR 오버레이들을 생성하는 단계; 및디스플레이 시스템을 통해 상기 생성된 AR 오버레이들을 제시하는 단계를 포함하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서,상기 AR 오버레이들을 기록하는 단계; 상기 기록된 오버레이들을 포함하는 AR 파일을 생성하는 단계; 및상기 AR 파일을 송신하는 단계를 더 포함하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>12. 제10 항에 있어서, 상기 프로프 객체는 상기 장면 내의 물리적 객체이며, 물리적 객체를 식별하는 단계는 상기 사용자 입력 시스템을 통해 상기 물리적 객체의 선택을 수신하는 단계를 포함하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 선택된 물리적 객체에 대한 카테고리를 식별하는 단계; 및상기 식별된 카테고리에 대한 응답으로 상기 물리적 객체에 대한 로직을 선택하는 단계를 더 포함하며, 상기 선택된 로직은 상기 AR 주 객체와 상기 물리적 객체 사이의 미리 정의된 상호작용들을 특정하며;상기 설정된 논리적 연결은 상기 선택된 로직에 기반하며, 상기 생성된 AR 오버레이들은 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 응답하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>14. 제10 항에 있어서, 상기 프로프 객체는 AR 보조 객체이며, AR 보조 객체를 식별하는 단계는 상기 사용자 입력 시스템을 통해 상기 AR 보조 객체의 선택을 수신하는 단계를 포함하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서, 상기 선택된 AR 보조 객체는 상기 AR 주 객체와 상기 AR 보조 객체 사이의 미리 정의된 상호작용들을 특정하는 로직과 연관되는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서, 상기 미리 정의된 상호작용들은 상기 AR 보조 객체가 상기 AR 주 객체의 움직임을 미러링하는 미러링 액션을 포함하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>17. 제10 항에 있어서, 상기 프로프 객체는 AR 보조 객체이며, AR 보조 객체를 식별하는 단계는 상기 사용자 입력 시스템을 통해 입력을 수신하며 상기 사용자 입력에 대한 응답으로 상기 AR 보조 객체를 생성하는 단계를 포함하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서,상기 생성된 AR 보조 객체에 대한 카테고리를 식별하는 단계; 및상기 식별된 카테고리에 대한 응답으로 상기 생성된 보조 객체에 대한 로직을 선택하는 단계를 더 포함하며, 상기 선택된 로직은 상기 AR 주 객체와 상기 AR 보조 객체 사이의 미리 정의된 상호작용들을 특정하며;상기 설정된 논리적 연결은 상기 선택된 로직에 기반하며, 상기 생성된 AR 오버레이들은 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 응답하는, AR 경험을 생성하기 위한 증강 현실(AR) 방법.</claim></claimInfo><claimInfo><claim>19. 명령들을 포함하는 프로그램 코드를 저장한 비-일시적 컴퓨터-판독 가능 매체로서, 상기 명령들은, 실행될 때, 전자 프로세서로 하여금, 카메라 시스템을 통해 장면의 이미지들을 캡처하는 단계;상기 장면 내 객체 수용 표면 및 대응 표면 좌표들을 식별하는 단계;사용자 입력 시스템을 통해 수신된 입력에 대한 응답으로, AR 주 객체 및 프로프 객체를 식별하는 단계 — 상기 AR 주 객체는 주 객체 좌표들의 적어도 하나의 세트와 연관됨 —;상기 AR 주 객체와 상기 프로프 객체 사이의 논리적 연결을 설정하는 단계;상기 장면 내 상기 주 객체 좌표들 및 상기 표면 좌표들에 대한 응답으로 상기 객체 수용 표면에 인접하게 상기 AR 주 객체를 포지셔닝하고 상기 논리적 연결에 따라 상기 AR 주 객체 및 상기 프로프 객체를 서로에 대해 포지셔닝하는, 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 대한 응답으로 상기 AR 주 객체와 연관된 액션들을 포함하는 AR 오버레이들을 생성하는 단계; 및디스플레이 시스템을 통해 상기 생성된 AR 오버레이들을 제시하는 단계를 수행하게 하도록 동작하는, 비-일시적 컴퓨터-판독 가능 매체.</claim></claimInfo><claimInfo><claim>20. 제19 항에 있어서, 상기 프로프 객체는 상기 장면 내의 물리적 객체이며, 물리적 객체를 식별하는 단계는 상기 사용자 입력 시스템을 통해 상기 물리적 객체의 선택을 수신하는 단계를 포함하며, 상기 방법은,  상기 선택된 물리적 객체에 대한 카테고리를 식별하는 단계; 및 상기 식별된 카테고리에 대한 응답으로 상기 물리적 객체에 대한 로직을 선택하는 단계를 더 포함하며, 상기 선택된 로직은 상기 AR 주 객체와 상기 물리적 객체 사이의 미리 정의된 상호작용들을 특정하며;상기 설정된 논리적 연결은 상기 선택된 로직에 기반하며, 상기 생성된 AR 오버레이들은 상기 사용자 입력 시스템을 통해 수신된 커맨드들에 응답하는, 비-일시적 컴퓨터-판독 가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>CHEN, Tianying</engName><name>첸, 텐잉</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>CHONG, Timothy</engName><name>종, 티모시</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>KRATZ, Sven</engName><name>크라츠, 스벤</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>LIU, Fannie</engName><name>리우, 패니</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MONROY-HERNANDEZ, Andres</engName><name>몬로이-헤르난데즈, 안드레스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>SEOW, Olivia</engName><name>서우, 올리비아</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>THAM, Yu Jiang</engName><name>탐, 유 지앙</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>VAISH, Rajan</engName><name>바이쉬, 라잔</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ZHANG, Lei</engName><name>장, 레이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.09.02</priorityApplicationDate><priorityApplicationNumber>63/240,049</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.03.29</receiptDate><receiptNumber>1-1-2024-0355856-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.04.03</receiptDate><receiptNumber>1-1-2024-0372907-97</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.04.03</receiptDate><receiptNumber>1-5-2024-0057310-88</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.06.11</receiptDate><receiptNumber>1-1-2025-0651432-68</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247010802.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9371b02c7f1ae7731050cfcb9aafe6e24b5b031ae690e8161525edde2c44f40513061e1f8cff0e9a88d28fb00e0b724cc1bbbebc6ed2387d3a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf65ac49f31857d016231acfb1e24f31998ab41ff4e3960a72eca4abfadbda5843028257c28bbb356b0e31cfd4a87a5c3d3a71a2291ec6e233</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>