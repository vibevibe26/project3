<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:54.5154</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7025835</applicationNumber><claimCount>36</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>네트워크-중심적 증강 현실 프로세싱을 위한 장치, 컴퓨터-구현 방법, 및 컴퓨터 프로그램 제품</inventionTitle><inventionTitleEng>APPARATUSES, COMPUTER-IMPLEMENTED METHODS, AND COMPUTER PROGRAM PRODUCTS FOR NETWORK-CENTRIC AUGMENTED REALITY PROCESSING</inventionTitleEng><openDate>2024.09.30</openDate><openNumber>10-2024-0142445</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.07.30</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 67/131</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 67/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 개시내용의 다양한 실시예는 네트워크-중심적 증강 현실 프로세싱을 위한 장치, 방법, 및 컴퓨터 프로그램 제품을 제공한다. 다양한 실시예는 네트워크 분석에서의 장점, 및 구역 내의 포지션(들)에서의 네트워크 품질을 개선시키기 위하여 구역 내의 디바이스 및/또는 객체를 위치결정 시의 추가적인 장점을 제공한다. 예시적인 실시예는 증강 현실 환경 내의 포지션을 카메라 데이터에서 표시되는 네트워크화된 디바이스 세트, 네트워크 액세스 디바이스 세트, 객체 세트, 및/또는 코너 세트로 매핑하기 위하여 수신된 카메라 데이터를 프로세싱한다. 추가적으로 또는 대안적으로, 일부 실시예는 프로세싱된 카메라 데이터에 기초하여 환경 플롯을 생성한다. 일부 실시예는 구역 내의 하나 이상의 디바이스의 서비스를 위한, 및/또는 하나 이상의 디바이스와 연관되는 디바이스 보호 프로그램 정보를 제공하기 위한 세션의 개시를 가능하게 한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.07.06</internationOpenDate><internationOpenNumber>WO2023129950</internationOpenNumber><internationalApplicationDate>2022.12.28</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/082459</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 네트워크-중심적 증강 현실 프로세싱을 위한 컴퓨터-구현 방법으로서,구역(premises)을 나타내는 증강 현실 환경과 연관되는 카메라 데이터를 수신하는 단계 - 상기 카메라 데이터는 카메라 회로부에 의해 캡처됨 -;상기 카메라 회로부가 상기 구역을 내비게이팅(navigate)할 때에 생성되도록 구성된 복수의 플롯 코너(plot corner)를 포함하는 플롯 코너 세트와 연관되는 적어도 하나의 표시를 수신하는 단계 - 상기 적어도 하나의 표시는 상기 카메라 데이터의 부분과 연관됨 -; 및상기 플롯 코너 세트 내의 각각의 플롯 코너를 상기 구역과 연관되는 상기 증강 현실 환경 내의 코너 위치로서 매핑함으로써 환경 플롯(environment plot)을 생성하는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 플롯 코너 세트와 연관되는 적어도 하나의 표시를 수신하는 단계는,사용자 입력 데이터가 상기 카메라 데이터에서의 제1 플롯 코너의 존재를 표시하는 것에 응답하여 제1 표시를 수신하는 단계; 및상기 카메라 데이터 및 제1 매핑 디바이스 포지션 데이터에 기초하여, 상기 제1 플롯 코너를 상기 증강 현실 환경 내의 제1 코너 위치로 매핑하는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,제2 매핑 디바이스 포지션에 대한 횡단을 표시하는 제2 매핑 디바이스 포지션 데이터를 수신하는 단계;제2 사용자 입력 데이터가 상기 카메라 데이터에서의 제2 플롯 코너의 존재를 표시하는 것에 응답하여 제2 표시를 수신하는 단계; 및상기 카메라 데이터 및 상기 제2 매핑 디바이스 포지션 데이터에 기초하여, 상기 제2 플롯 코너를 상기 증강 현실 환경 내의 제2 코너 위치로 매핑하는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 플롯 코너 세트와 연관되는 적어도 하나의 표시를 수신하는 단계는,제1 매핑 디바이스 포지션 데이터와 연관되는 상기 카메라 데이터를 수신하는 단계;상기 카메라 데이터에서 제1 플롯 코너를 검출하는 단계; 및제2 매핑 디바이스 포지션 데이터 및 상기 카메라 데이터에 기초하여, 상기 제1 플롯 코너를 상기 증강 현실 환경 내의 제1 코너 위치로 매핑하는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 카메라 데이터에 기초하여, 네트워크화된 디바이스의 제2 표시를 수신하는 단계; 및상기 네트워크화된 디바이스를 상기 증강 현실 환경 내의 네트워크화된 디바이스 위치와 매핑하는 단계 - 상기 환경 플롯은 상기 네트워크화된 디바이스 위치를 더 포함함 -를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 네트워크화된 디바이스의 제2 표시를 수신하는 단계는,사용자 입력 데이터가 상기 카메라 데이터에서의 상기 네트워크화된 디바이스의 존재를 표시하는 것에 응답하여 상기 제2 표시를 수신하는 단계; 및상기 카메라 데이터 및 제1 매핑 디바이스 포지션 데이터에 기초하여, 상기 네트워크화된 디바이스를 상기 증강 현실 환경 내의 상기 네트워크화된 디바이스 위치로 매핑하는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 네트워크화된 디바이스의 제2 표시를 수신하는 단계는,제1 매핑 디바이스 포지션 데이터와 연관되는 상기 카메라 데이터를 수신하는 단계;상기 카메라 데이터에서 상기 네트워크화된 디바이스를 검출하는 단계; 및제1 디바이스 위치결정 데이터 및 상기 카메라 데이터에 기초하여, 상기 네트워크화된 디바이스를 상기 증강 현실 환경 내의 상기 네트워크화된 디바이스 위치로 매핑하는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,제1 매핑 디바이스 포지션 데이터를 수신하는 단계;제1 네트워크 액세스 디바이스와 연관되는 제1 네트워크 강도 데이터를 결정하는 단계 - 상기 제1 네트워크 강도 데이터는 상기 제1 매핑 디바이스 포지션 데이터와 연관됨 -;제2 매핑 디바이스 포지션 데이터를 수신하는 단계 - 상기 제2 매핑 디바이스 포지션 데이터는 상기 제1 매핑 디바이스 포지션 데이터와는 상이한 포지션을 표시함 -; 및상기 제1 네트워크 액세스 디바이스와 연관되는 제2 네트워크 강도 데이터를 결정하는 단계 - 상기 제2 네트워크 강도 데이터는 상기 제2 매핑 디바이스 포지션 데이터와 연관되고, 상기 환경 플롯은 상기 제1 매핑 디바이스 포지션 데이터 및 상기 제1 네트워크 강도 데이터에 기초한 제1 네트워크 강도 표시자를 더 포함하고, 상기 환경 플롯은 상기 제2 매핑 디바이스 포지션 데이터 및 상기 제2 네트워크 강도 데이터에 기초한 제2 네트워크 강도 표시자를 더 포함함 -를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,적어도 상기 제1 매핑 디바이스 포지션 데이터와 연관되는 상기 제1 네트워크 강도 데이터 및 상기 제2 디바이스 위치결정 데이터와 연관되는 상기 제2 네트워크 강도 데이터의 비교에 기초하여, 선호되는 네트워크화된 디바이스 포지션 데이터를 생성하는 단계; 및상기 선호되는 네트워크화된 디바이스 포지션 데이터에 기초하여, 선호되는 네트워크화된 디바이스 포지션 표시자의 렌더링을 야기시키는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,환경 명명 데이터(environment naming data)를 수신하는 단계;상기 환경 명명 데이터와 연관되는 상기 환경 플롯을 저장하는 단계;상기 환경 플롯에 대응하는 상기 환경 명명 데이터와 연관되는, 그룹화되어야 할 적어도 하나의 네트워크화된 디바이스의 표시를 수신하는 단계; 및상기 환경 명명 데이터와 연관되는 상기 적어도 하나의 네트워크화된 디바이스에 대한 네트워크화된 디바이스 식별 데이터를 저장하는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 컴퓨터-구현 방법은,(1) 상기 카메라 데이터에 의해 표현되는, 실시간으로 캡처된 실세계 화상, 및 (2) 상기 카메라 데이터에 의해 표현되는 상기 실세계 화상에 대하여 렌더링되는 상기 증강 현실 환경의 적어도 부분을 포함하는 실시간 증강 현실 인터페이스를 제공하는 단계를 더 포함하고, 상기 증강 현실 환경의 부분은 상기 카메라 회로부의 방위(orientation)에 기초하고,상기 실시간 증강 현실 인터페이스는 (3) 상기 증강 현실 환경과 상호작용하기 위한 적어도 하나의 정적 인터페이스 엘리먼트(static interface element)를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>12. 네트워크-중심적 증강 현실 프로세싱을 위한 컴퓨터-구현 방법으로서,구역을 나타내는 증강 현실 환경과 연관되는 카메라 데이터를 수신하는 단계;상기 카메라 데이터에 기초하여, 간섭 객체 세트와 연관되는 적어도 하나의 표시를 수신하는 단계 - 상기 간섭 객체 세트는 물리적 구조, 가구 객체, 또는 신호 간섭기를 포함하는 적어도 하나의 객체와 연관되는 데이터를 포함함 -;상기 간섭 객체 세트의 적어도 하나의 간섭 객체 및 네트워크 액세스 디바이스에 기초하여, 상기 증강 현실 환경 내의 약화된 네트워크 강도 포지션을 결정하는 단계 - 상기 약화된 네트워크 강도 포지션은 상기 네트워크 액세스 디바이스에 대한 제1 네트워크 강도 데이터와 연관됨 -; 및상기 약화된 네트워크 강도 포지션에 관해 사용자에게 통지하기 위하여 상기 약화된 네트워크 강도 포지션과 연관되는 데이터의 렌더링을 야기시키는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 약화된 네트워크 강도 포지션과 연관되는 데이터의 렌더링을 야기시키는 단계는,상기 증강 현실 환경 내에서 시각적으로 구별되는 상기 약화된 네트워크 강도 포지션을 갖는 상기 증강 현실 환경의 적어도 부분의 렌더링을 야기시키는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 컴퓨터-구현 방법은,상기 카메라 데이터에 기초하여, 네트워크화된 디바이스의 표시를 수신하는 단계; 및상기 네트워크화된 디바이스가 상기 약화된 네트워크 강도 포지션으로부터의 미리 결정된 거리에서 또는 상기 미리 결정된 거리 내에서 배치되는 것으로 결정하는 단계를 더 포함하고,상기 약화된 네트워크 강도 포지션과 연관되는 데이터의 렌더링을 야기시키는 단계는,상기 네트워크화된 디바이스를 재위치시키기 위한 추천을 포함하는, 상기 사용자에 대한 통지의 렌더링을 야기시키는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 컴퓨터-구현 방법은,상기 증강 현실 환경 내의 제2 포지션과 연관되는 제2 네트워크 강도 데이터를 검출하는 단계를 더 포함하고,상기 통지는 상기 사용자가 상기 네트워크화된 디바이스를 상기 제2 포지션으로 재위치시켜야 한다는 것을 표시하는 적어도 하나의 인터페이스 엘리먼트를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 약화된 네트워크 강도 포지션과 연관되는 데이터의 렌더링을 야기시키는 단계는, 상기 약화된 네트워크 강도 포지션에서의 상기 제1 네트워크 강도 데이터를 개선시키기 위하여, 상기 간섭 객체 세트의 상기 적어도 하나의 간섭 객체가 재위치결정되거나 제거되어야 한다는 것을 표시하는 적어도 하나의 인터페이스 엘리먼트를 렌더링하는 단계를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서,상기 카메라 데이터에 기초하여, 간섭 객체 세트와 연관되는 적어도 하나의 표시를 수신하는 단계는,상기 카메라 데이터에 기초하여 제1 간섭 객체를 검출하기 위하여 객체 검출 모델을 사용하는 단계를 포함하고, 상기 객체 검출 모델은 적어도 하나의 간섭 객체 유형을 검출하도록 구성되는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서,상기 카메라 데이터에 기초하여, 상기 네트워크 액세스 디바이스의 표시를 수신하는 단계; 및상기 네트워크 액세스 디바이스의 상기 표시에 기초하여, 상기 네트워크 액세스 디바이스를 상기 증강 현실 환경 내의 네트워크 액세스 디바이스 포지션으로 매핑하는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>19. 네트워크-중심적 증강 현실 프로세싱을 위한 컴퓨터-구현 방법으로서,카메라 회로부에 의해 캡처되는 카메라 데이터에 적어도 기초하여, 환경 플롯을 생성하는 단계 - 상기 카메라 데이터는 구역을 나타내고, 상기 환경 플롯은 증강 현실 환경에 대응함 -;제1 네트워크 액세스 디바이스에 대한 제1 네트워크 강도 데이터를 검출하는 단계 - 상기 제1 네트워크 강도 데이터는 상기 증강 현실 환경 내의 제1 포지션과 연관됨 -; 및상기 증강 현실 환경 내의 상기 제1 포지션에서 위치되는 네트워크 강도 표시자를 포함하는 상기 증강 현실 환경의 렌더링을 야기시키는 단계 - 상기 네트워크 강도 표시자는 적어도 상기 제1 네트워크 강도 데이터에 기초하여 시각적으로 구성됨 -를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 네트워크 강도 표시자는 제1 네트워크 강도 표시자를 포함하고, 상기 컴퓨터-구현 방법은,제1 네트워크 액세스 디바이스에 대한 제2 네트워크 강도 데이터를 검출하는 단계 - 제2 네트워크 강도 데이터는 증강 현실 환경 내의 제2 포지션과 연관되고, 제1 네트워크 강도 데이터는 제2 네트워크 강도 데이터와는 상이함 -; 및상기 제2 포지션에서 위치되는 제2 네트워크 강도 표시자를 포함하는 상기 증강 현실 환경의 렌더링을 야기시키는 단계 - 상기 제2 네트워크 강도 표시자는 적어도 상기 제2 네트워크 강도 데이터에 기초하여, 상기 제1 네트워크 강도 표시자와는 시각적으로 별개인 것으로서 시각적으로 구성됨 -를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서,상기 네트워크 강도 표시자는 제1 컬러의 제1 파동 표현(wave representation)을 포함하고, 상기 제1 컬러는 상기 제1 네트워크 강도 데이터에 기초하여 선택되고, 상기 제2 네트워크 강도 표시자는 제2 컬러의 제2 파동 표현을 포함하고, 상기 제2 컬러는 상기 제2 네트워크 강도 데이터에 기초하여 선택되는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>22. 제19항에 있어서,상기 카메라 데이터에 기초하여, 네트워크화된 디바이스의 표시를 수신하는 단계 - 상기 네트워크화된 디바이스는 상기 증강 현실 환경 내의 상기 제1 포지션에서 배치됨 -;상기 제1 네트워크 강도 데이터가 상기 증강 현실 환경 내의 제2 포지션과 연관되는 제2 네트워크 강도 데이터보다 약한 것으로 결정하는 단계; 및상기 네트워크화된 디바이스가 상기 제2 포지션으로 재위치결정되어야 한다는 것을 표시하는 데이터의 렌더링을 야기시키는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>23. 제19항에 있어서,상기 증강 현실 환경 내의 상기 제1 포지션과 연관되는 상기 제1 네트워크 강도 데이터를 개선시키기 위하여 상기 제1 네트워크 액세스 디바이스를 재위치시키기 위한 제2 포지션을 결정하는 단계; 및상기 제1 네트워크 액세스 디바이스가 상기 증강 현실 환경 내의 상기 제2 포지션으로 재위치되어야 한다는 것을 표시하는 데이터의 렌더링을 야기시키는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>24. 제19항에 있어서,제1 네트워크 액세스 디바이스가 상기 증강 현실 환경 내의 상기 제1 포지션에서 위치결정되어야 한다는 것을 표시하는 데이터의 렌더링을 야기시키는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>25. 네트워크-중심적 증강 현실 프로세싱을 위한 컴퓨터-구현 방법으로서,증강 현실 환경과 연관되는 구역을 나타내는 카메라 데이터를 수신하는 단계;상기 카메라 데이터로부터, 네트워크화된 디바이스 유형의 네트워크화된 디바이스를 검출하는 단계;상기 네트워크화된 디바이스를 상기 증강 현실 환경 내의 디바이스 포지션으로 매핑하는 단계; 및상기 네트워크화된 디바이스 및 상기 증강 현실 환경 내의 상기 디바이스 포지션과 연관되는 디바이스 검출된 액션을 개시하는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서,상기 디바이스 검출된 액션은,상기 네트워크화된 디바이스가 알려진 네트워크 액세스 디바이스에 접속되는 것으로 결정하는 것;상기 알려진 네트워크 액세스 디바이스를 이용하여, 상기 네트워크화된 디바이스와의 접속을 확립하는 것; 및상기 네트워크화된 디바이스의 아이덴티티(identity)를 확인하기 위하여 직접 데이터 핸드쉐이크(direct data handshake)를 실행하는 것 - 상기 데이터 핸드쉐이크는 상기 네트워크화된 디바이스 유형에 기초함 -을 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>27. 제25항에 있어서,상기 디바이스 검출된 액션은,상기 네트워크화된 디바이스가 알려진 액세스 디바이스에 접속되는 것으로 결정하는 것;상기 네트워크화된 디바이스로 하여금, 간접 핸드쉐이크 액션(indirect handshake action)을 수행하게 하기 위하여, 상기 알려진 네트워크 액세스 디바이스를 이용하여 간접 핸드쉐이크 데이터를 송신하는 것;상기 간접 핸드쉐이크 액션과 연관되는 간접 핸드쉐이크 인증 데이터를 캡처하는 것; 및상기 간접 핸드쉐이크 액션의 성능을 검증하기 위하여 상기 간접 핸드쉐이크 인증 데이터를 프로세싱하는 것 - 상기 간접 핸드쉐이크 액션의 검증은 상기 네트워크화된 디바이스의 아이덴티티를 확인함 -을 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>28. 제25항에 있어서,상기 디바이스 검출된 액션은,상기 네트워크화된 디바이스와 적어도 하나의 다른 네트워크화된 디바이스와의 연관(association)을 가능하게 하기 위하여 디바이스 그룹화 인터페이스의 렌더링을 야기시키는 것을 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>29. 제25항에 있어서,상기 디바이스 검출된 액션은,상기 네트워크화된 디바이스와 연관되는 상기 네트워크화된 디바이스 유형을 자동적으로 결정하는 것; 및상기 결정되는 네트워크화된 디바이스 유형에 기초하여, 상기 네트워크화된 디바이스를 디바이스 그룹화와 자동적으로 연관시키는 것을 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서,상기 네트워크화된 디바이스는 제1 네트워크화된 디바이스를 포함하고, 상기 디바이스 포지션은 제1 디바이스 포지션을 포함하고, 상기 컴퓨터-구현 방법은,제2 디바이스 포지션과 연관되는 제2 네트워크화된 디바이스를 검출하는 단계;상기 제2 디바이스 포지션이 상기 제1 디바이스 포지션으로부터 임계 범위 내에 있는 것으로 결정하는 단계; 및상기 제2 네트워크화된 디바이스를 상기 디바이스 그룹화와 자동적으로 연관시키는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>31. 네트워크-중심적 증강 현실 프로세싱을 위한 컴퓨터-구현 방법으로서,구역의 실세계 화상을 나타내는 카메라 데이터를 수신하는 단계 - 상기 카메라 데이터는 적어도 하나의 네트워크화된 디바이스, 네트워크 액세스 디바이스, 및/또는 적어도 하나의 간섭 객체와 연관되는 적어도 하나의 포지션을 매핑하는 것과 연관되는 증강 현실 환경을 유지하기 위하여 사용됨 -; 및상기 증강 현실 환경과 연관되는 하나 이상의 디바이스를 서비스하는 것과 연관되는 증강 현실 서비스 세션을 개시하는 단계 - 상기 증강 현실 서비스 세션을 개시하는 것은 전자 지원 플랫폼과의 통신을 가능하게 함 -를 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서,상기 증강 현실 서비스 세션은 상기 전자 지원 플랫폼과 연관되는 디스플레이를 사용하여 렌더링하기 위하여 상기 전자 지원 플랫폼으로의 상기 카메라 데이터의 송신을 가능하게 하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>33. 제31항에 있어서,상기 전자 지원 플랫폼으로부터, 상기 증강 현실 환경 내의 표시자 포지션과 연관되는 전자 지원 생성된 증강 현실 표시자를 수신하는 단계; 및상기 표시자 포지션에서의 상기 전자 지원 생성된 증강 현실 표시자를 포함하는 상기 증강 현실 환경의 렌더링을 야기시키는 단계를 더 포함하는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서,상기 전자 지원 생성된 증강 현실 표시자는 상기 적어도 하나의 네트워크화된 디바이스의 서비스를 위한 제1 네트워크화된 디바이스를 식별하는 시각적 표시자를 나타내는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>35. 제33항에 있어서,상기 전자 지원 생성된 증강 현실 표시자는 새로운 네트워크화된 디바이스, 또는 상기 적어도 하나의 네트워크화된 디바이스의 제1 네트워크화된 디바이스를 배치하기 위한 상기 증강 현실 환경 내의 포지션을 식별하는 시각적 표시자를 나타내는, 컴퓨터-구현 방법.</claim></claimInfo><claimInfo><claim>36. 제33항에 있어서,상기 컴퓨터-구현 방법은,상기 증강 현실 환경 내의 제1 포지션에 대한 네트워크 강도 데이터에 대응하는 적어도 하나의 증강 현실 엘리먼트를 생성하는 단계를 더 포함하고, 상기 네트워크 강도 데이터는 특정한 네트워크 액세스 디바이스와 연관되고, 상기 전자 지원 생성된 증강 현실 표시자는 상기 증강 현실 환경 내의 상기 제1 포지션에서 상기 네트워크 강도 데이터를 개선시키기 위하여 상기 특정한 네트워크 액세스 디바이스를 배치하기 위한 상기 증강 현실 환경 내의 제2 포지션을 식별하는 시각적 표시자를 나타내는, 컴퓨터-구현 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 뉴욕 뉴욕 스위트 **** 브로드웨이 **</address><code>520050117760</code><country>미국</country><engName>Assurant, Inc.</engName><name>어슈어런트, 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 오하이오 웨스...</address><code> </code><country> </country><engName>SEGAL, Daniel</engName><name>시걸 다니엘</name></inventorInfo><inventorInfo><address>미국 ***** 오하이오 웨스...</address><code> </code><country> </country><engName>IONESCU, Mircea</engName><name>이오네스쿠 미르체아</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, 서림빌딩 **층 (역삼동)</address><code>920011000036</code><country>대한민국</country><engName>YOU ME PATENT &amp; LAW FIRM</engName><name>유미특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.30</priorityApplicationDate><priorityApplicationNumber>63/266,232</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.07.30</receiptDate><receiptNumber>1-1-2024-0831522-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[New Translation under Article 201 of Patent Act or Article 35 of Utility Model Act] Submission of Document</documentEngName><documentName>[특허법 제201조 또는 실용신안법 제35조에 따른 새로운 번역문]서류제출서</documentName><receiptDate>2024.08.05</receiptDate><receiptNumber>1-1-2024-0847879-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.02</receiptDate><receiptNumber>1-5-2024-0143398-24</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247025835.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338e2bd3a9276dafcb92dc6a11d646e8743981674da086c6f46f046865bc022a5eeac7dd93235cec48aface8d0825a142ba9ad926c7beff768f8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf29f3a01beb4bd35d85082d3306cccec2e22652ce29ac13e59d1b71f2d034b40c7459c86c4e1937f6f7a823f8b9953e85b64fb42a8439d666</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>