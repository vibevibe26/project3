<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:14.714</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7018302</applicationNumber><claimCount>32</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>물리적 표면들에 대한 가상 콘텐츠의 앵커링</inventionTitle><inventionTitleEng>ANCHORING VIRTUAL CONTENT TO PHYSICAL SURFACES</inventionTitleEng><openDate>2024.07.19</openDate><openNumber>10-2024-0112853</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.10.01</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.05.30</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 장면 내에 가상 콘텐츠를 렌더링하기 위한 시스템들 및 기법들이 제공된다. 예시적인 방법은, 물리적 환경의 장면 내의 표면 평면을 결정하는 단계; 장면 내의 일정 위치에 일정 관점으로 가상 콘텐츠를 렌더링하는 단계; 표면 평면의 제1 공간 상에 가상 콘텐츠와 연관된 콘텐츠 배치 표시자를 렌더링하는 단계 - 콘텐츠 배치 표시자는 가상 콘텐츠의 배치를 위한 제1 공간을 나타냄 -; 표면 평면과 연관된 표면 상의 하나 이상의 객체들의 하나 이상의 위치들을 결정하는 단계; 및 입력에 응답하여, 표면 평면의 제2 공간 상에 콘텐츠 배치 표시자를 렌더링하는 단계 - 제2 공간은 하나 이상의 위치들 및 입력에 기초하여 결정되고, 콘텐츠 배치 표시자는 가상 콘텐츠의 배치를 위한 제2 공간을 나타냄 - 를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.06.15</internationOpenDate><internationOpenNumber>WO2023107777</internationOpenNumber><internationalApplicationDate>2022.10.17</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/078235</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 물리적 환경의 장면 내에 가상 콘텐츠를 렌더링(rendering)하기 위한 장치로서,메모리; 및상기 메모리에 커플링된 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은, 상기 물리적 환경의 장면 내의 적어도 하나의 표면 평면을 결정하도록; 상기 장면 내의 제1 위치에 제1 관점으로 가상 콘텐츠 아이템을 렌더링하도록; 상기 적어도 하나의 표면 평면의 제1 공간 상에 상기 가상 콘텐츠 아이템과 연관된 콘텐츠 배치 표시자를 렌더링하도록 - 상기 콘텐츠 배치 표시자는 상기 가상 콘텐츠 아이템의 배치를 위한 상기 제1 공간의 적어도 일부를 나타냄 -; 상기 적어도 하나의 표면 평면과 연관된 표면 상의 하나 이상의 객체들의 하나 이상의 위치들을 결정하도록; 그리고 사용자 입력에 응답하여, 상기 적어도 하나의 표면 평면의 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하도록 - 상기 적어도 하나의 표면 평면의 제2 공간은 상기 하나 이상의 위치들 및 상기 사용자 입력에 기초하여 결정되고, 상기 콘텐츠 배치 표시자는 상기 가상 콘텐츠 아이템의 배치를 위한 상기 제2 공간의 적어도 일부를 나타냄 - 구성되는, 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 프로세서들은,상기 제2 공간 상에의 상기 가상 콘텐츠 아이템의 배치를 요청하는 추가 사용자 입력에 응답하여, 상기 콘텐츠 배치 표시자에 기초하여 상기 장면 내의 제2 위치에 제2 관점으로 상기 가상 콘텐츠 아이템을 렌더링하도록 추가로 구성되고, 상기 제2 위치는 상기 제2 공간 내에 있는, 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 하나 이상의 프로세서들은,상기 제2 공간의 관점에 기초하여 상기 제2 관점을 결정하도록 추가로 구성되는, 장치.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 하나 이상의 프로세서들은,상기 적어도 하나의 표면 평면 중 제1 표면 평면 및 제2 표면 평면을 결정하도록 - 상기 제1 공간은 상기 제1 표면 평면과 연관되고, 상기 제2 공간은 상기 제2 표면 평면과 연관됨 -; 그리고상기 제2 표면 평면의 관점에 기초하여 상기 제2 관점을 결정하도록 추가로 구성되는, 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하기 위해, 상기 하나 이상의 프로세서들은,상기 가상 콘텐츠 아이템과 상기 제2 표면 평면의 중첩을 결정하도록; 그리고상기 중첩이 제1 임계치를 초과한다는 결정 시에, 상기 제2 표면 평면과 연관된 상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하는 것으로 스위칭하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 제1 공간 및 상기 제2 공간은 상기 적어도 하나의 표면 평면 중 제1 표면 평면과 연관되고;상기 하나 이상의 프로세서들은, 하나 이상의 객체들을 검출하도록 - 상기 하나 이상의 객체들은 상기 제1 표면 평면의 적어도 일부를 폐색함 -; 그리고 적어도 상기 제1 표면 평면의 폐색된 부분에 기초하여 상기 제1 표면 평면을 적어도 제1 세그먼트 및 제2 세그먼트로 세그먼트화하도록 추가로 구성되며;상기 제1 공간은 상기 제1 세그먼트와 연관되고, 상기 제2 공간은 상기 제2 세그먼트와 연관되는, 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 제1 표면 평면을 적어도 상기 제1 세그먼트 및 상기 제2 세그먼트로 세그먼트화하기 위해, 상기 하나 이상의 프로세서들은 상기 제1 세그먼트 및 상기 제2 세그먼트에서 상기 제1 표면 평면의 관점으로 렌더링된 상기 가상 콘텐츠 아이템의 피팅을 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 하나 이상의 프로세서들은 상기 제1 세그먼트와 상기 제2 세그먼트 사이에서 상기 가상 콘텐츠 아이템의 종횡비를 변경하도록 추가로 구성되는, 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 하나 이상의 프로세서들은,상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하기 전에, 상기 콘텐츠 배치 표시자에 기초하여 상기 장면 내의 제3 위치에 제3 관점으로 상기 가상 콘텐츠 아이템을 렌더링하도록 구성되고, 상기 제3 위치는 상기 제1 공간 내에 있는, 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 하나 이상의 프로세서들은,상기 사용자 입력에 응답하여, 상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하기 전에 상기 제1 공간 내에서 상기 콘텐츠 배치 표시자를 이동시키도록 추가로 구성되는, 장치.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 장면 내의 상기 적어도 하나의 표면 평면을 결정하기 위해, 상기 하나 이상의 프로세서들은,상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 표면들을 결정하도록; 그리고상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 표면들에 기초하여 상기 적어도 하나의 표면 평면을 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 장면 내의 상기 적어도 하나의 표면 평면을 결정하기 위해, 상기 하나 이상의 프로세서들은,적어도 하나의 표면에 수직으로 그리고 상기 장치와 연관된 사용자의 시점을 향해 상기 적어도 하나의 표면 평면에 오프셋을 적용하도록 추가로 구성되는, 장치.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 장면 내의 상기 적어도 하나의 표면 평면을 결정하기 위해, 상기 하나 이상의 프로세서들은,상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 에지들을 결정하도록; 그리고상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 에지들에 기초하여 상기 적어도 하나의 표면 평면을 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 콘텐츠 배치 표시자를 렌더링하기 위해, 상기 하나 이상의 프로세서들은 상기 적어도 하나의 표면 평면 상에 패턴을 렌더링하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 패턴은, 하이라이트(highlight), 윤곽, 색상, 셰이드(shade), 그림자, 해칭(hatching), 및 그래디언트(gradient) 중 적어도 하나를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서, 상기 장치는 모바일 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 모바일 디바이스는 확장 현실 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>18. 물리적 환경의 장면 내에 가상 콘텐츠를 렌더링하기 위한 방법으로서,상기 물리적 환경의 장면 내의 적어도 하나의 표면 평면을 결정하는 단계;컴퓨팅 디바이스를 통해, 상기 장면 내의 제1 위치에 제1 관점으로 가상 콘텐츠 아이템을 렌더링하는 단계;상기 적어도 하나의 표면 평면의 제1 공간 상에 상기 가상 콘텐츠 아이템과 연관된 콘텐츠 배치 표시자를 렌더링하는 단계 - 상기 콘텐츠 배치 표시자는 상기 가상 콘텐츠 아이템의 배치를 위한 상기 제1 공간의 적어도 일부를 나타냄 -;상기 적어도 하나의 표면 평면과 연관된 표면 상의 하나 이상의 객체들의 하나 이상의 위치들을 결정하는 단계; 및사용자 입력에 응답하여, 상기 적어도 하나의 표면 평면의 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하는 단계 - 상기 적어도 하나의 표면 평면의 제2 공간은 상기 하나 이상의 위치들 및 상기 사용자 입력에 기초하여 결정되고, 상기 콘텐츠 배치 표시자는 상기 가상 콘텐츠 아이템의 배치를 위한 상기 제2 공간의 적어도 일부를 나타냄 - 를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 제2 공간 상에의 상기 가상 콘텐츠 아이템의 배치를 요청하는 추가 사용자 입력에 응답하여, 상기 콘텐츠 배치 표시자에 기초하여 상기 장면 내의 제2 위치에 제2 관점으로 상기 가상 콘텐츠 아이템을 렌더링하는 단계를 추가로 포함하고, 상기 제2 위치는 상기 제2 공간 내에 있는, 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 제2 공간의 관점에 기초하여 상기 제2 관점을 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제19항에 있어서,상기 적어도 하나의 표면 평면 중 제1 표면 평면 및 제2 표면 평면을 결정하는 단계 - 상기 제1 공간은 상기 제1 표면 평면과 연관되고, 상기 제2 공간은 상기 제2 표면 평면과 연관됨 -; 및상기 제2 표면 평면의 관점에 기초하여 상기 제2 관점을 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하는 단계는,상기 가상 콘텐츠 아이템과 상기 제2 표면 평면의 중첩을 결정하는 단계; 및상기 중첩이 제1 임계치를 초과한다는 결정 시에, 상기 제2 표면 평면과 연관된 상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하는 것으로 스위칭하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제18항에 있어서, 상기 제1 공간 및 상기 제2 공간은 상기 적어도 하나의 표면 평면 중 제1 표면 평면과 연관되고, 상기 방법은,하나 이상의 객체들을 검출하는 단계 - 상기 하나 이상의 객체들은 상기 제1 표면 평면의 적어도 일부를 폐색함 -; 및적어도 상기 제1 표면 평면의 폐색된 부분에 기초하여 상기 제1 표면 평면을 적어도 제1 세그먼트 및 제2 세그먼트로 세그먼트화하는 단계를 추가로 포함하며;상기 제1 공간은 상기 제1 세그먼트와 연관되고, 상기 제2 공간은 상기 제2 세그먼트와 연관되는, 방법.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 제1 표면 평면을 적어도 상기 제1 세그먼트 및 상기 제2 세그먼트로 세그먼트화하는 단계는 상기 제1 세그먼트 및 상기 제2 세그먼트에서 상기 제1 표면 평면의 관점으로 렌더링된 상기 가상 콘텐츠 아이템의 피팅을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 제1 세그먼트와 상기 제2 세그먼트 사이에서 상기 가상 콘텐츠 아이템의 종횡비를 변경하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 제18항에 있어서,상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하기 전에, 상기 콘텐츠 배치 표시자에 기초하여 상기 장면 내의 제3 위치에 제3 관점으로 상기 가상 콘텐츠 아이템을 렌더링하는 단계를 추가로 포함하고, 상기 제3 위치는 상기 제1 공간 내에 있는, 방법.</claim></claimInfo><claimInfo><claim>27. 제18항에 있어서,상기 사용자 입력에 응답하여, 상기 제2 공간 상에 상기 콘텐츠 배치 표시자를 렌더링하기 전에 상기 제1 공간 내에서 상기 콘텐츠 배치 표시자를 이동시키는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제18항에 있어서, 상기 장면 내의 상기 적어도 하나의 표면 평면을 결정하는 단계는,상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 표면들을 결정하는 단계; 및상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 표면들에 기초하여 상기 적어도 하나의 표면 평면을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 장면 내의 상기 적어도 하나의 표면 평면을 결정하는 단계는,적어도 하나의 표면에 수직으로 그리고 상기 컴퓨팅 디바이스와 연관된 사용자의 시점을 향해 상기 적어도 하나의 표면 평면에 오프셋을 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>30. 제18항에 있어서, 상기 장면 내의 상기 적어도 하나의 표면 평면을 결정하는 단계는,상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 에지들을 결정하는 단계; 및상기 장면 내의 상기 하나 이상의 객체들의 하나 이상의 에지들에 기초하여 상기 적어도 하나의 표면 평면을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>31. 제18항에 있어서, 상기 콘텐츠 배치 표시자를 렌더링하는 단계는 상기 적어도 하나의 표면 평면 상에 패턴을 렌더링하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>32. 제31항에 있어서, 상기 패턴은, 하이라이트, 윤곽, 색상, 셰이드, 그림자, 해칭, 및 그래디언트 중 적어도 하나를 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>WILLKIE, CHAD</engName><name>윌키 채드</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.09</priorityApplicationDate><priorityApplicationNumber>17/547,068</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.05.30</receiptDate><receiptNumber>1-1-2024-0590000-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.07.11</receiptDate><receiptNumber>1-5-2024-0113650-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.01</receiptDate><receiptNumber>1-1-2025-1123320-92</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.10.01</receiptDate><receiptNumber>1-1-2025-1123321-37</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247018302.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931d0b7398012ebfb1b05c9f0715356c8ff054783165fad36abd8d3fb8c3f3cb9c958b1ae77057fe068c1d033a640e769db9e7955e2cea8be1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf7fc546e9f1a3a07ebf0fbe457db5d46bda1b16aea2b9dfb3fdce34507ccfd07e5ca11861b696783d8c713ffb83be378b3ef98a73172a7fbf</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>