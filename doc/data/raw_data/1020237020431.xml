<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:39.4039</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7020431</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오 행동 인식을 위한 시간적 병목 어텐션 아키텍처</inventionTitle><inventionTitleEng>A TEMPORAL BOTTLENECK ATTENTION ARCHITECTURE FOR VIDEO ACTION RECOGNITION</inventionTitleEng><openDate>2023.07.10</openDate><openNumber>10-2023-0104738</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.22</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.06.16</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/21</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 분석을 위해 비디오 클립을 수신하고 - 비디오 클립은 비디오 프레임들의 시간 시퀀스를 포함함-, 키-프레임들의 감소된 시퀀스를 생성하기 위해 클립 내의 프레임들에 병목 어텐션 메커니즘을 적용하고, 각각의 키프레임에 대한 3D 임베딩 텐서를 획득하기 위해 키프레임들의 시퀀스에 2차원(2D) 컨볼루션 신경망을 적용하고, 최종 행동 컨텍스트를 생성하기 위해 3D 임베딩 텐서들에 다중 헤딩 어텐션 메커니즘을 적용하고, 행동 클래스에 의해 특정된 행동이 비디오 클립에서 발생했을 가능성을 나타내는 각각의 행동 클래스에 대한 확률을 획득하기 위해 분류 메커니즘을 최종 행동 컨텍스트에 적용함으로써 비디오 클립 내에서 수행되는 행동들을 분류한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.05.19</internationOpenDate><internationOpenNumber>WO2022104202</internationOpenNumber><internationalApplicationDate>2021.11.15</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/059372</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 클립(video clip) 내에서 수행되는 행동(action)들을 분류하기 위한 컴퓨터 구현 방법으로서, 분석을 위한 비디오 클립을 수신하는 단계 - 상기 비디오 클립은 비디오 프레임들의 시간 시퀀스를 포함함 -;감소된 키-프레임들의 시퀀스를 생성하기 위해 상기 클립내 상기 프레임들에 병목 어텐션 메커니즘(bottleneck attention mechanism)을 적용하는 단계;각각의 키프레임에 대한 3D 임베딩 텐서(embedding tensor)를 획득하기 위해 상기 키-프레임들의 시퀀스에 2차원(2D) 컨볼루션 신경망(convolutional neural network)을 적용하는 단계;최종 행동 컨텍스트(final action context)를 생성하기 위해 상기 3D 임베딩 텐서들에 다중 헤딩 어텐션 메커니즘(multi-headed attention mechanism)을 적용하는 단계; 및행동 클래스(action class)에 의해 지정된 행동이 상기 비디오 클립에서 발생했을 가능성을 나타내는 각각의 상기 행동 클래스에 대한 확률을 획득하기 위해 분류 메커니즘을 상기 최종 행동 컨텍스트에 적용하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 각각의 키-프레임은 상기 비디오 클립내의 시간적으로 인접한 프레임들의 상이한 서브세트를 나타내는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 병목 어텐션 메커니즘은 34개의 비디오 프레임들의 비디오 클립으로부터 16개의 키프레임들 또는 11개의 키프레임들을 생성하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 다중 헤딩 어텐션 메커니즘은,풀링 셀프-어텐션 절차(pooling self-attention procedure)를 적용하는 단계;잔차 셀프-어텐션 절차(residual self-attention procedure)를 적용하는 단계; 및상기 최종 행동 컨텍스트를 획득하기 위해 상기 풀링 셀프-어텐션 및 상기 잔차 셀프-어텐션 절차들의 결과들을 병합하는 단계(concatenating)를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 풀링 셀프-어텐션 절차는,3D 평균 풀링에 기초하여 클립내 각각의 키프레임에 대한 어텐션 가중치(attention weight)들을 계산하는 단계;평균 프레임 주위에 상기 어텐션 가중치들을 집중화하는 단계(centralizing);정규화된 어텐션 벡터를 생성하기 위해 상기 집중화된 어텐션 가중치들을 정규화하는 단계; 및상기 클립 내의 프레임들 간의 차이를 증강시키기 위해 상기 정규화된 어텐션 가중치와 개개의 키프레임을 곱하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서, 상기 병목 어텐션 메커니즘은,상기 비디오 프레임들의 각각에 대한 시간적 어텐션 가중치들을 계산하는 단계; 및키-프레임들을 계산하는 단계를 포함하되, 각각의 키-프레임은 시간적으로 인접한 프레임들의 서브세트의 가중된 평균이고, 상기 가중치들은 상기 계산된 시간적 어텐션 가중치들인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 시간적 어텐션 가중치들은 상기 풀링 셀프-어텐션 절차에 의해 생성되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서, 상기 잔차 셀프-어텐션 절차는,상기 임베딩 텐서 출력들을 2차원에서 1X1 커널과 컨벌루션하는 단계(convolving);2D 평균 풀링에 기초하여 각각의 컨볼루션된 텐서에 대한 어텐션 가중치들을 계산하는 단계;정규화된 어텐션 벡터를 생성하기 위해 상기 어텐션 가중치들에 소프트맥스(softmax)를 적용하는 단계; 및상기 잔차 행동 컨텍스트를 획득하기 위해 상기 가중치들에 상기 임베딩 텐서를 곱하고 상기 결과를 스케일링하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제4항에 있어서, 상기 시간적 어텐션 가중치들은 상기 잔차 셀프-어텐션 절차(residual self-attention procedure)에 의해 생성되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 비디오에서 발생한 가장 가능성 있는 행동을 예측하기 위해 상기 행동 컨텍스트 확률에서 가장 높은 확률을 선택하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 서버 컴퓨터에 있어서,프로세서;상기 프로세서와 통신하는 통신 인터페이스; 비디오 클립들을 저장하기 위한 데이터 저장소; 및명령어들을 저장하기 위해 상기 프로세서와 통신하는 메모리를 포함하되, 상기 명령어들이 상기 프로세서에 의해 실행될 때, 상기 서버가, 분석을 위한 비디오 클립을 수신하고 - 상기 비디오 클립은 비디오 프레임들의 시간 시퀀스를 포함함 -; 감소된 키-프레임들의 시퀀스를 생성하기 위해 상기 클립내 상기 프레임들에 병목 어텐션 메커니즘을 적용하고; 각각의 키프레임에 대한 3D 임베딩 텐서를 획득하기 위해 상기 키-프레임들의 시퀀스에 2차원(2D) 컨볼루션 신경망을 적용하고; 최종 행동 컨텍스트를 생성하기 위해 상기 3D 임베딩 텐서들에 다중 헤딩 어텐션 메커니즘을 적용하고; 및 행동 클래스에 의해 지정된 행동이 비디오 클립에서 발생했을 가능성을 나타내는 각각의 상기 행동 클래스에 대한 확률을 획득하기 위해 분류 메커니즘을 상기 최종 행동 컨텍스트에 적용하게 하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 각각의 키-프레임은 상기 비디오 클립내의 시간적으로 인접한 프레임들의 상이한 서브세트를 나타내는, 서버 컴퓨터. </claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 병목 어텐션 메커니즘은 34개의 비디오 프레임들의 비디오 클립으로부터 16개의 키프레임들 또는 11개의 키프레임들을 생성하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 다중 헤딩 어텐션 메커니즘은,풀링 셀프-어텐션 절차를 적용하는 단계;잔차 셀프-어텐션 절차를 적용하는 단계; 및최종 행동 컨텍스트를 획득하기 위해 상기 풀링 셀프-어텐션 및 상기 잔차 셀프-어텐션 절차들의 결과들을 병합하는 단계를 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 풀링 셀프-어텐션 절차는,3D 평균 풀링에 기초하여 클립의 각 키프레임에 대한 어텐션 가중치들을 계산하는 단계;평균 프레임 주위에 상기 어텐션 가중치들을 집중화하는 단계;정규화된 어텐션 벡터를 생성하기 위해 집중화된 어텐션 가중치들을 정규화하는 단계; 및상기 클립 내의 프레임들 간의 차이를 증강시키기 위해 상기 정규화된 어텐션 가중치와 개개의 키프레임을 곱하는 단계를 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서, 상기 병목 어텐션 메커니즘은,상기 비디오 프레임들의 각각에 대한 시간적 어텐션 가중치들을 계산하는 단계; 및키-프레임들을 계산하는 단계를 포함하되, 각각의 키-프레임은 시간적으로 인접한 프레임들의 서브세트의 가중된 평균이고, 상기 가중치들은 상기 계산된 시간적 어텐션 가중치들인, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 시간적 어텐션 가중치들은 상기 풀링 셀프-어텐션 절차에 의해 생성되는, 서버 컴퓨터. </claim></claimInfo><claimInfo><claim>18. 제14항에 있어서, 상기 잔차 셀프-어텐션 절차는,임베딩 텐서 출력들을 2차원에서 1X1 커널과 컨벌루션하는 단계;2D 평균 풀링에 기초하여 각각의 컨볼루션된 텐서에 대한 어텐션 가중치들을 계산하는 단계;정규화된 어텐션 벡터를 생성하기 위해 상기 어텐션 가중치들에 소프트맥스(softmax)를 적용하는 단계; 및상기 잔차 행동 컨텍스트를 획득하기 위해 상기 가중치들에 임베딩 텐서를 곱하고 상기 결과를 스케일링하는 단계를 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>19. 제14항에 있어서, 상기 시간적 어텐션 가중치들은 상기 잔차 셀프-어텐션 절차에 의해 생성되는, 서버 컴퓨터. </claim></claimInfo><claimInfo><claim>20. 제11항에 있어서, 상기 비디오에서 발생한 가장 가능성 있는 행동을 예측하기 위해 상기 행동 컨텍스트 확률에서 가장 높은 확률을 선택하는 것을 더 포함하는, 서버 컴퓨터. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 *****, 셔먼 옥스, 스위트 ****, 벤 추라 불러버드 *****</address><code>520230330757</code><country>미국</country><engName>BEN GROUP, INC.</engName><name>벤 그룹, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 *****, 셔먼...</address><code> </code><country> </country><engName>CARVALHO, Schubert R.</engName><name>카발로, 슈버트 알.</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****, 셔먼...</address><code> </code><country> </country><engName>BERTAGNOLLI, Nicolas M.</engName><name>버탁놀리, 니콜라스 엠.</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****, 셔먼...</address><code> </code><country> </country><engName>FOLKMAN, Tyler</engName><name>포크만, 타일러</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****, 셔먼...</address><code> </code><country> </country><engName>BUTLER, Richard Ray</engName><name>버틀러, 리처드 레이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 **길 **-*(역삼동, AIP빌딩)</address><code>920091000214</code><country>대한민국</country><engName>AIP Patent &amp; Law Firm</engName><name>특허법인에이아이피</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.11.16</priorityApplicationDate><priorityApplicationNumber>63/114,344</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.06.17</priorityApplicationDate><priorityApplicationNumber>17/350,283</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.06.16</receiptDate><receiptNumber>1-1-2023-0663852-87</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.06.20</receiptDate><receiptNumber>1-5-2023-0097616-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.10.22</receiptDate><receiptNumber>1-1-2024-1148690-54</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237020431.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c026f56c50df1eba6cdc4eabd854f4e019b7feda02cc0925b99f65faa7acfe7b5fbd3afcc0e00b468626877407615a5dbb5ccfcb3d14a854</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cffa2bdca3ffd61b84691144f35a236daa2265b6f8af45a4b8e69071653d7022835cbe31e76512da3841e71fa136f3c31be835f44d055ef4f3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>