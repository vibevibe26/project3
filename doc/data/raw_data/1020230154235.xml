<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:25:43.2543</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0154235</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>디스플레이 장치, 웨어러블 전자 장치, 및 전자 장치의 동작 방법</inventionTitle><inventionTitleEng>A DISPLAY DEVICE, WEARABLE ELECTRONIC DEVICE, AND  OPERATING METHOD OF ELECTRONIC DEVICE</inventionTitleEng><openDate>2025.05.16</openDate><openNumber>10-2025-0068128</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 1/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 기술적 사상에 따른 디스플레이 장치는, 디스플레이 패널이 출력하는 확장 현실(extended reality:XR) 이미지에 반응하는 대상 사용자의 적어도 하나의 신체 부위에 대한 움직임 정보를 획득하는 센싱부, 움직임 정보에 기초하여 대상 사용자의 움직임을 확장 현실 이미지로 생성하고, 대상 사용자의 움직임 정보 및 다른 사용자의 움직임 정보에 기초하여 다른 사용자에 대한 정서적 공감도 및 신체적 공감도를 계산하고, 정서적 공감도 및 신체적 공감도에 기초하여 다른 사용자에 대한 대상 사용자의 최종 공감도를 생성하는 프로세서를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1.  디스플레이 패널이 출력하는 확장 현실(extended reality:XR) 이미지에 반응하는 대상 사용자의 적어도 하나의 신체 부위에 대한 움직임 정보를 획득하는 센싱부;상기 움직임 정보에 기초하여 상기 대상 사용자의 움직임을 상기 확장 현실 이미지로 생성하고,상기 대상 사용자의 움직임 정보 및 다른 사용자의 움직임 정보에 기초하여 상기 다른 사용자에 대한 정서적 공감도 및 신체적 공감도를 계산하고, 상기 정서적 공감도 및 신체적 공감도에 기초하여 상기 다른 사용자에 대한 상기 대상 사용자의 최종 공감도를 생성하는 프로세서;를 포함하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>2.  제1 항에 있어서,상기 프로세서는,상기 대상 사용자 및 상기 다른 사용자 각각의 움직임 정보로부터 상기 대상 사용자 및 상기 다른 사용자 각각의 시선 정보를 획득하고, 상기 시선 정보를 이용하여 상기 대상 사용자와 상기 다른 사용자 간의 시선 일치도를 생성하고,상기 대상 사용자 및 상기 다른 사용자 각각의 움직임 정보로부터 상기 대상 사용자 및 상기 다른 사용자 각각의 얼굴 정보를 획득하고, 상기 얼굴 정보를 이용하여 상기 대상 사용자와 상기 다른 사용자 간의 표정 유사도를 생성하고,상기 시선 일치도 및 상기 표정 유사도 중 적어도 하나에 기초하여 상기 정서적 공감도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>3.  제2 항에 있어서,상기 시선 정보는,시선 방향 정보, 동공 정보, 및 눈의 움직임 정보 중 적어도 하나를 포함하고,상기 프로세서는,상기 대상 사용자 및 상기 다른 사용자 사이의 시선 방향의 유사도, 상기 대상 사용자 및 상기 다른 사용자 사이의 동공 크기의 차이, 및 상기 대상 사용자 및 상기 다른 사용자 사이의 눈의 움직임 속도의 차이 중 적어도 하나에 기초하여 상기 시선 일치도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>4.  제3 항에 있어서,상기 시선 일치도는,상기 시선 방향의 유사도가 높을수록, 상기 동공 크기의 차이 및 상기 눈의 움직임 속도의 차이가 작을수록 높아지는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>5.  제2 항에 있어서,상기 얼굴 정보는,얼굴의 복수의 부분들 중 적어도 하나의 부분에 대응하는 얼굴 근육의 움직임 정보를 포함하고,상기 프로세서는,상기 얼굴 근육의 움직임 정보에 기초하여 상기 표정 유사도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>6.  제1 항에 있어서,상기 프로세서는,상기 대상 사용자 및 상기 다른 사용자 각각의 움직임 정보로부터 상기 대상 사용자 및 상기 다른 사용자 사이의 위치 정보를 획득하고,상기 위치 정보에 기초하여 상기 대상 사용자와 상기 다른 사용자 사이의 신체 근접도 및 동작 유사도를 생성하고,상기 신체 근접도 및 상기 동작 유사도 중 적어도 하나에 기초하여 상기 신체적 공감도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>7.  제6 항에 있어서,상기 위치 정보는,상기 대상 사용자의 머리 위치 정보 및 상기 사용자의 손목 위치 정보를 포함하고,상기 프로세서는,상기 대상 사용자의 머리 위치와 상기 다른 사용자의 머리 위치 사이의 거리 및 상기 대상 사용자의 손목 위치와 상기 다른 사용자의 손목 위치 사이의 거리 중 적어도 하나에 기초하여 상기 신체 근접도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>8.  제7 항에 있어서,상기 신체 근접도는,상기 대상 사용자의 머리 위치와 상기 다른 사용자의 머리 위치 사이의 거리 및 상기 대상 사용자의 손목 위치와 상기 다른 사용자의 손목 위치 사이의 거리가 가까울수록 높아지는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>9.  제6 항에 있어서,상기 위치 정보는,상기 사용자의 머리 위치 정보 및 상기 사용자의 손목 위치 정보를 포함하고,상기 프로세서는,상기 대상 사용자의 머리 위치와 양 손목의 위치에 대한 제1 중심 위치 및 상기 다른 사용자의 머리 위치와 양 손목의 위치에 대한 제2 중심 위치의 차이에 기초하여 상기 동작 유사도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>10.  제6 항에 있어서,상기 위치 정보는,상기 사용자의 손 위치 정보를 포함하고,상기 프로세서는,상기 대상 사용자 및 상기 다른 사용자의 양 손가락의 위치 차이와 손가락 관절의 각도 차이 중 적어도 하나에 기초하여 상기 동작 유사도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>11.  제1 항에 있어서,상기 디스플레이 장치는,상기 훈련 움직임 정보로부터 획득되는 상기 최종 공감도를 생성하기 위해 사용되는, 시선 정보, 얼굴 정보, 및 위치 정보를 포함하는 샘플 특징 정보 및 상기 대상 사용자가 응답한 상기 다른 사용자에 대한 샘플 공감도에 기초하여 트레이닝되는 뉴럴 네트워크(Neural Network) 모델을 포함하고,상기 프로세서는,상기 뉴럴 네트워크 모델의 가중치에 기초하여 상기 최종 공감도를 생성하는 것을 특징으로 하는, 디스플레이 장치. </claim></claimInfo><claimInfo><claim>12.  적어도 하나의 인스트럭션을 저장하는 메모리; 및적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는 상기 적어도 하나의 인스트럭션을 실행하여,확장 현실(extended reality:XR) 이미지에 반응하는 제1 사용자의 적어도하나의 신체 부위에 대한 제1 움직임 정보 및 상기 확장 현실 이미지에 반응하는 제2 사용자의 적어도 하나의 신체 부위에 대한 제2 움직임 정보를 수신하고,상기 제1 움직임 정보로부터 상기 제1 사용자의 시선 정보, 얼굴 정보, 및 위치 정보를 포함하는 제1 특징 정보를 획득하고, 상기 제2 움직임 정보로부터 상기 제2 사용자의 시선 정보, 얼굴 정보, 및 위치 정보를 포함하는 제2 특징 정보를 획득하고,뉴럴 네트워크(Neural Network) 모델을 이용하여 특징 정보들에 대한 가중치를 획득하고,상기 제1 특징 정보, 상기 제2 특징 정보, 및 상기 가중치에 기초하여 상기 제2 사용자에 대한 상기 제1 사용자의 최종 공감도를 생성하는, 전자 장치. </claim></claimInfo><claimInfo><claim>13.  제12 항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 사용자의 상기 시선 정보 및 상기 제2 사용자의 상기 시선 정보에 기초하여 상기 제1 사용자 및 상기 제2 사용자 사이의 시선 일치도를 생성하고,상기 제1 사용자의 상기 얼굴 정보 및 상기 제2 사용자의 상기 얼굴 정보에 기초하여 상기 제1 사용자 및 상기 제2 사용자 사이의 표정 유사도를 생성하고,상기 시선 일치도 및 상기 표정 유사도 중 적어도 하나에 기초하여 상기 최종 공감도를 생성하는 것을 특징으로 하는, 전자 장치. </claim></claimInfo><claimInfo><claim>14.  제13 항에 있어서,상기 시선 정보는,시선 방향 정보, 동공 정보, 및 눈의 움직임 정보 중 적어도 하나를 포함하고,상기 적어도 하나의 프로세서는,상기 제1 사용자 및 상기 제2 사용자 사이의 시선 방향의 유사도, 상기 제1 사용자 및 상기 제2 사용자 사이의 동공 크기의 차이, 및 상기 제1 사용자 및 상기 제2 사용자 사이의 눈의 움직임 속도의 차이 중 적어도 하나에 기초하여 상기 시선 일치도를 생성하는 것을 특징으로 하는, 전자 장치. </claim></claimInfo><claimInfo><claim>15.  제13 항에 있어서,상기 얼굴 정보는,얼굴의 복수의 부분들 중 적어도 하나의 부분에 대응하는 얼굴 근육의 움직임 정보를 포함하고,상기 적어도 하나의 프로세서는,상기 얼굴 근육의 움직임 정보에 기초하여 상기 표정 유사도를 생성하는 것을 특징으로 하는, 전자 장치. </claim></claimInfo><claimInfo><claim>16.  제12 항에 있어서,상기 적어도 하나의 프로세서는,상기 제1 사용자 및 상기 제2 사용자 각각의 움직임 정보로부터 상기 제1사용자 및 상기 제2 사용자 사이의 위치 정보를 획득하고,상기 위치 정보에 기초하여 상기 제1 사용자와 상기 제2 사용자 사이의 신체 근접도 및 동작 유사도를 생성하고,상기 신체 근접도 및 상기 동작 유사도 중 적어도 하나에 기초하여 상기 최종 공감도를 생성하는 것을 특징으로 하는, 전자 장치. </claim></claimInfo><claimInfo><claim>17.  제16 항에 있어서,상기 위치 정보는,상기 사용자의 머리 위치 정보 및 상기 사용자의 손목 위치 정보를 포함하고,상기 적어도 하나의 프로세서는,상기 제1 사용자의 머리 위치와 상기 제2 사용자의 머리 위치 사이의 거리 및 상기 제1 사용자의 손목 위치와 상기 제2 사용자의 손목 위치 사이의 거리 중 적어도 하나에 기초하여 상기 신체 근접도를 생성하는 것을 특징으로 하는, 전자 장치. </claim></claimInfo><claimInfo><claim>18.  제16 항에 있어서,상기 위치 정보는,상기 사용자의 머리 위치 정보, 상기 사용자의 손목 위치 정보, 및 손 위치 정보를 포함하고,상기 적어도 하나의 프로세서는,상기 제1 사용자의 머리 위치와 양 손목의 위치에 대한 제1 중심 위치 및 상기 제2 사용자의 머리 위치와 양 손목의 위치에 대한 제2 중심 위치의 차이 및 상기 제1 사용자와 상기 제2 사용자의 손가락 관절의 각도 차이 중 적어도 하나에 기초하여 상기 동작 유사도를 생성하는 것을 특징으로 하는, 전자 장치. </claim></claimInfo><claimInfo><claim>19.  웨어러블 전자 장치에 있어서,사용자에게 확장 현실(extended reality:XR) 이미지를 출력하는 디스플레이 패널;상기 확장 현실 이미지에 반응하는 제1 사용자의 적어도 하나의 신체 부위에 대한 제1 움직임 정보를 획득하는 센싱부;상기 확장 현실 이미지에 반응하는 제2 사용자의 적어도 하나의 신체 부위에 대한 제2 움직임 정보를 수신하는 통신부; 및상기 제1 움직임 정보 및 상기 제2 움직임 정보에 기초하여 상기 제1 사용자의 상기 제2 사용자에 대한 정서적 공감도 및 신체적 공감도를 계산하고, 상기 정서적 공감도 및 신체적 공감도에 기초하여 상기 제2 사용자에 대한 상기 제1 사용자의 최종 공감도를 생성하는 프로세서;를 포함하는, 웨어러블 전자 장치. </claim></claimInfo><claimInfo><claim>20.  확장 현실(extended reality:XR) 이미지에 반응하는 제1 사용자의 적어도하나의 신체 부위에 대한 제1 움직임 정보 및 상기 확장 현실 이미지에 반응하는 제2 사용자의 적어도 하나의 신체 부위에 대한 제2 움직임 정보를 획득하는 단계;상기 제1 움직임 정보로부터 상기 제1 사용자의 시선 정보, 얼굴 정보, 및 위치 정보를 포함하는 제1 특징 정보를 획득하고, 상기 제2 움직임 정보로부터 상기 제2 사용자의 시선 정보, 얼굴 정보, 및 위치 정보를 포함하는 제2 특징 정보를 획득하는 단계;뉴럴 네트워크(Neural Network) 모델을 이용하여 특징 정보들에 대한 가중치를 획득하는 단계; 및상기 제1 특징 정보, 상기 제2 특징 정보, 및 상기 가중치에 기초하여 상기 제2 사용자에 대한 상기 제1 사용자의 최종 공감도를 생성하는 단계;를 포함하는, 전자 장치의 동작 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980077638</code><country>대한민국</country><engName>Electronics and Telecommunications Research Institute</engName><name>한국전자통신연구원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>LEE, Yong Ho</engName><name>이용호</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>GIL, Youn Hee</engName><name>길연희</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>BAEK, Seong Min</engName><name>백성민</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>SHIN, Hee Sook</engName><name>신희숙</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>YU, Cho Rong</engName><name>유초롱</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>HONG, Sung Jin</engName><name>홍성진</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로**길**, **층, **층(코아렌빌딩)</address><code>920161001214</code><country>대한민국</country><engName>ISIS IP Law LLC</engName><name>특허법인(유한)아이시스</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.09</receiptDate><receiptNumber>1-1-2023-1238935-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.12.05</receiptDate><receiptNumber>1-1-2023-1362326-80</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.06.13</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2025.08.12</receiptDate><receiptNumber>9-6-2025-0174892-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>접수중 (On receiving) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.11.07</receiptDate><receiptNumber>1-1-2025-1243094-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Reason for Return of Document</documentEngName><documentName>서류반려이유통지서</documentName><receiptDate>2025.11.12</receiptDate><receiptNumber>1-5-2025-0193534-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>접수중 (On receiving) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2025.11.13</receiptDate><receiptNumber>1-1-2025-1271375-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230154235.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936ce5295df05c78c12e215e7c53c5e08fb88b0f75607fe50fdd86e5825a6a5f339cf374bb20a4c8c559d5e326d8d2d20c423986d89ae26b6b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9df4b14edc179f05bdae282c4a4c8d57072b2ebb5c78c0164e964eac74ff87fea68d765344220504a5d13d889bfbf7071bcdc1bd576b7e11</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>