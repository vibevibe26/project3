<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:16.3316</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7016576</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>거울 기반 증강 현실 경험</inventionTitle><inventionTitleEng>MIRROR-BASED AUGMENTED REALITY EXPERIENCE</inventionTitleEng><openDate>2024.06.21</openDate><openNumber>10-2024-0090542</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.05.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.05.20</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/03</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 적어도 하나의 프로그램을 저장한 컴퓨터 판독가능 저장 매체를 포함하는 시스템, 및 동작들을 수행하기 위한 방법을 수반하며, 동작들은: 사람을 묘사하는 비디오를 수신하는 것을 포함한다. 동작들은 사람의 골격 관절 세트를 식별하는 것을 추가로 포함한다. 동작들은 골격 관절 세트의 포지셔닝에 기초하여 비디오에 묘사된 사람의 포즈를 식별하는 것(또는 손 포즈를 검출하는 것, 거울 프레임을 검출하는 것, 또는 모바일 디바이스를 검출하는 것)을 추가로 포함한다. 동작들은 사람의 포즈(또는 손 포즈 검출, 거울 프레임 검출, 또는 모바일 디바이스 검출)에 기초하여, 비디오가 사람의 거울 반사를 포함한다고 결정하는 것을 추가로 포함한다. 동작들은, 비디오가 사람의 거울 반사를 포함한다고 결정하는 것에 응답하여, 비디오에서 3D 가상 객체의 디스플레이를 야기하는 것을 추가로 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.04.27</internationOpenDate><internationOpenNumber>WO2023070021</internationOpenNumber><internationalApplicationDate>2022.10.20</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/078413</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 사람을 묘사하는 비디오를 수신하는 단계;상기 사람의 골격 관절 세트(set of skeletal joints)를 식별하는 단계;상기 골격 관절 세트의 포지셔닝(positioning)에 기초하여 상기 비디오에 묘사된 상기 사람의 포즈를 식별하는 단계;상기 사람의 포즈에 기초하여, 상기 비디오가 상기 사람의 거울 반사(mirror reflection)를 포함한다고 결정하는 단계; 및상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것에 응답하여, 상기 비디오에서 3D 가상 객체의 디스플레이를 야기하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 포즈에 기초하여, 상기 사람이 거울 앞에 서 있는 동안 상기 비디오를 캡처하고 있다고 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 사람이 상기 거울 앞에 서 있는 동안 상기 비디오를 캡처하고 있다고 결정하는 단계는:거울 앞에서 포즈를 취하고 있는 목표 사용자를 표현하는 목표 포즈를 획득하는 단계;상기 비디오에 묘사된 상기 사람의 포즈를 상기 목표 포즈와 비교하는 단계; 및상기 사람의 포즈가 상기 목표 포즈에 대응한다고 결정하는 것에 응답하여, 상기 사람이 상기 거울 앞에 서 있는 동안 상기 비디오를 캡처하고 있다고 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 사람을 묘사하는 비디오에 신경망을 적용하여 상기 비디오가 상기 거울 반사를 포함한다고 결정하는 단계를 추가로 포함하고, 상기 신경망은 사용자들을 묘사하는 복수의 트레이닝 비디오들과 실측 정보 거울 반사 분류(ground-truth mirror reflection classification) 사이의 관계를 확립하도록 트레이닝되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 복수의 트레이닝 비디오들을 포함하는 트레이닝 데이터 세트를 획득하는 단계;상기 복수의 트레이닝 비디오들 중의 제1 트레이닝 비디오에 상기 신경망을 적용하여 상기 제1 트레이닝 비디오가 사용자의 거울 반사를 포함한다는 분류를 추정하는 단계;상기 추정된 분류를 상기 제1 트레이닝 비디오와 연관된 상기 실측 정보 거울 반사 분류와 비교하는 단계; 및상기 추정된 분류를 상기 실측 정보 거울 반사 분류와 비교한 결과에 기초하여 상기 신경망의 하나 이상의 파라미터를 업데이트하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,클라이언트 디바이스의 후면 카메라가 상기 비디오를 캡처하는 데 사용되고 있다고 결정하는 단계를 추가로 포함하고, 상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것은 상기 후면 카메라가 상기 비디오를 캡처하는 데 사용되고 있다고 결정하는 것에 기초하여 추가로 수행되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 비디오에 묘사된 상기 사람의 손을 식별하는 단계; 및상기 비디오에 묘사된 상기 사람의 손의 포지션을 결정하는 단계를 추가로 포함하고, 상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것은 상기 비디오에 묘사된 상기 사람의 손의 포지션을 결정하는 것에 기초하여 추가로 수행되는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 손의 포즈가 상기 비디오에 묘사된 상기 사람의 신체 앞에서 올려진 손을 묘사하는 목표 포즈에 대응한다고 결정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제7항 또는 제8항에 있어서,상기 비디오에 묘사된 상기 사람의 손이 모바일 디바이스를 잡고 있다고 결정하는 단계를 추가로 포함하고, 상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것은 상기 비디오에 묘사된 상기 사람의 손이 상기 모바일 디바이스를 잡고 있다고 결정하는 것에 기초하여 추가로 수행되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제7항 내지 제9항 중 어느 한 항에 있어서, 상기 비디오에서 상기 3D 가상 객체의 디스플레이를 야기하는 단계는 상기 모바일 디바이스의 묘사를 상기 3D 가상 객체로 대체하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제7항 내지 제10항 중 어느 한 항에 있어서, 상기 3D 가상 객체는 토치 또는 메이크업 브러시를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서,상기 비디오에서 상기 거울의 프레임의 묘사를 검출하는 단계를 추가로 포함하고, 상기 비디오에서 상기 3D 가상 객체의 디스플레이를 야기하는 단계는 상기 비디오로부터 상기 프레임의 묘사를 제거하기 위해 상기 거울의 크기를 확대하는 단계를 포함하고, 상기 확대하는 단계는:상기 거울의 프레임의 임계 거리 내에 있는 상기 거울 내부의 픽셀들을 상기 거울의 프레임의 픽셀들과 블렌딩하는 단계; 및상기 거울의 프레임의 임계 거리 내에 있는 상기 거울 외부의 픽셀들을 상기 거울 내부의 픽셀들과 블렌딩하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 임계 거리는 상기 거울의 프레임의 가장자리와 상기 비디오의 프레임의 테두리 사이의 거리의 함수인, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 상기 비디오에서 상기 3D 가상 객체의 디스플레이를 야기하는 단계는, 상기 비디오에 묘사된 상기 사람의 하나 이상의 부분을 리터치하거나 밝게 하는 단계 또는 상기 비디오에 묘사된 배경을 제거하는 단계 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서,상기 사람의 3D 참조 포인트에 대한 상기 3D 가상 객체의 배치를 위한 3D 포지션을 계산하는 단계;상기 3D 포지션에서 상기 비디오 내에 상기 3D 가상 객체가 디스플레이되게 하는 단계; 및상기 사람의 3D 움직임에 기초하여 상기 3D 참조 포인트가 변경됨에 따라 상기 비디오 내의 상기 3D 가상 객체의 3D 포지션을 업데이트하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 3D 가상 객체는 상기 비디오에 묘사된 상기 사람과 함께 제시되는, 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서,상기 사람이 상기 비디오의 제1 프레임과 제2 프레임 사이에서 제1 3D 포지션으로부터 제2 3D 포지션으로 움직였다고 결정하는 단계;상기 제1 3D 포지션으로부터 상기 제2 3D 포지션으로의 상기 사람의 움직임의 거리 및 궤적을 계산하는 단계; 및상기 제1 3D 포지션으로부터 상기 제2 3D 포지션으로의 상기 사람의 움직임의 거리 및 궤적에 기초하여 상기 3D 가상 객체를 제3 3D 포지션으로부터 제4 3D 포지션으로 움직이게 하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제17항 중 어느 한 항에 있어서, 상기 비디오에서 상기 사람의 골격 관절 세트를 포지셔닝하는 것은 깊이 센서를 사용하지 않고 클라이언트 디바이스의 RGB 카메라에 의해 캡처된 이미지들을 사용하여 추적되는, 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서,동작들을 수행하도록 구성되는 하나 이상의 프로세서를 포함하고, 상기 동작들은:사람을 묘사하는 비디오를 수신하는 것;상기 사람의 골격 관절 세트를 식별하는 것;상기 골격 관절 세트의 포지셔닝에 기초하여 상기 비디오에 묘사된 상기 사람의 포즈를 식별하는 것;상기 사람의 포즈에 기초하여, 상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것; 및상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것에 응답하여, 상기 비디오에서 3D 가상 객체의 디스플레이를 야기하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함한 증강 현실 시스템을 포함하는 머신 판독가능 저장 매체로서, 상기 명령어들은, 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하며, 상기 동작들은:사람을 묘사하는 비디오를 수신하는 것;상기 사람의 골격 관절 세트를 식별하는 것;상기 골격 관절 세트의 포지셔닝에 기초하여 상기 비디오에 묘사된 상기 사람의 포즈를 식별하는 것;상기 사람의 포즈에 기초하여, 상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것; 및상기 비디오가 상기 사람의 거울 반사를 포함한다고 결정하는 것에 응답하여, 상기 비디오에서 3D 가상 객체의 디스플레이를 야기하는 것을 포함하는, 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>ZOHAR, Matan</engName><name>조하르, 마탄</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>ZHAO, Yanli</engName><name>자오, 얀리</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>FULKERSON, Brian</engName><name>풀커슨, 브라이언</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>BERGER, Itamar</engName><name>베르거, 이타마르</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.20</priorityApplicationDate><priorityApplicationNumber>17/506,442</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.05.20</receiptDate><receiptNumber>1-1-2024-0538441-61</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.05.20</receiptDate><receiptNumber>1-1-2024-0540784-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.05.24</receiptDate><receiptNumber>1-5-2024-0085715-66</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.04.10</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2025.05.27</receiptDate><receiptNumber>9-6-2025-0159572-58</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.08.25</receiptDate><receiptNumber>9-5-2025-0812924-43</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247016576.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930e3df87762206cf6e6e8ea84d1eab478507bc728e837f906a635c67ed0ae3a01b63c25d95982bae03cb68cac6f9b04ebde3c34eda2797175</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2aeac9f833dc818394264d432bd4f77dd3f0a07a04e20104323fe1a5d87b5d35a3a6799b793f2e8898f710eee4ef066a6f6ea06719d2709e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>