<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:54.1054</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.10.18</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2024-0142674</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자율 머신에서의 오작동 센서의 딥 러닝 기반의 실시간 검출 및 수정</inventionTitle><inventionTitleEng>DEEP LEARNING-BASED REAL-TIME DETECTION AND CORRECTION OF  COMPROMISED SENSORS IN AUTONOMOUS MACHINES</inventionTitleEng><openDate>2024.10.28</openDate><openNumber>10-2024-0155165</openNumber><originalApplicationDate>2018.10.25</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2018-0128300</originalApplicationNumber><originalExaminationRequestDate>2024.11.15</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/98</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 17/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020180128300</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 자율 머신에서 오작동 센서의 딥 러닝 기반의 실시간 검출 및 수정을 가능하게 하는 메커니즘이 설명된다. 본 명세서에 기술된 실시예의 장치는 하나 이상의 센서가 장면의 하나 이상의 이미지를 캡처하는 것을 가능하게 하는 검출 및 캡처 로직을 포함하며, 하나 이상의 이미지 중 하나의 이미지는 불명확하다고 판정되고, 하나 이상의 센서는 하나 이상의 카메라를 포함한다. 이 장치는 딥 러닝 모델(deep learning model)이 이미지와 연관된 센서를 실시간으로 식별하는 것을 가능하게 하는 분류 및 예측 로직을 더 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 장치로서, 메모리에 결합된 프로세서 회로를 포함하되, 상기 프로세서 회로는 하나 이상의 센서가 장면의 하나 이상의 이미지를 캡처하는 것을 가능하게 하고 - 상기 하나 이상의 이미지 중 하나의 이미지가 불명확하다고 판정되고, 상기 하나 이상의 센서는 하나 이상의 카메라를 포함함 - ,  딥 러닝 모델(deep learning model)이 상기 이미지와 연관된 센서를 실시간으로 식별하는 것을 가능하게 하는, 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 프로세서 회로는 또한, 상기 하나 이상의 이미지와 연관된 하나 이상의 데이터 입력을 수신하여, 상기 하나 이상의 데이터 입력을 상기 딥 러닝 모델에 의해 처리될 단일 데이터 입력으로 결합하는 것을 가능하게 하며, 상기 장치는, 자율 주행 자동차, 자율 비행 차량, 자율 항해 차량 및 자율 가정용 장치 중 하나 이상을 포함하는 자율 머신을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 프로세서 회로는 또한, 상기 딥 러닝 모델이 상기 단일 데이터 입력을 수신하여, 상기 불명확한 이미지와 연관된 센서를 실시간으로 식별하기 위한 트레이닝 과정 및 추론 과정을 포함하는 하나 이상의 딥 러닝 과정을 수행하는 것을 가능하게 하고, 상기 센서는 카메라를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 프로세서 회로는 또한, 상기 딥 러닝 모델로 하여금 복수의 데이터 입력을 수신하는 것과 상기 센서의 실시간 식별이 정확하고 시의적절하도록(timely) 상기 트레이닝 및 추론 과정을 통해 상기 복수의 데이터 입력을 실행하는 것을 가능하게 하는, 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 딥 러닝 모델은 하나 이상의 콘볼루션 신경망을 포함하는 하나 이상의 신경망을 포함하며, 상기 이미지는 상기 센서의 기술적인 결함 또는 상기 센서에 대한 물리적 장애물(obstruction) 중 하나 이상으로 인하여 불명확하고, 상기 물리적 장애물은 센서를 가리는 사람, 식물, 동물, 또는 물체, 혹은 센서의 렌즈의 일부분을 덮는 먼지, 얼룩, 진흙, 또는 이물질로 인한 것인, 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 프로세서 회로는 또한, 상기 불명확한 이미지의 실시간 통지 및 상기 센서의 실시간 자동 수정(auto-correction) 중 하나 이상을 제공하는, 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 프로세서 회로는, 공통 반도체 패키지 상에 애플리케이션 프로세서 회로와 함께 배치되는 그래픽 프로세서 회로를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>8. 방법으로서, 컴퓨팅 장치의 프로세서에 의해, 하나 이상의 센서가 장면의 하나 이상의 이미지를 캡처하는 것을 가능하게 하는 단계 - 상기 하나 이상의 이미지 중 하나의 이미지가 불명확하다고 판정되고, 상기 하나 이상의 센서는 컴퓨팅 장치의 하나 이상의 카메라를 포함함 - 와, 딥 러닝 모델이 상기 이미지와 연관된 센서를 실시간으로 식별하는 것을 가능하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 하나 이상의 이미지와 연관된 하나 이상의 데이터 입력을 수신하여, 상기 하나 이상의 데이터 입력을 상기 딥 러닝 모델에 의해 처리될 단일 데이터 입력으로 결합하는 단계를 더 포함하며, 상기 장치는, 자율 주행 자동차, 자율 비행 차량, 자율 항해 차량 및 자율 가정용 장치 중 하나 이상을 포함하는 자율 머신을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 딥 러닝 모델이 상기 단일 데이터 입력을 수신하여, 상기 불명확한 이미지와 연관된 센서를 실시간으로 식별하기 위한 트레이닝 과정 및 추론 과정을 포함하는 하나 이상의 딥 러닝 과정을 수행하는 것을 가능하게 하는 단계를 더 포함하며, 상기 센서는 카메라를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 딥 러닝 모델은 또한 복수의 데이터 입력을 수신하고, 상기 센서의 실시간 식별이 정확하고 시의적절하도록 상기 트레이닝 및 추론 과정을 통해 상기 복수의 데이터 입력을 실행하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제8항에 있어서, 상기 딥 러닝 모델은 하나 이상의 콘볼루션 신경망을 포함하는 하나 이상의 신경망을 포함하며, 상기 이미지는 상기 센서의 기술적인 결함 또는 상기 센서에 대한 물리적 장애물 중 하나 이상으로 인하여 불명확하고, 상기 물리적 장애물은 센서를 가리는 사람, 식물, 동물, 또는 물체, 혹은 센서의 렌즈의 일부분을 덮는 먼지, 얼룩, 진흙 또는 이물질로 인한 것인, 방법.</claim></claimInfo><claimInfo><claim>13. 제8항에 있어서, 상기 불명확한 이미지의 실시간 통지 및 상기 센서의 실시간 자동 수정 중 하나 이상을 제공하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제8항에 있어서, 상기 프로세서는 공통 반도체 패키지 상에 애플리케이션 프로세서와 함께 배치되는 그래픽 프로세서를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 컴퓨팅 장치에 의해 실행될 경우에 상기 컴퓨팅 장치로 하여금 동작들을 수행하게 하는 명령어를 포함하는 적어도 하나의 머신 판독가능한 매체로서, 상기 동작들은,  하나 이상의 센서가 장면의 하나 이상의 이미지를 캡처하는 것을 가능하게 하는 동작 - 상기 하나 이상의 이미지 중 하나의 이미지가 불명확하다고 판정되고, 상기 하나 이상의 센서는 하나 이상의 카메라를 포함함 - 과,  딥 러닝 모델이 상기 이미지와 연관된 센서를 실시간으로 식별하는 것을 가능하게 하는 동작을 포함하는, 머신 판독가능한 매체.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 동작들은, 상기 하나 이상의 이미지와 연관된 하나 이상의 데이터 입력을 수신하여, 상기 하나 이상의 데이터 입력을 상기 딥 러닝 모델에 의해 처리될 단일 데이터 입력으로 결합하는 동작을 더 포함하며, 상기 장치는, 자율 주행 자동차, 자율 비행 차량, 자율 항해 차량 및 자율 가정용 장치 중 하나 이상을 포함하는 자율 머신을 포함하는, 머신 판독가능한 매체.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 동작들은, 상기 딥 러닝 모델이 상기 단일 데이터 입력을 수신하여, 상기 불명확한 이미지와 연관된 센서를 실시간으로 식별하기 위한 트레이닝 과정 및 추론 과정을 포함하는 하나 이상의 딥 러닝 과정을 수행하는 것을 가능하게 하는 동작을 더 포함하며, 상기 센서는 카메라를 포함하는, 머신 판독가능한 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 딥 러닝 모델은 또한 복수의 데이터 입력을 수신하고, 상기 센서의 실시간 식별이 정확하고 시의적절하도록 상기 트레이닝 및 추론 과정을 통해 상기 복수의 데이터 입력을 실행하는, 머신 판독가능한 매체.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서, 상기 딥 러닝 모델은 하나 이상의 콘볼루션 신경망을 포함하는 하나 이상의 신경망을 포함하며, 상기 이미지는 상기 센서의 기술적인 결함 또는 상기 센서에 대한 물리적 장애물 중 하나 이상으로 인하여 불명확하고, 상기 물리적 장애물은 센서를 가리는 사람, 식물, 동물, 또는 물체, 혹은 센서의 렌즈의 일부분을 덮는 먼지, 얼룩, 진흙, 또는 이물질로 인한 것인, 머신 판독가능한 매체.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 동작들은, 상기 불명확한 이미지의 실시간 통지 및 상기 센서의 실시간 자동 수정 중 하나 이상을 제공하는 동작을 더 포함하며, 상기 컴퓨팅 장치는 공통 반도체 패키지 상에 애플리케이션 프로세서와 함께 배치된 그래픽 프로세서를 갖는 하나 이상의 프로세서를 포함하는, 머신 판독가능한 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미합중국 캘리포니아 ***** 산타클라라 미션 칼리지 블러바드 ****</address><code>520000333491</code><country>미국</country><engName>Intel Corporation</engName><name>인텔 코포레이션</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 상하이 ****** 송지앙 디스트릭트...</address><code> </code><country> </country><engName>YANG, Wenlong</engName><name>양 웬롱</name></inventorInfo><inventorInfo><address>이스라엘 나리아...</address><code> </code><country> </country><engName>RIDER, Tomer</engName><name>라이더 토머</name></inventorInfo><inventorInfo><address>중국 상하이 ****** ...</address><code> </code><country> </country><engName>ZHANG, Xiaopei</engName><name>장 시아오페이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2017.11.28</priorityApplicationDate><priorityApplicationNumber>15/824,808</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2024.10.18</receiptDate><receiptNumber>1-1-2024-1133679-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.15</receiptDate><receiptNumber>1-1-2024-1257025-46</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240142674.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9360acbdcd394169cfa6d16961ed75b4d5977c546975c089f47b9d711e5ed789d3a94488a524b31ca3e1ca56597cadb58b999ce2fdc1980f91</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf908c1cdbed7cf646d8605d6e1220036ef21d1269faf90767f966ec0ede1e31f428e705a738648bca160d5866e1e91fb8b87a329773bee5ca</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>