<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:16:42.1642</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.05.20</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7032674</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>단일 이미지-기반 실시간 신체 애니메이션</inventionTitle><inventionTitleEng>SINGLE IMAGE-BASED REAL-TIME BODY ANIMATION</inventionTitleEng><openDate>2025.10.20</openDate><openNumber>10-2025-0150685</openNumber><originalApplicationDate>2020.05.20</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2021-7038028</originalApplicationNumber><originalExaminationRequestDate>2025.09.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.09.29</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020217038028</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 단일 이미지-기반 신체 애니메이션을 위한 시스템 및 방법을 제공한다. 예시적인 방법은 컴퓨팅 장치에 의해, 사람의 신체를 포함하는 입력 이미지를 수신하는 단계, 입력 이미지를 신체 부분 및 배경 부분으로 세그먼트하는 단계 -신체 부분은 사람의 신체에 대응하는 픽셀들을 포함함-, 신체 부분에 모델을 피팅하는 단계-모델은, 신체의 포즈를 나타내는 포즈 파라미터들의 세트를 수신하고, 포즈를 취하는 신체의 이미지를 포함하는 출력 이미지를 생성하도록 구성됨-, 일련의 포즈 파라미터들을 수신하는 단계 - 포즈 파라미터들의 추가 세트들의 각각은, 신체의 추가 포즈들 중 하나를 나타냄-; 추가 포즈들을 취하는 일련의 신체의 출력 이미지들을 생성하기 위해, 일련의 포즈 파라미터들의 추가 세트들의 각각을 모델에 제공하는 단계, 및 일련의 출력 이미지들에 기초하여, 출력 비디오를 생성하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2020.12.10</internationOpenDate><internationOpenNumber>WO2020247174</internationOpenNumber><internationalApplicationDate>2020.05.20</internationalApplicationDate><internationalApplicationNumber>PCT/US2020/033742</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 단일 이미지-기반 신체 애니메이션을 위한 방법에 있어서,컴퓨팅 장치에 의해, 사람의 신체를 포함하는 입력 이미지를 수신하는 것;상기 컴퓨팅 장치에 의해, 상기 입력 이미지를 신체 부분 및 배경 부분으로 세그먼트하는 것 - 상기 신체 부분은 상기 입력 이미지의 픽셀들을 포함하고, 상기 픽셀들은 상기 사람의 상기 신체에 대응함 -;상기 컴퓨팅 장치에 의해, 상기 신체 부분에 모델을 피팅하는 것 - 상기 모델은, 상기 신체의 포즈를 나타내는 포즈 파라미터들의 세트를 수신하고, 상기 포즈 파라미터들의 세트에 기초하여 출력 이미지를 생성하도록 구성되고, 상기 출력 이미지는 상기 포즈를 취하는 상기 신체의 이미지를 포함함 -;상기 컴퓨팅 장치에 의해, 일련의 포즈 파라미터들의 추가 세트들을 수신하는 것 - 상기 일련의 포즈 파라미터들의 각각은 상기 신체의 추가 포즈들 중 적어도 하나를 나타내고, 상기 포즈 파라미터들의 상기 추가 세트들은 일반 모델을 사용하여 생성됨 -;상기 컴퓨팅 장치에 의해, 상기 추가 포즈들을 취하는 일련의 상기 신체의 출력 이미지들을 생성하기 위해, 상기 일련의 포즈 파라미터들의 추가 세트들의 각각을 상기 모델에 제공하는 것; 및상기 컴퓨팅 장치에 의해 및 상기 일련의 출력 이미지들에 기초하여, 출력 비디오를 생성하는 것 - 상기 출력 비디오의 각 프레임은 상기 출력 이미지들 중 적어도 하나를 포함함 -를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 입력 이미지를 세그먼트하는 것은,신경망에 의해 수행되는,방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 일련의 포즈 파라미터들의 추가 세트들은,하나 이상의 모션을 포함하는,방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 일반 모델을 사용한 상기 일련의 포즈 파라미터들의 추가 세트들의 생성은,하나 이상의 행위자에 의하여 수행된 하나 이상의 모션을 캡처하는 것, 및상기 하나 이상의 모션을 디지털화하는 것에 의하여 수행되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 일반 모델을 사용한 상기 일련의 포즈 파라미터들의 추가 세트들의 생성은,상기 일반 모델과 연관된 편집기를 사용하여 수행되는,방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 모델은,3차원(3D) 공간에서의 관절 점들의 세트 - 상기 관절 점들은 상기 신체에서 관절들의 위치를 나타냄 -;3D 공간에서의 메쉬 점들을 포함하는 메쉬 - 상기 메쉬 점들의 각각은 스키닝 가중치들의 세트가 할당되고, 상기 스키닝 가중치들의 각각은 상기 관절 점들 중 적어도 하나와 연관됨 -; 및상기 메쉬에 텍스처를 생성하기 위한 텍스처 맵을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 포즈 파라미터들의 세트는,기준 점에 대한 상기 관절 점들의 회전 각도들을 포함하고,상기 출력 이미지를 생성하는 것은,상기 메쉬 점들을 변환함으로써 상기 메쉬를 변환하는 것 - 상기 메쉬 점들의 각각은 각도들만큼 회전되고, 상기 각도들은 상기 관절 점들의 회전 각도들과 상기 스키닝 가중치들에 기초하여 결정됨 -, 및상기 변환된 메쉬의 텍스처를 생성하기 위해, 상기 변환된 메쉬에 상기 텍스처 맵을 적용하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 모델을 피팅하는 것은,상기 신체 부분에 기초하여, 상기 일반 모델을 결정하는 것 - 상기 일반 모델은, 상기 신체의 관절들을 나타내는 주요 점들의 세트 및 상기 신체의 형상을 나타내는 형상 파라미터들의 세트를 포함함 -;상기 신체 부분에 기초하여 상기 신체 이미지의 제1 실루엣을 결정하는 것;상기 일반 모델에 기초하여 상기 신체 이미지의 제2 실루엣을 결정하는 것;점들의 쌍들의 세트를 결정하는 것 - 상기 점들의 쌍들의 각각은, 상기 제1 실루엣 상에 위치된 제1 점 및 상기 제2 실루엣 상에 위치된 제2 점을 포함함 -;워핑된 모델을 획득하기 위해, 상기 점들의 쌍들의 세트에 기초하여 상기 일반 모델을 워핑하는 것; 및상기 워핑된 모델에 기초하여, 상기 관절 점들의 세트 및 상기 메쉬를 결정하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 관절 점들의 세트는,상기 메쉬에 기초하여 생성되고,상기 관절 점들의 세트는,상기 주요 점들의 세트인방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 텍스처 맵은,상기 메쉬의 2차원(2D) 표현을 생성하기 위해 상기 메쉬를 언래핑하는 것; 및상기 메쉬의 상기 2D 표현의 각 면에 대해:상기 면이 상기 입력 이미지에서 보이는 상기 신체의 일부에 대응하는지 여부를 결정하는 것;상기 면이 상기 입력 이미지에서 보이는 상기 신체의 상기 일부에 대응한다는 결정에 기초하여, 상기 메쉬의 상기 2D 표현의 상기 면에 상기 신체 부분의 세그먼트를 할당하는 것; 및상기 면이 상기 입력 이미지에서 보이는 상기 신체의 일부에 대응하지 않는다는 결정에 기초하여, 상기 신체 부분에 기초하여 예측된 면을 생성하고, 상기 메쉬의 상기 2D 표현의 상기 면에 상기 예측된 면을 할당하는 단계에 의해 생성되는,방법.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서,상기 주요 점들의 세트는,제1 신경망에 의해 결정되고,상기 일반 모델은,제2 신경망에 의해 결정되는,방법.</claim></claimInfo><claimInfo><claim>12. 단일 이미지-기반 신체 애니메이션을 위한 시스템에 있어서,상기 시스템은,적어도 하나의 프로세서, 및프로세서-실행 가능 코드들을 저장하는 메모리를 포함하고,상기 적어도 하나의 프로세서는, 상기 프로세서-실행 가능 코드들을 실행할 때, 동작들을 구현하도록 구성되고,상기 동작들은,사람의 신체를 포함하는 입력 이미지를 수신하는 동작;상기 입력 이미지를 신체 부분 및 배경 부분으로 세그먼트하는 동작 - 상기 신체 부분은 상기 입력 이미지의 픽셀들을 포함하고, 상기 픽셀들은 상기 사람의 상기 신체에 대응함 -;상기 신체 부분에 모델을 피팅하는 동작 - 상기 모델은, 상기 신체의 포즈를 나타내는 포즈 파라미터들의 세트를 수신하고, 상기 포즈 파라미터들의 세트에 기초하여 출력 이미지를 생성하도록 구성되고, 상기 출력 이미지는 상기 포즈를 취하는 상기 신체의 이미지를 포함함 -;일련의 포즈 파라미터들의 추가 세트들을 수신하는 동작 - 상기 일련의 포즈 파라미터들의 각각은 상기 신체의 추가 포즈들 중 적어도 하나를 나타내고, 상기 포즈 파라미터들의 상기 추가 세트들은 일반 모델을 사용하여 생성됨 -;상기 추가 포즈들을 취하는 일련의 상기 신체의 출력 이미지들을 생성하기 위해, 상기 일련의 포즈 파라미터들의 추가 세트들의 각각을 상기 모델에 제공하는 동작; 및상기 일련의 출력 이미지들에 기초하여, 출력 비디오를 생성하는 동작 - 상기 출력 비디오의 각 프레임은 상기 출력 이미지들 중 적어도 하나를 포함함 -을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 일련의 추가 포즈 파라미터들은,하나 이상의 모션을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 일반 모델을 사용한 상기 일련의 포즈 파라미터들의 추가 세트들의 생성은,하나 이상의 행위자에 의하여 수행된 하나 이상의 모션을 캡처하는 것, 및상기 하나 이상의 모션을 디지털화하는 것에 의하여 수행되는, 시스템.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 일반 모델을 사용한 상기 일련의 포즈 파라미터들의 추가 세트들의 생성은,상기 일반 모델과 연관된 편집기를 사용하여 수행되는,시스템.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 모델은,3차원(3D) 공간에서의 관절 점들의 세트 - 상기 관절 점들은 상기 신체에서 관절들의 위치를 나타냄 -;3D 공간에서의 메쉬 점들을 포함하는 메쉬 - 상기 메쉬 점들의 각각은 스키닝 가중치들의 세트가 할당되고, 상기 스키닝 가중치들의 각각은 상기 관절 점들 중 적어도 하나와 연관됨 -; 및상기 메쉬에 텍스처를 생성하기 위한 텍스처 맵을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 포즈 파라미터들의 세트는,기준 점에 대한 상기 관절 점들의 회전 각도들을 포함하고,상기 출력 이미지를 생성하는 것은,상기 메쉬 점들을 변환함으로써 상기 메쉬를 변환하는 것 - 상기 메쉬 점들의 각각은 각도들만큼 회전되고, 상기 각도들은 상기 관절 점들의 회전 각도들과 상기 스키닝 가중치들에 기초하여 결정됨 -, 및상기 변환된 메쉬의 텍스처를 생성하기 위해, 상기 변환된 메쉬에 상기 텍스처 맵을 적용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,상기 모델을 피팅하는 것은,상기 신체 부분에 기초하여, 상기 일반 모델을 결정하는 것 - 상기 일반 모델은, 상기 신체의 관절들을 나타내는 주요 점들의 세트 및 상기 신체의 형상을 나타내는 형상 파라미터들의 세트를 포함함 -;상기 신체 부분에 기초하여 상기 신체 이미지의 제1 실루엣을 결정하는 것;상기 일반 모델에 기초하여 상기 신체 이미지의 제2 실루엣을 결정하는 것;점들의 쌍들의 세트를 결정하는 것 - 상기 점들의 쌍들의 각각은, 상기 제1 실루엣 상에 위치된 제1 점 및 상기 제2 실루엣 상에 위치된 제2 점을 포함함 -;워핑된 모델을 획득하기 위해, 상기 점들의 쌍들의 세트에 기초하여 상기 일반 모델을 워핑하는 것; 및상기 워핑된 모델에 기초하여, 상기 관절 점들의 세트 및 상기 메쉬를 결정하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 텍스처 맵은,상기 메쉬의 2차원(2D) 표현을 생성하기 위해 상기 메쉬를 언래핑하는 것; 및상기 메쉬의 상기 2D 표현의 각 면에 대해:상기 면이 상기 입력 이미지에서 보이는 상기 신체의 일부에 대응하는지 여부를 결정하는 것;상기 면이 상기 입력 이미지에서 보이는 상기 신체의 상기 일부에 대응한다는 결정에 기초하여, 상기 메쉬의 상기 2D 표현의 상기 면에 상기 신체 부분의 세그먼트를 할당하는 것; 및상기 면이 상기 입력 이미지에서 보이는 상기 신체의 일부에 대응하지 않는다는 결정에 기초하여, 상기 신체 부분에 기초하여 예측된 면을 생성하고, 상기 메쉬의 상기 2D 표현의 상기 면에 상기 예측된 면을 할당하는 단계에 의해 생성되는,시스템.</claim></claimInfo><claimInfo><claim>20. 비일시적 프로세서 판독가능 매체에 있어서,인스트럭션들을 저장하고,상기 인스트럭션들은,하나 이상의 프로세서에 의하여 실행되는 경우, 상기 하나 이상의 프로세서로 하여금, 단일 이미지-기반 신체 애니메이션을 위한 방법을 구현하도록 하고,상기 방법은,사람의 신체를 포함하는 입력 이미지를 수신하는 것;상기 입력 이미지를 신체 부분 및 배경 부분으로 세그먼트하는 것 - 상기 신체 부분은 상기 입력 이미지의 픽셀들을 포함하고, 상기 픽셀들은 상기 사람의 상기 신체에 대응함 -;상기 신체 부분에 모델을 피팅하는 것 - 상기 모델은, 상기 신체의 포즈를 나타내는 포즈 파라미터들의 세트를 수신하고, 상기 포즈 파라미터들의 세트에 기초하여 출력 이미지를 생성하도록 구성되고, 상기 출력 이미지는 상기 포즈를 취하는 상기 신체의 이미지를 포함함 -;일련의 포즈 파라미터들의 추가 세트들을 수신하는 것 - 상기 일련의 포즈 파라미터들의 각각은 상기 신체의 추가 포즈들 중 적어도 하나를 나타내고, 상기 포즈 파라미터들의 상기 추가 세트들은 일반 모델을 사용하여 생성됨 -;상기 추가 포즈들을 취하는 일련의 상기 신체의 출력 이미지들을 생성하기 위해, 상기 일련의 포즈 파라미터들의 추가 세트들의 각각을 상기 모델에 제공하는 것; 및상기 일련의 출력 이미지들에 기초하여, 출력 비디오를 생성하는 것 - 상기 출력 비디오의 각 프레임은 상기 출력 이미지들 중 적어도 하나를 포함함 -를 포함하는, 비일시적 프로세서 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국, 캘리포니아 *****, 산타 모니카, ** 스트리트 ****</address><code>520200092045</code><country>미국</country><engName>Snap Inc.</engName><name>스냅 아이엔씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 ***** 산...</address><code> </code><country>러시아</country><engName>NEMCHINOV, Egor</engName><name>넴치노프, 이고르</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 산...</address><code> </code><country>러시아</country><engName>GORBATYUK, Sergei</engName><name>고르바티유크, 세르게이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 산...</address><code> </code><country>미국</country><engName>MASHRABOV, Aleksandr</engName><name>마슈라보프, 알렉산드르</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 산...</address><code> </code><country>러시아</country><engName>SPIRIN, Egor</engName><name>스피린, 이고르</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 산...</address><code> </code><country>러시아</country><engName>SOKOLOV, Iaroslav</engName><name>스콜로프, 이아로슬라프</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 산...</address><code> </code><country>러시아</country><engName>SMIRDIN, Andrei</engName><name>스미르딘, 안드레이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 산...</address><code> </code><country>러시아</country><engName>TUKH, Igor</engName><name>투크, 이고르</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.06.07</priorityApplicationDate><priorityApplicationNumber>16/434,185</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.09.29</receiptDate><receiptNumber>1-1-2025-1109116-55</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257032674.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338ebd6b9e5188b12e6e3dd807b411c835c5eaa8969a917153ad606781d03d6367391d4e58cd77edcbb26c58618949b9006e7289278aed2fcb6d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd79bea3195aba4d57a89e4b02c6d1a1f972cb3fcd723fa5948ad94c451ce116039327538de7ac6d7433ea83294af7ba21d638c57779bd5f0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>