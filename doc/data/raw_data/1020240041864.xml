<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:27.727</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0041864</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>위치 다중 헤드 어텐션 네트워크</inventionTitle><inventionTitleEng>POSITIONAL MULTI-HEAD ATTENTION NETWORK</inventionTitleEng><openDate>2025.10.13</openDate><openNumber>10-2025-0144719</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에 따른 위치 다중 헤드 어텐션 네트워크는, 다운샘플링(down sampling) 구조와 업샘플링(up sampling) 구조를 포함하는 유-넷(U-Net) 기반의 위치 다중 헤드 어텐션 네트워크(Positional Multi-Head Attention network, PMHA-NET)로서, 다운샘플링 과정에서 각 계층의 포인트 간 관계에 대한 다양한 관점을 얻는 위치 다중 헤드 어텐션; 및 상기 위치 다중 헤드 어텐션의 출력을 연결(concatenation)하여 계층 간의 정보를 결합하는 전체적(global) 다중 헤드 어텐션을 더 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 다운샘플링(down sampling) 구조와 업샘플링(up sampling) 구조를 포함하는 유-넷(U-Net) 기반의 위치 다중 헤드 어텐션 네트워크(Positional Multi-Head Attention network, PMHA-NET)로서,다운샘플링 과정에서 각 계층의 포인트 간 관계에 대한 다양한 관점을 얻는 위치 다중 헤드 어텐션; 및상기 위치 다중 헤드 어텐션의 출력을 연결(concatenation)하여 계층 간의 정보를 결합하는 전체적(global) 다중 헤드 어텐션을 더 포함하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>2. 제1항에서,상기 다운샘플링은, 로우 데이터(raw data)에서 세부적 특징을 추출하는 kNN 그룹화(k-Nearest Neighbors grouping) 및 특징 추출(feature extraction) 모듈을 포함하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>3. 제2항에서,상기 특징 추출 모듈은 PointMLP에서 사용한 Batch Normalization 및 Rectified Linear Unit(ReLU) 활성화 함수를 통합한 Residual Block을 포함하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>4. 제2항에서,상기 전체적 다중 헤드 어텐션의 출력을 이용하여 분류(classification) 작업을 실시하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>5. 제4항에서,상기 업샘플링의 출력과 상기 전체적 다중 헤드 어텐션의 출력을 연결(concatenation)하여 분할 작업을 실시하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에서,상기 위치 다중 헤드 어텐션은 각각의 해상도에서 진행되는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>7. 제6항에서,상기 위치 다중 헤드 어텐션은, 다중 해상도에서 포인트의 위치 정보를 획득하고, 다중 헤드 어텐션을 통해 다중 관점에서 위치 정보를 해석하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>8. 제6항에서,상기 위치 다중 헤드 어텐션은 상대적인 위치를 재가공한 위치 벡터의 채널을 헤드 수로 나누어 쿼리, 키, 밸류와 함께 사용하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>9. 제8항에서,상기 위치 벡터는,포인트 클라우드의 절대적인 위치 정보인 입력 데이터(SN)를 다운샘플링 과정에서 가장 먼 포인트 샘플링(farthest point sampling)을 통해 샘플링하여 SS = {ps1, ps2, . . . , psN}을  생성하는 단계;SS의 한 포인트(psi)를 기준으로, 3D 유클리드 거리로 SN의 k개의 이웃 포인트들을 검색하여 kNN 그룹인 SK ∈ RN×k×3를 얻는 단계;SK에서 psi를 빼서 상대적인 위치 정보인 ΔSK를 얻는 단계;상대적인 위치 정보에 절대값을 취하고, 객체 범위에서의 정규화인 전체적 정규화와 지역 범위에서의 정규화인 세부적 정규화를 적용하여 위치 점수를 얻는 단계; 및상기 위치 점수와 상기 입력 데이터를 연결하여 상기 위치 벡터를 생성하는 단계에 의해 생성되는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>10. 제9항에서,상기 업샘플링 과정에서, 위치 정보(positional information)을 추가하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>11. 제10항에서,상기 업샘플링 과정에서, 3개의 이웃한 포인트에 대한 특징 벡터를 보간(interpolation)한 후, 상기 위치 점수와 상기 입력 데이터를 연결(concatenation)한 후에, 다중 계층 퍼셉트론(multi-layer perceptron, MLP)을 통과하여 다음 계층에 전달될 특징 벡터에 상기 위치 정보를 추가하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>12. 제9항에서,상기 위치 점수를 얻기 위한 정규화 방법으로 최소-최대 정규화(min-max normalization)를 사용하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>13. 제12항에서,상기 최소-최대 정규화 시 IQR 이상치 검출(InterQuartile Range outlier detection)을 사용하여 이상치를 검출하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>14. 제13항에서,상기 최소-최대 정규화 시 최대값을 정할 때, 전체적 정규화는 객체 전체 범위에서 IQR(InterQuartile Range) 이상치 검출을 진행하고, 세부적 정규화는 kNN 그룹 범위 내에서 IQR 이상치 검출을 진행하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>15. 제14항에서,상기 전체적 정규화에서 이상치로 판단된 포인트들이 상기 세부적 정규화에서 이상치로 판단되지 않는 경우에는 세부적 정규화만 적용하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>16. 제6항에서,상기 전체적 다중 헤드 어텐션은 전체 해상도를 기준으로 진행되는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>17. 제16항에서,상기 전체적 다중 헤드 어텐션은 전체적 특징(global feature) 및 세부적 특징(local feature)을 모두 포함하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo><claimInfo><claim>18. 다운샘플링(down sampling) 구조와 업샘플링(up sampling) 구조를 포함하는 유-넷(U-Net) 기반의 위치 다중 헤드 어텐션 네트워크(Positional Multi-Head Attention network, PMHA-NET)로서,다운샘플링 과정에서 각 계층의 포인트 간 관계에 대한 다양한 관점을 얻는 위치 다중 헤드 어텐션; 및상기 위치 다중 헤드 어텐션의 출력을 연결(concatenation)하여 계층 간의 정보를 결합하는 전체적(global) 다중 헤드 어텐션을 더 포함하고,상기 업샘플링 과정에서, 3개의 이웃한 포인트에 대한 특징 벡터를 보간(interpolation)한 후, 상기 위치 점수와 상기 입력 데이터를 연결(concatenation)한 후에, 다중 계층 퍼셉트론(multi-layer perceptron, MLP)을 통과하여 다음 계층에 전달될 특징 벡터에 상기 위치 정보를 추가하며,상기 위치 다중 헤드 어텐션은 각각의 해상도에서 진행하고, 상기 전체적 다중 헤드 어텐션은 전체 해상도를 기준으로 진행하는 위치 다중 헤드 어텐션 네트워크.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성북구...</address><code>220040468902</code><country>대한민국</country><engName>Kookmin University Industry Academy Cooperation Foundation</engName><name>국민대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 구리시 ...</address><code> </code><country> </country><engName>JAESEUNG JEON</engName><name>전재승</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>SEOKJIN HONG</engName><name>홍석진</name></inventorInfo><inventorInfo><address>서울특별시 강북구...</address><code> </code><country> </country><engName>HOOKYUNG LEE</engName><name>이후경</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>JINWOO YOO</engName><name>유진우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로***길**, *층(대치동, 삼호빌딩)</address><code>920071001220</code><country>대한민국</country><engName>ROYAL Patent &amp; Law Office</engName><name>특허법인로얄</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.27</receiptDate><receiptNumber>1-1-2024-0343541-11</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240041864.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93522e59d419c828ebb188cd9ea1095751f2873b414b82a09f88c56ac1d8ee5487681d0cfce8eed95c53136b7671968f368454b2be28b66bc5</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff65f6b5fe7a7ae0584f674ea4203383a5979441a98df26d5a583fa37792a7587682e25596ef790d089c2dba9ce2a9564c83a2771222bd796</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>