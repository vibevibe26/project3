<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:47.747</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0037965</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신체 접촉 및 상호작용을 고려한 유도 확산 모델 기반 아바타 생성 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR GENERATING AVATARS BASED ON GUIDED  DIFFUSION MODEL CONSIDERING BODY CONTACT AND INTERACTION</inventionTitleEng><openDate>2025.09.26</openDate><openNumber>10-2025-0140908</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.19</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 신체 접촉 및 상호작용을 고려한 유도 확산 모델 기반 아바타 생성 방법 및 장치는 아바타 생성 모델에 파트너 아바타 표현 및 상호작용 라벨을 입력(input)하는 단계, 상기 입력된 파트너 아바타 표현 및 상호작용 라벨와 노이즈 샘플에 기초하여 상기 아바타 생성 모델의 디노이징(Denoising) 과정을 수행함으로써 노이즈가 제거된 디노이징 샘플 표현을 생성하는 단계, 접촉 예측 영역 세트에 기초하여 설정된 접촉 목표(contact objective)를 고려하는 가이던스에 기초하여 상기 디노이징 샘플 표현을 수정함으로써 타겟 샘플 표현을 생성하는 단계, 상기 타겟 샘플 표현으로부터 상기 아바타 생성 모델의 확산(Diffusion) 과정을 수행함으로써 부분적으로 디노이징된 아바타 표현을 생성하는 단계 및 상기 디노이징 샘플 표현의 생성 및 상기 부분적으로 디노이징된 아바타 표현의 생성을 반복함으로써 상기 상호작용 라벨에 대응하는 타겟 아바타 표현을 생성하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 프로세서에 의해 신체 접촉 및 상호작용을 고려한 아바타를 생성하는 방법에 있어서,아바타 생성 모델에 파트너 아바타 표현 및 상호작용 라벨을 입력(input)하는 단계;상기 입력된 파트너 아바타 표현 및 상호작용 라벨과 노이즈 샘플에 기초하여 상기 아바타 생성 모델의 디노이징(Denoising) 과정을 수행함으로써 노이즈가 제거된 디노이징 샘플 표현을 생성하는 단계;접촉 예측 영역 세트에 기초하여 설정된 접촉 목표(contact objective)를 고려하는 가이던스에 기초하여 상기 디노이징 샘플 표현을 수정함으로써 타겟 샘플 표현을 생성하는 단계;상기 타겟 샘플 표현으로부터 상기 아바타 생성 모델의 확산(Diffusion) 과정을 수행함으로써 부분적으로 디노이징된 아바타 표현을 생성하는 단계; 및상기 디노이징 샘플 표현의 생성 및 상기 부분적으로 디노이징된 아바타 표현의 생성을 반복함으로써 상기 상호작용 라벨에 대응하는 타겟 아바타 표현을 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 타겟 아바타 표현을 생성하는 단계는,상기 파트너 아바타 표현 및 상호작용 라벨과 상기 부분적으로 디노이징된 아바타 표현에 기초하여 다음 주기의 디노이징 샘플 표현을 생성하는 단계;상기 생성된 다음 주기의 디노이징 샘플 표현에 기초하여 다음 주기의 타겟 샘플 표현을 생성하는 단계;상기 다음 주기의 타겟 샘플 표현에 기초하여 그 다음 주기의 부분적으로 디노이징된 아바타 표현을 생성하는 단계; 및상기 다음 주기의 디노이징 샘플 표현 및 상기 다음 주기의 부분적으로 디노이징된 아바타 표현의 생성을 반복함으로써 상기 타겟 아바타 표현을 생성하는 단계를 포함하고,마지막 반복에 대해, 상기 타겟 아바타 표현은 상기 다음 주기의 부분적으로 디노이징된 아바타 표현인,방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 타겟 샘플 표현을 생성하는 단계는,상기 디노이징 샘플 표현, 상기 파트너 아바타 표현 및 상기 상호작용 라벨을 상기 아바타 생성 모델의 접촉 예측 모듈에 입력함으로써 접촉 예측 영역 세트를 생성하는 단계;상기 생성된 접촉 예측 영역 세트에 기초하여 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현 간의 물리적 접촉을 촉진시키는 접촉 목표를 설정하는 단계;상기 파트너 아바타 표현, 상기 상호작용 라벨 및 상기 디노이징 샘플 표현에 대한 상기 접촉 목표 기반의 목적 함수를 이용하여 상기 가이던스를 계산하는 단계; 및상기 디노이징 샘플 표현 및 상기 계산된 가이던스와 상기 가이던스에 대한 스케일링 벡터(scaling vector) 간의 원소 간 곱(element-wise product)에 기초하여 상기 타겟 샘플 표현을 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 접촉 목표를 설정하는 단계는,상기 접촉 예측 영역 세트에 속하는 영역들의 두 정점 세트 간의 챔퍼(Chamfer) 거리의 합에 기초하여 상기 접촉 목표를 설정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 접촉 예측 영역 세트를 생성하는 단계는,상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 신체를 메시(mesh) 표면으로 변환하는 단계;상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 메시 표면 상에 정점 인덱스(vertex indices)를 기준으로 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 신체를 미리 결정된 개수의 영역으로 나누는 단계; 및나뉘어진 영역 별로 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현 간의 각 영역별 접촉 확률 맵을 예측하여 상기 접촉 예측 영역 세트를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 접촉 예측 영역 세트를 생성하는 단계는,특징 벡터 변환기에 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 각 영역 별로 중심 위치를 입력하여 각 영역별 특징 벡터를 계산하는 단계;상기 계산된 각 영역별 특징 벡터를 상기 접촉 예측 모듈에 입력하여 상기 디노이징 샘플 표현의 영역과 상기 파트너 아바타 표현의 영역 간에 접촉이 발생할 확률을 나타내는 상기 각 영역별 접촉 확률 맵을 추정하는 단계; 및상기 각 영역별 접촉 확률 맵에서 미리 결정된 임계값 이상의 확률에 해당하는 접촉 예측 영역 쌍을 포함하는 상기 접촉 예측 영역 세트를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 각 영역별 접촉 확률 맵을 추정하기 이전에, 참 값(Ground Truth) 접촉 확률 맵과 추정된 접촉 확률 맵 간의 손실을 최소화하는 이진 교차 엔트로피 목적 함수에 기초하여 상기 접촉 예측 모듈을 트레이닝하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 아바타 생성 모델에 상기 파트너 아바타 표현 및 상호작용 라벨을 입력하기 이전에 상기 아바타 생성 모델의 디노이징 과정을 수행하는 노이즈 예측 모델을 트레이닝하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 노이즈 예측 모델을 트레이닝하는 단계는,트레이닝 데이터의 아바타 표현 특성에 따라 하나 이상의 부분으로 분리된 참 값 노이즈와 예측된 노이즈 간의 손실을 최소화하여 상기 노이즈 예측 모델을 트레이닝하는 단계 를 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 아바타 생성 모델에 파트너 아바타 표현 및 상호작용 라벨을 입력(input)하고, 상기 입력된 파트너 아바타 표현 및 상호작용 라벨과 노이즈 샘플에 기초하여 상기 아바타 생성 모델의 디노이징(Denoising) 과정을 수행함으로써 노이즈가 제거된 디노이징 샘플 표현을 생성하고, 접촉 예측 영역 세트에 기초하여 설정된 접촉 목표(contact objective)를 고려하는 가이던스에 기초하여 상기 디노이징 샘플 표현을 수정함으로써 타겟 샘플 표현을 생성하고, 상기 타겟 샘플 표현으로부터 상기 아바타 생성 모델의 확산(Diffusion) 과정을 수행함으로써 부분적으로 디노이징된 아바타 표현을 생성하며, 상기 디노이징 샘플 표현의 생성 및 상기 부분적으로 디노이징된 아바타 표현의 생성을 반복함으로써 상기 상호작용 라벨에 대응하는 타겟 아바타 표현을 생성하는 프로세서를 포함하는 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 프로세서는,상기 파트너 아바타 표현 및 상호작용 라벨과 상기 부분적으로 디노이징된 아바타 표현에 기초하여 다음 주기의 디노이징 샘플 표현을 생성하고, 상기 생성된 다음 주기의 디노이징 샘플 표현에 기초하여 다음 주기의 타겟 샘플 표현을 생성하고, 상기 다음 주기의 타겟 샘플 표현에 기초하여 그 다음 주기의 부분적으로 디노이징된 아바타 표현을 생성하며, 상기 다음 주기의 디노이징 샘플 표현 및 상기 다음 주기의 부분적으로 디노이징된 아바타 표현의 생성을 반복함으로써 상기 타겟 아바타 표현을 생성하는 단계를 포함하고, 마지막 반복에 대해, 상기 타겟 아바타 표현은 상기 다음 주기의 부분적으로 디노이징된 아바타 표현인,장치.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 프로세서는,상기 디노이징 샘플 표현, 상기 파트너 아바타 표현 및 상기 상호작용 라벨을 상기 아바타 생성 모델의 접촉 예측 모듈에 입력함으로써 접촉 예측 영역 세트를 생성하고, 상기 생성된 접촉 예측 영역 세트에 기초하여 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현 간의 물리적 접촉을 촉진시키는 접촉 목표를 설정하고, 상기 파트너 아바타 표현, 상기 상호작용 라벨 및 상기 디노이징 샘플 표현에 대한 상기 접촉 목표 기반의 목적 함수를 이용하여 상기 가이던스를 계산하며, 상기 디노이징 샘플 표현 및 상기 계산된 가이던스와 상기 가이던스에 대한 스케일링 벡터(scaling vector) 간의 원소 간 곱(element-wise product)에 기초하여 상기 타겟 샘플 표현을 생성하는,장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 프로세서는,상기 접촉 예측 영역 세트에 속하는 영역들의 두 정점 세트 간의 챔퍼(Chamfer) 거리의 합에 기초하여 상기 접촉 목표를 설정하는,장치.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 프로세서는,상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 신체를 메시(mesh) 표면으로 변환하고, 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 메시 표면 상에 정점 인덱스(vertex indices)를 기준으로 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 신체를 미리 결정된 개수의 영역으로 나누며, 나뉘어진 영역 별로 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현 간의 각 영역별 접촉 확률 맵을 예측하여 상기 접촉 예측 영역 세트를 생성하는,장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 프로세서는,특징 벡터 변환기에 상기 디노이징 샘플 표현과 상기 파트너 아바타 표현의 각 영역 별로 중심 위치를 입력하여 각 영역별 특징 벡터를 계산하고, 상기 계산된 각 영역별 특징 벡터를 상기 접촉 예측 모듈에 입력하여 상기 디노이징 샘플 표현의 영역과 상기 파트너 아바타 표현의 영역 간에 접촉이 발생할 확률을 나타내는 상기 각 영역별 접촉 확률 맵을 추정하며, 상기 각 영역별 접촉 확률 맵에서 미리 결정된 임계값 이상의 확률에 해당하는 접촉 예측 영역 쌍을 포함하는 상기 접촉 예측 영역 세트를 생성하는,장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 프로세서는,상기 각 영역별 접촉 확률 맵을 추정하기 이전에, 참 값(Ground Truth) 접촉 확률 맵과 추정된 접촉 확률 맵 간의 손실을 최소화하는 이진 교차 엔트로피 목적 함수에 기초하여 상기 접촉 예측 모듈을 트레이닝하는,장치.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서,상기 프로세서는,상기 아바타 생성 모델에 상기 파트너 아바타 표현 및 상호작용 라벨을 입력하기 이전에 상기 아바타 생성 모델의 디노이징 과정을 수행하는 노이즈 예측 모델을 트레이닝하는,장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 프로세서는,트레이닝 데이터의 아바타 표현 특성에 따라 하나 이상의 부분으로 분리된 참 값 노이즈와 예측된 노이즈 간의 손실을 최소화하여 상기 노이즈 예측 모델을 트레이닝하는,장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>울산광역시 울주군...</address><code>120150812047</code><country>대한민국</country><engName>UNIST(ULSAN NATIONAL INSTITUTE OF SCIENCE AND TECHNOLOGY)</engName><name>울산과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>JOO Kyung Don</engName><name>주경돈</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>GU Dong Jun</engName><name>구동준</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>SHIM Jae Hyeok</engName><name>심재혁</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>JANG Jae Hoon</engName><name>장재훈</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>KANG Chang Woo</engName><name>강창우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.19</receiptDate><receiptNumber>1-1-2024-0308646-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2024.10.22</receiptDate><receiptNumber>1-1-2024-1149704-84</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.12.14</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240037965.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c932de9b094ff4e017091f19325f68ef3c29ea61f25d702c89229ede4b787161e12d6314340ca855e0dd742b793facaf645c874164b9b547427</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf35c9256aefb5185ee47c3b1cfc5e406fd1bac7903c3e0a0982040cc71944730212631c45af45662ec8f0a0a736a941c2ed39d06b83ed88c4</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>