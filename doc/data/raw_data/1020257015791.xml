<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:34.4134</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.06.22</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-7015791</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>2D 이미지들로부터의 3D 객체 모델 재구성</inventionTitle><inventionTitleEng>3D OBJECT MODEL RECONSTRUCTION FROM 2D IMAGES</inventionTitleEng><openDate>2025.05.28</openDate><openNumber>10-2025-0075728</openNumber><originalApplicationDate>2021.06.22</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2023-7002302</originalApplicationNumber><originalExaminationRequestDate>2025.05.14</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.05.14</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020237002302</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 원근 및/또는 왜곡 효과가 중요한 2D 이미지들로부터 인체의 3D 모델들을 재구성하는 시스템들 및 방법들이 제공된다. 시스템들 및 방법들은 객체의 이미지를 포함하는 2차원 이미지로부터 3차원 장면에서 객체의 3차원 모델을 재구성하는 것을 포함한다. 시스템들 및 방법들은 이미지 내의 객체의 키 포인트의 절대 깊이를 결정하는 것; 키 포인트의 절대 깊이를 사용하여, 3차원 장면에서 키 포인트의 3차원 포지션을 결정하는 것; 신경망을 사용하여, 객체의 3차원 표현을 생성하는 것- 3차원 표현은 키 포인트에 대한 좌표계에서 정의된 메시 노드들을 포함함 -; 및 3차원 객체에 포지션 의존 회전을 적용함으로써 키 포인트의 포지션에 기초하여 장면에서 객체의 3차원 표현을 포지셔닝시키는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.12.30</internationOpenDate><internationOpenNumber>WO2021262667</internationOpenNumber><internationalApplicationDate>2021.06.22</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/038400</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 구현 방법(computer-implemented method)으로서,객체의 이미지를 포함하는 2차원(2D) 이미지로부터 3차원(3D) 장면에서 상기 객체의 3차원(3D) 모델을 재구성하는 단계 - 상기 3차원 모델은 복수의 노드를 포함하는 방향성 그래프(directed graph)를 포함하고, 각각의 노드는 하나 이상의 에지에 의해 하나 이상의 다른 노드에 링크되고, 상기 방향성 그래프 내의 복수의 노드의 개별 노드에 대해, 상기 3차원 모델을 재구성하는 단계는, 하나 이상의 컨볼루션 신경망을 사용하여 그리고 상기 방향성 그래프내의 이전 노드의 2차원 이미지 좌표에 기초하여, 상기 개별 노드를 상기 이전 노드에 연결하는 에지와 연관된 3차원 오프셋 필드를 추정하는 단계; 추가 컨볼루션 신경망을 사용하여, 이전 노드와 연관된 상기 3차원 이미지 내의 포인트 근방의 디스패리티를 추정하는 단계; 및 상기 이전 노드의 3차원 좌표, 상기 3차원 오프셋 필드 및 상기 추정된 디스패리티를 사용하여 상기 개별 노드에 대한 3차원 좌표를 결정하는 단계를 포함함-를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 2차원 이미지를 캡처한 카메라를 상기 객체의 키 포인트에 연결하는 광선과 상기 2차원 이미지의 이미지 평면의 교차점을 결정하는 단계를 추가로 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 세계 깊이(world depth) 및 상기 교차점에 기초하여 상기 3차원 장면의 좌표계에서 상기 객체의 키 포인트의 3차원 포지션을 결정하는 단계를 추가로 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 3차원 장면에서 상기 키 포인트의 3차원 포지션을 결정하는 단계는 상기 카메라의 초점 거리에 추가로 기초하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 객체의 투영된 이미지를 생성하는 단계;상기 투영된 이미지 내의 포인트들의 로케이션들을 상기 2차원 이미지 내의 대응하는 포인트들의 로케이션들과 비교하는 단계; 및상기 비교하는 단계에 기초하여 상기 하나 이상의 컨볼루션 신경망의 파라미터들을 업데이트하는 단계를 추가로 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 투영된 이미지는 키 포인트의 절대 깊이 및 3차원 표현에 의해 정의된 메시 노드들의 깊이들에 적어도 부분적으로 기초하여 생성되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,픽셀 크기의 함수인 절대 깊이를 사용하여 상기 하나 이상의 컨볼루션 신경망을 훈련하는 단계를 추가로 포함하고, 상기 절대 깊이는 키 포인트의 깊이를 결정하는 데 사용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 개별 노드에 대해 3차원 좌표를 결정하는 단계는,상기 이전 노드의 2차원 이미지 좌표 및 상기 3차원 오프셋 필드의 2개의 컴포넌트에 기초하여 상기 개별 노드에 대한 2차원 이미지 좌표를 결정하는 단계;상기 이전 노드의 깊이 좌표, 상기 3차원 오프셋 필드의 컴포넌트들 중 하나 및 상기 추정된 디스패리티에 기초하여 상기 개별 노드의 깊이 좌표를 결정하는 단계; 및상기 노드의 깊이 좌표 또는 상기 노드와 연관된 추정된 디스패리티를 사용하여 상기 노드에 대한 2차원 이미지 좌표를 상기 개별 노드의 2차원 장면 좌표로 변환하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 이전 노드의 깊이 좌표에 기초하여 상기 개별 노드의 깊이 좌표를 결정하는 단계는,상기 이전 노드의 깊이 좌표, 상기 3차원 오프셋 필드의 컴포넌트 및 상기 추정된 디스패리티에 기초하여 상기 깊이 좌표의 초기 추정치를 결정하는 단계; 및상기 개별 노드를 상수 값만큼 깊이 방향으로 병진시킴으로써 상기 깊이 좌표의 초기 추정치를 정제(refine)하는 단계 - 상기 상수 값은 각각의 노드의 깊이 좌표와 각각의 노드의 깊이의 디스패리티 추정치 사이의 차이의 가중 평균임 -를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 방법은 루트 노드로부터 시작하고, 상기 방법은 상기 루트 노드의 3차원 좌표를 결정하는 단계를 추가로 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 루트 노드의 3차원 좌표를 결정하는 단계는,상기 2차원 이미지로부터 상기 루트 노드의 2차원 좌표를 추정하는 단계;추가 컨볼루션 신경망을 사용하여, 상기 루트 노드와 연관된 상기 2차원 이미지 내의 포인트 근방의 디스패리티를 추정하는 단계; 및상기 루트 노드와 연관된 상기 추정된 디스패리티, 상기 루트 노드의 2차원 좌표 및 상기 2차원 이미지를 캡처한 카메라의 초점 거리에 기초하여 상기 루트 노드에 대한 깊이 좌표를 결정하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 하나 이상의 콘볼루션 신경망은,상기 2차원 이미지와 연관된 평면에서 2차원 오프셋 필드를 추정하도록 구성된 제1 신경망; 및상기 평면에 수직인 방향으로 1차원 깊이 오프셋 필드를 추정하도록 구성된 제2 신경망을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 복수의 노드는,상기 객체의 키 포인트와 각각 연관된 복수의 키 포인트 노드; 및각각이 상기 모델의 표면 상의 포인트와 연관되고 각각이 방향성 에지에 의해 하나 이상의 가장 가까운 키 포인트 노드에 연결되는 복수의 리프 노드(leaf node)를 포함하고, 상기 키 포인트 노드들의 3차원 좌표들은 상기 리프 노드들의 3D 좌표들 전에 결정되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>14. 시스템으로서,하나 이상의 프로세서를 포함하고, 상기 하나 이상의 프로세서는,방향성 그래프(directed graph) 내의 복수의 노드의 개별 노드에 대해, 하나 이상의 컨볼루션 신경망을 사용하여 그리고 상기 방향성 그래프내의 이전 노드의 2차원 이미지 좌표에 기초하여, 상기 개별 노드를 상기 이전 노드에 연결하는 에지와 연관된 3차원(3D) 오프셋 필드를 추정하는 것; 추가 컨볼루션 신경망을 사용하여, 상기 이전 노드와 연관된 3차원 이미지 내의 포인트 근방의 디스패리티를 추정하는 것; 및 상기 이전 노드의 3차원 좌표, 상기 3차원 오프셋 필드 및 상기 추정된 디스패리티를 사용하여 상기 개별 노드에 대한 3차원 좌표를 결정하는 것을 포함하는 동작들을 수행하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>15. 명령어들을 포함하는 비일시적 컴퓨터 판독가능 매체로서,상기 명령어들은, 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서로 하여금:방향성 그래프(directed graph) 내의 복수의 노드의 개별 노드에 대해, 하나 이상의 컨볼루션 신경망을 사용하여 그리고 상기 방향성 그래프내의 이전 노드의 2차원 이미지 좌표에 기초하여, 상기 개별 노드를 상기 이전 노드에 연결하는 에지와 연관된 3차원(3D) 오프셋 필드를 추정하는 것; 추가 컨볼루션 신경망을 사용하여, 이전 노드와 연관된 상기 3차원 이미지 내의 포인트 근방의 디스패리티를 추정하는 것; 및 상기 이전 노드의 3차원 좌표, 상기 3차원 오프셋 필드 및 상기 추정된 디스패리티를 사용하여 상기 개별 노드에 대한 3차원 좌표를 결정하는 것을 포함하는 동작들을 수행하도록 구성하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 개별 노드에 대해 3차원 좌표를 결정하는 것은,상기 이전 노드의 2차원 이미지 좌표 및 상기 3차원 오프셋 필드의 2개의 컴포넌트에 기초하여 상기 개별 노드에 대한 2차원 이미지 좌표를 결정하는 것;상기 이전 노드의 깊이 좌표, 상기 3차원 오프셋 필드의 컴포넌트들 중 하나 및 상기 추정된 디스패리티에 기초하여 상기 개별 노드의 깊이 좌표를 결정하는 것; 및상기 노드의 깊이 좌표 또는 상기 노드와 연관된 추정된 디스패리티를 사용하여 상기 노드에 대한 2차원 이미지 좌표를 상기 개별 노드의 2차원 장면 좌표로 변환하는 것을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 이전 노드의 깊이 좌표에 기초하여 상기 개별 노드의 깊이 좌표를 결정하는 것은,상기 이전 노드의 깊이 좌표, 상기 3차원 오프셋 필드의 컴포넌트 및 상기 추정된 디스패리티에 기초하여 상기 깊이 좌표의 초기 추정치를 결정하는 것; 및상기 개별 노드를 상수 값만큼 깊이 방향으로 병진시킴으로써 상기 깊이 좌표의 초기 추정치를 정제(refine)하는 것 - 상기 상수 값은 각각의 노드의 깊이 좌표와 각각의 노드의 깊이의 디스패리티 추정치 사이의 차이의 가중 평균임 -을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 상기 동작들은 루트 노드로부터 시작하고, 상기 동작들은 상기 루트 노드의 3차원 좌표를 결정하는 것을 추가로 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 루트 노드의 3차원 좌표를 결정하는 것은,상기 2차원 이미지로부터 상기 루트 노드의 2차원 좌표를 추정하는 것;추가 컨볼루션 신경망을 사용하여, 상기 루트 노드와 연관된 상기 2차원 이미지 내의 포인트 근방의 디스패리티를 추정하는 것; 및상기 루트 노드와 연관된 상기 추정된 디스패리티, 상기 루트 노드의 2차원 좌표 및 상기 2차원 이미지를 캡처한 카메라의 초점 거리에 기초하여 상기 루트 노드에 대한 깊이 좌표를 결정하는 것을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 하나 이상의 콘볼루션 신경망은,상기 2차원 이미지와 연관된 평면에서 2차원 오프셋 필드를 추정하도록 구성된 제1 신경망; 및상기 평면에 수직인 방향으로 1차원 깊이 오프셋 필드를 추정하도록 구성된 제2 신경망을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>그리스</country><engName>PAPANDREOU, Georgios</engName><name>파판드레우, 게오르기오스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>그리스</country><engName>KOKKINOS, Iason</engName><name>코키노스, 이아손</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>영국</priorityApplicationCountry><priorityApplicationDate>2020.06.22</priorityApplicationDate><priorityApplicationNumber>2009515.4</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.03.02</priorityApplicationDate><priorityApplicationNumber>17/249,441</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2025.05.14</receiptDate><receiptNumber>1-1-2025-0537834-67</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257015791.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9385f595290fd0a5ae6646a14bf33109f4875aa0d568c9ac5e99a698fa0f09c4770b6a6055dfa41d230ddddba9e2228aa754bbcf8468089f41</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfc17d465d221df212d8bae14594d0561c9fbd86cd136a5d2a6b7dbfba4b1ebdcc7864aa066db903c3ad2fa843e14c6b405b5210f472cceef5</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>