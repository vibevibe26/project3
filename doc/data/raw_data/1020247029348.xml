<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:29.429</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7029348</applicationNumber><claimCount>28</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>동적 렌즈 포지션들을 사용한 이미지 캡처</inventionTitle><inventionTitleEng>IMAGE CAPTURE USING DYNAMIC LENS POSITIONS</inventionTitleEng><openDate>2024.12.05</openDate><openNumber>10-2024-0170904</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.30</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/959</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/67</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/611</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 5/222</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 상이한 피사계 심도들에 있는 피사체들을 갖는 이미지들을 캡처하기 위한 시스템들, 장치들, 프로세스들, 및 컴퓨터 판독가능 매체들이 개시된다. 이미지 데이터를 프로세싱하는 방법은, 이전에 캡처된 이미지의 깊이 맵에 기초하여, 제1 객체까지의 제1 거리 및 제2 객체까지의 제2 거리를 결정하는 단계; 제1 거리 및 제2 거리를 사용하여 적어도 부분적으로 카메라 렌즈의 포커스 포인트를 식별하는 단계; 포커스 포인트를 캡처에 대한 기초로서 사용하여 이미지를 캡처하는 단계 - 이미지는 제1 객체에 대응하는 제1 영역 및 제2 객체에 대응하는 제2 영역을 포함함 -; 및 점상 강도 분포 함수(point spread function, PSF)를 사용하여 제1 영역 또는 제2 영역 중 적어도 하나를 향상시킴으로써 적어도 부분적으로 이미지로부터 제2 이미지를 생성하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.10.05</internationOpenDate><internationOpenNumber>WO2023192706</internationOpenNumber><internationalApplicationDate>2023.02.01</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/061787</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지를 캡처하기 위한 방법으로서,이전에 캡처된 이미지의 깊이 맵에 기초하여, 제1 객체까지의 제1 거리 및 제2 객체까지의 제2 거리를 결정하는 단계;상기 제1 거리 및 상기 제2 거리를 사용하여 적어도 부분적으로 카메라 렌즈의 포커스 포인트를 식별하는 단계;상기 포커스 포인트를 상기 캡처에 대한 기초로서 사용하여 이미지를 캡처하는 단계 - 상기 이미지는 상기 제1 객체에 대응하는 제1 영역 및 상기 제2 객체에 대응하는 제2 영역을 포함함 -; 및점상 강도 분포 함수(point spread function, PSF)를 사용하여 상기 제1 영역 또는 상기 제2 영역 중 적어도 하나를 향상(enhance)시킴으로써 적어도 부분적으로 상기 이미지로부터 제2 이미지를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 객체와 상기 포커스 포인트 사이의 거리 및 상기 제2 객체와 상기 포커스 포인트 사이의 거리 중 적어도 하나에 기초하여 상기 PSF를 선택하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 PSF는 룩업 테이블로부터 선택되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 룩업 테이블은 디포커싱된 이미지들 및 상기 디포커싱된 이미지들을 보정하기 위한 손실 함수를 사용하여 트레이닝된 머신 러닝(machine learning, ML) 모델을 사용하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 룩업 테이블은 디포커싱된 이미지들로부터 결정된 컴퓨터 비전 기반 PSF 추정치 및 에러 계산을 사용하여, 그리고 각각의 초점 거리 및 각각의 블러 양에 대해 최소 에러가 식별될 때까지 상기 컴퓨터 비전 기반 PSF 추정치를 반복적으로 수정하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 PSF에 기초하여 상기 제1 영역 또는 상기 제2 영역 중 적어도 하나를 향상시키는 것은,상기 PSF에 기초하여 상기 제1 영역에 디콘볼루션 연산을 적용함으로써 적어도 부분적으로 수정된 제1 영역을 생성하는 것; 및상기 PSF에 기초하여 상기 제2 영역에 디콘볼루션 연산을 적용함으로써 적어도 부분적으로 수정된 제2 영역을 생성하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 제1 객체는 제1 인물의 얼굴이고, 상기 제2 객체는 제2 인물의 얼굴인, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 제1 거리 및 상기 제2 거리를 사용하여 적어도 부분적으로 상기 포커스 포인트를 식별하는 단계는,상기 제1 객체와 연관된 제1 피사계 심도(depth of field) 및 상기 제2 객체와 연관된 제2 피사계 심도를 결정하는 단계; 및상기 포커스 포인트를 상기 제1 피사계 심도와 상기 제2 피사계 심도 사이의 지점으로서 식별하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 제1 피사계 심도는 상기 제1 객체와 연관된 깊이에 기초하여 룩업 테이블을 사용하여 결정되고, 상기 제2 피사계 심도는 상기 제2 객체와 연관된 깊이에 기초하여 상기 룩업 테이블을 사용하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>10. 이미지를 캡처하기 위한 방법으로서,객체의 포커스 포인트를 식별하는 단계;상기 포커스 포인트를 상기 캡처에 대한 기초로서 사용하여 제1 이미지를 캡처하는 단계 - 상기 제1 이미지는 광학적 변형으로 인해 열화된 제1 영역을 포함함 -;상기 포커스 포인트 및 상기 광학적 변형에 기초하여 점상 강도 분포 함수(PSF)를 추정하는 단계; 및상기 PSF를 사용하여 상기 제1 이미지의 상기 제1 영역을 향상시킴으로써 적어도 부분적으로 상기 제1 이미지로부터 제2 이미지를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 PSF에 기초하여 상기 광학적 변형의 타입을 결정하는 단계 - 상기 변형의 타입은 광학적 설정과 연관된 수차(aberration), 상기 객체의 모션, 또는 기울기 중 적어도 하나를 포함함 - 를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 제1 영역을 향상시킴으로써 적어도 부분적으로 상기 제1 이미지로부터 상기 제2 이미지를 생성하는 단계는,상기 PSF에 대응하는 상기 객체의 결정된 모션에 기초하여 상기 제1 영역을 향상시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 제1 영역을 향상시킴으로써 적어도 부분적으로 상기 제1 이미지로부터 상기 제2 이미지를 생성하는 단계는,기울기의 중심점 및 상기 기울기와 연관된 기울기 PSF에 기초하여 상기 제1 이미지의 상기 제1 영역을 향상시키는 단계; 및상기 중심점 및 상기 기울기와 연관된 상기 기울기 PSF에 기초하여 상기 제1 이미지의 제2 영역을 향상시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서, 상기 제1 영역을 향상시킴으로써 적어도 부분적으로 상기 제1 이미지로부터 상기 제2 이미지를 생성하는 단계는,상기 제1 이미지를 갭처하기 위해 사용된 광학적 설정에 기초하여 상기 제1 이미지의 상기 제1 영역을 향상시키는 단계 - 상기 광학적 설정은 렌즈의 타입 또는 상기 렌즈의 조리개 크기 중 하나를 포함함 - 를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 이미지를 캡처하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 이전에 캡처된 이미지의 깊이 맵에 기초하여, 제1 객체까지의 제1 거리 및 제2 객체까지의 제2 거리를 결정하도록; 상기 제1 거리 및 상기 제2 거리를 사용하여 적어도 부분적으로 카메라 렌즈의 포커스 포인트를 식별하도록; 상기 포커스 포인트를 상기 캡처에 대한 기초로서 사용하여 이미지를 캡처하도록 - 상기 이미지는 상기 제1 객체에 대응하는 제1 영역 및 상기 제2 객체에 대응하는 제2 영역을 포함함 -; 그리고 점상 강도 분포 함수(PSF)를 사용하여 상기 제1 영역 또는 상기 제2 영역 중 적어도 하나를 향상시킴으로써 적어도 부분적으로 상기 이미지로부터 제2 이미지를 생성하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 적어도 하나의 프로세서는,상기 제1 객체와 상기 포커스 포인트 사이의 거리 및 상기 제2 객체와 상기 포커스 포인트 사이의 거리 중 적어도 하나에 기초하여 상기 PSF를 선택하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 PSF는 룩업 테이블로부터 선택되는, 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 룩업 테이블은 디포커싱된 이미지들 및 상기 디포커싱된 이미지들을 보정하기 위한 손실 함수를 사용하여 트레이닝된 머신 러닝(ML) 모델을 사용하여 결정되는, 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 룩업 테이블은 디포커싱된 이미지들로부터 결정된 컴퓨터 비전 기반 PSF 추정치 및 에러 계산을 사용하여, 그리고 각각의 초점 거리 및 각각의 블러 양에 대해 최소 에러가 식별될 때까지 상기 컴퓨터 비전 기반 PSF 추정치를 반복적으로 수정하여 결정되는, 장치.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서, 상기 적어도 하나의 프로세서는,상기 PSF에 기초하여 상기 제1 영역에 디콘볼루션 연산을 적용함으로써 적어도 부분적으로 수정된 제1 영역을 생성하도록; 그리고상기 PSF에 기초하여 상기 제2 영역에 디콘볼루션 연산을 적용함으로써 적어도 부분적으로 수정된 제2 영역을 생성하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>21. 제15항에 있어서, 상기 제1 객체는 제1 인물의 얼굴이고, 상기 제2 객체는 제2 인물의 얼굴인, 장치.</claim></claimInfo><claimInfo><claim>22. 제15항에 있어서, 상기 적어도 하나의 프로세서는,상기 제1 객체와 연관된 제1 피사계 심도 및 상기 제2 객체와 연관된 제2 피사계 심도를 결정하도록; 그리고상기 포커스 포인트를 상기 제1 피사계 심도와 상기 제2 피사계 심도 사이의 지점으로서 식별하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 제1 피사계 심도는 상기 제1 객체와 연관된 깊이에 기초하여 룩업 테이블을 사용하여 결정되고, 상기 제2 피사계 심도는 상기 제2 객체와 연관된 깊이에 기초하여 상기 룩업 테이블을 사용하여 결정되는, 장치.</claim></claimInfo><claimInfo><claim>24. 이미지를 캡처하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 객체의 포커스 포인트를 식별하도록; 상기 포커스 포인트를 상기 캡처에 대한 기초로서 사용하여 제1 이미지를 캡처하도록 - 상기 제1 이미지는 광학적 변형으로 인해 블러링된 제1 영역을 포함함 -; 상기 포커스 포인트 및 상기 광학적 변형에 기초하여 점상 강도 분포 함수(PSF)를 추정하도록; 그리고 상기 PSF를 사용하여 상기 제1 이미지의 제1 영역을 향상시킴으로써 적어도 부분적으로 상기 제1 이미지로부터 제2 이미지를 생성하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 적어도 하나의 프로세서는,상기 PSF에 기초하여 상기 광학적 변형의 타입을 결정하도록 - 상기 변형의 타입은 광학적 설정과 연관된 수차, 상기 객체의 모션, 또는 기울기 중 적어도 하나를 포함함 - 구성되는, 장치.</claim></claimInfo><claimInfo><claim>26. 제24항에 있어서, 상기 적어도 하나의 프로세서는,상기 PSF에 대응하는 상기 객체의 결정된 모션에 기초하여 상기 제1 영역을 향상시키도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>27. 제24항에 있어서, 상기 적어도 하나의 프로세서는,기울기의 중심점 및 상기 기울기와 연관된 기울기 PSF에 기초하여 상기 제1 이미지의 상기 제1 영역을 향상시키도록; 그리고상기 중심점 및 상기 기울기와 연관된 상기 기울기 PSF에 기초하여 상기 제1 이미지의 제2 영역을 향상시키도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>28. 제24항에 있어서, 상기 적어도 하나의 프로세서는,상기 제1 이미지를 갭처하기 위해 사용된 광학적 설정에 기초하여 상기 제1 이미지의 상기 제1 영역을 향상시키도록 - 상기 광학적 설정은 렌즈의 타입 또는 상기 렌즈의 조리개 크기 중 하나를 포함함 - 구성되는, 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980798710</code><country>미국</country><engName>QUALCOMM INCORPORATED</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>FENG, Wen-Chun</engName><name>펑, 웬-춘</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>CHIU, Su-Chin</engName><name>치우, 수-친</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>LAI, Yu-Ren</engName><name>라이, 위-런</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>LIAW, Hang-Wei</engName><name>리우, 항-웨이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아주...</address><code> </code><country> </country><engName>SU, Jian-Jia</engName><name>수, 지안-지아</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.31</priorityApplicationDate><priorityApplicationNumber>17/710,774</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.30</receiptDate><receiptNumber>1-1-2024-0954587-64</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.11.04</receiptDate><receiptNumber>1-5-2024-0176954-73</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247029348.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938748ee9498cf0b5375a748b140aec1fd0ddc8c7d69bcc13f681de8c985186000d8c6876240ac30ab8fe72e799c7e71f7d290f677fcd72de1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf8150738a0aa920caab2e14a4103baed0feada1acc763e70efd8065762082edb2379cde3a6fdfe0a4ed3564a0c62e0d39ecf01adee24b05bd</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>