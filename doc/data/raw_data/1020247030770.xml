<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:13.4013</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7030770</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 세그먼트화를 대화형으로 정의함</inventionTitle><inventionTitleEng>INTERACTIVELY DEFINING AN OBJECT SEGMENTATION</inventionTitleEng><openDate>2024.10.15</openDate><openNumber>10-2024-0150481</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.09.12</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 객체를 세그먼트화하기 위한 동작들을 수행하기 위한 방법들 및 시스템들이 개시된다. 이러한 동작들은 제1 객체의 묘사를 포함하는 이미지를 수신하는 동작; 제1 세그먼트화 데이터세트를 수신하는 동작; 이미지에서 묘사되는 제1 객체의 제1 세그먼트화를 추정하기 위해 제1 세그먼트화 데이터세트 및 이미지에 제1 머신 학습 기술을 적용하는 동작; 제1 객체의 추정된 제1 세그먼트화 및 추정된 제1 세그먼트화에 대한 정정을 포함하는 제2 세그먼트화 데이터세트를 생성하는 동작; 이미지에서 묘사되는 제1 객체의 제2 세그먼트화를 추정하기 위해 제2 세그먼트화 데이터세트 및 이미지에 제1 머신 학습 기술을 적용하는 동작; 및 제1 객체의 추정된 제2 세그먼트화에 기초하여 이미지에 증강 현실 경험을 적용하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.08.17</internationOpenDate><internationOpenNumber>WO2023154544</internationOpenNumber><internationalApplicationDate>2023.02.14</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/012994</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 제1 객체의 묘사를 포함하는 이미지를 수신하는 단계;제1 세그먼트화 데이터세트를 수신하는 단계;상기 이미지에서 묘사되는 상기 제1 객체의 제1 세그먼트화를 추정하기 위해 상기 제1 세그먼트화 데이터세트 및 상기 이미지에 제1 머신 학습 기술을 적용하는 단계;상기 제1 객체의 상기 추정된 제1 세그먼트화 및 상기 추정된 제1 세그먼트화에 대한 정정을 포함하는 제2 세그먼트화 데이터세트를 생성하는 단계;상기 이미지에서 묘사되는 상기 제1 객체의 제2 세그먼트화를 추정하기 위해 상기 제2 세그먼트화 데이터세트 및 상기 이미지에 상기 제1 머신 학습 기술을 적용하는 단계; 및상기 제1 객체의 추정된 제2 세그먼트화에 기초하여 상기 이미지에 증강 현실 경험을 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 추가로,상기 이미지에서 묘사되는 복수의 객체들을 검출하는 단계;복수의 시각적 표시자들로 하여금 상기 복수의 객체들 각각과 관련하여 디스플레이되게 하는 단계; 및상기 복수의 시각적 표시자들 중 주어진 시각적 표시자를 선택하는 입력을 수신하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 주어진 시각적 표시자를 선택하는 입력을 수신하는 것에 응답하여 상기 제1 객체의 상기 제1 세그먼트화를 추정하기 위해 상기 제1 머신 학습 기술이 적용되는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 추가로,상기 제1 객체의 묘사를 포함하는 영역의 하나 이상의 식별자를 포함하는 입력을 수신하는 것에 응답하여 상기 제1 세그먼트화 데이터세트를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 추가로,상기 제2 세그먼트화 데이터세트를 생성하기 위해 상기 제1 객체의 상기 제1 세그먼트화에 대한 상기 정정을 명시하는 입력을 수신하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 입력은 하나 이상의 포지티브 정정 또는 하나 이상의 네거티브 정정 중 적어도 하나를 포함하고, 상기 하나 이상의 포지티브 정정은 상기 제1 객체의 묘사를 포함하는 상기 이미지의 제1 부분을 표현하고, 상기 하나 이상의 네거티브 정정은 상기 제1 객체의 묘사를 제외한 상기 이미지의 제2 부분을 표현하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 동작들을 수행하는 것에 의해 상기 제1 머신 학습 기술을 트레이닝하는 단계를 추가로 포함하고, 상기 동작들은,제1 트레이닝 데이터세트를 수신하는 동작- 상기 제1 트레이닝 데이터세트는 제1 트레이닝 객체를 포함하는 제1 트레이닝 이미지 및 상기 제1 트레이닝 객체의 실측 정보 세그먼트화를 포함함 -;제1 트레이닝 세그먼트화 데이터를 생성하기 위해 상기 제1 트레이닝 객체를 포함하는 상기 제1 트레이닝 이미지의 제1 부분으로부터 객체 픽셀들을 랜덤하게 샘플링하는 동작;상기 제1 트레이닝 세그먼트화 데이터에, 상기 제1 트레이닝 객체를 제외한 상기 제1 트레이닝 이미지의 픽셀들의 식별자들을 추가하는 동작;상기 제1 트레이닝 이미지에서 묘사되는 상기 제1 트레이닝 객체의 트레이닝 세그먼트화를 추정하기 위해 상기 제1 트레이닝 세그먼트화 데이터세트 및 상기 제1 트레이닝 이미지에 상기 제1 머신 학습 기술을 적용하는 동작;상기 제1 트레이닝 객체의 상기 트레이닝 세그먼트화와 상기 실측 정보 세그먼트화 사이의 편차를 컴퓨팅하는 동작; 및상기 편차에 기초하여 상기 제1 머신 학습 기술의 하나 이상의 파라미터를 업데이트하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 추가로,복수의 프레임들을 포함하는 비디오를 수신하는 단계- 상기 이미지는 상기 복수의 프레임들 중 제1 프레임을 포함함 -;상기 제1 객체를 묘사하는 상기 복수의 프레임들 중 제2 프레임에 액세스하는 단계; 및상기 제2 프레임에서 묘사되는 상기 제1 객체의 제3 세그먼트화를 추정하기 위해 상기 제2 프레임 및 상기 제1 객체의 상기 제2 추정된 세그먼트화에 제2 머신 학습 기술을 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 제1 머신 학습 기술은 세그먼트화 네트워크를 포함하고, 상기 제2 머신 학습 기술은 전파 네트워크를 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제8항 또는 제9항에 있어서, 동작들을 수행하는 것에 의해 상기 제2 머신 학습 기술을 트레이닝하는 단계를 추가로 포함하고, 상기 동작들은,제1 트레이닝 데이터세트를 수신하는 동작- 상기 제1 트레이닝 데이터세트는 제1 트레이닝 객체를 포함하는 제1 트레이닝 비디오 및 상기 제1 트레이닝 객체의 실측 정보 세그먼트화를 포함함 -;상기 트레이닝 비디오의 제1 트레이닝 프레임에 기초하여 생성되는 상기 제1 트레이닝 객체의 세그먼트화를 수신하는 동작;상기 제2 트레이닝 프레임에서 묘사되는 상기 제1 객체의 트레이닝 세그먼트화를 추정하기 위해 제2 트레이닝 프레임 및 상기 제1 트레이닝 객체의 세그먼트화에 제2 머신 학습 기술을 적용하는 단계;상기 제2 트레이닝 프레임에서 묘사되는 상기 제1 트레이닝 객체의 상기 트레이닝 세그먼트화와 상기 실측 정보 세그먼트화 사이의 편차를 컴퓨팅하는 동작; 및상기 편차에 기초하여 상기 제2 머신 학습 기술의 하나 이상의 파라미터를 업데이트하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제8항 내지 제10항 중 어느 한 항에 있어서, 상기 제1 트레이닝 객체의 세그먼트화는 상기 제1 트레이닝 프레임을 사용하여 생성되는 세그먼트화 데이터와 함께 상기 제1 트레이닝 프레임에 상기 제1 머신 학습 기술을 적용하는 것에 의해 생성되는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 이미지에 상기 증강 현실 경험을 적용하는 단계는 상기 제1 객체의 추정된 제2 세그먼트화에 기초하여 상기 이미지로부터 상기 제1 객체의 묘사를 제거하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 추가로,상기 제1 객체의 묘사가 제거된 상기 이미지의 부분에서 상기 제1 객체의 배경을 재구성하기 위해 인페인팅을 수행하는 단계; 및상기 이미지로부터 상기 제1 객체의 묘사를 제거한 후에 상기 이미지에 하나 이상의 증강 현실 엘리먼트를 추가하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 상기 이미지에 상기 증강 현실 경험을 적용하는 단계는 상기 제1 객체의 추정된 제2 세그먼트화에 기초하여 상기 이미지에서 묘사되는 상기 제1 객체의 시각적 속성을 수정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 이미지에 상기 증강 현실 경험을 적용하는 단계는, 상기 제1 객체의 추정된 제2 세그먼트화에 대응하는 상기 이미지의 부분을 크롭핑하는 단계; 및상기 크롭핑된 부분을 포함하는 새로운 이미지를 생성하기 위해 상기 이미지의 크롭핑된 부분을 저장하거나 또는 상기 크롭핑된 부분을 포함하는 메시지를 수신자에게 전송하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 이미지에 상기 증강 현실 경험을 적용하는 단계는 상기 제1 객체의 추정된 제2 세그먼트화에 기초하여 상기 제1 객체에 대한 경계 박스를 생성하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 제2 세그먼트화 데이터세트를 생성하기 위해 상기 추정된 제1 세그먼트화로 하여금 상기 이미지와 함께 클라이언트 디바이스 상에 디스플레이되게 하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 시스템으로서,클라이언트 디바이스의 프로세서; 및명령어들을 저장한 메모리 컴포넌트를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하고, 상기 동작들은,제1 객체의 묘사를 포함하는 이미지를 수신하는 동작;제1 세그먼트화 데이터세트를 수신하는 동작;상기 이미지에서 묘사되는 상기 제1 객체의 제1 세그먼트화를 추정하기 위해 상기 제1 세그먼트화 데이터세트 및 상기 이미지에 제1 머신 학습 기술을 적용하는 동작;상기 제1 객체의 상기 추정된 제1 세그먼트화 및 상기 추정된 제1 세그먼트화에 대한 정정을 포함하는 제2 세그먼트화 데이터세트를 생성하는 동작;상기 이미지에서 묘사되는 상기 제1 객체의 제2 세그먼트화를 추정하기 위해 상기 제2 세그먼트화 데이터세트 및 상기 이미지에 상기 제1 머신 학습 기술을 적용하는 동작; 및상기 제1 객체의 추정된 제2 세그먼트화에 기초하여 상기 이미지에 증강 현실 경험을 적용하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 추가로,상기 이미지에서 묘사되는 복수의 객체들을 검출하는 동작;복수의 시각적 표시자들로 하여금 상기 복수의 객체들 각각의 위에 디스플레이되게 하는 동작; 및상기 제1 객체의 위에 디스플레이되는 상기 복수의 시각적 표시자들 중 주어진 시각적 표시자를 선택하는 입력을 수신하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 저장한 비-일시적 컴퓨터-판독가능 저장 매체로서, 상기 명령어들은, 클라이언트 디바이스의 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 동작들을 수행하게 하고, 상기 동작들은제1 객체의 묘사를 포함하는 이미지를 수신하는 동작;제1 세그먼트화 데이터세트를 수신하는 동작;상기 이미지에서 묘사되는 상기 제1 객체의 제1 세그먼트화를 추정하기 위해 상기 제1 세그먼트화 데이터세트 및 상기 이미지에 제1 머신 학습 기술을 적용하는 동작;상기 제1 객체의 상기 추정된 제1 세그먼트화 및 상기 추정된 제1 세그먼트화에 대한 정정을 포함하는 제2 세그먼트화 데이터세트를 생성하는 동작;상기 이미지에서 묘사되는 상기 제1 객체의 제2 세그먼트화를 추정하기 위해 상기 제2 세그먼트화 데이터세트 및 상기 이미지에 상기 제1 머신 학습 기술을 적용하는 동작; 및상기 제1 객체의 추정된 제2 세그먼트화에 기초하여 상기 이미지에 증강 현실 경험을 적용하는 동작을 포함하는 비-일시적 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BEN BARUCH, Shani</engName><name>벤 바루크, 샤니</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>MISHIN SHUVI, Ma'ayan</engName><name>미신 슈비, 마아얀</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>DUDOVITCH, Gal</engName><name>두도비치, 갈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ASSOULINE, Avihay</engName><name>아술린, 아비하이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BERGER, Itamar</engName><name>베르거, 이타마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>SASSON, Gal</engName><name>사슨, 갈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.02.14</priorityApplicationDate><priorityApplicationNumber>17/650,918</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.09.12</receiptDate><receiptNumber>1-1-2024-1005320-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.09.12</receiptDate><receiptNumber>1-1-2024-1006583-81</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.20</receiptDate><receiptNumber>1-5-2024-0151823-71</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247030770.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934cb379fa631e130760146ce9f03cd3c0692d73d2bb0f25b2f6024b25cf6466e0af741501fe6422651dc5bd49ce3559c4aab79c48f9043570</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfcb7e719508a7bbaf12659598308689f98ea1fa76d28830d37da1a92edb28327973028b20db9daa0fdafd7ca90b57434bc3c487e43f603a6c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>