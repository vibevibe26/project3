<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:14:55.1455</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.01.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7031370</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전체적인 비디오 이해를 위한 비디오 모델의 적응적 사용</inventionTitle><inventionTitleEng>ADAPTIVE USE OF VIDEO MODELS FOR HOLISTIC VIDEO UNDERSTANDING</inventionTitleEng><openDate>2023.11.30</openDate><openNumber>10-2023-0163382</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.01.13</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.09.13</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/21</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/042</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/049</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/57</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전체적인 비디오 이해를 수행하기 위한 시스템들 및 기술들이 제공된다. 예를 들어, 프로세스는 제1 비디오를 획득하는 단계, 및 기계 학습 모델 결정 엔진을 사용하여, 제1 비디오의 적어도 일부를 프로세싱하기 위해 사용할 기계 학습 모델들의 세트로부터 제1 기계 학습 모델을 결정하는 단계를 포함할 수 있다. 제1 기계 학습 모델은 제1 비디오의 적어도 일부의 하나 이상의 특성들에 기초하여 결정될 수 있다. 프로세스는 제1 기계 학습 모델을 사용하여 제1 비디오의 적어도 일부를 처리하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.10.06</internationOpenDate><internationOpenNumber>WO2022211891</internationOpenNumber><internationalApplicationDate>2022.01.27</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/014137</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 데이터를 프로세싱하기 위한 장치로서,메모리; 및상기 메모리에 커플링된 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은,제 1 비디오를 획득하고;기계 학습 모델 결정 엔진을 사용하여, 기계 학습 모델들의 세트로부터, 상기 제 1 비디오의 적어도 일부의 하나 이상의 특성들(characteristics)에 기초하여 결정되는 제 1 기계 학습 모델을 결정하고; 그리고상기 제 1 기계 학습 모델을 사용하여 상기 제 1 비디오의 적어도 상기 일부를 프로세싱하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은,상기 제 1 기계 학습 모델을 사용하여 상기 제 1 비디오의 적어도 상기 일부를 프로세싱하는 것에 기초하여 상기 제 1 비디오의 적어도 상기 일부의 분류를 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은,상기 제 1 기계 학습 모델을 사용하여, 상기 제 1 비디오의 적어도 상기 일부로부터 제 1 의 하나 이상의 특징들(features)을 추출하고;제 1 보충 모델을 사용하여, 상기 제 1 의 하나 이상의 특징들을 프로세싱하고; 그리고상기 제 1 보충 모델을 사용하여 상기 제 1 의 하나 이상의 특징들을 프로세싱하는 것에 기초하여, 상기 제 1 비디오의 적어도 상기 일부의 제 1 분류를 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 제 1 보충 모델은 1차원 컨볼루션 신경망(CNN)을 포함하고;상기 제 1 의 하나 이상의 특징들은 상기 제 1 비디오의 적어도 상기 일부의 제 1 프레임에 기초한 제 1 특징 벡터 및 상기 제 1 비디오의 적어도 상기 일부의 제 2 프레임에 기초한 제 2 특징 벡터를 포함하고;상기 제 1 보충 모델은 적어도 상기 제 1 특징 벡터 및 제 2 특징 벡터로부터 상기 제 1 비디오의 적어도 상기 일부의 시간(temporal) 정보를 생성하는, 장치.</claim></claimInfo><claimInfo><claim>5. 제 3 항에 있어서, 상기 제 1 보충 모델은 다층 퍼셉트론(multi-layer perceptron)을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>6. 제 3 항에 있어서, 상기 제 1 보충 모델은 그래프 컨볼루션 네트워크(graph convolutional network)를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>7. 제 3 항에 있어서, 상기 제 1 보충 모델은 논-로컬 모델(non-local model)을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은,상기 기계 학습 모델 결정 엔진을 사용하여, 상기 기계 학습 모델들의 세트로부터, 상기 제 1 비디오의 적어도 다른 일부의 하나 이상의 특성들에 기초하여 결정되는 제 2 기계 학습 모델을 결정하고; 그리고상기 제 2 기계 학습 모델을 사용하여 상기 제 1 비디오의 적어도 상기 다른 일부를 프로세싱하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서, 상기 하나 이상의 프로세서들은,상기 제 2 기계 학습 모델을 사용하여, 상기 제 1 비디오의 적어도 상기 다른 일부로부터 제 2 의 하나 이상의 특징들을 추출하고;제 2 보충 모델을 사용하여, 상기 제 2 의 하나 이상의 특징들을 프로세싱하고; 그리고상기 제 2 보충 모델을 사용하여 상기 제 2 의 하나 이상의 특징들을 프로세싱하는 것에 기초하여, 상기 제 1 비디오의 적어도 상기 다른 일부의 제 2 분류를 결정하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>10. 제 1 항에 있어서, 상기 제 1 기계 학습 모델은 2차원(2D) CNN 을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서, 상기 2D CNN 은 2개의 공간 차원들로 상기 제 1 비디오의 적어도 상기 일부로부터 제 1 의 하나 이상의 특징들을 추출하는, 장치.</claim></claimInfo><claimInfo><claim>12. 제 1 항에 있어서, 상기 제 1 기계 학습 모델은 3차원(3D) CNN 을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서, 상기 3D CNN 은 2개의 공간 차원들 및 시간 차원으로 상기 제 1 비디오의 적어도 상기 일부로부터 제 1 의 하나 이상의 특징들을 추출하는, 장치.</claim></claimInfo><claimInfo><claim>14. 제 1 항에 있어서, 상기 하나 이상의 프로세서들은,제 2 비디오를 획득하고;상기 기계 학습 모델 결정 엔진을 사용하여, 상기 기계 학습 모델들의 세트로부터, 상기 제 2 비디오의 적어도 일부의 하나 이상의 특성들에 기초하여 결정되는 제 2 기계 학습 모델을 결정하고; 그리고상기 제 2 기계 학습 모델을 사용하여 상기 제 2 비디오의 적어도 상기 일부를 프로세싱하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>15. 제 1 항에 있어서, 상기 기계 학습 모델 결정 엔진은 상기 제 1 기계 학습 모델과 공통 신경망을 공유하고, 상기 하나 이상의 프로세서들은,상기 제 1 기계 학습 모델을 사용하여, 상기 제 1 비디오의 적어도 상기 일부를 프로세싱하기 위해 사용할 상기 기계 학습 모델들의 세트로부터 상기 제 1 기계 학습 모델을 결정하는 것과 병행하여 상기 제 1 비디오의 적어도 상기 일부로부터 제 1 의 하나 이상의 특징들을 추출하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>16. 제 1 항에 있어서, 상기 제 1 비디오의 적어도 상기 일부의 상기 하나 이상의 특성들은 공간적 및 시간적 특성들을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>17. 제 1 항에 있어서, 상기 제 1 비디오의 적어도 상기 일부의 상기 하나 이상의 특성들은 오디오 특성들을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>18. 비디오 데이터를 프로세싱하는 방법으로서,제 1 비디오를 획득하는 단계;기계 학습 모델 결정 엔진을 사용하여, 기계 학습 모델들의 세트로부터, 상기 제 1 비디오의 적어도 일부의 하나 이상의 특성들에 기초하여 결정되는 제 1 기계 학습 모델을 결정하는 단계; 및상기 제 1 기계 학습 모델을 사용하여 상기 제 1 비디오의 적어도 상기 일부를 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서, 상기 제 1 기계 학습 모델을 사용하여 상기 제 1 비디오의 적어도 상기 일부를 프로세싱하는 것에 기초하여 상기 제 1 비디오의 적어도 상기 일부의 분류를 결정하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>20. 제 18 항에 있어서, 추가로상기 제 1 기계 학습 모델을 사용하여, 상기 제 1 비디오의 적어도 상기 일부로부터 제 1 의 하나 이상의 특징들을 추출하는 단계;제 1 보충 모델을 사용하여, 상기 제 1 의 하나 이상의 특징들을 프로세싱하는 단계; 및상기 제 1 보충 모델을 사용하여 상기 제 1 의 하나 이상의 특징들을 프로세싱하는 것에 기초하여, 상기 제 1 비디오의 적어도 상기 일부의 제 1 분류를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서,:상기 제 1 보충 모델은 1차원 CNN을 포함하고;상기 제 1 의 하나 이상의 특징들은 상기 제 1 비디오의 제 1 프레임에 기초한 제 1 특징 벡터 및 상기 제 1 비디오의 제 2 프레임에 기초한 제 2 특징 벡터를 포함하고;상기 제 1 보충 모델은 적어도 상기 제 1 특징 벡터 및 제 2 특징 벡터로부터 상기 제 1 비디오의 적어도 상기 일부의 시간 정보를 생성하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제 18 항에 있어서, 추가로상기 기계 학습 모델 결정 엔진을 사용하여, 상기 기계 학습 모델들의 세트로부터, 상기 제 1 비디오의 적어도 다른 일부의 하나 이상의 특성들에 기초하여 결정되는 제 2 기계 학습 모델을 결정하는 단계; 및상기 제 2 기계 학습 모델을 사용하여 상기 제 1 비디오의 적어도 상기 다른 일부를 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제 22 항에 있어서, 추가로상기 제 2 기계 학습 모델을 사용하여, 상기 제 1 비디오의 적어도 상기 다른 일부로부터 제 2 의 하나 이상의 특징들을 추출하는 단계;제 2 보충 모델을 사용하여, 상기 제 2 의 하나 이상의 특징들을 프로세싱하는 단계; 및상기 제 2 보충 모델을 사용하여 상기 제 2 의 하나 이상의 특징들을 프로세싱하는 것에 기초하여, 상기 제 1 비디오의 적어도 상기 다른 일부의 제 2 분류를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 제 18 항에 있어서, 상기 제 1 기계 학습 모델을 사용하여, 상기 제 1 비디오의 적어도 상기 일부를 프로세싱하기 위해 사용할 상기 기계 학습 모델들의 세트로부터 상기 제 1 기계 학습 모델을 결정하는 것과 병행하여 상기 제 1 비디오의 적어도 상기 일부로부터 제 1 의 하나 이상의 특징들을 추출하는 단계를 추가로 포함하고, 상기 기계 학습 모델 결정 엔진은 상기 제 1 기계 학습 모델과 공통 신경망을 공유하는, 방법.</claim></claimInfo><claimInfo><claim>25. 제 18 항에 있어서, 상기 제 1 기계 학습 모델은 2D CNN을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 제 25 항에 있어서, 상기 2D CNN 은 2개의 공간 차원들로 상기 제 1 비디오의 적어도 상기 일부로부터 제 1 의 하나 이상의 특징들을 추출하는, 방법.</claim></claimInfo><claimInfo><claim>27. 제 18 항에 있어서, 상기 제 1 기계 학습 모델은 3D CNN을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제 18 항에 있어서, 추가로제 2 비디오를 획득하는 단계;상기 기계 학습 모델 결정 엔진을 사용하여, 상기 기계 학습 모델들의 세트로부터, 상기 제 2 비디오의 적어도 일부의 하나 이상의 특성들에 기초하여 결정되는 제 2 기계 학습 모델을 결정하는 단계; 및상기 제 2 기계 학습 모델을 사용하여 상기 제 2 비디오의 적어도 상기 일부를 프로세싱하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>29. 제 18 항에 있어서, 상기 제 1 비디오의 적어도 상기 일부의 상기 하나 이상의 특성들은 공간적 및 시간적 특성들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>30. 제 18 항에 있어서, 상기 제 1 비디오의 적어도 상기 일부의 상기 하나 이상의 특성들은 오디오 특성들을 포함하는, 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BEN YAHIA, HAITAM</engName><name>벤 야히아 하이탐</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>GHODRATI, AMIR</engName><name>고드라티 아미르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>JAIN, MIHIR</engName><name>자인 미히르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>HABIBIAN, AMIRHOSSEIN</engName><name>하비비안 아미르호세인</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.03.31</priorityApplicationDate><priorityApplicationNumber>17/219,460</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.09.13</receiptDate><receiptNumber>1-1-2023-1014577-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.11.03</receiptDate><receiptNumber>1-5-2023-0175785-40</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.01.13</receiptDate><receiptNumber>1-1-2025-0046293-83</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.01.13</receiptDate><receiptNumber>1-1-2025-0046294-28</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.01.13</receiptDate><receiptNumber>1-1-2025-0046295-74</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237031370.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93324db56d7d7eace943ff6bd5add7d796acf7e186ffc8efd3ad2ad33a6cc4a1478499eacc3f876955e83e70ac3dd3a827acfc2978ad1ac0c8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4c3cbe017fb8bf2ccbc9382939fb1a4f50c676f1adc7248981ac5bbe9640a3a88be35c6483abb79f21a95d87b9179f1d1ae86cb25c082f53</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>