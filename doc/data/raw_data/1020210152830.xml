<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:35.5335</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0152830</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이동체의 위치를 추정하는 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR ESTIMATING POSITION OF A  MOVING OBJECT</inventionTitleEng><openDate>2023.03.17</openDate><openNumber>10-2023-0038067</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.04</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B60W 40/02</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 전자 장치는, 이동체의 위치를 추정하기 위해, 이동체에 탑재된 촬영 장치로 획득한 주변 영상으로부터, 랜드마크(landmark) 기반 확률 맵(probability map) 형태의 2차원 특징점 정보를 획득하고, 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터, 랜드마크 기반 3차원 특징점 정보를 획득하고, 주변 영상의 2차원 특징점 정보와 고정밀 지도 데이터의 3차원 특징점 정보 중 어느 하나의 차원(dimension)을 다른 하나의 차원으로 변환하고, 주변 영상의 특징점 정보와 고정밀 지도 데이터의 특징점 정보 사이의 대응도(likelihood)를 계산하고, 대응도에 기초하여 이동체의 위치를 추정할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치의 동작 방법에 있어서,이동체에 탑재된 촬영 장치로 획득한 주변 영상으로부터, 랜드마크(landmark) 기반 확률 맵(probability map) 형태의 2차원 특징점 정보를 획득하는 단계;상기 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터, 랜드마크 기반 3차원 특징점 정보를 획득하는 단계;상기 주변 영상의 2차원 특징점 정보와 상기 고정밀 지도 데이터의 3차원 특징점 정보 중 어느 하나의 차원(dimension)을 다른 하나의 차원으로 변환하는 단계;상기 주변 영상의 특징점 정보와 상기 고정밀 지도 데이터의 특징점 정보 사이의 대응도(likelihood)를 계산하는 단계; 및상기 대응도에 기초하여 상기 이동체의 위치를 추정하는 단계를 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 주변 영상의 2차원 특징점 정보는, DNN(deep neural network) 기반의 시맨틱 세그멘테이션(semantic segmentation)에 기초하여 랜드마크에 따라 획득되는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터 상기 3차원 특징점 정보를 획득하는 단계는,상기 이동체의 위치 정보에 기초하여 고정밀 지도 데이터베이스로부터 상기 이동체 주변의 랜드마크에 대한 월드(world) 도메인 상의 3차원 특징점 정보를 수신하는 단계; 및상기 월드 도메인 상의 3차원 특징점 정보를 상기 촬영 장치에 대한 로컬 도메인으로 변환하는 단계를 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 주변 영상의 2차원 특징점 정보와 상기 고정밀 지도 데이터의 3차원 특징점 정보 중 어느 하나의 차원을 다른 하나의 차원으로 변환하는 단계는,역원근 변환법(inverse perspective mapping)에 기초하여, 상기 주변 영상의 2차원 특징점 정보를 3차원 확률 맵 형태로 변환하는 단계를 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 주변 영상의 2차원 특징점 정보와 상기 고정밀 지도 데이터의 3차원 특징점 정보 중 어느 하나의 차원을 다른 하나의 차원으로 변환하는 단계는,원근 변환법(perspective mapping)에 기초하여, 상기 고정밀 지도 데이터의 3차원 특징점 정보를 상기 주변 영상에서 획득한 2차원의 확률 맵으로 투영(project)하는 단계를 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 주변 영상의 특징점 정보와 상기 고정밀 지도 데이터의 특징점 정보 사이의 대응도(likelihood)를 계산하는 단계는,상기 주변 영상에서 획득한 확률 맵에서, 상기 고정밀 지도 데이터의 특징점 정보의 각 랜드마크에 대응하는 확률(probability)을 합산하는 단계; 및상기 각 랜드마크에 대응하여 합산된 확률들을 곱해 상기 대응도를 계산하는 단계를 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 대응도에 기초하여 상기 이동체의 위치를 추정하는 단계는,상기 대응도에 기초하여, 파티클 필터(particle filter) 또는 ML(maximum likelihood) 최적화 방법에 따른 상기 이동체의 위치 추정 결과를 업데이트하는 단계를 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 이동체는 자율 주행 차량 또는 ADAS(advanced driver assistance system)을 지원하는 차량인,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 랜드마크는, 흰색 차선, 노란색 차선, 횡단보도, 과속 방지턱, 교통 신호등 및 교통 표지판 중 적어도 어느 하나를 포함하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 파티클 필터(particle filter) 기반의 이동체의 위치 추정 방법에 있어서,이동체에 탑재된 촬영 장치로 획득한 주변 영상으로부터, 랜드마크(landmark) 기반 확률 맵(probability map) 형태의 2차원 특징점 정보를 획득하는 단계;상기 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터, 랜드마크 기반 3차원 특징점 정보를 획득하는 단계;상기 이동체의 후보 위치들에 대응하는 복수의 파티클(particle) 위치들을 예측하는 단계;상기 복수의 파티클 위치 각각에 대해, 상기 3차원 특징점 정보를 상기 주변 영상에서 획득한 확률 맵으로 투영(project)하는 단계;상기 복수의 파티클 위치 각각에 대해, 상기 확률 맵에 투영된 상기 3차원 특징점 정보와, 상기 확률 맵의 2차원 특징점 정보 사이의 대응도(likelihood)를 계산하는 단계; 및상기 대응도에 기초해 상기 복수의 파티클 위치들을 재배치하여 상기 이동체의 위치를 추정하는 단계를 포함하는,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 2차원 특징점 정보는, DNN(deep neural network) 기반의 시맨틱 세그멘테이션(semantic segmentation)에 기초하여 랜드마크에 따라 획득되는,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터 상기 3차원 특징점 정보를 획득하는 단계는,상기 이동체의 위치 정보에 기초하여 고정밀 지도 데이터베이스로부터 상기 이동체 주변의 랜드마크에 대한 월드(world) 도메인 상의 3차원 특징점 정보를 수신하는 단계; 및상기 월드 도메인 상의 3차원 특징점 정보를 상기 촬영 장치에 대한 로컬 도메인으로 변환하는 단계를 포함하는,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,상기 복수의 파티클 위치들을 예측하는 단계는,이전 시점에서 재배치된 파티클 위치 정보 및 상기 이전 시점부터의 상기 이동체의 이동 변위에 기초하여 상기 복수의 파티클 위치들을 예측하는 단계를 포함하는,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,상기 3차원 특징점 정보는, 원근 변환법(perspective mapping)에 기초하여 상기 주변 영상에서 획득한 2차원의 확률 맵으로 투영(project)되는,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서,상기 확률 맵에 투영된 3차원 특징점 정보와, 상기 확률 맵의 2차원 특징점 정보 사이의 대응도(likelihood)를 계산하는 단계는,상기 확률 맵에서, 상기 투영된 3차원 특징점 정보의 각 랜드마크에 대응하는 확률(probability)을 합산하는 단계; 및상기 각 랜드마크에 대응하여 합산된 확률들을 곱하는 단계를 포함하는,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서,상기 대응도에 기초해 상기 복수의 파티클 위치들을 재배치하여 상기 이동체의 위치를 추정하는 단계는,상기 대응도에 따라 상기 복수의 파티클 위치들 각각에 대해 가중치(weight)를 설정하는 단계;상기 가중치에 따라 상기 복수의 파티클 위치들을 재배치하는 단계; 및상기 재배치된 파티클의 평균값을 계산하여 상기 이동체의 위치를 추정하는 단계를 포함하는,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서,상기 이동체는 자율 주행 차량 또는 ADAS(advanced driver assistance system)을 지원하는 차량인,이동체의 위치 추정 방법.</claim></claimInfo><claimInfo><claim>18. 하드웨어와 결합되어 제1항 내지 제17항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>19. 전자 장치에 있어서,이동체 주변의 고정밀 지도(High Definition Map) 데이터 및 상기 이동체에 탑재된 촬영 장치로 획득한 주변 영상을 수신하는 통신 모듈;컴퓨터로 실행 가능한 명령어들(computer-executable instructions)이 저장된 메모리; 및상기 메모리에 억세스(access)하여 상기 명령어들을 실행하는 프로세서를 포함하고,상기 명령어들은,상기 주변 영상으로부터, 랜드마크(landmark) 기반 확률 맵(probability map) 형태의 2차원 특징점 정보를 획득하고,상기 고정밀 지도 데이터로부터, 랜드마크 기반 3차원 특징점 정보를 획득하고,상기 주변 영상의 2차원 특징점 정보와 상기 고정밀 지도 데이터의 3차원 특징점 정보 중 어느 하나의 차원(dimension)을 다른 하나의 차원으로 변환하고,상기 주변 영상의 특징점 정보와 상기 고정밀 지도 데이터의 특징점 정보 사이의 대응도(likelihood)를 계산하고,상기 대응도에 기초하여 상기 이동체의 위치를 추정하도록 구성되는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 명령어들은,상기 주변 영상에서 획득한 확률 맵에서, 상기 고정밀 지도 데이터의 특징점 정보의 각 랜드마크에 대응하는 확률(probability)을 합산하고,상기 각 랜드마크에 대응하여 합산된 확률들을 곱해 상기 대응도를 계산하도록 구성되는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420210372023</code><country>대한민국</country><engName>Park, Yongkonjong</engName><name>박용곤종</name></inventorInfo><inventorInfo><address>경기도 수원시 권선구...</address><code>420210861854</code><country>대한민국</country><engName>PARK, Hee Won</engName><name>박희원</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170479083</code><country>대한민국</country><engName>JANG, Cheolhun</engName><name>장철훈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2021.09.10</priorityApplicationDate><priorityApplicationNumber>1020210121201</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.11.09</receiptDate><receiptNumber>1-1-2021-1288948-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.04</receiptDate><receiptNumber>1-1-2024-1206328-91</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210152830.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9373c403ef61cb63851121d4eb33dc39864762b99ec6d7c5f562364585f0d7658d9730bda51f85e073d390dd770be442cc10c6bb430707255d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd90e51f3ed8abf748d2d144dbaab5875aaa28603e8be964aeca526e7f1309aae1cf2249614496ae909592058a7e0a84040cfe59e49b0795e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>