<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:18.4118</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.10.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0128468</applicationNumber><claimCount>14</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>GCN 기반의 3차원 객체 인식 및 포즈 추정 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR 3D OBJECT RECOGNITION AND  POSE ESTIMATION BASED ON GRAPH CONVOLUTIONAL NETWORK</inventionTitleEng><openDate>2024.04.16</openDate><openNumber>10-2024-0048762</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.10.07</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/762</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 3차원 객체 인식 및 포즈 추정 장치에서 수행되는 3차원 객체 인식 및 포즈 추정 방법으로서, 포인트 클라우드(Point Cloud)를 입력 받는 단계, 상기 포인트 클라우드로부터 그래프를 구성하는 단계, 상기 그래프에 GCN(Graph Convolutional Network)을 반복 적용하여 객체를 감지하고 포즈를 추정하는 단계, 및 상기 감지한 객체의 바운딩 박스(Bounding Box)를 결정하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 3차원 객체 인식 및 포즈 추정 장치에서 수행되는 3차원 객체 인식 및 포즈 추정 방법에 있어서,포인트 클라우드(Point Cloud)를 입력 받는 단계;상기 포인트 클라우드로부터 그래프를 구성하는 단계;상기 그래프에 GCN(Graph Convolutional Network)을 반복 적용하여 객체를 감지하고 포즈를 추정하는 단계; 및상기 감지한 객체의 바운딩 박스(Bounding Box)를 결정하는 단계를 포함하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 그래프를 구성하는 단계는,상기 포인트 클라우드에서 그래프의 정점이 될 키포인트를 결정하는 단계;상기 키포인트를 연결하여 그래프로 구조화하는 단계; 및상기 구조화한 그래프로부터 인접 행렬 및 특징 행렬을 생성하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 키포인트를 결정하는 단계는,상기 포인트 클라우드의 좌표 최대값을 기초로 공간의 크기를 산출하는 단계;상기 공간의 크기를 기설정된 복셀 크기로 나눠 상기 공간을 분할하는 단계;상기 포인트 클라우드의 각 좌표를 상기 복셀 크기로 나눠 복셀 인덱스를 설정하고 복셀 인덱스에 해당하는 복셀의 위치로 나타내는 단계; 및상기 복셀 인덱스를 기초로 동일한 복셀에 포함되는 포인트 중 랜덤으로 키포인트를 결정하는 단계를 포함하되,상기 복셀 크기는 검출하는 3차원 객체의 크기에 따라 설정되는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 그래프로 구조화하는 단계는,상기 키포인트를 결정된 순서에 따라 주소화하는 단계;상기 키포인트를 객체의 크기가 포함될 수 있는 크기로 설정된 원구 기반의 근접 이웃 탐색 알고리즘을 통해 연결하여 그래프를 구성하는 단계; 및상기 키포인트의 좌표 정보와 주소화 정보를 기초로 키포인트들의 연결 관계를 나타내는 에지 리스트를 생성하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 인접 행렬 및 특징 행렬을 생성하는 단계는,상기 에지 리스트에 키포인트 자신을 연결하는 루프(Loop)를 추가하여 키포인트들 간의 연결 상태를 나타내는 원본 인접 행렬을 생성하는 단계; 및상기 에지 리스트를 기초로 각 키포인트의 에지 개수를 나타내는 차수 행렬을 생성하고 상기 차수 행렬과 상기 원본 인접 행렬의 차를 통해 키포인트들 간의 연결 상태와 상대적인 거리 정보를 나타내는 상대 인접 행렬을 생성하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 인접 행렬 및 특징 행렬을 생성하는 단계는,상기 키포인트의 특징 정보를 기초로 특징 행렬을 생성하는 단계를 포함하되,상기 특징 정보는, 키포인트의 좌표 정보, 키포인트의 RGB 정보, 또는 키포인트에 대한 상대 인접 행렬의 좌표 정보에 해당하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 객체를 감지하고 포즈를 추정하는 단계는,상기 상대 인접 행렬과 상기 특징 행렬을 곱하여 상기 키포인트들 간의 상대적 특성이 반영된 상대적 특징 행렬을 생성하는 단계; 및상기 상대적 특징 행렬과 상기 키포인트의 색상 정보를 다층 신경망(Multi-Layer Perceptrons; MLP)에 적용시켜 새 특징 행렬을 획득하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 객체를 감지하고 포즈를 추정하는 단계는,상기 새 특징 행렬 및 상기 원본 인접 행렬을 곱하는 연산을 특정 횟수 반복하여 인접한 키포인트의 정보가 집계된 연산 산출값을 획득하는 단계;상기 연산 산출값을 다층 신경망에 적용시켜 키포인트의 특징 간 순서에 대한 정보가 제거된 최종 산출값으로 변환하는 단계; 및상기 최종 산출값을 기초로 객체의 클래스 및 바운딩 박스를 예측하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 연산 산출값을 획득하는 단계는,상기 새 특징 행렬 및 원본 인접 행렬을 곱하여 결과값을 획득하는 단계;상기 결과값에 대해 스킵 커넥션(Skip Connection)을 적용하는 단계; 및상기 스킵 커넥션을 적용한 후, 상기 새 특징 행렬 및 원본 인접 행렬을 곱하여 결과값을 획득하는 단계 및 스킵 커넥션을 적용하는 단계를 재수행하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 클래스 및 바운딩 박스를 예측하는 단계는,상기 최종 산출값을 다층 신경망에 적용시켜 각 클래스에 대한 예측값을 생성하는 단계;상기 예측값을 소프트맥스(Softmax)에 적용시켜 각 클래스에 대한 확률값으로 변환하는 단계; 및상기 클래스의 개수만큼 바운딩 박스를 예측하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 바운딩 박스를 결정하는 단계는,상기 감지된 객체에 대해 예측된 바운딩 박스에 대해 쿼터니언 회전을 수행하는 단계; 및상기 예측된 바운딩 박스가 복수개인 경우에는, NMS(Non-Maximum Suppression)을 이용하여 상기 객체에 대한 바운딩 박스를 결정하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 GCN을 학습하는 단계를 더 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 GCN을 학습하는 단계 이전에,상기 그래프를 구성하는 키포인트의 바운딩 박스에 대한 위치에 따라 해당 객체의 클래스 인덱스, 배경 인덱스, 또는 고려 안함 인덱스를 부여하여 클래스 레이블을 생성하는 단계; 및상기 바운딩 박스의 중심 좌표 (x,y,z), 너비, 깊이, 높이, 피치(pitch), 롤(roll), 및 요(yaw) 값을 기초로 박스 레이블을 생성하는 단계를 포함하되,상기 중심 좌표는 상기 바운딩 박스의 중심과 키포인트의 차를 통해 연산된 벡터값에 해당하고, 상기 너비, 깊이, 및 높이는 0과 1 사이의 정규화된 값이고, 상기 피치, 롤, 및 요는 쿼터니언 회전을 통해 변환된 값에 해당하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 GCN을 학습하는 단계는,상기 객체를 감지하기 위한 클래스 학습을 위해, 상기 객체의 실제 클래스와 상기 객체에 대해 예측된 클래스 간의 분포를 기초로 교차 엔트로피를 계산하는 단계; 및상기 객체의 포즈를 추정하기 위한 바운딩 박스 학습을 위해, 상기 객체의 실제 바운딩 박스와 상기 객체에 대해 예측된 바운딩 박스에 후버 손실(Huber loss) 함수를 적용하여 계산하는 단계를 포함하는 것을 특징으로 하는 3차원 객체 인식 및 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>15. 포인트 클라우드를 입력 받는 데이터 입력 모듈;상기 포인트 클라우드로부터 그래프를 구성하는 그래프 변환 모듈;상기 그래프에 GCN을 반복 적용하여 객체를 감지하고 포즈를 추정하는 딥러닝 수행 모듈; 및상기 감지한 객체의 바운딩 박스를 결정하는 박스 관리 모듈을 포함하는 3차원 객체 인식 및 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>16. 컴퓨터 판독 가능 매체에 저장되어 있는 컴퓨터 프로그램에 있어서,상기 컴퓨터 프로그램의 명령이 실행될 경우, 제1항 내지 제14항 중 어느 한 항에 따른 방법이 수행되는 것을 특징으로 하는 컴퓨터 판독 가능 매체에 저장되어 있는 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>부산광역시 강서구...</address><code>120210483291</code><country>대한민국</country><engName>SERDIC, Inc.</engName><name>주식회사 세르딕</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강동구...</address><code> </code><country> </country><engName>Jung, Tae Won</engName><name>정태원</name></inventorInfo><inventorInfo><address>서울특별시 노원구...</address><code> </code><country> </country><engName>Jung, Kye Dong</engName><name>정계동</name></inventorInfo><inventorInfo><address>서울특별시 노원구...</address><code> </code><country> </country><engName>JUNG, Chi Seo</engName><name>정치서</name></inventorInfo><inventorInfo><address>서울특별시 강북구...</address><code> </code><country> </country><engName>KIM, In Seon</engName><name>김인선</name></inventorInfo><inventorInfo><address>서울특별시 노원구...</address><code> </code><country> </country><engName>Yu, Min Su</engName><name>유민수</name></inventorInfo><inventorInfo><address>서울특별시 강북구...</address><code> </code><country> </country><engName>PARK, Chan Soo</engName><name>박찬수</name></inventorInfo><inventorInfo><address>서울특별시 용산구...</address><code> </code><country> </country><engName>KANG, Jin Kyu</engName><name>강진규</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 송파구 법원로 ***, A동 ****호(문정동, 엠스테이트)</address><code>920141000616</code><country>대한민국</country><engName>TNI IP LAW FIRM</engName><name>특허법인 티앤아이</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.10.07</receiptDate><receiptNumber>1-1-2022-1057274-93</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.02.10</receiptDate><receiptNumber>1-1-2023-0156626-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2023.02.10</receiptDate><receiptNumber>1-5-2023-0024005-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.03.10</receiptDate><receiptNumber>1-1-2023-0275993-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.03.13</receiptDate><receiptNumber>1-1-2023-0283454-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.08.20</receiptDate><receiptNumber>4-1-2024-5246868-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.08.30</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2024.09.30</receiptDate><receiptNumber>9-6-2025-0085500-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.05.17</receiptDate><receiptNumber>9-5-2025-0468821-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.07.15</receiptDate><receiptNumber>1-1-2025-0796939-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.07.15</receiptDate><receiptNumber>1-1-2025-0796934-87</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.08.13</receiptDate><receiptNumber>4-1-2025-5224722-86</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.08.28</receiptDate><receiptNumber>4-1-2025-5240400-65</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220128468.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9331a95b292e3220ea4201ab3d8ea4380ef67b56a46c2bf7c7cd68500148d7350cc19386de8c3f2eef4d1f8e9680504d3fe629f7450ca16b88</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfef3d89fddf14f06b8efaf9a6f7824f60be946bf607e45acf9e8b00e754c7664e52ec85766200d0cd714c927946ad7eccc88574b0a8c5fdd0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>