<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:46.4146</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.11.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0155291</applicationNumber><claimCount>57</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>단대단 자체 적응에 기반한 분산식 훈련 방법, 장치, 기기</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR DISTRIBUTED TRAINING BASED  ON END-TO-END ADAPTION, AND DEVICE</inventionTitleEng><openDate>2022.12.06</openDate><openNumber>10-2022-0161234</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.11.18</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 9/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 9/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 9/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 단대단 자체 적응에 기반한 분산식 훈련 방법, 장치, 기기 및 저장 매체를 제공하고, 인공지능 기술 분야에 관한 것으로, 특히 딥러닝, 클라우드 컴퓨팅 등 분야에 관한 것이다. 구체적인 구현 수단은, 훈련할 모델을 분할하여, 분할 결과를 획득하는 단계; 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는 단계 - 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 컴퓨팅 자원의 속성은 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 컴퓨팅 자원의 속성을 이용하여, 컴퓨팅 자원에서 각 분할 결과의 분산 전략을 결정하는 단계; 및 분산 전략에 따라, 컴퓨팅 자원을 이용하여 훈련할 모델에 대해 분산식 훈련하는 단계; 를 포함한다. 모델 훈련의 단대단 자체 적응 조절을 구현할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 단대단 자체 적응에 기반한 분산식 훈련 방법에 있어서,훈련할 모델을 분할하여, 분할 결과를 획득하는 단계; 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는 단계 - 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 상기 컴퓨팅 자원의 속성은 상기 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는 단계; 및상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,훈련할 모델을 분할하여, 분할 결과를 획득하는 단계는, 상기 훈련할 모델의 연산자 및 텐서를 결정하는 단계; 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는 단계는,상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하는 단계 - 상기 N은 양의 정수임 - ; 각 상기 슬라이스에 대해, 상기 슬라이스의 분산식 속성 정보를 로딩하는 단계 - 상기 분산식 속성 정보는 상기 훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스의 분할 매핑 정보, 당해 슬라이스의 슬라이스 크기 정보 중의 적어도 하나를 포함함 - ; 상기 분산식 속성 정보를 로딩하는 슬라이스를 상기 분할 결과로 하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 분산식 속성 정보 카테고리의 결정 방식은,미리 설정된 방식을 이용하여 상기 분산식 속성 정보의 복수 후보 카테고리를 수신하는 단계;상기 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 상기 분산식 속성 정보의 카테고리로 하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,각 상기 슬라이스의 분산식 속성을 이용하여, 각 상기 슬라이스의 배치 정보를 결정하는 단계를 더 포함하고, 상기 배치 정보가 상기 슬라이스와 상기 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 슬라이스가 상기 훈련할 모델의 인접 네트워크층에 위치하고 상기 슬라이스의 배치 정보가 부동할 경우,상기 배치 정보를 이용하여, 통신 보조 연산자를 결정하하는 단계를 포함하고, 상기 통신 보조 연산자가 각 상기 슬라이스 사이의 논리 연산 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우,각 상기 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>8. 제2항에 있어서,상기 분할 전략의 결정 방식은,상기 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>9. 제2항에 있어서,상기 분할 전략의 결정 방식은,미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 컴퓨팅 자원의 속성을 획득하는 단계는, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 상기 하드웨어 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는 단계를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는, 상기 컴퓨팅 자원의 최소 어셈블리를 결정하는 단계 - 상기 최소 어셈블리는 프로세서 또는 메모리를 포함함 - ; 적어도 하나의 상기 최소 어셈블리로 구성된 기계 기기를 결정하는 단계 - 각 상기 기계 기기의 최소 어셈블리는 중복되지 않음 - ; 적어도 하나의 상기 기계 기기로 구성된 클러스터를 결정하는 단계 - 각 상기 클러스터의 기계 기기는 중복되지 않음 - ; 및상기 최소 어셈블리, 상기 기계 기기 및 상기 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하는 단계는,각 상기 최소 어셈블리의 밀접 관계 리스트를 결정하는 단계 - 상기 밀접 관계 리스트는 소스 최소 어셈블리와 목적 최소 어셈블리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함함 - ; 상기 밀접 관계 리스트를 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는 단계; 를 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 또는 제10항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 사용자 단말에 의해 시작된 모델 훈련 요청의 내용 및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 따라 결정되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 또는 제10항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는 단계는,상기 컴퓨팅 자원의 통신 경로를 획득하는 단계; 상기 컴퓨팅 자원의 통신 경로를 이용하여, 각 상기 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축하는 단계; 및상기 통신 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는 단계를 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>16. 제1항에 있어서,상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는 단계는,상기 컴퓨팅 자원에서 각 상기 분할 결과의 후보 분산 전략을 결정하는 단계; 각 상기 후보 분산 전략의 효율을 각각 통계하는 단계; 및각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서,각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계는,미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는 단계; 정렬된 결과에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>18. 제1항에 있어서,상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는 단계는,상기 컴퓨팅 자원의 가용성을 정기적으로 검출하는 단계;검출 결과에 상기 컴퓨팅 자원의 불가용이 존재할 경우, 보완 조치를 수행하는 단계 - 상기 불가용 상황은 컴퓨팅 자원 고장 또는 컴퓨팅 자원 수량의 축소를 포함함 - ; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 불가용 상황이 컴퓨팅 자원 고장일 경우, 상기 보완 조치를 수행하는 단계는, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득하는 단계;상기 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기하는 단계; 및미리 설정된 시간 내에 상기 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 불가용이 컴퓨팅 자원 고장일 경우, 상기 보완 조치를 수행하는 단계는,상기 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정하는 단계;상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는 단계; 를 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서,상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는 단계는,상기 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하는 단계; 상기 훈련 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>22. 제20항에 있어서,상기 후보 컴퓨팅 자원에서 재시행하는 단계는, 훈련의 최초 상태를 획득하는 단계; 상기 최초 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>23. 제18항에 있어서,상기 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 상기 보완 조치를 수행하는 단계는,축소된 상기 컴퓨팅 자원의 제1 수량을 결정하는 단계;상기 제1 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득하는 단계;재결정된 축소 후의 나머지 상기 컴퓨팅 자원의 속성을 이용하여, 축소된 상기 컴퓨팅 자원에서 각 상기 재분할된 제1 결과의 제1 분산 전략을 결정하는 단계; 및상기 제1 분산 전략에 따라, 축소된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>24. 제18항에 있어서,검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우,사용 가능한 상기 여분의 컴퓨팅 자원의 제2 수량을 결정하는 단계;상기 제2 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득하는 단계;다시 결정된 여분의 상기 컴퓨팅 자원의 속성을 이용하여, 확장된 상기 컴퓨팅 자원에서 각 상기 재분할된 제2 결과의 제2 분산 전략을 결정하는 단계; 및상기 제2 분산 전략에 따라, 확장된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는 단계; 를 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>25. 제23항에 있어서,상기 컴퓨팅 자원의 수량이 변화될 경우,변화된 수량에 따라, 상기 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는 단계를 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>26. 제1항에 있어서,상기 분산식 훈련이, 분산 비동기 파이프라인 훈련을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>27. 제1항에 있어서,상기 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>28. 단대단 자체 적응에 기반한 분산식 훈련 장치에 있어서,훈련할 모델을 분할하여, 분할 결과를 획득하는데 사용되는 분할 모듈; 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원을 분석하여, 상기 컴퓨팅 자원의 속성을 획득하는데 사용되는 컴퓨팅 자원의 속성 결정 모듈 - 상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 훈련할 모델의 컴퓨팅 자원 수요, 기타 훈련하고 있는 모델에 의해 점용된 컴퓨팅 자원 및 유휴 컴퓨팅 자원에 의해 결정된 것이고, 상기 컴퓨팅 자원의 속성은 상기 컴퓨팅 자원의 토폴로지 관계, 태스크 처리 능력 중의 적어도 하나를 나타내는데 사용됨 - ; 상기 컴퓨팅 자원의 속성을 이용하여, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 분산 전략을 결정하는데 사용되는 분산 전략 결정 모듈; 및 상기 분산 전략에 따라, 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련하는데 사용되는 분산식 훈련 모듈; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서,상기 분할 모듈은,상기 훈련할 모델의 연산자 및 텐서를 결정하는데 사용되는 연산자 및 텐서의 결정 서브 모듈; 상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, 상기 분할 결과를 획득하는데 사용되는 분할 수행 서브 모듈; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서,상기 분할 수행 서브 모듈은,상기 분할 전략을 이용하여, 상기 훈련할 모델의 연산자 및 텐서를 분할하여, N개의 슬라이스를 획득하는데 사용되는 분할 전략 수행 유닛 - 상기 N은 양의 정수임 - ; 각 상기 슬라이스에 대해, 상기 슬라이스의 분산식 속성 정보를 로딩하는데 사용되는 분산식 속성 정보 로딩 유닛 - 상기 분산식 속성 정보는 상기 훈련할 모델에서 당해 슬라이스의 프로세스 토폴로지 정보, 당해 슬라이스의 분할 매핑 정보, 당해 슬라이스의 슬라이스 크기 정보 중의 적어도 하나를 포함함 - ; 을 포함하고,상기 분산식 속성 정보를 로딩하는 슬라이스를 상기 분할 결과로 하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서,상기 분산식 속성 정보 로딩 유닛은, 미리 설정된 방식을 이용하여 상기 분산식 속성 정보의 복수 후보 카테고리를 수신하는데 사용되는 후보 카테고리 수신 서브 유닛; 상기 복수의 후보 카테고리에서 타겟 카테고리를 결정하여, 상기 분산식 속성 정보의 카테고리로 하는데 사용되는 선별 서브 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>32. 제30항에 있어서,배치 정보 결정 유닛을 더 포함하고, 상기 배치 정보 결정 유닛은, 각 상기 슬라이스의 분산식 속성을 이용하여, 각 상기 슬라이스의 배치 정보를 결정하는데 사용되고, 상기 배치 정보가 상기 슬라이스와 상기 컴퓨팅 자원의 물리 매핑 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>33. 제32항에 있어서,상기 슬라이스가 상기 훈련할 모델의 인접 네트워크층에 위치하고 상기 슬라이스의 배치 정보가 부동할 경우, 통신 보조 연산자 결정 유닛을 포함하고, 구체적으로, 상기 배치 정보를 이용하여, 통신 보조 연산자를 결정하하는데 사용되고, 상기 통신 보조 연산자가 각 상기 슬라이스 사이의 논리 연산 관계를 나타내는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>34. 제32항에 있어서,상기 슬라이스가 훈련할 모델의 동일 네트워크층에 위치할 경우, 재구성 전환 연산자 결정 유닛을 포함하고, 상기 재구성 전환 연산자 결정 유닛은, 각 상기 슬라이스 사이의 네트워크층 일치성 관계를 나타내는데 사용되는 재구성 전환 연산자를 결정하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>35. 제29항 내지 제34항 중의 어느 한 항에 있어서,상기 분할 수행 서브 모듈은, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 대해 분석 결정을 수행하는데 사용되는 분할 전략 결정 유닛을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>36. 제29항 내지 제34항 중의 어느 한 항에 있어서,상기 분할 수행 서브 모듈은, 미리 훈련된 분할 전략을 이용하여 모델 결정을 수행하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>37. 제28항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계를 결정하고, 상기 하드웨어 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>38. 제37항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 최소 어셈블리를 결정하는데 사용되는 최소 어셈블리 결정 서브 모듈 - 상기 최소 어셈블리는 프로세서 또는 메모리를 포함함 - ; 적어도 하나의 상기 최소 어셈블리로 구성된 기계 기기를 결정하는데 사용되는 기계 기기 결정 서브 모듈 - 각 상기 기계 기기의 최소 어셈블리는 중복되지 않음 - ; 및적어도 하나의 상기 기계 기기로 구성된 클러스터를 결정하는데 사용되는 클러스터 결정 서브 모듈 - 각 상기 클러스터의 기계 기기는 중복되지 않음 - ; 를 포함하고,상기 최소 어셈블리, 상기 기계 기기 및 상기 클러스터를 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>39. 제38항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 각 상기 최소 어셈블리의 밀접 관계 리스트를 결정하고; 상기 밀접 관계 리스트는 소스 최소 어셈블리와 목적 최소 어셈블리 사이의 연결 관계, 대역폭 정보 및 지연 정보 중의 적어도 하나를 포함하고, 상기 밀접 관계 리스트를 상기 컴퓨팅 자원의 하드웨어 토폴로지 관계로 하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>40. 제28항 또는 제37항에 있어서,상기 훈련할 모델에 할당되어 훈련하는 컴퓨팅 자원은 상기 사용자 단말에 의해 시작된 모델 훈련 요청의 내용 및 모델 훈련 요청을 시작하는 사용자 단말의 수량 중의 적어도 하나에 따라 결정되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>41. 제28항 또는 제37항에 있어서,상기 컴퓨팅 자원의 속성 결정 모듈은, 상기 컴퓨팅 자원의 통신 경로를 획득하는데 사용되는 통신 경로 획득 서브 모듈; 상기 컴퓨팅 자원의 통신 경로를 이용하여, 각 상기 컴퓨팅 자원 사이의 통신 토폴로지 관계를 구축하는데 사용되는 통신 토폴로지 관계 구축 서브 모듈; 을 포함하고, 상기 통신 토폴로지 관계를 상기 컴퓨팅 자원의 속성으로 하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>42. 제41항에 있어서,최단 통신 경로 구축 서브 모듈을 더 포함하고, 상기 최단 통신 경로 구축 서브 모듈은, 상기 통신 토폴로지 관계에 따라, 소스 컴퓨팅 자원과 타겟 컴퓨팅 자원 사이의 최단 통신 경로를 결정하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>43. 제28항에 있어서,상기 분산 전략 결정 모듈은, 상기 컴퓨팅 자원에서 각 상기 분할 결과의 후보 분산 전략을 결정하는데 사용되는 후보 분산 전략 획득 서브 모듈; 각 상기 후보 분산 전략의 효율을 각각 통계하는데 사용되는 효율 통계 서브 모듈; 및 각 상기 후보 분산 전략의 효율에 따라, 상기 후보 분산 전략에서 타겟 분산 전략을 결정하는데 사용되는 타겟 분산 전략 결정 서브 모듈; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>44. 제28항 또는 제43항에 있어서,상기 타겟 분산 전략 결정 서브 모듈은, 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는데 사용되는 정렬 유닛; 미리 설정된 규칙을 이용하여, 각 상기 후보 분산 전략을 정렬하는데 사용되는 결과 결정 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 장치.</claim></claimInfo><claimInfo><claim>45. 제28항에 있어서,상기 분산식 훈련 모듈은, 상기 컴퓨팅 자원의 가용성을 정기적으로 검출하는데 사용되는 가용성 검출 서브 모듈; 검출 결과에 상기 컴퓨팅 자원의 불가용이 존재할 경우, 보완 조치를 수행하는데 사용되는 보완 조치 수행 서브 모듈 - 상기 불가용 상황은 컴퓨팅 자원 고장 또는 컴퓨팅 자원 수량의 축소를 포함함 - ; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>46. 제45항에 있어서,상기 불가용 상황이 컴퓨팅 자원 고장일 경우, 상기 보완 조치 수행 서브 모듈은, 상기 사용자 단말에 의해 시작된 모델 훈련 요청에 포함된 훈련 모드를 획득하는데 사용되는 훈련 모드 획득 유닛; 상기 훈련 모드가 내결함성 훈련 모드일 경우, 컴퓨팅 자원의 고장이 복구될 때 까지 대기하는데 사용되는 대기 유닛; 및 미리 설정된 시간 내에 상기 컴퓨팅 자원의 고장이 복구되지 않을 경우, 수행 종료로 결정하는데 사용되는 결과 결정 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>47. 제46항에 있어서,상기 불가용이 컴퓨팅 자원 고장일 경우, 상기 보완 조치 수행 서브 모듈은, 상기 훈련 모드가 탄성 훈련 모드일 경우, 후보 컴퓨팅 자원을 결정하는데 사용되는 후보 컴퓨팅 자원 결정 유닛; 상기 후보 컴퓨팅 자원에서 훈련의 재시행을 진행하는데 사용되는 재시행 유닛; 을 더 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>48. 제47항에 있어서,상기 재시행 유닛은, 상기 컴퓨팅 자원이 고장날 경우의 훈련 상태를 획득하는데 사용되는 훈련 상태 획득 서브 유닛; 상기 훈련 상태를 기반으로, 상기 후보 컴퓨팅 자원에서 훈련 재시행을 진행하는데 사용되는 재시행 수행 서브 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>49. 제47항에 있어서,상기 재시행 유닛은, 훈련의 최초 상태를 획득하는데 사용되는 최초 상태 획득 서브 유닛; 훈련의 최초 상태를 획득하는데 사용되는 재시행 수행 서브 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>50. 제45항에 있어서,상기 불가용 상황이 컴퓨팅 자원 수량의 축소일 경우, 상기 보완 조치 수행 서브 모듈은, 축소된 상기 컴퓨팅 자원의 제1 수량을 결정하는데 사용되는 제1 수량 결정 유닛; 상기 제1 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제1 결과를 획득하는데 사용되는 제1 재분할 유닛; 재결정된 축소 후의 나머지 상기 컴퓨팅 자원의 속성을 이용하여, 축소된 상기 컴퓨팅 자원에서 각 상기 재분할된 제1 결과의 제1 분산 전략을 결정하는데 사용되는 제1 분산 전략 결정 유닛; 및 상기 제1 분산 전략에 따라, 축소된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는데 사용되는 분산식 훈련 수행 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>51. 제45항에 있어서,검출 결과에 사용 가능한 여분의 컴퓨팅 자원이 존재할 경우,사용 가능한 상기 여분의 컴퓨팅 자원의 제2 수량을 결정하는데 사용되는 제2 수량 결정 유닛; 상기 제2 수량에 따라, 상기 훈련할 모델을 재분할하여, 재분할된 제2 결과를 획득하는데 사용되는 제2 재분할 유닛; 다시 결정된 여분의 상기 컴퓨팅 자원의 속성을 이용하여, 확장된 상기 컴퓨팅 자원에서 각 상기 재분할된 제2 결과의 제2 분산 전략을 결정하는데 사용되는 제2 분산 전략 결정 유닛; 및상기 제2 분산 전략에 따라, 확장된 상기 컴퓨팅 자원을 이용하여 상기 훈련할 모델에 대해 분산식 훈련을 수행하는데 사용되는 분산식 훈련 수행 유닛; 을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>52. 제50항 또는 제51항에 있어서,상기 컴퓨팅 자원의 수량이 변화될 경우, 조정 서브 유닛을 더 포함하고, 상기 조정 서브 유닛은, 변화된 수량에 따라, 상기 훈련할 모델의 학습률 및 단번의 훈련에 선택된 샘플 수량을 조정하는데 사용되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>53. 제28항, 제45항, 제50항 또는 제51항 중 어느 한 항에 있어서,상기 분산식 훈련이, 분산 비동기 파이프라인 훈련을 포함하는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>54. 제28항 내지 제53항 중 어느 한 항에 있어서,상기 훈련할 모델은 사용자 단말에 의해 시작된 모델 훈련 요청에 따라 획득되는,것을 특징으로 하는 단대단 자체 적응에 기반한 분산식 훈련 방법.</claim></claimInfo><claimInfo><claim>55. 전자 기기에 있어서,적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 가능하게 연결되는 메모리; 를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 당해 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서가 제1항 내지 제27항 중 어느 한 항의 방법을 수행하는, 것을 특징으로 하는 전자 기기.</claim></claimInfo><claimInfo><claim>56. 컴퓨터 프로그램이 저장되어 있는 비일시적 컴퓨터 판독 가능 저장 매체에 있어서,상기 컴퓨터 프로그램이 수행될 경우 제1항 내지 제27항 중 어느 한 항의 방법이 구현되는,것을 특징으로 하는 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>57. 컴퓨터 판독 가능 저장 매체에 저장된 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행 될 경우 제1항 내지 제27항 중 어느 한 항의 방법을 구현하는,것을 특징으로 하는 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 베이징 ****** 하이디안 디...</address><code> </code><country> </country><engName>WANG, Haifeng</engName><name>왕, 하이펑</name></inventorInfo><inventorInfo><address>중국 베이징 ****** 하이디안 디...</address><code> </code><country> </country><engName>WU, Zhihua</engName><name>우, 치후아</name></inventorInfo><inventorInfo><address>중국 베이징 ****** 하이디안 디...</address><code> </code><country> </country><engName>YU, Dianhai</engName><name>유, 디안하이</name></inventorInfo><inventorInfo><address>중국 베이징 ****** 하이디안 디...</address><code> </code><country> </country><engName>MA, Yanjun</engName><name>마, 얀준</name></inventorInfo><inventorInfo><address>중국 베이징 ****** 하이디안 디...</address><code> </code><country> </country><engName>WU, Tian</engName><name>우, 티안</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 역삼로 *** *층 (역삼동, 현죽빌딩)</address><code>920181000011</code><country>대한민국</country><engName>SUNGAM SUH INTERNATIONAL PATENT &amp; LAW FIRM</engName><name>특허법인성암</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2021.12.06</priorityApplicationDate><priorityApplicationNumber>202111471601.7</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.11.18</receiptDate><receiptNumber>1-1-2022-1232106-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2023.02.03</receiptDate><receiptNumber>9-1-2023-9001223-37</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220155291.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93322564df10dfa7c4e2957caef126622aa16e7dba4772a64460337743618b26c959711e6f25422d7a28b9946c789042e61ac0ac79f4d01339</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf147abadbc5fd96f0ae79581df6c8f59992cdd0b92f3f6be0d4510f531ca87b294f6edbf8597444fd262cfa69faf6eb8c4aab886f3b5a5178</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>