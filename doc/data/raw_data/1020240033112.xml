<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:03:17.317</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0033112</applicationNumber><claimCount>21</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체의 변화 전후 데이터에 기초하여 객체의 부피를 예측하는 방법</inventionTitle><inventionTitleEng>METHOD FOR PREDICTING VOLUME OF OBJECT BASED ON DATA BEFORE  AND AFTER CHANGES TO THE OBJECT</inventionTitleEng><openDate>2025.09.16</openDate><openNumber>10-2025-0136533</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01F 17/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 실시예에 따라 컴퓨팅 장치의 하나 이상의 프로세서에 의해 수행되는, 객체의 부피를 예측하기 위한 방법이 개시된다. 상기 방법은, 객체가 담길 수 있는 용기가 포함된 제 1 시점의 이미지 및 제 2 시점의 이미지를 획득하는 단계; 상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 단계; 상기 제 1 시점의 이미지에 포함된 제 1 객체 영역에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 시점의 이미지에 포함된 제 2 객체 영역에 기초하여 제 2 다차원 데이터를 획득하는 단계; 및 상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 장치의 하나 이상의 프로세서에 의해 수행되는, 객체의 부피를 예측하는 방법으로서,객체가 담길 수 있는 용기가 포함된 제 1 시점의 이미지 및 제 2 시점의 이미지를 획득하는 단계;상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 단계;상기 제 1 시점의 이미지에 포함된 제 1 객체 영역에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 시점의 이미지에 포함된 제 2 객체 영역에 기초하여 제 2 다차원 데이터를 획득하는 단계; 및상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 단계는,상기 제 2 시점의 이미지에 포함된 제 2 용기 영역을 식별하고, 상기 제 2 용기 영역 내부의 제 2 객체 영역을 식별하는 단계; 및상기 제 2 용기 영역과 대응되는 상기 제 1 시점의 이미지에 포함된 제 1 용기 영역을 식별하고, 상기 제 1 용기 영역 내부의 제 1 객체 영역을 식별하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>3.  제 1 항에 있어서, 상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 단계는, 상기 제 2 객체 영역에 기초하여 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,상기 다차원 데이터는,다차원 매쉬(mesh) 데이터를 포함하는,방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 제 1 시점의 이미지에 포함된 제 1 객체 영역에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 시점의 이미지에 포함된 제 2 객체 영역에 기초하여 제 2 다차원 데이터를 획득하는 단계는,상기 제 1 객체 영역에 기초하여 제 1 포인트 클라우드 데이터를 획득하고, 상기 제 2 객체 영역에 기초하여 제 2 포인트 클라우드 데이터를 획득하는 단계; 및상기 획득된 제 1 포인트 클라우드 데이터에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 포인트 클라우드 데이터에 기초하여 제 2 다차원 데이터를 획득하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,상기 획득된 제 1 포인트 클라우드 데이터에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 포인트 클라우드 데이터에 기초하여 제 2 다차원 데이터를 획득하는 단계는,상기 제 1 포인트 클라우드 데이터 및 상기 제 2 포인트 클라우드 데이터에 각각 포함된 빈 공간을 보정하여 상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터를 획득하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,상기 제 1 포인트 클라우드 데이터 및 상기 제 2 포인트 클라우드 데이터에 각각 포함된 빈 공간을 보정하는 과정은,보간(interpolation) 방법;복원(reconstruction) 방법; 또는필터링(filtering) 방법;중 적어도 하나에 기초하여 수행되는,방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계는,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 통합 다차원 데이터를 획득하는 단계; 및상기 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 통합 다차원 데이터를 획득하는 단계는,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 통합 다차원 데이터에 포함된 공통 외곽 데이터를 획득하는 단계를 포함하고,상기 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계는,상기 공통 외곽 데이터에 기초하여 상기 통합 다차원 데이터를 필터링하여 제 1 필터링된 통합 다차원 데이터를 획득하는 단계; 및상기 제 1 필터링된 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 제 8 항에 있어서,상기 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계는,상기 통합 다차원 데이터에 포함된 제 1 다차원 데이터 및 제 2 다차원 데이터 간의 미대응 영역을 식별하는 단계;상기 통합 다차원 데이터에 대해 상기 미대응 영역을 필터링하여 제 2 필터링된 통합 다차원 데이터를 획득하는 단계; 및상기 제 2 필터링된 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서,상기 통합 다차원 데이터에 대해 상기 미대응 영역을 필터링하여 제 2 필터링된 통합 다차원 데이터를 획득하는 단계는,상기 통합 다차원 데이터에 포함된 제 2 다차원 데이터를 기준으로 상기 제 1 다차원 데이터와의 대응 영역을 식별하는 단계; 및상기 통합 다차원 데이터에 포함된 제 2 다차원 데이터에 대해 상기 식별된 대응 영역 이외의 상기 미대응 영역을 필터링하여 상기 제 2 필터링된 통합 다차원 데이터를 획득하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 하나 이상의 프로세서에 의해 실행되는 경우, 상기 하나 이상의 프로세서로 하여금 객체의 부피를 예측하기 위한 동작들을 수행하도록 하며, 상기 동작들은:객체가 담길 수 있는 용기가 포함된 제 1 시점의 이미지 및 제 2 시점의 이미지를 획득하는 동작;상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 동작;상기 제 1 시점의 이미지에 포함된 제 1 객체 영역에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 시점의 이미지에 포함된 제 2 객체 영역에 기초하여 제 2 다차원 데이터를 획득하는 동작; 및상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서,상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 동작은,상기 제 2 시점의 이미지에 포함된 제 2 용기 영역을 식별하고, 상기 제 2 용기 영역 내부의 제 2 객체 영역을 식별하는 동작; 및상기 제 2 용기 영역과 대응되는 상기 제 1 시점의 이미지에 포함된 제 1 용기 영역을 식별하고, 상기 제 1 용기 영역 내부의 제 1 객체 영역을 식별하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>14. 제 12 항에 있어서, 상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 동작은, 상기 제 2 객체 영역에 기초하여 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 동작을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 제 12 항에 있어서,상기 제 1 시점의 이미지에 포함된 제 1 객체 영역에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 시점의 이미지에 포함된 제 2 객체 영역에 기초하여 제 2 다차원 데이터를 획득하는 동작은,상기 제 1 객체 영역에 기초하여 제 1 포인트 클라우드 데이터를 획득하고, 상기 제 2 객체 영역에 기초하여 제 2 포인트 클라우드 데이터를 획득하는 동작; 및상기 획득된 제 1 포인트 클라우드 데이터에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 포인트 클라우드 데이터에 기초하여 제 2 다차원 데이터를 획득하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서,상기 획득된 제 1 포인트 클라우드 데이터에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 포인트 클라우드 데이터에 기초하여 제 2 다차원 데이터를 획득하는 동작은,상기 제 1 포인트 클라우드 데이터 및 상기 제 2 포인트 클라우드 데이터에 각각 포함된 빈 공간을 보정하여 상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터를 획득하는 동작;을 포함하는,방법.</claim></claimInfo><claimInfo><claim>17. 제 12 항에 있어서,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 동작은,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 통합 다차원 데이터를 획득하는 동작; 및상기 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 통합 다차원 데이터를 획득하는 동작은,상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 통합 다차원 데이터에 포함된 공통 외곽 데이터를 획득하는 동작을 포함하고,상기 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 동작은,상기 공통 외곽 데이터에 기초하여 상기 통합 다차원 데이터를 필터링하여 제 1 필터링된 통합 다차원 데이터를 획득하는 동작; 및상기 제 1 필터링된 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>19. 제 17 항에 있어서,상기 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 동작은,상기 통합 다차원 데이터에 포함된 제 1 다차원 데이터 및 제 2 다차원 데이터 간의 미대응 영역을 식별하는 동작;상기 통합 다차원 데이터에 대해 상기 미대응 영역을 필터링하여 제 2 필터링된 통합 다차원 데이터를 획득하는 동작; 및상기 제 2 필터링된 통합 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>20. 컴퓨팅 장치로서,적어도 하나의 프로세서; 및메모리를 포함하고,상기 적어도 하나의 프로세서는,객체가 담길 수 있는 용기가 포함된 제 1 시점의 이미지 및 제 2 시점의 이미지를 획득하고;상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하고;상기 제 1 시점의 이미지에 포함된 제 1 객체 영역에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 시점의 이미지에 포함된 제 2 객체 영역에 기초하여 제 2 다차원 데이터를 획득하고; 그리고상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 객체의 부피를 예측하도록 구성되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>21. 컴퓨터 판독가능 저장 매체에 포함되는 데이터 구조로서, 상기 데이터 구조는 신경망의 파라미터에 대응되며, 그리고 상기 신경망은 상기 파라미터에 적어도 부분적으로 기초하여 이하의 단계를 수행하며, 상기 단계는,객체가 담길 수 있는 용기가 포함된 제 1 시점의 이미지 및 제 2 시점의 이미지를 획득하는 단계;상기 제 2 시점의 이미지에 대해 제 2 객체 영역을 식별하고, 상기 제 1 시점의 이미지에 대해 제 1 객체 영역을 식별하는 단계;상기 제 1 시점의 이미지에 포함된 제 1 객체 영역에 기초하여 제 1 다차원 데이터를 획득하고, 상기 제 2 시점의 이미지에 포함된 제 2 객체 영역에 기초하여 제 2 다차원 데이터를 획득하는 단계; 및상기 제 1 다차원 데이터 및 상기 제 2 다차원 데이터에 기초하여 상기 객체의 부피를 예측하는 단계;를 포함하는,컴퓨터 판독가능 저장 매체에 포함되는 데이터 구조.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>인천광역시 서구...</address><code>120180757108</code><country>대한민국</country><engName>NUVILABS Co., Ltd.</engName><name>주식회사 누비랩</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>CHA, Eunseong</engName><name>차은성</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920090037635</code><country>대한민국</country><engName>LEE, Dae Ho</engName><name>이대호</name></agentInfo><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920120001378</code><country>대한민국</country><engName>Park, Gun Hong</engName><name>박건홍</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.08</receiptDate><receiptNumber>1-1-2024-0264228-48</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240033112.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c36a90f6218edad0926340e7bcc794cc5f49860ed6fee79a836f08c6419a76c33a9b8ab3e17c00c477a82d4cf63d69223801fb46f7c573a0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa86d01f579aa2bab0b8b8e8e0104184765925bd452391b52e082bf1e93931392a6d0496c013153e2be629d7f02194e4e335a1484fbbf66ba</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>