<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:11.1011</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.22</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0163309</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 인식 모델에서 신호등을 탐지하는 방법 및 그 장치</inventionTitle><inventionTitleEng>A METHOD AND APPARTUS FOR DETECTING TRAFFIC SIGNALS  IN AN OBJECT DETECTION MODEL</inventionTitleEng><openDate>2025.05.29</openDate><openNumber>10-2025-0076051</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/762</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/14</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B60W 40/02</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 아래의 개시는 객체 인식 모델에서 신호등을 탐지하는 방법에 관한 것으로, 자율 주행 차량에 포함된 카메라로부터 입력 이미지를 획득하는 단계, 사전 지식에 기초하여, 입력 이미지에서 제1 관심 영역(Region of interests, RoI)을 추정하는 단계, 과거 프레임의 탐지 결과에 기초하여, 제1 관심 영역을 제2 관심 영역으로 업데이트하는 단계 및 디텍터를 이용하여 입력 이미지 및 제2 관심 영역에 기초하여, 입력 이미지에서 신호등을 탐지하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 자율 주행 차량에 포함된 카메라로부터 입력 이미지를 획득하는 단계;사전 지식에 기초하여, 상기 입력 이미지에서 제1 관심 영역(Region of interests, RoI)을 추정하는 단계;과거 프레임의 탐지 결과에 기초하여, 상기 제1 관심 영역을 제2 관심 영역으로 업데이트하는 단계; 및디텍터를 이용하여 상기 입력 이미지 및 상기 제2 관심 영역에 기초하여, 상기 입력 이미지에서 신호등을 탐지하는 단계를 포함하는 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 신호등을 탐지하는 단계는상기 제2 관심 영역에 대응하는 크기의 타겟 이미지들을 획득하는 단계; 및상기 타겟 이미지들의 크기를 상기 입력 이미지의 크기에 대응하는 크기로 확대하여 상기 디텍터에 입력하는 단계를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 사전 지식은복수의 테스트 주행 환경에서 취득한 영상 데이터에서, 픽셀 값이 임계 값 이하인 타겟 신호등의 분포를 추출한 상기 타겟 신호등의 분포 데이터를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 사전 지식은상기 타겟 신호등의 분포 데이터에 기초하여 생성된 상기 제1 관심 영역에 관한 정보를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 사전 지식은상기 자율 주행 차량이 주행하는 환경에 관한 주행 환경 정보, 상기 자율 주행 차량에 포함된 상기 카메라의 스펙을 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 제1 관심 영역을 추정하는 단계는상기 자율 주행 차량의 주행 환경에 따라 상기 자율 주행 차량의 센서를 이용하여, 상기 제1 관심 영역을 보정하는 단계를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서상기 제1 관심 영역을 추정하는 단계는상기 자율 주행 차량에 포함된 상기 카메라의 스펙을 고려하여, 상기 제1 관심 영역을 보정하는 단계를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제2 관심 영역으로 업데이트하는 단계는상기 디텍터가 탐지한 상기 과거 프레임의 탐지 결과를 최신 순으로 취합하는 단계상기 과거 프레임의 탐지 결과를 클러스터링하여, 복수의 대표 센터를 획득하는 단계; 및상기 복수의 대표 센터를 필터링하여 제2 관심 영역을 획득하는 단계를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 과거 프레임의 탐지 결과를 최신 순으로 취합하는 단계는미리 정해진 개수의 상기 탐지 결과가 누적될 때까지, 상기 과거 프레임의 탐지 결과를 최신 순으로 저장하는 단계를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 제2 관심 영역을 획득하는 단계는상기 복수의 대표 센터들 사이의 거리 함수를 획득하는 단계;상기 거리 함수에서 최소 조건을 만족하는 대표 센터들을 제외한 나머지 대표 센터들을 제거하는 단계; 및상기 최소 조건을 만족하는 대표 센터들을 중심으로 제2 관심 영역을 생성하는 단계를 포함하는, 객체 인식 모델의 동작 방법.</claim></claimInfo><claimInfo><claim>11. 인스트럭션들을 포함하는 메모리;카메라; 및상기 카메라로부터 입력 이미지를 획득하고,사전 지식에 기초하여, 상기 입력 이미지에서 제1 관심 영역(Region of interests, RoI)을 추정하고,과거 프레임의 탐지 결과에 기초하여, 상기 제1 관심 영역을 제2 관심 영역으로 업데이트하고,디텍터를 이용하여 상기 입력 이미지 및 상기 제2 관심 영역에 기초하여, 상기 입력 이미지에서 신호등을 탐지하는 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 프로세서는상기 제2 관심 영역에 대응하는 크기의 타겟 이미지들을 획득하고, 상기 타겟 이미지들의 크기를 상기 입력 이미지의 크기에 대응하는 크기로 확대하여 상기 디텍터에 입력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 사전 지식은복수의 테스트 주행 환경에서 취득한 영상 데이터에서, 픽셀 값이 임계 값 이하인 타겟 신호등의 분포를 추출한 상기 타겟 신호등 분포 데이터를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 사전 지식은상기 타겟 신호등의 분포 데이터에 기초하여 생성된 상기 제1 관심 영역에 관한 정보를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서,상기 사전 지식은상기 자율 주행 차량이 주행하는 환경에 관한 주행 환경 정보, 상기 자율 주행 차량에 포함된 상기 카메라의 스펙을 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서,상기 프로세서는상기 자율 주행 차량의 주행 환경에 따라 상기 자율 주행 차량의 센서를 이용하여, 상기 제1 관심 영역을 보정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서상기 프로세서는상기 자율 주행 차량에 포함된 상기 카메라의 스펙을 고려하여, 상기 제1 관심 영역을 보정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서,상기 프로세서는상기 디텍터가 탐지한 상기 과거 프레임의 탐지 결과를 최신 순으로 취합하고,상기 과거 프레임의 탐지 결과를 클러스터링하여, 복수의 대표 센터를 획득하고,상기 복수의 대표 센터를 필터링하여 제2 관심 영역을 획득하는, 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 프로세서는미리 정해진 개수의 상기 탐지 결과가 누적될 때까지, 상기 과거 프레임의 탐지 결과를 최신 순으로 저장하는, 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 프로세서는상기 복수의 대표 센터들 사이의 거리 함수를 획득하고,상기 거리 함수에서 최소 조건을 만족하는 대표 센터들을 제외한 나머지 대표 센터들을 제거하고,상기 최소 조건을 만족하는 대표 센터들을 중심으로 제2 관심 영역을 생성하는, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 장안구...</address><code>420220749459</code><country>대한민국</country><engName>JO, Dae Ung</engName><name>조대웅</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420210391736</code><country>대한민국</country><engName>Yoo, Jaewook</engName><name>유재욱</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.22</receiptDate><receiptNumber>1-1-2023-1304333-51</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230163309.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931792d097891e809a9364a3680364f4eb14b390dedd18796c0c5e72429593dd4c2d4a5acaa427390f7b6c6032d19b809ca1dc15d2151b14f6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfab33cdfc523979453af58b171253d46d577301dfb531e2645a70ff73eeb03536a98f6a0feea8b16638ca9cdcfa45dbbf853f34488cf38484</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>