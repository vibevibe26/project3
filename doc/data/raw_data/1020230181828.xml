<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:09.49</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0181828</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치 및 그의 학습 방법</inventionTitle><inventionTitleEng>ELECTRICAL APPARATUS TO PERFORM JOINTLY ADAPTIVE BATCHING  AND AUTOMATIC SCALING FOR DNN MODEL TRAINING AND TRAINING  METHOD THEREOF</inventionTitleEng><openDate>2025.06.23</openDate><openNumber>10-2025-0091659</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.14</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0985</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/098</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06T 1/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 일 실시예에 따른 DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치는 글로벌 배치 사이즈에 따라 GPU 자원 구성을 자동 스케일링하는 자동 스케일링부; 각 GPU 자원의 로컬 배치 사이즈()와 GA 스텝 수()를 설정하는 구성 솔버(configuration solver); 설정된 상기 로컬 배치 사이즈와 GA 스텝 수를 전달 받아 에포크의 실행을 시작하는 상태 관리부(state manager); 그래디언트 유사도 메트릭 기반 적응 배칭 기법에 따라 에포크의 글로벌 배치 사이즈를 결정하는 적응 배칭부; 및 상기 자동 스케일링부, 상기 적응 배칭부, 상기 구성 솔버 및 상기 상태 관리부를 제어하는 적어도 하나의 프로세서;를 포함하고, 상기 적어도 하나의 프로세서는, 학습에 사용할 DNN 모델, 초기 글로벌 배치 사이즈, 상기 GPU 자원이 허용 가능한 로컬 배치 사이즈 범위 및 사용 가능한 GPU 자원을 입력 받고, 상기 자동 스케일링부에서 상기 초기 글로벌 배치 사이즈 따라 GPU 자원 구성을 결정하고, 상기 구성 솔버가 상기 초기 글로벌 배치 사이즈에 따라 각 GPU 자원 구성에 대응하는 로컬 배치 사이즈 및 GA 스텝 수를 설정하고, 상기 상태 관리부가 설정된 상기 로컬 배치 사이즈 및 상기 GA 스텝 수에 따라 각 GPU 자원 구성에 대한 분산 학습을 수행하도록 구성될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 글로벌 배치 사이즈에 따라 GPU 자원 구성을 자동 스케일링하는 자동 스케일링부;각 GPU 자원의 로컬 배치 사이즈()와 GA 스텝 수()를 설정하는 구성 솔버(configuration solver);설정된 상기 로컬 배치 사이즈와 GA 스텝 수를 전달 받아 에포크의 실행을 시작하는 상태 관리부(state manager); 그래디언트 유사도 메트릭 기반 적응 배칭 기법에 따라 에포크의 글로벌 배치 사이즈를 결정하는 적응 배칭부; 및 상기 자동 스케일링부, 상기 적응 배칭부, 상기 구성 솔버 및 상기 상태 관리부를 제어하는 적어도 하나의 프로세서;를 포함하고,상기 적어도 하나의 프로세서는,학습에 사용할 DNN 모델, 초기 글로벌 배치 사이즈, 상기 GPU 자원이 허용 가능한 로컬 배치 사이즈 범위 및 사용 가능한 GPU 자원을 입력 받고,상기 자동 스케일링부에서 상기 초기 글로벌 배치 사이즈 따라 GPU 자원 구성을 결정하고,상기 구성 솔버가 상기 초기 글로벌 배치 사이즈에 따라 각 GPU 자원 구성에 대응하는 로컬 배치 사이즈 및 GA 스텝 수를 설정하고,상기 상태 관리부가 설정된 상기 로컬 배치 사이즈 및 상기 GA 스텝 수에 따라 각 GPU 자원 구성에 대한 분산 학습을 수행하도록 구성된 DNN 모델 학습을 위한 공동 적응 배칭 및 자동 스케일링을 수행하는 전자 장치. </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 적어도 하나의 프로세서는, 기설정된 주기마다 계산된 그래디언트 유사도 메트릭을 상기 적응 배칭부에 전달하여 상기 적응 배칭부가 다음 에포크의 글로벌 배치 사이즈를 재조정하도록 구성된DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제2 항에 있어서,상기 적어도 하나의 프로세서는, 상기 구성 솔버가 재조정된 상기 글로벌 배치 사이즈에 따라 상기 로컬 배치 사이즈와 상기 GA 스텝 수를 재설정하도록 구성된 DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,상기 적응 배칭부에 의해 수집된 정보를 기반으로 다음 에포크의 글로벌 배치 사이즈의 변화 궤도를 예측하는 글로벌 배치 사이즈 예측기를 더 포함하는DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서,상기 적어도 하나의 프로세서는, 상기 자동 스케일링부가 상기 글로벌 배치 사이즈 예측기가 예측한 변화 궤도에 따라 상기 사용 가능한 GPU 자원을 고려하여 GPU 자원 구성을 자동 스케일링 하도록 구성된 DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 적어도 하나의 프로세서는, 상기 구성 솔버가 최적 데이터 처리량을 구현하기 위해 상기 GPU 자원 구성과 GPU 자원 설정을 탐색하도록 구성된 DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서,상기 자동 스케일링부에서 결정한 GPU 자원 구성은 상기 사용 가능한 GPU 자원 구성보다 작은 것을 특징으로 하는 DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서,상기 적어도 하나의 프로세서는, 상기 적응 배칭부가 앙상블 학습을 통해 GPR(Gaussian Process Regression) 모델과 ES(Exponential Smoothing) 모델을 적용하여 다음 에포크의 글로벌 배치 사이즈의 변화를 예측하도록 구성된DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서,상기 적어도 하나의 프로세서는,상기 적응 배칭부가 결정한 다음 에포크의 글로벌 배치 사이즈에 따라 상기 자동 스케일링부에서 GPU 자원 구성을 재결정하고,상기 구성 솔버가 상기 다음 에포크의 글로벌 배치 사이즈에 따라 각 GPU 자원 구성에 대응하는 로컬 배치 사이즈 및 GA 스텝 수를 재설정하고,상기 상태 관리부가 설정된 상기 로컬 배치 사이즈 및 상기 GA 스텝 수에 따라 각 GPU 자원 구성에 대한 분산 학습을 다시 수행하도록 구성된 DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치.</claim></claimInfo><claimInfo><claim>10. DNN 모델 학습을 위한 적응 배칭 및 자동 스케일링을 공동 수행하는 전자 장치에 의해 수행되는 학습 방법에 있어서,학습에 사용할 DNN 모델, 초기 글로벌 배치 사이즈, 상기 GPU 자원이 허용 가능한 로컬 배치 사이즈 범위 및 사용 가능한 GPU 자원을 입력 받는 단계;상기 초기 글로벌 배치 사이즈 따라 GPU 자원 구성을 결정하여 자동 스케일링하는 단계;상기 초기 글로벌 배치 사이즈에 따라 각 GPU 자원 구성에 대응하는 로컬 배치 사이즈() 및 GA 스텝 수()를 설정하여 적응 배칭하는 단계; 및설정된 상기 로컬 배치 사이즈 및 상기 GA 스텝 수에 따라 에포크의 실행을 시작하여 각 GPU 자원 구성에 대한 분산 학습을 수행하는 단계;를 포함하는DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서, 그래디언트 유사도 메트릭 기반 적응 배칭 기법에 따라 에포크의 글로벌 배치 사이즈를 결정하는 단계를 더 포함하는DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서, 기설정된 주기마다 계산된 그래디언트 유사도 메트릭을 기반으로 다음 에포크의 글로벌 배치 사이즈를 재조정하는 단계를 더 포함하는DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,재조정된 상기 글로벌 배치 사이즈에 따라 상기 로컬 배치 사이즈와 상기 GA 스텝 수를 재설정하는 단계를 더 포함하는 DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,그래디언트 유사도 메트릭 기반 적응 배칭 기법에 의해 수집된 정보를 기반으로 다음 에포크의 글로벌 배치 사이즈의 변화 궤도를 예측하는 단계를 더 포함하는DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,상기 글로벌 배치 사이즈에 대해 예측한 변화 궤도에 따라 상기 사용 가능한 GPU 자원을 고려하여 GPU 자원 구성을 자동 스케일링하는 단계를 더 포함하는 DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서,최적 데이터 처리량을 구현하기 위해 상기 GPU 자원 구성과 GPU 자원 설정을 탐색하는 단계를 더 포함하는 DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>17. 제16 항에 있어서,상기 자동 스케일링하는 단계에서 결정한 GPU 자원 구성은 상기 사용 가능한 GPU 자원 구성보다 작은 것을 특징으로 하는 DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>18. 제10 항에 있어서,상기 적응 배칭하는 단계는, 앙상블 학습을 통해 GPR(Gaussian Process Regression) 모델과 ES(Exponential Smoothing) 모델을 적용하여 다음 에포크의 글로벌 배치 사이즈의 변화를 예측하는 단계를 더 포함하는DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>19. 제18 항에 있어서,상기 적응 배칭하는 단계에서 결정한 다음 에포크의 글로벌 배치 사이즈에 따라 상기 자동 스케일링부에서 GPU 자원 구성을 재결정하는 단계;상기 다음 에포크의 글로벌 배치 사이즈에 따라 각 GPU 자원 구성에 대응하는 로컬 배치 사이즈 및 GA 스텝 수를 재설정하는 단계; 및 설정된 상기 로컬 배치 사이즈 및 상기 GA 스텝 수에 따라 각 GPU 자원 구성에 대한 분산 학습을 다시 수행하는 단계를 더 포함하는DNN 모델 학습 방법.</claim></claimInfo><claimInfo><claim>20. 컴퓨터와 결합되어 제10 항 내지 제19 항 중 어느 한 항의 DNN 모델 학습 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>울산광역시 울주군...</address><code>120150812047</code><country>대한민국</country><engName>UNIST(ULSAN NATIONAL INSTITUTE OF SCIENCE AND TECHNOLOGY)</engName><name>울산과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>Choi Young-ri</engName><name>최영리</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>GYEONGCHAN YUN</engName><name>윤경찬</name></inventorInfo><inventorInfo><address>울산광역시 울주군...</address><code> </code><country> </country><engName>JUNESOO KANG</engName><name>강준수</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구  법원로*길  **, *층 (서초동, 태흥빌딩)</address><code>920201001264</code><country>대한민국</country><engName>BLT Patent &amp; Law Firm</engName><name>특허법인비엘티</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.14</receiptDate><receiptNumber>1-1-2023-1403417-32</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.01.25</receiptDate><receiptNumber>4-1-2024-5044479-73</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230181828.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93833953af3c1afa293a949207f8145db50eb9b53a2c067a0b1379d690625cdba7308f873d875df7b3d0288e9ce58178a77f4aaa8174521998</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf418ef51f3dcb3ca2fffe9fddeeb94c8fddb5533c330d69f66ebaded1128f0579ff833e55fb51528a6c0298740f3087e066f2d5e8da05564f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>