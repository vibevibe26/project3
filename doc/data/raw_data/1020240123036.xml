<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:09:51.951</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.09.10</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0123036</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>상호작용 중인 사람과 사물을 특정하는 임베딩 벡터에 기반한 행동 인식 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR RECOGNIZING BEHAVIOR BASED ON  EMBEDDING VECTOR THAT SPECIFIES PEOPLE AND OBJECT BEING  INTERACTED WITH</inventionTitleEng><openDate>2025.05.28</openDate><openNumber>10-2025-0075446</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.10</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 행동 인식 장치는 타겟 영상에서 사람 객체를 포함하는 제1 바운딩 박스를 추출하는 동작; 상기 제1 바운딩 박스 내의 사람 객체의 자세에 대한 클래스 정보를 판별하는 제1 분류 모델을 사용하여 상기 제1 바운딩 박스에 대한 제1 특징 벡터를 추출하는 동작; 상기 타겟 영상 내의 사물 객체 중 상기 사람 객체와 상호작용하는 사물 객체를 포함하는 제2 바운딩 박스를 추출하는 동작; 상기 제2 바운딩 박스 내의 사물 객체에 대한 클래스 정보를 판별하는 제2 분류 모델을 사용하여 상기 제2 바운딩 박스에 대한 제2 특징 벡터를 추출하는 동작; 상기 제1 특징 벡터 및 제2 특징 벡터를 기초로 임베딩 벡터를 생성하는 동작; 및 사람과 사물 간의 상호작용에 따른 행동을 판별하는 제3 분류 모델에 상기 임베딩 벡터를 입력하여 상기 타겟 영상에 포함된 사람의 행동을 인식하는 동작을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 프로세서에 의해 동작하는 행동 인식 장치가 수행하는 방법에 있어서,타겟 영상에서 사람 객체를 포함하는 제1 바운딩 박스를 추출하는 동작;상기 제1 바운딩 박스 내의 사람 객체의 자세에 대한 클래스 정보를 판별하는 제1 분류 모델을 사용하여 상기 제1 바운딩 박스에 대한 제1 특징 벡터를 추출하는 동작;상기 타겟 영상 내의 사물 객체 중 상기 사람 객체와 상호작용하는 사물 객체를 포함하는 제2 바운딩 박스를 추출하는 동작; 상기 제2 바운딩 박스 내의 사물 객체에 대한 클래스 정보를 판별하는 제2 분류 모델을 사용하여 상기 제2 바운딩 박스에 대한 제2 특징 벡터를 추출하는 동작;상기 제1 특징 벡터 및 제2 특징 벡터를 기초로 임베딩 벡터를 생성하는 동작; 및사람과 사물 간의 상호작용에 따른 행동을 판별하는 제3 분류 모델에 상기 임베딩 벡터를 입력하여 상기 타겟 영상에 포함된 사람의 행동을 인식하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제2 바운딩 박스를 추출하는 동작은 상기 제1 바운딩 박스와 사물 객체를 포함하는 바운딩 박스 간의 근접성을 기반으로 사람 객체와 사물 객체 간의 상호작용을 판별하는 동작을 포함하는,방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제2 바운딩 박스를 추출하는 동작은 사람 객체와 사물 객체의 바운딩 박스 중심점 간의 유클리드 거리를 계산하는 동작; 및상기 유클리드 거리가 기 설정된 임계값 이하인 사물 객체가 존재하는 경우, 상기 기 설정된 임계값 이하인 사물 객체를 포함하는 바운딩 박스를 상기 제2 바운딩 박스로 추출하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 유클리드 거리의 기 설정된 임계값은 0.05로 설정되는 것이 특징인,방법. </claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 제2 바운딩 박스를 추출하는 동작은 상기 제1 바운딩 박스의 면적과 사물 객체를 포함하는 바운딩 박스의 면적 간의 합집합 면적에 대한 교집합 면적의 비율(Intersection over Union)을 기반으로 사람 객체와 사물 객체 간의 상호작용을 판별하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 제2 바운딩 박스를 추출하는 동작은 상기 합집합 면적에 대한 교집합 면적의 비율이 기 설정된 임계값 이상인 사물 객체가 존재하는 경우, 상기 기 설정된 임계값 이상인 사물 객체를 포함하는 바운딩 박스를 상기 제2 바운딩 박스로 추출하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 합집합 면적에 대한 교집합 면적의 비율에 대한 기 설정된 임계값은 0.1로 설정되는 것이 특징인방법. </claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제2 바운딩 박스를 추출하는 동작은 상기 제1 바운딩 박스의 면적에 대한 사물 객체를 포함하는 바운딩 박스의 면적에 대한 비율이  기 설정된 값 이상이면 상기 제1 바운딩 박스의 면적과 사물 객체를 포함하는 바운딩 박스의 면적 간의 합집합 면적에 대한 교집합 면적의 비율(Intersection over Union)을 기반으로 사람 객체와 사물 객체 간의 상호작용을 판별하고;상기 제1 바운딩 박스의 면적에 대한 사물 객체를 포함하는 바운딩 박스의 면적에 대한 비율이  기 설정된 값 미만이면 상기 제1 바운딩 박스와 사물 객체를 포함하는 바운딩 박스 간의 근접성을 기반으로 사람 객체와 사물 객체 간의 상호작용을 판별하는, 방법. </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 분류 모델은, 다중 출력 분류 네트워크를 사용하여 복수의 클래스를 판별하도록 상기 제1 특징 벡터를 생성하는 것이 특징인, 방법. </claim></claimInfo><claimInfo><claim>10. 명령어를 포함하는 메모리; 및상기 명령어를 기초로 소정의 동작을 수행하는 프로세서를 포함하고, 상기 프로세서의 동작은,타겟 영상에서 사람 객체에 대한 제1 바운딩 박스를 추출하는 동작;상기 제1 바운딩 박스 내의 사람 객체의 자세에 대한 클래스 정보를 판별하는 제1 분류 모델을 사용하여 상기 제1 바운딩 박스에 대한 제1 특징 벡터를 추출하는 동작;상기 타겟 영상 내의 사물 객체 중 상기 사람 객체와 상호작용하는 사물 객체를 포함하는 제2 바운딩 박스를 추출하는 동작; 상기 제2 바운딩 박스 내의 사물 객체에 대한 클래스 정보를 판별하는 제2 분류 모델을 사용하여 상기 제2 바운딩 박스에 대한 제2 특징 벡터를 추출하는 동작;상기 제1 특징 벡터 및 제2 특징 벡터를 기초로 임베딩 벡터를 생성하는 동작; 및사람과 사물 간의 상호작용에 따른 행동을 판별하는 제3 분류 모델에 상기 임베딩 벡터를 입력하여 상기 타겟 영상에 포함된 사람의 행동을 인식하는 동작을 포함하는, 행동 인식 장치. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성북구...</address><code>220040170680</code><country>대한민국</country><engName>Korea University Research and Business Foundation</engName><name>고려대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM, Sang Pil</engName><name>김상필</name></inventorInfo><inventorInfo><address>서울시 성북구...</address><code> </code><country> </country><engName>SEO, Dong Yoon</engName><name>서동윤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 송파구 송파대로 ***, 에이동 ***호(문정동, 문정역테라타워)</address><code>920221000019</code><country>대한민국</country><engName>WESOL IP Law Firm</engName><name>특허법인위솔</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.11.20</priorityApplicationDate><priorityApplicationNumber>1020230160835</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.09.10</receiptDate><receiptNumber>1-1-2024-0993670-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[공지예외적용 보완 증명서류]서류제출서</documentName><receiptDate>2024.09.12</receiptDate><receiptNumber>1-1-2024-1008578-09</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[출원서 등 보완]보정서</documentName><receiptDate>2024.09.12</receiptDate><receiptNumber>1-1-2024-1008579-44</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.02.20</receiptDate><receiptNumber>1-1-2025-0199979-38</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.02.21</receiptDate><receiptNumber>1-1-2025-0205717-81</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.07.03</receiptDate><receiptNumber>1-1-2025-0748767-99</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240123036.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9385f595290fd0a5aef241e42035d03e673b511877dbddfdcfa92e6fc51832a34207786e0e7e661b2272e9d304f5de1fbadc316388f368e049</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfc17d465d221df212e078f3bcce9ae5dcbd729184a65ac9ce0d0a6c90689867fdefe87be1a7c595997a187f5a8e725e495bda0aa3f58db3f5</path></imagePathInfo><rndInfoArray><rndInfo><rndDepartmentName>과학기술정보통신부</rndDepartmentName><rndDuration>2025.03.01 ~ 2026.02.28</rndDuration><rndManagingInstituteName>고려대학교</rndManagingInstituteName><rndProjectName>(이공)우수신진연구</rndProjectName><rndSpecialInstituteName>한국연구재단</rndSpecialInstituteName><rndTaskContribution> </rndTaskContribution><rndTaskName>멀티모달 생성형 AI 모델의 저작권 보호 및 생성물 위·변조 방지 연구</rndTaskName><rndTaskNumber>2710081174</rndTaskNumber></rndInfo><rndInfo><rndDepartmentName>문화체육관광부</rndDepartmentName><rndDuration>2024.04.01 ~ 2027.12.31</rndDuration><rndManagingInstituteName>고려대학교</rndManagingInstituteName><rndProjectName>지정공모(R＆D)</rndProjectName><rndSpecialInstituteName>한국콘텐츠진흥원</rndSpecialInstituteName><rndTaskContribution> </rndTaskContribution><rndTaskName>생성형 AI 저작권 관리 및 보호 기술 개발을 위한 국제공동연구 및 글로벌 인재 양성</rndTaskName><rndTaskNumber>2370000334</rndTaskNumber></rndInfo><rndInfo><rndDepartmentName>문화체육관광부</rndDepartmentName><rndDuration>2024.04.01 ~ 2027.12.31</rndDuration><rndManagingInstituteName>고려대학교</rndManagingInstituteName><rndProjectName>지정공모(R＆D)</rndProjectName><rndSpecialInstituteName>한국콘텐츠진흥원</rndSpecialInstituteName><rndTaskContribution> </rndTaskContribution><rndTaskName>생성형 AI 3D 콘텐츠 저작권 보호를 위한 뉴럴 워터마크 기술 연구</rndTaskName><rndTaskNumber>2370000314</rndTaskNumber></rndInfo><rndInfo><rndDepartmentName>문화체육관광부</rndDepartmentName><rndDuration>2024.04.01 ~ 2027.12.31</rndDuration><rndManagingInstituteName>고려대학교</rndManagingInstituteName><rndProjectName>지정공모(R＆D)</rndProjectName><rndSpecialInstituteName>한국콘텐츠진흥원</rndSpecialInstituteName><rndTaskContribution> </rndTaskContribution><rndTaskName>인공지능을 활용한 4D 실감 콘텐츠 창작물 생성 및 저작권 핵심 기술 연구개발</rndTaskName><rndTaskNumber>1375027631</rndTaskNumber></rndInfo></rndInfoArray></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>