<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:45.4145</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0014362</applicationNumber><claimCount>21</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>영상 분석 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>VIDEO ANALIZING APPARATUS AND OPERATING METHOD OF THEREOF</inventionTitleEng><openDate>2024.08.06</openDate><openNumber>10-2024-0119855</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.01.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06Q 10/10</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 실시예는, 영상 분석 장치와 영상 분석 장치의 동작 방법에 대한 것이다. 실시예에 따른 영상 분석 장치의 동작 방법은, 입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계; 상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계; 및 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 도출하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 영상 분석 장치의 동작 방법에 있어서,입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계;상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계; 및학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 도출하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 분석하는 단계는,레이블링된 감정 종류별로 상기 멀티모달 데이터가 해당 감정을 나타낼 확률을 각각 도출하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계는,카메라를 통해 입력되는 상기 사용자의 얼굴 영역을 포함하는 영상 데이터에서 상기 사용자의 적어도 하나의 신체 부위를 탐지하는 단계; 및상기 탐지된 적어도 하나의 신체 부위의 움직임을 추적하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 사용자의 적어도 하나의 신체 부위는,상기 사용자의 눈, 입술, 얼굴, 손, 어깨 중 적어도 하나를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 도출하는 단계는,상기 미리 정해진 시간 간격으로 상기 멀티모달 데이터를 분석하는 단계; 및상기 분석된 감정 정보를 상기 미리 정해진 시간 간격으로 제공하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계는,상기 사용자에게 질의를 제공하는 단계;상기 질의에 반응하여, 상기 입력 장치를 통해 입력되는 상기 사용자의 음성 데이터를 수신하는 단계; 및상기 음성 데이터를 텍스트 데이터로 변환하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 분석하는 단계는,상기 텍스트 데이터로부터 키워드들을 추출하는 단계; 및상기 학습된 신경망을 통해 상기 키워드들에 대응하는 상기 감정 정보를 분석하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 학습된 신경망은,적어도 하나의 멀티모달 데이터 및 상기 적어도 하나의 멀티모달 데이터에 감정 정보가 레이블링된 학습 데이터 세트에 기초하여 학습되는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 학습된 신경망은,시계열 축에서 상기 멀티모달 데이터 사이의 중요도를 다르게 출력하도록 학습되는,영상 분석 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 신경망을 학습하는 방법에 있어서,멀티모달 데이터들 및 상기 멀티모달 데이터들에 레이블링된 감정 정보를 포함하는 학습 데이터를 획득하는 단계;적어도 하나의 신체 부위가 탐지되는 복수 개의 영상 데이터들을 분석하여 획득한 멀티모달 데이터를 상기 신경망에 입력하는 단계; 및상기 멀티모달 데이터에 대응하여 레이블링된 감정 정보가 출력되도록 상기 신경망을 학습하는 단계를 포함하는,신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 적어도 하나의 신체 부위는,눈, 입술, 얼굴, 손, 어깨 중 적어도 하나를 포함하고,상기 멀티모달 데이터는, 상기 적어도 하나의 신체 부위의 움직임을 포함하는,신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 멀티모달 데이터를 추출하여 상기 신경망에 입력하는 단계는,상기 적어도 하나의 신체 부위의 움직임 정보를 상기 신경망에 입력하는 단계; 및질의에 대한 반응에 해당하는 반응 정보를 상기 신경망에 입력하는 단계를 포함하는, 신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 질의에 대한 반응 정보는,미리 정해진 질의에 반응하여 입력되는 상기 적어도 하나의 신체 부위의 움직임 및 음성 데이터를 포함하는 멀티모달 데이터인,신경망을 학습하는 방법.</claim></claimInfo><claimInfo><claim>14. 하드웨어와 결합되어 제1항 내지 제13항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능 기록 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 영상 분석 장치에 있어서,하나 이상의 프로세서;메모리; 및상기 메모리에 저장되어 있으며 상기 하나 이상의 프로세서에 의하여 실행되도록 구성되는 하나 이상의 프로그램을 포함하고,상기 프로그램은,입력 장치를 통해 원격의 사용자의 영상을 획득하는 단계;상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계; 및학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 도출하는 단계를 실행하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 분석하는 단계는,레이블링된 감정 종류별로 상기 멀티모달 데이터가 해당 감정을 나타낼 확률을 각각 도출하는 단계를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 영상을 분석하여 상기 사용자의 멀티모달 데이터를 획득하는 단계는,카메라를 통해 입력되는 상기 사용자의 얼굴 영역을 포함하는 영상 데이터에서 상기 사용자의 적어도 하나의 신체 부위를 탐지하는 단계; 및상기 탐지된 적어도 하나의 신체 부위의 움직임을 추적하는 단계를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 사용자의 적어도 하나의 신체 부위는,상기 사용자의 눈, 입술, 얼굴, 손, 어깨 중 적어도 하나를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서,상기 학습된 신경망을 통해 상기 멀티모달 데이터를 분석하여 상기 사용자의 감정 정보를 도출하는 단계는,상기 미리 정해진 시간 간격으로 상기 멀티모달 데이터를 분석하는 단계; 및상기 분석된 감정 정보를 상기 미리 정해진 시간 간격으로 제공하는 단계를 포함하는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서,상기 학습된 신경망은,적어도 하나의 멀티모달 데이터 및 상기 적어도 하나의 멀티모달 데이터에 감정 정보가 레이블링된 학습 데이터 세트에 기초하여 학습되는,영상 분석 장치.</claim></claimInfo><claimInfo><claim>21. 영상 분석 장치의 동작 방법에 있어서,입력 장치를 통해 사용자의 영상 데이터를 획득하는 단계;상기 영상 데이터로부터 상기 사용자의 멀티모달 데이터를 획득하는 단계; 및- 상기 멀티모달 데이터로부터 상기 사용자의 얼굴, 음성을 인식하는 단계; 및- 상기 인식된 얼굴 및 음성에 기초하여 상기 사용자의 움직임 정보, 상기 음성의 톤 정보, 상기 음성의 텍스트 정보 및 상기 사용자의 심박 정보를 획득하는 단계학습된 신경망을 통해 상기 멀티모달 데이터를 시계열적으로 분석하여 상기 사용자의 감정 정보를 도출하는 단계를 포함하는,영상 분석 장치의 동작 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>부산광역시 강서구...</address><code>120170679454</code><country>대한민국</country><engName>WITHMIND</engName><name>주식회사 위드마인드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>JOO Min Sung</engName><name>주민성</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.01.30</priorityApplicationDate><priorityApplicationNumber>1020230012051</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.01.30</receiptDate><receiptNumber>1-1-2024-0120575-33</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.03.11</receiptDate><receiptNumber>4-1-2024-5088819-71</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.11.21</receiptDate><receiptNumber>4-1-2024-5339798-63</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240014362.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c84b81bbf751471c48d0354006987012634ba4fb3dd7fcc01c94d57bf98143ff0d96831e333c3928c493614e1a45d58fbe5c62b4d88b0703</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4893544a71462661ab3f2b85b98399c70e37d9f7d767b26f9afe71709560874c8d56c85942f133a3a86a11af2bdd391aabb0e1a7ada228d2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>