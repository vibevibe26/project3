<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:24.4024</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7027508</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>AR 신체 부분 추적 시스템</inventionTitle><inventionTitleEng>AR BODY PART TRACKING SYSTEM</inventionTitleEng><openDate>2024.09.20</openDate><openNumber>10-2024-0139063</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.16</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.08.16</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/776</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 AR 아이템들을 제시하기 위한 시스템을 수반한다. 이러한 시스템은 동작들을 수행하고, 이러한 동작들은, 현실-세계 환경에서의 제1 현실-세계 신체 부분의 묘사를 포함하는 이미지를 수신하는 동작; 이미지에서의 복수의 픽셀들의 각각의 픽셀과 각각 연관된 복수의 조밀한 출력들을 생성하기 위해 이미지에 머신 학습 기술을 적용하는 동작; 제1 현실-세계 신체 부분의 중심에 대응하는 픽셀을 식별하기 위해 복수의 조밀한 출력들에 제1 태스크-특유 디코더를 적용하는 동작; 복수의 조밀한 출력들로부터 제1 현실-세계 신체 부분의 3D 회전, 병진 및 스케일을 검색하기 위해 식별된 픽셀을 사용하여 제2 태스크-특유 디코더를 적용하는 동작; 제1 현실-세계 신체 부분의 3D 회전, 병진, 및 스케일에 기초하여 AR 객체를 수정하는 동작; 및 수정된 AR 객체의 묘사를 포함하도록 이미지를 수정하는 동작을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.07.20</internationOpenDate><internationOpenNumber>WO2023137482</internationOpenNumber><internationalApplicationDate>2023.01.17</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/060730</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 현실-세계 환경에서의 제1 현실-세계 신체 부분의 묘사를 포함하는 이미지를 수신하는 단계;상기 하나 이상의 프로세서에 의해, 상기 이미지에서의 복수의 픽셀들의 각각의 픽셀과 각각 연관된 복수의 조밀한 출력들을 생성하기 위해 상기 이미지에 머신 학습 기술을 적용하는 단계;상기 제1 현실-세계 신체 부분의 중심에 대응하는 픽셀을 식별하기 위해 상기 복수의 조밀한 출력들에 제1 태스크-특유 디코더를 적용하는 단계;상기 복수의 조밀한 출력들로부터 제1 현실-세계 신체 부분의 3차원(3D) 회전, 병진 및 스케일을 검색하기 위해 상기 식별된 픽셀을 사용하여 제2 태스크-특유 디코더를 적용하는 단계;제1 현실-세계 신체 부분의 상기 3D 회전, 병진, 및 스케일에 기초하여 AR(augmented reality) 객체를 수정하는 단계; 및상기 수정된 AR 객체의 묘사를 포함하도록 상기 이미지를 수정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 현실-세계 신체 부분은 현실-세계 발을 포함하고, 상기 AR 객체는 AR 신발 객체를 포함하며, 상기 식별된 픽셀을 좌측 또는 우측 발로서 분류하기 위해 제3-태스크 특유 디코더를 상기 복수의 조밀한 출력들에 적용하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 좌측 또는 우측 발로서의 상기 식별된 픽셀의 분류에 기초하여 좌측 AR 신발 객체와 우측 AR 신발 객체 사이에서 상기 AR 신발 객체를 선택하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 중심은 2차원(2D) 중심이며, 상기 방법은 상기 제1 현실-세계 신체 부분의 중심의 3D 좌표들을 컴퓨팅하기 위해 역 투영 모델을 상기 제1 현실-세계 신체 부분의 상기 2D 중심에 적용하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 AR 객체는 상기 제1 현실-세계 신체 부분의 중심의 3D 좌표들에 기초하여 수정되는 방법.</claim></claimInfo><claimInfo><claim>6. 제4항 또는 제5항에 있어서, 추가로,상기 이미지에 대한 디스패리티를 획득하기 위해 상기 복수의 조밀한 출력들에 제3 태스크-특유 디코더를 적용하는 단계- 상기 역 투영 모델은 상기 3D 좌표들을 컴퓨팅하기 위해 상기 이미지에 대한 디스패리티를 사용함 -를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 머신 학습 기술은 상기 복수의 조밀한 출력들을 동시에 생성하고, 상기 이미지에서의 상기 픽셀들 각각은 복수의 값들과 연관되고, 상기 복수의 조밀한 출력들 중 제1 조밀한 출력은 상기 제1 현실-세계 신체 부분의 중심과 연관된 픽셀들의 디스크를 포함하고, 상기 복수의 조밀한 출력들 중 제2 조밀한 출력은 상기 픽셀들의 디스크에서의 각각의 픽셀과 상기 제1 현실-세계 신체 부분의 중심 사이의 거리를 포함하고, 상기 복수의 조밀한 출력들 중 제3 조밀한 출력은 좌측 또는 우측 분류를 포함하고, 상기 복수의 조밀한 출력들 중 제4 조밀한 출력은 상기 제1 현실-세계 신체 부분의 회전을 포함하고, 상기 복수의 조밀한 출력들 중 제5 조밀한 출력은 상기 제1 현실-세계 신체 부분의 병진을 포함하고, 상기 복수의 조밀한 출력들 중 제6 조밀한 출력은 디스패리티를 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 복수의 조밀한 출력들에 상기 제1 태스크-특유 디코더를 적용하는 단계는,상이한 신체 부분 중심들을 표현하는 상기 복수의 조밀한 출력들로부터 복수의 중심 위치들을 획득하는 단계;상기 복수의 중심 위치들 각각을 스코어링하기 위해 상기 복수의 중심 위치들을 스코어링하는 단계; 및상기 복수의 중심 위치들 각각의 스코어에 기초하여 상기 복수의 중심 위치들 중 주어진 하나를 선택하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 복수의 중심 위치들은 백색 디스크를 포함하고, 상기 복수의 중심 위치들을 스코어링하는 단계는 상기 백색 디스크에서의 픽셀들 중에서 가장 백색의 픽셀 값을 표현하는 스코어를 배정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 추가로,상기 복수의 중심 위치들 각각과 상기 제1 현실-세계 신체 부분의 중심 사이의 복수의 거리들을 획득하기 위해 상기 복수의 조밀한 출력들에 제3 태스크 특유 디코더를 적용하는 단계;상기 백색 디스크에서의 상기 가장 백색의 픽셀 값과 연관된 상기 복수의 거리들로부터 주어진 거리를 식별하는 단계; 및상기 주어진 거리에 대응하는 상기 이미지에서의 픽셀 좌표를, 상기 식별된 픽셀로서, 획득하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 이미지는 복수의 현실-세계 발들을 묘사하고, 상기 머신 학습 기술은 상기 복수의 현실-세계 발들 각각에 대한 복수의 중심들 및 상기 복수의 현실-세계 발들 각각에 대한 각각의 3D 회전 및 병진을 추정하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 3D 회전, 병진 및 스케일은 PNP(Perspective-N-Point) 프로세스를 사용하지 않고 추정되는 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서, 트레이닝 데이터를 사용하여 상기 머신 학습 기술을 트레이닝하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 머신 학습 기술을 트레이닝하는 단계는,상기 트레이닝 데이터를 수신하는 단계- 상기 트레이닝 데이터는 복수의 트레이닝 이미지들 및 상기 복수의 트레이닝 이미지들에서 각각 묘사되는 트레이닝 현실-세계 신체 부분들과 연관된 복수의 실측 중심들을 포함하고, 상기 트레이닝 데이터는 상기 트레이닝 현실-세계 신체 부분 각각에 대한 실측 회전, 병진 및 스케일을 포함함 -;상기 제1 트레이닝 이미지에서 묘사되는 트레이닝 현실-세계 신체 부분의 복수의 트레이닝 조밀한 출력들을 추정하기 위해 상기 복수의 트레이닝 이미지들 중 제1 트레이닝 이미지에 상기 머신 학습 기술을 적용하는 단계;상기 제1 트레이닝 이미지에서 묘사되는 상기 트레이닝 현실-세계 신체 부분의 중심을 표현하는 상기 제1 트레이닝 이미지와 연관된 실측 중심 픽셀 좌표를 획득하는 단계;상기 실측 중심 픽셀 좌표에 기초하여, 상기 복수의 트레이닝 조밀한 출력들 중 하나와 연관된 편차 및 상기 제1 트레이닝 이미지와 연관된 실측 정보에 기초하여 하나 이상의 손실을 컴퓨팅하는 단계; 및상기 컴퓨팅된 편차에 기초하여 상기 머신 학습 기술의 파라미터들을 업데이트하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>15. 제13항 또는 제14항에 있어서, 상기 하나 이상의 손실 중 제1 손실은 상기 3D 회전, 병진 및 스케일에 대한 손실을 포함하고, 상기 방법은 추가로,상기 복수의 트레이닝 조밀한 출력들로부터 상기 트레이닝 제1 현실-세계 신체 부분의 추정된 3D 회전, 병진 및 스케일을 검색하기 위해 상기 실측 중심 픽셀 좌표를 사용하여 상기 제2 태스크 특유 디코더를 적용하는 단계; 및상기 트레이닝 제1 현실-세계 신체 부분의 상기 추정된 3D 회전, 병진 및 스케일과 상기 제1 트레이닝 이미지와 연관된 상기 트레이닝 제1 현실-세계 신체 부분의 상기 실측 회전, 병진 및 스케일 사이의 편차를 컴퓨팅하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서, 상기 하나 이상의 손실 중 제2 손실은 추정된 중심에 대한 손실을 포함하고, 상기 방법은 추가로,상기 제1 현실-세계 신체 부분의 중심에 대응하는 추정된 픽셀을 식별하기 위해 상기 복수의 조밀한 출력들에 상기 제1 태스크-특유 디코더를 적용하는 단계; 및상기 제1 현실-세계 신체 부분의 중심에 대응하는 상기 추정된 픽셀과 상기 실측 중심 픽셀 좌표 사이의 편차를 컴퓨팅하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 추가로,상기 트레이닝 현실-세계 신체 부분들 각각에 대한 상기 실측 회전, 병진, 및 스케일을 생성하기 위해 PNP(Perspective-N-Point) 프로세스에 상기 트레이닝 데이터를 적용하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 추가적인 트레이닝 데이터를 생성하기 위해 상기 복수의 트레이닝 이미지들에 데이터 증강 기술을 적용하는 단계- 상기 데이터 증강 기술은 상기 복수의 트레이닝 이미지들 중 주어진 하나에서 묘사되는 트레이닝 현실-세계 신체 부분에 대한 크롭핑, 플립핑, 회전, 컬러 수정, 또는 블러 적용 중 적어도 하나를 포함함 -를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서,하나 이상의 컴퓨터 프로세서; 및상기 하나 이상의 컴퓨터 프로세서에 의해 실행될 때, 상기 시스템으로 하여금 동작들을 수행하게 하는 명령어들을 저장한 하나 이상의 컴퓨터-판독가능 매체를 포함하고, 상기 동작들은,현실-세계 환경에서의 제1 현실-세계 신체 부분의 묘사를 포함하는 이미지를 수신하는 동작;상기 이미지에서의 복수의 픽셀들의 각각의 픽셀과 각각 연관된 복수의 조밀한 출력들을 생성하기 위해 상기 이미지에 머신 학습 기술을 적용하는 동작;상기 제1 현실-세계 신체 부분의 중심에 대응하는 픽셀을 식별하기 위해 상기 복수의 조밀한 출력들에 제1 태스크-특유 디코더를 적용하는 동작;상기 복수의 조밀한 출력들로부터 제1 현실-세계 신체 부분의 3차원(3D) 회전, 병진 및 스케일을 검색하기 위해 상기 식별된 픽셀을 사용하여 제2 태스크-특유 디코더를 적용하는 동작;제1 현실-세계 신체 부분의 상기 3D 회전, 병진, 및 스케일에 기초하여 AR(augmented reality) 객체를 수정하는 동작; 및상기 수정된 AR 객체의 묘사를 포함하도록 상기 이미지를 수정하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함하는 비-일시적 머신-판독가능 저장 매체로서, 상기 명령어들은, 하나 이상의 컴퓨팅 디바이스의 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 컴퓨팅 디바이스로 하여금 동작들을 수행하게 하고, 상기 동작들은,현실-세계 환경에서의 제1 현실-세계 신체 부분의 묘사를 포함하는 이미지를 수신하는 동작;상기 이미지에서의 복수의 픽셀들의 각각의 픽셀과 각각 연관된 복수의 조밀한 출력들을 생성하기 위해 상기 이미지에 머신 학습 기술을 적용하는 동작;상기 제1 현실-세계 신체 부분의 중심에 대응하는 픽셀을 식별하기 위해 상기 복수의 조밀한 출력들에 제1 태스크-특유 디코더를 적용하는 동작;상기 복수의 조밀한 출력들로부터 제1 현실-세계 신체 부분의 3차원(3D) 회전, 병진 및 스케일을 검색하기 위해 상기 식별된 픽셀을 사용하여 제2 태스크-특유 디코더를 적용하는 동작;제1 현실-세계 신체 부분의 상기 3D 회전, 병진, 및 스케일에 기초하여 AR(augmented reality) 객체를 수정하는 동작; 및상기 수정된 AR 객체의 묘사를 포함하도록 상기 이미지를 수정하는 동작을 포함하는 비-일시적 머신-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>STODDART, Daniel Monteiro</engName><name>스토다트, 다니엘 몬테이로</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>SKORDOS, Efstratios</engName><name>스코도스, 에프스트라티오스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>KOKKINOS, Iason</engName><name>코키노스, 이아손</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>그리스</priorityApplicationCountry><priorityApplicationDate>2022.01.17</priorityApplicationDate><priorityApplicationNumber>20220100040</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.09</priorityApplicationDate><priorityApplicationNumber>17/690,504</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.08.16</receiptDate><receiptNumber>1-1-2024-0891942-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.08.16</receiptDate><receiptNumber>1-1-2024-0893348-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.08.20</receiptDate><receiptNumber>1-5-2024-0136282-73</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2024.10.14</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247027508.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93cfee614daddf932494916502aa54309578bda5fd4e01505f83516b3446e88a13a486cd03e795bf21bf102b99f056be48d7e689d41c0f3df0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4cefca99ddc9543e1a76b5b06009e7cf8bbe4ab4189a75cabe05270807ea44f7666993b906211e326d822abf1a62e53a36d75a4e007e7b62</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>