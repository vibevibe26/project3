<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:56:14.5614</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.21</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7010274</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다중-관점 증강 현실 경험</inventionTitle><inventionTitleEng>MULTI-PERSPECTIVE AUGMENTED REALITY EXPERIENCE</inventionTitleEng><openDate>2025.04.23</openDate><openNumber>10-2025-0054817</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.28</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.28</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/81</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/344</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/478</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/4788</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/239</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/156</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/279</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/368</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/106</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/388</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/117</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/189</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용은 다중-관점 증강 현실 경험을 제공하기 위한 방법들 및 시스템들에 관한 것이다. 3차원 공간의 체적 비디오가 캡처된다. 3차원 공간의 체적 비디오는 3차원 공간 내에서 제1 사용자의 체적 표현을 포함한다. 체적 비디오는 제2 사용자에 의해 착용된 디스플레이 디바이스에 의해 디스플레이되고, 제2 사용자는 3차원 공간 내에서 제1 사용자의 체적 표현을 본다. 제2 사용자와 제1 사용자의 체적 표현의 상호작용(예를 들어, 들어가기 또는 나가기)을 표시하는 입력이 검출된다. 상호작용을 표시하는 입력을 검출하는 것에 기초하여, 디스플레이 디바이스는 제1 사용자의 기록된 관점의 디스플레이로 스위칭한다. 따라서, 체적 비디오에서 제1 사용자의 체적 표현과 상호작용함으로써, 제2 사용자는 3차원 공간의 제1 사용자의 관점을 본다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.07</internationOpenDate><internationOpenNumber>WO2024050245</internationOpenNumber><internationalApplicationDate>2023.08.21</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/072557</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,3차원 공간 내에서 제1 사용자의 체적(volumetric) 표현을 포함하는 체적 비디오를 포함하는 체적 콘텐츠에 액세스하는 단계;제2 사용자의 디스플레이 디바이스에 의해 상기 체적 비디오의 프레젠테이션(presentation)을 야기하는 단계 - 상기 체적 비디오의 프레젠테이션을 야기하는 것은 상기 3차원 공간 내에서 상기 제1 사용자의 체적 표현의 프레젠테이션을 야기하는 것을 포함함 -;상기 체적 비디오의 프레젠테이션 내에서 상기 제2 사용자와 상기 제1 사용자의 체적 표현의 상호작용을 표시하는 입력을 검출하는 단계; 및상기 제2 사용자에 의한 상기 제1 사용자의 체적 표현과의 상호작용을 표시하는 입력을 검출하는 것에 응답하여, 상기 3차원 공간의 상기 제1 사용자의 기록된 관점에 액세스하는 단계; 및 상기 디스플레이 디바이스로 하여금 상기 3차원 공간의 상기 제1 사용자의 기록된 관점의 프레젠테이션으로 스위칭하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제2 사용자와 상기 체적 표현의 상호작용을 표시하는 입력을 검출하는 단계는 상기 제2 사용자가 상기 제1 사용자의 체적 표현에 들어가는 것을 검출하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 제2 사용자가 상기 제1 사용자의 체적 표현에 들어가는 것을 검출하는 단계는:상기 제1 사용자의 체적 표현과 상기 제2 사용자의 실제 체적 신체(real-life volumetric body) 사이의 타깃 공간 관계를 검출하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 타깃 공간 관계를 검출하는 단계는:상기 제2 사용자의 실제 체적 신체가 상기 제1 사용자의 체적 표현과 적어도 부분적으로 중첩된다고 결정하는 단계;상기 제2 사용자의 실제 체적 신체가 상기 제1 사용자의 체적 표현의 미리 정의된 거리 내에 있다고 결정하는 단계; 또는상기 제2 사용자의 시선이 상기 제1 사용자의 체적 표현을 향한다고 결정하는 단계 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 제1 사용자의 기록된 관점은 상기 체적 비디오의 캡처 동안 상기 제1 사용자에 의해 제공된 오디오를 포함하는 오디오 신호를 추가로 포함하고, 상기 제1 사용자의 기록된 관점의 프레젠테이션을 야기하는 것은 상기 오디오 신호의 프레젠테이션을 야기하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 3차원 공간은 현실 세계 위치에 대응하고;상기 디스플레이 디바이스는 상기 현실 세계 위치에서 상기 제2 사용자에 의해 착용되고;상기 체적 비디오의 프레젠테이션은 상기 체적 비디오의 캡처 동안 상기 현실 세계 위치에서의 상기 제1 사용자의 포지션에 대응하는 상기 현실 세계 위치에서의 포지션에서 상기 현실 세계 위치 상에 오버레이된 상기 제1 사용자의 체적 표현의 프레젠테이션을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 3차원 공간은 제1 현실 세계 위치에 대응하고;상기 디스플레이 디바이스는 제2 현실 세계 위치에서 상기 제2 사용자에 의해 착용되고;상기 체적 비디오의 프레젠테이션은 상기 체적 비디오의 캡처 동안 상기 현실 세계 위치에서의 상기 제1 사용자의 포지션에 대응하는 상기 3차원 공간에서의 포지션에서 상기 제1 사용자의 체적 표현의 프레젠테이션을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 디스플레이 디바이스에 의해 상기 체적 비디오의 프레젠테이션을 야기하는 단계는 상기 현실 세계 위치의 하나 이상의 요소 상에 오버레이된 하나 이상의 AR 콘텐츠 아이템의 프레젠테이션을 야기하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 3차원 공간은 현실 세계 위치에 대응하고;상기 디스플레이 디바이스는 상기 현실 세계 위치에서 상기 제2 사용자에 의해 착용되고;상기 디스플레이 디바이스에 의해 상기 체적 비디오의 프레젠테이션을 야기하는 단계는 상기 현실 세계 위치의 하나 이상의 요소 상에 오버레이된 상기 제1 사용자의 체적 표현의 프레젠테이션을 야기하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 체적 비디오는 상기 제2 사용자의 체적 표현을 추가로 포함하고;상기 제1 사용자의 기록된 관점은 상기 제2 사용자의 체적 표현을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 3차원 공간은 상기 제2 사용자를 포함하고, 상기 방법은:상기 3차원 공간 내에서 제2 사용자의 체적 표현을 포함하는 상기 체적 비디오를 포함하는 상기 체적 콘텐츠에 액세스하는 단계;제1 사용자의 디스플레이 디바이스에 의해 상기 3차원 공간 내에서 상기 제2 사용자의 체적 표현의 프레젠테이션을 야기하는 단계;상기 체적 비디오의 프레젠테이션 내에서 상기 제1 사용자와 상기 제2 사용자의 체적 표현의 상호작용을 표시하는 입력을 검출하는 단계; 및상기 제1 사용자에 의한 상기 제2 사용자의 체적 표현과의 상호작용을 표시하는 입력을 검출하는 것에 응답하여, 상기 3차원 공간의 상기 제2 사용자의 기록된 관점에 액세스하는 단계; 및 상기 제1 사용자의 디스플레이 디바이스로 하여금 상기 3차원 공간의 상기 제2 사용자의 기록된 관점의 프레젠테이션으로 스위칭하게 하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 컴퓨팅 장치로서,프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때,3차원 공간 내에서 제1 사용자의 체적 표현을 포함하는 체적 비디오를 포함하는 체적 콘텐츠에 액세스하고;제2 사용자의 디스플레이 디바이스에 의해 상기 체적 비디오의 프레젠테이션을 야기하고 - 상기 체적 비디오의 프레젠테이션을 야기하는 것은 상기 3차원 공간 내에서 상기 제1 사용자의 체적 표현의 프레젠테이션을 야기하는 것을 포함함 -;상기 체적 비디오의 프레젠테이션 내에서 상기 제2 사용자와 상기 제1 사용자의 체적 표현의 상호작용을 표시하는 입력을 검출하고;상기 제2 사용자에 의한 상기 제1 사용자의 체적 표현과의 상호작용을 표시하는 입력을 검출하는 것에 응답하여, 상기 3차원 공간의 상기 제1 사용자의 기록된 관점에 액세스하고; 상기 디스플레이 디바이스로 하여금 상기 3차원 공간의 상기 제1 사용자의 기록된 관점의 프레젠테이션으로 스위칭하게 하도록 상기 장치를 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제2 사용자와 상기 체적 표현의 상호작용을 표시하는 입력을 검출하기 위해, 상기 명령어들은,상기 제1 사용자의 체적 표현과 상기 제2 사용자의 실제 체적 신체 사이의 타깃 공간 관계를 검출하도록 상기 장치를 추가로 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 타깃 공간 관계를 검출하기 위해, 상기 명령어들은:상기 제2 사용자의 실제 체적 신체가 상기 제1 사용자의 체적 표현과 적어도 부분적으로 중첩된다고 결정하거나;상기 제2 사용자의 실제 체적 신체가 상기 제1 사용자의 체적 표현의 미리 정의된 거리 내에 있다고 결정하거나; 또는상기 제2 사용자의 시선이 상기 제1 사용자의 체적 표현을 향한다고 결정하도록 상기 장치를 추가로 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 제12항에 있어서,상기 3차원 공간은 현실 세계 위치에 대응하고;상기 디스플레이 디바이스는 상기 현실 세계 위치에서 상기 제2 사용자에 의해 착용되고;상기 체적 비디오의 프레젠테이션은 상기 체적 비디오의 캡처 동안 상기 현실 세계 위치에서의 상기 제1 사용자의 포지션에 대응하는 상기 현실 세계 위치에서의 포지션에서 상기 현실 세계 위치 상에 오버레이된 상기 제1 사용자의 체적 표현의 프레젠테이션을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 3차원 공간은 제1 현실 세계 위치에 대응하고;상기 디스플레이 디바이스는 제2 현실 세계 위치에서 상기 제2 사용자에 의해 착용되고;상기 체적 비디오의 프레젠테이션은 상기 체적 비디오의 캡처 동안 상기 현실 세계 위치에서의 상기 제1 사용자의 포지션에 대응하는 상기 3차원 공간에서의 포지션에서 상기 제1 사용자의 체적 표현의 프레젠테이션을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 디스플레이 디바이스에 의해 상기 체적 비디오의 프레젠테이션을 야기하는 것은 상기 현실 세계 위치의 하나 이상의 요소 상에 오버레이된 하나 이상의 AR 콘텐츠 아이템의 프레젠테이션을 야기하는 것을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서,상기 3차원 공간은 현실 세계 위치에 대응하고;상기 디스플레이 디바이스는 상기 현실 세계 위치에서 상기 제2 사용자에 의해 착용되고;상기 디스플레이 디바이스에 의해 상기 체적 비디오의 프레젠테이션을 야기하는 것은 상기 현실 세계 위치의 하나 이상의 요소 상에 오버레이된 상기 제1 사용자의 체적 표현의 프레젠테이션을 야기하는 것을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>19. 제12항에 있어서,상기 체적 비디오는 상기 제2 사용자의 체적 표현을 추가로 포함하고;상기 제1 사용자의 기록된 관점은 상기 제2 사용자의 체적 표현을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>20. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금,3차원 공간 내에서 제1 사용자의 체적 표현을 포함하는 체적 비디오를 포함하는 체적 콘텐츠에 액세스하게 하고;제2 사용자의 디스플레이 디바이스에 의해 상기 체적 비디오의 프레젠테이션을 야기하게 하고 - 상기 체적 비디오의 프레젠테이션을 야기하는 것은 상기 3차원 공간 내에서 상기 제1 사용자의 체적 표현의 프레젠테이션을 야기하는 것을 포함함 -;상기 체적 비디오의 프레젠테이션 내에서 상기 제2 사용자와 상기 제1 사용자의 체적 표현의 상호작용을 표시하는 입력을 검출하게 하고;상기 제2 사용자에 의한 상기 제1 사용자의 체적 표현과의 상호작용을 표시하는 입력을 검출하는 것에 응답하여, 상기 3차원 공간의 상기 제1 사용자의 기록된 관점에 액세스하게 하고; 상기 디스플레이 디바이스로 하여금 상기 3차원 공간의 상기 제1 사용자의 기록된 관점의 프레젠테이션으로 스위칭하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>인도</country><engName>VAISH, Rajan</engName><name>바이쉬, 라잔</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>독일</country><engName>KRATZ, Sven</engName><name>크라츠, 스벤</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>멕시코</country><engName>MONROY-HERNANDEZ, Andres</engName><name>몬로이-에르난데즈, 안드레스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>SMITH, Brian Anthony</engName><name>스미스, 브라이언 앤소니</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.31</priorityApplicationDate><priorityApplicationNumber>17/900,200</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.28</receiptDate><receiptNumber>1-1-2025-0352463-93</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.04.01</receiptDate><receiptNumber>1-5-2025-0054486-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.10.29</receiptDate><receiptNumber>1-1-2025-1206026-42</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[우선심사신청]심사청구서·우선심사신청서</documentName><receiptDate>2025.10.29</receiptDate><receiptNumber>1-1-2025-1206040-82</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257010274.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9363100c2748609d2de64702bc9c4ffd30ead72f242b85a57d25bde867066949ffd3f52068ef5f58e79aad7d3fa8b2f7a2cb7deef357fba113</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf13178c98c3ee5be0f621cb176bd1dc4592f3ed36f0e2fde3cd08e90cdfc806d3dc81eae4b436fafaa8a23100d9aa04fe2ef78aac6c9756fa</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>