<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:20.5120</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7024391</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 인체공학 평가 시스템</inventionTitle><inventionTitleEng>AUGMENTED REALITY ERGONOMICS EVALUATION SYSTEM</inventionTitleEng><openDate>2025.08.18</openDate><openNumber>10-2025-0123921</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.07.21</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> AR 디바이스의 AR 애플리케이션들을 위한 인체공학 평가 시스템이 설명된다. 일 양태에서, 방법은 증강 현실 애플리케이션의 사용자 인터페이스 요소들에 액세스하는 단계, 복수의 사용자 모델들 및 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 액세스하는 단계, 복수의 사용자 모델들 및 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 기초하여, 복수의 사용자 모델들로부터, 증강 현실 애플리케이션을 동작시키는 시뮬레이션된 증강 현실 디바이스와의 시뮬레이션된 사용자 상호작용들을 식별하는 단계, 시뮬레이션된 사용자 상호작용들에 컴퓨터 비전 알고리즘을 적용하는 단계, 시뮬레이션된 사용자 상호작용들에 기초하여 사용자 자세들 및 사용자 모션들을 식별하는 단계, 및 사용자 자세들 및 사용자 모션들에 기초하여 제1 인체공학 피드백을 생성하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.06.27</internationOpenDate><internationOpenNumber>WO2024137521</internationOpenNumber><internationalApplicationDate>2023.12.18</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/084658</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,증강 현실 애플리케이션의 사용자 인터페이스 요소들에 액세스하는 단계;복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 액세스하는 단계;상기 복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 기초하여, 상기 복수의 사용자 모델들로부터, 상기 증강 현실 애플리케이션을 동작시키는 시뮬레이션된 증강 현실 디바이스와의 시뮬레이션된 사용자 상호작용들을 식별하는 단계;상기 시뮬레이션된 사용자 상호작용들에 컴퓨터 비전 알고리즘을 적용하는 단계;상기 시뮬레이션된 사용자 상호작용들에 기초하여 사용자 자세들 및 사용자 모션들을 식별하는 단계; 및상기 사용자 자세들 및 상기 사용자 모션들에 기초하여 제1 인체공학 피드백(ergonomic feedback)을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 인체공학 피드백은 상기 증강 현실 애플리케이션의 사용자 인터페이스 요소들의 인체공학 평가(ergonomics evaluation)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 인체공학 평가는 상기 사용자 인터페이스 요소들에 대한 제안된 조정들을 표시하고, 상기 제안된 조정들은 상기 증강 현실 애플리케이션의 타깃 사용자 그룹에 대응하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제안된 조정들은 사용자 인터페이스 요소 스케일(user interface element scale), 손잡이 구성(handedness configuration), 및 가상 객체 크기의 조합을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서, 상기 인체공학 피드백은 상기 사용자 인터페이스 요소들에 대한 상기 제안된 조정들에 기초하여 상기 증강 현실 애플리케이션에 대한 추정된 사용자 시간 소비 변경들(estimated user time spending changes)을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,사용자에 의해 동작되는 사용자 증강 현실 디바이스로부터의 센서 데이터에 액세스하는 단계 - 상기 사용자 증강 현실 디바이스는 상기 증강 현실 애플리케이션을 동작시키고, 상기 센서 데이터는 상기 사용자 증강 현실 디바이스의 이미지 센서에 의해 캡처된 이미지들 및 상기 사용자 증강 현실 디바이스의 관성 모션 유닛 디바이스로부터의 관성 모션 유닛 신호들을 포함함 -;상기 센서 데이터에 상기 컴퓨터 비전 알고리즘을 적용하여 상기 사용자의 자세 및 모션들을 식별하는 단계; 및상기 사용자의 자세 및 모션들에 기초하여 상기 사용자에 대한 제2 인체공학 피드백을 생성하는 단계를 추가로 포함하고, 상기 제2 인체공학 피드백은 상기 사용자 증강 현실 디바이스를 동작시키는 동안 상기 사용자의 자세에 대한 제안된 조정들을 표시하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 센서 데이터를 기록하는 단계; 및상기 센서 데이터를 이용하여 상기 복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터를 업데이트하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 사용자 증강 현실 디바이스의 센서 데이터 및 상기 사용자의 프로파일에 기초하여 상기 사용자에 대응하는 사용자 그룹을 식별하는 단계; 및상기 사용자 그룹, 상기 사용자 증강 현실 디바이스의 센서 데이터, 및 상기 사용자의 프로파일에 기초하여 상기 복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터를 캘리브레이션하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 사용자 증강 현실 디바이스로부터 증강 현실 애플리케이션 쿼리 요청을 수신하는 단계;상기 증강 현실 애플리케이션 쿼리 요청을 수신하는 것에 응답하여, 상기 사용자에 대응하는 상기 사용자 그룹과 호환가능한 적어도 하나의 증강 현실 애플리케이션을 식별하는 단계; 및상기 사용자 증강 현실 디바이스에서, 상기 적어도 하나의 증강 현실 애플리케이션의 사용자 인터페이스 요소들의 인체공학 평가를 제시하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 복수의 사용자 모델들의 각각의 사용자 모델은 사용자의 신체 부분의 물리적 치수들의 범위를 표시하는, 방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨팅 장치로서,프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 프로세서에 의해 실행될 때,증강 현실 애플리케이션의 사용자 인터페이스 요소들에 액세스하고;복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 액세스하고;상기 복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 기초하여, 상기 복수의 사용자 모델들로부터, 상기 증강 현실 애플리케이션을 동작시키는 시뮬레이션된 증강 현실 디바이스와의 시뮬레이션된 사용자 상호작용들을 식별하고;상기 시뮬레이션된 사용자 상호작용들에 컴퓨터 비전 알고리즘을 적용하고;상기 시뮬레이션된 사용자 상호작용들에 기초하여 사용자 자세들 및 사용자 모션들을 식별하고;상기 사용자 자세들 및 상기 사용자 모션들에 기초하여 제1 인체공학 피드백을 생성하도록 상기 장치를 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제1 인체공학 피드백은 상기 증강 현실 애플리케이션의 사용자 인터페이스 요소들의 인체공학 평가를 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 인체공학 평가는 상기 사용자 인터페이스 요소들에 대한 제안된 조정들을 표시하고, 상기 제안된 조정들은 상기 증강 현실 애플리케이션의 타깃 사용자 그룹에 대응하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 제안된 조정들은 사용자 인터페이스 요소 스케일, 손잡이 구성, 및 가상 객체 크기의 조합을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서, 상기 인체공학 피드백은 상기 사용자 인터페이스 요소들에 대한 상기 제안된 조정들에 기초하여 상기 증강 현실 애플리케이션에 대한 추정된 사용자 시간 소비 변경들을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 명령어들은:사용자에 의해 동작되는 사용자 증강 현실 디바이스로부터의 센서 데이터에 액세스하고 - 상기 사용자 증강 현실 디바이스는 상기 증강 현실 애플리케이션을 동작시키고, 상기 센서 데이터는 상기 사용자 증강 현실 디바이스의 이미지 센서에 의해 캡처된 이미지들 및 상기 사용자 증강 현실 디바이스의 관성 모션 유닛 디바이스로부터의 관성 모션 유닛 신호들을 포함함 -;상기 센서 데이터에 상기 컴퓨터 비전 알고리즘을 적용하여 상기 사용자의 자세 및 모션들을 식별하고;상기 사용자의 자세 및 모션들에 기초하여 상기 사용자에 대한 제2 인체공학 피드백을 생성하도록 상기 장치를 추가로 구성하고, 상기 제2 인체공학 피드백은 상기 사용자 증강 현실 디바이스를 동작시키는 동안 상기 사용자의 자세에 대한 제안된 조정들을 표시하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 명령어들은:상기 센서 데이터를 기록하고;상기 센서 데이터를 이용하여 상기 복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터를 업데이트하도록 상기 장치를 추가로 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 명령어들은:상기 사용자 증강 현실 디바이스의 센서 데이터 및 상기 사용자의 프로파일에 기초하여 상기 사용자에 대응하는 사용자 그룹을 식별하고;상기 사용자 그룹, 상기 사용자 증강 현실 디바이스의 센서 데이터, 및 상기 사용자의 프로파일에 기초하여 상기 복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터를 캘리브레이션하도록 상기 장치를 추가로 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 명령어들은:상기 사용자 증강 현실 디바이스로부터 증강 현실 애플리케이션 쿼리 요청을 수신하고;상기 증강 현실 애플리케이션 쿼리 요청을 수신하는 것에 응답하여, 상기 사용자에 대응하는 상기 사용자 그룹과 호환가능한 적어도 하나의 증강 현실 애플리케이션을 식별하고;상기 사용자 증강 현실 디바이스에서, 상기 적어도 하나의 증강 현실 애플리케이션의 사용자 인터페이스 요소들의 인체공학 평가를 제시하도록 상기 장치를 추가로 구성하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>20. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는 명령어들을 포함하고, 상기 명령어들은, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금,증강 현실 애플리케이션의 사용자 인터페이스 요소들에 액세스하게 하고;복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 액세스하게 하고;상기 복수의 사용자 모델들 및 상기 복수의 사용자 모델들에 대한 대응하는 시뮬레이션된 증강 현실 디바이스 센서 데이터에 기초하여, 상기 복수의 사용자 모델들로부터, 상기 증강 현실 애플리케이션을 동작시키는 시뮬레이션된 증강 현실 디바이스와의 시뮬레이션된 사용자 상호작용들을 식별하게 하고;상기 시뮬레이션된 사용자 상호작용들에 컴퓨터 비전 알고리즘을 적용하게 하고;상기 시뮬레이션된 사용자 상호작용들에 기초하여 사용자 자세들 및 사용자 모션들을 식별하게 하고;상기 사용자 자세들 및 상기 사용자 모션들에 기초하여 제1 인체공학 피드백을 생성하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>XI, Yubin</engName><name>시, 유빈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>ZHOU, Kai</engName><name>저우, 카이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.12.21</priorityApplicationDate><priorityApplicationNumber>18/069,779</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.07.21</receiptDate><receiptNumber>1-1-2025-0821225-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.07.25</receiptDate><receiptNumber>1-5-2025-0125528-97</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257024391.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9379d33ad6429f17c32d91a0963c78c0cbbe0fb0662846ba727bfb5ac0e7edaf8bc547f09c370a14f453ba63cd2c4debdd5856b4c36128fd89</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa6469609a00e18b95c7e5c3439a373b8872e512a3e28ebfb9b0db1351b6acf537208cd778ca24a32c155365f295f6f2e38cf677fe2c78e28</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>