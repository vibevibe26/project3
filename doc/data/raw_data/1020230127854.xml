<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:29.529</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0127854</applicationNumber><claimCount>21</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>3차원 객체의 임의의 시점에서의 2차원 이미지를 예측하는 방법을 학습하기 위한 전자 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>An electronic device for learning a method to predict  a 2D image of 3D object in an arbitrary view and  an operation method thereof</inventionTitleEng><openDate>2025.04.01</openDate><openNumber>10-2025-0045058</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.09.25</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 3차원 객체의 임의의 시점에서의 2차원 이미지를 예측하는 방법을 학습하기 위한 전자 장치가 개시된다. 이 전자 장치는, 저장부, 및 프로세서를 포함하고, 상기 프로세서는, 상호 연결된 복수의 메쉬를 포함하는 메쉬 구조를 생성하고, 색 예측 인공 신경망을 이용해 타겟 메쉬, 및 상기 타겟 메쉬 주변의 복수의 주변 메쉬 각각의 위치 및 표면 법선 방향 및 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측함으로써 2차원 이미지를 예측하고, 예측된 상기 2차원 이미지와 상기 시점 방향에서 상기 3차원 객체의 실제 2차원 이미지 사이의 차이로부터 제1 이미지 손실을 계산하고, 상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 3차원 객체의 임의의 시점에서의 2차원 이미지를 예측하는 방법을 학습하기 위한 전자 장치에 있어서,저장부; 및프로세서;를 포함하고,상기 프로세서는, 상호 연결된 복수의 메쉬를 포함하는 메쉬 구조를 생성하고,색 예측 인공 신경망을 이용해 타겟 메쉬, 및 상기 타겟 메쉬 주변의 복수의 주변 메쉬 각각의 위치 및 표면 법선 방향 및 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측함으로써 2차원 이미지를 예측하고,예측된 상기 2차원 이미지와 상기 시점 방향에서 상기 3차원 객체의 실제 2차원 이미지 사이의 차이로부터 제1 이미지 손실을 계산하고,상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 프로세서는,변화량 예측 인공 신경망을 이용해 상기 복수의 메쉬의 위치 및 표면 법선 방향으로부터 상기 복수의 메쉬의 위치의 변화량 및 표면 법선 방향의 변화량을 계산하고, 상기 복수의 메쉬의 위치의 변화량 및 표면 법선 방향의 변화량에 기초해 상기 복수의 메쉬의 위치 및 상기 표면 법선 방향을 수정하고,상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터, 상기 변화량 예측 인공 신경망의 파라미터, 및 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 프로세서는,위치 인코더를 이용해 상기 복수의 메쉬 각각의 위치로부터 상기 복수의 메쉬 각각의 위치 특징을 추출하고,상기 색 예측 인공 신경망을 이용해 상기 타겟 메쉬, 및 상기 복수의 주변 메쉬 각각의 위치 특징 및 표면 법선 방향 및 상기 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측함으로써 상기 복수의 메쉬 각각의 위치의 색을 예측하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,상기 프로세서는,상기 색 예측 인공 신경망의 제1 서브 인공 신경망을 이용해 상기 타겟 메쉬, 및 상기 복수의 주변 메쉬 각각의 위치 특징으로부터 상기 타겟 메쉬의 위치의 중간 특징을 추출함으로써 상기 복수의 메쉬 각각의 위치의 중간 특징을 추출하고,상기 색 예측 인공 신경망의 제2 서브 인공 신경망을 이용해 타겟 메쉬, 및 상기 타겟 메쉬 주변의 복수의 주변 메쉬 각각의 상기 중간 특징 및 상기 표면 법선 방향 및 상기 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측하는, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,상기 프로세서는,예측된 상기 2차원 이미지에서 상기 3차원 객체가 차지하는 부분을 나타내는 마스크와 상기 실제 2차원 이미지에서 상기 3차원 객체가 차지하는 부분을 나타내는 실제 마스크 사이의 차이로부터 제2 이미지 손실을 계산하고,상기 제1 이미지 손실 및 상기 제2 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,상기 프로세서는,상기 예측된 2차원 이미지를, 입력 층, 중간 층, 및 출력 층을 포함하는 사전 학습된 평가용 인공 신경망의 상기 입력 층에 입력했을 때 상기 중간 층의 출력과 상기 실제 2차원 이미지를 상기 입력 층에 입력했을 때 상기 중간 층의 출력 사이의 차이로부터 제3 이미지 손실을 계산하고,상기 제1 이미지 손실 및 상기 제3 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 프로세서는,상기 예측된 2차원 이미지와 상기 실제 2차원 이미지 사이의 SSIM(Structural Similarity Index Measure)로부터 제4 이미지 손실을 계산하고,상기 제1 이미지 손실 및 상기 제4 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서,상기 프로세서는,상기 메쉬 구조의 이웃한 꼭지점들 사이의 거리로부터 제1 메쉬 손실을 계산하고,상기 제1 이미지 손실 및 상기 제1 메쉬 손실에 기초해 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,상기 프로세서는,상기 메쉬 구조의 이웃한 표면들의 표면 법선 방향들 사이의 각도로부터 제2 메쉬 손실을 계산하고, 상기 제1 이미지 손실 및 상기 제2 메쉬 손실에 기초해 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제1 항에 있어서,상기 프로세서는,상기 복수의 메쉬 각각을 복수의 서브 메쉬로 분할하고,상기 색 예측 인공 신경망을 이용해 타겟 서브 메쉬, 및 상기 타겟 서브 메쉬 주변의 복수의 주변 서브 메쉬 각각의 위치 및 표면 법선 방향 및 시점 방향으로부터 상기 타겟 서브 메쉬의 위치의 색을 예측함으로써 새로운 2차원 이미지를 예측하고,예측된 새로운 2차원 이미지와 상기 시점 방향에서 상기 3차원 객체의 실제 2차원 이미지 사이의 차이로부터 새로운 제1 이미지 손실을 계산하고,상기 새로운 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는, 전자 장치.</claim></claimInfo><claimInfo><claim>11. 3차원 객체의 임의의 시점에서의 2차원 이미지를 예측하는 방법을 학습하기 위한 전자 장치의 동작 방법에 있어서,상호 연결된 복수의 메쉬를 포함하는 메쉬 구조를 생성하는 단계;색 예측 인공 신경망을 이용해 타겟 메쉬, 및 상기 타겟 메쉬 주변의 복수의 주변 메쉬 각각의 위치 및 표면 법선 방향 및 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측함으로써 2차원 이미지를 예측하는 단계;예측된 상기 2차원 이미지와 상기 시점 방향에서 상기 3차원 객체의 실제 2차원 이미지의 사이의 차이로부터 제1 이미지 손실을 계산하는 단계; 및상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계;를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,변화량 예측 인공 신경망을 이용해 상기 복수의 메쉬의 위치 및 표면 법선 방향으로부터 상기 복수의 메쉬의 위치의 변화량 및 표면 법선 방향의 변화량을 계산하는 단계; 및상기 복수의 메쉬의 위치의 변화량 및 표면 법선 방향의 변화량에 기초해 상기 복수의 메쉬의 위치 및 상기 표면 법선 방향을 수정하는 단계;를 더 포함하고,상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계는, 상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터, 상기 변화량 예측 인공 신경망의 파라미터, 및 상기 메쉬 구조를 수정하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>13. 제11 항에 있어서,상기 2차원 이미지를 예측하는 단계는,위치 인코더를 이용해 상기 복수의 메쉬 각각의 위치로부터 상기 복수의 메쉬 각각의 위치 특징을 추출하는 단계; 및상기 색 예측 인공 신경망을 이용해 상기 타겟 메쉬, 및 상기 복수의 주변 메쉬 각각의 위치 특징 및 표면 법선 방향 및 상기 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측함으로써 상기 복수의 메쉬 각각의 위치의 색을 예측하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,상기 복수의 메쉬 각각의 위치의 색을 예측하는 단계는,상기 색 예측 인공 신경망의 제1 서브 인공 신경망을 이용해 상기 타겟 메쉬, 및 상기 복수의 주변 메쉬 각각의 위치 특징으로부터 상기 타겟 메쉬의 위치의 중간 특징을 추출함으로써 상기 복수의 메쉬 각각의 위치의 중간 특징을 추출하는 단계; 및상기 색 예측 인공 신경망의 제2 서브 인공 신경망을 이용해 타겟 메쉬, 및 상기 타겟 메쉬 주변의 상기 복수의 주변 메쉬 각각의 상기 중간 특징 및 상기 표면 법선 방향 및 상기 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>15. 제11 항에 있어서,예측된 상기 2차원 이미지에서 상기 3차원 객체가 차지하는 부분을 나타내는 마스크와 상기 실제 2차원 이미지에서 상기 3차원 객체가 차지하는 부분을 나타내는 실제 마스크 사이의 차이로부터 제2 이미지 손실을 계산하는 단계를 더 포함하고,상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계는, 상기 제1 이미지 손실 및 상기 제2 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>16. 제11 항에 있어서,상기 예측된 2차원 이미지를, 입력 층, 중간 층, 및 출력 층을 포함하는 사전 학습된 평가용 인공 신경망의 상기 입력 층에 입력했을 때 상기 중간 층의 출력과 상기 실제 2차원 이미지를 상기 입력 층에 입력했을 때 상기 중간 층의 출력 사이의 차이로부터 제3 이미지 손실을 계산하는 단계를 더 포함하고,상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계는, 상기 제1 이미지 손실 및 상기 제3 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>17. 제11 항에 있어서,상기 예측된 2차원 이미지와 상기 실제 2차원 이미지 사이의 SSIM(Structural Similarity Index Measure)로부터 제4 이미지 손실을 계산하는 단계를 더 포함하고,상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계는, 상기 제1 이미지 손실 및 상기 제4 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>18. 제11 항에 있어서,상기 메쉬 구조의 이웃한 꼭지점들 사이의 거리로부터 제1 메쉬 손실을 계산하는 단계; 를 더 포함하고,상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계는, 상기 제1 이미지 손실 및 상기 제1 메쉬 손실에 기초해 상기 메쉬 구조를 수정하는 단계; 및 상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터를 수정하는 단계;를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>19. 제11 항에 있어서,상기 메쉬 구조의 이웃한 표면들의 표면 법선 방향들 사이의 각도로부터 제2 메쉬 손실을 계산하는 단계:를 더 포함하고, 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계는, 상기 제1 이미지 손실 및 상기 제2 메쉬 손실에 기초해 상기 메쉬 구조를 수정하는 단계; 및 상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터를 수정하는 단계;를 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>20. 제11 항에 있어서,상기 복수의 메쉬 각각을 복수의 서브 메쉬로 분할하는 단계;상기 색 예측 인공 신경망을 이용해 타겟 서브 메쉬, 및 상기 타겟 서브 메쉬 주변의 복수의 주변 서브 메쉬 각각의 위치 및 표면 법선 방향 및 시점 방향으로부터 상기 타겟 서브 메쉬의 위치의 색을 예측함으로써 새로운 2차원 이미지를 예측하는 단계;예측된 새로운 2차원 이미지와 상기 시점 방향에서 상기 3차원 객체의 실제 2차원 이미지 사이의 차이로부터 새로운 제1 이미지 손실을 계산하는 단계; 및상기 새로운 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계;를 더 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>21. 전자 장치의 프로세서에 의해 실행되는 경우 전자 장치의 동작을 수행하도록 하는 컴퓨터 명령을 저장하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 동작은,상호 연결된 복수의 메쉬를 포함하는 메쉬 구조를 생성하는 단계;색 예측 인공 신경망을 이용해 타겟 메쉬, 및 상기 타겟 메쉬 주변의 복수의 주변 메쉬 각각의 위치 및 표면 법선 방향 및 시점 방향으로부터 상기 타겟 메쉬의 위치의 색을 예측함으로써 2차원 이미지를 예측하는 단계;예측된 상기 2차원 이미지와 상기 시점 방향에서 상기 3차원 객체의 실제 2차원 이미지의 사이의 차이로부터 제1 이미지 손실을 계산하는 단계; 및상기 제1 이미지 손실에 기초해 상기 색 예측 인공 신경망의 파라미터 및 상기 메쉬 구조를 수정하는 단계;를 포함하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 용산구...</address><code>220050092977</code><country>대한민국</country><engName>Sookmyung Women's university industry-academic cooperation foundation</engName><name>숙명여자대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 용산구...</address><code> </code><country> </country><engName>Jiwoo Kang</engName><name>강지우</name></inventorInfo><inventorInfo><address>서울특별시 마포구...</address><code> </code><country> </country><engName>Juheon Hwang</engName><name>황주헌</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 성동구 상원**길 ** (성수동*가) 서울숲에이원센터 ***호(가능성특허법률사무소)</address><code>920180008827</code><country>대한민국</country><engName>HWANG DONG SUK</engName><name>황동석</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.09.25</receiptDate><receiptNumber>1-1-2023-1059570-84</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230127854.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9382897c2e23e1008c050932dbabd4157855c76f6f39ce24f0092338976395d17ace9b0f3b875f5e5ae8ba929ccb379af33dda41c7aeee5c23</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb882ff2bbe0977f99e4511634288858d11c9177614c2951e3e6f445255101a063dfb30a2759d642e1e0f0e5a3b48b28f08202c3f90617899</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>