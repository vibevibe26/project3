<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:51.4151</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.03.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0030463</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>객체 추적 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR TRACKING OBJECT</inventionTitleEng><openDate>2024.02.06</openDate><openNumber>10-2024-0016866</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 객체 추적 방법 및 장치에 관한 것으로, 객체 추적 방법은 비디오 시퀀스에서 상기 현재 프레임 이미지의 예측을 기반으로 획득하는 단기 필터와 이전에 획득한 장기 필터이거나 객체 템플릿 특징 풀을 기반으로 이전에 획득한 장기 필터를 최적화하여 획득하는 장기 필터를 융합하여 혼합 필터를 획득하는 단계 및 상기 혼합 필터를 기반으로 현재 프레임 이미지에서 객체 추적을 수행하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 단기 필터와 장기 필터를 융합하여 혼합 필터를 획득하는 단계; 및상기 혼합 필터를 기반으로 현재 프레임 이미지에서 객체 추적을 수행하는 단계를 포함하고,상기 단기 필터는,비디오 시퀀스에서 상기 현재 프레임 이미지의 예측을 기반으로 획득하고,상기 장기 필터는,이전에 획득한 장기 필터이거나 객체 템플릿 특징 풀을 기반으로 상기 이전에 획득한 장기 필터를 최적화하여 획득하는객체 추적 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 혼합 필터를 획득하는 단계 이전에,상기 비디오 시퀀스의 제1 프레임 이미지, 상기 현재 프레임 이미지 및 보조 프레임 이미지를 기반으로 상기 현재 프레임 이미지에 대응하는 상기 단기 필터를 예측하여 획득하는 단계를 더 포함하고,상기 보조 프레임 이미지는,상기 비디오 시퀀스에서 추적 성공 신뢰도가 제1 임계값보다 높고 시간 순서상 상기 현재 프레임에 가장 가까운 이미지 프레임인객체 추적 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 단기 필터를 예측하여 획득하는 단계는,특징 추출 네트워크를 통해 상기 제1 프레임 이미지의 객체 탐색 영역인 제1 탐색 영역, 상기 보조 프레임 이미지의 객체 탐색 영역인 보조 탐색 영역 및 상기 현재 프레임 이미지의 객체 탐색 영역인 현재 탐색 영역에 대해 특징을 추출하여 상기 제1 탐색 영역의 깊이 특징인 제1 깊이 특징, 상기 보조 탐색 영역의 깊이 특징인 보조 깊이 특징 및 상기 현재 탐색 영역의 깊이 특징인 현재 깊이 특징을 획득하는 단계; 상기 제1 깊이 특징 및 상기 제1 프레임 이미지의 객체의 바운딩 박스인 제1 바운딩 박스, 상기 보조 깊이 특징 및 상기 보조 프레임 이미지의 객체의 바운딩 박스인 보조 바운딩 박스에 대해 객체 상태 인코딩을 수행하여, 객체 상태 인코딩 벡터를 획득하는 단계; 상기 현재 깊이 특징에 대해 인코딩을 수행하여 현재 프레임 인코딩 벡터를 획득하는 단계;훈련된 트랜스포머 모델로 상기 객체 상태 인코딩 벡터와 상기 현재 프레임 인코딩 벡터를 처리하여 히든 특징을 얻는 단계; 및상기 히든 특징을 선형 변환하여 상기 단기 필터를 획득하는 단계를 포함하고,상기 제1 탐색 영역은,상기 제1 바운딩 박스에 따라 결정되고,상기 보조 탐색 영역은,상기 보조 바운딩 박스에 따라 결정되고,상기 현재 탐색 영역은,상기 현재 프레임 이미지 이전의 N 프레임 이미지(상기 N은 1보다 크거나 같은 정수임)를 기반으로 예측된 객체의 바운딩 박스인 예측 바운딩 박스에 따라 결정되는 -상기 N은 1보다 크거나 같은 정수임- 객체 추적 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 혼합 필터를 획득하는 단계 이전에,상기 장기 필터를 획득하는 단계를 더 포함하고,상기 장기 필터를 획득하는 단계는,상기 현재 프레임 이미지가 상기 비디오 시퀀스의 기설정된 위치에 있는 이미지 프레임인 경우, 객체 템플릿 특징 풀을 기반으로 이전에 획득한 장기 필터를 최적화하여 상기 장기 필터를 획득하거나, 또는상기 현재 프레임 이미지가 상기 비디오 시퀀스의 기설정된 위치에 있는 이미지 프레임이 아닌 경우, 이전에 획득한 장기 필터를 상기 장기 필터로 획득하는객체 추적 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 이전에 획득한 장기 필터의 최적화는,상기 객체 템플릿 특징 풀에서 소정 개수의 깊이 특징 및 상응하는 객체의 바운딩 박스를 추출하여 필터 훈련 세트로 결정하는 단계; 및상기 필터 훈련 세트를 기반으로, 필터 최적화 알고리즘을 통해 상기 이전에 획득한 장기 필터에 대해 훈련 및/또는 최적화하는 단계를 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 단기 필터와 상기 장기 필터를 융합하여 혼합 필터를 획득하는 단계는,상기 단기 필터 및 상기 장기 필터를 이용하여 각각 상기 현재 프레임 이미지에 대해 상관 처리를 수행하여, 단기 객체 포지셔닝 응답맵(response map) 및 장기 객체 포지셔닝 응답맵을 획득하는 단계; 및상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 획득하는 단계를 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 획득하는 단계는,상기 단기 객체 포지셔닝 응답맵의 단기 포지셔닝 맵 품질인 단기 맵 품질 및 상기 장기 객체 포지셔닝 응답맵의 장기 포지셔닝 맵 품질인 장기 맴 품질을 평가하는 단계;상기 단기 맵 품질 및 상기 장기 맴 품질과 제2 기설정된 임계값의 비교 결과에 따라, 상기 단기 필터의 혼합 가중치 및 상기 장기 필터의 혼합 가중치를 결정하는 단계; 및상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 얻는 단계를 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 단기 필터의 혼합 가중치 및 상기 장기 필터의 혼합 가중치를 결정하는 단계는,상기 단기 맵 품질이 상기 제2 기설정된 임계값보다 크거나 같고, 상기 장기 맵 품질이 상기 제2 기설정된 임계값보다 작을 경우, 상기 단기 필터의 혼합 가중치를 1로 설정하고 상기 장기 필터의 혼합 가중치를 0으로 설정하는 단계; 또는상기 단기 맵 품질이 상기 제2 기설정된 임계값보다 작고 상기 장기 맴 품질이 상기 제2 기설정된 임계값보다 크거나 같을 경우, 상기 단기 필터의 혼합 가중치를 0으로 설정하고 상기 장기 필터의 혼합 가중치를 1로 설정하는 단계; 또는상기 단기 필터의 혼합 가중치 및 상기 장기 맴 품질이 모두 상기 제2 기설정된 임계값보다 작을 경우, 상기 단기 필터의 혼합 가중치 및 상기 장기 필터의 혼합 가중치를 이전에 획득한 혼합 필터의 상응하는 가중치 값으로 설정하는 단계; 또는상기 단기 필터의 혼합 가중치 및 상기 장기 맴 품질이  모두 상기 제2 기설정된 임계값보다 크거나 같을 경우, 상기 단기 필터의 혼합 가중치 및 상기 장기 필터의 혼합 가중치를 상기 단기 맵 품질과 상기 장기 맴 품질의 소프트맥스(Softmax) 활성화 함수의 정규화된 출력의 혼합 가중치로 설정하는 단계를 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서, 상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 획득하는 단계는,상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 컨볼루션 신경망과 정규화 함수를 이용하여 상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치를 얻는 단계; 및상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 얻는 단계를 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 컨볼루션 신경망과 정규화 함수를 이용하여 상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치를 얻는 단계는,상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵을 혼합 처리하여 혼합 응답맵을 얻는 단계;상기 컨볼루션 신경망을 이용하여 상기 혼합 응답맵에서 특징을 추출하고, 선형 변환 레이어를 이용하여 추출된 특징을 선형 변환하여 혼합 가중치 벡터를 얻는 단계; 및소프트맥스 활성화 함수에 따라 상기 혼합 가중치 벡터를 정규화하여 상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치를 얻는 단계를 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 혼합 필터를 기반으로 상기 현재 프레임 이미지에서 객체 추적을 수행하는 단계는,상기 혼합 필터를 이용하여 상기 현재 프레임 이미지의 객체 탐색 영역의 깊이 특징인 현재 깊이 특징에 대해 상관 처리를 수행하여 객체 포지셔닝 응답맵을 얻는 단계;상기 객체 포지셔닝 응답맵을 기반으로, 상기 현재 프레임 이미지의 초기 객체 대상 바운딩 박스를 예측하는 단계; 및상기 초기 객체 대상 바운딩 박스에 기초하여, 분할 네트워크를 사용하여 객체 대상을 분할하고, 상기 객체 대상의 객체 대상 분할맵 및 최종 객체 대상의 바운딩 박스를 획득하는 단계를 포함하고,상기 현재 프레임 이미지의 객체 탐색 영역은,상기 현재 프레임 이미지 이전의 N 프레임 이미지(상기 N은 1보다 크거나 같은 정수임)를 기반으로 예측된 객체 대상의 바운딩 박스에 따라 결정되는객체 추적 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 객체 템플릿 특징 풀은,상기 현재 프레임 이미지의 객체 탐색 영역의 깊이 특징; 및/또는상기 비디오 시퀀스의 제1 프레임 이미지의 객체 탐색 영역에 대해 다중 증강(augmentation) 처리를 수행하여 복수의 증강 이미지를 획득하고 상기 복수의 증강 이미지에 대해 특징을 추출하여 획득한 복수의 깊이 특징; 및/또는 상기 비디오 시퀀스에서 상기 현재 프레임 이미지 이전의 이미지 프레임에 대해 객체 추적을 수행할 때 추적 성공 신뢰도가 제1 기설정된 임계값보다 높은 이미지 프레임의 깊이 특징을 포함하는 객체 추적 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항의 방법을 실행하기 위한 프로그램이 기록되어 있는 것을 특징으로 하는 컴퓨터에서 판독 가능한 기록 매체.</claim></claimInfo><claimInfo><claim>14. 단기 필터와 장기 필터를 융합하여 혼합 필터를 획득하는 혼합 필터 획득부; 및상기 혼합 필터를 기반으로 현재 프레임 이미지에서 객체 추적을 수행하는 객체 추적부를 포함하고,상기 단기 필터는,비디오 시퀀스에서 상기 현재 프레임 이미지의 예측을 기반으로 획득하고,상기 장기 필터는,이전에 획득한 장기 필터이거나 객체 템플릿 특징 풀을 기반으로 상기 이전에 획득한 장기 필터를 최적화하여 획득하는객체 추적 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 비디오 시퀀스의 제1 프레임 이미지, 상기 현재 프레임 이미지 및 보조 프레임 이미지를 기반으로 상기 현재 프레임 이미지에 대응하는 상기 단기 필터를 예측하여 획득하는 단기 필터 획득부를 더 포함하고,상기 보조 프레임 이미지는,상기 비디오 시퀀스에서 추적 성공 신뢰도가 제1 임계값보다 높고 시간 순서상 상기 현재 프레임에 가장 가까운 이미지 프레임인객체 추적 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 현재 프레임 이미지가 상기 비디오 시퀀스의 기설정된 위치에 있는 이미지 프레임인 경우, 객체 템플릿 특징 풀을 기반으로 이전에 획득한 장기 필터를 최적화하여 상기 장기 필터를 획득하거나, 또는 상기 현재 프레임 이미지가 상기 비디오 시퀀스의 기설정된 위치에 있는 이미지 프레임이 아닌 경우, 이전에 획득한 장기 필터를 상기 장기 필터로 획득하는 장기 필터 획득부를 더 포함하는 객체 추적 장치.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 혼합 필터 획득부는,상기 단기 필터 및 상기 장기 필터를 이용하여 각각 상기 현재 프레임 이미지에 대해 상관 처리를 수행하여, 단기 객체 포지셔닝 응답맵(response map) 및 장기 객체 포지셔닝 응답맵을 획득하고,상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 획득하는객체 추적 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 혼합 필터 획득부는,상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 획득할 때,상기 단기 객체 포지셔닝 응답맵의 단기 포지셔닝 맵 품질인 단기 맵 품질 및 상기 장기 객체 포지셔닝 응답맵의 장기 포지셔닝 맵 품질인 장기 맴 품질을 평가하고,상기 단기 맵 품질 및 상기 장기 맴 품질과 제2 기설정된 임계값의 비교 결과에 따라, 상기 단기 필터의 혼합 가중치 및 상기 장기 필터의 혼합 가중치를 결정하고,상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 얻는객체 추적 장치.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 혼합 필터 획득부는,상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 획득할 때,상기 단기 객체 포지셔닝 응답맵과 상기 장기 객체 포지셔닝 응답맵에 따라, 컨볼루션 신경망과 정규화 함수를 이용하여 상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치를 얻고,상기 단기 필터의 혼합 가중치와 상기 장기 필터의 혼합 가중치에 따라, 상기 단기 필터와 상기 장기 필터를 융합하여 상기 혼합 필터를 얻는객체 추적 장치.</claim></claimInfo><claimInfo><claim>20. 제14항에 있어서, 상기 객체 추적부는,상기 혼합 필터를 이용하여 상기 현재 프레임 이미지의 객체 탐색 영역의 깊이 특징인 현재 깊이 특징에 대해 상관 처리를 수행하여 객체 포지셔닝 응답맵을 얻는 객체 포지셔닝 응답맵 획득부;상기 객체 포지셔닝 응답맵을 기반으로, 상기 현재 프레임 이미지의 초기 객체 대상 바운딩 박스를 예측하는 초기 객체 대상 바운딩 박스 예측부; 및상기 초기 객체 대상 바운딩 박스에 기초하여, 분할 네트워크를 사용하여 객체 대상을 분할하고, 상기 객체 대상의 객체 대상 분할맵 및 최종 객체 대상의 바운딩 박스를 획득하는 최종 객체 대상 바운딩 박스 예측부를 포함하고,상기 현재 프레임 이미지의 객체 탐색 영역은,상기 현재 프레임 이미지 이전의 N 프레임 이미지(상기 N은 1보다 크거나 같은 정수임)를 기반으로 예측된 객체 대상의 바운딩 박스에 따라 결정되는객체 추적 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중화인민공화국 베이징 차오양 구...</address><code> </code><country> </country><engName>Yiwei CHEN</engName><name>이웨이 첸</name></inventorInfo><inventorInfo><address>중화인민공화국 베이징 차오양 구...</address><code> </code><country> </country><engName>Siyang PAN</engName><name>시양 판</name></inventorInfo><inventorInfo><address>중화인민공화국 베이징 차오양 구...</address><code> </code><country> </country><engName>Jiaqian YU</engName><name>자첸 위</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420200167444</code><country>대한민국</country><engName>PARK, Chang Beom</engName><name>박창범</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code>420190717755</code><country>대한민국</country><engName>LEE, HYUNJEONG</engName><name>이현정</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170498351</code><country>대한민국</country><engName>Seohyung Lee</engName><name>이서형</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code>420170743681</code><country>대한민국</country><engName>YOO BYUNG IN</engName><name>유병인</name></inventorInfo><inventorInfo><address>중화인민공화국 베이징 차오양 구...</address><code> </code><country> </country><engName>Qiang WANG</engName><name>창 왕</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2022.07.29</priorityApplicationDate><priorityApplicationNumber>202210910093.6</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.03.08</receiptDate><receiptNumber>1-1-2023-0264648-76</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2023.03.14</receiptDate><receiptNumber>9-1-2023-9003040-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230030463.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93620fc635aa7be36b81dd7ab1b387397031d92e06312232f4cf58af95fda9ddc9dd9286b8542633007b210b6e5b1ebeb61fe7d3dca164054b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfdcb19a5a772fd2b3c6d4a21cbb6a4b5a5e95cdaf9788a4a769ea67c5ec5cb61fd87e29cecfe657f3a61cf2bfe342d87a9ebd7efc580e5440</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>