<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:18.3918</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0190941</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공신경망 기반의 이미지 캡션 생성을 통한 이미지 확장 방법 및 그 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR GENERATING EXPANSIVE IMAGE  USING IMAGE CAPTIONING BASED ON ARTIFICIAL NEURAL  NETWORK</inventionTitleEng><openDate>2024.07.09</openDate><openNumber>10-2024-0107889</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/092</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/214</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시에 따르면, 캡션 기반 광범위한 페인팅 작업을 수행하는 컴퓨팅 장치로서, 마스킹 처리된 영역을 포함하는 이미지를 입력받아 입력 이미지를 설명하는 상기 마스킹 처리된 영역에 대한 언어 힌트를 생성하는 이미지 캡션 모듈, 그리고 상기 입력 이미지와 상기 언어 힌트를 입력받아 상기 언어 힌트의 가이드에 따라 상기 마스킹 처리된 영역의 이미지를 예측하고, 예측한 이미지로 상기 마스킹 처리된 영역을 채운 확장 이미지를 출력하는 텍스트-가이드 이미지 조작 모듈을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 캡션 기반 광범위한 페인팅 작업을 수행하는 컴퓨팅 장치로서,마스킹 처리된 영역을 포함하는 이미지를 입력받아 입력 이미지를 설명하는 상기 마스킹 처리된 영역에 대한 언어 힌트를 생성하는 이미지 캡션 모듈, 그리고상기 입력 이미지와 상기 언어 힌트를 입력받아 상기 언어 힌트의 가이드에 따라 상기 마스킹 처리된 영역의 이미지를 예측하고, 예측한 이미지로 상기 마스킹 처리된 영역을 채운 확장 이미지를 출력하는 텍스트-가이드 이미지 조작 모듈를 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에서,상기 이미지 캡션 모듈은,입력 이미지로부터 시각적 특징을 추출하는 인코더, 그리고상기 시각적 특징으로부터 일련의 단어들을 생성하는 디코더를 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에서,상기 이미지 캡션 모듈은,입력 이미지로부터 상기 입력 이미지를 설명하는 자연어로 이루어진 텍스트를 출력하도록 사전 학습된 언어 모델을 랜덤하게 마스킹된 이미지들로 구성된 학습 데이터를 이용하여 학습되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에서, 상기 이미지 캡션 모듈은, 상기 학습 데이터와 SCST(self-critical sequence training) 방법을 사용하여 학습되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>5. 제3항에서, 상기 이미지 캡션 모듈은, 교차 엔트로피 손실(cross entropy loss)과 강화 학습(reinforcement learning)을 이용하여 학습되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>6. 제1항에서,상기 텍스트-가이드 이미지 조작 모듈은,텍스트와 이미지가 쌍으로 이루어진 학습 데이터를 이용하여 텍스트에 상응하는 이미지를 출력하도록 학습되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에서,상기 이미지 캡션 모듈과 상기 텍스트-가이드 이미지 조작 모듈은,인공신경망 모델인 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>8. 컴퓨팅 장치에 의해 수행되는 이미지 아웃페인팅 방법으로서,임의의 영역이 마스킹 처리된 이미지를 입력받는 단계,입력 이미지로부터 일련의 단어들을 생성하도록 학습된 이미지 캡션 모듈을 이용하여, 상기 마스킹된 이미지에서 마스킹 처리되지 않은 이미지에 대한 의미 및 텍스트 정보를 자연 언어로 설명한 언어 힌트를 생성하는 단계, 상기 언어 힌트를 이용하여 상기 임의의 영역의 이미지를 예측하는 단계, 그리고상기 예측한 이미지를 포함하는 확장 이미지를 출력하는 단계를 포함하는, 이미지 아웃 페인딩 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에서,상기 예측하는 단계는,입력 텍스트에 상응하는 이미지를 생성하도록 학습된 텍스트-가이드 이미지 조작 모듈에 상기 마스킹 처리된 이미지와 상기 언어 힌트를 입력하여, 상기 언어 힌트의 가이드에 따라 상기 마스킹 처리된 임의의 영역의 이미지를 예측하는, 이미지 아웃 페인딩 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에서,상기 텍스트-가이드 이미지 조작 모듈은,텍스트와 이미지가 쌍으로 이루어진 학습 데이터를 이용하여 텍스트에 상응하는 이미지를 출력하도록 학습된 인공신경망 모델인, 이미지 아웃 페인딩 방법.</claim></claimInfo><claimInfo><claim>11. 제8항에서,상기 이미지 캡션 모듈은,사전 학습된 언어 모델이 랜덤하게 마스킹된 이미지들로 구성된 학습 데이터를 이용하여 학습된 인공신경망 모델이고,상기 사전 학습된 언어 모델은, 입력 이미지로부터 상기 입력 이미지를 설명하는 자연어로 이루어진 텍스트를 출력하는 모델인, 이미지 아웃 페인팅 방법.</claim></claimInfo><claimInfo><claim>12. 컴퓨팅 장치에 의해 수행되는 광범위한 이미지 블렌딩 방법으로서,제1 이미지와 제2 이미지가 연결되는 지점을 마스킹 영역으로 설정하는 단계,상기 마스킹 영역을 기준으로 양측에 상기 제1 이미지와 상기 제2 이미지가 각각 배치된 이미지를 생성하는 단계, 입력 이미지로부터 일련의 단어들을 생성하도록 학습된 이미지 캡션 모듈을 이용하여, 상기 생성한 이미지에서 마스킹 처리되지 않은 이미지에 대한 의미 및 텍스트 정보를 자연 언어로 설명한 언어 힌트를 생성하는 단계, 상기 언어 힌트를 이용하여 상기 마스킹 영역의 이미지를 예측하는 단계, 그리고상기 제1 이미지, 상기 예측한 이미지, 및 상기 제2 이미지가 순차적으로 배치된 파노라마 이미지를 출력하는 단계를 포함하는, 광범위한 이미지 블렌딩 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에서,상기 설정하는 단계 이전에,이전 단계에서 예측된 출력을 다음 단계의 입력으로 사용하는 이미지 아웃페인팅을 반복하여 상기 제1 이미지를 생성하는 단계, 그리고상기 제1 이미지와 반대 방향으로 상기 이미지 아웃페인팅을 반복하여 제2 이미지를 생성하는 단계를 포함하고,상기 이미지 아웃페인팅은,마스킹 영역에 대한 이미지를 예측하는 작업인, 광범위한 이미지 블렌딩 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에서,상기 이미지 아웃페인팅은,상기 마스킹 영역이 포함된 이미지에서 마스킹되지 않은 영역에 대한 의미 및 텍스트 정보를 자연 언어로 설명한 언어 힌트를 사용하여 상기 마스킹 영역의 이미지를 예측하고, 상기 마스킹 영역을 예측한 이미지로 채운 확장 이미지를 생성하는 작업을 포함하는, 광범위한 이미지 블렌딩 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에서,상기 이미지 아웃페인팅은,텍스트에 상응하는 이미지를 출력하도록 학습된 인공신경망 모델에 상기 언어 힌트와 상기 마스킹 영역이 포함된 이미지를 입력하여 상기 언어 힌트의 가이드에 따라 상기 마스킹 영역의 이미지를 예측하는 작업을 포함하는, 광범위한 이미지 블렌딩 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 마포구...</address><code>220040246082</code><country>대한민국</country><engName>Sogang University Research &amp; Business Development Foundation</engName><name>서강대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 고양시 일산서구...</address><code> </code><country> </country><engName>KANG, SUK-JU</engName><name>강석주</name></inventorInfo><inventorInfo><address>서울특별시 마포구...</address><code> </code><country> </country><engName>KIM, JIHYUN</engName><name>김지현</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***, 서림빌딩 **층 (역삼동)</address><code>920011000036</code><country>대한민국</country><engName>YOU ME PATENT &amp; LAW FIRM</engName><name>유미특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.30</receiptDate><receiptNumber>1-1-2022-1425244-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.01.10</receiptDate><receiptNumber>4-1-2024-5014264-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220190941.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938826990045ec5c6d3f157225867559b21add52c78aef5284e6d9f0a9dee348ac899eca886c0cc443073a2d1be7b0cbc3adb9835448aab8d3</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf66b532a156c4392b4b70f234fc58dad65edee41883694b7ee098ee1d2e8af7870c69e03fbe4cfbea1515476eb6d5d51214481757e4f65c8f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>