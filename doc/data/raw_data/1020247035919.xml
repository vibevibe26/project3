<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:38.438</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.04.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7035919</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>대조 캡셔닝 신경망</inventionTitle><inventionTitleEng>CONTRASTIVE CAPTIONING NEURAL NETWORKS</inventionTitleEng><openDate>2024.12.03</openDate><openNumber>10-2024-0169665</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.28</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.10.28</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 대조 캡셔닝 신경망(contrastive captioning neural network)을 사용하여 멀티모달 입력을 처리하기 위한, 컴퓨터 저장 매체 상에 인코딩된 컴퓨터 프로그램을 포함하는 방법, 시스템, 및 장치. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.11.02</internationOpenDate><internationOpenNumber>WO2023212340</internationOpenNumber><internationalApplicationDate>2023.04.28</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/020434</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 컴퓨터 및 하나 이상의 컴퓨터에 의해 실행될 때 하나 이상의 컴퓨터로 하여금 대조 캡셔닝 신경망을 구현하게 하는 명령어를 저장한 하나 이상의 저장 디바이스를 포함하는 시스템으로서, 상기 신경망은,하나 이상의 이미지를 포함하는 시각적 입력을 처리하여 시각적 입력의 인코딩된 표현을 생성하도록 구성된 시각적 인코더 신경망; 및 언어 모델 신경망 - 상기 언어 모델 신경망은 현재 텍스트 시퀀스를 처리하여 현재 텍스트 시퀀스에 첨부될 새로운 토큰을 정의하는 출력을 생성하도록 구성되고, 상기 현재 텍스트 시퀀스는 하나 이상의 입력 위치 각각에서 개별 텍스트 토큰을 포함함 - 을 포함하고, 상기 언어 모델 신경망은, 현재 텍스트 시퀀스의 각 텍스트 토큰을 포함하는 입력을 처리하여 상기 시각적 입력과 독립적인 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 유니모달 표현을 생성하도록 구성된 초기 신경망 계층 세트; 및  현재 텍스트 시퀀스의 텍스트 토큰의 개별 유니모달 표현을 포함하는 입력을 처리하여 상기 현재 텍스트 시퀀스에 첨부될 새로운 토큰을 정의하는 출력을 생성하도록 구성된 후속 신경망 계층 세트를 포함하고, 상기 후속 신경망 계층은 시각적 입력의 인코딩된 표현에 조건화되는 하나 이상의 교차모달 계층을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 초기 유니모달 신경망 계층 세트는 초기 어텐션 계층 시퀀스를 포함하고,상기 초기 어텐션 계층 각각은 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 현재 표현을 입력으로 수신하고 상기 개별 현재 표현을 처리하여 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 업데이트된 표현을 출력으로 생성하도록 구성되고,상기 초기 어텐션 계층 시퀀스에서 제1 초기 어텐션 계층에 의해 입력으로 수신되는 개별 현재 표현은 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 임베딩이고,상기 초기 어텐션 계층 시퀀스에서 제1 초기 어텐션 계층 이후의 각 초기 어텐션 계층에 의해 입력으로 수신되는 개별 현재 표현은 상기 초기 어텐션 계층 시퀀스에서 이전의 초기 어텐션 계층에 의해 출력으로 생성되는 현재 텍스트 시퀀스의 상기 텍스트 토큰의 개별 업데이트된 표현인, 시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 현재 텍스트 시퀀스의 텍스트 토큰의 개별 유니모달 표현은,초기 어텐션 계층 시퀀스에서 마지막 초기 어텐션 계층에 의해 출력으로 생성되는 상기 현재 텍스트 시퀀스의 텍스트 토큰의 개별 업데이트된 표현인, 시스템.</claim></claimInfo><claimInfo><claim>4. 제2항 또는 제3항에 있어서, 상기 개별 현재 표현을 처리하여 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 업데이트된 표현을 출력으로 생성하는 것은 인과적으로 마스킹된 셀프 어텐션 메커니즘을 적용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 현재 텍스트 시퀀스에 첨부될 새로운 토큰을 정의하는 출력은 텍스트 토큰 어휘 내의 각 텍스트 토큰에 개별 스코어를 할당하는 스코어 분포를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,상기 후속 신경망 계층 세트는 후속 어텐션 계층 시퀀스를 포함하고,상기 후속 어텐션 계층 각각은 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 현재 표현을 입력으로 수신하고 상기 개별 현재 표현을 처리하여 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 업데이트된 표현을 출력으로 생성하도록 구성되고,상기 후속 어텐션 계층 시퀀스에서 제1 후속 어텐션 계층에 의해 입력으로 수신되는 개별 현재 표현은 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 유니모달 표현이고,상기 후속 어텐션 계층 시퀀스에서 제1 후속 어텐션 계층 이후의 각 후속 어텐션 계층에 의해 입력으로 수신되는 개별 현재 표현은 후속 어텐션 계층 시퀀스에서 이전의 초기 어텐션 계층에 의해 출력으로 생성되는 상기 현재 텍스트 시퀀스의 텍스트 토큰의 개별 업데이트된 표현인, 시스템.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 후속 신경망 계층 세트는,상기 후속 어텐션 계층 시퀀스에서 마지막 초기 후속 어텐션 계층에 의해 출력으로 생성되는 현재 텍스트 시퀀스의 텍스트 토큰의 개별 업데이트된 표현 중 하나 이상을 수신하고 상기 하나 이상의 개별 업데이트된 표현을 처리하여 현재 텍스트 시퀀스에 첨부될 새로운 토큰을 정의하는 출력을 생성하도록 구성된 출력 계층 블록을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서, 상기 후속 신경망 계층 중 하나 이상에 대해, 개별 현재 표현을 처리하여 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 업데이트된 표현을 출력으로 생성하는 것은 인과적으로 마스킹된 셀프 어텐션 메커니즘을 적용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제6항 내지 제8항 중 어느 한 항에 있어서, 상기 하나 이상의 교차모달 계층은 각각 상기 후속 어텐션 계층 시퀀스의 후속 어텐션 계층 중 하나이고, 그리고상기 각 교차모달 계층에 대해, 개별 현재 표현을 처리하여 현재 텍스트 시퀀스의 각 텍스트 토큰의 개별 업데이트된 표현을 출력으로 생성하는 것은,시각적 입력의 인코딩된 표현으로부터 도출된 입력과 상기 교차모달 계층에 의해 입력으로 수신된 현재 텍스트 시퀀스의 텍스트 토큰의 개별 현재 표현 간에 교차 어텐션 메커니즘을 적용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 상기 인코딩된 표현은 시각적 입력의 복수의 패치 각각에 대한 개별 업데이트된 토큰을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 대조 캡셔닝 신경망은,상기 업데이트된 토큰 및 학습된 쿼리 토큰의 제1 세트에 대해 어텐션을 적용하여 상기 학습된 쿼리 토큰 각각에 대한 개별 업데이트된 쿼리 토큰을 생성하는 제1 어텐션 풀링 계층을 더 포함하고, 각각의 교차모달 계층은 개별 업데이트된 쿼리 토큰을 입력으로 수신하는, 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 제9항에 종속되는 경우, 상기 인코딩된 표현으로부터 도출된 입력은 개별 업데이트된 쿼리 토큰인, 시스템.</claim></claimInfo><claimInfo><claim>13. 제10항 내지 제12항 중 어느 한 항에 있어서, 상기 시각적 인코더 신경망은 비전 트랜스포머 신경망인, 시스템.</claim></claimInfo><claimInfo><claim>14. 제10항 내지 제13항 중 어느 한 항에 있어서, 상기 대조 캡셔닝 신경망은,상기 업데이트된 토큰 및 학습된 쿼리 토큰의 제2 세트에 대해 어텐션을 적용하여 상기 제2 세트 내의 학습된 쿼리 토큰 각각에 대한 개별 업데이트된 쿼리 토큰을 생성하는 제2 어텐션 풀링 계층을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 학습된 쿼리 토큰의 제2 세트는 단일 학습된 쿼리 토큰만 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항의 대조 캡셔닝 신경망을 훈련시키는 방법으로서, 상기 방법은,개별 시각적 입력 및 개별 텍스트 시퀀스를 각각 포함하는 하나 이상의 훈련 쌍 세트를 획득하는 단계와;각 훈련 쌍에 대해, 대조 캡셔닝 신경망을 사용하여 훈련 쌍의 개별 시각적 입력 및 개별 텍스트 시퀀스를 처리하는 단계 - 상기 처리하는 단계는, 시각적 인코더 신경망을 사용하여 훈련 쌍의 시각적 입력을 처리하여 시각적 입력의 인코딩된 표현을 생성하는 단계; 초기 신경망 계층 세트를 사용하여 훈련 쌍의 텍스트 시퀀스를 처리하여 텍스트 시퀀스의 각 텍스트 토큰의 개별 유니모달 표현을 생성하는 단계; 및  후속 신경망 계층 세트를 사용하여 텍스트 시퀀스의 텍스트 토큰의 개별 유니모달 표현을 처리하여, 개별 텍스트 시퀀스의 복수의 텍스트 토큰 각각에 대해, 텍스트 토큰의 어휘에 대한 개별 스코어 분포를 생성하는 단계를 포함함 - 와; 그리고(i) 상기 시각적 입력의 인코딩된 표현으로부터 도출된 대조 표현과 상기 훈련 쌍의 각 텍스트 시퀀스의 하나 이상의 텍스트 토큰의 유니모달 표현 간의 유사성에 기초하는 대조 학습 손실 항, 및 (ii) 각 훈련 쌍에 대해, 상기 개별 텍스트 시퀀스의 상기 복수의 텍스트 토큰에 대한 개별 스코어 분포에 기초하는 캡셔닝 손실 항을 포함하는 손실 함수를 최소화하도록 신경망을 훈련시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 각 훈련 쌍에 대해, 초기 신경망 계층 세트를 사용하여 훈련 쌍의 텍스트 시퀀스를 처리하는 것 및 후속 신경망 계층 세트를 사용하여 개별 유니모달 표현을 처리하는 것은 언어 모델 신경망을 통한 단일 순방향 패스에서 수행되는, 방법.</claim></claimInfo><claimInfo><claim>18. 제16항 또는 제17항에 있어서, 상기 캡셔닝 손실 항은,각 훈련 쌍에 대해 그리고 개별 텍스트 시퀀스의 복수의 토큰 각각에 대해, 텍스트 시퀀스의 해당 토큰을 기준으로 상기 토큰에 대한 개별 스코어 분포의 품질을 측정하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제16항 내지 제18항 중 어느 한 항에 있어서, 각 훈련 쌍의 각 훈련 텍스트 시퀀스는 동일한 지정 토큰을 포함하고, 상기 대조 학습 손실 항은 훈련 쌍의 시각적 입력에 대한 인코딩된 표현으로부터 도출된 대조 표현과 훈련 쌍의 훈련 텍스트 시퀀스의 상기 지정된 토큰에 대한 개별 유니모달 표현 간의 유사성에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제16항 내지 제19항 중 어느 한 항에 있어서, 제15항에 종속되는 경우, 각 시각적 입력에 대한 대조 표현은 제2 세트의 단일 쿼리 토큰에 대한 업데이트된 쿼리 토큰인, 방법.</claim></claimInfo><claimInfo><claim>21. 제16항 내지 제19항 중 어느 한 항에 있어서, 제10항에 종속되는 경우, 각 시각적 입력에 대한 상기 대조 표현은 시각적 입력의 복수의 패치 각각에 대한 개별 업데이트된 토큰을 풀링함으로써 생성되는, 방법.</claim></claimInfo><claimInfo><claim>22. 제16항 내지 제21항 중 어느 한 항에 있어서,훈련 후, (i) 시각적 인코더, (ii) 초기 신경망 계층 세트, 또는 (iii) 후속 신경망 계층 세트 중 하나 이상을 사용하여 다운스트림 작업을 수행하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서,훈련 후, (i) 시각적 인코더, (ii) 초기 신경망 계층 세트, 또는 (iii) 후속 신경망 계층 세트 중 하나 이상을 사용하여 다운스트림 작업을 수행하기 전에, 상기 다운스트림 작업을 위해 라벨링된 훈련 데이터에 대해 대조 캡셔닝 신경망의 하나 이상의 컴포넌트를 미세 조정하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>24. 제22항에 있어서, 훈련 후, (i) 시각적 인코더, (ii) 초기 신경망 계층 세트, 또는 (iii) 후속 신경망 계층 세트 중 하나 이상을 사용하여 다운스트림 작업을 수행하기 전에, 상기 다운스트림 작업을 위해 라벨링된 훈련 데이터에 대해 대조 캡셔닝 신경망의 하나 이상의 컴포넌트를 포함하는 다운스트림 신경망을 미세 조정하는 단계를 더 포함하는 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 다운스트림 신경망을 미세 조정하는 단계는,(i) 시각적 인코더, (ii) 초기 신경망 계층 세트, 또는 (iii) 후속 신경망 계층 세트 중 하나 이상을 고정한 상태로 유지하면서 상기 다운스트림 신경망의 하나 이상의 추가 컴포넌트를 훈련시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>26. 하나 이상의 컴퓨터에 의해 수행되는 방법으로서, 상기 방법은,다운스트림 작업에 대한 새로운 입력을 수신하는 단계; 및다운스트림 작업에 대한 작업 출력을 생성하기 위해 (i) 시각적 인코더, (ii) 초기 신경망 계층 세트, 또는 (iii) 후속 신경망 계층 세트 중 하나 이상을 포함하는 다운스트림 작업 신경망을 사용하여 상기 새로운 입력을 처리하는 단계를 포함하고, 상기 다운스트림 작업에 대한 작업 출력을 생성하기 위해 (i) 시각적 인코더, (ii) 초기 신경망 계층 세트, 또는 (iii) 후속 신경망 계층 세트 중 하나 이상은 제16항 내지 제25항 중 어느 한 항의 개별 동작을 수행함으로써 훈련된, 방법.</claim></claimInfo><claimInfo><claim>27. 하나 이상의 컴퓨터에 의해 실행될 때 하나 이상의 컴퓨터로 하여금 제1항 내지 제15항 중 어느 한 항의 대조 캡셔닝 신경망을 구현하게 하는 명령어를 저장한 하나 이상의 컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>28. 제1항 내지 제15항 중 어느 한 항의 대조 캡셔닝 신경망에 의해 수행되는 개별 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>29. 시스템으로서,하나 이상의 컴퓨터; 및하나 이상의 컴퓨터에 의해 실행될 때 하나 이상의 컴퓨터로 하여금 제16항 내지 제26항 중 어느 한 항의 방법의 개별 동작을 수행하게 하는 명령어를 저장한 하나 이상의 저장 디바이스를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>30. 하나 이상의 컴퓨터에 의해 실행될 때 하나 이상의 컴퓨터로 하여금 제16항 내지 제26항 중 어느 한 항의 방법의 개별 동작을 수행하게 하는 명령어를 저장한 하나 이상의 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>YU, Jiahui</engName><name>유 쟈후이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>WANG, Zirui</engName><name>왕 지루이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>VASUDEVAN, Vijay</engName><name>바수데반 비제이</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>YEUNG, Ho Man</engName><name>양 호 만</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SEYEDHOSSEINI TARZJANI, Seyed Mojtaba</engName><name>세이예드호세이니 타르자니 사예드 무즈타바</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>WU, Yonghui</engName><name>우 용후이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.04.28</priorityApplicationDate><priorityApplicationNumber>63/336,274</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.05.03</priorityApplicationDate><priorityApplicationNumber>63/337,991</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.10.28</receiptDate><receiptNumber>1-1-2024-1174205-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.10.30</receiptDate><receiptNumber>1-5-2024-0175288-05</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247035919.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9343d148be82cc5e90b65494c1d50db410ce0dc16fba94f2871d120ffa2577f5131a07b19377aacb012f2e080135de15ef7df7a8bfb4d56f24</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa1ba6a15d813ca4ee35f909b074d3c815a9236b24b1069887d1039541c3aa1b3d05befb7bacacc0c53e43c11b7407593badc4ff4272d87d2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>