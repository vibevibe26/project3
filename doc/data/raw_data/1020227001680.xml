<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:54.4054</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.09.24</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7001680</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>프레임 간 예측 방법 및 장치, 기기, 저장 매체</inventionTitle><inventionTitleEng>INTER-FRAME PREDICTION METHOD AND APPARATUS, DEVICE AND STORAGE MEDIUM</inventionTitleEng><openDate>2022.05.19</openDate><openNumber>10-2022-0064950</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.09.07</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.01.17</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/176</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/139</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/109</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/147</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/184</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 실시예는 프레임 간 예측 방법 및 장치, 기기, 저장 매체를 개시하였고, 여기서, 상기 프레임 간 예측 방법은, 현재 블록이 비디오 이미지에서의 위치에 따라, 제1 움직임 정보 및 제2 후보 움직임 정보를 결정하는 단계(301) - 상기 움직임 정보는 적어도 움직임 벡터를 포함함 - ; 상기 제1 움직임 정보의 움직임 벡터와 상기 제2 후보 움직임 정보의 움직임 벡터 사이의 거리가 제1 임계값보다 큰지 여부를 판단하는 단계(302); 판단 결과는 상기 거리가 상기 제1 임계값보다 작거나 같은 것일 때, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계(304); 판단 결과는 상기 거리가 상기 제1 임계값보다 큰 것일 때, 상기 제2 후보 움직임 정보를 제2 움직임 정보로 사용하는 단계(303); 및 상기 제1 움직임 정보 및 상기 제2 움직임 정보를 사용하여, 상기 현재 블록에 대해 프레임 간 예측을 수행하는 단계(305)를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.04.01</internationOpenDate><internationOpenNumber>WO2021056225</internationOpenNumber><internationalApplicationDate>2019.09.24</internationalApplicationDate><internationalApplicationNumber>PCT/CN2019/107615</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 프레임 간 예측 방법으로서, 비디오 이미지 인코더에 적용되고,현재 블록이 비디오 이미지에서의 위치에 따라, 제1 움직임 정보 및 제2 후보 움직임 정보를 결정하는 단계 - 상기 움직임 정보는 적어도 움직임 벡터를 포함함 - ; 상기 제1 움직임 정보의 움직임 벡터와 상기 제2 후보 움직임 정보의 움직임 벡터 사이의 거리가 제1 임계값보다 큰지 여부를 판단하는 단계; 판단 결과는 상기 거리가 상기 제1 임계값보다 작거나 같은 것일 때, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻고; 판단 결과는 상기 거리가 상기 제1 임계값보다 큰 것일 때, 상기 제2 후보 움직임 정보를 제2 움직임 정보로 사용하는 단계; 및상기 제1 움직임 정보 및 상기 제2 움직임 정보를 사용하여, 상기 현재 블록에 대해 프레임 간 예측을 수행하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 현재 블록이 비디오 이미지에서의 위치에 따라, 제1 움직임 정보 및 제2 후보 움직임 정보를 결정하는 단계는,상기 현재 블록이 상기 비디오 이미지에서의 위치에 따라, 기설정된 움직임 정보 도출 방법을 통해 얻은 첫 번째 움직임 정보를 상기 제1 움직임 정보로 사용하는 단계; 및 상기 기설정된 움직임 정보 도출 방법을 통해 얻은 두 번째 움직임 정보를 상기 제2 후보 움직임 정보로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 기설정된 움직임 정보 도출 방법은 융합(Merge) 모드의 움직임 정보 도출된 방법인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 제1 움직임 정보의 움직임 벡터와 상기 제2 후보 움직임 정보의 움직임 벡터 사이의 거리가 제1 임계값보다 큰지 여부를 판단하는 단계는,상기 제1 움직임 정보의 움직임 벡터가 가리키는 위치와 상기 제2 후보 움직임 정보의 움직임 벡터가 가리키는 위치 사이의 거리가 제1 임계값보다 큰지 여부를 판단하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,두 개의 움직임 벡터 사이의 유클리드 거리를 상기 두 개의 움직임 벡터 사이의 거리로 사용하는 단계 - 상기 두 개의 움직임 벡터는 각각 상기 제1 움직임 정보의 움직임 벡터 및 상기 제2 후보 움직임 정보의 움직임 벡터임 - 를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 두 개의 움직임 벡터가 수평 방향 및 수직 방향 중 적어도 하나의 방향에서의 좌표 차이값을 상기 두 개의 움직임 벡터 사이의 거리로 사용하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서, 상기 제1 임계값은 기설정값인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 기설정값은 분수 픽셀 정밀도가 나타내는 값인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 기설정값은 1/2 픽셀 또는 1/4 픽셀인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>10. 제4항에 있어서, 상기 제1 임계값은 자가 적응 결정된 값인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 제1 임계값은 자가 적응 결정된 값이고, 상기 현재 블록의 인접 블록의 복수 개의 움직임 벡터 사이의 상관성 파라미터를 계산하여, 두 개의 움직임 벡터 사이 상관성이 제일 큰 것을 나타내는 상관성 파라미터 값에 대응되는 움직임 벡터 사이의 거리를 상기 제1 임계값으로 사용하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>12. 제2항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 두 번째 후보 움직임 정보를 획득한 다음, 상기 기설정된 움직임 정보 도출 방법을 계속 사용하여 도출된 움직임 정보를 얻는 단계; 및상기 제1 움직임 정보의 움직임 벡터 및 상기 도출된 움직임 정보의 움직임 벡터 사이의 거리가 상기 제1 임계값보다 클 때, 상기 도출된 움직임 정보를 상기 제2 움직임 정보로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>13. 제2항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 두 번째 후보 움직임 정보를 획득한 다음, 상기 기설정된 움직임 정보 도출 방법을 계속 사용하여 도출된 움직임 정보를 얻는 단계; 및상기 제1 움직임 정보의 움직임 벡터와 상기 기설정된 움직임 정보 도출 방법을 통해 얻은 어느 한 움직임 정보의 움직임 벡터 사이의 거리가 상기 제1 임계값보다 작거나 같을 때, 지정된 하나의 도출된 움직임 정보를 상기 제2 움직임 정보로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 제2 후보 움직임 정보를 가리키는 움직임 벡터 방향에서 제1 경계선과 교차하는 움직임 벡터를 상기 제2 움직임 정보의 움직임 벡터로 사용하는 단계 - 상기 제1 경계선은 상기 제1 움직임 정보의 움직임 벡터 지향점을 중심 점으로 하고, 상기 중심 점과의 거리가 상기 제1 임계값과 동일한 점으로 구성됨 - 를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 제1 후보 움직임 정보의 움직임 벡터와의 거리가 기설정 거리인 점을 가리키는 움직임 벡터를 상기 제2 움직임 정보의 움직임 벡터로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 기설정 거리는 1/2 픽셀 또는 1/4 픽셀인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서, 상기 제1 움직임 정보 및 상기 제2 움직임 정보를 사용하여, 상기 현재 블록에 대해 프레임 간 예측을 수행하는 단계는,상기 제1 움직임 정보 및 상기 제2 움직임 정보가 지시하는 후보 움직임 정보에서, 최적의 움직임 정보를 선택하는 단계; 및상기 최적화 움직임 정보를 사용하여, 상기 현재 블록의 프레임 간 예측값을 구성하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,움직임 벡터 오프셋의 융합 모드 MMVD의 방법을 사용하여, 상기 제1 움직임 정보 및 상기 제2 움직임 정보가 지시하는 후보 움직임 정보를 결정하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서,비율 왜곡 최적화의 방법을 사용하여 상기 최적화 움직임 정보를 결정하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>20. 제17항에 있어서,상기 최적화 움직임 정보를 지시하기 위한 파라미터에 대해 인코딩을 수행하고, 비트 스트림에 기입하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>21. 프레임 간 예측 방법으로서, 비디오 이미지 비트 스트림 디코딩에 적용되고,비트 스트림을 해석하여, 현재 블록이 비디오 이미지에서의 위치를 획득하는 단계;상기 위치에 따라, 제1 움직임 정보 및 제2 후보 움직임 정보를 결정하는 단계 - 상기 움직임 정보는 적어도 움직임 벡터를 포함함 - ; 상기 제1 움직임 정보의 움직임 벡터와 상기 제2 후보 움직임 정보의 움직임 벡터 사이의 거리가 제1 임계값보다 큰지 여부를 판단하는 단계;판단 결과는 상기 거리가 상기 제1 임계값보다 작거나 같은 것일 때, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻고; 판단 결과는 상기 거리가 상기 제1 임계값보다 큰 것일 때, 상기 제2 후보 움직임 정보를 제2 움직임 정보로 사용하는 단계; 및상기 제1 움직임 정보 및 상기 제2 움직임 정보를 사용하여, 상기 현재 블록의 프레임 간 예측값을 구성하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 위치에 따라, 제1 움직임 정보 및 제2 후보 움직임 정보를 결정하는 단계는,상기 위치에 따라, 기설정된 움직임 정보 도출 방법을 통해 얻은 첫 번째 움직임 정보를 상기 제1 움직임 정보로 사용하는 단계; 및상기 기설정된 움직임 정보 도출 방법을 통해 얻은 두 번째 움직임 정보를 상기 제2 후보 움직임 정보로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 기설정된 움직임 정보 도출 방법은 융합(Merge) 모드의 움직임 정보 도출된 방법인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>24. 제21항에 있어서, 상기 제1 움직임 정보의 움직임 벡터와 상기 제2 후보 움직임 정보의 움직임 벡터 사이의 거리가 제1 임계값보다 큰지 여부를 판단하는 단계는,상기 제1 움직임 정보의 움직임 벡터가 가리키는 위치와 상기 제2 후보 움직임 정보의 움직임 벡터가 가리키는 위치 사이의 거리가 제1 임계값보다 큰지 여부를 판단하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서,두 개의 움직임 벡터 사이의 유클리드 거리를 상기 두 개의 움직임 벡터 사이의 거리로 사용하는 단계 - 상기 두 개의 움직임 벡터는 각각 상기 제1 움직임 정보의 움직임 벡터 및 상기 제2 후보 움직임 정보의 움직임 벡터임 - 를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>26. 제24항에 있어서,상기 두 개의 움직임 벡터가 수평 방향 및 수직 방향 중 적어도 하나의 방향에서의 좌표 차이값을 상기 두 개의 움직임 벡터 사이의 거리로 사용하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>27. 제24항에 있어서, 상기 제1 임계값은 기설정값인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 기설정값은 분수 픽셀 정밀도가 나타내는 값인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서, 상기 기설정값은 1/2 픽셀 또는 1/4 픽셀인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>30. 제24항에 있어서, 상기 제1 임계값은 자가 적응 결정된 값인 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서,상기 현재 블록의 인접 블록의 복수 개의 움직임 벡터 사이의 상관성 파라미터 값을 계산하여, 두 개의 움직임 벡터 사이 상관성이 제일 큰 것을 나타내는 상관성 파라미터 값에 대응되는 움직임 벡터 사이의 거리를 상기 제1 임계값으로 사용하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>32. 제22항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 두 번째 후보 움직임 정보를 획득한 다음, 상기 기설정된 움직임 정보 도출 방법을 계속 사용하여 도출된 움직임 정보를 얻는 단계; 및상기 제1 움직임 정보의 움직임 벡터 및 상기 도출된 움직임 정보의 움직임 벡터 사이의 거리가 상기 제1 임계값보다 클 때, 상기 도출된 움직임 정보를 상기 제2 움직임 정보로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>33. 제22항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 두 번째 후보 움직임 정보를 획득한 다음, 상기 기설정된 움직임 정보 도출 방법을 계속 사용하여 도출된 움직임 정보를 얻는 단계; 및상기 제1 움직임 정보의 움직임 벡터와 상기 기설정된 움직임 정보 도출 방법을 통해 얻은 어느 한 움직임 정보의 움직임 벡터 사이의 거리가 상기 제1 임계값보다 작거나 같을 때, 지정된 하나의 도출된 움직임 정보를 상기 제2 움직임 정보로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>34. 제21항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 제2 후보 움직임 정보를 가리키는 움직임 벡터 방향에서 제1 경계선과 교차하는 움직임 벡터를 상기 제2 움직임 정보의 움직임 벡터로 사용하는 단계 - 상기 제1 경계선은 상기 제1 움직임 정보의 움직임 벡터 지향점을 중심 점으로 하고, 상기 중심 점과의 거리가 상기 제1 임계값과 동일한 점으로 구성됨 - 를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>35. 제21항에 있어서, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻는 단계는,상기 제1 후보 움직임 정보의 움직임 벡터와의 거리가 기설정 거리인 점을 가리키는 움직임 벡터를 상기 제2 움직임 정보의 움직임 벡터로 사용하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>36. 제21항에 있어서, 상기 제1 움직임 정보 및 상기 제2 움직임 정보를 사용하여, 상기 현재 블록의 프레임 간 예측값을 구성하는 단계는,비트 스트림을 해석하여, 상기 현재 블록의 프레임 간 예측 값을 구성하기 위한 움직임 정보를 지시하기 위한 파라미터를 획득하는 단계;상기 움직임 정보의 파라미터에 따라, 상기 제1 움직임 정보 및 상기 제2 움직임 정보에 의해 지시되는 후보 움직임 정보에서 움직임 벡터를 선택하는 단계;상기 움직임 정보의 파라미터에 따라, 움직임 벡터 보정량을 계산하는 단계;상기 선택된 움직임 벡터와 상기 움직임 벡터의 보정량의 합을, 상기 현재 블록의 움직임 벡터로 사용하는 단계; 및상기 현재 블록의 움직임 벡터를 사용하여, 상기 현재 블록의 프레임 간 예측값을 구성하는 단계를 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서,움직임 벡터 오프셋의 융합 모드 MMVD의 방법을 사용하여, 상기 제1 움직임 정보 및 상기 제2 움직임 정보가 지시하는 후보 움직임 정보를 결정하는 단계를 더 포함하는 것을 특징으로 하는 프레임 간 예측 방법.</claim></claimInfo><claimInfo><claim>38. 프레임 간 예측 장치로서,현재 블록이 비디오 이미지에서의 위치에 따라, 제1 움직임 정보 및 제2 후보 움직임 정보를 결정하도록 구성된 제1 결정 모듈 - 상기 움직임 정보는 적어도 움직임 벡터를 포함함 - ; 상기 제1 움직임 정보의 움직임 벡터와 상기 제2 후보 움직임 정보의 움직임 벡터 사이의 거리가 제1 임계값보다 큰지 여부를 판단하며; 판단 결과는 상기 거리가 상기 제1 임계값보다 작거나 같은 것일 때, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻고; 판단 결과는 상기 거리가 상기 제1 임계값보다 큰 것일 때, 상기 제2 후보 움직임 정보를 제2 움직임 정보로 사용하도록 구성된 제1 판단 모듈; 및상기 제1 움직임 정보 및 상기 제2 움직임 정보를 사용하여, 상기 현재 블록에 대해 프레임 간 예측을 수행하도록 구성된 제1 예측 모듈을 포함하는 것을 특징으로 하는 프레임 간 예측 장치.</claim></claimInfo><claimInfo><claim>39. 프레임 간 예측 장치로서,비트 스트림을 해석하여, 현재 블록이 비디오 이미지에서의 위치를 획득하도록 구성된 해석 모듈; 상기 위치에 따라, 제1 움직임 정보 및 제2 후보 움직임 정보를 결정하도록 구성된 제2 결정 모듈 - 상기 움직임 정보는 적어도 움직임 벡터를 포함함 - ; 상기 제1 움직임 정보의 움직임 벡터와 상기 제2 후보 움직임 정보의 움직임 벡터 사이의 거리가 제1 임계값보다 큰지 여부를 판단하며; 판단 결과는 상기 거리가 상기 제1 임계값보다 작거나 같은 것일 때, 상기 제2 후보 움직임 정보를 업데이트하여, 제2 움직임 정보를 얻고; 판단 결과는 상기 거리가 상기 제1 임계값보다 큰 것일 때, 상기 제2 후보 움직임 정보를 제2 움직임 정보로 사용하도록 구성된 제2 판단 모듈; 및상기 제1 움직임 정보 및 상기 제2 움직임 정보를 사용하여, 상기 현재 블록의 프레임 간 예측값을 구성하도록 구성된 제2 예측 모듈을 포함하는 것을 특징으로 하는 프레임 간 예측 장치.</claim></claimInfo><claimInfo><claim>40. 전자 기기로서, 메모리 및 프로세서를 포함하고 상기 메모리에는 프로세서에서 작동 가능한 컴퓨터 프로그램이 저장되어 있으며, 상기 프로세서가 상기 프로그램을 실행할 때 제1항 내지 제20항 중 어느 한 항에 따른 프레임 간 예측 방법에서의 단계를 구현하거나, 상기 프로그램을 실행할 때 제21항 내지 제37항 중 어느 한 항에 따른 프레임 간 예측 방법에서의 단계를 구현하는 것을 특징으로 하는 전자 기기.</claim></claimInfo><claimInfo><claim>41. 컴퓨터 판독 가능 저장 매체로서, 컴퓨터 프로그램이 저장되어 있고, 상기 컴퓨터 프로그램이 프로세서에 의해 실행될 때 제1항 내지 제20항 중 어느 한 항에 따른 프레임 간 예측 방법에서의 단계를 구현하거나, 상기 프로그램을 실행할 때 제21항 내지 제37항 중 어느 한 항에 따른 프레임 간 예측 방법에서의 단계를 구현하는 것을 특징으로 하는 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국, 광동 ******, 동관, 창안, 우샤, 하이빈 로드, 넘버 **</address><code>520160675505</code><country>중국</country><engName>GUANGDONG OPPO MOBILE TELECOMMUNICATIONS CORP., LTD.</engName><name>광동 오포 모바일 텔레커뮤니케이션즈 코포레이션 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국,...</address><code> </code><country> </country><engName>HUO, Junyan</engName><name>훠, 준옌</name></inventorInfo><inventorInfo><address>중국,...</address><code> </code><country> </country><engName>MA, Yanzhuo</engName><name>마, 옌주오</name></inventorInfo><inventorInfo><address>중국,...</address><code> </code><country> </country><engName>WAN, Shuai</engName><name>완, 슈아이</name></inventorInfo><inventorInfo><address>중국,...</address><code> </code><country> </country><engName>ZHANG, Wei</engName><name>장, 웨이</name></inventorInfo><inventorInfo><address>중국,...</address><code> </code><country> </country><engName>YANG, Fuzheng</engName><name>양, 푸쩡</name></inventorInfo><inventorInfo><address>중국,...</address><code> </code><country> </country><engName>RAN, Qihong</engName><name>란, 치홍</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 사평대로 ***, *층 (반포동)</address><code>920161000615</code><country>대한민국</country><engName>Jipyong Intellectual Property Law Firm</engName><name>특허법인지평</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.01.17</receiptDate><receiptNumber>1-1-2022-0059095-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.04.26</receiptDate><receiptNumber>1-5-2022-0063372-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.09.07</receiptDate><receiptNumber>1-1-2022-0943831-84</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.09.07</receiptDate><receiptNumber>1-1-2022-0943895-95</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.01.16</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2025.02.24</receiptDate><receiptNumber>9-6-2025-0043180-22</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.03.07</receiptDate><receiptNumber>9-5-2025-0235404-90</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.21</receiptDate><receiptNumber>1-1-2025-0448271-07</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.04.21</receiptDate><receiptNumber>1-1-2025-0448270-51</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227001680.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f8f018fcd921254242e77fcb5a9a5d5d79e8d6ce0bec3f35c26068bed9ce1d947e685c1d0f56cadc00c79f38c3092ac8574a520233c7fe37</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1095602f9cfea1fd85b143f8279971025bc1a8049951a0350468156ae5733a703c608d6578f233c32ed996906ce3d87c127cf49a7af9646d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>