<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:11.4111</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.03.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0033110</applicationNumber><claimCount>21</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신경망을 활용하여 가상 프로덕션을 구현하기 위한 방법</inventionTitle><inventionTitleEng>METHOD FOR IMPLEMENTING VIRTUAL PRODUCTION USING NEURAL  NETWORK</inventionTitleEng><openDate>2025.09.16</openDate><openNumber>10-2025-0136532</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.03.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/136</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/90</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시의 일 실시예에 따라 컴퓨팅 장치의 하나 이상의 프로세서에 의해 수행되는, 신경망을 활용하여 가상 프로덕션(Virtual production)을 구현하기 위한 방법이 개시된다. 상기 방법은, 객체 및 배경을 포함하는 원본 영상을 획득하는 단계; 상기 원본 영상에 기초하여 상기 객체 및 상기 배경을 식별하고, 상기 객체 및 배경의 경계를 식별하는 단계; 상기 식별된 객체 및 배경을 기초로 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 단계; 상기 객체에 대한 상기 세부 경계에 기초하여 상기 식별된 객체를 분리하는 단계; 및 합성 배경을 획득하고, 상기 분리된 객체 및 상기 합성 배경에 기초하여 결과 영상을 획득하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 장치의 하나 이상의 프로세서에 의해 수행되는, 신경망을 활용하여 가상 프로덕션(Virtual production)을 구현하기 위한 방법으로서,객체 및 배경을 포함하는 원본 영상을 획득하는 단계;상기 원본 영상에 기초하여 상기 객체 및 상기 배경을 식별하고, 상기 객체 및 배경의 경계를 식별하는 단계;상기 식별된 객체 및 배경을 기초로 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 단계;상기 객체에 대한 상기 세부 경계에 기초하여 상기 식별된 객체를 분리하는 단계; 및합성 배경을 획득하고, 상기 분리된 객체 및 상기 합성 배경에 기초하여 결과 영상을 획득하는 단계; 를 포함하는,방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 객체 및 배경을 포함하는 원본 영상을 획득하는 단계는,영상을 출력하는 디스플레이에 기초하여 상기 배경을 출력하는 단계; 및상기 객체 및 상기 디스플레이에 출력된 배경을 포함하는 원본 영상을 획득하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 디스플레이에 출력된 배경은,상기 디스플레이에 기초한 시각적 결함을 포함하는 배경인,방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,상기 원본 영상에 기초하여 상기 객체 및 상기 배경을 식별하고, 상기 객체 및 배경의 경계를 식별하는 단계는,사전 학습된 객체 구분(Segmentation) 신경망 모델 또는 객체 구분을 위한 알고리즘 중 적어도 하나를 활용하여 상기 원본 영상에 포함된 상기 객체 및 상기 배경을 식별하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 식별된 객체 및 배경을 기초로 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 단계는,상기 원본 영상에 대해 상기 식별된 객체 영역 및 상기 식별된 배경 영역에 기초하여, 상기 객체 및 배경 사이의 중간 영역을 획득하는 단계; 및 상기 객체 및 배경 사이의 중간 영역에 기초하여 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,상기 원본 영상에 대해 상기 식별된 객체 영역 및 상기 식별된 배경 영역에 기초하여, 상기 객체 및 배경 사이의 중간 영역을 획득하는 단계는,상기 원본 영상에 대해 상기 식별된 객체 영역 및 상기 식별된 배경 영역에 기초하여, 상기 객체 및 배경 사이의 중간 영역의 크기를 결정하는 단계; 및상기 객체 및 배경 사이의 중간 영역의 크기에 기초하여 상기 객체 및 배경 사이의 중간 영역을 획득하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>7. 제 5 항에 있어서,상기 객체 및 배경 사이의 중간 영역에 기초하여 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 단계는,매팅(matting) 마스크를 획득하도록 사전 학습된 신경망 모델 또는 매팅(matting) 마스크를 획득하기 위한 알고리즘 중 적어도 하나를 활용하여, 상기 객체 및 배경 사이의 중간 영역에 기초하여 매팅 마스크를 획득하는 단계; 및상기 획득된 매팅 마스크에 기초하여 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 단계를 포함하는,방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서,상기 합성 배경을 획득하고, 상기 분리된 객체 및 상기 합성 배경에 기초하여 결과 영상을 획득하는 단계는,상기 원본 영상에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 단계; 및상기 분리된 객체 및 상기 색상 보정된 합성 배경에 기초하여 상기 결과 영상을 획득하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 원본 영상에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 단계는,색상 변환 테이블을 획득하는 단계;상기 색상 변환 테이블에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 단계;를 포함하고,상기 색상 변환 테이블은,영상을 출력하는 디스플레이 및 상기 디스플레이를 촬영하는 카메라에 기초하여 획득되는,방법.</claim></claimInfo><claimInfo><claim>10. 제 8 항에 있어서,상기 원본 영상에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 단계는,상기 원본 영상에 기초하여 원본 색상 분포 특징을 추출하는 단계;상기 합성 배경에 기초하여 합성 색상 분포 특징을 추출하는 단계; 및상기 원본 색상 분포 특징 및 상기 합성 색상 분포 특징에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 하나 이상의 프로세서에 의해 실행되는 경우, 상기 하나 이상의 프로세서로 하여금 신경망을 활용하여 가상 프로덕션(Virtual production)을 구현하기 위한 동작들을 수행하도록 하며, 상기 동작들은:객체 및 배경을 포함하는 원본 영상을 획득하는 동작;상기 원본 영상에 기초하여 상기 객체 및 상기 배경을 식별하고, 상기 객체 및 배경의 경계를 식별하는 동작;상기 식별된 객체 및 배경을 기초로 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 동작;상기 객체에 대한 상기 세부 경계에 기초하여 상기 식별된 객체를 분리하는 동작; 및합성 배경을 획득하고, 상기 분리된 객체 및 상기 합성 배경에 기초하여 결과 영상을 획득하는 동작; 을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 객체 및 배경을 포함하는 원본 영상을 획득하는 동작은,영상을 출력하는 디스플레이에 기초하여 상기 배경을 출력하는 동작; 및상기 객체 및 상기 디스플레이에 출력된 배경을 포함하는 원본 영상을 획득하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 제 11 항에 있어서,상기 원본 영상에 기초하여 상기 객체 및 상기 배경을 식별하고, 상기 객체 및 배경의 경계를 식별하는 동작은,사전 학습된 객체 구분(Segmentation) 신경망 모델 또는 객체 구분을 위한 알고리즘 중 적어도 하나를 활용하여 상기 원본 영상에 포함된 상기 객체 및 상기 배경을 식별하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 식별된 객체 및 배경을 기초로 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 동작은,상기 원본 영상에 대해 상기 식별된 객체 영역 및 상기 식별된 배경 영역에 기초하여, 상기 객체 및 배경 사이의 중간 영역을 획득하는 동작; 및 상기 객체 및 배경 사이의 중간 영역에 기초하여 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서,상기 원본 영상에 대해 상기 식별된 객체 영역 및 상기 식별된 배경 영역에 기초하여, 상기 객체 및 배경 사이의 중간 영역을 획득하는 동작은,상기 원본 영상에 대해 상기 식별된 객체 영역 및 상기 식별된 배경 영역에 기초하여, 상기 객체 및 배경 사이의 중간 영역의 크기를 결정하는 동작; 및상기 객체 및 배경 사이의 중간 영역의 크기에 기초하여 상기 객체 및 배경 사이의 중간 영역을 획득하는 동작을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 제 14 항에 있어서,상기 객체 및 배경 사이의 중간 영역에 기초하여 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 동작은,매팅(matting) 마스크를 획득하도록 사전 학습된 신경망 모델 또는 매팅(matting) 마스크를 획득하기 위한 알고리즘 중 적어도 하나를 활용하여, 상기 객체 및 배경 사이의 중간 영역에 기초하여 매팅 마스크를 획득하는 동작; 및상기 획득된 매팅 마스크에 기초하여 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 동작을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>17. 제 11 항에 있어서,상기 합성 배경을 획득하고, 상기 분리된 객체 및 상기 합성 배경에 기초하여 결과 영상을 획득하는 동작은,상기 원본 영상에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 동작; 및상기 분리된 객체 및 상기 색상 보정된 합성 배경에 기초하여 상기 결과 영상을 획득하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,상기 원본 영상에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 동작은,색상 변환 테이블을 획득하는 동작;상기 색상 변환 테이블에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 동작;을 포함하고,상기 색상 변환 테이블은,영상을 출력하는 디스플레이 및 상기 디스플레이를 촬영하는 카메라에 기초하여 획득되는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>19. 제 17 항에 있어서,상기 원본 영상에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 동작은,상기 원본 영상에 기초하여 원본 색상 분포 특징을 추출하는 동작;상기 합성 배경에 기초하여 합성 색상 분포 특징을 추출하는 동작; 및상기 원본 색상 분포 특징 및 상기 합성 색상 분포 특징에 기초하여 상기 합성 배경에 대한 색상 보정을 수행하고, 색상 보정된 합성 배경을 획득하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>20. 컴퓨팅 장치로서,적어도 하나의 프로세서; 및메모리를 포함하고,상기 적어도 하나의 프로세서는,객체 및 배경을 포함하는 원본 영상을 획득하고;상기 원본 영상에 기초하여 상기 객체 및 상기 배경을 식별하고, 상기 객체 및 배경의 경계를 식별하고;상기 식별된 객체 및 배경을 기초로 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하고;상기 객체에 대한 상기 세부 경계에 기초하여 상기 식별된 객체를 분리하고; 그리고합성 배경을 획득하고, 상기 분리된 객체 및 상기 합성 배경에 기초하여 결과 영상을 획득하도록 구성되는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>21. 컴퓨터 판독가능 저장 매체에 포함되는 데이터 구조로서, 상기 데이터 구조는 신경망의 파라미터에 대응되며, 그리고 상기 신경망은 상기 파라미터에 적어도 부분적으로 기초하여 이하의 단계를 수행하며, 상기 단계는,객체 및 배경을 포함하는 원본 영상을 획득하는 단계;상기 원본 영상에 기초하여 상기 객체 및 상기 배경을 식별하고, 상기 객체 및 배경의 경계를 식별하는 단계;상기 식별된 객체 및 배경을 기초로 상기 객체에 대하여 상기 경계보다 더 세부적인 세부 경계를 획득하는 단계;상기 객체에 대한 상기 세부 경계에 기초하여 상기 식별된 객체를 분리하는 단계; 및합성 배경을 획득하고, 상기 분리된 객체 및 상기 합성 배경에 기초하여 결과 영상을 획득하는 단계; 를 포함하는,컴퓨터 판독가능 저장 매체에 포함되는 데이터 구조.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강남구...</address><code>120170248261</code><country>대한민국</country><engName>VIVE STUDIOS Co.,Ltd</engName><name>주식회사 비브스튜디오스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 하남시 위례중앙로 ***,...</address><code> </code><country> </country><engName>LEE, Kwanghee</engName><name>이광희</name></inventorInfo><inventorInfo><address>경기도 과천시 과천대로*길 **...</address><code> </code><country> </country><engName>KIM, Woonggon</engName><name>김웅곤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920090037635</code><country>대한민국</country><engName>LEE, Dae Ho</engName><name>이대호</name></agentInfo><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920120001378</code><country>대한민국</country><engName>Park, Gun Hong</engName><name>박건홍</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.03.08</receiptDate><receiptNumber>1-1-2024-0264218-92</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.05.08</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Report of Prior Art Search</documentEngName><documentName>선행기술조사보고서</documentName><receiptDate>2025.06.25</receiptDate><receiptNumber>9-6-2025-0154055-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.08.25</receiptDate><receiptNumber>9-5-2025-0811085-73</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240033110.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c36a90f6218edad0926340e7bcc794cc5f49860ed6fee79a836f08c6419a76c3e31a1438f6b06475a05e52fbd5e44d44bdaa017c877a2592</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa86d01f579aa2bab0b8b8e8e0104184765925bd452391b52e082bf1e939313921bd48537f14263bfa72b83888bb4b2a33ab4f991c647d04d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>