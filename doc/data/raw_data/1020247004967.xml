<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:14:14.1414</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.07.28</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7004967</applicationNumber><claimCount>23</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자동 회귀 언어 모델 신경망을 사용하여 출력 시퀀스 평가</inventionTitle><inventionTitleEng>EVALUATING OUTPUT SEQUENCES USING AN AUTO-REGRESSIVE LANGUAGE MODEL NEURAL NETWORK</inventionTitleEng><openDate>2024.03.14</openDate><openNumber>10-2024-0034804</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.02.13</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.02.13</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0475</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/2113</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 언어 모델 신경망을 사용하여 후보 출력 시퀀스를 평가하기 위한 컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램을 포함한 방법, 시스템 및 장치가 개시된다. 특히 자동 회귀 언어 모델 신경망은 후보 출력 시퀀스를 생성하는 데 사용된다. 동일한 자동 회귀 언어 모델 신경망을 사용하여 후보 출력 시퀀스를 평가하여 하나 이상의 기준 각각에 대한 평가 점수를 결정한다. 그런 다음 평가 점수를 사용하여 후보 출력 시퀀스를 제공할지 여부를 결정한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.02.02</internationOpenDate><internationOpenNumber>WO2023009766</internationOpenNumber><internationalApplicationDate>2022.07.28</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/038742</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 컴퓨터에 의해 수행되는 방법으로서,출력 시퀀스에 대한 요청을 수신하는 단계;자동 회귀 언어 모델 신경망을 사용하여 제1 후보 출력 시퀀스를 생성하는 단계 -상기 제1 후보 출력 시퀀스는 토큰들의 어휘로부터 각각 선택되는 복수의 토큰들을 포함함-;하나 이상의 출력 시퀀스 기준의 세트의 각 출력 시퀀스 기준에 대해: 상기 자동 회귀 언어 모델 신경망을 사용하여, (i) 제1 후보 출력 시퀀스에 이어 (ii) 상기 어휘의 각 토큰에 대한 각각의 점수를 생성하기 위해 출력 시퀀스 기준을 지정하는 하나 이상의 토큰들을 포함하는 입력 시퀀스를 프로세싱하는 단계; 상기 토큰들의 어휘의 해당 고유 서브세트에 있는 토큰들에 대한 각각의 점수로부터, 상기 자동 회귀 언어 모델 신경망에 의해 생성된 상기 제1 후보 출력 시퀀스가 출력 시퀀스 기준을 만족하는 정도를 나타내는 상기 제1 후보 출력 시퀀스에 대한 각각의 평가 점수(rating score)를 결정하는 단계; 그리고상기 하나 이상의 출력 시퀀스 기준에 대한 상기 제1 후보 출력 시퀀스에 대한 각각의 평가 점수를 사용하여 상기 요청에 응답하여 상기 제1 후보 출력 시퀀스를 제공하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 요청은 컨텍스트 시퀀스를 따르는 출력 시퀀스에 대한 것이며,상기 제1 후보 출력 텍스트 시퀀스를 생성하는 단계는 상기 컨텍스트 시퀀스를 포함하는 입력에 대해 상기 자동 회귀 언어 모델 신경망을 컨디셔닝(conditioning)하는 단계를 포함하고, 그리고 (i) 제1 후보 출력 시퀀스에 이어 (ii) 출력 시퀀스 기준을 지정하는 하나 이상의 토큰들을 포함하는 입력 시퀀스는 상기 컨텍스트 시퀀스를 더 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 방법은,상기 자동 회귀 언어 모델 신경망을 사용하여, 하나 이상의 추가 후보 출력 시퀀스들을 생성하는 단계;각각의 추가 후보 출력 시퀀스에 대해: 하나 이상의 출력 시퀀스 기준의 세트의 각 출력 시퀀스 기준에 대해:  (i) 추가 후보 출력 시퀀스에 이어 (ii) 상기 어휘의 각 토큰에 대한 각각의 점수를 생성하기 위해 상기 자동 회귀 언어 모델 신경망을 사용하여 상기 출력 시퀀스 기준을 지정하는 하나 이상의 토큰들을 포함하는 입력 시퀀스를 프로세싱하는 단계;  상기 토큰들의 어휘의 해당 서브세트의 토큰들에 대한 각각의 점수로부터, 상기 자동 회귀 언어 모델 신경망에 의해 생성된 상기 추가 후보 출력 시퀀스가 상기 출력 시퀀스 기준을 만족시키는 정도를 나타내는 각각의 평가 점수를 결정하는 단계를 더 포함하며; 그리고상기 하나 이상의 출력 시퀀스 기준에 대한 각각의 평가 점수를 사용하여 상기 요청에 응답하여 상기 제1 후보 출력 시퀀스를 제공하는 단계는,상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스 중, 상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스에 대한 각각의 평점 점수를 사용하여 상기 요청에 응답하여 제공할 시퀀스를 선택하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스 중, 상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스에 대한 각각의 평점 점수를 사용하여 상기 요청에 응답하여 제공할 시퀀스를 선택하는 단계는, 후보 출력 시퀀스 각각에 대해, 상기 세트 내의 출력 시퀀스 기준 중 하나 이상 각각에 대한 후보 출력 시퀀스에 대한 각각의 평가 점수로부터 각각의 품질 점수를 생성하는 단계; 그리고상기 요청에 대한 응답으로 제공될 시퀀스로서, 상기 각각의 품질 점수가 가장 높은 후보 출력 시퀀스를 선택하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 하나 이상의 출력 시퀀스 기준에 대한 각각의 평가 점수를 사용하여 상기 요청에 응답하여 상기 제1 후보 출력 시퀀스를 제공하는 단계는,상기 세트 내의 제1 출력 기준에 대한 제1 후보 출력 시퀀스에 대한 각각의 품질 점수가 임계값을 만족하는지 여부를 결정하는 단계; 그리고상기 세트 내의 제1 출력 기준에 대한 제1 후보 출력 시퀀스에 대한 각각의 품질 점수가 상기 임계값을 만족하지 않을 때, 상기 요청에 응답하여 제1 후보 출력 시퀀스를 제공하지 않기로 결정하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>6. 선행하는 청구항 중 어느 한 항의 자동 회귀 언어 모델 신경망을 트레이닝하는 방법으로서,하나 이상의 트레이닝 예의 배치(batch)를 획득하는 단계 -각 트레이닝 예는 (i) 트레이닝 출력 시퀀스에 이어 (ii) 출력 시퀀스 기준의 세트로부터 특정 출력 시퀀스 기준을 지정하는 하나 이상의 토큰들을 포함하는 트레이닝 입력 시퀀스, 및 상기 트레이닝 출력 시퀀스가 특정 출력 시퀀스 기준을 만족시키는 정도를 나타내는 해당 출력 시퀀스 기준에 대한 GT(ground truth) 평가 점수를 포함함-;상기 배치의 각 트레이닝 예에 대해: 상기 자동 회귀 언어 모델 신경망을 사용하여, 상기 트레이닝 예의 상기 트레이닝 입력 시퀀스를 프로세싱하여 상기 어휘의 각 토큰에 대한 개별 점수를 생성하는 단계; 그리고상기 자동 회귀 언어 모델 신경망을 트레이닝하여, 상기 배치의 각 트레이닝 예에 대해, (i) 상기 트레이닝 예를 위해 생성된 상기 어휘의 토큰들에 대한 각각의 점수와 (ii) 상기 트레이닝 예에 대한 GT(ground truth) 평가 점수를 산출하는 상기 어휘의 토큰들에 대한 점수들의 GT(ground truth) 세트 사이의 에러를 측정하는 손실 함수를 최소화하는 단계를 포함하는, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 자동 회귀 언어 모델 신경망을 트레이닝하여 손실 함수를 최소화하는 단계는,트레이닝 입력 시퀀스의 이전 위치에는 손실을 적용하지 않고 상기 에러에만 손실을 적용하는 단계를 포함하는, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서, 상기 방법은,상기 자동 회귀 언어 모델 신경망을 트레이닝하여 손실 함수를 최소화하기 전에, 토큰들의 시퀀스의 이전 토큰들이 주어지면 토큰들의 시퀀스의 다음 토큰을 예측해야 하는 언어 모델링 태스크에 대해 상기 자동 회귀 언어 모델 신경망을 트레이닝하는 단계를 더 포함하는, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>9. 하나 이상의 컴퓨터에 의해 수행되는 방법으로서,출력 시퀀스에 대한 요청을 수신하는 단계;자동 회귀 언어 모델 신경망을 사용하여, 제1 후보 출력 시퀀스를 생성하는 단계 -상기 제1 후보 출력 시퀀스는 복수의 위치 각각에 각각의 토큰을 포함하고, 그리고 언어 모델 신경망은 제1 서브네트워크와 출력 서브네트워크를 포함하며,  상기 제1 서브네트워크는, 복수의 위치 중 각각의 특정 위치에서,  복수의 입력 토큰들을 포함하는 입력을 프로세싱하여 입력 토큰들 각각에 대해 각각의 은닉 상태를 생성하며, 상기 입력 토큰들은 제1 후보 출력 시퀀스의 특정 위치보다 앞선 각 위치의 토큰들을 포함하며; 그리고 상기 출력 서브네트워크는, 복수의 위치 중 각각의 특정 위치에서,  특정 위치 바로 앞의 위치에서 입력 토큰에 대한 각각의 은닉 상태를 프로세싱하여 토큰들의 어휘의 각 토큰에 대한 각각의 점수를 생성하고; 그리고  상기 각각의 점수를 사용하여 상기 제1 후보 출력 시퀀스의 특정 위치에 있는 토큰으로서 어휘의 토큰들 중 하나를 선택함-;하나 이상의 분류기 계층을 사용하여, 상기 제1 후보 출력 시퀀스의 모든 위치에 있는 모든 토큰을 포함하는 복수의 입력 토큰들을 포함하는 입력을 프로세싱함으로써 상기 제1 서브네트워크에 의해 생성된 각각의 은닉 상태 중 하나 이상을 프로세싱하여, 자동 회귀 언어 모델 신경망에 의해 생성된 제1 후보 출력 시퀀스가 출력 시퀀스 기준을 만족시키는 정도를 나타내는 하나 이상의 출력 시퀀스 기준의 세트에서 각 출력 시퀀스 기준에 대한 각각의 평가 점수를 생성하는 단계; 그리고하나 이상의 출력 시퀀스 기준에 대한 제1 후보 출력 시퀀스에 대한 각각의 평가 점수를 사용하여 상기 요청에 응답하여 제1 후보 출력 시퀀스를 제공하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 요청은 컨텍스트 시퀀스를 따르는 출력 시퀀스에 대한 것이고, 상기 제1 후보 출력 텍스트 시퀀스를 생성하는 단계는 상기 컨텍스트 시퀀스를 포함하는 입력에 대해 상기 자동 회귀 언어 모델 신경망을 컨디셔닝하는 단계를 포함하고, 각각의 특정 위치에 대해, 입력 토큰들은 상기 컨텍스트 시퀀스로부터의 토큰들을 더 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>11. 제9항 또는 제10항에 있어서, 상기 방법은,상기 자동 회귀 언어 모델 신경망을 사용하여 하나 이상의 추가 후보 출력 시퀀스를 생성하는 단계;각각의 추가 후보 출력 시퀀스에 대해, 상기 자동 회귀 언어 모델 신경망에 의해 생성된 상기 추가 후보 출력 시퀀스가 상기 출력 시퀀스 기준을 만족하는 정도를 나타내는 하나 이상의 출력 시퀀스 기준의 세트의 각 출력 시퀀스 기준에 대한 개별 평가 점수를 생성하는 단계를 더 포함하며, 그리고상기 하나 이상의 출력 시퀀스 기준에 대한 각각의 평가 점수를 사용하여 상기 요청에 응답하여 상기 제1 후보 출력 시퀀스를 제공하는 단계는,상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스 중, 상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스에 대한 각각의 평점 점수를 사용하여 상기 요청에 응답하여 제공할 시퀀스를 선택하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스 중, 상기 제1 후보 출력 시퀀스 및 상기 하나 이상의 추가 후보 출력 시퀀스에 대한 각각의 평점 점수를 사용하여 상기 요청에 응답하여 제공할 시퀀스를 선택하는 단계는, 상기 후보 출력 시퀀스 각각에 대해, 상기 세트 내의 출력 시퀀스 기준 중 하나 이상 각각에 대한 후보 출력 시퀀스에 대한 각각의 평가 점수로부터 각각의 품질 점수를 생성하는 단계; 그리고상기 요청에 대한 응답으로 제공될 시퀀스로서 각각의 품질 점수가 가장 높은 후보 출력 시퀀스를 선택하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>13. 제9항 내지 제12항 중 어느 한 항에 있어서, 상기 하나 이상의 출력 시퀀스 기준에 대한 각각의 평가 점수를 사용하여 상기 요청에 응답하여 상기 제1 후보 출력 시퀀스를 제공하는 단계는,상기 세트 내의 제1 출력 기준에 대한 제1 후보 출력 시퀀스에 대한 각각의 품질 점수가 임계값을 만족하는지 여부를 결정하는 단계; 그리고상기 세트 내의 제1 출력 기준에 대한 제1 후보 출력 시퀀스에 대한 각각의 품질 점수가 상기 임계값을 만족하지 않을 때, 상기 요청에 응답하여 제1 후보 출력 시퀀스를 제공하지 않기로 결정하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>14. 제9항 내지 제13항 중 어느 한 항에 있어서, 상기 제1 후보 출력 시퀀스의 모든 위치에서 모든 토큰을 포함하는 복수의 입력 토큰들을 포함하는 입력을 프로세싱함으로써 상기 제1 서브네트워크에 의해 생성된 각각의 은닉 상태 중 하나 이상을 프로세싱하는 단계는,제1 후보 출력 시퀀스의 마지막 위치에 있는 토큰에 대해 상기 제1 서브네트워크에 의해 생성된 각각의 은닉 상태를 프로세싱하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>15. 제9항 내지 제14항 중 어느 한 항에 있어서, 상기 제1 후보 출력 시퀀스의 모든 위치에서 모든 토큰을 포함하는 복수의 입력 토큰들을 포함하는 입력을 프로세싱함으로써 상기 제1 서브네트워크에 의해 생성된 각각의 은닉 상태 중 하나 이상을 프로세싱하는 단계는,입력 토큰들 중 지정된 위치에서 지정된 입력 토큰에 대해 제1 서브네트워크에 의해 생성된 각각의 은닉 상태를 프로세싱하는 단계를 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>16. 제9항 내지 제15항 중 어느 한 항에 있어서, 상기 방법은,상기 제1 후보 출력 시퀀스의 생성 동안 및 상기 제1 후보 출력 시퀀스의 마지막 위치 앞의 하나 이상의 지정된 위치에 대해,하나 이상의 분류기 계층을 사용하여 제1 후보 출력 시퀀스의 지정된 위치에서 제1 서브네트워크에 의해 생성된 각각의 은닉 상태 중 하나 이상을 프로세싱하여, 지정된 위치에서 생성된 제1 후보 출력 시퀀스의 일부가 출력 시퀀스 기준을 만족하는 정도를 나타내는 하나 이상의 출력 시퀀스 기준의 세트의 각각의 출력 시퀀스 기준에 대한 각각의 평가 점수를 생성하는 단계;(i) 지정된 위치를 지나 제1 후보 출력 시퀀스를 계속 생성할지 또는 (ii) 상기 지정된 위치에서 생성된 세트의 출력 시퀀스 기준에 대한 각각의 평가 점수에 기초하여 상기 요청에 응답하여 제1 후보 출력 시퀀스의 일부를 제공하지 않을지 여부를 결정하는 단계를 더 포함하는, 하나 이상의 컴퓨터에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>17. 제9항 내지 제16항 중 어느 한 항에 따른 자동 회귀 언어 모델 신경망을 트레이닝하는 방법으로서,하나 이상의 트레이닝 예의 배치(batch)를 획득하는 단계 -각 트레이닝 예는,  트레이닝 출력 시퀀스, 및  상기 트레이닝 출력 시퀀스가 특정 출력 시퀀스 기준을 만족시키는 정도를 나타내는 하나 이상의 출력 시퀀스 기준 각각에 대한 개별 GT(ground truth) 평가 점수를 포함함-;상기 배치의 각 트레이닝 예에 대해: 하나 이상의 분류기 계층을 사용하여 트레이닝 예의 트레이닝 출력 시퀀스의 모든 위치에 있는 모든 토큰을 포함하는 복수의 입력 토큰들을 포함하는 입력을 프로세싱함으로써 제1 서브네트워크에 의해 생성된 각각의 은닉 상태 중 하나 이상을 프로세싱하여, 각각의 출력 시퀀스 기준에 대한 각각의 평가 점수를 생성하는 단계; 그리고상기 배치의 각 트레이닝 예에 대해, (i) 트레이닝 예에 대해 생성된 각각의 평가 점수와 (ii) 트레이닝 예에 대한 각각의 GT 평가 점수 사이의 에러를 측정하는 손실 함수를 최소화하기 위해 상기 하나 이상의 분류기 계층을 트레이닝하는 단계를 포함하는, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 손실 함수를 최소화하기 위해 하나 이상의 분류기 계층을 트레이닝하는 단계는,상기 하나 이상의 분류기 계층을 트레이닝하는 동안 입력 서브네트워크를 고정 상태(frozen)로 유지하는 단계를 포함하는, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>19. 제17항 또는 제18항에 있어서, 상기 방법은,상기 하나 이상의 분류기 계층을 트레이닝하기 전에, 토큰들의 시퀀스의 이전 토큰들이 주어지면 토큰들의 시퀀스의 다음 토큰을 예측해야 하는 언어 모델링 태스크에 대해 자동 회귀 언어 모델 신경망을 트레이닝하는 단계를 더 포함하는, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>20. 선행하는 청구항 중 어느 한 항에 있어서, 상기 출력 시퀀스는 텍스트 시퀀스이고, 상기 토큰들의 어휘는 복수의 텍스트 토큰들을 포함하는, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 제2항 또는 제10항에 종속되는 경우, 상기 컨텍스트 시퀀스는 텍스트 시퀀스인, 자동 회귀 언어 모델 신경망을 트레이닝하는 방법.</claim></claimInfo><claimInfo><claim>22. 시스템으로서,하나 이상의 컴퓨터; 그리고상기 하나 이상의 컴퓨터에 의해 실행될 때, 상기 하나 이상의 컴퓨터로 하여금 제1항 내지 제21항 중 어느 한 항의 각각의 동작을 수행하게 하는 명령어를 저장하는 하나 이상의 저장 장치를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>23. 하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 제1항 내지 제21항 중 어느 한 항의 방법의 각각의 동작을 수행하게 하는 명령어를 저장하는 하나 이상의 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>DE FREITAS ADIWARDANA, Daniel</engName><name>드 프레이타스 아디와다나 다니엘</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SHAZEER, Noam M.</engName><name>셰이저 노암 엠.</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.07.28</priorityApplicationDate><priorityApplicationNumber>63/226,748</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.02.13</receiptDate><receiptNumber>1-1-2024-0165049-27</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.02.15</receiptDate><receiptNumber>1-5-2024-0028550-59</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247004967.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a7e5ef5e88e7aecdd2c01949ec8c2e5df314f8440760321abd26144675120c90fe4ee5f64b4d00da33a137d30e666e2b8715af32804497c0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff2e1b327c13fd8d95460187e673e9c6b29d7da32bd7a127e073349456d3296300db7efe8881a67f27adc4bdf3d1a48a6bda89daa6ad18d10</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>