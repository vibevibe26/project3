<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:55.555</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.06.07</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2024-7037706</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 컨텐츠 항목들에서의 머신 러닝</inventionTitle><inventionTitleEng>MACHINE LEARNING IN AUGMENTED REALITY CONTENT ITEMS</inventionTitleEng><openDate>2024.11.26</openDate><openNumber>10-2024-0166591</openNumber><originalApplicationDate>2021.06.07</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2023-7000879</originalApplicationNumber><originalExaminationRequestDate>2024.11.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.11.12</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020237000879</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서의 시스템들 및 방법들은, 이미지 캡처 디바이스를 통해 이미지를 수신하는 것, 머신 러닝 모델을 사용하는 것, 이미지 증강 결정을 생성하는 것, 증강 현실 컨텐츠 항목에 액세스하는 것, 생성된 이미지 증강 결정을 증강 현실 컨텐츠 항목과 연관 짓는 것, 증강 현실 컨텐츠 항목 및 연관된 이미지 증강 결정을 사용하여 수신된 이미지를 수정하는 것, 및 컴퓨팅 디바이스의 그래픽 사용자 인터페이스 상에서 수정된 이미지의 제시를 야기하는 것을 기술한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.12.16</internationOpenDate><internationOpenNumber>WO2021252386</internationOpenNumber><internationalApplicationDate>2021.06.07</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/036238</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서를 사용하여, 이미지 캡처 디바이스를 통해 이미지를 수신하는 단계;제1 모델 타입을 포함하는 제1 머신 러닝 모델을 사용하여, 이미지 증강 결정을 생성하는 단계- 상기 이미지 증강 결정은 상기 수신된 이미지 및 상기 이미지 캡처 디바이스의 하나 이상의 센서로부터 수신된 비-이미지 데이터에 기초함 -;제2 모델 타입을 포함하는 제2 머신 러닝 모델을 사용하여, 보충적인 이미지 증강 결정을 생성하는 단계 - 상기 보충적인 이미지 증강 결정은 상기 이미지 증강 결정에 기초하고, 상기 제2 모델 타입은 상기 제1 모델 타입과는 상이함 -;상기 이미지 증강 결정 및 상기 보충적인 이미지 증강 결정에 기초하여 증강 현실 경험에 액세스하는 단계; 및상기 증강 현실 경험, 상기 이미지 증강 결정, 및 상기 보충적인 이미지 증강 결정을 사용하여 상기 이미지를 수정하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 비-이미지 데이터는 위치 데이터 및 오디오 데이터 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 생성된 이미지 증강 결정을 상기 증강 현실 경험에 대한 입력으로서 제공하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 제1 머신 러닝 모델 및 상기 제2 머신 러닝 모델 중 하나 또는 둘 다가 리소스 라이브러리로부터 액세스되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 제1 모델 타입 및 상기 제2 모델 타입은,미리 정의된 카테고리 내에 입력이 존재할 확률을 제공하도록 구성된 분류 모델(classification model);미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성되는 세그먼테이션 모델; 및상기 이미지 내의 관심 포인트들을 예측하도록 구성되는 특징(saliency) 모델중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 제1 모델 타입은 미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성된 세그먼테이션 모델이고, 상기 제2 모델 타입은 미리 정의된 카테고리 내에 입력이 존재할 확률을 제공하도록 구성된 분류 모델 및 상기 이미지 내의 관심 포인트들을 예측하도록 구성된 특징 모델 중 하나인, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 제1 모델 타입은 미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성되는 세그먼테이션 모델이고, 상기 제2 머신 러닝 모델은 상기 제1 머신 러닝 모델에 의해 필터링된 상기 이미지의 일부의 패턴 및 텍스처 데이터 중 하나 또는 둘 다를 결정하도록 구성되는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 증강 현실 경험은 사용자 개입 없이 자동으로 액세스되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 증강 현실 경험은 상기 수신된 이미지의 이미지 콘텐츠를 수정하도록 구성되는 증강 현실 콘텐츠 아이템인, 방법.</claim></claimInfo><claimInfo><claim>10. 시스템으로서,하나 이상의 프로세서; 및명령어들을 저장한 메모리를 포함하고, 상기 명령어들은, 상기 하나 이상의 프로세서에 의해 실행될 때, 상기 하나 이상의 프로세서로 하여금,하나 이상의 프로세서를 사용하여, 이미지 캡처 디바이스를 통해 이미지를 수신하는 동작;제1 모델 타입을 포함하는 제1 머신 러닝 모델을 사용하여, 이미지 증강 결정을 생성하는 동작- 상기 이미지 증강 결정은 상기 수신된 이미지 및 상기 이미지 캡처 디바이스의 하나 이상의 센서로부터 수신된 비-이미지 데이터에 기초함 -;제2 모델 타입을 포함하는 제2 머신 러닝 모델을 사용하여, 보충적인 이미지 증강 결정을 생성하는 동작 - 상기 보충적인 이미지 증강 결정은 상기 이미지 증강 결정에 기초하고, 상기 제2 모델 타입은 상기 제1 모델 타입과는 상이함 -;상기 이미지 증강 결정 및 상기 보충적인 이미지 증강 결정에 기초하여 증강 현실 경험에 액세스하는 동작; 및상기 증강 현실 경험, 상기 이미지 증강 결정, 및 상기 보충적인 이미지 증강 결정을 사용하여 상기 이미지를 수정하는 동작을 포함하는 동작들을 수행하도록 야기하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 생성된 이미지 증강 결정을 상기 증강 현실 경험에 대한 입력으로서 제공하는 동작을 추가로 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 제1 머신 러닝 모델 및 상기 제2 머신 러닝 모델 중 하나 또는 둘 다가 리소스 라이브러리로부터 액세스되는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 제1 모델 타입 및 상기 제2 모델 타입은,미리 정의된 카테고리 내에 입력이 존재할 확률을 제공하도록 구성된 분류 모델(classification model);미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성되는 세그먼테이션 모델; 및상기 이미지 내의 관심 포인트들을 예측하도록 구성되는 특징(saliency) 모델중 하나 이상을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서, 상기 제1 모델 타입은 미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성된 세그먼테이션 모델이고, 상기 제2 모델 타입은 미리 정의된 카테고리 내에 입력이 존재할 확률을 제공하도록 구성된 분류 모델 및 상기 이미지 내의 관심 포인트들을 예측하도록 구성된 특징 모델 중 하나인, 시스템.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서, 상기 제1 모델 타입은 미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성되는 세그먼테이션 모델이고, 상기 제2 머신 러닝 모델은 상기 제1 머신 러닝 모델에 의해 필터링된 상기 이미지의 일부의 패턴 및 텍스처 데이터 중 하나 또는 둘 다를 결정하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>16. 명령어들을 저장한 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 명령어들은, 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하도록 야기하고, 상기 동작들은,하나 이상의 프로세서를 사용하여, 이미지 캡처 디바이스를 통해 이미지를 수신하는 동작;제1 모델 타입을 포함하는 제1 머신 러닝 모델을 사용하여, 이미지 증강 결정을 생성하는 동작- 상기 이미지 증강 결정은 상기 수신된 이미지 및 상기 이미지 캡처 디바이스의 하나 이상의 센서로부터 수신된 비-이미지 데이터에 기초함 -;제2 모델 타입을 포함하는 제2 머신 러닝 모델을 사용하여, 보충적인 이미지 증강 결정을 생성하는 동작 - 상기 보충적인 이미지 증강 결정은 상기 이미지 증강 결정에 기초하고, 상기 제2 모델 타입은 상기 제1 모델 타입과는 상이함 -;상기 이미지 증강 결정 및 상기 보충적인 이미지 증강 결정에 기초하여 증강 현실 경험에 액세스하는 동작; 및상기 증강 현실 경험, 상기 이미지 증강 결정, 및 상기 보충적인 이미지 증강 결정을 사용하여 상기 이미지를 수정하는 동작을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 생성된 이미지 증강 결정을 상기 증강 현실 경험에 대한 입력으로서 제공하는 동작을 추가로 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 제1 머신 러닝 모델 및 상기 제2 머신 러닝 모델 중 하나 또는 둘 다가 리소스 라이브러리로부터 액세스되는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 제1 모델 타입 및 상기 제2 모델 타입은,미리 정의된 카테고리 내에 입력이 존재할 확률을 제공하도록 구성된 분류 모델(classification model);미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성되는 세그먼테이션 모델; 및상기 이미지 내의 관심 포인트들을 예측하도록 구성되는 특징(saliency) 모델중 하나 이상을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서, 상기 제1 모델 타입은 미리 정의된 기준에 기초하여 상기 이미지의 일부를 필터링하도록 구성된 세그먼테이션 모델이고, 상기 제2 모델 타입은 미리 정의된 카테고리 내에 입력이 존재할 확률을 제공하도록 구성된 분류 모델 및 상기 이미지 내의 관심 포인트들을 예측하도록 구성된 특징 모델 중 하나인, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>우크라이나</country><engName>RYKHLIUK, Olha</engName><name>라이클리우크, 올하</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>미국</country><engName>SOLICHIN, Jonathan</engName><name>솔리친, 조나단</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>러시아</country><engName>STOLIAR, Aleksei</engName><name>스톨리아, 알렉세이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.06.10</priorityApplicationDate><priorityApplicationNumber>63/037,518</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.06.19</priorityApplicationDate><priorityApplicationNumber>16/946,413</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2024.11.12</receiptDate><receiptNumber>1-1-2024-1242566-84</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247037706.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e1495820a1bd63d9713daec52230998422373360a04c3617172af6deb708508927c1d3b0f66219c068851310a46d0aaeb85a55e49dbda548</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2bd40d05a7bb6068e839e76b32f0a9a6867ccbcf2a637970010f9a5205b74ebaf8f13508703b61b8f9a920737da07f9b992feeded81acf9c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>