<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:46.4046</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.06.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7001121</applicationNumber><claimCount>7</claimCount><examinerName> </examinerName><finalDisposal>거절결정 후 재심사중</finalDisposal><inventionTitle>근안 디스플레이들에서의 눈 추적</inventionTitle><inventionTitleEng>EYE TRACKING IN NEAR-EYE DISPLAYS</inventionTitleEng><openDate>2023.02.24</openDate><openNumber>10-2023-0026398</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.06.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.01.10</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G02B 27/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/082</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 7/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/277</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 증강 현실 시스템에서 눈의 움직임을 추적하기 위한 기술들은 객체 또는 그 일부의 복수의 베이스 이미지들을 식별한다. 검색 이미지가 복수의 베이스 이미지들 중 적어도 일부에 적어도 부분적으로 기초하여 를 생성될 수 있다. 딥 러닝 결과가 딥 러닝 모델에서 신경망을 사용하여 베이스 이미지에 대해 적어도 딥 러닝 프로세스를 수행하여 생성될 수 있다. 캡처된 이미지가 칼만 필터 모델 및 딥 러닝 결과를 사용하여 캡처된 이미지와 검색 이미지에 대해 적어도 이미지 정합 프로세스를 수행하여 로컬화될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.12.16</internationOpenDate><internationOpenNumber>WO2021252940</internationOpenNumber><internationalApplicationDate>2021.06.11</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/037072</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 근안(near-eye) 디스플레이에서 눈의 움직임을 추적하기 위한 방법으로서,객체 또는 그 일부의 복수의 베이스 이미지들을 식별하는 단계;상기 복수의 베이스 이미지들 중 적어도 일부에 적어도 부분적으로 기초하여 검색 이미지를 생성하는 단계;딥 러닝(deep learning) 모델에서 신경망을 사용하여 베이스 이미지에 대해 적어도 딥 러닝 프로세스를 수행하여 딥 러닝 결과를 생성하는 단계; 및칼만(Kalman) 필터 모델 및 상기 딥 러닝 결과를 사용하여 캡처된 이미지와 상기 검색 이미지에 대해 적어도 이미지 정합(registration) 프로세스를 수행하여 상기 검색 이미지에 상기 캡처된 이미지를 로컬화(localizing)하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 객체는 사용자의 망막을 포함하고, 상기 망막의 적어도 일부를 나타내는 상기 캡처된 이미지는 하나 이상의 입력 광 패턴들에 응답하여 동공으로부터의 글린트(glint)를 캡처하는 동공-글린트 기술들을 사용하지 않고 상기 검색 이미지에 대해 로컬화되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 딥 러닝 결과를 생성하는 단계는,딥 컨벌루션 신경망(DCNN: deep convolution neural network)을 사용하여 상기 캡처된 이미지의 영역의 피처(feature)를 추출하는 단계;상기 피처를 제1 피처 및 제2 피처를 포함하는 복수의 피처들로 변환하는 단계;상기 제1 피처에 적어도 부분적으로 기초하여 상기 영역을 포지티브(positive) 영역 또는 네거티브(negative) 영역으로 분류하는 단계; 및상기 제2 피처에 적어도 부분적으로 기초하여 상기 영역에 대한 회귀 또는 보정을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,상기 딥 러닝 결과를 생성하는 단계는,딥 컨벌루션 신경망(DCNN)을 사용하여 상기 캡처된 이미지의 영역의 피처를 추출하는 단계; 및상기 피처를 제1 피처 및 제2 피처를 포함하는 복수의 피처들로 변환하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서,상기 딥 러닝 결과를 생성하는 단계는,상기 DCNN에서 하나 이상의 컨벌루션 계층들을 사용하여 적어도 상기 제1 피처를 적어도 컨벌빙(convolving)함으로써 제1 응답 맵을 생성하는 단계; 및상기 제1 응답 맵에 적어도 부분적으로 기초하여 상기 영역을 포지티브 영역 또는 네거티브 영역으로 분류하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5 항에 있어서,상기 딥 러닝 결과를 생성하는 단계는,상기 DCNN에서 상기 하나 이상의 컨벌루션 계층들 또는 하나 이상의 상이한 컨벌루션 계층들을 사용하여 적어도 상기 제2 피처를 컨벌빙함으로써 제2 응답 맵을 생성하는 단계; 및적어도 상기 제2 응답 맵을 사용하여 상기 영역의 예측된 위치에 대한 회귀 또는 보정을 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 캡처된 이미지를 로컬화하는 단계는,상기 딥 러닝 프로세스를 상태 천이 모델에 매립하는 단계; 및적어도 상기 상태 천이 모델을 사용하여 하나 이상의 측정치들로서 상기 칼만 필터 모델에서의 상기 딥 러닝 결과를 수신하는 단계 — 상기 상태 천이 모델은 이전 시점에서의 이전 포지션 상태에 적어도 부분적으로 기초하고 상태 추정 모델의 제어 벡터 또는 프로세스 잡음 중 적어도 하나에 기초하여 다음 시점에서의 다음 포지션 상태를 결정하는 데 사용됨 — 를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 캡처된 이미지를 로컬화하는 단계는,상기 이미지 정합 프로세스에서 적어도 상기 칼만 필터 모델을 사용하여 다음 시점에서의 측정치를 결정하는 단계;적어도 상기 이미지 정합 프로세스를 수행하여 유사한 배경 또는 하나 이상의 유사한 피처들의 간섭들을 감소시키는 단계; 및상기 칼만 필터 모델 및 상기 이미지 정합 프로세스를 사용하여 상기 검색 이미지에서 상기 캡처된 이미지를 로컬화하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제7 항에 있어서,상기 딥 러닝 프로세스를 매립하는 단계는,상기 상태 천이 모델에 대한 하나 이상의 제어 벡터들을 결정하는 단계;통계적 분포로부터 프로세스 잡음을 도출하는 단계; 및상기 상태 천이 모델에 대한 시간 스텝(step)을 결정을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,상기 칼만 필터 모델 및 상기 이미지 정합 프로세스를 사용하여 상기 검색 이미지에서 상기 캡처된 이미지를 로컬화하는 단계는,상기 캡처된 이미지의 전체 프레임에 대해 대략적인 정합을 수행하는 단계; 및상기 대략적인 정합에서 참조되는 영역 주위의 외부 영역에서 하나 이상의 피처들 또는 피처 포인트들에 대해 미세 정합을 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서,상기 캡처된 이미지의 전체 프레임에 대해 상기 대략적인 정합을 수행하는 단계는,상기 캡처된 이미지 또는 상기 검색 이미지의 상기 전체 프레임의 하나 이상의 영역들에서 상기 하나 이상의 피처들 또는 상기 피처 포인트들을 검출하는 단계; 및상기 캡처된 이미지를 상기 전체 프레임의 상기 하나 이상의 영역들에 정합시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,상기 대략적인 정합에서 참조되는 영역 주위의 상기 외부 영역에서 상기 하나 이상의 피처들 또는 피처 포인트들에 대해 상기 미세 정합을 수행하는 단계는,상기 대략적인 정합에서 참조되는 상기 영역에 대응하는 확대된 영역 내의 피처 또는 피처 포인트를 선택하는 단계; 및상기 피처 또는 상기 피처 포인트를 상기 검색 이미지의 상기 외부 영역의 대응하는 피처 또는 피처 포인트와 매칭시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12 항에 있어서,상기 대략적인 정합에서 참조되는 영역 주위의 상기 외부 영역에서 상기 하나 이상의 피처들 또는 피처 포인트들에 대해 상기 미세 정합을 수행하는 단계는,상기 피처 또는 상기 피처 포인트와 상기 검색 이미지의 상기 외부 영역의 대응하는 피처 또는 피처 포인트의 매칭의 결과에 적어도 부분적으로 기초하여 상기 검색 이미지에서 상기 캡처된 이미지를 로컬화하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 근안 디스플레이에서 눈의 움직임을 추적하기 위한 시스템으로서,프로세서, 스캐닝 파이버(fiber) 조립체 및 명령어들을 저장하는 메모리를 포함하고, 상기 명령어들은 상기 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 근안 디스플레이에서 눈의 움직임을 추적하기 위해 제1 항 내지 제13 항 중 어느 한 항에 따른 방법을 수행하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>15. 명령어들을 저장한 비일시적 컴퓨터-판독 가능 매체로서,상기 명령어들은 마이크로프로세서에 의해 실행될 때, 상기 마이크로프로세서로 하여금 근안 디스플레이에서 눈의 움직임을 추적하기 위해 제1 항 내지 제13 항 중 어느 한 항에 따른 방법을 수행하게 하는, 비일시적 컴퓨터-판독 가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 워싱턴주 시애틀 스위트 *** 루즈벨트 웨이 노쓰이스트 ****</address><code>520130302039</code><country>미국</country><engName>UNIVERSITY OF WASHINGTON</engName><name>유니버시티 오브 워싱턴</name></applicantInfo><applicantInfo><address>미국 플로리다 플랜타티온 웨스트 선라이즈 블러바드 **** (우: *****)</address><code>520140046502</code><country>미국</country><engName>MAGIC LEAP, INC.</engName><name>매직 립, 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 워싱턴 시애틀 스위트 ***...</address><code> </code><country> </country><engName>SEIBEL, Eric J.</engName><name>세이벨, 에릭 제이.</name></inventorInfo><inventorInfo><address>미국 ***** 워싱턴 시애틀 스위트 ***...</address><code> </code><country> </country><engName>BRUNTON, Steven L.</engName><name>브런튼, 스티븐 엘.</name></inventorInfo><inventorInfo><address>미국 ***** 워싱턴 시애틀 스위트 ***...</address><code> </code><country> </country><engName>GONG, Chen</engName><name>공, 첸</name></inventorInfo><inventorInfo><address>미국 ***** 플로리다 플랜타티온 웨스...</address><code> </code><country> </country><engName>SCHOWENGERDT, Brian T.</engName><name>쇼웬게르트, 브라이언 티.</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 서소문로**(서소문동, 정안빌딩*층)</address><code>920121001826</code><country>대한민국</country><engName>NAM &amp; NAM</engName><name>특허법인 남앤남</name></agentInfo><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.06.12</priorityApplicationDate><priorityApplicationNumber>63/038,414</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.01.10</receiptDate><receiptNumber>1-1-2023-0035273-43</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2023.01.17</receiptDate><receiptNumber>1-5-2023-0009798-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.01.26</receiptDate><receiptNumber>1-1-2023-0094970-75</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.01.30</receiptDate><receiptNumber>1-5-2023-0016293-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.04.04</receiptDate><receiptNumber>1-1-2024-0374064-59</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2024.04.04</receiptDate><receiptNumber>1-1-2024-0377088-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.06.11</receiptDate><receiptNumber>1-1-2024-0627704-39</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.06.11</receiptDate><receiptNumber>1-1-2024-0627703-94</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[우선심사신청]심사청구서·우선심사신청서</documentName><receiptDate>2024.06.11</receiptDate><receiptNumber>1-1-2024-0627705-85</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2024.10.16</receiptDate><receiptNumber>9-5-2024-0879048-20</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2024.12.13</receiptDate><receiptNumber>1-1-2024-1385832-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.12.13</receiptDate><receiptNumber>1-1-2024-1385833-34</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Decision to Refuse a Patent</documentEngName><documentName>거절결정서</documentName><receiptDate>2025.04.03</receiptDate><receiptNumber>9-5-2025-0330030-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Amendment to Description, etc(Reexamination)</documentEngName><documentName>[명세서등 보정]보정서(재심사)</documentName><receiptDate>2025.06.25</receiptDate><receiptNumber>1-1-2025-0714477-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.06.25</receiptDate><receiptNumber>1-1-2025-0714476-77</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237001121.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bf95bbb81a79cd7e2288c2fa8ca8ef139d4f479962bc76d05baa14085354e95dc804a7af98d568c96de1a31ea9968e247bed20d849e14cd0</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf671ff7ae7342bf82768451a7296ea9a68784996b9b9955ce7f626ec633585047780b42e00b3087f32d96865433efceeea43b98c2daf709f7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>