<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:38:48.3848</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.10.22</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0142133</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>실시간 사람 감지 및 추적 시스템을 위한 전자 장치 및 그 제어 방법</inventionTitle><inventionTitleEng>ELECTRONIC APPARATUS FOR REAL-TIME HUMAN DETECTION  AND TRACKING SYSTEM AND CONTROLLING METHOD THEREOF</inventionTitleEng><openDate>2023.05.02</openDate><openNumber>10-2023-0057867</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/174</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/136</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/292</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/521</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 7/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치가 개시된다. 전자 장치는 컬러(color) 이미지를 획득하는 제1 센서, 뎁스(depth) 이미지를 획득하는 제2 센서, 신경망 모델을 저장하는 메모리 및 제1 센서로부터 제1 컬러 이미지가 수신되면, 제1 컬러 이미지를 신경망 모델에 입력하여 제1 관심 영역을 획득하고, 제1 관심 영역에 포함된 오브젝트 및 전자 장치 간 거리가 임계 거리 미만인지 여부를 식별하는 프로세서를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 있어서,컬러(color) 이미지를 획득하는 제1 센서;뎁스(depth) 이미지를 획득하는 제2 센서;신경망 모델을 저장하는 메모리; 및상기 제1 센서로부터 제1 컬러 이미지가 수신되면, 상기 제1 컬러 이미지를 상기 신경망 모델에 입력하여 제1 관심 영역을 획득하고,상기 제1 관심 영역에 포함된 오브젝트 및 상기 전자 장치 간 거리가 임계 거리 미만인지 여부를 식별하는 프로세서;를 포함하며,상기 프로세서는,상기 식별된 거리가 상기 임계 거리 미만이면, 상기 제1 컬러 이미지에 대응되는 제1 뎁스 이미지에 포함된 복수의 픽셀 중 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제1 영역을 식별하고,상기 제1 관심 영역 및 상기 제1 영역 간 인터섹션(intersection) 정보를 획득하고,상기 획득된 인터섹션(intersection) 정보가 임계 값 이상이면, 상기 제1 영역이 상기 오브젝트를 포함하는 것으로 식별하는, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 프로세서는,상기 제2 센서로부터 수신된 제2 컬러 이미지에 대응되는 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제2 영역을 식별하고, 상기 제1 영역 및 상기 제2 영역 간 인터섹션 정보를 획득하고,상기 획득된 인터섹션 정보가 상기 임계 값 이상이면, 상기 제2 영역이 상기 오브젝트를 포함하는 것으로 식별하고, 상기 제1 영역 및 상기 제2 영역에 기초하여 상기 오브젝트의 위치를 트랙킹하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 프로세서는,상기 획득된 인터섹션 정보가 상기 임계 값 이상이면, 상기 제1 관심 영역 및 상기 제1 영역이 병합된 제1 병합 영역을 획득하고,상기 제2 센서로부터 수신된 제2 컬러 이미지에 대응되는 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제2 영역을 식별하고, 상기 제1 병합 영역 및 상기 제2 영역 간 인터섹션 정보를 획득하고,상기 획득된 인터섹션 정보가 상기 임계 값 이상이면, 상기 제2 영역이 상기 오브젝트를 포함하는 것으로 식별하고, 상기 제1 병합 영역 및 상기 제2 영역에 기초하여 상기 오브젝트의 위치를 트랙킹하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 프로세서는,상기 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들의 비율이 임계 비율 이상이면, 상기 제2 뎁스 이미지에 포함된 복수의 픽셀 중 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 상기 제2 영역을 식별하는, 전자 장치. </claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 프로세서는,상기 제1 센서로부터 수신된 제2 컬러 이미지를 상기 신경망 모델에 입력하고, 상기 신경망 모델의 출력에 기초하여 상기 제2 컬러 이미지에서 관심 영역이 식별되지 않는 경우, 상기 제2 컬러 이미지에 대응되는 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 상기 제2 영역을 식별하는, 전자 장치.  </claim></claimInfo><claimInfo><claim>6. 제2항에 있어서,상기 프로세서는,상기 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들의 비율이 임계 비율 미만이면, 상기 제2 컬러 이미지를 상기 신경망 모델에 입력하여 상기 오브젝트를 포함하는 제2 관심 영역을 획득하고, 상기 제2 관심 영역에 포함된 오브젝트 및 상기 전자 장치 간 거리가 임계 거리 미만인지 여부를 식별하고, 상기 식별된 거리가 상기 임계 거리 미만이면, 상기 제2 뎁스 이미지에 포함된 복수의 픽셀 중 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제2 영역을 식별하고,상기 제2 관심 영역 및 상기 제2 영역 간 인터섹션 정보를 획득하고,상기 획득된 인터섹션 정보가 임계 값 이상이면, 상기 제2 영역이 상기 오브젝트를 포함하는 것으로 식별하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 프로세서는,상기 식별된 거리가 상기 임계 거리 이상이면, 상기 제1 관심 영역, 상기 제1 영역 및 상기 제2 관심 영역에 기초하여 상기 오브젝트의 위치를 트랙킹하는, 전자 장치. </claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 프로세서는,상기 식별된 거리가 상기 임계 거리 이상이면, 상기 제1 관심 영역에 기초하여 상기 오브젝트의 위치를 식별하는, 전자 장치. </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 센서는,카메라 또는 RGB 컬러 센서 중 적어도 하나를 포함하고, 상기 제2 센서는,Stereo vision 센서, ToF 센서 또는 라이다 센서(LiDAR) 중 적어도 하나를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 전자 장치의 제어 방법에 있어서,제1 센서로부터 제1 컬러 이미지가 수신되면, 상기 제1 컬러 이미지를 신경망 모델에 입력하여 제1 관심 영역을 획득하는 단계; 및상기 제1 관심 영역에 포함된 오브젝트 및 상기 전자 장치 간 거리가 임계 거리 미만인지 여부를 식별하는 단계;를 포함하며,상기 식별하는 단계는,상기 식별된 거리가 상기 임계 거리 미만이면, 상기 제1 컬러 이미지에 대응되는 제1 뎁스 이미지에 포함된 복수의 픽셀 중 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제1 영역을 식별하는 단계;상기 제1 관심 영역 및 상기 제1 영역 간 인터섹션(intersection) 정보를 획득하는 단계; 및상기 획득된 인터섹션 정보가 임계 값 이상이면, 상기 제1 영역이 상기 오브젝트를 포함하는 것으로 식별하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 제2 센서로부터 수신된 제2 컬러 이미지에 대응되는 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제2 영역을 식별하는 단계;상기 제1 영역 및 상기 제2 영역 간 인터섹션 정보를 획득하는 단계;상기 획득된 인터섹션 정보가 상기 임계 값 이상이면, 상기 제2 영역이 상기 오브젝트를 포함하는 것으로 식별하는 단계; 및상기 제1 영역 및 상기 제2 영역에 기초하여 상기 오브젝트의 위치를 트랙킹(tracking)하는 단계;를 더 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서,상기 획득된 인터섹션 정보가 상기 임계 값 이상이면, 상기 제1 관심 영역 및 상기 제1 영역이 병합된 제1 병합 영역을 획득하는 단계;상기 제2 센서로부터 수신된 제2 컬러 이미지에 대응되는 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제2 영역을 식별하는 단계;상기 제1 병합 영역 및 상기 제2 영역 간 인터섹션 정보를 획득하는 단계;상기 획득된 인터섹션 정보가 상기 임계 값 이상이면, 상기 제2 영역이 상기 오브젝트를 포함하는 것으로 식별하는 단계; 및상기 제1 병합 영역 및 상기 제2 영역에 기초하여 상기 오브젝트의 위치를 트랙킹하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 제2 영역을 식별하는 단계는,상기 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들의 비율이 임계 비율 이상이면, 상기 제2 뎁스 이미지에 포함된 복수의 픽셀 중 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 상기 제2 영역을 식별하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서,상기 제1 센서로부터 수신된 제2 컬러 이미지를 상기 신경망 모델에 입력하는 단계;를 더 포함하고,상기 제2 영역을 식별하는 단계는, 상기 신경망 모델의 출력에 기초하여 상기 제2 컬러 이미지에서 관심 영역이 식별되지 않는 경우, 상기 제2 컬러 이미지에 대응되는 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 상기 제2 영역을 식별하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서,상기 제2 뎁스 이미지에서 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들의 비율이 임계 비율 미만이면, 상기 제2 컬러 이미지를 상기 신경망 모델에 입력하여 상기 오브젝트를 포함하는 제2 관심 영역을 획득하는 단계; 및상기 제2 관심 영역에 포함된 오브젝트 및 상기 전자 장치 간 거리가 임계 거리 미만인지 여부를 식별하는 단계;를 더 포함하고,상기 제2 영역을 식별하는 단계는,상기 식별된 거리가 상기 임계 거리 미만이면, 상기 제2 뎁스 이미지에 포함된 복수의 픽셀 중 상기 임계 거리 미만의 뎁스 정보를 포함하는 픽셀들을 포함하는 제2 영역을 식별하는 단계;를 포함하고,상기 제2 관심 영역 및 상기 제2 영역 간 인터섹션 정보를 획득하는 단계; 및상기 획득된 인터섹션 정보가 임계 값 이상이면, 상기 제2 영역이 상기 오브젝트를 포함하는 것으로 식별하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 트랙킹하는 단계는,상기 식별된 거리가 상기 임계 거리 이상이면, 상기 제1 관심 영역, 상기 제1 영역 및 상기 제2 관심 영역에 기초하여 상기 오브젝트의 위치를 트랙킹하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서, 상기 식별된 거리가 상기 임계 거리 이상이면, 상기 제1 관심 영역에 기초하여 상기 오브젝트의 위치를 식별하는 단계;를 더 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 제1 센서는,카메라 또는 RGB 컬러 센서 중 적어도 하나를 포함하고,상기 제2 센서는,Stereo vision 센서, ToF 센서 또는 라이다 센서(LiDAR) 중 적어도 하나를 포함하는, 제어 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LIM, Yu Sun</engName><name>임유선</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.10.22</receiptDate><receiptNumber>1-1-2021-1216020-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.10.17</receiptDate><receiptNumber>1-1-2024-1128105-19</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210142133.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93cd0772a3f16193c41b62ee3d33611f89174e62c46d75f52dd92b9a568337648f9d04f391a58fa88e671dfff2e815dbfacec0841f626bc260</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf40e2d19f28431e423b571b4e3dbb1755ed6dca2872a028e2625160a937cfd91fc112fcce7aac2fc061aef9b620246d76a9af26b1a3f50950</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>