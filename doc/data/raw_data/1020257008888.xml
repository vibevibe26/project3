<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:29:51.2951</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.08.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7008888</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>기판 결함 검출 및 비교</inventionTitle><inventionTitleEng>SUBSTRATE DEFECT-DETECTION AND COMPARISON</inventionTitleEng><openDate>2025.04.17</openDate><openNumber>10-2025-0051735</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.18</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.18</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01N 21/88</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4046</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 명세서에 설명된 다양한 예들은 기판들 상의 특징부들의 결함 검출 및 비교를 위해 사용되는 이미지 데이터의 이미지 프로세싱 태스크들을 포함한다. 딥-convnet 기반 및 트랜스포머 기반 백본 네트워크(공통 백본) 중 적어도 하나는, 다양한 타입들의 원시 이미지 데이터를 특징부들로 변환하도록 배열되며, 특징부들은 결국, 특정 태스크들의 최종 계산들을 수행하기 위해 더 작은 뉴럴 네트워크들에 의해 사용될 수 있다. 더 작은 뉴럴 네트워크들은, 예를 들어, 제조 설비에서의 최종 결함 검출들, 다이-대-다이 이미지 비교들, 이상 검출, 및 고객-특정 태스크들을 수행한다. 공통 백본 네트워크는 초기에 원시 이미지 데이터에 기초한 자기 지도 학습을 사용하여 트레이닝될 수 있고, 이어서 전이 학습이 태스크-특정 네트워크들의 최종 애플리케이션을 트레이닝하는 데 사용될 수 있다. 다른 시스템들 및 방법들이 또한 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.02.22</internationOpenDate><internationOpenNumber>WO2024039785</internationOpenNumber><internationalApplicationDate>2023.08.17</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/030475</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 제조 설비에서 비교 데이터를 제공하기 위한 시스템으로서, 상기 시스템은머신 학습 기반 네트워크에 기초한 공통 백본 네트워크를 포함하고, 상기 공통 백본 네트워크는,원시(raw) 이미지 데이터를 수신하기 위한 입력 컴포넌트;상기 원시 이미지 데이터로부터 머신 학습 기반 비교 데이터베이스를 생성하기 위한 자기 지도(self-supervised) 트레이닝 컴포넌트; 및상기 공통 백본 네트워크에 전자적으로 커플링된 복수의 태스크-특정 네트워크들로부터 수신된 이미지들의 이상(anomaly) 검출 및 분류를 수행하기 위한 분석 엔진 - 상기 복수의 태스크-특정 네트워크들 각각은 적어도 하나의 타입의 장비에 커플링되고, 상기 분석 엔진은 상기 원시 이미지 데이터를 특징부들로 변환하기 위한 것이며, 상기 특징부들은 상기 제조 설비 내의 특정 태스크들의 최종 계산들을 수행하기 위해 상기 복수의 태스크-특정 네트워크들로 송신됨 - 을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 원시 이미지 데이터는 획득된 이미지들 및 기준 이미지들을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 기준 이미지들은 CAD 기반 기준 이미지들 및 기준 다이 이미지들을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 공통 백본 네트워크는 이미지 특징부들을 추출하도록 그리고 상기 이미지 특징부들을 입력 데이터 컴포넌트에 제공되는 이미지 데이터에 대해 정렬 및 크기조정하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 이미지 특징부들은 상기 제조 설비 내의 결함들을 결정하기 위해 상기 복수의 태스크-특정 네트워크들로 송신되는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 원시 이미지 데이터의 각각의 컴포넌트를 라벨링할 필요 없이 상기 원시 이미지 데이터가 백본 네트워크를 트레이닝하는 데 사용될 수 있는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 분석 엔진은 상기 복수의 태스크-특정 네트워크들로부터 수신된 이미지들을, 상기 원시 이미지 데이터로부터 생성된 상기 머신 학습 기반 비교 데이터베이스 내의 이미지들 중 관련 이미지들과 비교하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 머신 학습 기반 네트워크는 콘볼루션 뉴럴 네트워크(convolutional-neural network, convnet) 및 트랜스포머 기반 네트워크 중 적어도 하나에 기초하는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제조 설비 내의 결함들을 카테고리화하기 위한 이미지 프로세싱 시스템으로서, 상기 이미지 프로세싱 시스템은머신 학습 기반 네트워크에 기초한 공통 백본 네트워크; 및상기 공통 백본 네트워크에 전자적으로 커플링된 복수의 태스크-특정 네트워크들 - 상기 복수의 태스크-특정 네트워크들 각각은 상기 공통 백본 네트워크와는 별개인 머신 학습 기반 네트워크에 기초하고, 상기 복수의 태스크-특정 네트워크들 각각은 상기 제조 설비 내의 특정 태스크에 대해 트레이닝되도록 구성됨 - 을 포함하는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 공통 백본 네트워크는,원시 이미지 데이터를 수신하기 위한 입력 컴포넌트;상기 원시 이미지 데이터로부터 머신 학습 기반 비교 데이터베이스를 생성하기 위한 자기 지도 트레이닝 컴포넌트; 및상기 복수의 태스크-특정 네트워크들로부터 수신된 이미지들의 이상 검출 및 분류를 수행하기 위한 분석 엔진 - 상기 분석 엔진은 상기 원시 이미지 데이터를 특징부들로 변환하기 위한 것이며, 상기 특징부들은 상기 제조 설비 내의 특정 태스크들의 최종 계산들을 수행하기 위해 상기 복수의 태스크-특정 네트워크들로 송신됨 - 을 포함하는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 머신 학습 기반 비교 데이터베이스는 콘볼루션 뉴럴 네트워크(convnet) 및 트랜스포머 기반 네트워크 중 적어도 하나에 기초하는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 분석 엔진은 상기 복수의 태스크-특정 네트워크들로부터 수신된 이미지들을, 상기 원시 이미지 데이터로부터 생성된 상기 머신 학습 기반 비교 데이터베이스 내의 이미지들 중 관련 이미지들과 비교하도록 추가로 구성되는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 복수의 태스크-특정 네트워크들 각각은 상기 공통 백본 네트워크의 상기 분석 엔진으로부터 수신된 상기 특징부들에 기초하여 결함 검출 및 다이-대-다이 비교들의 동작들을 수행하도록 구성되는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>14. 제9항에 있어서, 상기 복수의 태스크-특정 네트워크들 각각은, 계측 툴 및 검사 툴을 포함하는 적어도 하나의 타입의 장비에 커플링되고 그로부터 데이터를 수집하는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>15. 제9항에 있어서, 상기 복수의 태스크-특정 네트워크들 각각은 사전결정된 허용오차(tolerance) 값에 기초하여 특정 프로세스에 대한 정규 프로세스 변형들을 무시하도록 트레이닝되는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>16. 제9항에 있어서, 상기 복수의 태스크-특정 네트워크들 각각은 특정 프로세스에 대한 태스크-특정 레시피들로 맞춤화되는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>17. 제9항에 있어서, 상기 머신 학습 기반 네트워크들 각각은 콘볼루션 뉴럴 네트워크(convnet) 및 트랜스포머 기반 네트워크 중 적어도 하나에 기초하는, 이미지 프로세싱 시스템.</claim></claimInfo><claimInfo><claim>18. 제조 설비에서 데이터를 비교하기 위한 방법으로서, 상기 방법은머신 학습 기반 네트워크에 기초한 공통 백본 네트워크에 대한 입력들로서 원시 이미지 데이터를 수신하는 단계;자기 지도 트레이닝을 사용하여 상기 원시 이미지 데이터로부터 머신 학습 기반 비교 데이터베이스를 생성하는 단계;상기 공통 백본 네트워크에 전자적으로 커플링된 복수의 태스크-특정 네트워크들로부터 수신된 이미지들의 이상 검출 및 분류를 수행하는 단계; 및상기 원시 이미지 데이터를 특징부들로 변환하고 상기 특징부들을 상기 복수의 태스크-특정 네트워크들로 송신하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 특징부들에 기초하여 상기 제조 설비 내의 특정 태스크들의 최종 계산들을 수행하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서, 전이 학습을 사용하여 상기 복수의 태스크-특정 네트워크들 각각에 대한 최종 애플리케이션을 트레이닝하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제18항에 있어서,이미지 특징부들을 추출하는 단계; 및상기 이미지 특징부들을, 상기 공통 백본 네트워크 내의 상기 원시 이미지 데이터로부터의 공통 좌표계에 대해 정렬 및 크기조정하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제18항에 있어서, 상기 복수의 태스크-특정 네트워크들로부터 수신된 이미지들을, 상기 원시 이미지 데이터로부터 생성된 상기 머신 학습 기반 비교 데이터베이스 내의 이미지들 중 관련 이미지들과 비교하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제18항에 있어서, 계측 툴 및 검사 툴을 포함하는 장비 타입으로부터 선택된 적어도 하나의 타입의 장비로부터 상기 복수의 태스크-특정 네트워크들 중 적어도 하나로부터의 상기 이미지들을 수신하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 제18항에 있어서, 상기 머신 학습 기반 네트워크는 콘볼루션 뉴럴 네트워크(convnet) 및 트랜스포머 기반 네트워크 중 적어도 하나에 기초하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 매사추세츠 ***** 윌밍톤 존스핀 로드 **</address><code>520200273649</code><country>미국</country><engName>ONTO INNOVATION, INC.</engName><name>온투 이노베이션 아이엔씨.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 매사...</address><code> </code><country>미국</country><engName>REMILLARD, Jason Paul</engName><name>레밀라드, 제이슨 폴</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.18</priorityApplicationDate><priorityApplicationNumber>63/371,806</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.18</receiptDate><receiptNumber>1-1-2025-0306228-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.03.21</receiptDate><receiptNumber>1-5-2025-0047988-67</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257008888.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9322c558d239100025cda84aee53231378f717cc18eba8770ab838729619223119cb7ff71824f68fb3012a0a07333f12a42a2047733ea2dde4</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6fd517dc0b648a7c0210011f696047d0acb50606ea902d6e13fc8e57cc1ac6019162387e30b50c8222445cc9985f9a9d7853069f98610788</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>