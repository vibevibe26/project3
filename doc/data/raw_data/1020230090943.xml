<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:50.4150</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0090943</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>카메라의 정보를 이용하여 이미지와 관련된 외부 객체의 위치를 식별하기 위한 전자 장치 및 그 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE FOR IDENTIFYING POSITION OF EXTERNAL  OBJECT ASSOCIATED WITH IMAGE BY USING INFORMATION  OF CAMERA AND METHOD THEREOF</inventionTitleEng><openDate>2024.02.06</openDate><openNumber>10-2024-0016886</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시 예에 따른, 전자 장치(electronic device)는, 카메라 및 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 카메라를 이용하여 획득된 이미지로부터, 외부 객체와 관련된 부분의 꼭짓점들(vertices)을 나타내는 2차원 좌표 값들을 획득하도록, 구성될 수 있다. 상기 프로세서는, 상기 이미지에 포함된 기준 평면 상에서 기준 방향을 따라 연장되고, 상기 꼭짓점들 중 제1 꼭짓점과 중첩된 제1 라인 및 상기 이미지 내 기준점 및 상기 꼭짓점들 중 제2 꼭짓점을 연결하는 제2 라인을 식별하도록, 구성될 수 있다. 상기 프로세서는, 상기 제1 라인 및 상기 제2 라인의 교차점(intersection)에 기반하여, 상기 외부 객체에 대응하는 3차원 외부 공간의 꼭짓점들 각각을 나타내는 3차원 좌표 값들을 획득하도록, 구성될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치(electronic device)에 있어서,  카메라; 및  프로세서를 포함하고;  상기 프로세서는,  상기 카메라를 이용하여 획득된 이미지로부터, 외부 객체와 관련된 부분의 꼭짓점들(vertices)을 나타내는 2차원 좌표 값들을 획득하고;상기 이미지에 포함된 기준 평면 상에서 기준 방향을 따라 연장되고, 상기 꼭짓점들 중 제1 꼭짓점과 중첩된 제1 라인 및 상기 이미지 내 기준점 및 상기 꼭짓점들 중 제2 꼭짓점을 연결하는 제2 라인을 식별하고;상기 제1 라인 및 상기 제2 라인의 교차점(intersection)에 기반하여, 상기 외부 객체에 대응하는 3차원 외부 공간의 꼭짓점들 각각을 나타내는 3차원 좌표 값들을 획득하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서, 상기 프로세서는,상기 부분의 꼭짓점들 중 제3 꼭짓점 및 상기 교차점에 대응하는 2차원 지점을 연결하는 제3 라인을 식별하고;상기 제1 꼭짓점 및 상기 제2 꼭짓점을 연결하는 제4 라인 및 상기 제3 라인의 교차점을 식별하고;상기 제4 라인 및 상기 제3 라인의 상기 교차점에 대한 역투영을 수행하여 식별된, 3차원 지점을, 상기 외부 객체에 대응하는 상기 외부 공간의 상기 꼭짓점들 중 어느 한 꼭짓점으로 결정하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>3. 청구항 2에 있어서, 상기 프로세서는,상기 3차원 지점으로부터 상기 기준 방향을 따라 연장된 제5 라인 및 상기 제1 꼭짓점 및 상기 부분의 꼭짓점들 중 제4 꼭짓점을 연결하는 제6 라인의 교차점에 대응하는 3차원 지점을, 상기 외부 공간의 상기 꼭짓점들 중 다른 한 꼭짓점으로 결정하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>4. 청구항 2에 있어서, 상기 프로세서는,상기 3차원 지점으로부터 상기 기준 방향에 수직인 다른 방향을 따라 연장된 제7 라인 및 상기 제2 꼭짓점 및 상기 제3 꼭짓점을 연결하는 제8 라인의 교차점에 대응하는 3차원 지점을, 상기 외부 공간의 상기 꼭짓점들 중 다른 한 꼭짓점으로 결정하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>5. 청구항 1에 있어서, 상기 프로세서는,객체 인식을 위해 트레이닝된 뉴럴 네트워크를 이용하여, 상기 2차원 좌표 값들을 획득하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>6. 청구항 1에 있어서, 상기 프로세서는,상기 카메라에 대한 내재적 파라미터(intrinsic parameter)를 이용하여, 상기 이미지에 포함되고, 상기 카메라의 렌즈에 의해 야기된, 왜곡을 보상하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>7. 청구항 6에 있어서, 상기 프로세서는,상기 왜곡이 보상된 이미지 내 상기 부분에 대한 상기 2차원 좌표 값들을 획득하도록, 구성된,전자 장치.</claim></claimInfo><claimInfo><claim>8. 전자 장치의 방법에 있어서,상기 전자 장치의 카메라를 이용하여 획득된 이미지로부터, 외부 객체와 관련된 부분의 꼭짓점들을 나타내는 2차원 좌표 값들을 획득하는 동작;상기 이미지에 포함된 기준 평면 상에서 기준 방향을 따라 연장되고, 상기 꼭짓점들 중 제1 꼭짓점과 중첩된 제1 라인 및 상기 이미지 내 기준점 및 상기 꼭짓점들 중 제2 꼭짓점을 연결하는 제2 라인을 식별하는 동작;상기 제1 라인 및 상기 제2 라인의 교차점에 기반하여, 상기 외부 객체에 대응하는 3차원 외부 공간의 꼭짓점들 각각을 나타내는 3차원 좌표 값들을 획득하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 청구항 8에 있어서, 상기 3차원 좌표 값들을 획득하는 동작은,상기 부분의 꼭짓점들 중 제3 꼭짓점 및 상기 교차점에 대응하는 2차원 지점을 연결하는 제3 라인을 식별하는 동작;상기 제1 꼭짓점 및 상기 제2 꼭짓점을 연결하는 제4 라인 및 상기 제3 라인의 교차점을 식별하는 동작;상기 제4 라인 및 상기 제3 라인의 상기 교차점에 대한 역투영을 수행하여 식별된, 3차원 지점을, 상기 외부 객체에 대응하는 상기 외부 공간의 상기 꼭짓점들 중 어느 한 꼭짓점으로 결정하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 청구항 9에 있어서, 상기 3차원 좌표 값들을 획득하는 동작은,상기 3차원 지점으로부터 상기 기준 방향을 따라 연장된 제5 라인 및 상기 제1 꼭짓점 및 상기 부분의 꼭짓점들 중 제4 꼭짓점을 연결하는 제6 라인의 교차점에 대응하는 3차원 지점을, 상기 외부 공간의 상기 꼭짓점들 중 다른 한 꼭짓점으로 결정하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>11. 청구항 9에 있어서, 상기 3차원 좌표 값들을 획득하는 동작은,상기 3차원 지점으로부터 상기 기준 방향에 수직인 다른 방향을 따라 연장된 제7 라인 및 상기 제2 꼭짓점 및 상기 제3 꼭짓점을 연결하는 제8 라인의 교차점에 대응하는 3차원 지점을, 상기 외부 공간의 상기 꼭짓점들 중 다른 한 꼭짓점으로 결정하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 청구항 8에 있어서, 상기 2차원 좌표 값들을 획득하는 동작은,객체 인식을 위해 트레이닝된 뉴럴 네트워크를 이용하여, 상기 2차원 좌표 값들을 획득하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>13. 청구항 8에 있어서,상기 카메라에 대한 내재적 파라미터(intrinsic parameter)를 이용하여, 상기 이미지에 포함되고, 상기 카메라의 렌즈에 의해 야기된, 왜곡을 보상하는 동작을 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>14. 청구항 13에 있어서, 상기 2차원 좌표 값들을 획득하는 동작은,상기 왜곡이 보상된 이미지 내 상기 부분에 대한 상기 2차원 좌표 값들을 획득하는 동작을 포함하는,방법.</claim></claimInfo><claimInfo><claim>15. 인스트럭션들을 포함하는 컴퓨터 판독 가능 저장 매체에 있어서, 상기 인스트럭션들은, 전자 장치의 프로세서에 의해 실행될 때에,상기 전자 장치의 카메라를 이용하여 획득된 이미지로부터, 외부 객체와 관련된 부분의 꼭짓점들을 나타내는 2차원 좌표 값들을 획득하고;상기 이미지에 포함된 기준 평면 상에서 기준 방향을 따라 연장되고, 상기 꼭짓점들 중 제1 꼭짓점과 중첩된 제1 라인 및 상기 이미지 내 기준점 및 상기 꼭짓점들 중 제2 꼭짓점을 연결하는 제2 라인을 식별하고;상기 제1 라인 및 상기 제2 라인의 교차점에 기반하여, 상기 외부 객체에 대응하는 3차원 외부 공간의 꼭짓점들 각각을 나타내는 3차원 좌표 값들을 획득하도록, 상기 전자 장치를 야기하는,컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>16. 청구항 15에 있어서, 상기 인스트럭션들은, 전자 장치의 프로세서에 의해 실행될 때에,상기 부분의 꼭짓점들 중 제3 꼭짓점 및 상기 교차점에 대응하는 2차원 지점을 연결하는 제3 라인을 식별하고;상기 제1 꼭짓점 및 상기 제2 꼭짓점을 연결하는 제4 라인 및 상기 제3 라인의 교차점을 식별하고;상기 제4 라인 및 상기 제3 라인의 상기 교차점에 대한 역투영을 수행하여 식별된, 3차원 지점을, 상기 외부 객체에 대응하는 상기 외부 공간의 상기 꼭짓점들 중 어느 한 꼭짓점으로 결정하도록, 상기 전자 장치를 야기하는,컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>17. 청구항 16에 있어서, 상기 인스트럭션들은, 전자 장치의 프로세서에 의해 실행될 때에,상기 3차원 지점으로부터 상기 기준 방향을 따라 연장된 제5 라인 및 상기 제1 꼭짓점 및 상기 부분의 꼭짓점들 중 제4 꼭짓점을 연결하는 제6 라인의 교차점에 대응하는 3차원 지점을, 상기 외부 공간의 상기 꼭짓점들 중 다른 한 꼭짓점으로 결정하도록, 상기 전자 장치를 야기하는,컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>18. 청구항 16에 있어서, 상기 인스트럭션들은, 전자 장치의 프로세서에 의해 실행될 때에,상기 3차원 지점으로부터 상기 기준 방향에 수직인 다른 방향을 따라 연장된 제7 라인 및 상기 제2 꼭짓점 및 상기 제3 꼭짓점을 연결하는 제8 라인의 교차점에 대응하는 3차원 지점을, 상기 외부 공간의 상기 꼭짓점들 중 다른 한 꼭짓점으로 결정하도록, 상기 전자 장치를 야기하는,컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>19. 청구항 15에 있어서, 상기 인스트럭션들은, 전자 장치의 프로세서에 의해 실행될 때에,객체 인식을 위해 트레이닝된 뉴럴 네트워크를 이용하여, 상기 2차원 좌표 값들을 획득하도록, 상기 전자 장치를 야기하는,컴퓨터 판독 가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 청구항 15에 있어서, 상기 인스트럭션들은, 전자 장치의 프로세서에 의해 실행될 때에,상기 카메라에 대한 내재적 파라미터(intrinsic parameter)를 이용하여, 상기 이미지에 포함되고, 상기 카메라의 렌즈에 의해 야기된, 왜곡을 보상하도록, 상기 전자 장치를 야기하는,컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>119990173084</code><country>대한민국</country><engName>THINKWARE CORPORATION</engName><name>팅크웨어(주)</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>Sukpil KO</engName><name>고석필</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구  논현로**길  **, *층, *층 (도곡동, 덕영빌딩)</address><code>920191001617</code><country>대한민국</country><engName>KWANG AND JANG PATENT LAW FIRM</engName><name>특허법인광앤장</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.07.29</priorityApplicationDate><priorityApplicationNumber>1020220094678</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.07.13</receiptDate><receiptNumber>1-1-2023-0771517-52</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230090943.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93620fc635aa7be36b81dd7ab1b38739709036f4e52d843d7b5a64b50765c3b4aa0aab7241769685f16efed970f4f7279bdc39aff286b76a70</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfdcb19a5a772fd2b3c6d4a21cbb6a4b5a47a32d7bd97c4d8a6856514ae9c7650b885cf026bb32dfbbd59d8514233d247c260a5a7037ed4d63</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>