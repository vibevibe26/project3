<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:21.5121</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7023018</applicationNumber><claimCount>21</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>멀티-SOC 손 추적 플랫폼</inventionTitle><inventionTitleEng>MULTI-SOC HAND-TRACKING PLATFORM</inventionTitleEng><openDate>2025.08.01</openDate><openNumber>10-2025-0116764</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.07.09</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/03</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/94</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 멀티-시스템 온 칩(SoC) 손 추적 플랫폼이 제공된다. 멀티-SoC 손 추적 플랫폼은 컴퓨터 비전 SoC와 하나 이상의 애플리케이션 SoC를 포함한다. 컴퓨터 비전 SoC는 손 추적 입력 파이프라인을 호스팅한다. 하나 이상의 애플리케이션 SoC는 손 추적 입력 파이프라인에 의해 생성된 입력 이벤트 데이터의 소비자들인 하나 이상의 애플리케이션을 호스팅한다. 애플리케이션들은 공유 메모리 버퍼를 사용하여 손 추적 입력 파이프라인의 일부 컴포넌트들과 통신하고, IPC(Inter-Process Communication) 메소드 호출들을 사용하여 손 추적 입력 파이프라인의 일부 컴포넌트들과 통신한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.06.13</internationOpenDate><internationOpenNumber>WO2024123693</internationOpenNumber><internationalApplicationDate>2023.12.04</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/082328</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 시스템으로서,제1 시스템 온 칩(System on Chip, SoC); 및제2 SoC를 포함하고,상기 제1 SoC는: 제1 하나 이상의 프로세서; 및 상기 제1 하나 이상의 프로세서에 의해 실행될 때, 상기 제1 SoC로 하여금 증강 현실(Augmented Reality, AR) 시스템의 손 추적 입력 파이프라인의 동작들을 수행하게 하는 제1 명령어들을 저장한 제1 메모리를 포함하고, 상기 손 추적 입력 파이프라인의 동작들은:  상기 손 추적 입력 파이프라인의 카메라 컴포넌트를 사용하여 상기 AR 시스템의 사용자에 의해 행해지는 손 움직임들에 기초하여 현실 세계 장면 환경 프레임 데이터를 생성하는 것;  상기 현실 세계 장면 환경 프레임 데이터에 기초하여 제스처 입력 이벤트 데이터를 생성하는 것; 및  상기 제스처 입력 이벤트 데이터를 상기 AR 시스템의 컴포넌트에 통신하는 것을 포함하고;상기 제2 SoC는: 제2 하나 이상의 프로세서; 및 상기 제2 하나 이상의 프로세서에 의해 실행될 때, 상기 제2 SoC로 하여금 상기 AR 시스템의 컴포넌트의 동작들을 수행하게 하는 제2 명령어들을 저장한 제2 메모리를 포함하고, 상기 AR 시스템의 컴포넌트의 동작들은:  상기 제스처 입력 이벤트 데이터를 수신하는 것; 및  상기 제스처 입력 이벤트 데이터를 사용자 입력 데이터로서 활용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 AR 시스템의 컴포넌트와 손 추적 입력 파이프라인은 IPC(Inter-Process Communication) 프로토콜을 통해 통신하는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 제1 하나 이상의 프로세서에 의해 실행될 때, 상기 제1 SoC로 하여금 상기 손 추적 입력 파이프라인의 동작들을 수행하게 하는 제1 명령어들은, 추가로 상기 제1 SoC로 하여금:상기 현실 세계 장면 환경 프레임 데이터에 기초하여 골격 모델 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 제1 하나 이상의 프로세서에 의해 실행될 때, 상기 제1 SoC로 하여금 상기 손 추적 입력 파이프라인의 동작들을 수행하게 하는 제1 명령어들은, 추가로 상기 제1 SoC로 하여금:상기 현실 세계 장면 환경 프레임 데이터에 기초하여 골격 모델 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제1 하나 이상의 프로세서에 의해 실행될 때, 상기 제1 SoC로 하여금 상기 손 추적 입력 파이프라인의 동작들을 수행하게 하는 제1 명령어들은, 추가로 상기 제1 SoC로 하여금:상기 골격 모델 데이터에 기초하여 손 분류기 확률 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 제1 하나 이상의 프로세서에 의해 실행될 때, 상기 제1 SoC로 하여금 상기 손 추적 입력 파이프라인의 동작들을 수행하게 하는 제1 명령어들은, 추가로 상기 제1 SoC로 하여금:상기 손 분류기 확률 데이터에 기초하여 상기 제스처 입력 이벤트 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 AR 시스템은 머리 착용형 디바이스(head-worn device)를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>8. 컴퓨터에 의해 구현되는 방법(computer-implemented method)으로서,제1 시스템 온 칩(SoC)의 제1 하나 이상의 프로세서에 의해, 증강 현실(AR) 시스템의 손 추적 입력 파이프라인의 카메라 컴포넌트를 사용하여 상기 AR 시스템의 사용자에 의해 행해지는 손 움직임들에 기초하여 현실 세계 장면 환경 프레임 데이터를 생성하는 단계;상기 AR 시스템의 손 추적 입력 파이프라인에 의해, 상기 제1 하나 이상의 프로세서를 사용하여 상기 현실 세계 장면 환경 프레임 데이터에 기초하여 제스처 입력 이벤트 데이터를 생성하는 단계;상기 AR 시스템의 손 추적 입력 파이프라인에 의해, 상기 제1 하나 이상의 프로세서를 사용하여 상기 제스처 입력 이벤트 데이터를 상기 AR 시스템의 컴포넌트에 통신하는 단계;상기 컴포넌트에 의해, 제2 SoC의 제2 하나 이상의 프로세서를 사용하여 상기 제스처 입력 이벤트 데이터를 수신하는 단계; 및상기 컴포넌트에 의해, 상기 제2 하나 이상의 프로세서를 사용하여 상기 제스처 입력 이벤트 데이터를 사용자 입력 데이터로서 활용하는 단계를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 손 추적 입력 파이프라인과 상기 컴포넌트는 IPC(Inter-Process Communication) 프로토콜을 통해 통신하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 AR 시스템의 손 추적 입력 파이프라인에 의해, 상기 제1 하나 이상의 프로세서를 사용하여 상기 현실 세계 장면 환경 프레임 데이터에 기초하여 골격 모델 데이터를 생성하는 단계를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 AR 시스템의 손 추적 입력 파이프라인에 의해, 상기 제1 하나 이상의 프로세서를 사용하여 상기 현실 세계 장면 환경 프레임 데이터에 기초하여 골격 모델 데이터를 생성하는 단계를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 AR 시스템의 손 추적 입력 파이프라인에 의해, 상기 제1 하나 이상의 프로세서를 사용하여 상기 골격 모델 데이터에 기초하여 손 분류기 확률 데이터를 생성하는 단계를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 AR 시스템의 손 추적 입력 파이프라인에 의해, 상기 제1 하나 이상의 프로세서를 사용하여 상기 손 분류기 확률 데이터에 기초하여 상기 제스처 입력 이벤트 데이터를 생성하는 단계를 추가로 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>14. 제8항에 있어서, 상기 AR 시스템은 머리 착용형 디바이스를 포함하는, 컴퓨터에 의해 구현되는 방법.</claim></claimInfo><claimInfo><claim>15. 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 컴퓨터 판독가능 저장 매체는, 컴퓨터에 의해 실행될 때, 상기 컴퓨터로 하여금 동작들을 수행하게 하는 명령어들을 포함하고, 상기 동작들은:증강 현실(AR) 시스템의 손 추적 입력 파이프라인의 카메라 컴포넌트를 사용하여 상기 AR 시스템의 사용자에 의해 행해지는 손 움직임들에 기초하여 현실 세계 장면 환경 프레임 데이터를 생성하는 것;상기 현실 세계 장면 환경 프레임 데이터에 기초하여 제스처 입력 이벤트 데이터를 생성하는 것; 및상기 제스처 입력 이벤트 데이터를 수신하고 상기 제스처 입력 이벤트 데이터를 사용자 입력 데이터로서 활용하는 상기 AR 시스템의 컴포넌트에 상기 제스처 입력 이벤트 데이터를 통신하는 것을 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 명령어들은, 상기 컴퓨터에 의해 실행될 때, 추가로 상기 컴퓨터로 하여금:상기 제스처 입력 이벤트 데이터를 IPC(Inter-Process Communication) 프로토콜을 통해 상기 컴포넌트에 통신하는 것을 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 명령어들은, 상기 컴퓨터에 의해 실행될 때, 추가로 상기 컴퓨터로 하여금:상기 현실 세계 장면 환경 프레임 데이터에 기초하여 골격 모델 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 명령어들은, 상기 컴퓨터에 의해 실행될 때, 추가로 상기 컴퓨터로 하여금:상기 현실 세계 장면 환경 프레임 데이터에 기초하여 골격 모델 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 명령어들은, 상기 컴퓨터에 의해 실행될 때, 추가로 상기 컴퓨터로 하여금:상기 골격 모델 데이터에 기초하여 손 분류기 확률 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 명령어들은, 상기 컴퓨터에 의해 실행될 때, 추가로 상기 컴퓨터로 하여금:상기 손 분류기 확률 데이터에 기초하여 상기 제스처 입력 이벤트 데이터를 생성하는 것을 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>21. 제15항에 있어서, 상기 AR 시스템은 머리 착용형 디바이스를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>루마니아</country><engName>COCONU, Liviu Marius</engName><name>코코누, 리비우 마리우스</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>COLASCIONE, Daniel</engName><name>콜라시오네, 다니엘</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>캐나다</country><engName>ZARE SEISAN, Farid</engName><name>자레 세이산, 파리드</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>HARRIS, Daniel</engName><name>해리스, 다니엘</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>미국</country><engName>POUNDS, Jennica</engName><name>파운즈, 제니카</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.12.09</priorityApplicationDate><priorityApplicationNumber>18/078,547</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.07.09</receiptDate><receiptNumber>1-1-2025-0774836-06</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.07.15</receiptDate><receiptNumber>1-5-2025-0118613-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257023018.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934719fa4b07931921a65cd5feaa1126b9a1e36eb3f11c0b8b0ab06a9dc4cc73f17e9aa04397eb9ba4b10ce8e1c860ef34b93bfc0927a5cd5c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf79bddb8025c59b6674c8fd0d6e42d169e6958323aa71ac7f7daa1998f092b7a9554a51d51fd188dbf46f994c693271da6bd9302b0abb059e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>