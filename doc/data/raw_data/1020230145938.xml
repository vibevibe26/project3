<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:16.416</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0145938</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>메타 렌즈를 이용하여 획득한 이미지로부터 비전 인식을 수행하는 전자 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>AN ELECTRONIC DEVICE FOR PERFROMING VISION PERCEPTION  FROM THE IMAGE OBTAINED BY META LENS AND A METHOD  FOR OPERATING THE SAME</inventionTitleEng><openDate>2025.05.09</openDate><openNumber>10-2025-0063887</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/55</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/54</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G03B 17/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G02B 1/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/56</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 메타 렌즈를 이용하여 획득된 이미지로부터 비전 인식을 수행하는 전자 장치 및 그 동작 방법을 제공한다. 본 개시의 일 실시예에 따른 전자 장치는 표면에 서로 다른 형태, 높이, 및 넓이를 갖는 복수의 기둥(pillar) 또는 핀으로 구성된 패턴이 형성된 메타 렌즈, 객체로부터 반사되어 메타 렌즈를 투과한 위상 변조된 광을 수신하고, 수신된 광을 전기적 신호로 변환하여 부호화 이미지(coded image)를 획득하는 이미지 센서, 및 인공지능(Artificial Intelligence) 모델에 부호화 이미지를 입력하고, 인공지능 모델을 이용하는 추론을 통해 객체의 인식 결과를 나타내는 라벨(label)을 획득하는 적어도 하나의 프로세서를 포함하고, 상기 인공지능 모델은 RGB 이미지를 메타 렌즈의 광학 특성을 반영한 모델에 입력하여 시뮬레이션 이미지를 획득하고, 시뮬레이션 이미지의 인식 결과 입력된 RGB 이미지의 정답 값(ground truth)을 나타내는 라벨을 출력하도록 학습된(trained) 신경망 모델(neural network model)일 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 표면에 서로 다른 형태, 높이, 및 넓이를 갖는 복수의 기둥(pillar) 또는 핀으로 구성된 패턴이 형성되고, 상기 표면의 패턴을 통해 객체로부터 반사된 광의 위상을 변조하는 광학 특성을 갖는 메타 렌즈(metalens)(110); 객체로부터 반사되어 상기 메타 렌즈(110)를 투과한 위상 변조된 광을 수신하고, 수신된 광을 전기적 신호로 변환하여 부호화 이미지(coded image)를 획득하는 이미지 센서(120); 및인공지능(Artificial Intelligence) 모델에 상기 부호화 이미지를 입력하고, 상기 인공지능 모델(200)을 이용하는 추론(inferencing)을 통해 상기 객체의 인식 결과를 출력하는 적어도 하나의 프로세서(130); 를 포함하고, 상기 인공지능 모델(200)은, RGB 이미지를 상기 메타 렌즈(110)의 광학 특성을 반영한 모델에 입력하여 시뮬레이션 이미지를 획득하고, 상기 획득된 시뮬레이션 이미지의 인식 결과 상기 입력된 RGB 이미지의 정답 값(ground truth)을 나타내는 라벨을 출력하도록 학습된(trained) 신경망 모델(neural network model)이고, 상기 인공지능 모델(200)은 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사 정도를 수치적으로 나타내는 유사도 값을 손실 값(loss)으로 적용하여, 상기 손실 값을 최소화하도록 학습된, 전자 장치(100). </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서, 상기 메타 렌즈(110)의 표면 패턴을 형성하는 상기 복수의 기둥 또는 핀의 형태, 높이, 및 넓이는 상기 인공지능 모델(200)의 학습 결과에 따른 수학적 모델링 파라미터에 기초하여 형성된, 전자 장치(100). </claim></claimInfo><claimInfo><claim>3. 제1 항 또는 제2 항에 있어서, 상기 인공지능 모델(200)은, 상기 메타 렌즈(110)의 광학 특성을 수학적으로 모델링한 점 퍼짐 함수(point spread function)를 상기 RGB 이미지와 컨볼루션(convolution)하여 상기 RGB 이미지로부터 상기 시뮬레이션 이미지를 출력하도록 학습된 제1 인공지능 모델을 포함하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서, 상기 제1 인공지능 모델은,복수의 이미지 간의 유사도를 수치적으로 측정하는 미분 가능한 수학 모델 또는 신경망 알고리즘을 이용하여 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도를 산출하고, 상기 산출된 유사도를 손실 값으로 적용하는 역 전파(back propagation)를 통해 레이어들 간의 가중치들(weights)을 업데이트함으로써 상기 손실 값을 최소화하도록 학습된 심층 신경망 모델(deep neural network)인, 전자 장치(100). </claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서, 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도는 VIF(visual information fidelity), LPIPS(Learned Perceptual Image Patch Similarity), 또는 이들의 조합 중 적어도 하나를 통해 산출되는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>6. 제1 항 내지 제5 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은, 상기 시뮬레이션 이미지가 입력되면, 상기 메타 렌즈(110)의 광학 특성에 의해 왜곡되기 전의 원본 RGB 이미지를 복원(reconstruction)하도록 학습된 제2 인공지능 모델을 더 포함하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서, 상기 제2 인공지능 모델은, 상기 복원된 RGB 이미지와 상기 인공지능 모델에 입력된 상기 원본 RGB 이미지 간의 차이 값의 역수를 손실 값으로 적용하여, 상기 손실 값을 최소화하도록 학습된 심층 신경망 모델인, 전자 장치(100). </claim></claimInfo><claimInfo><claim>8. 제1 항 내지 제7 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은, 상기 입력된 부호화 이미지가 입력되면, 비전 태스크(vision task)의 특성에 따른 인식 결과를 출력하도록 학습된 제3 인공지능 모델을 더 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 제3 인공지능 모델에 상기 부호화 이미지를 입력하고, 상기 제3 인공지능 모델을 이용하는 추론을 통해 비전 태스크의 특성에 따른 인식 결과를 나타내는 라벨을 출력하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>9. 제8 항에 있어서, 상기 제3 인공지능 모델은, 상기 인식 결과로서 출력된 라벨과 상기 인공지능 모델(200)에 입력되는 RGB 이미지와 페어링(pairing)된 정답 값을 나타내는 라벨 간의 차이값을 손실 값으로 적용하고, 상기 손실 값을 최소화하도록 학습된 심층 신경망 모델인, 전자 장치(100). </claim></claimInfo><claimInfo><claim>10. 제1 항 내지 제9 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은, 상기 입력된 부호화 이미지가 입력되면, 상기 부호화 이미지로부터 인식되는 개인 식별 정보(identification information)를 출력하도록 학습된 제4 인공지능 모델을 더 포함하고, 상기 제4 인공지능 모델은, 상기 인식 결과로서 출력된 개인 식별 정보와 상기 인공지능 모델(200)에 입력되는 RGB 이미지와 페어링(pairing)된 정답 값 간의 차이 값을 산출하고, 상기 산출된 차이 값의 역수를 손실 값으로 적용하여 상기 손실 값을 최소화하도록 학습된 심층 신경망 모델인, 전자 장치(100). </claim></claimInfo><claimInfo><claim>11. 제10 항에 있어서, 상기 개인 식별 정보는, 상기 부호화 이미지로부터 인식될 수 있는 성별(gender), 나이, 인종, 피부 색, 머리 색, 또는 눈동자 색 중 적어도 하나를 포함하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>12. 제1 항 내지 제11 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은,사용자에 의한 상기 메타 렌즈(110)의 교체 또는 변경을 인식하는 메타렌즈 프로파일러 모델(metalens profiler)을 더 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 메타렌즈 프로파일러 모델을 통해 상기 메타 렌즈(110)의 교체 또는 변경이 인식된 경우, 교체 또는 변경된 메타 렌즈(110)에 대응되는 비전 태스크를 식별하고, 상기 인공지능 모델(200)에 포함되는 백본 네트워크 및 헤드 네트워크를 상기 식별된 비전 태스크에 최적화된 모델로서 미리 결정된 백본 네트워크 및 헤드 네트워크로 변경하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>13. 제1 항 내지 제12 항 중 어느 하나의 항에 있어서, 객체의 깊이 값을 측정하도록 구성된 깊이 센서(depth sensor)(170); 및 상기 객체로부터 음향 신호를 획득하는 오디오 센서(audio sensor)(180);를 더 포함하고, 상기 적어도 하나의 프로세서(130)는, 상기 깊이 센서(170)에 의해 측정된 상기 객체의 깊이 값 및 상기 오디오 센서(180)에 의해 획득된 상기 음향 신호를 상기 인공지능 모델(200)에 입력하고, 상기 인공지능 모델(200)을 이용하는 추론을 통해 상기 객체의 인식 결과에 따른 라벨을 획득하는, 전자 장치(100). </claim></claimInfo><claimInfo><claim>14. 전자 장치(100)가 메타 렌즈(110)를 통해 획득된 이미지로부터 객체의 인식 결과를 획득하는 방법에 있어서, 객체로부터 반사되어 상기 메타 렌즈(110)를 투과한 위상 변조된 광을 수신하고, 수신된 광을 전기적 신호로 변환하여 부호화 이미지(coded image)를 획득하는 단계(S210); 및인공지능(Artificial Intelligence) 모델에 상기 부호화 이미지를 입력하고, 상기 인공지능 모델(200)을 이용하는 추론을 통해 상기 객체의 인식 결과를 나타내는 라벨(label)을 획득하는 단계(S220);를 포함하고, 상기 인공지능 모델(200)은, RGB 이미지를 상기 메타 렌즈(110)의 광학 특성을 반영한 모델에 입력하여 시뮬레이션 이미지를 획득하고, 상기 획득된 시뮬레이션 이미지의 인식 결과 상기 입력된 RGB 이미지의 정답 값(ground truth)을 나타내는 라벨을 출력하도록 학습된 신경망 모델(neural network model)이고, 상기 인공지능 모델(200)은 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사 정도를 수치적으로 나타내는 유사도 값을 손실 값(loss)으로 적용하여, 상기 손실 값을 최소화하도록 학습된(trained), 방법. </claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서, 상기 인공지능 모델(200)은, 상기 메타 렌즈(110)의 광학 특성을 수학적으로 모델링한 점 퍼짐 함수(point spread function)를 상기 RGB 이미지와 컨볼루션(convolution)하여 상기 RGB 이미지로부터 상기 시뮬레이션 이미지를 출력하도록 학습된 제1 인공지능 모델을 포함하고, 상기 제1 인공지능 모델은,복수의 이미지 간의 유사도를 수치적으로 측정하는 미분 가능한 수학 모델 또는 신경망 알고리즘을 이용하여 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도를 산출하고, 상기 산출된 유사도를 손실 값으로 적용하는 역 전파(back propagation)를 통해 레이어들 간의 가중치들(weights)을 업데이트함으로써 상기 손실 값을 최소화하도록 학습된 심층 신경망 모델(deep neural network)인, 방법. </claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서, 상기 RGB 이미지와 상기 시뮬레이션 이미지 간의 유사도는 VIF(visual information fidelity), LPIPS(Learned Perceptual Image Patch Similarity), 또는 이들의 조합 중 적어도 하나를 통해 산출되는, 방법.  </claim></claimInfo><claimInfo><claim>17. 제14 항 내지 제16 항 중 어느 하나의 항에 있어서, 상기 인공지능 모델(200)은, 상기 입력된 부호화 이미지로부터 특징 맵(feature map)을 추출하도록 학습된 백본 네트워크(backbone network) 및 상기 특징 맵으로부터 상기 부호화 이미지의 인식 결과를 나타내는 라벨을 출력하도록 학습된 헤드 네트워크(head network)를 포함하고, 상기 라벨을 획득하는 단계(S220)는,상기 인공지능 모델(200)을 이용하여 인식하고자 하는 비전 태스크(vision task)의 목적 또는 용도에 기초하여 상기 백본 네트워크 및 상기 헤드 네트워크 중 적어도 하나를 변경하는 단계(S1010); 및상기 백본 네트워크 및 상기 헤드 네트워크 중 적어도 하나가 변경된 상기 인공지능 모델(200)에 상기 부호화 이미지를 입력하여, 상기 부호화 이미지의 인식 결과를 나타내는 라벨을 출력하는 단계(S1020);를 포함하는, 방법,</claim></claimInfo><claimInfo><claim>18. 제14 항 내지 제17 항 중 어느 하나의 항에 있어서, 사용자에 의한 상기 메타 렌즈(110)의 교체 또는 변경을 인식하는 단계(S1310); 상기 교체 또는 변경된 메타 렌즈(110)에 대응되는 비전 태스크를 식별하는 단계(S1320); 및상기 인공지능 모델(200)의 백본 네트워크 및 헤드 네트워크를 상기 식별된 비전 태스크에 최적화된 모델로서 미리 결정된 백본 네트워크 및 헤드 네트워크로 변경하는 단계(S1330);를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제14 항 내지 제18 항 중 어느 하나의 항에 있어서, 깊이 센서(170)로부터 상기 객체의 깊이 값을 획득하는 단계; 및오디오 센서(180)로부터 상기 객체로부터 음향 신호를 획득하는 단계; 를 더 포함하고, 상기 라벨을 획득하는 단계(S220)는,상기 깊이 센서(170)에 의해 측정된 상기 객체의 깊이 값 및 상기 오디오 센서(180)에 의해 획득된 상기 음향 신호를 상기 인공지능 모델(200)에 입력하고, 상기 인공지능 모델(200)을 이용하는 추론을 통해 상기 객체의 인식 결과에 따른 라벨을 획득하는, 방법. </claim></claimInfo><claimInfo><claim>20. 제14 항 내지 제19 항 중 어느 하나의 항에 기재된 방법을 구현하기 위한 적어도 하나의 프로그램이 기록된 컴퓨터로 판독 가능한 기록 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>AN, Sung Kwon</engName><name>안성권</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Bo Mi</engName><name>김보미</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, Jung Min</engName><name>이정민</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JUNG, Hyun Joo</engName><name>정현주</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>CHOI, Kwang Pyo</engName><name>최광표</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.27</receiptDate><receiptNumber>1-1-2023-1187229-43</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230145938.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938f458fcc1ada6988220aff835a71286b88d76150a2bc618aa6223b03b75da04b5fa6a6ebd228d2ef94057a7ea23fabc0cebb08c7d5152e58</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf27df225b53af5c9d8edeab6abea1acab31b878547ed6a83ffda6f6bd2ca6655ea79090f7dda6183cb288e8428007a7170300e8e37ba28f36</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>