<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:21.4121</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0019144</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치 및 방법</inventionTitle><inventionTitleEng>3D point for enhancement reality and precision human posture  estimation device and the method based on the mesh model  matching</inventionTitleEng><openDate>2025.08.18</openDate><openNumber>10-2025-0123298</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.02.07</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 5/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치와 추정방법에 관한 것이다. 본 발명은 사용자를 촬영한 영상 데이터로부터 포인트 클라우드를 획득하는 단계; 상기 생성된 포인트 클라우드를 정확한 자세를 얻도록 하기 위하여 전처리하는 단계; 사용자의 자세를 추정하기 위한 모델을 사전에 딥러닝 훈련하는 단계; 상기 포인트 클라우드를 3D 메쉬로 변환하고, 상기 3D 메쉬로부터 관절, 자세, 모양을 출력하는 단계; 상기 단계에서 입력된 포인트 클라우드를 위치를 정렬하고 영상을 회전시켜, 위치 및 회전 각도를 일정하게 정렬하는 정렬 단계; 및 상기 단계에서 회전 및 정렬된 이미지를 투사(projection)하는 단계를 포함하는 것을 특징으로 하는 것이다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치에 있어서, 포인트 클라우드 데이터를 수집하여 인체의 영상을 3D메쉬로 출력하는 출력부;상기 출력부를 통하여 출력된 포인트 클라우드를 전처리(Pre-processing)하는 전처리부; 상기 전처리부를 통한 전처리된 포인트 클라우드를 기반으로 하여 사전에 딥러닝을 시킨 훈련모델과, SMPL(Skinned Multi-Person Linear) 파라미터를 이용하여  3D 영상 모델로 생성하는 SMPL 모델이 내장된 인식 모듈;상기 전처리부를 통하여 상기 포인트 클라우드를 제공받고, 상기 인식모듈로부터 SMPL을 이용한 인체 이미지의 각 신체 부위를 감지하고, 감지된 상기 신체 부위 간의 흐름에 관한 상기 신체 부위 관계성을 인코딩하며, 매칭을 통해 형태 및 관절을 완성하여, 상기 사용자의 포즈를 실시간 추정하여 상기 사용자 포즈의 데이터를 생성하며, 상기 생성된 데이터를 합성 이미지화하여 합성 이미지 영상을 송출하는 투사 이미지 생성부로 이루어지는 데이터 생성 모듈; 및상기 데이터 생성 모듈로부터 생성된 포즈, 형태, 관절을 실시간 추정하여, 사용자 데이터로 관리하는 통합 데이터 관리 장치;를 포함하는 것을 특징으로 하는 증강현실을 위한 3D 포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 전처리부는 정확한 자세를 얻도록 하기 위하여, 축 부재를 사용하는 것을 특징으로 하는 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 훈련모델의 딥러닝 학습을 통하여 인체의 관절, 자세, 형태를 사전에 예측하는 것을 특징으로 하는 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 SMPL은 Shape 파라미터와 Pose 파라미터로 이루어진 것을 특징으로 하는 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 딥러닝의 훈련모델은 상기 포인트 클라우드의 각 정점에 대하여 별도의 GMM(Gaussian Mixture Model)을 사용한 것을 특징으로 하는 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 전처리부는 상기 포인트 클라우드의 위치와 축을 설정하기 위하여 메쉬 랩(Mesh Lab)을 사용한 것을 특징으로 하는 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 출력부는 RGB-D 카메라로부터 제공되는 실내 공간의 RGB-D 영상 데이터를 입력 받는 영상입력부;와 상기 영상 입력부로부터 입력받은 포인트 클라우드 정보를 3D 메쉬 정보로 변환하여 저장하는 메쉬 생성부;를 포함하는 것을 특징으로 하는 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정장치.</claim></claimInfo><claimInfo><claim>8. 증강현실을 위한 3D포인트와 메쉬모델 정합기반 정밀 휴먼자세 추정방법에 있어서,사용자를 촬영한 영상 데이터로부터 포인트 클라우드를 획득하는 단계; 상기 생성된 포인트 클라우드를 정확한 자세를 얻도록 하기 위하여 전처리하는 단계; 사용자의 자세를 추정하기 위한 모델을 사전에 딥러닝 훈련하는 단계; 상기 포인트 클라우드를 3D 메쉬로 변환하고, 상기 3D 메쉬로부터 관절, 자세, 모양을 출력하는 단계; 상기 단계에서 입력된 포인트 클라우드를 위치를 정렬하고 영상을 회전시켜, 위치 및 회전 각도를 일정하게 정렬하는 정렬 단계;상기 단계에서 회전 및 정렬된 이미지를 투사(projection)하는 단계를 포함하는 것을 특징으로 하는 정밀 휴먼자세 추정방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 딥러닝 훈련을 하는 단계에서 인체의 뼈대 추출을 위한 모델을 생성하는 것을 특징으로 하는 정밀 휴먼자세 추정방법. </claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 모델의 딥러닝 학습을 통하여, 인체의 관절, 자세, 형태를 사전에 예측하는 것을 특징으로 하는 정밀 휴먼자세 추정방법. </claim></claimInfo><claimInfo><claim>11. 제8항에 있어서, 상기 모델은 SMPL(Skinned Multi-Person Linear Model) 파라미터를 이용하여 생성한 3D 영상인 것을 특징으로 하는 정밀 휴먼자세 추정방법. </claim></claimInfo><claimInfo><claim>12. 제8항에 있어서, 상기 전처리하는 방법은 메쉬 랩(Mesh Lab)을 사용하여 임의의 포인트 클라우드의 위치와 축을 설정하는 것을 특징으로 하는 정밀 휴먼자세 추정방법. </claim></claimInfo><claimInfo><claim>13. 제8항에 있어서, 상기 전처리하는 단계는 상기 모델의 골격을 추출할 수 있도록 원하지 않는 바닥 제거를 위하여, RANSAC 방법을 실행하는 단계와 축 설정을 하는 단계를 포함하는 것을 특징으로 하는 정밀 휴먼자세 추정방법. </claim></claimInfo><claimInfo><claim>14. 제8항에 있어서, 상기 모델의 학습 시 가우시안(Gaussian) 노이즈를 추가하는 것을 특징으로 하는 정밀 휴먼자세 추정방법. </claim></claimInfo><claimInfo><claim>15. 비일시적 컴퓨터 판독 가능한 저장 매체(non-transitory computer readable storage medium)에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은 하나 이상의 명령어들을 포함하고, 상기 명령어들은 하나 이상의 프로세서들을 갖는 컴퓨팅 장치에 의해 실행될 때, 상기 컴퓨팅 장치로 하여금, 사용자를 촬영한 영상 데이터로부터 포인트 클라우드를 획득하는 단계; 상기 생성된 포인트 클라우드를 정확한 자세를 얻도록 하기 위하여 전처리하는 단계; 사용자의 자세를 추정하기 위한 모델을 사전에 딥러닝 훈련하는 단계; 상기 포인트 클라우드를 3D 메쉬로 변환하고, 상기 3D 메쉬로부터 관절, 자세, 모양을 출력하는 단계; 상기 단계에서 입력된 포인트 클라우드를 위치를 정렬하고 영상을 회전시켜, 위치 및 회전 각도를 일정하게 정렬하는 정렬 단계;상기 단계에서 회전 및 정렬된 이미지를 투사(projection)하는 단계를 수행하도록 하는, 비일시적 컴퓨터 판독 가능한 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경상북도 경산시...</address><code>220040363026</code><country>대한민국</country><engName>Industry Academic Cooperation Foundation of Yeungnam University</engName><name>영남대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대구광역시 수성구...</address><code> </code><country> </country><engName>KIM, Sungho</engName><name>김성호</name></inventorInfo><inventorInfo><address>경상북도 경산시 대...</address><code> </code><country> </country><engName>BHATTACHARYYA CHAITALI</engName><name>밭타차리야쪼이탈리</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로***, *층(논현동,시그너스빌딩)</address><code>920141000411</code><country>대한민국</country><engName>DooHo IP Law Firm</engName><name>두호특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.02.07</receiptDate><receiptNumber>1-1-2024-0154743-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.07.03</receiptDate><receiptNumber>4-1-2025-5182004-48</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240019144.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9379d33ad6429f17c39b1366505c2896fa1a4bb9ad9ffa6c98c7311e4eafe2eff83ead93c34219e9cdcbf4d3fd2520dabdbf03210019f815bf</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa6469609a00e18b9001ae939b9aa426a1aa662e2ad0c8d7dfebd1397a056191a8373f6ed8356c69f6989250c89a4ffeaf7a70e814d29e9b9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>