<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:42:05.425</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.12.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7025495</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>대화 이해 용이성 평가를 위한 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR DIALOGUE INTELLIGIBILITY ASSESSMENT</inventionTitleEng><openDate>2022.08.23</openDate><openNumber>10-2022-0117329</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.12.06</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.07.21</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 방법은: 비대화 사운드와 믹싱된 대화를 포함하는 믹싱된 사운드트랙을 획득하는 단계; 상기 믹싱된 사운드트랙을 비교 텍스트로 변환하는 단계; 상기 대화의 명료도에 대한 참조로서 상기 대화에 대한 참조 텍스트를 획득하는 단계; 상기 비교 텍스트와 상기 참조 텍스트의 비교에 기초하여 청취자에 대한 상기 믹싱된 사운드트랙의 상기 대화의 명료도의 측정치를 결정하는 단계; 및 상기 대화의 명료도의 측정치를 보고하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.07.01</internationOpenDate><internationOpenNumber>WO2021133382</internationOpenNumber><internationalApplicationDate>2019.12.23</internationalApplicationDate><internationalApplicationNumber>PCT/US2019/068391</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,비대화 사운드와 믹싱된 대화를 포함하는 믹싱된 사운드트랙을 획득하는 단계;상기 믹싱된 사운드트랙을 비교 텍스트로 변환하는 단계;상기 대화의 명료도(intelligibility)에 대한 참조로서 상기 대화에 대한 참조 텍스트를 획득하는 단계;상기 비교 텍스트와 상기 참조 텍스트의 비교에 기초하여 청취자에 대한 상기 믹싱된 사운드트랙의 상기 대화의 명료도의 측정치를 결정하는 단계; 및상기 대화의 명료도의 측정치를 보고하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 변환하는 단계는 자동 음성 인식(automatic speech recognition, ASR)을 이용하여 상기 믹싱된 사운드트랙을 상기 비교 텍스트로 변환하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 대화의 명료도의 측정치를 결정하는 단계는:상기 비교에 기초하여 상기 믹싱된 사운드트랙의 시간 슬라이스들에 대한 상기 대화의 명료도의 개별 측정치들을 계산하는 단계; 및상기 대화의 명료도의 개별 측정치들에 기초하여 상기 대화의 명료도의 측정치를 계산하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 보고하는 단계는:상기 대화의 명료도의 측정치 및 상기 대화의 명료도의 개별 측정치들을 디스플레이하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 대화의 명료도의 개별 측정치들을 계산하는 단계는 상기 믹싱된 사운드트랙의 시간 슬라이스들에 대응하는 상기 비교 텍스트의 세그먼트들과 상기 참조 텍스트의 세그먼트들 중 대응하는 세그먼트들 간의 차이들을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 보고하는 단계는:상기 대화의 명료도의 측정치, 상기 대화의 명료도의 개별 측정치들, 상기 비교 텍스트의 세그먼트들, 및 상기 참조 텍스트의 세그먼트들 중 대응하는 세그먼트들을 디스플레이하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제3항에 있어서, 디지털 재생 디바이스를 위해 구성되고, 적어도 상기 대화의 명료도의 개별 측정치들을 포함하는 메타데이터를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 참조 텍스트는 각각의 시간 간격들에 걸친 자막 텍스트의 청크들을 포함하고;상기 명료도의 측정치를 결정하는 단계는 (i) 상기 믹싱된 사운드트랙의 시간 슬라이스들에 대응하는 상기 비교 텍스트의 세그먼트들과, (ii) 상기 비교 텍스트의 세그먼트들에 공통의 대화를 전달하는 상기 자막 텍스트의 청크들 중 대응하는 청크들 간의 개별 차이들을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 비교 텍스트의 세그먼트들 각각과 상기 자막 텍스트의 청크들 중 매칭되는 청크들 간의 텍스트 유사성을 최대화하는 텍스트 매칭 알고리즘을 이용하여 상기 비교 텍스트의 세그먼트들을 상기 자막 텍스트의 청크들 중 대응하는 청크들에 매칭시키는 단계를 더 포함하고,상기 개별 차이들을 결정하는 단계는 상기 매칭의 결과들에 기초하여 상기 개별 차이들을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 참조 텍스트를 획득하는 단계는:대화만의 사운드트랙(dialogue-only soundtrack)을 상기 참조 텍스트로 변환하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 참조 텍스트를 획득하는 단계는 상기 대화의 텍스트 기반 자막들을 상기 참조 텍스트로서 수신하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 믹싱된 사운드트랙을 획득하는 단계는:비대화 사운드와 믹싱된 상기 대화를 포함하는 오리지널 믹싱된 사운드트랙을 수신하는 단계; 및실내 음향들, 사운드 재생 시스템 재생 음향들, 및 배경 잡음 중 하나 이상을 에뮬레이트하는 에뮬레이트된 사운드 효과로 상기 오리지널 믹싱된 사운드트랙을 음향적으로 수정하여, 상기 믹싱된 사운드트랙을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 변환하는 단계는:기계 학습 대화 추출기를 이용하여, 상기 믹싱된 사운드트랙으로부터 상기 대화를 추출하여 주로 대화 사운드트랙(predominantly dialogue soundtrack)을 생성하는 단계; 및상기 주로 대화 사운드트랙을 상기 비교 텍스트로 변환하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 대화의 명료도의 측정치를 결정하는 단계는 상기 비교 텍스트와 상기 참조 텍스트 간의 차이를 계산하는 단계, 및 상기 차이에 기초하여 상기 대화의 명료도의 측정치를 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 차이를 계산하는 단계는 상기 차이를 글자들 또는 단어들의 차이들을 나타내는 텍스트 거리로서, 또는 사운드의 차이들을 나타내는 음성학 텍스트 거리로서 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서, 상기 차이를 계산하는 단계는:제1 비교 알고리즘을 이용하여 상기 비교 텍스트와 상기 참조 텍스트 간의 제1 차이를 계산하는 단계;상기 제1 비교 알고리즘과 상이한 제2 비교 알고리즘을 이용하여 상기 비교 텍스트와 상기 참조 텍스트 간의 제2 차이를 계산하는 단계; 및상기 차이를 상기 제1 차이와 상기 제2 차이의 가중 조합으로서 계산하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 장치로서,프로세서를 포함하고, 상기 프로세서는:비대화 사운드와 믹싱된 대화를 포함하는 믹싱된 사운드트랙을 획득하고;상기 믹싱된 사운드트랙을 비교 텍스트로 변환하고;청취자에 대한 상기 대화의 명료도에 대한 참조로서 상기 대화에 대한 참조 텍스트를 획득하고;상기 비교 텍스트와 상기 참조 텍스트 간의 비교에 기초하여 상기 믹싱된 사운드트랙의 상기 대화의 명료도의 개별 측정치들을 계산하고;상기 대화의 명료도의 개별 측정치들에 기초하여 상기 믹싱된 사운드트랙의 상기 대화의 명료도의 전체 측정치를 계산하고; 상기 대화의 명료도의 전체 측정치를 포함한 보고서를 생성하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 프로세서는 상기 믹싱된 사운드트랙의 시간 슬라이스들에 대응하는 상기 비교 텍스트의 세그먼트들과 상기 참조 텍스트의 세그먼트들 중 대응하는 세그먼트들 간의 차이들을 결정하는 것에 의해 상기 대화의 명료도의 개별 측정치들을 계산하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 프로세서는 상기 ASR을 이용하여 대화만의 사운드트랙을 상기 참조 텍스트로 변환하는 것에 의해 상기 참조 텍스트를 획득하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>20. 제17항에 있어서, 상기 프로세서는 상기 대화의 텍스트 기반 자막들을 상기 참조 텍스트로서 수신하는 것에 의해 상기 참조 텍스트를 획득하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>21. 제17항에 있어서, 상기 프로세서는:비대화 사운드와 믹싱된 상기 대화를 포함하는 오리지널 믹싱된 사운드트랙을 수신하는 것; 및실내 음향들, 사운드 재생 시스템 재생 음향들, 및 배경 잡음 중 하나 이상을 에뮬레이트하는 에뮬레이트된 사운드 효과로 상기 오리지널 믹싱된 사운드트랙을 음향적으로 수정하여, 상기 믹싱된 사운드트랙을 생성하는 것에 의해 상기 믹싱된 사운드트랙을 획득하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>22. 명령어들로 인코딩된 비일시적 컴퓨터 판독가능 매체로서, 상기 명령어들은, 프로세서에 의해 실행될 때, 상기 프로세서로 하여금:비대화 사운드와 믹싱된 대화를 포함하는 믹싱된 사운드트랙을 획득하고;자동 음성 인식(automatic speech recognition, ASR)을 이용하여 상기 믹싱된 사운드트랙의 시간 슬라이스들을 비교 텍스트로 변환하고; 상기 대화의 명료도에 대한 참조로서 상기 대화에 대한 참조 텍스트를 획득하고;상기 비교 텍스트와 상기 참조 텍스트 간의 차이들에 기초하여 상기 시간 슬라이스들에 대한 상기 믹싱된 사운드트랙의 상기 대화의 명료도의 개별 측정치들을 계산하고;상기 대화의 명료도의 개별 측정치들에 기초하여 상기 믹싱된 사운드트랙의 상기 대화의 명료도의 전체 측정치를 계산하고;상기 대화의 명료도의 전체 측정치 및 상기 대화의 명료도의 개별 측정치들을 포함한 보고서를 생성하게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 프로세서로 하여금 상기 참조 텍스트를 획득하게 하는 명령어들은, 상기 프로세서로 하여금 상기 ASR을 이용하여 대화만의 사운드트랙을 상기 참조 텍스트로 변환하게 하는 명령어들을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>24. 제22항에 있어서, 상기 프로세서로 하여금 상기 참조 텍스트를 획득하게 하는 명령어들은, 상기 프로세서로 하여금 상기 대화의 텍스트 기반 자막들을 상기 참조 텍스트로서 수신하게 하는 명령어들을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>25. 제22항에 있어서, 상기 프로세서로 하여금 상기 믹싱된 사운드트랙을 획득하게 하는 명령어들은, 상기 프로세서로 하여금:비대화 사운드와 믹싱된 상기 대화를 포함하는 오리지널 믹싱된 사운드트랙을 수신하고;실내 음향들, 사운드 재생 시스템 재생 음향들, 및 배경 잡음 중 하나 이상을 에뮬레이트하는 에뮬레이트된 사운드 효과로 상기 오리지널 믹싱된 사운드트랙을 음향적으로 수정하여, 상기 믹싱된 사운드트랙을 생성하게 하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아주 ***** 칼라바자스 라스 버지니스 로드   ****</address><code>519980630980</code><country>미국</country><engName>DTS, Inc.</engName><name>디티에스, 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아주 ***** 칼라바자스...</address><code> </code><country> </country><engName>PROVENCIO, David, Cortes</engName><name>프로벤시오 데이비드 코르테스</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ***** 칼라바자스...</address><code> </code><country> </country><engName>WALSH, Martin</engName><name>월시 마틴</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ***** 칼라바자스...</address><code> </code><country> </country><engName>SLACK, Brian</engName><name>슬랙 브라이언</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ***** 칼라바자스...</address><code> </code><country> </country><engName>STEIN, Edward</engName><name>스테인 에드워드</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.07.21</receiptDate><receiptNumber>1-1-2022-0763876-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Translation of Amendment made during International Phase] Submission of Document</documentEngName><documentName>[국제단계보정서 번역문]서류제출서</documentName><receiptDate>2022.07.21</receiptDate><receiptNumber>1-1-2022-0763877-06</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.07.26</receiptDate><receiptNumber>1-5-2022-0111024-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.12.06</receiptDate><receiptNumber>1-1-2022-1310829-46</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.12.06</receiptDate><receiptNumber>1-1-2022-1310830-93</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.17</receiptDate><receiptNumber>9-5-2025-1002950-22</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227025495.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9323630666477480b7618453b7615172014596a1147b5643630be065e6460f0ac4fd1b776112b582eef98ca4cab8098bbea364a8f3bec5fe4f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe35eb336ffe7d232b94952175d1648dfda7493a606d0defa30f02b9f92101dfff55c8a82303686913f9ac4c59408b62ba4b00217a5623446</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>