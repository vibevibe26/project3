<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:13.4013</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.02.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7030070</applicationNumber><claimCount>71</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>기계 학습 기반 센서 분석 및 혈관 트리 분할을 위한 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEM AND METHOD FOR MACHINE-LEARNING BASED SENSOR ANALYSIS AND VASCULAR TREE SEGMENTATION</inventionTitleEng><openDate>2024.10.11</openDate><openNumber>10-2024-0148399</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.06</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.09.06</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/187</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 혈관 특징을 자동으로 식별하는 방법이 설명된다. 일부 실시예에서, 하나 이상의 기계 학습(machine learning; ML) 기반 혈관 분류기가 사용되며, 그 결과는 최종 결과를 생성하기 위해 적어도 하나의 다른 혈관 분류기의 결과와 조합된다. 이 접근 방식의 잠재적인 장점은 ML 분류기의 특정 강점을 더 고전적인(&quot;공식 기반&quot;) 방법에 기초한 분할 접근 방식과 조합할 수 있다는 점을 포함한다. 이러한 강점은 비슷해 보이지만 해부학적으로 다른 표적을 함께 나타내는 영상 내에 혼합된 해부학적으로 식별된 표적을 특히 식별하는 것을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.08.17</internationOpenDate><internationOpenNumber>WO2023152688</internationOpenNumber><internationalApplicationDate>2023.02.09</internationalApplicationDate><internationalApplicationNumber>PCT/IB2023/051186</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 혈관 영상의 혈관 부분을 식별하는 방법에 있어서, 상기 방법은:상기 혈관 영상에 접근하는 것;상기 혈관 영상에 제1 ML 기반 혈관 식별자(ML-based vascular identifier)를 적용하여 상기 혈관 영상에서 적어도 일부 혈관 부분을 식별하는 제1 데이터 구조를 생성하는 것;상기 혈관 영상에 제 2 혈관 식별자를 적용하여 제2 데이터 구조를 생성하는 것 - 상기 제2 데이터 구조는 상기 제1 데이터 구조에 없는 상기 혈관 영상 내의 일부 혈관 부분을 식별함 - ; 및상기 혈관 영상 내의 혈관 부분의 조합된 식별을 생성하기 위하여 상기 제1 및 제2 데이터 구조를 조합하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서:상기 제1 ML 기반 혈관 식별자는, 상기 ML 기반 혈관 식별자를 생성하는 데 사용된 훈련 입력에 기초하여, 제1 해부학적으로 정의된 혈관 유형을 인식하도록 구성되고; 및 상기 제2 혈관 식별자는 또한 ML 기반 혈관 식별자이고, 상기 ML 기반 혈관 식별자를 생성하는 데 사용된 훈련 입력에 기초하여, 제2 해부학적으로 정의된 혈관 유형을 인식하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 제1 및 제2 해부학적으로 정의된 혈관 유형은: LAD, LAD 하위 트리의 다른 혈관, LCX, LCX 하위 트리의 다른 혈관, RCA, 및 RCA 하위 트리의 다른 혈관으로 구성된 군으로부터 선택되는 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 제1 및 제2 ML 기반 혈관 식별자는 각각 상기 제1 및 제2 해부학적으로 정의된 혈관 유형에 대한 영상 및 영상 위치 표시를 포함하는 훈련 입력을 사용하여 각자의 해부학적으로 정의된 제1 및 제2 혈관 유형을 인식하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서:상기 제1 데이터 구조는 경로 정의를 포함하고, 상기 경로는 혈관 부분을 따라 연장되며; 및상기 제2 데이터 구조는 혈관 부분에 대응하는 화소를 식별하는 화소 마스크를 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 제1 ML 기반 혈관 식별자는 출력 계층이 회귀 계층인 네트워크를 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서, 상기 제2 혈관 식별자는 출력 계층이 분류 계층인 ML 기반 혈관 식별자인 방법.</claim></claimInfo><claimInfo><claim>8. 제5항에 있어서, 상기 조합하는 것은:상기 제1 ML 기반 혈관 식별자 및 상기 제2 혈관 식별자 모두에 의해 식별된 제1 및 제2 영역을 식별하는 것, 및상기 제1 ML 기반 혈관 식별자 및 상기 제2 혈관 식별자 중 하나에 의해 식별된 제3 영역을, 상기 제1 및 제2 영역 사이에서 연장되는 상기 제3 영역에 기초하여, 상기 조합된 식별 내에 포함시키기 위하여 선택하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 제1 및 제2 데이터 구조 중 적어도 하나는 잘못 식별된 혈관 부분을 포함하고; 상기 방법은:상기 제1 및 제2 데이터 구조 사이의 혈관 부분 식별에서의 차이가 상기 제1 ML 기반 혈관 식별자 및 상기 제2 혈관 식별자 중 하나의 알려진 오류 경향에 대응하는지 여부를 결정하는 것을 포함하고; 및상기 조합하는 것은, 식별된 알려진 오류 경향에 따라, 상기 조합된 식별 내에 식별된 혈관 부분을 선택적으로 포함시키는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 혈관 영상의 혈관 부분을 식별하는 방법에 있어서, 상기 방법은:상기 혈관 영상을 포함하는 복수의 혈관 영상에 접근하는 것;상기 복수의 혈관 영상에 ML 기반 혈관 식별자를 적용하여 그 적어도 일부 혈관 부분을 식별하는 제1 데이터 구조를 생성하는 것; 및상기 제1 데이터 구조를 상기 혈관 영상과 비교하여 그 혈관 부분을 식별하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 복수의 혈관 영상은 각각 동일한 시계열 영상의 일부인 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 시계열의 각 영상은 동일한 해부학적 영역을 이미징하고, 상기 시계열의 각 인접한 영상 쌍의 영상들은 1초 이하의 간격 내에서 상기 해부학적 영역을 이미징하는 방법.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 ML 기반 혈관 식별자는 복수의 시계열 영상에 대해 훈련된 ML 기반 혈관 식별자인 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 제2 데이터 구조는 상기 제1 데이터 구조에서 식별된 일부 혈관 부분을 생략하는 방법.</claim></claimInfo><claimInfo><claim>15. 혈관 영상의 혈관 부분을 식별하는 시스템에 있어서, 상기 시스템은 프로세서 및 메모리를 포함하고, 상기 메모리는 상기 프로세서가: 상기 혈관 영상에 접근하고;상기 혈관 영상에 제1 ML 기반 혈관 식별자를 적용하여 상기 혈관 영상에서 적어도 일부 혈관 부분을 식별하는 제1 데이터 구조를 생성하고 상기 메모리에 저장하고;상기 혈관 영상에 제 2 혈관 식별자를 적용하여 제2 데이터 구조를 생성하고 상기 메모리에 저장하고 - 상기 제2 데이터 구조는 상기 제1 데이터 구조에 없는 상기 혈관 영상 내의 일부 혈관 부분을 식별함 - ; 및상기 제1 및 제2 데이터 구조를 조합하여 상기 혈관 영상 내의 혈관 부분의 조합된 식별을 생성하고 상기 메모리에 저장하도록 하는 명령을 인코딩하는 시스템.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 제1 ML 기반 혈관 식별자는, 상기 ML 기반 혈관 식별자를 생성하는 데 사용된 훈련 입력에 기초하여, 제1 해부학적으로 정의된 혈관 유형을 인식하도록 구성되고, 상기 제2 혈관 식별자는 또한 ML 기반 혈관 식별자이고, 상기 ML 기반 혈관 식별자를 생성하는 데 사용된 훈련 입력에 기초하여, 제2 해부학적으로 정의된 혈관 유형을 인식하도록 구성되는 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 제1 및 제2 해부학적으로 정의된 혈관 유형은: LAD, LAD 하위 트리의 다른 혈관, LCX, LCX 하위 트리의 다른 혈관, RCA, 및 RCA 하위 트리의 다른 혈관으로 구성된 군으로부터 선택되는 시스템. </claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 제1 및 제2 ML 기반 혈관 식별자는 각각 상기 제1 및 제2 해부학적으로 정의된 혈관 유형에 대한 영상 및 영상 위치 표시를 포함하는 훈련 입력을 사용하여 각자의 해부학적으로 정의된 제1 및 제2 혈관 유형을 인식하도록 구성되는 시스템. </claim></claimInfo><claimInfo><claim>19. 제15항에 있어서:상기 제1 데이터 구조는 경로 정의를 포함하고, 상기 경로는 혈관 부분을 따라 연장되며; 및상기 제2 데이터 구조는 혈관 부분에 대응하는 화소를 식별하는 화소 마스크를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 제1 ML 기반 혈관 식별자는 출력 계층이 회귀 계층인 네트워크를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>21. 제19항에 있어서, 상기 제2 혈관 식별자는 출력 계층이 분류 계층인 ML 기반 혈관 식별자인 시스템.</claim></claimInfo><claimInfo><claim>22. 제19항에 있어서, 상기 명령은 상기 프로세서가:상기 제1 ML 기반 혈관 식별자 및 상기 제2 혈관 식별자 모두에 의해 식별된 제1 및 제2 영역을 식별하고, 및상기 제1 ML 기반 혈관 식별자 및 상기 제2 혈관 식별자 중 하나에 의해 식별된 제3 영역을, 상기 제1 및 제2 영역 사이에서 연장되는 상기 제3 영역에 기초하여, 상기 조합된 식별 내에 포함시키기 위하여 선택하도록 더 명령하는 시스템.</claim></claimInfo><claimInfo><claim>23. 제15항에 있어서, 상기 명령은 상기 프로세서가:상기 제1 및 제2 데이터 구조 중 적어도 하나가 잘못 식별된 혈관 부분을 포함하는 조건을 결정하고;상기 제1 및 제2 데이터 구조 사이의 혈관 부분 식별에서의 차이가 상기 제1 ML 기반 혈관 식별자 및 상기 제2 혈관 식별자 중 하나의 알려진 오류 경향에 대응하는지 여부를 결정하고; 및식별된 알려진 오류 경향에 따라 선택적으로 상기 제1 및 제2 데이터 구조를 조합하도록 더 명령하는 시스템.</claim></claimInfo><claimInfo><claim>24. 제15항에 있어서, 상기 제2 데이터 구조는 상기 제1 데이터 구조에서 식별된 일부 혈관 부분을 생략하는 시스템.</claim></claimInfo><claimInfo><claim>25. 혈관 영상의 혈관 부분을 식별하는 시스템에 있어서, 상기 시스템은 프로세서 및 메모리를 포함하고, 상기 메모리는 상기 프로세서가: 상기 혈관 영상을 포함하는 복수의 혈관 영상에 접근하고;상기 복수의 혈관 영상에 ML 기반 혈관 식별자를 적용하여 그 적어도 일부 혈관 부분을 식별하는 제1 데이터 구조를 생성하고; 및상기 제1 데이터 구조를 상기 혈관 영상과 비교하여 그 혈관 부분을 식별하도록 하는 명령을 인코딩하는 시스템.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 복수의 혈관 영상은 각각 동일한 시계열 영상의 일부인 시스템.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 시계열의 각 영상은 동일한 해부학적 영역을 이미징하고, 상기 시계열의 각 인접한 영상 쌍의 영상들은 1초 이하의 간격 내에서 상기 해부학적 영역을 이미징하는 시스템.</claim></claimInfo><claimInfo><claim>28. 제25항에 있어서, 상기 ML 기반 혈관 식별자는 복수의 시계열 영상에 대해 훈련된 ML 기반 혈관 식별자인 시스템.</claim></claimInfo><claimInfo><claim>29. 하나 이상의 컴퓨터의 시스템에 의해 구현되는 방법에 있어서, 상기 방법은:복수의 혈관 영상 - 상기 혈관 영상은 특정 관찰지점으로부터 심장의 일부를 묘사하고 상기 혈관 영상은 시간 범위 내에서 상이한 시간과 연관됨 - 을 포함하는 영상 시퀀스에 접근하는 것;특정 심장 단계와 연관된 상기 혈관 영상의 부분 집합을 결정하는 것 - 상기 결정은 심장 단계에 기초하여 혈관 영상을 분류하도록 훈련된 기계 학습 모델을 통해 순방향 통과를 계산하는 것을 포함함 - ;상기 부분 집합과 연관된 분할 마스크(segmentation mask)를 생성하는 것 - 상기 분할 마스크는 상기 부분 집합을 형성하는 각각의 혈관 영상에 포함된 혈관을 분할하고, 상기 분할 마스크에 대하여 분할 마스크에 포함된 혈관과 연관된 크기 또는 길이를 나타내는 마스크 점수가 결정되고, 상기 마스크 점수에 기초하여 하나 이상의 혈관 영상을 제거하기 위하여 상기 부분 집합이 필터링됨 - ; 및상기 필터링된 부분 집합에 포함된 특정 혈관 영상을 결정하는 것 - 상기 결정은 상기 필터링된 부분 집합에 포함된 각 혈관 영상에 대해 결정된 하나 이상의 영상 품질 척도를 분석하는 것에 기초함 - 을 포함하며,상기 특정 혈관 영상은 대화형 사용자 인터페이스에 포함되도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서, 상기 혈관 영상은 혈관조영 영상인 방법.</claim></claimInfo><claimInfo><claim>31. 제29항에 있어서, 상기 혈관 영상은 컴퓨터 단층촬영 영상인 방법.</claim></claimInfo><claimInfo><claim>32. 제29항에 있어서, 상기 영상 시퀀스에 포함된 상기 혈관 영상은 특정 주파수에서 획득되어, 상기 특정 주파수에 따라 시간이 구분되는 방법.</claim></claimInfo><claimInfo><claim>33. 제29항에 있어서, 상기 영상 시퀀스는 상기 특정 관찰지점에서 상기 영상 시퀀스를 획득하도록 배치된 c-암(c-arm)을 통해 획득되는 방법.</claim></claimInfo><claimInfo><claim>34. 제29항에 있어서, 심장 단계 영상의 부분 집합을 결정하는 것은:상기 영상 시퀀스가 심장의 왼쪽 또는 오른쪽과 연관되는지 결정하는 것을 포함하고,상기 기계 학습 모델은 상기 결정에 기초하여 복수의 기계 학습 모델로부터 선택되는 방법.</claim></claimInfo><claimInfo><claim>35. 제34항에 있어서, 상기 영상 시퀀스가 왼쪽 또는 오른쪽과 연관되는지 결정하는 것은 상이한 기계 학습 모델의 사용에 기초하고, 상기 상이한 기계 학습 모델은 각 혈관 영상에 상기 혈관 영상이 왼쪽 또는 오른쪽과 연관될 가능성을 나타내는 값을 할당하는 방법.</claim></claimInfo><claimInfo><claim>36. 제29항에 있어서, 상기 기계 학습 모델은 합성곱 신경망이고, 상기 부분 집합을 결정하는 것은:상기 영상 시퀀스로부터, 임계값 수의 상기 혈관 영상을 획득하는 것 - 상기 임계값 수를 형성하는 상기 영상은 상기 영상 시퀀스 내에서 연속적임 - ; 및상기 임계값 수의 상기 혈관 영상을 상기 기계 학습 모델에 입력으로 제공하는 것 - 상기 기계 학습은 상기 임계값 수 내의 특정 영상과 연관된 분류를 출력함 - 을 포함하는 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서, 상기 특정 영상은 상기 임계값 수의 상기 혈관 영상의 가운데 영상인 방법. </claim></claimInfo><claimInfo><claim>38. 제29항에 있어서, 상기 특정 심장 단계는 이완기 말(end-diastolic)인 방법.</claim></claimInfo><claimInfo><claim>39. 제29항에 있어서, 상기 기계 학습 모델은 상기 혈관 영상이 이완기 말일 가능성을 나타내는 값을 출력하는 방법.</claim></claimInfo><claimInfo><claim>40. 제29항에 있어서, 상기 기계 학습 모델은 하나 이상의 장단기 메모리 장치를 사용하는 방법.</claim></claimInfo><claimInfo><claim>41. 제29항에 있어서, 상기 분할 마스크는 상이한 기계 학습 모델에 기초하여 생성되며, 상기 상이한 기계 학습 모델은 혈관 영상에 묘사된 혈관을 분할하도록 훈련되는 방법.</claim></claimInfo><claimInfo><claim>42. 제41항에 있어서, 상기 상이한 기계 학습 모델은 합성곱 신경망인 방법.</claim></claimInfo><claimInfo><claim>43. 제29항에 있어서, 상기 분할 마스크는 프랜지(Frangi) 필터의 사용에 기초하여 생성되는 방법.</claim></claimInfo><claimInfo><claim>44. 제29항에 있어서, 분할 마스크는 이진 색상이 할당된 화소를 포함하며, 제1 색상은 할당된 화소가 혈관의 일부를 형성함을 나타내고, 제2 색상은 할당된 화소가 혈관의 일부를 형성하지 않음을 나타내는 방법.</claim></claimInfo><claimInfo><claim>45. 제29항에 있어서, 상기 영상 시퀀스는 심장의 왼쪽 또는 오른쪽과 연관되는지 결정되고, 오른쪽에 대해서는 상기 부분 집합에 포함되는 각 혈관 영상에 대하여 단일 분할 마스크가 생성되는 방법. </claim></claimInfo><claimInfo><claim>46. 제45항에 있어서, 상기 단일 분할 마스크는 우관상 동맥(right coronary artery)과 연관된 혈관을 분할하는 방법. </claim></claimInfo><claimInfo><claim>47. 제29항에 있어서, 상기 영상 시퀀스는 심장의 왼쪽 또는 오른쪽과 연관되는지 결정되고, 왼쪽에 대해서는 상기 부분 집합에 포함되는 각 혈관 영상에 대하여 둘 이상의 분할 마스크가 생성되는 방법. </claim></claimInfo><claimInfo><claim>48. 제47항에 있어서, 상기 둘 이상의 분할 마스크는 좌전하(left anterior descending; LAD) 동맥, 좌회선 동맥(left circumflex artery; LCX) 및 좌변연 동맥(left marginal artery) 중 둘 이상과 연관된 혈관을 분할하는 방법. </claim></claimInfo><claimInfo><claim>49. 제29항에 있어서, 상기 분할 마스크는 블롭 유형(blob-type) 또는 경로 유형(path-type)인 방법.</claim></claimInfo><claimInfo><claim>50. 제29항에 있어서, 상기 기계 학습 모델의 출력은 ML 기반 혈관 식별자인 방법.</claim></claimInfo><claimInfo><claim>51. 제29항에 있어서, 상기 부분 집합 내에 포함되는 하나 이상의 혈관 영상은 상기 분할 마스크에 기초하여 폐기되고, 폐기는 불연속성을 갖는 상기 분할 마스크 내에 포함된 혈관에 기초하는 방법.</claim></claimInfo><claimInfo><claim>52. 제29항에 있어서, 마스크 점수는 혈관과 연관된 길이 또는 상기 혈관과 연관된 면적을 나타내는 방법.</claim></claimInfo><claimInfo><claim>53. 제29항에 있어서, 상기 특정 혈관조영 영상을 결정하는 것은:상기 필터링된 부분 집합에 포함된 상기 혈관 영상을 등록하는 것 - 등록은 상기 혈관 영상에 묘사된 특징을 정렬하는 것을 포함함 - ;상기 필터링된 부분 집합에 포함된 상기 혈관 영상에 대한 대비 점수를 포함하는 영상 품질 척도를 결정하는 것 - 대비 점수는 상기 혈관 영상 내의 혈관과 연관된 평균 회색조 값을 나타냄 - ; 및상기 대비 점수에 기초하여 상기 특정 혈관조영 영상을 결정하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>54. 제53항에 있어서, 상기 필터링된 부분 집합에 포함된 상기 혈관 영상에 대하여 통합 분할 마스크가 생성되고, 상기 대비 점수는 상기 혈관 영상에 포함된 동일한 혈관의 대비를 비교하는 방법.</claim></claimInfo><claimInfo><claim>55. 제53항에 있어서, 거리 점수는 채우기 점수이고, 추가로, 상기 채우기 점수를 결정하는 것은 상기 분할 마스크를 사용하여 혈관을 형성하는 화소 수량이나 화소 수량의 추정치를 결정하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>56. 제29항에 있어서, 상기 대화형 사용자 인터페이스는 상기 특정 혈관 영상이 아닌 다른 혈관 영상을 선택할 수 있도록 구성되며, 상기 시스템은 상기 선택에 기초하여 상기 기계 학습 모델을 업데이트하도록 구성되는 방법.</claim></claimInfo><claimInfo><claim>57. 제29항에 있어서, 상기 대화형 사용자 인터페이스는 상기 특정 혈관조영 영상 내의 혈관의 윤곽 또는 위치를 나타내는 사용자 입력에 응답하는 방법.</claim></claimInfo><claimInfo><claim>58. 하나 이상의 컴퓨터 및 상기 하나 이상의 컴퓨터에 의해 실행될 때, 상기 하나 이상의 컴퓨터가 제29항 내지 제57항 중 어느 한 항에 따른 방법을 수행하도록 하는 명령을 저장하는 비일시적 컴퓨터 저장 매체를 포함하는 시스템.</claim></claimInfo><claimInfo><claim>59. 하나 이상의 컴퓨터의 시스템에 의해 실행될 때, 상기 하나 이상의 컴퓨터가 제26항 내지 제57항 중 어느 한 항에 따른 방법을 수행하도록 하는 명령을 저장하는 비일시적 컴퓨터 저장 매체.</claim></claimInfo><claimInfo><claim>60. 하나 이상의 컴퓨터의 시스템에 의해 구현되는 방법에 있어서, 상기 방법은:복수의 혈관 영상 - 상기 혈관 영상은 특정 관찰지점으로부터 심장의 일부를 묘사하고 상기 혈관 영상은 시간 범위 내에서 상이한 시간과 연관됨 - 을 포함하는 영상 시퀀스에 접근하는 것;혈관 영상의 제1 집합을 형성하도록 구성된 제1 기계 학습 모델을 적용하는 것 - 상기 복수의 혈관 영상에서 하나 이상의 혈관 영상이 제거되어 상기 제1 집합을 형성하고, 상기 제1 집합은 심장의 이완기 말 단계와 연관된 혈관 영상을 포함함 - ; 혈관 영상의 제2 집합을 형성하도록 구성된 제2 기계 학습 모델을 적용하는 것 - 상기 제1 집합의 하나 이상의 혈관 영상이 제거되어 제2 집합을 형성하고, 상기 제2 집합은 임계 백분위수보다 큰 길이를 갖는 혈관과 연관된 혈관 영상을 포함함 - ; 및상기 제2 집합과 연관된 대비 점수에 기초하여 상기 제2 집합으로부터 특정 혈관조영 영상을 결정하는 것 - 대비 점수는 혈관 영상에 묘사된 하나 이상의 혈관과 연관된 대비 품질의 척도를 나타냄 - 을 포함하는 방법.</claim></claimInfo><claimInfo><claim>61. 제60항에 있어서, 상기 제1 기계 학습 모델 및 제2 기계 학습 모델은 상기 영상 시퀀스가 심장의 왼쪽 또는 오른쪽을 묘사하는지에 기초하여 선택되는 방법.</claim></claimInfo><claimInfo><claim>62. 하나 이상의 컴퓨터 및 명령을 저장하는 비일시적 컴퓨터 저장 매체를 포함하는 시스템에 있어서, 상기 명령은, 상기 하나 이상의 컴퓨터에 의해 실행될 때, 상기 하나 이상의 컴퓨터가: 복수의 혈관 영상을 포함하는 영상 시퀀스에 제1 기계 학습 모델을 적용하고 - 상기 제2 기계 학습 모델은 혈관 영상의 제1 집합을 형성하도록 구성되고, 상기 복수의 혈관 영상에서 하나 이상의 혈관 영상이 제거되어 상기 제1 집합을 형성하고, 상기 제1 집합은 심장의 이완기 말 단계와 연관된 혈관 영상을 포함함 - ; 혈관 영상의 제2 집합을 형성하도록 구성된 제2 기계 학습 모델을 적용하고 - 상기 제1 집합에서 하나 이상의 혈관 영상이 제거되어 상기 제2 집합을 형성하고, 상기 제2 집합은 임계 백분위수보다 더 큰 길이를 갖는 혈관과 연관된 혈관 영상을 포함함 - ; 및 상기 제2 집합과 연관된 대비 점수에 기초하여 상기 제2 집합으로부터 특정 혈관조영 영상을 결정 - 대비 점수는 혈관 영상에 묘사된 하나 이상의 혈관과 연관된 대비 품질의 척도를 나타냄 - 하도록 하는 시스템. </claim></claimInfo><claimInfo><claim>63. 제62항에 있어서, 상기 제1 기계 학습 모델 및 상기 제2 기계 학습 모델은 상기 영상 시퀀스가 심장의 왼쪽 또는 오른쪽을 묘사하는지에 기초하여 선택되는 시스템.</claim></claimInfo><claimInfo><claim>64. 명령을 저장하는 비일시적 컴퓨터 저장 매체에 있어서, 상기 명령은, 하나 이상의 컴퓨터의 시스템에 의해 실행될 때, 상기 하나 이상의 컴퓨터가: 복수의 혈관 영상을 포함하는 영상 시퀀스에 제1 기계 학습 모델을 적용하고 - 상기 제1 기계 학습 모델은 혈관 영상의 제1 집합을 형성하도록 구성되고, 상기 복수의 혈관 영상에서 하나 이상의 혈관 영상이 제거되어 상기 제1 집합을 형성하고, 상기 제1 집합은 심장의 이완기 말 단계와 연관된 혈관 영상을 포함함 - ; 혈관 영상의 제2 집합을 형성하도록 구성된 제2 기계 학습 모델을 적용하고 - 상기 제1 집합에서 하나 이상의 혈관 영상이 제거되어 상기 제2 집합을 형성하고, 상기 제2 집합은 임계 백분위수보다 더 큰 길이를 갖는 혈관과 연관된 혈관 영상을 포함함 - ; 및 상기 제2 집합과 연관된 대비 점수에 기초하여 상기 제2 집합으로부터 특정 혈관조영 영상을 결정 - 대비 점수는 혈관 영상에 묘사된 하나 이상의 혈관과 연관된 대비 품질의 척도를 나타냄 - 하도록 하는 비일시적 컴퓨터 저장 매체.</claim></claimInfo><claimInfo><claim>65. 제64항에 있어서, 상기 제1 기계 학습 모델 및 상기 제2 기계 학습 모델은 상기 영상 시퀀스가 심장의 왼쪽 또는 오른쪽을 묘사하는지에 기초하여 선택되는 컴퓨터 저장 매체.</claim></claimInfo><claimInfo><claim>66. 하나 이상의 컴퓨터의 시스템에 의해 구현되는 방법에 있어서, 상기 방법은:복수의 혈관 영상 - 상기 혈관 영상은 특정 관찰지점으로부터 심장의 일부를 묘사하고 상기 혈관 영상은 시간 범위 내에서 상이한 시간과 연관됨 - 을 각각 포함하는 복수의 영상 시퀀스에 접근하는 것;사용자 디바이스를 통해 대화형 사용자 인터페이스에 제시하게 하는 것 - 상기 대화형 사용자 인터페이스는: 특정 영상 시퀀스의 선택에 응답하고, 상기 선택은 상기 특정 영상 시퀀스 내에 포함된 특정 혈관 영상의 결정을 트리거링하고, 상기 특정 혈관 영상의 결정은:  특정 심장 단계와 연관된 상기 특정 영상 시퀀스 내에 포함된 상기 혈관 영상의 부분 집합을 결정하는 것 - 상기 결정은 심장 단계에 기초하여 혈관 영상을 분류하도록 훈련된 기계 학습 모델을 통해 순방향 통과를 계산하는 것을 포함함 - ;  상기 부분 집합과 연관된 분할 마스크를 생성하는 것 - 상기 분할 마스크는 상기 부분 집합을 형성하는 각각의 혈관 영상에 포함된 혈관을 분할하고, 상기 분할 마스크에 대하여 분할 마스크에 포함된 혈관과 연관된 크기 또는 길이를 나타내는 마스크 점수가 결정되고, 상기 마스크 점수에 기초하여 하나 이상의 혈관 영상을 제거하도록 상기 부분 집합이 필터링됨 - ; 및  상기 필터링된 부분 집합에 포함된 특정 혈관 영상을 결정하는 것을 포함하고, 상기 결정은 상기 필터링된 부분 집합에 포함된 각 혈관 영상에 대해 결정된 하나 이상의 영상 품질 척도를 분석하는 것에 기초함 - ; 및 상기 특정 혈관 영상을 포함하도록 상기 대화형 사용자 인터페이스를 업데이트하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>67. 제66항에 있어서, 상기 대화형 사용자 인터페이스는 상기 특정 영상 시퀀스를 형성하는 상기 혈관 영상의 애니메이션 또는 동영상을 제시하는 방법.</claim></claimInfo><claimInfo><claim>68. 제67항에 있어서, 상기 특정 혈관 영상은 상기 애니메이션 또는 동영상의 제시 내에서 식별되는 방법.</claim></claimInfo><claimInfo><claim>69. 하나 이상의 컴퓨터의 시스템에 의해 구현되는 방법에 있어서, 상기 방법은:복수의 혈관 영상 - 상기 혈관 영상은 특정 관찰지점으로부터 심장의 일부를 묘사하고 상기 혈관 영상은 시간 범위 내에서 상이한 시간과 연관됨 - 을 각각 포함하는 복수의 영상 시퀀스에 접근하는 것;사용자 디바이스를 통해 대화형 사용자 인터페이스에 제시하게 하는 것 - 상기 대화형 사용자 인터페이스는: 특정 영상 시퀀스의 선택에 응답하고 상기 선택은 상기 특정 영상 시퀀스 내에 포함된 특정 혈관 영상의 결정을 트리거링하고, 상기 특정 혈관 영상의 결정은:  상기 특정 영상 시퀀스에 제1 기계 학습 모델을 적용하는 것 - 상기 제1 기계 학습 모델은 혈관 영상의 제1 집합을 형성하도록 구성되고, 상기 특정 영상 시퀀스에서 하나 이상의 혈관 영상이 제거되어 상기 제1 집합을 형성하고, 상기 제1 집합은 심장의 이완기 말 단계와 연관된 혈관 영상을 포함함 - ;   혈관 영상의 제2 집합을 형성하도록 구성된 제2 기계 학습 모델을 적용하는 것 - 상기 제1 집합에서 하나 이상의 혈관 영상이 제거되어 상기 제2 집합을 형성하고, 상기 제2 집합은 임계 백분위수보다 더 큰 길이를 갖는 혈관과 연관된 혈관 영상을 포함함 - ; 및   상기 제2 집합과 연관된 대비 점수에 기초하여 상기 제2 집합으로부터 특정 혈관조영 영상을 결정하는 것을 포함하고, 대비 점수는 혈관 영상에 묘사된 하나 이상의 혈관과 연관된 대비 품질의 척도를 나타냄 - , 및상기 특정 혈관 영상을 포함하도록 상기 대화형 사용자 인터페이스를 업데이트하는 것을 포함하는 방법.</claim></claimInfo><claimInfo><claim>70. 제69항에 있어서, 상기 대화형 사용자 인터페이스는 상기 특정 영상 시퀀스를 형성하는 상기 혈관 영상의 애니메이션 또는 동영상을 제시하는 방법.</claim></claimInfo><claimInfo><claim>71. 제70항에 있어서, 상기 특정 혈관 영상은 상기 애니메이션 또는 동영상의 제시 내에서 식별되는 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>이스라엘 크파르 사바 ******* 라파포트 *</address><code>520150494251</code><country>이스라엘</country><engName>CATHWORKS LTD.</engName><name>캐스웍스 엘티디.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>이스라엘 크파르 사...</address><code> </code><country> </country><engName>SHALHON, LIVNE, Moran</engName><name>샬혼, 리브네, 모란</name></inventorInfo><inventorInfo><address>이스라엘 크파르 사...</address><code> </code><country> </country><engName>YAARI, Avishai, Baruch</engName><name>야아리, 아비샤이, 바루흐</name></inventorInfo><inventorInfo><address>이스라엘 크파르 사...</address><code> </code><country> </country><engName>BLECHER, SEGEV, Hila</engName><name>블레처, 시지브, 힐라</name></inventorInfo><inventorInfo><address>이스라엘 크파르 사...</address><code> </code><country> </country><engName>SHAPIRA, Tomer</engName><name>샤피라, 토머</name></inventorInfo><inventorInfo><address>이스라엘 크파르 사...</address><code> </code><country> </country><engName>NOKED, PARTOUCHE, Ori, Ahron</engName><name>노키드, 파르투슈, 오리, 아론</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 남대문로 **, *층(소공동, 한진빌딩 본관)</address><code>920151000211</code><country>대한민국</country><engName>Lee &amp; Ko IP</engName><name>특허법인광장리앤고</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.02.10</priorityApplicationDate><priorityApplicationNumber>63/308,550</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.09.06</receiptDate><receiptNumber>1-1-2024-0983169-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.10</receiptDate><receiptNumber>1-5-2024-0148705-10</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247030070.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9398493e17c3b8ac69225fecaf97ad45dfe16aadb96cb7ef19afcbd8e8dc20c6627aca2967c062c9ba262e037d8328d08423ca514015fdbb24</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1cfe29b956979877fe9edf457a82e5c350040ead191af9c84d87a6a5efe5aa7f1011796d1e7a2c1be5a12b4631a199e6f0a85d796b171922</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>