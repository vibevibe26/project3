<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:27.4127</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.01.27</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2023-7032471</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>계산 검출 방법들을 위해 전자 이미지들을 처리하기 위한 시스템들 및 방법들</inventionTitle><inventionTitleEng>systems and methods for processing electronic images  for computational detection methods</inventionTitleEng><openDate>2023.10.05</openDate><openNumber>10-2023-0138062</openNumber><originalApplicationDate>2021.01.27</originalApplicationDate><originalApplicationKind>국제출원/분할</originalApplicationKind><originalApplicationNumber>10-2022-7025752</originalApplicationNumber><originalExaminationRequestDate>2024.01.18</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.09.21</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/28</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/136</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020227025752</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 조직 표본과 연관된 하나 이상의 전자 슬라이드 이미지를 수신—조직 표본은 환자 및/또는 의료 케이스와 연관됨—하고, 하나 이상의 전자 슬라이드 이미지 중 제1 슬라이드 이미지를 복수의 타일로 분할하고, 제1 슬라이드 이미지 및/또는 복수의 타일의 복수의 조직 영역을 검출하여 조직 마스크를 생성하고, 복수의 타일 중 임의의 타일이 비조직에 대응하는지를 결정하고, 비조직인 것으로 결정되는 복수의 타일 중 임의의 타일을 제거하고, 기계 학습 예측 모델을 이용하여, 하나 이상의 전자 슬라이드 이미지에 대한 적어도 하나의 라벨에 대한 예측을 결정—기계 학습 예측 모델은 복수의 훈련 이미지를 처리함으로써 생성됨—하고, 훈련된 기계 학습 예측 모델의 예측을 출력하기 위한 시스템들 및 방법들이 개시된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.08.05</internationOpenDate><internationOpenNumber>WO2021154849</internationOpenNumber><internationalApplicationDate>2021.01.27</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/015285</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 슬라이드 이미지들을 처리하는 컴퓨터로 구현된 방법으로서,조직 표본과 관련된 하나 이상의 전자 슬라이드 이미지들을 수신하는 단계 - 상기 조직 표본은 환자 및/또는 의료 케이스와 관련됨 -;기계 학습 예측 모델을 사용하여, 상기 하나 이상의 전자 슬라이드 이미지들에 대한 적어도 하나의 라벨에 대한 예측을 결정하는 단계를 포함하고, 상기 기계 학습 예측 모델은,　복수의 훈련 이미지 중 하나를 상기 복수의 훈련 이미지에 대한 복수의 훈련 타일로 분할하고;상기 하나 이상의 전자 슬라이드 이미지들의 배경으로부터 적어도 하나의 조직 영역을 검출함으로써 훈련 조직 마스크를 생성하고;비조직인 것으로 검출된 복수의 타일들 중 적어도 하나를 제거하고;상기 복수의 훈련 이미지의 복수의 시냅틱 주석들의 적어도 하나의 라벨을 사용하여 적어도 하나의 타일-레벨 예측을 추론하기 위해 약한 감독 하에서 상기 기계 학습 예측 모델을 이용하는 것에 의해 생성되는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 비조직인 것으로 결정된 상기 복수의 타일은 상기 조직 표본의 배경인 것으로 더 결정되는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 조직 영역을 상기 배경으로부터 세그먼트화함으로써 상기 하나 이상의 전자 슬라이드 이미지들의 복수의 조직 영역들 및/또는 복수의 타일들을 검출하는 단계를 더 포함하는 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 세그먼트화는 색상, 색상 강도, 및/또는 텍스처 특징들에 기초한 임계화를 사용하는 것을 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 복수의 훈련 이미지는 복수의 전자 슬라이드 이미지 및 복수의 타겟 라벨을 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 약한 감독 하에서 상기 기계 학습 예측 모델을 이용하는 단계는, 다중 인스턴스 학습(MIL), 다중 인스턴스 다중 라벨 학습(MIMLL), 자가-감독된 학습, 및 무감독된 클러스터링을 이용하는 단계를 포함하는, 컴퓨터-구현된 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 약한 감독 하에서 상기 기계 학습 예측 모델을 이용하는 단계는 다중 인스턴스 다중 라벨 러닝(MIMLL), 자가-감독된 학습, 및 무감독된 클러스터링 중 적어도 하나를 이용하는 단계를 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 복수의 훈련 타일에 대한 약하게 감독된 타일-레벨 학습 모듈로부터 적어도 하나의 특징의 복수의 예측을 수신하는 단계;상기 기계 학습 모델을 적용하여, 상기 복수의 훈련 타일에 대해 상기 약하게 감독된 타일-레벨 학습 모듈로부터 상기 적어도 하나의 특징의 복수의 예측들을 입력으로서 취하는 단계; 및　상기 복수의 훈련 타일을 이용하여, 슬라이드 또는 환자 표본에 대한 복수의 라벨을 예측하는 단계를 더 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 복수의 라벨 중 적어도 하나는 이진수, 카테고리, 서수 또는 실수 값인, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 복수의 훈련 타일에 대한 상기 약하게 감독된 타일-레벨 학습 모듈로부터 상기 적어도 하나의 특징의 복수의 예측들을 상기 입력으로서 취하도록 상기 기계 학습 모델을 적용하는 단계는 복수의 이미지 특징들을 포함하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 기계 학습 예측 모델은 적어도 하나의 보이지 않는 슬라이드를 이용하여 적어도 하나의 라벨을 예측하는, 컴퓨터로 구현된 방법.</claim></claimInfo><claimInfo><claim>12. 조직 표본에 대응하는 전자 슬라이드 이미지들을 처리하기 위한 시스템으로서,명령어들을 저장하는 적어도 하나의 메모리; 및상기 명령어들을 실행하여 동작들을 수행하도록 구성된 적어도 하나의 프로세서를 포함하고, 상기 동작들은,　상기 조직 표본과 관련된 하나 이상의 전자 슬라이드 이미지들을 수신하는 것;기계 학습 예측 모델을 사용하여, 상기 하나 이상의 전자 슬라이드 이미지들에 대한 적어도 하나의 라벨에 대한 예측을 결정하는 것을 포함하고,상기 기계 학습 예측 모델은,복수의 훈련 이미지 중 하나를 상기 복수의 훈련 이미지에 대한 복수의 훈련 타일로 분할하고;상기 하나 이상의 전자 슬라이드 이미지들의 배경으로부터 적어도 하나의 조직 영역을 검출함으로써 훈련 조직 마스크를 생성하고;비조직인 것으로 검출된 복수의 타일들 중 적어도 하나를 제거하고;상기 복수의 훈련 이미지의 복수의 시냅틱 주석들의 적어도 하나의 라벨을 사용하여 적어도 하나의 타일-레벨 예측을 추론하기 위해 약한 감독 하에서 상기 기계 학습 예측 모델을 이용하는 것에 의해 생성되는, 시스템.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 비조직인 것으로 결정되는 상기 복수의 훈련 타일은 상기 조직 표본의 배경인 것으로 추가로 결정되는, 시스템.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 조직 영역들을 배경으로부터 세그먼트화함으로써 상기 하나 이상의 전자 슬라이드 이미지의 복수의 조직 영역들 및/또는 복수의 타일들을 검출하는 단계를 더 포함하는 시스템.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 세그먼트화는 색상, 색상 강도, 및/또는 텍스처 특징들에 기초한 임계화를 사용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서, 복수의 훈련 전자 슬라이드 이미지는 복수의 전자 슬라이드 이미지 및 복수의 타겟 라벨을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제12항에 있어서, 약한 감독 하에서 상기 기계 학습 예측 모델을 이용하는 것은, 다중 인스턴스 학습(MIL), 다중 인스턴스 다중 라벨 학습(MIMLL), 자가-감독된 학습, 및 무감독된 클러스터링을 이용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서,상기 복수의 훈련 타일에 대한 약하게 감독된 타일-레벨 학습 모듈로부터 적어도 하나의 특징의 복수의 예측을 수신하는 단계;상기 기계 학습 모델을 적용하여, 상기 복수의 훈련 타일에 대해 상기 약하게 감독된 타일-레벨 학습 모듈로부터 상기 적어도 하나의 특징의 상기 복수의 예측을 입력으로서 취하는 단계; 및　상기 복수의 훈련 타일을 이용하여, 슬라이드 또는 환자 표본에 대한 복수의 라벨을 예측하는 단계를 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 복수의 라벨 중 적어도 하나는 이진수, 카테고리, 서수 또는 실수 값인, 시스템.</claim></claimInfo><claimInfo><claim>20. 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 조직 표본에 대응하는 전자 슬라이드 이미지들을 처리하기 위한 방법을 수행하게 하는 명령어들을 저장하는 비일시적 컴퓨터 판독 가능 매체로서, 상기 방법은,환자 및/또는 의료 케이스와 연관된 조직 표본과 연관된 하나 이상의 전자 슬라이드 이미지들을 수신하는 단계;기계 학습 예측 모델을 사용하여, 상기 하나 이상의 전자 슬라이드 이미지들에 대한 적어도 하나의 라벨에 대한 예측을 결정하는 단계를 포함하고,상기 기계 학습 예측 모델은,복수의 훈련 이미지 중 하나를 상기 복수의 훈련 이미지에 대한 복수의 훈련 타일로 분할하고;상기 하나 이상의 전자 슬라이드 이미지들의 배경으로부터 적어도 하나의 조직 영역을 검출함으로써 훈련 조직 마스크를 생성하고;비조직인 것으로 검출된 상기 복수의 타일 중 적어도 하나를 제거하고;상기 복수의 훈련 이미지의 복수의 시냅틱 주석들의 적어도 하나의 라벨을 사용하여 적어도 하나의 타일-레벨 예측을 추론하기 위해 약한 감독 하에서 상기 기계 학습 예측 모델을 이용하는 것에 의해 생성되는,비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 뉴욕주 뉴욕 타임즈 스퀘어 ** **층</address><code>520180506241</code><country>미국</country><engName>PAIGE.AI, Inc.</engName><name>페이지.에이아이, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 뉴욕주 뉴욕 타임...</address><code> </code><country> </country><engName>ROTHROCK, Brandon</engName><name>로스록 브랜든</name></inventorInfo><inventorInfo><address>미국 ***** 뉴욕주 뉴욕 타임...</address><code> </code><country> </country><engName>KANAN, Christopher</engName><name>카난 크리스토퍼</name></inventorInfo><inventorInfo><address>미국 ***** 뉴욕주 뉴욕 타임...</address><code> </code><country> </country><engName>VIRET, Julian</engName><name>비렛 줄리안</name></inventorInfo><inventorInfo><address>미국 ***** 뉴욕주 뉴욕 타임...</address><code> </code><country> </country><engName>FUCHS, Thomas</engName><name>푹스 토마스</name></inventorInfo><inventorInfo><address>미국 ***** 뉴욕주 뉴욕 타임...</address><code> </code><country> </country><engName>GRADY, Leo</engName><name>그래디 레오</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990004151</code><country>대한민국</country><engName>Kim Yoon Ki</engName><name>김윤기</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.01.28</priorityApplicationDate><priorityApplicationNumber>62/966,716</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application(International Application)] Patent Application</documentEngName><documentName>[분할출원(국제출원)]특허출원서</documentName><receiptDate>2023.09.21</receiptDate><receiptNumber>1-1-2023-1048351-34</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.01.18</receiptDate><receiptNumber>1-1-2024-0068444-51</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237032471.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9367e202351212a42004c63707e32aa7b4ff3b46cefcd3b67182ac0e9808497c7aa3b94ef1b59d9ee36eb428f89a138fee8916807efa767099</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbd98389d5627f7213b130db0683bf924c07de6879dc78292ac1216ce667e991e4a9de467412bd0d3934fea2ebdab86c9a5b4c4554aebde78</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>