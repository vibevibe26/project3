<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:22.422</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.04</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0150845</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비전 정보를 이용하여 전자기기를 제어하는 웨어러블 전자 장치 및 방법</inventionTitle><inventionTitleEng>WEARABLE ELECTRONIC APPARATUS AND METHOD FOR  CONTROLLING ELECTRONIC DEVICES USING VISION  INFORMATION</inventionTitleEng><openDate>2023.05.11</openDate><openNumber>10-2023-0065049</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.06</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 비전 정보를 이용하여 전자기기를 제어하는 웨어러블 장치 및 방법이 개시된다. 일 실시예에 따른 전자 장치는 전자 장치의 주변을 촬영하여 현재 영상을 획득하는 카메라, 사용자 발화를 수신하는 음성 입력 장치, 프로세서, 및 프로세서에 의해 실행될 인스트럭션들(instructions)을 저장하는 적어도 하나의 메모리를 포함하고, 프로세서에 의해 인스트럭션들이 실행될 때, 프로세서는, 수신한 사용자 발화에 기초하여 사용자의 의도를 결정하는 동작, 결정된 의도에 대응되는 타겟 제어 대상 기기를 결정하는 동작, 및 결정된 의도에 기초하여 결정된 타겟 제어 대상 기기를 제어하는 동작을 수행하고, 타겟 제어 대상 기기를 결정하는 동작은, 사용자 발화로부터 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작, 및 사용자 발화로부터 타겟 제어 대상 기기를 결정하는 것이 가능하지 않은 경우, 카메라를 통해 획득된 현재 영상에 기초하여 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 있어서,상기 전자 장치의 주변을 촬영하여 현재 영상을 획득하는 카메라;사용자 발화를 수신하는 음성 입력 장치;프로세서; 및상기 프로세서에 의해 실행될 인스트럭션들(instructions)을 저장하는 적어도 하나의 메모리를 포함하고,상기 프로세서에 의해 상기 인스트럭션들이 실행될 때, 상기 프로세서는,상기 수신한 사용자 발화에 기초하여 사용자의 의도를 결정하는 동작;상기 결정된 의도에 대응되는 타겟 제어 대상 기기를 결정하는 동작; 및상기 결정된 의도에 기초하여 상기 결정된 타겟 제어 대상 기기를 제어하는 동작을 수행하고,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 사용자 발화로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작; 및상기 사용자 발화로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능하지 않은 경우, 상기 카메라를 통해 획득된 상기 현재 영상에 기초하여 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작을 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 현재 영상으로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능한 경우, 상기 현재 영상으로부터 결정된 타겟 제어 대상 기기를 상기 결정된 의도에 대응되는 타겟 제어 대상 기기로 결정하는 동작을 더 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 현재 영상에 기초하여 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작은,상기 현재 영상에서 적어도 하나의 제어 가능 기기를 식별하는 동작; 및상기 식별된 적어도 하나의 제어 가능 기기 중에서 상기 결정된 의도에 대응되는 제어 가능 기기가 있는 경우, 상기 타겟 제어 대상 기기의 결정이 가능한 것으로 판단하는 동작을 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 현재 영상으로부터 상기 타겟 제어 대상 기기의 결정이 가능하지 않은 경우, 상기 현재 영상보다 이전에 획득된 이전 영상에서 식별된 적어도 하나의 제어 가능 기기에 기초하여 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작을 더 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 메모리는,상기 현재 영상과 상기 이전 영상에서 인식될 수 있는 물체에 대한 물체 정보들 및 상기 물체 정보들과 대응되는 적어도 하나의 공간 태그를 저장하는 데이터베이스를 저장하고,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 이전 영상에서 식별된 적어도 하나의 제어 가능 기기로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능하지 않은 경우, 상기 데이터베이스에 저장된 적어도 하나의 공간 태그 중 상기 사용자가 위치한 공간에 대응되는 공간 태그를 결정하는 것이 가능한지 여부를 판단하는 동작을 더 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 공간 태그를 결정하는 것이 가능한 경우, 상기 사용자가 공간 태그를 지정하여 등록한 제어 가능 기기에 대한 정보를 저장하는 사물 인터넷 서버로부터, 상기 사용자가 위치한 공간에 대응되는 공간 태그로 등록된 제어 가능 기기에 대한 정보를 수신하는 동작; 및상기 사물 인터넷 서버로부터 수신한 정보에 상기 결정된 의도에 대응되는 제어 가능 기기가 포함되어 있는 경우, 상기 타겟 제어 대상 기기를 결정하는 것이 가능한 것으로 판단하는 동작을 더 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 타겟 제어 대상 기기를 결정하는 것이 가능한 것으로 판단하는 동작은,상기 사물 인터넷 서버로부터 수신한 정보에 상기 결정된 의도에 대응되는 제어 가능 기기가 2개 이상 포함되어 있는 경우, 상기 전자 장치의 디스플레이 및 상기 전자 장치의 음성 출력 장치 중 적어도 하나를 이용하여 상기 2개 이상의 제어 가능 기기들 중 어떤 제어 가능 기기를 제어할 것인지 사용자에게 질의하는 동작을 더 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 현재 영상은,상기 사용자 발화가 상기 음성 입력 장치에 입력된 시점 이후의 제1 시간 동안 획득된 영상인, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제4항에 있어서,상기 이전 영상은,상기 사용자 발화가 상기 음성 입력 장치에 입력된 시점 이전의 제2 시간 동안 획득된 영상인, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제5항에 있어서,상기 공간 태그를 결정하는 것이 가능한지 여부를 판단하는 동작은,상기 현재 영상에서 물체를 인식하는 동작; 및상기 현재 영상에서 인식된 물체에 대응되는 상기 데이터베이스의 공간 태그에 기초하여 상기 사용자가 위치한 공간에 대응되는 공간 태그를 결정하는 하는 것이 가능한지 여부를 판단하는 동작을 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 공간 태그를 결정하는 것이 가능한지 여부를 판단하는 동작은,상기 현재 영상에서 인식된 물체가 없는 경우, 상기 이전 영상에서 인식된 물체에 대응되는 상기 데이터베이스의 공간 태그에 기초하여 상기 사용자가 위치한 공간에 대응되는 공간 태그를 결정하는 것이 가능한지 여부를 판단하는 동작을 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>12. 제3항에 있어서,상기 현재 영상에서 적어도 하나의 제어 가능 기기를 식별하는 동작은딥 러닝(deep learning) 모델을 이용하여 수행되는, 전자 장치.</claim></claimInfo><claimInfo><claim>13. 비전 정보를 이용하여 전자기기를 제어하는 방법에 있어서,웨어러블 전자 장치의 음성 입력 장치를 통해 사용자 발화를 수신하는 동작;상기 수신한 사용자 발화에 기초하여 사용자의 의도를 결정하는 동작;상기 결정된 의도에 대응되는 타겟 제어 대상 기기를 결정하는 동작; 및상기 결정된 의도에 기초하여 상기 결정된 타겟 제어 대상 기기를 제어하는 동작을 포함하고,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 사용자 발화로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작; 및 상기 사용자 발화로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능하지 않은 경우, 상기 웨어러블 전자 장치의 주변을 촬영하여 현재 영상을 획득하는 카메라를 통해 획득된 상기 현재 영상에 기초하여 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 현재 영상으로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능한 경우, 상기 현재 영상으로부터 결정된 타겟 제어 대상 기기를 상기 결정된 의도에 대응되는 타겟 제어 대상 기기로 결정하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 현재 영상에 기초하여 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작은,상기 현재 영상에서 적어도 하나의 제어 가능 기기를 식별하는 동작; 및상기 식별된 적어도 하나의 제어 가능 기기 중에서 상기 결정된 의도에 대응되는 제어 가능 기기가 있는 경우, 상기 타겟 제어 대상 기기의 결정이 가능한 것으로 판단하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 현재 영상으로부터 상기 타겟 제어 대상 기기의 결정이 가능하지 않은 경우, 상기 현재 영상보다 이전에 획득된 이전 영상에서 식별된 적어도 하나의 제어 가능 기기에 기초하여 상기 타겟 제어 대상 기기를 결정하는 것이 가능한지 여부를 판단하는 동작을 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 타겟 제어 대상 기기를 결정하는 동작은,상기 이전 영상에서 식별된 적어도 하나의 제어 가능 기기로부터 상기 타겟 제어 대상 기기를 결정하는 것이 가능하지 않은 경우, 상기 현재 영상과 상기 이전 영상에서 인식될 수 있는 물체에 대한 물체 정보들 및 상기 물체 정보들과 대응되는 적어도 하나의 공간 태그를 저장하는 데이터베이스에 저장된 적어도 하나의 공간 태그 중 상기 사용자가 위치한 공간에 대응되는 공간 태그를 결정하는 것이 가능한지 여부를 판단하는 동작;상기 공간 태그를 결정하는 것이 가능한 경우, 상기 사용자가 공간 태그를 지정하여 등록한 제어 가능 기기에 대한 정보를 저장하는 사물 인터넷 서버로부터, 상기 사용자가 위치한 공간에 대응되는 공간 태그로 등록된 제어 가능 기기에 대한 정보를 수신하는 동작; 및상기 사물 인터넷 서버로부터 수신한 정보에 상기 결정된 의도에 대응되는 제어 가능 기기가 포함되어 있는 경우, 상기 타겟 제어 대상 기기를 결정하는 것이 가능한 것으로 판단하는 동작을 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 타겟 제어 대상 기기를 결정하는 것이 가능한 것으로 판단하는 동작은,상기 사물 인터넷 서버로부터 수신한 정보에 상기 결정된 의도에 대응되는 제어 가능 기기가 2개 이상 포함되어 있는 경우, 상기 전자 장치의 디스플레이 및 상기 전자 장치의 음성 출력 장치 중 적어도 하나를 이용하여 상기 2개 이상의 제어 가능 기기들 중 어떤 제어 가능 기기를 제어할 것인지 사용자에게 질의하는 동작을 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서,상기 공간 태그를 결정하는 것이 가능한지 여부를 판단하는 동작은,상기 현재 영상에서 물체를 인식하는 동작; 및상기 현재 영상에서 인식된 물체에 대응되는 상기 데이터베이스의 공간 태그에 기초하여 상기 사용자가 위치한 공간에 대응되는 공간 태그를 결정하는 하는 것이 가능한지 여부를 판단하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제13항 내지 제19항 중 어느 한 항의 방법을 실행하는 컴퓨터 프로그램을 저장하는 컴퓨터 판독가능 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Hyunchul WOO</engName><name>우현철</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Gajin SONG</engName><name>송가진</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.11.04</receiptDate><receiptNumber>1-1-2021-1274653-38</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.09.06</receiptDate><receiptNumber>1-1-2024-0982986-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.06</receiptDate><receiptNumber>1-1-2024-0982992-43</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210150845.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93acac1d6f24fbdcd16c480ed0eb409fe37068dc9cfe1fa5e4c0e4dd7d44bae5c92c6e110964788ecc164dfa7a01128f35d42504c8b5ce6e71</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf258eab45f6a5cb5908aa1ab2a7bbbbf64ae798898e1426c452624114a3d3e2fa92ed41089391095436797203c0754eb40a595ed6962a8bbe</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>