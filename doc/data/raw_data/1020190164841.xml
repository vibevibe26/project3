<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:40.3940</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.12.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2019-0164841</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>화자를 인식하는 방법 및 장치</inventionTitle><inventionTitleEng>SPEAKER AUTHENTICATION METHOD, LEARNING METHOD FOR  SPEAKER AUTHENTICATION AND DEVICES THEREOF</inventionTitleEng><openDate>2021.06.21</openDate><openNumber>10-2021-0073975</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.10.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 21/0208</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 19/038</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/04</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 화자를 인식하는 방법 및 장치는 화자의 제1 음성 신호를 수신하고, 제1 음성 신호를 음성 향상시켜 제2 음성 신호를 생성하고, 제1 음성 신호 및 제2 음성 신호를 연관시켜 다중 채널의 음성 신호를 생성하며, 다중 채널의 음성 신호를 기초로 화자를 인식한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 화자의 제1 음성 신호를 수신하는 단계;상기 제1 음성 신호를 음성 향상(speech enhancement)시켜 제2 음성 신호를 생성하는 단계;상기 제1 음성 신호 및 상기 제2 음성 신호를 연관(association)시켜 다중 채널의 음성 신호를 생성하는 단계; 및 상기 다중 채널의 음성 신호를 기초로, 상기 화자를 인식하는 단계를 포함하는, 화자를 인식하는 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제2 음성 신호를 생성하는 단계는 상기 제1 음성 신호로부터 추정된 노이즈 신호를 제거함으로써 상기 제1 음성 신호를 음성 향상시키는 단계; 및 상기 제1 음성 신호로부터 감지된 상기 화자의 음성에 대응하는 에너지를 증가시킴으로써 상기 제1 음성 신호를 음성 향상시키는 단계중 적어도 하나를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 노이즈 신호를 제거함으로써 상기 제1 음성 신호를 음성 향상시키는 단계는상기 제1 음성 신호에서 미니멈 풀링(minimum pooling)을 통해 고정 노이즈 억제(stationary noise suppression)를 수행함으로써 상기 노이즈 신호를 제거하는 단계;상기 제1 음성 신호에서 추정된 노이즈 신호를 제거하는 단계;상기 제1 음성 신호를 채널 정규화(channel normalization)하여 상기 노이즈 신호를 제거하는 단계; 및 상기 제 1 음성 신호를 음원 분리(sound source separation)하여 상기 노이즈 신호를 제거하는 단계중 적어도 하나를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 다중 채널의 음성 신호를 생성하는 단계는상기 제1 음성 신호로부터 상기 화자의 발성 정보가 포함된 제1 특징 벡터를 추출하는 단계;  상기 제2 음성 신호로부터 상기 화자의 발성 정보가 포함된 제2 특징 벡터를 추출하는 단계; 및 상기 제1 특징 벡터 및 상기 제2 특징 벡터를 연관시켜 상기 다중 채널의 음성 신호를 생성하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 제1 특징 벡터를 추출하는 단계는상기 제1 음성 신호로부터 가변 길이의 제1 특징 벡터를 추출하는 단계; 및상기 가변 길이의 제1 특징 벡터로부터 상기 화자의 발성 정보가 포함된 고정 길이의 상기 제1 특징 벡터를 추출하는 단계를 포함하는, 화자를 인식하는 방법</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 고정 길이의 제1 특징 벡터를 추출하는 단계는 상기 가변 길이의 제1 특징 벡터로부터 상기 화자를 인식하도록 트레이닝된 신경망에 대응하는 상기 고정 길이의 제1 특징 벡터를 추출하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서, 상기 제2 특징 벡터를 추출하는 단계는상기 제2 음성 신호로부터 가변 길이의 제2 특징 벡터를 추출하는 단계; 및상기 가변 길이의 제2 특징 벡터로부터 상기 화자의 발성 정보가 포함된 고정 길이의 제2 특징 벡터를 추출하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서, 상기 가변 길이의 제2 특징 벡터를 추출하는 단계는상기 제2 음성 신호의 스펙트럼에 기반한 특징 추출 기법 및 상기 제2 음성 신호의 싱크 함수(sync function)를 기반으로 유효한 발성 주파수 구간을 추출하는 신경망 기반의 특징 추출 기법 중 적어도 하나를 이용하여 상기 가변 길이의 제2 특징 벡터를 추출하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서, 상기 고정 길이의 제2 특징 벡터를 추출하는 단계는 상기 가변 길이의 제2 특징 벡터로부터 상기 화자를 인식하도록 트레이닝된 신경망에 대응하는 상기 고정 길이의 제2 특징 벡터를 추출하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 고정 길이의 제2 특징 벡터를 추출하는 단계는상기 제2 음성 신호의 시간 슬롯 별 프레임들에 대한 에너지에 기초하여 음성 신호의 특징을 추출하는 K-Top Pooling 기법에 의해 상기 고정 길이의 제2 특징 벡터를 추출하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 다중 채널의 음성 신호는 상기 제1 음성 신호 및 상기 제2 음성 신호의 동일 발화 지점에 대응하고, 상기 제1 음성 신호 및 상기 제2 음성 신호와 동일 차원으로 구성되는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 다중 채널의 사용 여부를 결정하는 단계를 더 포함하고, 상기 제2 음성 신호를 생성하는 단계는상기 다중 채널의 사용 여부에 기초하여 상기 제2 음성 신호를 생성하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 다중 채널의 사용 여부를 결정하는 단계는상기 화자를 인식하는 장치의 요구 사항에 따른 연산 부하, 및 응답 속도, 상기 제1 음성 신호에 포함된 정적 노이즈의 크기, 상기 제1 음성 신호에 대응하는 상기 화자의 목소리 크기 중 적어도 하나에 기초하여 상기 다중 채널의 사용 여부를 결정하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서, 상기 다중 채널의 음성 신호를 생성하는 단계는상기 다중 채널의 사용 여부에 기초하여, 상기 다중 채널의 음성 신호를 생성하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 상기 다중 채널의 음성 신호를 생성하는 단계는상기 다중 채널의 개수를 결정하는 단계; 및 상기 다중 채널의 개수에 따라 상기 제1 음성 신호 및 상기 제2 음성 신호를 연관시켜 다중 채널의 음성 신호를 생성하는 단계 를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 다중 채널의 개수를 결정하는 단계는 상기 제1 음성 신호의 특징, 및 상기 제1 음성 신호가 발화된 장소의 노이즈 중 적어도 하나에 기초하여, 상기 다중 채널의 개수를 결정하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 제1 음성 신호의 특징은 상기 제1 음성 신호에 포함된 정적 노이즈의 크기, 상기 제1 음성 신호에 대응하는 상기 화자의 목소리 크기, 및 상기 제1 음성 신호에 대응하는 애디티브 노이즈(additive noise)의 크기 중 적어도 하나를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>18. 제1항에 있어서, 상기 화자를 인식하는 단계는상기 다중 채널의 음성 신호를 신경망에 인가함으로써 상기 화자에 대응하는 제3 특징 벡터를 출력하는 단계;상기 제3 특징 벡터와 상기 화자의 등록 특징 벡터 간의 비교 결과에 따른 유사도 스코어를 산출하는 단계; 및 상기 유사도 스코어에 기초하여 상기 화자를 인식하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>19. 제1항에 있어서, 상기 제1 음성 신호를 수신하는 단계는마이크(microphone)를 포함하는 음성 신호 수집 장치를 통해 상기 제1 음성 신호를 수집하는 단계를 포함하는, 화자를 인식하는 방법.</claim></claimInfo><claimInfo><claim>20. 하드웨어와 결합되어 제1항 내지 제19항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>21. 화자의 제1 음성 신호를 수집하는 마이크; 및 상기 제1 음성 신호를 음성 향상(speech enhancement)시켜 제2 음성 신호를 생성하고, 상기 제1 음성 신호 및 상기 제2 음성 신호를 연관(association)시켜 다중 채널의 음성 신호를 생성하며, 상기 다중 채널의 음성 신호를 기초로, 상기 화자를 인식하는 프로세서를 포함하는, 화자를 인식하는 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420190826158</code><country>대한민국</country><engName>CHO, Sung Jae</engName><name>조성재</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420180507468</code><country>대한민국</country><engName>KIM, Kyu Hong</engName><name>김규홍</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code>420170731631</code><country>대한민국</country><engName>Han, Jae Joon</engName><name>한재준</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2019.12.11</receiptDate><receiptNumber>1-1-2019-1281509-88</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.10.27</receiptDate><receiptNumber>1-1-2022-1139924-63</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.04.23</receiptDate><receiptNumber>9-5-2025-0394350-52</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.06.19</receiptDate><receiptNumber>1-1-2025-0689503-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.06.19</receiptDate><receiptNumber>1-1-2025-0689504-81</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020190164841.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936e5831558f388517b4930cae56fa5baa85ebe5f8363ba4d2312af6dd1249a1c090e26d55959ca496f682305b0de72603651ea7d4cd4162af</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf91f0fe67bb6d8e262beb617236ec63aa253919ee1d2723f96c284ffb68f2aa41f48a6a2ef6a871883907008474043783548f331958053e07</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>