<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:03.533</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.10.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7020776</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다수의 데이터 소스들을 사용한 스피치 전사</inventionTitle><inventionTitleEng>SPEECH TRANSCRIPTION USING MULTIPLE DATA SOURCES</inventionTitleEng><openDate>2022.07.26</openDate><openNumber>10-2022-0104769</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.06.17</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 15/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G10L 17/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>H04N 7/15</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G02B 27/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용은 오디오, 이미지, 및 다른 데이터를 사용하여 스피치를 전사하는 것을 설명한다. 복수의 화자들과 연관된 오디오 데이터를 캡처하도록 구성된 오디오 캡처 시스템, 복수의 화자들 중 하나 이상의 이미지들을 캡처하도록 구성된 이미지 캡처 시스템, 및 스피치 프로세싱 엔진을 포함하는 시스템이 설명된다. 스피치 프로세싱 엔진은 오디오 데이터에서 복수의 스피치 세그먼트를 인식하고, 복수의 스피치 세그먼트들의 각 스피치 세그먼트에 대해 그리고 이미지들에 기반하여, 스피치 세그먼트와 연관된 화자를 식별하고, 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해, 스피치 세그먼트와 연관된 화자의 표시를 포함하는 복수의 스피치 세그먼트들의 전사를 생성하기 위해 복수의 스피치 세그먼트들 각각을 전사하고, 전사로부터 도출된 추가 데이터를 생성하기 위해 전사를 분석하도록 구성될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.05.27</internationOpenDate><internationOpenNumber>WO2021101695</internationOpenNumber><internationalApplicationDate>2020.10.31</internationalApplicationDate><internationalApplicationNumber>PCT/US2020/058432</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 시스템에 있어서,복수의 화자(speaker)들과 연관된 오디오 데이터를 캡처하도록 구성된 오디오 캡처 시스템; 상기 복수의 화자들 중 하나 이상의 이미지들을 캡처하도록 구성된 이미지 캡처 시스템; 및 스피치 프로세싱 엔진(speech processing engine)을 포함하고, 상기 스피치 프로세싱 엔진은: 상기 오디오 데이터에서 복수의 스피치 세그먼트들을 인식하고, 상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해 그리고 상기 이미지들에 기반하여, 상기 스피치 세그먼트와 연관된 화자를 식별하고, 상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해, 상기 스피치 세그먼트와 연관된 상기 화자의 표시를 포함하는 상기 복수의 스피치 세그먼트들의 전사(transcription)를 생성하기 위해, 상기 복수의 스피치 세그먼트들 각각을 전사하고,  상기 전사에서 도출된 추가 데이터를 생성하기 위해 상기 전사를 분석하도록 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 복수의 스피치 세그먼트들을 인식하기 위해, 상기 스피치 프로세싱 엔진은 상기 이미지들에 기반하여, 상기 복수의 스피치 세그먼트들을 인식하도록 추가로 구성되고;바람직하게는, 상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해 상기 화자를 식별하기 위해, 상기 스피치 프로세싱 엔진은 상기 이미지들에서 하나 이상의 얼굴들을 검출하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 상기 스피치 프로세싱 엔진은 각각의 스피치 세그먼트와 연관된 상기 화자의 아이덴티티에 기반하여, 하나 이상의 스피치 인식 모델들을 선택하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서, 상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해 상기 화자를 식별하기 위해, 상기 스피치 프로세싱 엔진은 상기 이미지들에서 입술들이 움직이는 하나 이상의 얼굴들을 검출하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제 1 항 내지 제 4 항 중 어느 한 항에 있어서, 상기 스피치 프로세싱 엔진은 외부 데이터에 액세스하도록 추가로 구성되고; 상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해 상기 화자를 식별하기 위해, 상기 스피치 프로세싱 엔진은:상기 외부 데이터에 기반하여 상기 화자를 식별하도록 추가로 구성되고;바람직하게는 외부 데이터는 캘린더 정보 및 위치 정보 중 하나 이상을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제 3 항 내지 제 5 항 중 어느 한 항에 있어서, 사용자에 의해 착용될 수 있는 HMD(head-mounted display)를 더 포함하고, 상기 하나 이상의 스피치 인식 모델들은 상기 사용자에 대한 음성 인식 모델을 포함하고;바람직하게는, 상기 HMD는 인공 현실 콘텐츠를 출력하도록 구성되고, 상기 인공 현실 콘텐츠는 비디오 스트림 및 오디오 스트림을 포함하는 가상 회의 애플리케이션을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>7. 제 3 항 내지 제 5 항 중 어느 한 항에 있어서, 사용자에 의해 착용될 수 있는 HMD(head-mounted display)를 더 포함하고, 상기 스피치 프로세싱 엔진은 상기 복수의 스피치 세그먼트들의 속성들에 기반하여 상기 HMD의 사용자를 상기 복수의 스피치 세그먼트들의 화자로서 식별하도록 추가로 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제 1 항 내지 제 7 항 중 어느 한 항에 있어서, 상기 오디오 캡처링 시스템은 마이크로폰 어레이를 포함하고;바람직하게는 상기 추가 데이터는 상기 복수의 화자들 중 적어도 하나와 연관된 스피치 세그먼트들의 수정된 버전을 포함하는 오디오 스트림을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제 1 항 내지 제 8 항 중 어느 한 항에 있어서, 상기 추가 데이터는 상기 전사에서 설명된 회의 또는 이벤트에 대한 캘린더 초대(calendar invitation), 상기 전사에서 식별된 주제들과 관련된 정보, 또는 상기 전사에서 식별된 작업들을 포함하는 작업 목록 중 하나 이상을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>10. 제 1 항 내지 제 9 항 어느 한 항에 있어서, 상기 추가 데이터는: 상기 화자에 의해 말해진 단어들의 수, 상기 화자의 톤, 상기 화자에 의해 사용된 필러 단어(filler word)들에 관한 정보, 상기 화자가 말한 시간의 백분율, 사용된 욕설에 관한 정보, 사용된 단어들의 길이에 관한 정보, 전사의 요약 또는 상기 화자의 감정을 포함하는 상기 전사에 관한 통계 중 적어도 하나를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 방법에 있어서,복수의 화자들과 연관된 오디오 데이터를 캡처하는 단계; 상기 복수의 화자들 중 하나 이상의 이미지들을 캡처하는 단계; 상기 오디오 데이터에서 복수의 스피치 세그먼트들을 인식하는 단계;상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해 그리고 상기 이미지들에 기반하여, 상기 스피치 세그먼트와 연관된 화자를 식별하는 단계;상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해, 상기 스피치 세그먼트와 연관된 상기 화자의 표시를 포함하는 상기 복수의 스피치 세그먼트들의 전사를 생성하기 위해 상기 복수의 스피치 세그먼트들 각각을 전사하는 단계; 및 상기 전사에서 도출된 추가 데이터를 생성하기 위해 상기 전사를 분석하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,외부 데이터에 액세스하는 단계; 및 상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해, 상기 외부 데이터에 기반하여 상기 화자를 식별하는 단계를 더 포함하고;바람직하게는 상기 외부 데이터는 캘린더 정보 및 위치 정보 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제 11 항 또는 제 12 항에 있어서, 상기 추가 데이터는 상기 전사에서 설명된 회의 또는 이벤트에 대한 캘린더 초대, 상기 전사에서 식별된 주제들과 관련된 정보, 또는 상기 전사에서 식별된 작업들을 포함하는 작업 목록 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제 11 항 내지 제 13 항 어느 한 항에 있어서, 상기 추가 데이터는: 상기 화자에 의해 말해진 단어들의 수, 상기 화자의 톤, 상기 화자에 의해 사용된 필러 단어들에 관한 정보, 상기 화자가 말한 시간의 백분율, 사용된 욕설에 관한 정보, 사용된 단어들의 길이에 관한 정보, 전사의 요약 또는 상기 화자의 감정을 포함하는 상기 전사에 관한 통계 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 명령들을 포함하는 컴퓨터-판독가능 저장 매체에 있어서,상기 명령들은, 실행될 때:복수의 화자들과 연관된 오디오 데이터를 캡처하고; 상기 복수의 화자들 중 하나 이상의 이미지들을 캡처하고; 상기 오디오 데이터에서 복수의 스피치 세그먼트들을 인식하고;상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해 그리고 상기 이미지들에 기반하여, 상기 스피치 세그먼트와 연관된 화자를 식별하고;상기 복수의 스피치 세그먼트들의 각각의 스피치 세그먼트에 대해, 상기 스피치 세그먼트와 연관된 상기 화자의 표시를 포함하는 상기 복수의 스피치 세그먼트들의 전사를 생성하기 위해 상기 복수의 스피치 세그먼트들 각각을 전사하고; 상기 전사에서 도출된 추가 데이터를 생성하기 위해 상기 전사를 분석하도록 컴퓨팅 시스템의 프로세싱 회로를 구성하는, 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 ***** 멘로 파크, 윌로우 로드 ****</address><code>520150001761</code><country>미국</country><engName>Meta Platforms Technologies, LLC</engName><name>메타 플랫폼즈 테크놀로지스, 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 ****...</address><code> </code><country> </country><engName>CHEUNG, Vincent Charles</engName><name>청 빈센트 찰스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ****...</address><code> </code><country> </country><engName>BAI, Chengxuan</engName><name>바이 쳉쑤언</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ****...</address><code> </code><country> </country><engName>SHENG, Yating Sasha</engName><name>셍 야팅 사샤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 세종대로 ***, **층 (세종로, 광화문빌딩)(법무법인센트럴)</address><code>919990006014</code><country>대한민국</country><engName>HOON CHANG</engName><name>장훈</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.11.20</priorityApplicationDate><priorityApplicationNumber>16/689,662</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.06.17</receiptDate><receiptNumber>1-1-2022-0635751-38</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.06.23</receiptDate><receiptNumber>1-5-2022-0093630-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2022.07.29</receiptDate><receiptNumber>4-1-2022-5178788-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.10.11</receiptDate><receiptNumber>1-1-2023-1112774-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.10.11</receiptDate><receiptNumber>1-1-2023-1112800-79</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227020776.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93fadba541b6eabba9099fde4bc075bdf619d624f8e69843e0c6939e9cff2f9bb62ded2ed826d9407f898804b2322df4a54a9780655907c054</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf83e22141e7e6467cda42fbdc8cdf8a3c99c1d71e222feaf703e0ff7307e7be84f6ab9cf70d7df36281d54e4cb2a081dc658245a6533bf3a2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>