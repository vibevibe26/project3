<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:42.5142</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.04.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0042414</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사용자의 제스처를 인식하는 방법, 장치, 시스템 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>Method, apparatus, system and computer program  for recognizing gesture of user</inventionTitleEng><openDate>2023.10.12</openDate><openNumber>10-2023-0143471</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/772</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 사용자의 제스처를 인식하는 방법, 장치, 시스템 및 컴퓨터 프로그램에 관한 것으로서, 보다 구체적으로는 사용자의 손동작 등이 촬영되는 영상에서 복수의 단위 동작을 포함하여 구성되는 제스처를 인식하는 방법, 장치, 시스템 및 컴퓨터 프로그램에 관한 것이다. 본 발명에서는, 제스처 학습 장치가 영상 내의 제스처를 인식할 수 있는 신경망을 학습시키는 방법에 있어서, 인식하고자 하는 제스처에 대한 하나 이상의 제스처 영상을 분석하여 상기 제스처 영상에 포함되는 둘 이상의 단위 동작과 각 단위 동작이 수행되는 시간에 대한 정보를 포함하는 단위 동작 분석 데이터를 산출하는 단계; 및 상기 단위 동작 분석 데이터를 학습 데이터에 포함시켜 상기 제스처를 인식하는 신경망에 대한 학습을 수행하는 단계;를 포함하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법을 개시한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 제스처 학습 장치가, 영상 내의 제스처를 인식할 수 있는 신경망을 학습시키는 방법에 있어서,인식하고자 하는 제스처에 대한 하나 이상의 제스처 영상을 분석하여 상기 제스처 영상에 포함되는 둘 이상의 단위 동작과 각 단위 동작이 수행되는 시간에 대한 정보를 포함하는 단위 동작 분석 데이터를 산출하는 단계; 및상기 단위 동작 분석 데이터를 학습 데이터에 포함시켜 상기 제스처를 인식하는 신경망에 대한 학습을 수행하는 단계;를 포함하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 단위 동작 분석 데이터를 산출하는 단계는,상기 제스처 영상을 복수의 구간으로 분할하여 분할된 각 구간에 대한 대표 이미지를 산출하는 단계; 및상기 대표 이미지를 미리 구성된 단위 동작 데이터베이스에 포함되는 이미지와 대비하여 상기 각 구간에 포함되는 단위 동작을 식별하는 단계;를 포함하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 단위 동작 데이터베이스는,복수의 이미지를 유사도 기준으로 상기 복수의 단위 동작에 대응하도록 복수의 그룹으로 분류된 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 단위 동작 데이터베이스에서 상기 복수의 그룹 중 제1 그룹에 속하는 제1 이미지와 상기 제1 그룹에 속하지 않는 제2 이미지의 특성을 조합하여 상기 제1 그룹에 속하는 이미지를 증강(augmentation)하는 단계;를 더 포함하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서,상기 단위 동작을 식별하는 단계에서는,상기 각 구간에 대하여 식별된 단위 동작을 시간 순서에 따라 배열하여 상기 단위 동작 분석 데이터를 산출하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서,상기 단위 동작 분석 데이터는,상기 인식 대상 영상을 미리 정해진 시간 주기로 분할한 각 구간 중 상기 각 단위 동작이 수행된 구간에 대한 정보를 포함하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 단위 동작 분석 데이터를 산출하는 단계에서는,상기 인식하고자 하는 제스처에 대한 하나 이상의 제스처 영상의 일부 특성을 변경하여 상기 제스처 영상을 증강(augmentation)하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 하나 이상의 제스처 영상을 전송한 디바이스의 사용자에게 상기 학습된 신경망을 이용하여 상기 제스처에 대한 인식을 위한 서비스를 제공하는 제스처 인식 서비스 제공 단계;를 더 포함하는 것을 특징으로 하는 제스처 인식 신경망 학습 방법.</claim></claimInfo><claimInfo><claim>9. 제스처 인식 장치가, 인식 대상 영상을 분석하여 제스처를 인식하는 방법에 있어서,복수 종류의 단위 동작 중 상기 인식 대상 영상에 포함되는 둘 이상의 단위 동작과 각 단위 동작이 수행되는 시간에 대한 정보를 포함하는 단위 동작 분석 데이터를 산출하는 단계; 및상기 단위 동작 분석 데이터를 입력받아 제스처를 인식하도록 학습된 신경망을 이용하여 상기 둘 이상의 단위 동작을 포함하여 구성되는 제스처를 인식하는 단계;를 포함하는 것을 특징으로 하는 제스처 인식 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 단위 동작 분석 데이터를 산출하는 단계는,상기 인식 대상 영상을 복수의 구간으로 분할하여 분할된 각 구간에 대한 대표 이미지를 산출하는 단계; 및상기 대표 이미지를 미리 구성된 단위 동작 데이터베이스에 포함되는 이미지와 대비하여 상기 각 구간에 포함되는 단위 동작을 식별하는 단계;를 포함하는 것을 특징으로 하는 제스처 인식 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 단위 동작을 식별하는 단계에서는,상기 각 구간에 대하여 식별된 단위 동작을 시간 순서에 따라 배열하여 상기 단위 동작 분석 데이터를 산출하는 것을 특징으로 하는 제스처 인식 방법.</claim></claimInfo><claimInfo><claim>12. 제9항에 있어서,상기 제스처를 인식하는 단계에서는,상기 단위 동작 분석 데이터를 미리 학습된 신경망으로 입력하여 상기 제스처를 인식하는 것을 특징으로 하는 제스처 인식 방법.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,상기 단위 동작 분석 데이터는,상기 인식 대상 영상을 미리 정해진 시간 주기로 분할한 각 구간 중 상기 각 단위 동작이 수행된 구간에 대한 정보를 포함하는 것을 특징으로 하는 제스처 인식 방법.</claim></claimInfo><claimInfo><claim>14. 제9항에 있어서,상기 제스처 인식 장치는 가상 현실, 증강 현실 또는 확장 현실 환경에서 상기 인식 대상 영상을 실시간으로 분석하여 미리 정의된 제스처를 인식하는 것을 특징으로 하는 제스처 인식 방법.</claim></claimInfo><claimInfo><claim>15. 컴퓨터에서 제1항 내지 제14항 중 어느 한 항에 기재된 방법의 각 단계를 실행시키기 위한 컴퓨터로 판독 가능한 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>219980054563</code><country>대한민국</country><engName>KT Corporation</engName><name>주식회사 케이티</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>Lee, Jung Jun</engName><name>이정준</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 역삼로***,*층(역삼동,성보역삼빌딩)</address><code>920041000211</code><country>대한민국</country><engName>HMP IP GROUP</engName><name>특허법인충정</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.04.05</receiptDate><receiptNumber>1-1-2022-0364256-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2022.08.08</receiptDate><receiptNumber>4-1-2022-5185849-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.03.21</receiptDate><receiptNumber>1-1-2025-0322256-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>4-1-2025-5080836-48</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220042414.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9335bbea9beb7c6cc6db6adf1f898d89d5ed6a3010b7404fb24b0045b5c50a670d950e6334451aee0aee00bf4f8c46e9272233bc4eef94f627</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe1cae543f338d2d6ffdb9a691d1495ac2574af646e9093d95d92cbd97bfed076985a29f4be7b2a6b3fa986d3601517e45d72099639faa5b9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>