<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:13:46.1346</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.05.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0062283</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>가변 초점 카메라의 깊이 추정 방법</inventionTitle><inventionTitleEng>METHOD FOR DEPTH ESTIMATION FOR A VARIABLE FOCUS  CAMERA</inventionTitleEng><openDate>2022.11.29</openDate><openNumber>10-2022-0157329</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.05.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/571</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 서로 다른 초점 위치에서 카메라에 의해 촬영된 복수의 이미지로부터 깊이 정보를 추출하기 위한 컴퓨터로 구현된 방법으로, 미리 결정된 초점 스케줄에 따라 서로 다른 초점 위치에서 카메라로 장면의 이미지 시퀀스를 캡처하고, 기계 학습 알고리즘을 통해 처리하여 2차원 깊이 맵을 생성한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 서로 다른 초점 위치에서 카메라에 의해 촬영된 복수의 이미지로부터 깊이 정보를 추출하기 위한 컴퓨터로 구현된 방법(800)에 있어서,카메라의 초점 위치들의 시간 순서를 지정하는 미리 결정된 초점 스케줄에 따라 서로 다른 초점 위치에서 카메라로 장면의 이미지 시퀀스를 캡처하는 단계(801);합성곱 신경망을 포함하는 기계 학습 알고리즘에 의해 미리 결정된 수의 캡처된 이미지의 이미지 특징을 추출하고 상기 추출된 이미지 특징을 저장하는 단계(802),상기 미리 결정된 수의 캡처된 이미지로부터 이미지 특징을 추출 및 저장한 후, 상기 기계 학습 알고리즘에 의해 이미지 특징이 아직 추출되지 않은 캡처된 이미지를 처리하는 단계(803) - 상기 캡처된 이미지는 현재 처리된 이미지를 나타냄;미리 결정된 초점 스케줄에 명시된 초점 위치들과 적어도 하나의 생성된 다차원 텐서를 사용하여 2차원 깊이 맵을 생성하는 단계(807);를 포함하되,상기 처리하는 단계는 상기 기계 학습 알고리즘에 의해 현재 처리된 이미지로부터 이미지 특징을 추출하고 추출된 이미지 특징을 저장하는 단계(804)를 포함하고,상기 처리하는 단계는 이전에 캡처된 이미지로부터 저장된 이미지 특징을 현재 처리된 이미지의 이미지 특징과 정렬하는(aligning) 단계(805)와, 현재 처리된 이미지의 이미지 특징에 정렬된 처리된 이미지 중 적어도 일부의 이미지 특징을 나타내는 적어도 하나의 다차원 텐서를 생성하는 단계(806)를 더 포함하는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,이미지 특징은 폭 차원(W), 높이 차원(H)과 채널 차원(C)을 포함하는 3차원 특징 텐서로 추출되되 상기 채널 차원은 합성곱 신경망의 하나 이상의 레이어를 통해 이미지로부터 추출된 특징 맵(feature maps)의 수를 명시하고,추출된 이미지 특징을 저장하는 단계는 추출된 이미지 특징을 3차원 특징 텐서의 리스트로 저장하는 단계를 포함하는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항 내지 제 2 항 중 어느 하나의 항에 있어서,이전에 캡처된 이미지로부터 저장된 이미지 특징을 현재 처리된 이미지의 이미지 특징과 정렬하는 단계는 이전에 캡쳐된 이미지로부터 저장된 이미지 특징과 현재 처리된 이미지의 이미지 특징에 4차원 인코딩을 적용하는 단계를 포함하고,상기 4차원 인코딩은 시간 정보, 공간 정보 및 초점 위치 정보를 이전에 캡처된 이미지의 이미지 특징과 현재 처리된 이미지의 이미지 특징에 임베딩하는 단계를 포함하는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항 내지 제 3 항 중 어느 하나의 항에 있어서,4차원 인코딩은 비선형 및/또는 4차원 인코딩은 현재 처리된 이미지의 이미지 특징과 이전에 캡쳐된 이미지로부터 저장된 이미지 특징 각각에 추가하는 것을 통해 적용되는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항 내지 제 4 항 중 어느 하나의 항에 있어서, 4차원 인코딩은 삼각함수를 사용하는 것에 기초하는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>6. 제 1 항 내지 제 5 항 중 어느 하나의 항에 있어서,미리 결정된 초점 스케줄에 명시된 초점 위치와 적어도 하나의 생성된 다차원 텐서를 사용하는 2차원 깊이 맵을 생성하는 단계는 기계 학습 알고리즘에 의해 적어도 하나의 다차원 초점 확률 맵을 생성하는 단계와, 상기 적어도 하나의 다차원 초점 확률 맵을 미리 결정된 초점 스케줄에 명시된 초점 위치를 사용하여 실제 물리적 거리에 재매핑(remapping)하는 단계를 포함하는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항 내지 제 6 항 중 어느 하나의 항에 있어서,적어도 하나의 다차원 초점 확률 맵은 폭 차원(W), 높이 차원(H)과 초점 위치 차원(N)을 갖는 3차원 텐서이고, 상기 초점 위치 차원은 초점 위치의 수를 명시하고,폭과 높이 차원의 크기는 입력 이미지의 폭과 높이 차원의 크기와 동일하고,상기 입력 이미지는 미리 결정된 수의 캡처된 이미지 중의 하나의 이미지 또는 현재 처리된 이미지인, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항 내지 제 7 항 중 어느 하나의 항에 있어서, 미리 결정된 초점 스케줄에 명시된 초점 위치를 사용하여 실제 물리적 거리에 대한 적어도 하나의 다차원 초점 확률 맵을 재매핑하는 단계는 적어도 하나의 다차원 초점 확률 맵의 각 픽셀과 초점 스케줄 내의 초점 위치 사이의 내적(dot product)을 계산하는 단계를 포함하는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>9. 제 1 항 내지 제 8 항 중 어느 하나의 항에 있어서, 현재 처리된 이미지의 이미지 특징에 정렬된 모든 처리된 이미지의 이미지 특징을 나타내는 적어도 하나의 생성된 다차원 텐서는 폭 차원(W)과, 높이 차원(H)과, 채널 차원(C)과, 초점 위치 차원(N)을 포함하는 4차원 텐서이되 상기 채널 차원은 합성곱 신경망의 하나 이상의 레이어에 의해 처리된 이미지로부터 추출된 특징 맵의 수를 명시하고, 상기 초점 위치 차원은 초점 위치의 수를 명시하는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>10. 제 1 항 내지 제 9 항 중 어느 하나의 항에 있어서,미리 결정된 수의 캡처된 이미지의 이미지 특징을 추출하는 단계와 현재 처리된 이미지의 이미지 특징을 추출하는 단계는 기계 학습 알고리즘에 의해 상이한 스케일의 이미지 특징을 추출하는 단계를 더 포함하고, 상기 스케일은 입력 이미지의 높이의 비율 및/또는 입력 이미지의 폭의 비율로 정의되며, 상기 입력 이미지는 미리 결정된 수의 캡처된 이미지 중의 하나의 이미지 또는 현재 처리된 이미지 인, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>11. 제 1 항 내지 제 10 항 중 어느 하나의 항에 있어서, 미리 결정된 수의 캡처된 이미지로부터 추출된 이미지 특징과 현재 처리된 이미지로부터 추출된 이미지 특징은 원형 버퍼인 컴퓨터 판독 가능한 메모리에 저장되되 원형 버퍼는 미리 결정된 수의 캡처된 이미지의 이미지 특징을 저장할 수 있고 및/또는 적어도 캡처된 이미지의 미리 결정된 수는 적어도 초점 스케줄에 명시된 서로 다른 초점 위치의 수보다 크거나 같은, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>12. 제 1 항 내지 제 11 항 중 어느 하나의 항에 있어서,합성곱 신경망은 복수의 상이한 장면에 대하여 상이한 초점 위치에 초점을 맞춘 복수의 이미지를 포함하는 학습 샘플에 대해 학습된 합성곱 신경망이고, 상기 장면은 정적 또는 동적이며, 합성곱 신경망 파라미터는 손실 함수를 사용하여 합성곱 신경망에 의해 생성된 추정된 깊이 맵과 대응하는 알려진 정답 깊이 맵을 비교함으로써 최적화되는, 깊이 정보 추출 방법.</claim></claimInfo><claimInfo><claim>13. 컴퓨터 메모리;하나 이상의 프로세서(CPU 및/또는 GPU);를 포함하되,컴퓨터 메모리는 서로 다른 초점 위치에서 카메라에 의해 촬영된 복수의 이미지로부터 깊이 정보를 추출하는 제 1 항 내지 제 12 항 중 어느 하나의 방법을 수행하도록 하나 이상의 프로세서에 지시하는 명령을 저장하는, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서, 상기 컴퓨팅 시스템은 서로 다른 초점 위치로 장면의 이미지를 캡처하도록 구성된 카메라를 포함하는 휴대형 모바일 장치(예, 스마트폰)인, 컴퓨팅 시스템.</claim></claimInfo><claimInfo><claim>15. 컴퓨터 시스템에 의해 실행될 때 서로 다른 초점 위치에서 카메라에 의해 촬영된 복수의 이미지로부터 깊이 정보를 추출하는 제 1 항 내지 제 12 항 중 어느 하나의 방법을 수행하는 컴퓨터 실행 가능 명령을 저장하기 위한 컴퓨터로 판독 가능한 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>스페인 마드리드 ***** 칼레 벨라스케스 ***</address><code>520190327355</code><country>스페인</country><engName>WOOPTIX, S.L.</engName><name>웁틱스, 에스.엘.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>스페인 마드리드 ***** **-...</address><code> </code><country> </country><engName>Ceruso SABATO</engName><name>세루소 사바토</name></inventorInfo><inventorInfo><address>스페인 마드리드 ***** **-...</address><code> </code><country> </country><engName>Ricardo Oliva GARCIA</engName><name>리카르도 올리바 가르시아</name></inventorInfo><inventorInfo><address>스페인 마드리드 ***** **-...</address><code> </code><country> </country><engName>Jose Manuel Rodriguez RAMOS</engName><name>호세 마누엘 로드리게스 라모스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로*길 **, *층 ***호실(역삼동, 청원빌딩)</address><code>920101000618</code><country>대한민국</country><engName>SINJI PATENT FIRM</engName><name>특허법인 신지</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2021.05.20</priorityApplicationDate><priorityApplicationNumber>21382458.4</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.05.20</receiptDate><receiptNumber>1-1-2022-0537920-82</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(EPO)</documentEngName><documentName>우선권주장증명서류제출서(EPO)</documentName><receiptDate>2022.05.26</receiptDate><receiptNumber>9-1-2022-9006235-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.05.19</receiptDate><receiptNumber>9-5-2025-0469916-20</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.06.20</receiptDate><receiptNumber>4-1-2025-5168463-52</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.07.16</receiptDate><receiptNumber>1-1-2025-0807125-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.07.16</receiptDate><receiptNumber>1-1-2025-0807145-28</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220062283.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c8d6c0a9f4e161c6e3b7e9dc7364283945c5fd53cefeb403ef8a979699f177ddfb696f18c56f699122848a21ca2144e309675c62926275ee</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4777c4153bb9864d25f752f3e64c6fe2b4b41a636c4c5f77072d61485680b3b003f44aa578348c9b360276989630dae2fee35a3c812da463</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>