<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:03.63</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0156891</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>포즈 추정 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS WITH POSE ESTIMATION</inventionTitleEng><openDate>2023.05.23</openDate><openNumber>10-2023-0070872</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/543</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/593</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06V 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 포즈 추정 방법 및 장치가 제공된다. 일 실시예에 따르면, 그 방법은 서로 직교하는 평면들을 포함하는 타겟 장면의 깊이를 센싱하여 깊이 데이터를 획득하고, 상기 깊이 데이터의 깊이 포인트들에 대응하는 법선 벡터들을 결정하고, 상기 법선 벡터들을 자세 후보들과 비교하여 상기 디바이스의 자세 데이터를 추정하고, 상기 디바이스로부터 상기 평면들까지의 거리들에 기초하여 상기 디바이스의 위치 데이터를 추정하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디바이스의 포즈 추정 방법에 있어서,서로 직교하는 평면들을 포함하는 타겟 장면의 깊이를 센싱하여 깊이 데이터를 획득하는 단계;상기 깊이 데이터의 깊이 포인트들에 대응하는 법선 벡터들을 결정하는 단계;상기 법선 벡터들을 자세 후보들과 비교하여 상기 디바이스의 자세 데이터를 추정하는 단계; 및상기 디바이스로부터 상기 평면들까지의 거리들에 기초하여 상기 디바이스의 위치 데이터를 추정하는 단계를 포함하는 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 서로 직교하는 평면들은서로 직교하는 벽면들, 및 상기 벽면들과 직교하는 바닥면 중 적어도 일부를 포함하는,포즈 추정 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 법선 벡터들을 결정하는 단계는상기 깊이 데이터를 3차원 공간으로 역투영하여 상기 깊이 포인트들에 대응하는 장면 포인트들을 포함하는 3차원 공간 데이터를 생성하는 단계;상기 3차원 공간 데이터의 제1 장면 포인트 및 상기 제1 장면 포인트에 이웃하여 배치된 이웃 장면 포인트들에 기초하여 제1 국부 평면을 결정하는 단계; 및상기 제1 국부 평면의 법선에 기초하여 상기 제1 장면 포인트의 제1 법선 벡터를 결정하는 단계를 포함하는, 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 자세 데이터를 추정하는 단계는상기 법선 벡터들과 상기 자세 후보들 간의 매칭을 수행하면서 상기 자세 후보들의 매칭 수를 측정하는 단계; 및상기 자세 후보들의 상기 매칭 수에 기초하여 상기 자세 데이터를 추정하는 단계를 포함하는, 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 법선 벡터들은 제1 법선 벡터를 포함하고,상기 매칭 수를 측정하는 단계는상기 자세 후보들 중 상기 제1 법선 벡터와 직교 관계 또는 평행 관계에 있는 적어도 일부를 상기 제1 법선 벡터와 매칭하는 단계를 포함하는,포즈 추정 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 위치 데이터를 추정하는 단계는상기 디바이스로부터 상기 평면들까지의 거리들 및 상기 자세 데이터에 기초하여 장면 좌표계를 결정하는 단계; 및상기 장면 좌표계에서 상기 디바이스의 현재 위치에 대응하는 좌표를 결정하는 단계를 포함하는, 포즈 추정 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 평면들은 서로 직교하는 벽면들, 및 상기 벽면들과 직교하는 바닥면을 포함하고,상기 장면 좌표계를 결정하는 단계는상기 자세 데이터에 기초하여 상기 장면 좌표계의 좌표 축을 정렬하는 단계; 및상기 벽면들 및 상기 바닥면의 교점을 상기 장면 좌표계의 원점으로 결정하는 단계를 포함하는,포즈 추정 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 깊이 데이터를 획득하는 단계는상기 디바이스의 깊이 센서 및 카메라 중 적어도 하나로 상기 타겟 장면을 센싱하는 단계를 포함하는,포즈 추정 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 깊이 데이터는 현재 시점의 센싱 데이터로부터 획득되고,상기 자세 데이터 및 상기 위치 데이터는 상기 현재 시점의 절대 추정치에 해당하고, 다른 시점의 센싱 데이터와 독립적으로 결정되는,포즈 추정 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 포즈 추정 방법은이전 시점의 센싱 데이터와 상기 현재 시점의 상기 센싱 데이터 간의 비교에 따른 상대 추정치 및 상기 현재 시점의 상기 센싱 데이터에 따른 상기 절대 추정치에 기초하여 상기 현재 시점의 포즈를 추정하는 단계를 더 포함하는,포즈 추정 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 상대 추정치는VIO(visual inertial odometry) 및 SLAM(simultaneous localization and mapping)의 적어도 일부를 이용하여 결정되는,포즈 추정 방법.</claim></claimInfo><claimInfo><claim>12. 하드웨어와 결합되어 제1항 내지 제11항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 프로세서; 및상기 프로세서에서 실행가능한 명령어들을 포함하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에서 실행되면, 상기 프로세서는서로 직교하는 평면들을 포함하는 타겟 장면의 깊이를 센싱하여 깊이 데이터를 획득하고,상기 깊이 데이터의 깊이 포인트들에 대응하는 법선 벡터들을 결정하고,상기 법선 벡터들을 자세 후보들과 비교하여 디바이스의 자세 데이터를 추정하고,상기 디바이스로부터 상기 평면들까지의 거리들에 기초하여 상기 디바이스의 위치 데이터를 추정하는,포즈 추정 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 서로 직교하는 평면들은서로 직교하는 벽면들, 및 상기 벽면들과 직교하는 바닥면 중 적어도 일부를 포함하는,포즈 추정 장치.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 프로세서는상기 깊이 데이터를 3차원 공간으로 역투영하여 상기 깊이 포인트들에 대응하는 장면 포인트들을 포함하는 3차원 공간 데이터를 생성하고,상기 3차원 공간 데이터의 제1 장면 포인트 및 상기 제1 장면 포인트에 이웃하여 배치된 이웃 장면 포인트들에 기초하여 제1 국부 평면을 결정하고,상기 제1 국부 평면의 법선에 기초하여 상기 제1 장면 포인트의 제1 법선 벡터를 결정하는,포즈 추정 장치.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 프로세서는상기 법선 벡터들과 상기 자세 후보들 간의 매칭을 수행하면서 상기 자세 후보들의 매칭 수를 측정하고,상기 자세 후보들의 상기 매칭 수에 기초하여 상기 자세 데이터를 추정하는,포즈 추정 장치.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서,상기 프로세서는상기 디바이스로부터 상기 평면들까지의 거리들 및 상기 자세 데이터에 기초하여 장면 좌표계를 결정하고,상기 장면 좌표계에서 상기 디바이스의 현재 위치에 대응하는 좌표를 결정하는,포즈 추정 장치.</claim></claimInfo><claimInfo><claim>18. 서로 직교하는 평면들을 포함하는 타겟 장면의 깊이를 센싱하여 깊이 데이터를 생성하는 센싱 장치; 및상기 깊이 데이터의 깊이 포인트들에 대응하는 법선 벡터들을 결정하고, 상기 법선 벡터들을 자세 후보들과 비교하여 디바이스의 자세 데이터를 추정하고, 상기 디바이스로부터 상기 평면들까지의 거리들에 기초하여 상기 디바이스의 위치 데이터를 추정하는, 프로세서를 포함하고,상기 서로 직교하는 평면들은서로 직교하는 벽면들, 및 상기 벽면들과 직교하는 바닥면 중 적어도 일부를 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 프로세서는상기 법선 벡터들과 상기 자세 후보들 간의 매칭을 수행하면서 상기 자세 후보들의 매칭 수를 측정하고,상기 자세 후보들의 상기 매칭 수에 기초하여 상기 자세 데이터를 추정하는,전자 장치.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 프로세서는상기 디바이스로부터 상기 평면들까지의 거리들 및 상기 자세 데이터에 기초하여 장면 좌표계를 결정하고,상기 장면 좌표계에서 상기 디바이스의 현재 위치에 대응하는 좌표를 결정하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 송파구...</address><code>420170474303</code><country>대한민국</country><engName>CHANG, Hyun Sung</engName><name>장현성</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420190573582</code><country>대한민국</country><engName>KIM, Seung Eon</engName><name>김승언</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170495152</code><country>대한민국</country><engName>SON, Minjung</engName><name>손민정</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170474144</code><country>대한민국</country><engName>LEE, Won Hee</engName><name>이원희</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170474417</code><country>대한민국</country><engName>JUNG, Kyung Boo</engName><name>정경부</name></inventorInfo><inventorInfo><address>경상북도 포항시 남구...</address><code>420180163128</code><country>대한민국</country><engName>HA, Inwoo</engName><name>하인우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.11.15</receiptDate><receiptNumber>1-1-2021-1315852-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.26</receiptDate><receiptNumber>1-1-2024-1050421-70</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210156891.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c932adeac86893106b3f49843f4fe6cf95da7bfdbaa5ab3cb2163d753c3e36287474d8272bf2d194d91a44cb4041f3f882c16fb3701552aae40</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff0ec8b851941c223c46cf0920a74ad45af82ada7f15a4d98328c957504b740948d8bd93d8fd758fe4083b0ffa69b695c9be9898b26b00909</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>