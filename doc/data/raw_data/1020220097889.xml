<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:00.370</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.08.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0097889</applicationNumber><claimCount>9</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>Fusion SLAM 방법 및 시스템</inventionTitle><inventionTitleEng>Fusion SLAM method and system</inventionTitleEng><openDate>2024.02.14</openDate><openNumber>10-2024-0019995</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.08.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> Fusion SLAM 방법 및 시스템이 제공된다. 본 발명의 실시예에 따른 Fusion SLAM 방법은 Lidar SLAM과 Vision SLAM을 융합하여 로봇의 위치를 추정하되, 두 SLAM이 모두 잘 동작하지 않는 경우에는 로봇의 Encoder 정보를 이용하여 로봇 위치를 추정한다. 이에 의해 사용 환경이나 장애물 등에 따라 달라지는 SLAM의 신뢰도를 예측하고, 각 SLAM 결과의 가중치를 실시간으로 조정하여 최적의 Fusion SLAM 결과를 얻을 수 있게 된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 제1 SLAM 기법을 이용하여 로봇의 위치를 추정하는 제1 추정단계;제2 SLAM 기법을 이용하여 로봇의 위치를 추정하는 제2 추정단계;제1 추정단계에서 추정된 위치와 제2 추정단계에서 추정된 위치를 가중합하여 로봇의 위치를 계산하는 단계;를 포함하는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서,계산단계는,제1 SLAM 기법에 의한 위치 인식지수인 제1 위치 인식지수가 제1 임계값을 초과하거나 제2 SLAM 기법에 의한 위치 인식지수인 제2 위치 인식지수가 제2 임계값을 초과하는 경우에 수행되는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>3. 청구항 1에 있어서,계산단계는,제1 추정단계에서 추정된 위치에 제1 가중치를 적용하고, 제2 추정단계에서 추정된 위치에 제2 가중치를 적용하며, 제1 가중치는,현재 환경에서 제1 SLAM 기법의 신뢰도를 기초로 결정되고,제2 가중치는,현재 환경에서 제2 SLAM 기법의 신뢰도를 기초로 결정되는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 3에 있어서,제1 SLAM 기법의 신뢰도는,제1 위치 인식지수를 기초로 산정되고,제2 SLAM 기법의 신뢰도는,제2 위치 인식지수를 기초로 산정되는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 4에 있어서,제1 SLAM 기법의 신뢰도는,제1 위치 인식지수가 제1 임계값 근방에서 급격하게 낮아지도록 하는 제1 함수를 이용하여 산정되고,제2 SLAM 기법의 신뢰도는,제2 위치 인식지수가 제2 임계값 근방에서 급격하게 낮아지도록 하는 제2 함수를 이용하여 산정되는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 5에 있어서,제1 함수는,제1 임계값 만큼 평행 이동시킨 sigmoid 함수이고,제2 함수는,제2 임계값 만큼 평행 이동시킨 sigmoid 함수인 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 3에 있어서,제1 가중치와 제2 가중치는,외부 환경에 의해 상대적 비중이 추가로 조정되는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>8. 청구항 2에 있어서,제1 SLAM 기법에 의한 위치 인식지수가 제1 임계치 이하이고 제2 SLAM 기법에 의한 위치 인식지수가 제2 임계치 이하이면, 로봇의 엔코더 정보를 이용하여 로봇의 위치를 추정하는 제3 추정단계;를 더 포함하는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 1에 있어서,제1 SLAM 기법에 의한 결과와 제2 SLAM 기법에 의한 결과를 좌표 정렬하되, 오차가 임계값 미만이 될 때까지 주행하면서 반복하는 단계;를 더 포함하는 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 1에 있어서,제1 SLAM 기법은,거리 센서를 이용한 SLAM 기법이고,제2 SLAM 기법은,Vision 센서를 이용한 SLAM 기법인 것을 특징으로 하는 Fusion SLAM 방법.</claim></claimInfo><claimInfo><claim>11. 제1 센서;제2 센서; 및제1 센서 기반의 제1 SLAM 기법을 이용하여 로봇의 위치를 추정하고, 제2 센서 기반의 제2 SLAM 기법을 이용하여 로봇의 위치를 추정하며, 제1 SLAM 기법으로 추정된 위치와 제2 SLAM 기법으로 추정된 위치를 가중합하여 로봇의 위치를 계산하는 프로세서;를 포함하는 것을 특징으로 하는 Fusion SLAM 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>충청북도 청주시 서원구...</address><code>120210875825</code><country>대한민국</country><engName>Vista Technology Co.,Ltd</engName><name>비스타테크놀러지 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>HWANG, Young Bae</engName><name>황영배</name></inventorInfo><inventorInfo><address>경기도 용인시 수지구...</address><code> </code><country> </country><engName>KIM, Yong Jun</engName><name>김용준</name></inventorInfo><inventorInfo><address>충청북도 청주시 흥덕구...</address><code> </code><country> </country><engName>LEE, Jae Hem</engName><name>이재흠</name></inventorInfo><inventorInfo><address>충청북도 청주시 흥덕구...</address><code> </code><country> </country><engName>CHO, Tae Sang</engName><name>조태상</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 ***, *층(역삼동, 광진빌딩)(알렉스국제특허법률사무소)</address><code>920050001097</code><country>대한민국</country><engName>Sung Hwan Yang</engName><name>양성환</name></agentInfo><agentInfo><address>서울 강남구 언주로 ***, *층(역삼동, 광진빌딩)(알렉스국제특허법률사무소)</address><code>920050001136</code><country>대한민국</country><engName>Han Geena</engName><name>한지나</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.08.05</receiptDate><receiptNumber>1-1-2022-0821595-75</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2022.08.18</receiptDate><receiptNumber>1-1-2022-0861862-98</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2022.12.28</receiptDate><receiptNumber>1-1-2022-1414129-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.04.03</receiptDate><receiptNumber>9-5-2025-0331370-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.05.14</receiptDate><receiptNumber>1-1-2025-0539189-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.05.14</receiptDate><receiptNumber>1-1-2025-0539225-18</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220097889.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93dc2217b8f493de222b09ed0936f1677ab5574fbee039bd666a9ead5122342de350a7846d3c5df835d50a2ff4f7312e658b75e7b5b37ea9df</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf8a39ebcce26d6f075cc1fd3dc76a97e8905cbf67e9511307666da93e067b6e666a4cf587f57e4d2146c93e3f00aea823f83f6ccdade9564d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>