<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:11:16.1116</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0153993</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>간헐적으로 수퍼바이징되는 단안 깊이 추정을 위한 깊이 에지 개선 방법</inventionTitle><inventionTitleEng>DEPTH EDGES REFINEMENT METHOD FOR SPARSELY SUPERVISED  MONOCULAR DEPTH ESTIMATION</inventionTitleEng><openDate>2024.05.16</openDate><openNumber>10-2024-0067048</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/13</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 깊이 추정을 위한 시스템 및 방법이 제공된다. 시스템 및 방법의 한 실시예는 이미지를 획득하는 것을 포함할 수 있다. 시스템 및 방법의 또 다른 실시예는 MDE(Monocular Depth Estimation) 네트워크를 사용하여 이미지의 깊이 맵을 생성하는 것을 포함하며, MDE 네트워크는 DEE(Depth Edge Estimation) 네트워크에 의해 생성된 에지 데이터를 포함하는 트레이닝 데이터를 사용하여 트레이닝될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지를 획득하는 단계; 및MDE(Monocular Depth Estimation) 네트워크를 사용하여 상기 이미지의 깊이 맵을 생성하는 단계를 포함하고,상기 MDE 네트워크는 DEE(Depth Edge Estimation) 네트워크에 의해 생성된 에지 데이터를 포함하는 트레이닝 데이터를 사용하여 트레이닝되는, 방법.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서,상기 깊이 맵에 기초하여 물체의 경계를 표시하는 단계를 더 포함하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 깊이 맵에 기초하여 내비게이션 정보를 생성하는 단계를 더 포함하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 MDE 네트워크와 동일한 장치에 있는 카메라를 사용하여 상기 이미지를 캡쳐하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 깊이 맵은 상기 이미지의 픽셀에 대한 깊이 추정을 포함하고, 상기 에지 데이터는 트레이닝 이미지의 픽셀에 대한 에지의 확률을 포함하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>6. DEE(Depth Edge Estimation) 네트워크에 의해 생성된 슈도 실측 에지 데이터(pseudo ground-truth edge data)를 포함하는 트레이닝 데이터를 획득하는 단계; 및상기 트레이닝 데이터를 사용해 MDE(Monocular Depth Estimation) 네트워크를 트레이닝하여 깊이 맵을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 6에 있어서,상기 깊이 맵에 기초하여 예측 에지 데이터를 생성하는 단계; 및상기 예측 에지 데이터 및 상기 슈도 실측 에지 데이터에 기초하여 에지 손실을 계산하는 단계를 더 포함하고,상기 MDE 네트워크는 상기 에지 손실에 기초하여 트레이닝되는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>8. 청구항 6에 있어서,합성 이미지 및 합성 에지 데이터를 포함하는 합성 트레이닝 데이터를 획득하는 단계; 및상기 합성 트레이닝 데이터에 기초하여 상기 DEE 네트워크를 트레이닝하는 단계를 더 포함하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 6에 있어서,실제 이미지를 획득하는 단계; 및DEE 네트워크를 트레이닝한 후 상기 실제 이미지에 기초하여 상기 슈도 실측 에지 데이터를 생성하는 단계를 더 포함하는 것을 특징으로 하는, 방법.</claim></claimInfo><claimInfo><claim>10. 적어도 하나의 메모리 구성요소;상기 적어도 하나의 메모리 구성요소에 결합되는 적어도 하나의 프로세싱 장치; 및이미지의 깊이 맵을 생성하도록 구성된 MDE(Monocular Depth Estimation) 네트워크를 포함하고, 상기 MDE 네트워크는 DEE(Depth Edge Estimation) 네트워크에 의해 생성된 에지 데이터를 포함하는 트레이닝 데이터를 사용하여 트레이닝되고,상기 적어도 하나의 프로세싱 장치는 상기 적어도 하나의 메모리 구성요소에 저장된 명령어들을 실행하도록 구성되는, 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>DANA, Alexandra</engName><name>다나 알렉산드라</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>COHEN, Aviad</engName><name>코헨 아비애드</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YOSEF, Erez</engName><name>요세프 에레즈</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>DINERSTEIN, Michael</engName><name>다이너스타인 마이클</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>BEN-Dror, Amir</engName><name>벤 드로르 아미르</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>TALKER, Lior</engName><name>토커 리오르</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.11.08</priorityApplicationDate><priorityApplicationNumber>63/423,622</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.07.18</priorityApplicationDate><priorityApplicationNumber>18/354,039</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.08</receiptDate><receiptNumber>1-1-2023-1236886-58</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.11.15</receiptDate><receiptNumber>9-1-2023-9012499-78</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.11.15</receiptDate><receiptNumber>9-1-2023-9012508-02</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230153993.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93db8b76472a45e38f90f3c131f1b838704b1714eb9acf7dab2e559883c4bfe02168a0fd05e70ed60f99d1e55851eae88bc001ded81f1a6b6c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf9940cf183a4cd1ef65833005ab4a68dfab4343dfcedd4a8574f2a8e42c54289b2b480249e92e09dbf83fd4aefaac78a18d164b8e694242ef</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>