<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:02.42</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2025.05.19</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2025-0064779</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>LIDAR를 사용한 대상체 식별</inventionTitle><inventionTitleEng>IDENTIFYING OBJECTS USING LIDAR</inventionTitleEng><openDate>2025.07.02</openDate><openNumber>10-2025-0099664</openNumber><originalApplicationDate>2021.10.20</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2021-0140353</originalApplicationNumber><originalExaminationRequestDate>2025.06.18</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/931</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/89</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/24</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/521</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G01S 7/48</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 111/10</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020210140353</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 무엇보다도, LiDAR를 사용하여 식별된 차량 기반 대상체의 움직임을 제어 회로를 사용하여 제어하기 위한 기술이 설명되어 있다. 예를 들어, 포인트 클라우드의 포인트의 각자의 등급이 결정되고, 결정된 포인트 클라우드의 포인트의 각자의 등급에 기반하여 차량 주변의 대상체가 식별된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,적어도 하나의 프로세서를 사용하여, 포인트 클라우드 내의 복수의 포인트들과 연관된 LiDAR 포인트 클라우드 데이터를 수신하는 단계;상기 적어도 하나의 프로세서를 사용하여, 상기 포인트 클라우드 내의 상기 복수의 포인트들에 기초하여 상기 포인트 클라우드의 제1 뷰 및 상기 포인트 클라우드의 제2 뷰를 생성하는 단계 - 상기 제2 뷰는 상기 제1 뷰와 상이함 -;상기 적어도 하나의 프로세서를 사용하여, 상기 제1 뷰를 제1 뷰 신경 네트워크에 대한 입력으로서 제공하고 상기 제2 뷰를 제2 뷰 신경 네트워크에 대한 입력으로서 제공하는 단계 - 상기 제2 뷰 신경 네트워크는 상기 제1 뷰 신경 네트워크와 상이함 -;상기 적어도 하나의 프로세서를 사용하여, 상기 포인트 클라우드 내의 각각의 포인트에 대해, 상기 제1 뷰 신경 네트워크를 사용하여 대상체 클래스들을 나타내는 제1 클래스 점수 세트를 생성하고 상기 제2 뷰 신경 네트워크를 사용하여 상기 대상체 클래스들을 나타내는 제2 클래스 점수 세트를 생성하는 단계 - 상기 제1 클래스 점수 세트와 상기 제2 클래스 점수 세트는 병렬로 생성됨 -;상기 적어도 하나의 프로세서를 사용하여, 상기 포인트 클라우드 내의 적어도 하나의 포인트에 대한 완성된 라벨을 결정하는 단계 - 상기 결정하는 단계는 상기 적어도 하나의 포인트의 상기 제1 클래스 점수 세트 및 상기 적어도 하나의 포인트의 상기 제2 클래스 점수 세트에 기초함 -;상기 적어도 하나의 프로세서를 사용하여, 상기 적어도 하나의 포인트의 상기 완성된 라벨에 적어도 부분적으로 기초하여 차량 부근에 있는 적어도 하나의 대상체를 식별하는 단계; 및상기 적어도 하나의 프로세서를 사용하여, 상기 적어도 하나의 대상체에 기초하여 상기 차량의 모션을 제어하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 포인트 클라우드 내의 적어도 하나의 포인트에 대한 완성된 라벨을 결정하는 상기 단계는:상기 포인트 클라우드에서 적어도 하나의 불확실한 포인트를 결정하는 단계 - 상기 결정하는 단계는 상기 적어도 하나의 불확실한 포인트의 상기 제1 클래스 점수 세트 및 상기 적어도 하나의 불확실한 포인트의 상기 제2 클래스 점수 세트에 기초함 -;융합 신경 네트워크를 사용하여, 상기 적어도 하나의 불확실한 포인트의 상기 제1 클래스 점수 세트 및 상기 적어도 하나의 불확실한 포인트의 상기 제2 클래스 점수 세트 중 적어도 하나에 기초하여 상기 적어도 하나의 불확실한 포인트에 대한 제3 클래스 점수 세트를 생성하는 단계 - 상기 제3 클래스 점수 세트는 상기 적어도 하나의 불확실한 포인트의 이웃 포인트들의 특성들에 기초함 -; 및상기 제3 클래스 점수 세트에 기초하여, 상기 적어도 하나의 프로세서를 사용하여, 상기 적어도 하나의 불확실한 포인트의 완성된 라벨을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 LiDAR 포인트 클라우드 데이터는 상기 포인트 클라우드에 포함된 적어도 하나의 포인트와 연관된 색상에 관한 정보를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 또는 제2항에 있어서, 상기 뷰들 중 적어도 하나는 BeV(Birds-eye View) 또는 RV(Range View)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 또는 제2항에 있어서, 상기 LiDAR 포인트 클라우드 데이터는 포인트 강도 정보를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서, 특정 포인트의 상기 제1 클래스 점수 세트, 상기 제2 클래스 점수 세트 또는 상기 제3 클래스 점수 세트에 포함된 적어도 하나의 클래스 점수는 미리 정의된 대상체 클래스에 대응하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제2항에 있어서, 상기 제1 뷰 신경 네트워크, 상기 제2 뷰 신경 네트워크 및 상기 융합 신경 네트워크 중 적어도 하나는 적어도 하나의 순환 계층을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 또는 제2항에 있어서, 상기 제1 뷰를 제1 뷰 신경 네트워크에 대한 입력으로서 제공하고 상기 제2 뷰를 제2 뷰 신경 네트워크에 대한 입력으로서 제공하는 단계는:상기 제1 뷰를 제1 뷰 신경 네트워크에 대한 입력으로서 제공하고 상기 제2 뷰를 제2 뷰 신경 네트워크에 대한 입력으로서 제공하는 단계 - 상기 제1 뷰 또는 상기 제2 뷰는 데이터 증강에 적어도 부분적으로 기초하여 생성됨 - 를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제2항에 있어서, 상기 불확실한 포인트는 클래스 점수들의 임계 차이와 관련하여 결정되며, 상기 임계 차이는 확률 함수 또는 필터링 함수 또는 둘 모두 중 적어도 하나에 기초하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 또는 제2항에 있어서, 상기 적어도 하나의 불확실한 포인트에 대한 클래스 점수는 상기 적어도 하나의 불확실한 포인트의 이웃 포인트들의 연결된 특징(feature)들에 기초하여 결정되는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 연결된 특징들은 상기 제1 뷰 신경 네트워크 및 상기 제2 뷰 신경 네트워크의 중간 계층들의 중간 출력을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 연결된 특징들은 상기 제1 뷰 신경 네트워크 및 상기 제2 뷰 신경 네트워크 중 적어도 하나로부터의 출력 클래스 점수들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제2항에 있어서, 상기 융합 신경 네트워크는 다층 퍼셉트론(perceptron) 또는 콘볼루션(convolutional) 계층 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 차량으로서,복수의 LiDAR 데이터 포인트들을 포함하는 LiDAR 스캔 포인트 클라우드를 생성할 수 있는 적어도 하나의 LiDAR 디바이스; 및상기 LiDAR 디바이스에 결합된 프로세싱 회로 - 상기 프로세싱 회로는 제1항의 방법을 수행하도록 구성됨 - 를 포함하는, 차량.</claim></claimInfo><claimInfo><claim>15. 제1 디바이스의 적어도 하나의 프로세서에 의해 실행하기 위한 적어도 하나의 프로그램을 포함하는 비일시적 컴퓨터 판독 가능 저장 매체로서, 상기 적어도 하나의 프로그램은, 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 제1 디바이스로 하여금 제1항의 방법을 수행하게 하는 명령어들을 포함하는, 비일시적 컴퓨터 판독 가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매사추세츠주 보스턴 노던 애비뉴 ***</address><code>520200342330</code><country>미국</country><engName>Motional AD LLC</engName><name>모셔널 에이디 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>싱가포르 ****** 싱가포르...</address><code> </code><country>필리핀</country><engName>LIONG, Venice Erin Baylon</engName><name>리옹 베니스 에린 바이론</name></inventorInfo><inventorInfo><address>싱가포르 ****** 싱가포르...</address><code> </code><country>베트남</country><engName>NGUYEN, Tho Thi Ngoc</engName><name>응우옌 소 티 응옥</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.10.21</priorityApplicationDate><priorityApplicationNumber>63/094,809</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.18</priorityApplicationDate><priorityApplicationNumber>17/504,449</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2025.05.19</receiptDate><receiptNumber>1-1-2025-0558682-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2025.06.04</receiptDate><receiptNumber>1-5-2025-0092690-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment(Payer number)</documentEngName><documentName>[출원서 등 보정]보정서(납부자번호)</documentName><receiptDate>2025.06.18</receiptDate><receiptNumber>1-1-2025-0623636-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.06.18</receiptDate><receiptNumber>1-1-2025-0682468-16</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.06.18</receiptDate><receiptNumber>1-1-2025-0682469-62</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020250064779.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b50b5d14733fc9b3f2ae2298f3334767f07df7f9aa9060ae848d6559d51eda134883ced09d8114ea00b6c5a1c2b73bad797b81becc9dda11</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0ce06e803298f607531823c6ad81592b97a103be669a0209666907b6be72b3925aa67b4a39bf346abec3a2fba25c8a1b708a2846bc64e94f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>