<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:35.4035</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7020430</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오 행동 인식을 위한 다중 해상도 어텐션 네트워크</inventionTitle><inventionTitleEng>A MULTI-RESOLUTION ATTENTION NETWORK FOR VIDEO ACTION RECOGNITION</inventionTitleEng><openDate>2023.07.10</openDate><openNumber>10-2023-0104737</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.06.16</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/21</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 분석을 위해 비디오 클립을 수신하는 단계, 클립 내의 각각의 프레임에 대한 4D 임베딩 텐서를 생성하기 위해 컨볼루션 신경망 메커니즘(CNN)을 클립 내의 프레임들 각각에 적용하는 단계, 감소된 해상도 블록들의 시퀀스를 생성하기 위해 다중 해상도 컨볼루션 신경망 메커니즘(CNN)을 클립 내의 프레임들 각각에 적용하는 단계, 블록 내의 모션의 양을 추정하는 운동학 어텐션 가중치를 계산하는 단계, 클립 내의 각각의 프레임에 대한 임베딩 텐서들에 어텐션 가중치들을 적용하여, 클립 내의 모든 프레임들을 표현하는 가중된 임베딩 텐서 또는 컨텍스트를 해상도에서 생성하는 단계, 모든 해상도들에 걸쳐 컨텍스트들을 조합하여 다중 해상도 컨텍스트를 생성하는 단계, 1D 특징 벡터를 획득하기 위해 3D 풀링을 수행하는 단계, 특징 벡터에 기초하여 비디오 클립의 예비 행동을 분류하는 단계에 의해 비디오 클립에 출현하는 행동을 분류한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.05.19</internationOpenDate><internationOpenNumber>WO2022104281</internationOpenNumber><internationalApplicationDate>2021.11.16</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/059568</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 비디오 클립(video clip)에 출현하는 행동(action)들을 분류하기 위한 컴퓨터 구현 방법으로서, 분석을 위한 비디오 클립을 수신하는 단계 - 상기 비디오 클립은 비디오 프레임들의 시간 시퀀스를 포함함 -;상기 클립 내의 각각의 프레임에 대한 4D 임베딩 텐서(embedding tensor)를 생성하기 위해 상기 클립 내의 프레임들에 컨볼루션 신경망 메커니즘(CNN : convolutional neural network mechanism)을 적용하는 단계 - 상기 4차원은 클립 내의 비디오 프레임들의 시퀀스에 의해 표현된 시간, 특징(feature)들, 이미지 폭(image width) 및 이미지 높이(image height)임 -;감소된 해상도 운동학 텐서(reduced resolution kinematic tensor)들의 시퀀스를 생성하기 위해 상기 클립의 프레임들 각각에 다중 해상도(multi-resolution) 컨볼루션 신경망 메커니즘(CNN)을 적용하는 단계 - 각각의 상기 운동학 텐서는 감소된 해상도들 중 하나에서의 프레임을 나타냄 -; 각각의 감소된 해상도 운동학 텐서에 대해, 감소된 해상도에서 대응하는 비디오 클립에서의 모션(motion)의 양을 추정하는 운동학 어텐션 가중치(kinematic attention weight)를 계산하는 단계; 각각의 해상도에 대해, 상기 클립 내의 각각의 프레임에 대한 상기 임베딩 텐서들에 상기 어텐션 가중치들을 적용하여, 상기 클립 내의 모든 프레임들을 나타내는 컨텍스트(context)로 지칭되는 가중된(weighted) 임베딩 텐서를 상기 해상도에서 생성하는 단계; 모든 해상도에 걸쳐 상기 컨텍스트(context)를 조합하여 다중 해상도 컨텍스트를 생성하는 단계;특징 벡터(feature vector)에서의 각각의 값이 대응하는 특징의 상대적 중요도를 나타내는 1D 특징 벡터를 획득하기 위해 상기 다중 해상도 어텐션의 3D 풀링(pooling)을 수행하는 단계; 및 상기 특징 벡터에 기초하여 상기 비디오 클립의 예비 행동(primary action)을 분류하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 특징 벡터에 기초하여 상기 비디오 클립을 분류하는 단계는 행동 분류 세트 내의 각각의 행동 클래스에 대한 확률을 계산하는 단계를 포함하고, 행동 클래스 확률은 대응하는 행동이 상기 비디오 클립에서 발생했을 가능성을 특정하는, 방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 각각의 행동 클래스에 대한 확률을 계산하는 단계는, 상기 행동 분류 세트 내의 각각의 클래스에 대한 확률로 귀결되는, 상기 행동 분류 세트를 나타내는 1D 행동 클래스 벡터와 상기 1D 특징 벡터 사이의 선형 변환을 수행하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 하나 이상의 특징들을 제거하는 드롭아웃 메커니즘(dropout mechanism)을 상기 특징 벡터에 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 각각의 연속적인 감소된 해상도 임베딩 텐서는 이전의 감소된 해상도 임베딩 텐서의 해상도의 절반(half)인, 방법. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 감소된 해상도 운동학 텐서에 다중 해상도 어텐션 메커니즘(multi-resolution attention mechanism)을 적용하는 단계는,대응하는 비디오 프레임 내의 각각의 공간 위치에서의 상기 모션을 나타내는 각각의 해상도에서 각각의 프레임에 대한 텐서를 계산하는 단계; 및상기 폭, 높이 및 특징 차원을 컬랩스(collapse)하는 3D 풀링 연산을 수행하여 각각의 해상도에서 각각의 프레임에 대한 스칼라 어텐션 가중치를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 다중 해상도 어텐션의 3D 풀링을 수행하는 단계는 상기 운동학 텐서의 폭, 높이, 및 특징 차원들을 평균화하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 감소된 해상도 운동학 텐서들의 시퀀스를 생성하는 단계는,새로운 컨볼루션 계층을 생성하기 위해 컨볼루션 신경망 연산을 수행하는 단계; 쌍선형 보간(bilinear interpolation), 평균화(averaging), 가중화(weighting), 서브샘플링(subsampling), 또는 2D 풀링 함수 적용으로 이루어진 그룹으로부터 선택된 기술을 사용하여 상기 새로운 컨볼루션 계층의 해상도를 감소시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 비디오에서의 상기 모션의 양을 추정하는 운동학 어텐션 가중치를 계산하는 단계는,시간 t에 기초한 1차 유한 도함수(first order finite derivative), 2차 유한 도함수(second order finite derivative) 및 절대 위치로 이루어진 그룹으로부터 선택된 방법을 사용하여 시간 t에서 비디오 프레임의 텐서 표현을 생성하는 단계; 및 상기 텐서 표현을 평균 프레임 값 주위에 집중화하는 단계(centralizing)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 모든 해상도들에 걸쳐 상기 컨텍스트들을 조합하는 단계는,각 해상도의 상기 컨텍스트를 스택하는 단계(stacking); 및각각의 2D 공간 위치에 대한 특징 값을 갖는 단일 3D 텐서를 계산하는 단계를 포함하는, 방법. </claim></claimInfo><claimInfo><claim>11. 서버 컴퓨터에 있어서,프로세서;상기 프로세서와 통신하는 통신 인터페이스; 비디오 클립들을 저장하기 위한 데이터 저장소; 및명령어들을 저장하기 위해 상기 프로세서와 통신하는 메모리를 포함하되, 상기 명령어들이 상기 프로세서에 의해 실행될 때 상기 서버가,분석을 위한 비디오 클립을 수신하고 - 상기 비디오 클립은 비디오 프레임들의 시간 시퀀스를 포함함 -;상기 클립 내의 각각의 프레임에 대한 4D 임베딩 텐서를 생성하기 위해 클립 내의 프레임들에 컨볼루션 신경망 메커니즘(CNN : convolutional neural network mechanism)을 적용하고 - 상기 4 차원은 상기 클립 내의 비디오 프레임들의 시퀀스에 의해 표현되는 시간, 특징들, 이미지 폭 및 이미지 높이임 -;감소된 해상도 운동학 텐서(kinematic tensor)들의 시퀀스를 생성하기 위해 상기 클립의 프레임들 각각에 다중 해상도 컨볼루션 신경망 메커니즘(CNN)을 적용하고 - 각각의 운동학 텐서는 감소된 해상도들 중 하나에서의 프레임을 나타냄 -; 각각의 감소된 해상도 운동학 텐서에 대해, 상기 감소된 해상도에서 대응하는 비디오 클립에서의 모션의 양을 추정하는 운동학 어텐션 가중치(kinematic attention weight)를 계산하고; 각각의 해상도에 대해, 클립 내의 각 프레임에 대한 상기 임베딩 텐서들에 어텐션 가중치들을 적용하여, 상기 클립 내의 모든 프레임들을 나타내는 컨텍스트(context)로 지칭되는 가중된 임베딩 텐서를 상기 해상도에서 생성하고; 모든 해상도에서 컨텍스트를 조합하여 다중 해상도 컨텍스트를 생성하고;특징 벡터에서의 각각의 값이 대응하는 특징의 상대적 중요도를 나타내는 1D 특징 벡터를 획득하기 위해 상기 다중 해상도 어텐션의 3D 풀링을 수행하고; 및 상기 특징 벡터에 기초하여 비디오 클립의 예비 행동(primary action)을 분류하게 하는, 서버 컴퓨터. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 특징 벡터에 기초하여 상기 비디오 클립을 분류하는 것은 행동 분류 세트 내의 각각의 행동 클래스에 대한 확률을 계산하는 것을 포함하고, 행동 클래스 확률은 대응하는 행동이 상기 비디오 클립에서 발생했을 가능성을 특정하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 각각의 행동 클래스에 대한 확률을 계산하는 것은 상기 행동 분류 세트 내의 각각의 클래스에 대한 확률로 귀결되는, 상기 행동 분류 세트를 나타내는 1D 행동 클래스 벡터와 상기 1D 특징 벡터 사이의 선형 변환을 수행하는 것을 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 메모리는 추가로 상기 서버가,하나 이상의 특징을 제거하는 드롭아웃 메커니즘을 특징 벡터에 적용하게 하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 각각의 연속적인 감소된 해상도 임베딩 텐서는 이전의 감소된 해상도 임베딩 텐서의 해상도의 절반인, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 감소된 해상도 운동학 텐서에 다중 해상도 어텐션 메커니즘을 적용하는 것은,대응하는 비디오 프레임 내의 각각의 공간 위치에서의 모션을 나타내는 각각의 해상도에서 각각의 프레임에 대한 텐서를 계산하는 것; 및상기 폭, 높이 및 특징 차원을 컬랩스하는 3D 풀링 연산을 수행하여 각 해상도에서 각 프레임에 대한 스칼라 어텐션 가중치를 생성하는 것을 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 다중 해상도 어텐션의 3D 풀링을 수행하는 것은 상기 운동학 텐서의 폭, 높이, 및 특징 차원들을 평균화하는 것을 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 감소된 해상도 운동학 텐서들의 시퀀스를 생성하는 것은,새로운 컨볼루션 계층을 생성하기 위해 컨볼루션 신경망 연산을 수행하는 것; 쌍선형 보간, 평균화, 가중화, 서브샘플링, 또는 2D 풀링 함수 적용으로 이루어진 그룹으로부터 선택된 기술을 사용하여 새로운 컨볼루션 계층의 해상도를 감소시키는 것을 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 비디오에서 상기 모션의 양을 추정하는 운동학 어텐션 가중치를 계산하는 것은,시간 t에 기초한 1차 유한 도함수(first order finite derivative), 2차 유한 도함수(second order finite derivative) 및 절대 위치로 이루어진 그룹으로부터 선택된 방법을 사용하여 시간 t에서 비디오 프레임의 텐서 표현을 생성하는 것; 및 상기 텐서 표현을 평균 프레임 값 주위에 집중화하는 것을 포함하는, 서버 컴퓨터.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서, 상기 모든 해상도들에 걸쳐 상기 컨텍스트들을 조합하는 것은,각각의 해상도의 컨텍스트를 스택하는 것; 및각각의 2D 공간 위치에 대한 특징 값을 갖는 단일 3D 텐서를 계산하는 것을 포함하는, 서버 컴퓨터.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 *****, 셔먼 옥스, 스위트 ****, 벤 추라 불러버드 *****</address><code>520230330757</code><country>미국</country><engName>BEN GROUP, INC.</engName><name>벤 그룹, 인크.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 *****, 셔먼...</address><code> </code><country> </country><engName>CARVALHO, Schubert R.</engName><name>카발로, 슈버트 알.</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****, 셔먼...</address><code> </code><country> </country><engName>FOLKMAN, Tyler</engName><name>포크만, 타일러</name></inventorInfo><inventorInfo><address>미국 캘리포니아 *****, 셔먼...</address><code> </code><country> </country><engName>BUTLER, Richard Ray</engName><name>버틀러, 리처드 레이</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 **길 **-*(역삼동, AIP빌딩)</address><code>920091000214</code><country>대한민국</country><engName>AIP Patent &amp; Law Firm</engName><name>특허법인에이아이피</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.11.16</priorityApplicationDate><priorityApplicationNumber>63/114,344</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.06.16</receiptDate><receiptNumber>1-1-2023-0663851-31</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.06.20</receiptDate><receiptNumber>1-5-2023-0097618-26</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.11.12</receiptDate><receiptNumber>1-1-2024-1240966-97</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237020430.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c026f56c50df1eba6cdc4eabd854f4e019b7feda02cc0925b99f65faa7acfe7b495fafd141a2fccbcf75a76fffa4341ab515c8c4d95ac816</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cffa2bdca3ffd61b84691144f35a236daa2265b6f8af45a4b8e69071653d7022837edd378410b84183fc7441a9ecbc7a9410d8ec30aabeda3c</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>