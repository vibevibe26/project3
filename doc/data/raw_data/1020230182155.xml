<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:23:52.2352</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0182155</applicationNumber><claimCount>11</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>3D 모델 정합 텍스처 개선 방법, 서버 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>METHOD, SERVER AND COMPUTER PROGRAM FOR IMPROVING 3D MODEL  REGISTRATION TEXTURE</inventionTitleEng><openDate>2025.06.23</openDate><openNumber>10-2025-0091815</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/30</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 11/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/06</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전술한 바와 같은 과제를 실현하기 위한 본 발명의 다양한 실시예에 따른 Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법이 개시된다. 상기 방법은, 복수 개의 3차원 모델을 정합하여 정합 모델을 생성하는 단계, 상기 복수 개의 3차원 모델 각각의 생성에 대응하는 데이터 셋을 획득하는 단계, 상기 정합 모델에 대응하는 변환 매트릭스를 획득하는 단계, 상기 변환 매트릭스 및 상기 데이터 셋을 기반으로 입력 데이터를 구축하는 단계, 상기 입력 데이터에 대한 전처리를 수행하는 단계, 상기 전처리된 입력 데이터를 활용하여 하나 이상의 네트워크 함수에 대한 학습을 수행함으로써 합성 텍스처 생성 모델을 생성하는 단계 및 상기 학습된 텍스처 생성 모델을 통해 상기 정합 모델에 대응하는 텍스처 정보를 생성하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨팅 장치의 하나 이상의 프로세서에서 수행되는 방법에 있어서,복수 개의 3차원 모델을 정합하여 정합 모델을 생성하는 단계;상기 복수 개의 3차원 모델 각각의 생성에 대응하는 데이터 셋을 획득하는 단계;상기 정합 모델에 대응하는 변환 매트릭스를 획득하는 단계;상기 변환 매트릭스 및 상기 데이터 셋을 기반으로 입력 데이터를 구축하는 단계;상기 입력 데이터에 대한 전처리를 수행하는 단계;상기 전처리된 입력 데이터를 활용하여 하나 이상의 네트워크 함수에 대한 학습을 수행함으로써 합성 텍스처 생성 모델을 생성하는 단계; 및상기 학습된 텍스처 생성 모델을 통해 상기 정합 모델에 대응하는 텍스처 정보를 생성하는 단계; 를 포함하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 데이터 셋을 획득하는 단계는,제1모델의 생성에 활용된 제1이미지, 상기 제1이미지에 대응하는 오브젝트 마스크 및 카메라 파라미터 정보를 포함하는 제1데이터 셋을 획득하는 단계; 및제2모델의 생성에 활용된 제2이미지, 상기 제2이미지에 대응하는 오브젝트 마스크 및 카메라 파라미터 정보를 포함하는 제2데이터 셋을 획득하는 단계; 를 포함하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 입력 데이터에 대한 전처리를 수행하는 단계는,상기 변환 매트릭스를 기반으로 상기 제1데이터 셋 및 상기 제2데이터 셋의 카메라 포즈를 정렬시키는 단계; 및상기 정합 모델에 기초하여 초기 density volume을 획득하는 단계; 를 포함하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 합성 텍스처 생성 모델을 생성하는 단계는,전처리된 제1데이터 셋을 기반으로 제1학습을 수행하여 제1신경망 서브 모델을 생성하는 단계; 및상기 제1신경망 서브 모델과 전처리된 제2데이터 셋을 활용한 제2학습을 수행하여 제2신경망 서브 모델을 생성하는 단계; 를 포함하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제1학습은,상기 정합 모델에 기초하여 획득된 초기 density volume을 활용하여 상기 전처리된 제1데이터 셋으로 제1신경망 서브 모델에 대한 뉴럴 랜더링(neural rendering) 기반 학습에 관련한 것으로,상기 뉴럴 랜더링의 결과와 실제 촬영 이미지에 관련한 볼륨 랜더링(volume rendering)의 비교 기초하여 산출된 랜더링 로스rendering loss)를 기반으로 상기 제1신경망 서브 모델의 연결 가중치를 조정하는 것을 특징으로 하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 학습된 제1신경망 서브 모델은,상기 전처리된 제1데이터 셋을 통해 계산된 제1ray를 입력으로 3차원 모델에 대한 색상값을 출력하는 것을 특징으로 하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 제1신경망 서브 모델과 전처리된 제2데이터 셋을 활용한 제2학습을 수행하여 제2신경망 서브 모델을 생성하는 단계는,상기 전처리된 제2데이터 셋을 통해 제2ray를 계산하는 단계;상기 제2ray를 상기 학습된 제1신경망 서브 모델에 입력하여 제1색상값을 도출하는 단계;상기 제2ray를 상기 제2신경망 서브 모델에 입력하여 제2색상값을 도출하는 단계;상기 제2신경망 서브 모델의 뉴럴 랜더링 결과와 실제 촬영 이미지에 관련한 볼륨 랜더링의 비교에 기초하여 랜더링 로스를 산출하는 단계;상기 제1색상값 및 상기 제2색상값 각각의 색상 변화량에 기초하여 포이슨 블랜딩 로스를 산출하는 단계; 및상기 랜더링 로스 및 상기 포이슨 블랜딩 로스를 기반으로 상기 제2신경망 서브 모델에 대한 학습을 수행하는 단계; 를 포함하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 학습된 텍스처 생성 모델은,상기 제1색상값 및 상기 제2색상값에 대응하는 image color gradient를 수행하여 상기 정합 모델의 vertex에 대한 vertex 색상 정보를 출력하며, 출력된 상기 vertex 색상 정보를 텍스처 맵으로 맵핑하여 상기 텍스처 정보를 출력하는 것을 특징으로 하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 학습된 텍스처 생성 모델의 출력에 대응하는 상기 텍스처 정보는,정합이 완료된 3차원 모델의 색상 왜곡이 개선된 가공 텍스처 맵인 것을 특징으로 하는,Neural rendering 및 Poisson blending 기반 3D 모델 정합 텍스처 개선 방법.</claim></claimInfo><claimInfo><claim>10. 하나 이상의 인스트럭션을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 인스트럭션을 실행하는 프로세서를 포함하고,상기 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,제1항의 방법을 수행하는, 서버.</claim></claimInfo><claimInfo><claim>11. 하드웨어인 컴퓨터와 결합되어, 제1항의 방법을 수행할 수 있도록 컴퓨터에서 독출가능한 기록매체에 저장된 컴퓨터프로그램.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>120220188885</code><country>대한민국</country><engName>Rebuilderai Inc.</engName><name>주식회사 리빌더에이아이</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 남양주시 평내로 ***, **...</address><code> </code><country> </country><engName>Jung Geun Ho</engName><name>정근호</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***-*, *층(역삼동)</address><code>920201000818</code><country>대한민국</country><engName>RPM IP&amp;LAW FIRM</engName><name>특허법인알피엠</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.14</receiptDate><receiptNumber>1-1-2023-1405047-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.03.05</receiptDate><receiptNumber>4-1-2024-5081405-91</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230182155.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93833953af3c1afa293a949207f8145db5ad95e85d2fa5a67b015552366311fc0bb5ea937c2811b600589d0aec0005a6654e375a01178e669f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf418ef51f3dcb3ca2fffe9fddeeb94c8f05dc47909fb3ec799a5a6dd2fd8d31ee022f74f735bda33c76d46b3c0e2550037616ee68b7bd3e7a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>