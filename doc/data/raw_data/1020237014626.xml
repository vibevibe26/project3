<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:55:50.5550</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.09.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7014626</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>게이밍 애플리케이션들에서 딥 러닝 기반 예측을 이용한 레이턴시 관리</inventionTitle><inventionTitleEng>LATENCY MANAGEMENT WITH DEEP LEARNING BASED PREDICTION IN GAMING APPLICATIONS</inventionTitleEng><openDate>2023.06.07</openDate><openNumber>10-2023-0079414</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.11</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.04.28</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>A63F 13/358</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>A63F 13/355</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>A63F 13/67</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/503</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 방법으로서, 제1 프레임을 획득하는 단계(305B) - 상기 제1 프레임은 게이밍 애플리케이션에서 사용자에 의해 수행되는 제1 액션을 나타냄 -; 게이밍 애플리케이션에서 사용자에 의해 수행되는 제2 액션을 나타내는 정보를 획득하는 단계(500) - 상기 제2 액션은 제1 액션을 따름 -; 및 신경 네트워크를 사용하여 적어도 제1 프레임 및 제2 액션을 나타내는 정보를 포함하는 데이터로부터 제2 액션에 대응하는 제2 프레임을 예측하는 단계(500)를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.04.14</internationOpenDate><internationOpenNumber>WO2022073840</internationOpenNumber><internationalApplicationDate>2021.09.30</internationalApplicationDate><internationalApplicationNumber>PCT/EP2021/076914</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 방법으로서,제1 프레임을 획득하는 단계(305B) - 상기 제1 프레임은 상기 게이밍 애플리케이션에서 사용자에 의해 수행되는 제1 액션을 나타냄 -;상기 게이밍 애플리케이션에서 상기 사용자에 의해 수행되는 제2 액션을 나타내는 정보를 획득하는 단계(500) - 상기 제2 액션은 상기 제1 액션을 따름 -; 및신경 네트워크를 사용하여 적어도 상기 제1 프레임 및 제2 액션을 나타내는 상기 정보를 포함하는 데이터로부터 상기 제2 액션에 대응하는 제2 프레임을 예측하는 단계(500)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 방법은 상기 제2 프레임을 디스플레이하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 방법은 상기 제1 프레임과 함께 메타데이터를 획득하는 단계를 추가로 포함하고, 상기 메타데이터는, 적어도 상기 제1 액션 및/또는 상기 제1 액션에 대응하는 시간에 상기 게임의 상태를 나타내고, 상기 제2 프레임은 상기 신경 네트워크를 사용하여 상기 메타데이터로부터 추가로 예측되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 게임의 상태를 나타내는 상기 메타데이터는 상기 사용자를 나타내는 정보 및/또는 상기 게임에서의 다른 사용자들 및/또는 동적 객체들을 나타내는 정보를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 신경 네트워크는 파라미터들을 사용하고, 상기 파라미터들은,상기 게임 애플리케이션의 오프라인 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 오프라인으로 트레이닝되거나; 또는,상기 게임 애플리케이션의 현재 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 온더플라이(on the fly)로 트레이닝되거나; 또는,상기 게임 애플리케이션의 오프라인 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 오프라인으로 트레이닝되고, 이어서 상기 게임 애플리케이션의 현재 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 온더플라이로 트레이닝되는 파라미터들을 사용하여 상기 게임 애플리케이션의 실행의 시작 시에 초기화되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 신경 네트워크의 파라미터들의 트레이닝은 상기 제1 액션의 발생과 상기 제1 프레임의 획득 사이의 시간 차이를 고려하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 신경 네트워크의 파라미터들이 오프라인으로 트레이닝될 때, 파라미터들의 복수의 세트들이 트레이닝되고, 파라미터들의 각각의 세트는 오프라인 시간 차이라고 불리는 상이한 값의 시간 차이에 대해 트레이닝되고, 상기 게임 애플리케이션의 현재 실행 동안, 상기 방법은, 실제 시간 차이를 나타내는 정보에 가장 가까운 상기 오프라인 시간 차이에 대응하는, 상기 파라미터들의 복수의 세트들 중의 파라미터들의 세트를 선택하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제2항 내지 제7항 중 어느 한 항에 있어서, 상기 신경 네트워크의 파라미터들의 트레이닝은 상기 신경 네트워크에 의해 예측된 상기 제2 액션에 대응하는 상기 제2 프레임과, 동일한 상기 제2 액션에 대응하는 상기 게임 애플리케이션에 의해 생성된 실제 프레임 사이의 차이를 추정하는 손실 함수를 사용하고, 상기 제2 프레임의 디스플레이된 부분으로 불리는 하위부분만이 디스플레이되고, 상기 디스플레이된 부분만이 상기 손실 함수에 의해 고려되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 게이밍 애플리케이션은 네트워크 기반 게이밍 애플리케이션이고, 게임은 네트워크(3)를 통해 클라이언트 시스템(2)과 통신하는 서버(1)에 의해 관리되며, 상기 방법은 상기 클라이언트 시스템에 의해 실행되고;상기 제1 액션은 제1 시간에 상기 사용자에 의해 수행되고 상기 클라이언트 시스템에 의해 등록되고(200), 상기 제1 액션을 나타내는 정보는 상기 서버로 송신되고(301A);상기 제1 프레임 및/또는 상기 메타데이터는 상기 서버로부터 수신된(305B) 비디오 스트림의 일부분을 디코딩함으로써(306bis) 획득되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 비디오 스트림의 일부분은 상기 제1 프레임과 연관된 상기 제1 액션을 나타내는 메타데이터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제11항에 있어서, 상기 제1 액션을 나타내는 상기 메타데이터는, 상기 제1 액션이 실행되었던 시간을 나타내는, 방법.</claim></claimInfo><claimInfo><claim>12. 제9항, 제10항 또는 제11항에 있어서, 상기 메타데이터는 상기 실제 시간 차이를 나타내는 정보를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제9항, 제10항, 제11항 또는 제12항에 있어서, 상기 메타데이터는 SEI(Supplemental Enhancement Information) 메시지에 의해 전달되는, 방법.</claim></claimInfo><claimInfo><claim>14. 제9항 내지 제14항 중 어느 한 항에 있어서,상기 제1 프레임은 상기 제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 서버에 의해 예측된 상기 제1 시간 이후의 제2 시간에 상기 사용자의 제2 액션에 대응하고;상기 방법은,상기 제1 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하는 단계(708);상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터의 상기 서버로의 송신 후, 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 상기 서버로부터 수신하는 단계(305B); 및상기 실제 프레임을 디코딩하고(306bis), 상기 프레임 버퍼에서 상기 예측된 프레임의 재구성된 버전을 상기 실제 프레임의 재구성된 버전으로 대체하는 단계(706)를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 방법으로서,클라이언트 시스템으로부터, 상기 게이밍 애플리케이션에서 제1 시간에 사용자에 의해 수행되는 제1 액션을 나타내는 정보를 수신하는 단계(301B);제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 제1 시간 이후의 제2 시간에 대응하는 제2 액션을 예측하는 단계(701);상기 제2 액션에 대응하는, 예측된 프레임으로 불리는 프레임을 생성하는 단계(702, 703);상기 예측된 프레임을 인코딩하고(704), 상기 예측된 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하는 단계;상기 인코딩된 예측된 프레임을 상기 클라이언트 시스템으로 송신하는 단계(705);상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터가 수신될 때 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 생성하는 단계(301B, 202, 203); 및상기 실제 프레임을 인코딩하고(304bis), 상기 프레임 버퍼에서 상기 예측된 프레임의 재구성된 버전을 상기 실제 프레임의 재구성된 버전으로 대체하는 단계(700)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 전자 회로부를 포함하는, 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 디바이스로서, 상기 전자 회로부는,제1 프레임을 획득하기 위해(305B) - 상기 제1 프레임은 상기 게이밍 애플리케이션에서 사용자에 의해 수행되는 제1 액션을 나타냄 -;상기 게이밍 애플리케이션에서 상기 사용자에 의해 수행되는 제2 액션을 나타내는 정보를 획득하기 위해(500) - 상기 제2 액션은 상기 제1 액션을 따름 -; 그리고신경 네트워크를 사용하여 적어도 상기 제1 프레임 및 제2 액션을 나타내는 상기 정보를 포함하는 데이터로부터 상기 제2 액션에 대응하는 제2 프레임을 예측하기 위해(500) 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 전자 회로부는 상기 제2 프레임의 디스플레이를 제어하기 위해 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>18. 제16항 또는 제17항에 있어서, 상기 전자 회로부는 상기 제1 프레임과 함께 메타데이터를 획득하기 위해 추가로 적응되고, 상기 메타데이터는, 적어도 상기 제1 액션 및/또는 상기 제1 액션에 대응하는 시간에 상기 게임의 상태를 나타내고, 상기 제2 프레임은 상기 신경 네트워크를 사용하여 상기 메타데이터로부터 추가로 예측되는, 디바이스.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 게임의 상태를 나타내는 상기 메타데이터는 상기 사용자를 나타내는 정보 및/또는 상기 게임에서의 다른 사용자들 및/또는 동적 객체들을 나타내는 정보를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>20. 제16항 내지 제19항 중 어느 한 항에 있어서, 상기 신경 네트워크는 파라미터들을 사용하고, 상기 파라미터들은,상기 게임 애플리케이션의 오프라인 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 오프라인으로 트레이닝되거나; 또는,상기 게임 애플리케이션의 현재 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 온더플라이로 트레이닝되거나; 또는,상기 게임 애플리케이션의 오프라인 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 오프라인으로 트레이닝되고, 이어서 상기 게임 애플리케이션의 현재 실행 동안 수집된 상기 게임의 상태, 사용자 액션들, 및 프레임들을 나타내는 데이터를 사용하여 온더플라이로 트레이닝되는 파라미터들을 사용하여 상기 게임 애플리케이션의 실행의 시작 시에 초기화되는, 디바이스.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 신경 네트워크의 파라미터들의 트레이닝은 상기 제1 액션의 발생과 상기 제1 프레임의 획득 사이의 시간 차이를 고려하는, 디바이스.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 신경 네트워크의 파라미터들이 오프라인으로 트레이닝될 때, 파라미터들의 복수의 세트들이 트레이닝되고, 파라미터들의 각각의 세트는 오프라인 시간 차이라고 불리는 상이한 값의 시간 차이에 대해 트레이닝되고, 상기 게임 애플리케이션의 현재 실행 동안, 상기 전자 회로부는, 실제 시간 차이를 나타내는 정보에 가장 가까운 상기 오프라인 시간 차이에 대응하는, 상기 파라미터들의 복수의 세트들 중의 파라미터들의 세트를 선택하기 위해 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>23. 제17항 내지 제22항 중 어느 한 항에 있어서, 상기 신경 네트워크의 파라미터들의 트레이닝은 상기 신경 네트워크에 의해 예측된 상기 제2 액션에 대응하는 상기 제2 프레임과, 동일한 상기 제2 액션에 대응하는 상기 게임 애플리케이션에 의해 생성된 실제 프레임 사이의 차이를 추정하는 손실 함수를 사용하고, 상기 제2 프레임의 디스플레이된 부분으로 불리는 하위부분만이 디스플레이되고, 상기 디스플레이된 부분만이 상기 손실 함수에 의해 고려되는, 디바이스.</claim></claimInfo><claimInfo><claim>24. 제16항 내지 제23항 중 어느 한 항에 있어서, 상기 게이밍 애플리케이션은 네트워크 기반 게이밍 애플리케이션이고, 게임은 네트워크(3)를 통해 디바이스(2)와 통신하는 서버(1)에 의해 관리되고, 상기 전자 회로부는,제1 액션을 등록하기 위해(200) - 상기 제1 액션은 제1 시간에 사용자에 의해 수행됨 -;상기 제1 액션을 나타내는 정보를 상기 서버로 송신하기 위해; 그리고,상기 서버로부터 수신된(305B) 비디오 스트림의 일부분을 디코딩함으로써(306bis) 상기 제1 프레임 및/또는 상기 메타데이터를 획득하기 위해 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 비디오 스트림의 일부분은 상기 제1 프레임과 연관된 상기 제1 액션을 나타내는 메타데이터를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 제1 액션을 나타내는 상기 메타데이터는, 상기 제1 액션이 실행되었던 시간을 나타내는, 디바이스.</claim></claimInfo><claimInfo><claim>27. 제24항, 제25항 또는 제26항에 있어서, 상기 메타데이터는 실제 시간 차이를 나타내는 정보를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>28. 제24항, 제25항, 제26항 또는 제27항에 있어서, 상기 메타데이터는 SEI 메시지에 의해 전달되는, 디바이스.</claim></claimInfo><claimInfo><claim>29. 제24항 내지 제28항 중 어느 한 항에 있어서,상기 제1 프레임은 상기 제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 서버에 의해 예측된 상기 제1 시간 이후의 제2 시간에 상기 사용자의 제2 액션에 대응하고; 상기 전자 회로부는,상기 제1 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하기 위해(708);상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터의 상기 서버로의 송신 후, 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 상기 서버로부터 수신하기 위해(305B); 그리고상기 실제 프레임을 디코딩하고(306bis), 상기 프레임 버퍼에서 상기 예측된 프레임의 재구성된 버전을 상기 실제 프레임의 재구성된 버전으로 대체하기 위해(706) 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>30. 전자 회로부를 포함하는, 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 디바이스로서, 상기 전자 회로부는,클라이언트 시스템으로부터, 상기 게이밍 애플리케이션에서 제1 시간에 사용자에 의해 수행되는 제1 액션을 나타내는 정보를 수신하기 위해(301B);제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 제1 시간 이후의 제2 시간에 대응하는 제2 액션을 예측하기 위해(701);상기 제2 액션에 대응하는, 예측된 프레임으로 불리는 프레임을 생성하기 위해(702, 703);상기 예측된 프레임을 인코딩하고(704), 상기 예측된 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하기 위해;상기 인코딩된 예측된 프레임을 상기 클라이언트 시스템으로 송신하기 위해(705);상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터가 수신될 때 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 생성하기 위해(301B, 202, 203); 그리고상기 실제 프레임을 인코딩하고(304bis), 상기 프레임 버퍼에서 상기 예측된 프레임의 재구성된 버전을 상기 실제 프레임의 재구성된 버전으로 대체하기 위해(700) 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>31. 제16항 내지 제30항 중 어느 한 항에 따른 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>32. 제16항 내지 제29항 중 어느 한 항에 따른 디바이스를 포함하는 클라이언트 시스템 및 제30항에 따른 디바이스를 포함하는 서버를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>33. 제15항의 방법에 의해 또는 제30항의 디바이스에 의해 생성되는, 신호.</claim></claimInfo><claimInfo><claim>34. 제1항 내지 제15항 중 어느 한 항에 따른 방법을 구현하기 위한 프로그램 코드 명령어들을 포함하는, 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>35. 제1항 내지 제15항 중 어느 한 항에 따른 방법을 구현하기 위한 프로그램 코드 명령어들을 저장하는, 비일시적 정보 저장 매체.</claim></claimInfo><claimInfo><claim>36. 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 방법으로서,클라이언트 시스템으로부터, 상기 게이밍 애플리케이션에서 제1 시간에 사용자에 의해 수행되는 제1 액션을 나타내는 정보를 수신하는 단계(301B);제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 제1 시간 이후의 제2 시간에 대응하는 제2 액션을 예측하는 단계(701);상기 제2 액션에 대응하는, 예측된 프레임으로 불리는 프레임을 생성하는 단계(702, 703);상기 예측된 프레임을 인코딩하고(704), 상기 예측된 프레임이 기준 프레임으로서 사용될 수 있는 경우, 상기 예측된 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하는 단계;상기 인코딩된 예측된 프레임을 상기 클라이언트 시스템으로 송신하는 단계(705);상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터가 수신될 때 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 생성하는 단계(301B, 202, 203); 및상기 실제 프레임을 인코딩하고(304bis), 상기 예측된 프레임의 재구성된 버전 대신에 상기 실제 프레임의 재구성된 버전을 상기 프레임 버퍼에 저장하는 단계(700)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서, 상기 인코딩된 예측된 프레임에 연관된 신택스 요소는, 상기 예측된 프레임으로부터의 시간적 예측이 허용되지 않는다는 것을 시그널링하는, 방법.</claim></claimInfo><claimInfo><claim>38. 제36항 또는 제37항에 있어서, 상기 인코딩된 실제 프레임은 상기 클라이언트 시스템으로 송신되는, 방법.</claim></claimInfo><claimInfo><claim>39. 제38항에 있어서, 상기 인코딩된 실제 프레임에 연관된 신택스 요소는, 이러한 실제 프레임의 디스플레이가 허용되지 않는다는 것을 시그널링하는, 방법.</claim></claimInfo><claimInfo><claim>40. 제36항 내지 제39항 중 어느 한 항에 있어서, 상기 프레임 버퍼에 상기 실제 프레임의 저장 후, 시간적 예측을 위해 상기 프레임 버퍼를 사용하여 상기 실제 프레임 이후의 적어도 하나의 예측된 프레임을 재인코딩하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>41. 제36항 내지 제40항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은, 상기 프레임이 실제 프레임인지 또는 예측된 프레임인지를 나타내는 신택스 요소에 연관되는, 방법.</claim></claimInfo><claimInfo><claim>42. 제36항 내지 제41항 중 어느 한 항에 있어서, 프레임들은 다중 계층 비디오 인코더를 사용하여 인코딩되고, 실제 프레임들은 제1 계층에서 인코딩되고 예측된 프레임은 적어도 하나의 제2 계층에서 인코딩되는, 방법.</claim></claimInfo><claimInfo><claim>43. 제36항 내지 제42항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은 실제 프레임 및 동일한 시간에 대응하는 예측된 프레임을 상기 프레임의 디코딩 순서를 나타내는 동일한 프레임 식별자를 사용하도록 인가하는 신택스 요소에 연관되는, 방법.</claim></claimInfo><claimInfo><claim>44. 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 방법으로서,상기 게이밍 애플리케이션에서 제1 시간에 사용자에 의해 수행되는 제1 액션을 나타내는 정보를 서버로 송신하는 단계(301A);상기 제1 시간 이후의 제2 시간에 상기 사용자의 제2 액션에 대응하는, 예측된 프레임으로 불리는 프레임을 상기 서버로부터 수신하는 단계(707) - 상기 제2 액션은 상기 제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 서버에 의해 예측되었음 -;상기 예측된 프레임을 디코딩하고(708), 상기 예측된 프레임이 시간적 예측에 사용될 수 있는 경우, 상기 예측된 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하는 단계;상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터의 상기 서버로의 송신 후, 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 상기 서버로부터 수신하는 단계(305B); 및상기 실제 프레임을 디코딩하고(306bis), 상기 예측된 프레임의 재구성된 버전 대신에 상기 실제 프레임의 재구성된 버전을 상기 프레임 버퍼에 저장하는 단계(706)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>45. 제44항에 있어서, 상기 인코딩된 예측된 프레임에 연관된 신택스 요소는, 상기 예측된 프레임으로부터의 시간적 예측이 허용되지 않는다는 것을 시그널링하는, 방법.</claim></claimInfo><claimInfo><claim>46. 제44항 또는 제45항에 있어서, 상기 인코딩된 실제 프레임에 연관된 신택스 요소는, 이러한 실제 프레임의 디스플레이가 허용되지 않는다는 것을 시그널링하는, 방법.</claim></claimInfo><claimInfo><claim>47. 제44항 내지 제46항 중 어느 한 항에 있어서, 상기 프레임 버퍼에 저장된 적어도 하나의 예측된 프레임의 새로운 버전을 수신하는 단계 - 상기 새로운 버전은, 적어도 하나의 선행하는 예측된 프레임이 대응하는 실제 프레임에 의해 대체되었던 프레임 버퍼를 사용하는 상기 예측된 프레임의 재인코딩에 대응함 -, 및 상기 프레임 버퍼에 저장된 상기 예측된 프레임의 재구성된 버전을 상기 새로운 버전으로 대체하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>48. 제44항 내지 제47항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은, 상기 프레임이 실제 프레임인지 또는 예측된 프레임인지를 나타내는 신택스 요소에 연관되는, 방법.</claim></claimInfo><claimInfo><claim>49. 제44항 내지 제48항 중 어느 한 항에 있어서, 실제 프레임들은 다중 계층 비디오 인코딩의 제1 계층을 형성하고, 예측된 프레임들은 상기 다중 계층 비디오 인코딩의 적어도 하나의 제2 계층을 형성하는, 방법.</claim></claimInfo><claimInfo><claim>50. 제44항 내지 제49항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은 실제 프레임 및 동일한 시간에 대응하는 예측된 프레임을 상기 프레임의 디코딩 순서를 나타내는 동일한 프레임 식별자를 사용하도록 인가하는 신택스 요소에 연관되는, 방법.</claim></claimInfo><claimInfo><claim>51. 제44항 내지 제50항 중 어느 한 항에 있어서, 상기 방법은,상기 게이밍 애플리케이션에서 상기 제2 시간에 상기 사용자에 의해 실제로 수행되는 제3 액션을 나타내는 정보를 획득하는 단계(500); 및신경 네트워크를 사용하여 적어도 상기 제2 액션에 대응하는 상기 예측된 프레임 및 상기 제3 액션을 나타내는 정보를 포함하는 데이터로부터 상기 제3 액션에 대응하는, 최종 프레임으로 불리는 프레임을 예측하는 단계(500)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>52. 제44항 내지 제51항 중 어느 한 항에 있어서, 상기 예측된 프레임 또는 상기 최종 프레임이 디스플레이되는, 방법.</claim></claimInfo><claimInfo><claim>53. 전자 회로부를 포함하는, 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 디바이스로서, 상기 전자 회로부는,클라이언트 시스템으로부터, 상기 게이밍 애플리케이션에서 제1 시간에 사용자에 의해 수행되는 제1 액션을 나타내는 정보를 수신하기 위해(301B);제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 제1 시간 이후의 제2 시간에 대응하는 제2 액션을 예측하기 위해(701);상기 제2 액션에 대응하는, 예측된 프레임으로 불리는 프레임을 생성하기 위해(702, 703);상기 예측된 프레임을 인코딩하고(704), 상기 예측된 프레임이 기준 프레임으로서 사용될 수 있는 경우, 상기 예측된 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하기 위해;상기 인코딩된 예측된 프레임을 상기 클라이언트 시스템으로 송신하기 위해(705);상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터가 수신될 때 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 생성하기 위해(301B, 202, 203); 그리고상기 실제 프레임을 인코딩하고(304bis), 상기 예측된 프레임의 재구성된 버전 대신에 상기 실제 프레임의 재구성된 버전을 상기 프레임 버퍼에 저장하기 위해(700) 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>54. 제53항에 있어서, 상기 인코딩된 예측된 프레임에 연관된 신택스 요소는, 상기 예측된 프레임으로부터의 시간적 예측이 허용되지 않는다는 것을 시그널링하는, 디바이스.</claim></claimInfo><claimInfo><claim>55. 제53항 또는 제54항에 있어서, 상기 인코딩된 실제 프레임은 상기 클라이언트 시스템으로 송신되는, 디바이스.</claim></claimInfo><claimInfo><claim>56. 제55항에 있어서, 상기 인코딩된 실제 프레임에 연관된 신택스 요소는, 이러한 실제 프레임의 디스플레이가 허용되지 않는다는 것을 시그널링하는, 디바이스.</claim></claimInfo><claimInfo><claim>57. 제53항 내지 제56항 중 어느 한 항에 있어서, 상기 전자 회로부는, 상기 프레임 버퍼에 상기 실제 프레임의 저장 후, 시간적 예측을 위해 상기 프레임 버퍼를 사용하여 상기 실제 프레임 이후의 적어도 하나의 예측된 프레임을 재인코딩하기 위해 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>58. 제53항 내지 제57항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은, 상기 프레임이 실제 프레임인지 또는 예측된 프레임인지를 나타내는 신택스 요소에 연관되는, 디바이스.</claim></claimInfo><claimInfo><claim>59. 제53항 내지 제58항 중 어느 한 항에 있어서, 프레임들은 다중 계층 비디오 인코더를 사용하여 인코딩되고, 실제 프레임들은 제1 계층에서 인코딩되고 예측된 프레임은 적어도 하나의 제2 계층에서 인코딩되는, 디바이스.</claim></claimInfo><claimInfo><claim>60. 제53항 내지 제59항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은 실제 프레임 및 동일한 시간에 대응하는 예측된 프레임을 상기 프레임의 디코딩 순서를 나타내는 동일한 프레임 식별자를 사용하도록 인가하는 신택스 요소에 연관되는, 디바이스.</claim></claimInfo><claimInfo><claim>61. 전자 회로부를 포함하는, 게이밍 애플리케이션에서 레이턴시를 감소시키기 위한 디바이스로서, 상기 전자 회로부는,상기 게이밍 애플리케이션에서 제1 시간에 사용자에 의해 수행되는 제1 액션을 나타내는 정보를 서버로 송신하기 위해(301A);상기 제1 시간 이후의 제2 시간에 상기 사용자의 제2 액션에 대응하는, 예측된 프레임으로 불리는 프레임을 상기 서버로부터 수신하기 위해(707) - 상기 제2 액션은 상기 제1 액션을 나타내는 상기 정보 및 상기 제1 시간에 상기 게임 애플리케이션의 상태를 나타내는 정보로부터 상기 서버에 의해 예측되었음 -;상기 예측된 프레임을 디코딩하고(708), 상기 예측된 프레임이 시간적 예측에 사용될 수 있는 경우, 상기 예측된 프레임의 재구성된 버전을 다음 프레임들의 시간적 예측에 사용되는 프레임 버퍼에 저장하기 위해;상기 제2 시간에 상기 사용자에 의해 수행되는 액션을 나타내는 데이터의 상기 서버로의 송신 후, 상기 제2 시간에 대응하는, 실제 프레임으로 불리는 프레임을 상기 서버로부터 수신하기 위해(305B); 그리고,상기 실제 프레임을 디코딩하고(306bis), 상기 예측된 프레임의 재구성된 버전 대신에 상기 실제 프레임의 재구성된 버전을 상기 프레임 버퍼에 저장하기 위해(706) 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>62. 제61항에 있어서, 상기 인코딩된 예측된 프레임에 연관된 신택스 요소는, 상기 예측된 프레임으로부터의 시간적 예측이 허용되지 않는다는 것을 시그널링하는, 디바이스.</claim></claimInfo><claimInfo><claim>63. 제61항 또는 제62항에 있어서, 상기 인코딩된 실제 프레임에 연관된 신택스 요소는, 이러한 실제 프레임의 디스플레이가 허용되지 않는다는 것을 시그널링하는, 디바이스.</claim></claimInfo><claimInfo><claim>64. 제61항 내지 제63항 중 어느 한 항에 있어서, 상기 전자 회로부는, 상기 프레임 버퍼에 저장된 적어도 하나의 예측된 프레임의 새로운 버전을 수신하기 위해 - 상기 새로운 버전은, 적어도 하나의 선행하는 예측된 프레임이 대응하는 실제 프레임에 의해 대체되었던 프레임 버퍼를 사용하는 상기 예측된 프레임의 재인코딩에 대응함 -, 그리고 상기 프레임 버퍼에 저장된 상기 예측된 프레임의 재구성된 버전을 상기 새로운 버전으로 대체하기 위해 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>65. 제61항 내지 제64항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은, 상기 프레임이 실제 프레임인지 또는 예측된 프레임인지를 나타내는 신택스 요소에 연관되는, 디바이스.</claim></claimInfo><claimInfo><claim>66. 제61항 내지 제65항 중 어느 한 항에 있어서, 실제 프레임들은 다중 계층 비디오 인코딩의 제1 계층을 형성하고, 예측된 프레임들은 상기 다중 계층 비디오 인코딩의 적어도 하나의 제2 계층을 형성하는, 디바이스.</claim></claimInfo><claimInfo><claim>67. 제61항 내지 제66항 중 어느 한 항에 있어서, 각각의 인코딩된 프레임은 실제 프레임 및 동일한 시간에 대응하는 예측된 프레임을 상기 프레임의 디코딩 순서를 나타내는 동일한 프레임 식별자를 사용하도록 인가하는 신택스 요소에 연관되는, 디바이스.</claim></claimInfo><claimInfo><claim>68. 제61항 내지 제67항 중 어느 한 항에 있어서, 상기 전자 회로부는,상기 게이밍 애플리케이션에서 상기 제2 시간에 상기 사용자에 의해 실제로 수행되는 제3 액션을 나타내는 정보를 획득하기 위해(500); 그리고,신경 네트워크를 사용하여 적어도 상기 제2 액션에 대응하는 상기 예측된 프레임 및 상기 제3 액션을 나타내는 정보를 포함하는 데이터로부터 상기 제3 액션에 대응하는, 최종 프레임으로 불리는 프레임을 예측하기 위해(501) 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>69. 제61항 내지 제68항 중 어느 한 항에 있어서, 상기 전자 회로부는 상기 예측된 프레임 또는 상기 최종 프레임의 디스플레이를 제어하기 위해 추가로 적응되는, 디바이스.</claim></claimInfo><claimInfo><claim>70. 제53항 내지 제69항 중 어느 한 항에 따른 디바이스를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>71. 제53항 내지 제60항 중 어느 한 항에 따른 디바이스를 포함하는 서버 및 제61항 내지 제69항 중 어느 한 항에 따른 디바이스를 포함하는 클라이언트 시스템을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>72. 제36항 내지 제43항 중 어느 한 항의 방법에 의해, 또는 제53항 내지 제61항 중 어느 한 항의 디바이스에 의해 생성되는, 신호.</claim></claimInfo><claimInfo><claim>73. 제36항 내지 제52항 중 어느 한 항에 따른 방법을 구현하기 위한 프로그램 코드 명령어들을 포함하는, 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>74. 제36항 내지 제52항 중 어느 한 항에 따른 방법을 구현하기 위한 프로그램 코드 명령어들을 저장하는, 비일시적 정보 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>프랑스 ***** 빠리 뤼 뒤 꼴로넬 몰 *</address><code>520180576061</code><country>프랑스</country><engName>InterDigital CE Patent Holdings, SAS </engName><name>인터디지털 씨이 페이튼트 홀딩스, 에스에이에스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>프랑스 세송-세비뉴 ***** 씨에스 *...</address><code> </code><country> </country><engName>GALPIN, Franck</engName><name>갈핀, 프랑크</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 씨에스 *...</address><code> </code><country> </country><engName>BORDES, Philippe</engName><name>보르데스, 필리프</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 씨에스 *...</address><code> </code><country> </country><engName>LE LEANNEC, Fabrice</engName><name>러 레리네크, 파브리스</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 씨에스 *...</address><code> </code><country> </country><engName>NASER, Karam</engName><name>나세르, 카람</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 씨에스 *...</address><code> </code><country> </country><engName>CHEVALLIER, Louis</engName><name>쉐발리에, 루이스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2020.10.09</priorityApplicationDate><priorityApplicationNumber>20306182.5</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2020.10.09</priorityApplicationDate><priorityApplicationNumber>20306183.3</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Translation of Amendment made during International Phase] Submission of Document</documentEngName><documentName>[국제단계보정서 번역문]서류제출서</documentName><receiptDate>2023.04.28</receiptDate><receiptNumber>1-1-2023-0479831-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.04.28</receiptDate><receiptNumber>1-1-2023-0479711-31</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.05.11</receiptDate><receiptNumber>1-1-2023-0522474-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.05.12</receiptDate><receiptNumber>1-5-2023-0076430-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2023.05.16</receiptDate><receiptNumber>1-1-2023-0542484-28</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Change of Applicant] Report on Change of Proprietary Status</documentEngName><documentName>[출원인변경]권리관계변경신고서</documentName><receiptDate>2023.10.11</receiptDate><receiptNumber>1-1-2023-1112759-94</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.11</receiptDate><receiptNumber>1-1-2024-1000888-61</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.11.14</receiptDate><receiptNumber>9-5-2025-1106894-79</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237014626.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93e581c55c90ffd268d9ed81b087ba600f0511e5ff20bec3a9ecce70271be0391a225ba7c92cc599c3bf01518b984c3f05945448cf1cb7f304</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb4c1e48a651fb0d628e74e52e93e9ddf9f2720901be809096b03a00e36a8c2955b5d3088be73da7a58423ec0cafad2d75d26eed9e8c17e8f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>