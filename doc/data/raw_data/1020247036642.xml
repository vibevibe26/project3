<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:25.125</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.05.09</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7036642</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지 내의 객체 분할</inventionTitle><inventionTitleEng>SEGMENTATION OF OBJECTS IN AN IMAGE</inventionTitleEng><openDate>2024.12.09</openDate><openNumber>10-2024-0172208</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.11.01</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.11.01</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06V 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 미디어 애플리케이션이 초기 이미지 내의 객체들의 세트를 식별하기 위해 초기 이미지에 대해 객체 인식을 수행한다. 미디어 애플리케이션은 초기 이미지가 실외 장면인지 여부를 결정한다. 초기 이미지가 실외 장면인 것에 응답하여, 미디어 애플리케이션은 초기 이미지로부터 하늘 세그먼트를 결정한다. 미디어 애플리케이션은 초기 이미지가 사람 또는 동물인 대상체를 포함하는지 여부를 결정한다. 초기 이미지가 대상체를 포함하는 것에 응답하여, 미디어 애플리케이션은 초기 이미지로부터 대상체 세그먼트를 결정한다. 미디어 애플리케이션은 초기 이미지를 포함하는 사용자 인터페이스에서, 객체들의 세트로부터 선택된 객체의 선택에 대응하는 사용자 입력을 수신한다. 미디어 애플리케이션은 선택된 객체가 선택되었다는 표시를 포함하도록 사용자 인터페이스를 업데이트한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.11.14</internationOpenDate><internationOpenNumber>WO2024233818</internationOpenNumber><internationalApplicationDate>2024.05.09</internationalApplicationDate><internationalApplicationNumber>PCT/US2024/028647</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 구현 방법으로서,초기 이미지에 대해 객체 인식을 수행하여 초기 이미지 내의 객체들의 세트를 식별하는 단계;초기 이미지가 실외 장면인지 여부를 결정하는 단계;초기 이미지가 실외 장면인 것에 응답하여, 초기 이미지로부터 하늘 세그먼트를 결정하는 단계;초기 이미지가 사람 또는 동물인 대상체(subject)를 포함하는지 여부를 결정하는 단계;초기 이미지가 상기 대상체를 포함하는 것에 응답하여, 초기 이미지로부터 대상체 세그먼트를 결정하는 단계;초기 이미지가 하나 이상의 방해 객체를 포함하는지 여부를 결정하는 단계;초기 이미지가 하나 이상의 방해 객체를 포함하는 것에 응답하여, 초기 이미지로부터 하나 이상의 방해 세그먼트를 결정하는 단계;초기 이미지를 포함하는 사용자 인터페이스에서, 객체들의 세트로부터 선택된 객체의 선택에 대응하는 사용자 입력을 수신하는 단계; 및선택된 객체가 선택되었다는 표시를 포함하도록 사용자 인터페이스를 업데이트하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 사용자 입력은 상기 선택된 객체의 다수의 탭을 포함하고,사용자 입력으로부터 탭의 개수를 결정하는 단계; 및탭의 개수에 기초하여 상기 선택된 객체를 결정하는 단계 - 제1 탭은 제2 탭과 상이한 영역과 연관됨 - 를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,초기 이미지가 상기 대상체를 포함하는 것에 응답하여, 배경 세그먼트를 생성하는 단계 — 상기 대상체 세그먼트는 전경 영역과 연관되고, 상기 배경 세그먼트는 배경 영역과 연관되며, 상기 초기 이미지 내의 픽셀은 전경 영역 또는 배경 영역과 연관됨 —; 및사용자 입력이 전경 영역과 연관된 픽셀과 접촉하는 것에 기초하여 사용자 입력이 전경 영역에 대응한다고 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 객체 인식을 수행하여 초기 이미지 내의 객체를 식별하는 단계는 각 객체에 대한 객체 경계 박스를 결정하는 단계를 포함하고, 상기 방법은:가장 가까운 객체 경계 박스에 대한 사용자 입력의 근접성에 기초하여 사용자 입력이 상기 선택된 객체에 대응한다고 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 컨볼루션 신경망(CNN)이 분할(segmentation)을 수행하고, 상기 방법은:컨볼루션 신경망에 입력으로서 초기 이미지 및 키포인트(keypoints)의 히트맵을 제공하는 단계; 및컨볼루션 신경망을 이용하여, 하늘 세그먼트, 대상체 세그먼트, 및 하나 이상의 방해 세그먼트에 대응하는 분할 마스크들을 출력하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 사용자 입력은 하늘의 선택을 포함하고, 상기 방법은:초기 이미지의 조명을 변경하라는 요청을 사용자로부터 수신하는 단계;확산 모델에 대한 입력으로서, 초기 이미지 및 그 초기 이미지의 조명을 변경하라는 요청을 제공하는 단계; 및확산 모델을 이용하여, 그 요청을 만족시키는 출력 이미지를 출력하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 사용자 입력은 제거할 하나 이상의 배경 객체의 선택을 포함하고,상기 방법은:객체 인식에 기초하여 초기 이미지로부터 하나 이상의 방해 객체를 제거하는 단계; 및하나 이상의 방해 객체와 연관된 픽셀의 인페인팅(inpainting)을 포함하는 수정된 이미지를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 선택된 객체는 불완전한 객체이고, 상기 불완전한 객체의 생략된 부분은 초기 이미지의 경계에 의해 잘리거나 다른 객체에 의해 가려지고,상기 방법은:불완전한 객체를 포함하는 보존 마스크를 생성하는 단계;초기 이미지로부터 불완전한 객체를 제거하는 단계;불완전한 객체에 대응하는 불완전한 객체 픽셀을 초기 이미지 내의 배경과 매칭되는 배경 픽셀로 대체하는 인페인팅된 이미지를 생성하는 단계;확산 모델에 대한 입력으로서, 보존 마스크, 불완전한 객체, 및 인페인팅된 이미지를 제공하는 단계;확산 모델을 이용하여, 완전한 객체를 출력하는 단계; 및보존 마스크를 사용하여 완전한 객체의 하나 이상의 버전을 상기 인페인팅된 이미지의 하나 이상의 버전과 블렌딩함으로써 수정된 이미지를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,초기 이미지 내의 선택된 객체를 변경하라는 텍스트 요청을 수신하는 단계;초기 이미지로부터, 대상체 세그먼트에 기초하여 그 대상체의 얼굴에 대한 얼굴 세그먼트를 결정하는 단계;얼굴 세그먼트에 대응하는 보존 마스크를 생성하는 단계;텍스트 요청, 초기 이미지, 및 보존 마스크를 확산 모델에 입력으로서 제공하는 단계; 및확산 모델을 이용하여, 텍스트 요청을 만족시키는 출력 이미지를 출력하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 하나 이상의 프로세서에 의해 실행될 때 하나 이상의 프로세서로 하여금 동작들을 수행하게 하는 명령어가 저장된 비-일시적 컴퓨터 판독가능 매체로서, 상기 동작들은:초기 이미지에 대해 객체 인식을 수행하여 초기 이미지 내의 객체들의 세트를 식별하는 동작;초기 이미지가 실외 장면인지 여부를 결정하는 동작;초기 이미지가 실외 장면인 것에 응답하여, 초기 이미지로부터 하늘 세그먼트를 결정하는 동작;초기 이미지가 사람 또는 동물인 대상체를 포함하는지 여부를 결정하는 동작;초기 이미지가 상기 대상체를 포함하는 것에 응답하여, 초기 이미지로부터 대상체 세그먼트를 결정하는 동작;초기 이미지가 하나 이상의 방해 객체를 포함하는지 여부를 결정하는 동작;초기 이미지가 상기 하나 이상의 방해 객체를 포함하는 것에 응답하여, 초기 이미지로부터 하나 이상의 방해 세그먼트를 결정하는 동작;초기 이미지를 포함하는 사용자 인터페이스에서, 객체들의 세트로부터 선택된 객체의 선택에 대응하는 사용자 입력을 수신하는 동작; 및선택된 객체가 선택되었다는 표시를 포함하도록 사용자 인터페이스를 업데이트하는 동작을 포함하는, 비-일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 사용자 입력은 상기 선택된 객체의 다수의 탭을 포함하고, 상기 동작들은:사용자 입력으로부터 탭의 개수를 결정하는 동작; 및탭의 개수에 기초하여 상기 선택된 객체를 결정하는 동작 - 제1 탭은 제2 탭과 상이한 영역과 연관됨 - 을 더 포함하는, 비-일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 동작들은:초기 이미지가 대상체를 포함하는 것에 응답하여, 배경 세그먼트를 생성하는 동작 — 상기 대상체 세그먼트는 전경 영역과 연관되고, 상기 배경 세그먼트는 배경 영역과 연관되며, 상기 초기 이미지 내의 픽셀은 전경 영역 또는 배경 영역과 연관됨 —; 및사용자 입력이 전경 영역과 연관된 픽셀과 접촉하는 것에 기초하여 사용자 입력이 전경 영역에 대응한다고 결정하는 동작을 더 포함하는, 비-일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서, 상기 객체 인식을 수행하여 초기 이미지 내의 객체을 식별하는 동작은 각 객체에 대한 객체 경계 박스를 결정하는 동작을 포함하고, 상기 동작들은:가장 가까운 객체 경계 박스에 대한 사용자 입력의 근접성에 기초하여 사용자 입력이 상기 선택된 객체에 대응한다고 결정하는 동작을 더 포함하는, 비-일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서, 컨볼루션 신경망(CNN)이 분할을 수행하고, 상기 동작들은:컨볼루션 신경망에 입력으로서 초기 이미지 및 키포인트들의 히트맵을 제공하는 동작; 및컨볼루션 신경망을 이용하여, 하늘 세그먼트, 대상체 세그먼트, 및 하나 이상의 방해 세그먼트에 대응하는 분할 마스크들을 출력하는 동작을 더 포함하는, 비-일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>15. 제10항에 있어서, 상기 사용자 입력은 하늘의 선택을 포함하고, 상기 동작들은:상기 초기 이미지에서의 조명을 변경하라는 요청을 사용자로부터 수신하는 동작;확산 모델에 대한 입력으로서, 초기 이미지 및 상기 초기 이미지에서의 조명을 변경하라는 요청을 제공하는 동작; 및상기 확산 모델을 이용하여, 상기 요청을 만족시키는 출력 이미지를 출력하는 동작을 더 포함하는, 비-일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>16. 시스템으로서,프로세서; 및프로세서에 결합되고 상기 프로세서에 의해 실행될 때 그 프로세서로 하여금 동작들을 수행하게 하는 명령어가 저장된 메모리를 포함하고, 상기 동작들은: 초기 이미지에 대해 객체 인식을 수행하여 초기 이미지 내의 객체들의 세트를 식별하는 동작; 초기 이미지가 실외 장면인지 여부를 결정하는 동작; 초기 이미지가 실외 장면인 것에 응답하여, 초기 이미지로부터 하늘 세그먼트를 결정하는 동작; 초기 이미지가 사람 또는 동물인 대상체를 포함하는지 여부를 결정하는 동작; 초기 이미지가 상기 대상체를 포함하는 것에 응답하여, 초기 이미지로부터 대상체 세그먼트를 결정하는 동작; 초기 이미지가 하나 이상의 방해 객체를 포함하는지 여부를 결정하는 동작; 초기 이미지가 하나 이상의 방해 객체를 포함하는 것에 응답하여, 초기 이미지로부터 하나 이상의 방해 세그먼트를 결정하는 동작; 초기 이미지를 포함하는 사용자 인터페이스에서, 객체들의 세트로부터 선택된 객체의 선택에 대응하는 사용자 입력을 수신하는 동작; 및 선택된 객체가 선택되었다는 표시를 포함하도록 사용자 인터페이스를 업데이트하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 사용자 입력은 선택된 객체의 다수의 탭을 포함하고, 상기 동작들은:사용자 입력으로부터 탭의 개수를 결정하는 동작; 및탭의 개수에 기초하여 상기 선택된 객체를 결정하는 동작 - 제1 탭은 제2 탭과 상이한 영역과 연관됨 - 을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 동작들은:초기 이미지가 상기 대상체를 포함하는 것에 응답하여, 배경 세그먼트를 생성하는 동작 — 상기 대상체 세그먼트는 전경 영역과 연관되고, 상기 배경 세그먼트는 배경 영역과 연관되며, 상기 초기 이미지 내의 픽셀은 전경 영역 또는 배경 영역과 연관됨 —; 및사용자 입력이 전경 영역과 연관된 픽셀들과 접촉하는 것에 기초하여 사용자 입력이 전경 영역에 대응한다고 결정하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 객체 인식을 수행하여 초기 이미지 내의 객체들을 식별하는 동작은 각 객체에 대한 객체 경계 박스를 결정하는 동작을 포함하고, 상기 동작들은:가장 가까운 객체 경계 박스에 대한 사용자 입력의 근접성에 기초하여 사용자 입력이 상기 선택된 객체에 대응한다고 결정하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서, 컨볼루션 신경망(CNN)이 분할을 수행하고, 상기 동작들은:컨볼루션 신경망 입력으로서 초기 이미지 및 키포인트들의 히트맵을 제공하는 동작; 및컨볼루션 신경망을 이용하여, 하늘 세그먼트, 대상체 세그먼트, 및 하나 이상의 방해 세그먼트에 대응하는 분할 마스크들을 출력하는 동작을 더 포함하는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country>미국</country><engName>FELDMAN, Bryan</engName><name>펠드먼 브라이언</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.05.09</priorityApplicationDate><priorityApplicationNumber>63/465,224</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.05.09</priorityApplicationDate><priorityApplicationNumber>63/465,226</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.05.09</priorityApplicationDate><priorityApplicationNumber>63/465,230</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.05.09</priorityApplicationDate><priorityApplicationNumber>63/465,232</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2024.03.07</priorityApplicationDate><priorityApplicationNumber>63/562,634</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.11.01</receiptDate><receiptNumber>1-1-2024-1200736-76</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.11.08</receiptDate><receiptNumber>1-5-2024-0181375-65</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247036642.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937b4f32412194f3d24009eca2ac4766ccf63c3a2787d199bc5b8df0b186eec3149b2ab38d03cf1552ce5d0769616f4611c19d8b2312e73325</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4547f2ee98594573e025cd3cab287298b1f84475563bf68270e8b36e61dba782367d69036a66223a1879812873022ae8789ed022225a6260</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>