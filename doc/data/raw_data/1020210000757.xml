<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:07:23.723</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.01.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0000757</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인체 포즈 추정 장치 및 방법</inventionTitle><inventionTitleEng>Apparatus and method for estimating the pose of the  human body</inventionTitleEng><openDate>2022.07.12</openDate><openNumber>10-2022-0098895</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.01.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/77</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/32</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 경량화된 피라미드 구조의 딥러닝 네트워크를 이용하여 입력 영상에서 인체 포즈를 빠르고 정확하게 추정하기 위한 인체 포즈 추정 장치 및 방법이 개시된다. 일 실시예에 따른 영상에서 인체 포즈를 추정하는 인체 포즈 추정 장치는, 적어도 하나의 카메라에서 촬영된 복수의 프레임으로 구성된 입력 영상을 저장하는 저장부; 및 피라미드 구조의 딥러닝 네트워크를 이용하여 상기 입력 영상의 각 프레임에서 관절 좌표를 추출하는 포즈 추출부를 포함하고, 상기 포즈 추출부는, 입력 데이터로부터 서로 다른 해상도의 복수의 특징 맵을 생성하는 복수의 스테이지; 및 상기 복수의 스테이지의 마지막 스테이지에서 출력되는 복수의 특징 맵을 혼합하여 각 프레임별로 각 관절 부위별 히트 맵을 생성하는 혼합층을 포함하고, 상기 복수의 스테이지 및 상기 혼합층 중 적어도 하나의 스테이지 또는 혼합층은, 입력되는 복수의 특징 맵 간의 관계 및 각 특징 맵 내의 픽셀 간의 관계를 반영한 복수의 특징 맵을 생성하는 어텐션 모듈을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 영상에서 인체 포즈를 추정하는 인체 포즈 추정 장치에 있어서,적어도 하나의 카메라에서 촬영된 복수의 프레임으로 구성된 입력 영상을 저장하는 저장부; 및피라미드 구조의 딥러닝 네트워크를 이용하여 상기 입력 영상의 각 프레임에서 관절 좌표를 추출하는 포즈 추출부를 포함하고, 상기 포즈 추출부는, 입력 데이터로부터 서로 다른 해상도의 복수의 특징 맵을 생성하는 복수의 스테이지; 및상기 복수의 스테이지의 마지막 스테이지에서 출력되는 복수의 특징 맵을 혼합하여 각 프레임별로 각 관절 부위별 히트 맵을 생성하는 혼합층을 포함하고,상기 복수의 스테이지 및 상기 혼합층 중 적어도 하나의 스테이지 또는 혼합층은, 입력되는 복수의 특징 맵 간의 관계 및 각 특징 맵 내의 픽셀 간의 관계를 반영한 복수의 특징 맵을 생성하는 어텐션 모듈을 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 복수의 스테이지 각각은, 입력 데이터에 대해 배치 정규화를 수행하는 배치 정규화부;상기 배치 정규화된 입력 데이터에 비선형 활성화 함수를 적용하는 정류화 선형유닛; 및상기 정류화 선형유닛의 출력 데이터에 대해 복수의 필터를 컨볼루션 연산하여 복수의 특징 맵을 생성하는 컨볼루션부를 포함하는 기본 모듈을 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 어텐션 모듈은,입력되는 복수의 특징 맵 각각에서 최대 픽셀값을 추출하는 최대 풀링과 픽셀값의 평균을 추출하는 평균 풀링을 수행하고, 이를 기초로 새로운 복수의 특징 맵을 생성하는 채널 어텐션부; 및상기 채널 어텐션부에서 출력되는 복수의 특징 맵에서 각 동일 좌표마다 최대 픽셀값을 추출하는 최대 풀링과 각 동일 좌표의 픽셀값의 평균을 추출하는 평균 풀링을 수행하고, 이를 기초로 새로운 복수의 특징 맵을 생성하는 공간 어텐션부를 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 채널 어텐션부는,최대 풀링 결과와 평균 풀링 결과 각각에 대해 제1 컨볼루션 연산, 정류화 선형 연산 및 제2 컨볼루션 연산을 순차적으로 수행하여 결합하고, 결합 결과에 활성화 함수를 적용한 후 해당 채널 어텐션부에 입력된 복수의 특징 맵을 곱하여 새로운 복수의 특징 맵을 생성하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 공간 어텐션부는,최대 풀링 결과와 평균 풀링 결과를 결합하고 그 결과에 대해 컨볼루션 연산 및 활성화 함수 적용을 순차적으로 수행한 후, 해당 공간 어텐션부에 입력된 복수의 특징 맵을 곱하여 새로운 복수의 특징 맵을 생성하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>6. 제3항에 있어서,상기 어텐션 모듈은,입력되는 복수의 특징 맵에 대해 배치 정규화를 수행하는 제1 배치 정규화부;상기 제1 배치 정규화부에서 출력되는 데이터에 비선형 활성화 함수를 적용하는 제1 정류화 선형유닛; 상기 제1 정류화 선형유닛에서 출력되는 데이터에 복수의 필터를 컨볼루션 연산하여 복수의 특징 맵을 생성하는 컨볼루션부;상기 컨볼루션부에서 출력되는 복수의 특징 맵에 대해 배치 정규화를 수행하는 제2 배치 정규화부; 및상기 제2 배치 정규화부에서 출력되는 복수의 특징 맵에 비선형 활성화 함수를 적용하여 상기 채널 어텐션부로 출력하는 제2 정류화 선형유닛을 더 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,현재 프레임으로부터 추출된 관절 좌표들의 픽셀값이 제1임계값 이상인 경우, 이전 프레임에서 추출된 관절 좌표들을 현재 프레임에서 추출된 관절 좌표들로 갱신하는 보정부를 더 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,현재 프레임으로부터 추출된 관절 좌표들과 이전 프레임으로부터 추출된 관절 좌표들 간의 유클리드 거리가 제2임계값 미만인 경우, 이전 프레임에서 추출된 관절 좌표들을 현재 프레임에서 추출된 관절 좌표들로 갱신하는 보정부를 더 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,특정 시점(view)의 현재 프레임으로부터 추출된 관절 좌표들과 인접 시점(view)의 동일 시간 시퀀스의 현재 프레임에서 추출된 관절 좌표들 간의 유클리드 거리가 제3임계값 미만인 경우, 특정 시점의 이전 프레임에서 추출된 관절 좌표들을 현재 프레임에서 추출된 관절 좌표들로 갱신하는 보정부를 더 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,특정 시간 시퀀스에서 획득된 서로 다른 시점의 복수의 카메라 각각의 영상 프레임들을 이용하여 피사체인 인체의 3차원 영상을 구성하고, 해당 3차원 영상을 각 카메라의 2차원 평면에 재투영(reprojection)했을 때 얻어지는 2차원 평면에서의 특정 관절의 좌표들과, 상기 포즈 추출부에서 추출한 각 시점의 특정 관절의 좌표들 간의 유클리드 거리를 계산하고, 계산된 유클리드 거리가 제4임계값 이상인 경우, 해당 관절의 좌표를 오검출로 판단하고, 상기 재투영된 2차원 평면에서의 관절 좌표를 해당 특정 관절의 좌표로 사용하는 보정부를 더 포함하는 것을 특징으로 하는 인체 포즈 추정 장치.</claim></claimInfo><claimInfo><claim>11. 인체 포즈 추정 장치가 영상에서 인체 포즈를 추정하는 방법으로서,적어도 하나의 카메라에서 촬영된 복수의 프레임으로 구성된 입력 영상을 저장하는 단계; 복수의 스테이지 및 혼합층을 포함하는 피라미드 구조의 딥러닝 네트워크의 각 스테이지에서 입력 데이터로부터 서로 다른 해상도의 복수의 특징 맵을 생성하는 단계; 및상기 혼합층에서 상기 복수의 스테이지의 마지막 스테이지에서 출력되는 복수의 특징 맵을 혼합하여 각 프레임별로 각 관절 부위별 히트 맵을 생성하여 관절 좌표를 추출하는 단계를 포함하고, 상기 복수의 특징 맵을 생성하는 단계 또는 관절 좌표를 추출하는 단계 중 적어도 하나는,입력되는 복수의 특징 맵 간의 관계 및 각 특징 맵 내의 픽셀 간의 관계를 반영한 복수의 특징 맵을 생성하는 어텐션 처리를 수행하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,각 스테이지에서 상기 복수의 특징 맵을 생성하는 단계는, 입력 데이터에 대해 배치 정규화를 수행하는 단계;배치 정규화된 데이터에 비선형 활성화 함수를 적용하는 단계;비선형 활성화 함수가 적용된 데이터에 대해 복수의 필터를 컨볼루션 연산하여 복수의 특징 맵을 생성하는 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 어텐션 처리를 수행하는 단계는,입력되는 복수의 특징 맵 각각에서 최대 픽셀값을 추출하는 최대 풀링과 픽셀값의 평균을 추출하는 평균 풀링을 수행하고, 이를 기초로 새로운 복수의 특징 맵을 생성하는 채널 어텐션 처리 단계; 및상기 채널 어텐션 처리 단계에서 출력되는 복수의 특징 맵에서 각 동일 좌표마다 최대 픽셀값을 추출하는 최대 풀링과 각 동일 좌표의 픽셀값의 평균을 추출하는 평균 풀링을 수행하고, 이를 기초로 새로운 복수의 특징 맵을 생성하는 공간 어텐션 처리 단계를 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 채널 어텐션 처리 단계는,최대 풀링 결과와 평균 풀링 결과 각각에 대해 제1 컨볼루션 연산, 정류화 선형 연산 및 제2 컨볼루션 연산을 순차적으로 수행하여 결합하고, 결합 결과에 활성화 함수를 적용한 후 해당 채널 어텐션 처리를 위해 입력된 복수의 특징 맵을 곱하여 새로운 복수의 특징 맵을 생성하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 공간 어텐션 처리 단계는,최대 풀링 결과와 평균 풀링 결과를 결합하고 그 결과에 대해 컨볼루션 연산 및 활성화 함수 적용을 순차적으로 수행한 후, 해당 공간 어텐션 처리를 위해 입력된 복수의 특징 맵을 곱하여 새로운 복수의 특징 맵을 생성하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 어텐션 처리를 수행하는 단계는,입력되는 복수의 특징 맵에 대해 배치 정규화를 수행하는 제1 배치 정규화 단계;상기 제1 배치 정규화 단계에서 출력되는 데이터에 비선형 활성화 함수를 적용하는 제1 정류화 선형 단계; 상기 제1 정류화 선형 단계에서 출력되는 데이터에 복수의 필터를 컨볼루션 연산하여 복수의 특징 맵을 생성하는 컨볼루션 단계;상기 컨볼루션 단계에서 출력되는 복수의 특징 맵에 대해 배치 정규화를 수행하는 제2 배치 정규화 단계; 및상기 제2 배치 정규화 단계에서 출력되는 복수의 특징 맵에 비선형 활성화 함수를 적용하여 상기 채널 어텐션 처리를 위해 출력하는 제2 정류화 선형 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서,현재 프레임으로부터 추출된 관절 좌표들의 픽셀값이 제1임계값 이상인 경우, 이전 프레임에서 추출된 관절 좌표들을 현재 프레임에서 추출된 관절 좌표들로 갱신하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서,현재 프레임으로부터 추출된 관절 좌표들과 이전 프레임으로부터 추출된 관절 좌표들 간의 유클리드 거리가 제2임계값 미만인 경우, 이전 프레임에서 추출된 관절 좌표들을 현재 프레임에서 추출된 관절 좌표들로 갱신하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서,특정 시점(view)의 현재 프레임으로부터 추출된 관절 좌표들과 인접 시점(view)의 동일 시간 시퀀스의 현재 프레임에서 추출된 관절 좌표들 간의 유클리드 거리가 제3임계값 미만인 경우, 특정 시점의 이전 프레임에서 추출된 관절 좌표들을 현재 프레임에서 추출된 관절 좌표들로 갱신하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서,특정 시간 시퀀스에서 획득된 서로 다른 시점의 복수의 카메라 각각의 영상 프레임들을 이용하여 피사체인 인체의 3차원 영상을 구성하고, 해당 3차원 영상을 각 카메라의 2차원 평면에 재투영(reprojection)했을 때 얻어지는 2차원 평면에서의 특정 관절의 좌표들과, 상기 포즈 추출부에서 추출한 각 시점의 특정 관절의 좌표들 간의 유클리드 거리를 계산하고, 계산된 유클리드 거리가 제4임계값 이상인 경우, 해당 관절의 좌표를 오검출로 판단하고, 상기 재투영된 2차원 평면에서의 관절 좌표를 해당 특정 관절의 좌표로 사용하는 단계를 더 포함하는 것을 특징으로 하는 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>219980054563</code><country>대한민국</country><engName>KT Corporation</engName><name>주식회사 케이티</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 구로구...</address><code> </code><country> </country><engName>JO, Ji-Eun</engName><name>조지은</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>YOO, Ju-Han</engName><name>유주한</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 서초중앙로 **, *층(서초동, 준영빌딩)</address><code>920071000011</code><country>대한민국</country><engName>PHIL &amp; ONZI INT'L PATENT &amp; LAW FIRM</engName><name>특허법인필앤온지</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.01.05</receiptDate><receiptNumber>1-1-2021-0008464-65</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2022.08.08</receiptDate><receiptNumber>4-1-2022-5185849-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.01.02</receiptDate><receiptNumber>1-1-2024-0004256-96</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>4-1-2025-5080836-48</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210000757.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93868ec81ad06785fd4301cadd4106e1a90ab044ccefbbca409925a14fa26166893aff51b4f8fa94fe3b78057af4bc8b9c02c030345c710de4</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfcf6d45c8393d941558d36e649bd23fa52dc7073eb759a2312d752dba677572f261964ca9d4169c774acb8f7bce01a6459dec2974d0175d84</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>