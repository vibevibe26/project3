<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:42.3942</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.18</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0159308</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>웨어러블 전자 장치 및 웨어러블 전자 장치의 동작 방법</inventionTitle><inventionTitleEng>WEARABLE ELECTRONIC DEVICE AND OPERATING METHOD OF  WEARABLE ELECTRONIC DEVICE</inventionTitleEng><openDate>2023.05.25</openDate><openNumber>10-2023-0072757</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 1/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따르면, 카메라를 포함하는 웨어러블 전자 장치의 동작 방법은 카메라의 뷰에 대응하는 영상 프레임 내에서 사용자의 뷰에 대응하는 관심 영역을 설정하기 위한 사용자의 손의 제1 제스쳐를 인식하고, 제1 제스쳐의 인식 여부를 기초로 관심 영역을 투사하기 위한 가상 디스플레이를 생성하고, 영상 프레임으로부터 관심 영역을 추출하고, 관심 영역의 크기 조절을 위한 손의 제2 제스쳐를 인식하며, 제2 제스쳐의 인식 여부를 기초로 관심 영역의 크기를 조절하여 가상 디스플레이에 투사한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 카메라를 포함하는 웨어러블 전자 장치의 동작 방법에 있어서, 상기 카메라의 뷰에 대응하는 영상 프레임 내에서 사용자의 뷰에 대응하는 관심 영역을 설정하기 위한 상기 사용자의 손의 제1 제스쳐를 인식하는 단계;상기 제1 제스쳐의 인식 여부를 기초로, 상기 관심 영역을 투사하기 위한 가상 디스플레이를 생성하는 단계;상기 영상 프레임으로부터 상기 관심 영역을 추출하는 단계;상기 관심 영역의 크기 조절을 위한 상기 손의 제2 제스쳐를 인식하는 단계; 및 상기 제2 제스쳐의 인식 여부를 기초로, 상기 관심 영역의 크기를 조절하여 상기 가상 디스플레이에 투사하는 단계 를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 관심 영역을 추출하는 단계는상기 영상 프레임에서 상기 사용자의 손 관절들의 위치들을 추정하는 단계; 및 상기 추정된 손 관절들의 위치들을 기초로, 상기 관심 영역을 추출하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 사용자의 손 관절들의 위치들을 추정하는 단계는상기 제1 제스쳐의 유형 별로, 상기 영상 프레임으로부터 상기 사용자의 손 관절들의 위치를 추정하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 관심 영역을 추정하는 단계는상기 제1 제스쳐의 유형 별로 추정된 손 관절들의 위치를 이용하여 상기 관심 영역을 설정하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제2항에 있어서, 상기 손 관절들의 위치들을 추정하는 단계는상기 손 관절들의 위치들 간의 회귀 분석(regression)을 기초로, 상기 손의 회전 각도를 추정하는 단계; 및 상기 추정한 손의 회전 각도를 보정하여 새로운 손 관절들의 위치를 산출하는 단계를 포함하고, 상기 관심 영역을 추출하는 단계는상기 새로운 손 관절들의 위치들을 기초로, 상기 관심 영역을 추출하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서, 상기 관심 영역을 추출하는 단계는상기 추정된 손 관절들의 위치들 간의 가중합을 기초로, 상기 관심 영역의 중심점 및 상기 관심 영역의 각 변의 길이를 산출하는 단계; 및 상기 관심 영역의 중심점 및 상기 관심 영역의 각 변의 길이를 기초로, 상기 관심 영역을 추출하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 관심 영역을 추출하는 단계는미리 학습된 신경망을 이용하여 상기 사용자의 손의 포즈를 추정하는 단계;  상기 추정된 손의 포즈로부터 상기 사용자의 손 관절들의 위치를 추정하는 단계; 및상기 추정된 손 관절들의 위치로부터 상기 관심 영역의 중심 위치, 및 상기 관심 영역의 각 변의 길이를 산출하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 가상 디스플레이는 상기 제1 제스쳐 및 상기 제2 제스쳐 중 어느 하나의 제스쳐가 유지되는지 여부에 따라 표시되는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 가상 디스플레이를 생성하는 단계는상기 카메라의 뷰 위치와 무관하게 상기 가상 디스플레이를 생성하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 제1 제스쳐를 인식하는 단계는상기 영상 프레임 내에서 상기 제1 제스쳐가 인식되지 않는 경우, 상기 영상 프레임의 이전 영상 프레임에서 상기 제1 제스쳐를 인식하는 단계을 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 가상 디스플레이에 투사하는 단계는상기 제2 제스쳐가 인식된 경우, 상기 관심 영역 내 중심부를 고정 배율로 확대하는 단계; 및 상기 확대된 중심부를 상기 가상 디스플레이에 투사하는 단계를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 가상 디스플레이에 투사하는 단계는상기 제1 제스쳐에서 양 손의 검지 손가락들 간의 제1 거리와 상기 제2 제스쳐에서 상기 양 손의 검지 손가락들 간의 제2 거리에 기초한 가변 비율에 의해 상기 관심 영역의 크기를 조절하는 단계; 및 상기 조절된 크기의 관심 영역을 상기 가상 디스플레이에 투사하는 단계 를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 제2 제스쳐가 인식되지 않는 경우, 상기 관심 영역을 상기 가상 디스플레이에 투사하는 단계를 더 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 웨어러블 전자 장치는 VR 글래스(virtual reality glass)를 포함하는 스마트 글래스(smart glass), AR(Augmented Reality) 기기, VR(Virtual Reality) 기기, 및 MR(Mixed Reality) 기기를 포함하는 헤드 마운티드 디스플레이(head mounted display; HMD), 및 아이 마운티드 디스플레이(eye mounted display) 중 적어도 하나를 포함하는, 웨어러블 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>15. 하드웨어와 결합되어 제1항 내지 제14항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>16. 영상 프레임을 획득하는 카메라; 및 상기 카메라의 뷰에 대응하는 영상 프레임 내에서 사용자의 뷰에 대응하는 관심 영역을 설정하기 위한 상기 사용자의 손의 제1 제스쳐를 인식하고, 상기 제1 제스쳐의 인식 여부를 기초로, 상기 관심 영역을 투사하기 위한 가상 디스플레이를 생성하고, 상기 영상 프레임으로부터 상기 관심 영역을 추출하고, 상기 관심 영역의 크기 조절을 위한 상기 손의 제2 제스쳐를 인식하며, 상기 제2 제스쳐의 인식 여부를 기초로, 상기 관심 영역의 크기를 조절하여 상기 가상 디스플레이에 투사하는 프로세서 를 포함하는, 웨어러블 전자 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 프로세서는 상기 영상 프레임에서 상기 사용자의 손 관절들의 위치들을 추정하고, 상기 추정된 손 관절들의 위치들을 기초로, 상기 관심 영역을 추출하는,웨어러블 전자 장치.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 프로세서는 상기 제1 제스쳐의 유형 별로, 상기 영상 프레임으로부터 상기 사용자의 손 관절들의 위치를 추정하고, 상기 제1 제스쳐의 유형 별로 추정된 손 관절들의 위치를 이용하여 상기 관심 영역을 설정하는,웨어러블 전자 장치.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 프로세서는 상기 손 관절들의 위치들 간의 회귀 분석을 기초로, 상기 손의 회전 각도를 추정하고, 상기 추정한 손의 회전 각도를 보정하여 새로운 손 관절의 위치를 산출하며, 상기 새로운 손 관절들의 위치들을 기초로, 상기 관심 영역을 추출하는, 웨어러블 전자 장치.</claim></claimInfo><claimInfo><claim>20. 제17항에 있어서, 상기 프로세서는 상기 추정된 손 관절들의 위치들 간의 가중합을 기초로, 상기 관심 영역의 중심점 및 상기 관심 영역의 각 변의 길이를 산출하고, 상기 관심 영역의 중심점 및 상기 관심 영역의 각 변의 길이를 기초로, 상기 관심 영역을 추출하는, 웨어러블 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Paul OH</engName><name>오바울</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.11.18</receiptDate><receiptNumber>1-1-2021-1331903-29</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.26</receiptDate><receiptNumber>1-1-2024-1050422-15</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.31</receiptDate><receiptNumber>9-5-2025-1058855-38</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210159308.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937827ef9081e78b6b214771b7c823b50a1e5703f7d1635e280d66f0aa14e9d365d88ffafd2d5ebe5ad716f5b11a4c30b530dc79b4d948ad5a</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cface99f7837a24b81b6e4a8378f0ddba74f908521f3111a75a82a892e7d3e39bc8eaec67e812cf1f9a9ff3bc7eb79fadd8d5c0c6ee6725e91</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>