<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:54:43.5443</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.09.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7012589</applicationNumber><claimCount>27</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>심층 예측 정제</inventionTitle><inventionTitleEng>DEEP PREDICTION REFINEMENT</inventionTitleEng><openDate>2023.05.16</openDate><openNumber>10-2023-0067653</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.04.13</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/577</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/124</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/176</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 심층 예측 정제를 위한 방법 및 장치가 개시된다. 픽처의 블록에 대한 제1 모션 보상된 영역 및 상기 블록에 대한 제2 영역이 획득된다. 상기 블록에 대한 예측은 상기 제1 모션 보상된 영역 및 상기 제2 영역을 사용하는 신경 네트워크를 사용하여 결정된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.03.24</internationOpenDate><internationOpenNumber>WO2022058293</internationOpenNumber><internationalApplicationDate>2021.09.14</internationalApplicationDate><internationalApplicationNumber>PCT/EP2021/075156</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,- 픽처의 블록에 대한 제1 모션 보상된 영역을 획득하고 상기 블록에 대한 제2 영역을 획득하는 단계,- 상기 제1 모션 보상된 영역 및 상기 제2 영역을 사용하는 신경 네트워크를 사용하여 상기 블록에 대한 예측을 결정하는 단계, 및- 상기 예측에 기초하여 상기 블록을 인코딩하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 장치로서, 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은,- 픽처의 블록에 대한 제1 모션 보상된 영역을 획득하고 상기 블록에 대한 제2 영역을 획득하도록,- 상기 제1 모션 보상된 영역 및 상기 제2 영역을 사용하는 신경 네트워크를 사용하여 상기 블록에 대한 예측을 결정하도록, 그리고- 상기 예측에 기초하여 상기 블록을 인코딩하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>3. 방법으로서,- 픽처의 블록에 대한 제1 모션 보상된 영역을 획득하고 상기 블록에 대한 제2 영역을 획득하는 단계,- 상기 제1 모션 보상된 영역 및 상기 제2 영역을 사용하는 신경 네트워크를 사용하여 상기 블록에 대한 예측을 결정하는 단계, 및- 상기 예측에 기초하여 상기 블록을 디코딩하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 장치로서, 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은,- 픽처의 블록에 대한 제1 모션 보상된 영역을 획득하고 상기 블록에 대한 제2 영역을 획득하도록,- 상기 제1 모션 보상된 영역 및 상기 제2 영역을 사용하는 신경 네트워크를 사용하여 상기 블록에 대한 예측을 결정하도록, 그리고- 상기 예측에 기초하여 상기 블록을 디코딩하도록 구성되는, 장치.</claim></claimInfo><claimInfo><claim>5. 제1항 또는 제3항의 방법, 또는 제2항 또는 제4항의 장치에 있어서, 상기 예측은 상기 신경 네트워크에 의해 출력되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>6. 제1항 또는 제3항의 방법, 또는 제2항 또는 제4항의 장치에 있어서, 신경 네트워크를 사용하여 상기 블록에 대한 예측을 결정하는 것은,- 상기 신경 네트워크를 사용하여 상기 블록에 대한 예측 정제 파라미터들의 맵을 획득하는 것 - 상기 신경 네트워크는 상기 제1 모션 보상된 영역 및 상기 제2 영역을 사용함 -, 및- 상기 제1 모션 보상된 영역 및 상기 예측 정제 파라미터들의 맵에 적어도 기초하여 상기 블록에 대한 상기 예측을 획득하는 것을 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>7. 제4항의 방법, 또는 제4항의 장치에 있어서, 상기 예측 정제 파라미터들의 맵은 픽셀 기반 예측 정제 파라미터들을 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>8. 제4항의 방법 또는 제4항의 장치에 있어서, 상기 예측 정제 파라미터들의 맵은 상기 블록의 서브-블록들에 대한 예측 정제 파라미터들을 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>9. 제1항, 제3항 또는 제5항 내지 제8항 중 어느 한 항의 방법, 또는 제2항 또는 제4항 내지 제8항 중 어느 한 항의 장치에 있어서, 상기 제2 영역은 상기 블록에 대한 제2 모션 보상된 영역을 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 예측 정제 파라미터들의 맵은 상기 제1 모션 보상된 영역 및 상기 제2 모션 보상된 영역의 가중 합을 획득하기 위해 사용되는 적어도 하나의 가중치 및 상기 가중 합을 보정하기 위해 사용되는 오프셋을 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>11. 제9항에 있어서, 상기 예측 정제 파라미터들의 맵은 제1 가중치 및 제2 가중치로 각각 가중된 상기 제1 모션 보상된 영역 및 상기 제2 모션 보상된 영역으로부터 가중 합을 획득하기 위한 적어도 상기 제1 가중치 및 상기 제2 가중치, 및 상기 가중 합을 보정하기 위한 오프셋을 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>12. 제9항 내지 제11항 중 어느 한 항의 방법, 또는 제9항 내지 제11항 중 어느 한 항의 장치에 있어서,● 제1 비트 깊이는 상기 제1 모션 보상된 영역 및 상기 제2 영역을 획득하기 위해 사용되고,● 제2 비트 깊이는 획득된 상기 제1 모션 보상된 영역 및 상기 제2 영역을 저장하기 위해 사용되고, 상기 제1 비트 깊이는 상기 제2 비트 깊이보다 더 높으며,● 상기 제1 모션 보상된 영역 및 상기 제2 영역은 상기 제2 비트 깊이보다 더 높은 비트 깊이에서 상기 신경 네트워크에 제공되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제1 모션 보상된 영역은 상기 제1 비트 깊이에서 상기 신경 네트워크에 제공되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>14. 제12항 또는 제13항에 있어서, 상기 제1 비트 깊이는, 상기 제1 모션 보상된 영역을 획득하기 위해, 상기 블록에 대해 획득된 적어도 하나의 모션 벡터를 사용하여 제1 기준 픽처로부터의 기준 블록의 모션 보상을 수행하기 위해 사용되는 비트 깊이인, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>15. 제13항 또는 제14항에 있어서, 상기 제1 모션 보상된 영역을 상기 신경 네트워크에 제공하기 전에 상기 제1 비트 깊이에 따라 상기 제1 모션 보상된 영역을 정규화하는 단계를 추가로 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 블록의 예측이 상기 신경 네트워크에 의해 출력될 때 상기 제2 비트 깊이에 따라 상기 예측을 비정규화(de-normalizing)하는 단계를 추가로 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>17. 제1항, 제3항 또는 제5항 내지 제16항 중 어느 한 항의 방법, 또는 제2항 또는 제4항 내지 제16항 중 어느 한 항의 장치에 있어서, 상기 신경 네트워크는,● 적어도 2개의 분기(branch)들을 포함하고, 상기 적어도 2개의 분기들 중 하나의 분기는 제1 블록 크기에서 입력들을 프로세싱하고, 상기 적어도 2개의 분기들 중 다른 하나의 분기는 제2 블록 크기에서 입력들을 프로세싱하며, 상기 제1 블록 크기와 상기 제2 블록 크기는 상이한, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>18. 제5항 내지 제16항 중 어느 한 항에 있어서, 상기 신경 네트워크는 상기 예측 정제 맵의 예측 파라미터 당 하나의 분기를 포함하고, 상기 분기는 적어도 하나의 컨볼루션 층을 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 신경 네트워크의 각각의 분기에 대해 상이한 블록 크기가 사용되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>20. 제18항 또는 제19항에 있어서, 적어도 하나의 층이 상기 분기들 사이에서 공유되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>21. 제1항, 제3항 또는 제5항 내지 제20항 중 어느 한 항의 방법, 또는 제2항 또는 제4항 내지 제20항 중 어느 한 항의 장치에 있어서, 추가 데이터가 상기 신경 네트워크에 제공되고, 상기 추가 데이터는,● 모션 보상에 사용되는 필터를 나타내는 정보,● 상기 제1 및 제2 모션 보상된 영역들이 획득되는 기준 픽처들 사이의 시간적 거리를 나타내는 정보, 및● 상기 블록을 인코딩하기 위해 사용되는 양자화 파라미터를 나타내는 정보 중 적어도 하나를 포함하는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>22. 제1항, 제3항 또는 제5항 내지 제21항 중 어느 한 항의 방법, 또는 제2항 또는 제4항 내지 제21항 중 어느 한 항의 장치에 있어서, 상기 신경 네트워크는 컨볼루션 층들의 세트를 포함하고, 각각의 층에 대한 컨볼루션들의 수는 2의 거듭제곱의 배수인, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>23. 제1항, 제3항 또는 제5항 내지 제22항 중 어느 한 항의 방법, 또는 제2항 또는 제4항 내지 제22항 중 어느 한 항의 장치에 있어서, 상기 신경 네트워크는 스킵 연결(skip connection)을 포함하며, 이 스킵 연결에 따라 상기 제1 모션 보상된 영역 및 상기 제2 영역이 상기 신경 네트워크의 메인 분기의 이전 층의 출력과 함께 상기 신경 네트워크의 다음 층에 제공되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>24. 제21항에 종속되는 제23항에 있어서, 추가 데이터는 상기 신경 네트워크의 메인 분기에만 제공되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>25. 제23항 또는 제24항에 있어서, 상기 신경 네트워크의 다음 층은 상기 신경 네트워크의 마지막 컨볼루션 층인, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>26. 제23항 내지 제25항 중 어느 한 항에 있어서, 상기 신경 네트워크의 다음 층에 제공되기 위해, 상기 스킵 연결의 출력은 상기 신경 네트워크의 메인 분기의 이전 층의 출력에 연접되거나, 또는 상기 스킵 연결의 출력은 상기 신경 네트워크의 메인 분기의 이전 층의 출력에 컨볼루션되고 가산되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 연접 층 전의 상기 신경 네트워크의 메인 분기의 층은 N-2의 컨볼루션들의 수를 갖고, N은 2의 거듭제곱의 배수인, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>28. 제23항 내지 제25항 중 어느 한 항에 있어서, 상기 신경 네트워크의 메인 분기의 이전 층의 출력은 상기 스킵 연결의 입력의 크기에 대응하는 크기를 갖는 제1 부분 및 제2 부분으로 분할되고, 상기 제1 부분은 상기 스킵 연결의 입력에 가산되고, 상기 제2 부분과 연접되고, 상기 신경 네트워크의 다음 층에 제공되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>29. 제1항, 제3항 또는 제5항 내지 제28항 중 어느 한 항의 방법, 또는 제2항 또는 제4항 내지 제28항 중 어느 한 항의 장치에 있어서, 상기 제1 모션 보상된 영역 및 상기 제2 영역은, 상기 신경 네트워크에 의해 사용되기 전에 적어도 상기 신경 네트워크의 수용 필드의 크기에 따라 각각 확대되는, 방법 또는 장치.</claim></claimInfo><claimInfo><claim>30. 하나 이상의 프로세서들로 하여금, 제1항, 제3항 또는 제5항 내지 제29항 중 어느 한 항의 방법을 수행하게 하기 위한 명령어들이 저장된 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>31. 프로그램이 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금, 제1항, 제3항 또는 제5항 내지 제29항 중 어느 한 항의 방법을 수행하게 하는 명령어들을 포함하는 컴퓨터 프로그램 제품.</claim></claimInfo><claimInfo><claim>32. 디바이스로서,- 제2항 또는 제5항 내지 제29항 중 어느 한 항에 따른 장치; 및- (i) 적어도 하나의 이미지의 적어도 하나의 부분을 나타내는 데이터를 포함하는 신호를 수신하도록 구성된 안테나, (ii) 수신된 상기 신호를, 상기 적어도 하나의 이미지의 적어도 하나의 부분을 나타내는 데이터를 포함하는 주파수들의 대역으로 제한하도록 구성된 대역 제한기, 또는 (iii) 상기 적어도 하나의 이미지의 적어도 하나의 부분을 디스플레이하도록 구성된 디스플레이 중 적어도 하나를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>33. 제32항에 있어서, TV, 셀룰러폰, 태블릿 또는 셋톱 박스를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>34. 제1항에 따라 인코딩된 비디오를 나타내는 데이터를 포함하는 비트스트림을 포함하는 신호.</claim></claimInfo><claimInfo><claim>35. 장치로서,- 제34항에 따른 신호를 포함하는 데이터에 액세스하도록 구성된 액세스 유닛, 및- 액세스된 상기 데이터를 송신하도록 구성된 송신기를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>36. 방법으로서, 제34항에 따른 신호를 포함하는 데이터에 액세스하는 단계, 및 액세스된 상기 데이터를 송신하는 단계를 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>프랑스 ***** 빠리 뤼 뒤 꼴로넬 몰 *</address><code>520180576061</code><country>프랑스</country><engName>InterDigital CE Patent Holdings, SAS </engName><name>인터디지털 씨이 페이튼트 홀딩스, 에스에이에스</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>프랑스 세송-세비뉴 ***** 애비뉴 데스 ...</address><code> </code><country> </country><engName>GALPIN, Franck</engName><name>갈핀, 프랑크</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 애비뉴 데스 ...</address><code> </code><country> </country><engName>BORDES, Philippe</engName><name>보르데스, 필리프</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 애비뉴 데스 ...</address><code> </code><country> </country><engName>DUMAS, Thierry</engName><name>두마스, 티에리</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 애비뉴 데스 ...</address><code> </code><country> </country><engName>NASER, Karam</engName><name>나세르, 카람</name></inventorInfo><inventorInfo><address>프랑스 세송-세비뉴 ***** 애비뉴 데스 ...</address><code> </code><country> </country><engName>NIKITIN, Pavel</engName><name>니키틴, 파벨</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920020002981</code><country>대한민국</country><engName>Lee Min Ho</engName><name>이민호</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2020.09.15</priorityApplicationDate><priorityApplicationNumber>20306029.8</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2020.12.18</priorityApplicationDate><priorityApplicationNumber>20306603.0</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2021.03.16</priorityApplicationDate><priorityApplicationNumber>21305320.0</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.04.13</receiptDate><receiptNumber>1-1-2023-0415285-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.04.17</receiptDate><receiptNumber>1-5-2023-0061941-82</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.04.18</receiptDate><receiptNumber>1-1-2023-0433956-43</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2023.04.25</receiptDate><receiptNumber>1-1-2023-0464206-45</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Change of Applicant] Report on Change of Proprietary Status</documentEngName><documentName>[출원인변경]권리관계변경신고서</documentName><receiptDate>2023.10.11</receiptDate><receiptNumber>1-1-2023-1112759-94</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.05</receiptDate><receiptNumber>1-1-2024-0977109-47</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237012589.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93bc3707d24fb922b2487de7b20c773354f6c294abd8be8ad38815f1c22ba30e434a3f4adf9df3a5a0f204cbd25acb0e1da437f378332949c7</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf386252d8df6a618441197b0901368981373c30cee2467cd381ff417beab1c9ddfa90d4ef3d9ddabec25282eeea398448b8bb5049b71bb84a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>