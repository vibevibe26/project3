<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:30.4130</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.12.05</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0174594</applicationNumber><claimCount>13</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전자 장치 및 그의 단일 예시 객체 분할 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE AND ONE-SHOT OBJECT SEGMENTATION METHOD THEREOF</inventionTitleEng><openDate>2025.06.12</openDate><openNumber>10-2025-0085381</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.05</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/42</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 제1영상을 획득하는 단계; 상기 제1영상에 대응하는 적어도 하나의 제1특징맵을 획득하는 단계; 표적과 관련된 단일한 제2영상에 대응하는 제2특징맵 및 상기 적어도 하나의 제1특징맵에 기반하여 적어도 하나의 통합 특징맵을 획득하는 단계; 상기 적어도 하나의 통합 특징맵을 인공신경망에 입력하여, 상기 제1영상에서 상기 표적의 분할(Segmentation) 정보를 출력하는 단계를 포함하는 전자 장치의 단일 예시(One-shot) 객체 분할 방법이 제공된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치의 단일 예시(One-shot) 객체 분할 방법에 있어서,제1영상을 획득하는 단계;상기 제1영상에 대응하는 적어도 하나의 제1특징맵을 획득하는 단계;표적과 관련된 단일한 제2영상에 대응하는 제2특징맵 및 상기 적어도 하나의 제1특징맵에 기반하여 적어도 하나의 통합 특징맵을 획득하는 단계;상기 적어도 하나의 통합 특징맵을 인공신경망에 입력하여, 상기 제1영상에서 상기 표적의 분할(Segmentation) 정보를 출력하는 단계를 포함하는, 단일 예시 객체 분할 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 적어도 하나의 제1특징맵을 획득하는 단계는,상기 제1영상의 적어도 하나의 Region-of-Interest(RoI)별로 상기 적어도 하나의 제1특징맵을 획득하는 단계를 포함하는, 단일 예시 객체 분할 방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 통합 특징맵을 획득하는 단계는,각각의 상기 제1특징맵과 상기 제2특징맵을 곱하여 각각의 제3특징맵을 획득하는 단계;각각의 상기 제3특징맵과 상기 제2특징맵을 곱하여 각각의 제4특징맵을 획득하는 단계;각각의 상기 제4특징맵과 각각의 상기 제1특징맵을 결합(Concatenate)하여 각각의 제5특징맵을 획득하는 단계; 및각각의 상기 제5특징맵과 필터를 합성곱하여 각각의 상기 적어도 하나의 통합 특징맵을 획득하는 단계를 포함하는, 단일 예시 객체 분할 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 분할 정보를 출력하는 단계는,각각의 상기 통합 특징맵을 상기 인공신경망에 입력하여, (i) 각각의 상기 적어도 하나의 RoI별로 상기 표적을 포함할 확률, (ii) 각각의 상기 적어도 하나의 RoI별로 상기 표적을 포함할 것으로 예측되는 바운딩 박스의 좌표 및 (iii) 각각의 상기 적어도 하나의 RoI별로 상기 바운딩 박스 내에서 상기 표적에 해당하는 픽셀에 대한 정보를 포함하는 상기 분할 정보를 출력하는 단계를 포함하는, 단일 예시 객체 분할 방법. </claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 인공신경망으로부터 출력된 학습용 분할 정보, 정답(Ground-Truth, GT) 분할 정보 및 초점 손실함수에 기반하여 로스를 계산하는 단계; 및상기 로스를 역전파함으로써 상기 인공신경망을 학습하는 단계를 더 포함하는, 단일 예시 객체 분할 방법. </claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 로스를 계산하는 단계는,상기 학습용 분할 정보 및 상기 정답 분할 정보에 대응하는 정보에 각각 포함된, 학습용 표적에 대응하는 학습용 픽셀 정보 및 정답 픽셀 정보에 대응하는 정보를 초점 손실함수에 입력함에 따라 출력된 값에 기반하여 상기 로스를 계산하는 단계를 포함하는, 단일 예시 객체 분할 방법. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 로스를 계산하는 단계는,상기 학습용 분할 정보 및 상기 정답 분할 정보에 각각 포함된, 상기 학습용 분할 정보에 대응하는 RoI가 학습용 표적을 포함할지 여부와 관련된 학습용 확률 및 정답 확률에 대응하는 정보를 크로스 엔트로피 손실함수에 입력하여 제1로스를 계산하는 단계;상기 학습용 분할 정보 및 상기 정답 분할 정보에 각각 포함된, 상기 학습용 분할 정보에 대응하는 RoI 상에 상기 학습용 표적이 위치한 영역과 관련된 학습용 바운딩 박스 좌표 및 정답 바운딩 박스 좌표에 대응하는 정보를 L1 손실함수에 입력하여 제2로스를 계산하는 단계; 및상기 제1로스, 상기 제2로스 및 상기 초점 손실함수에서 출력된 값에 대응하는 제3로스에 기반하여 상기 로스를 계산하는 단계를 포함하는, 단일 예시 객체 분할 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 제1영상은 적성(Hostile) 목표의 이미지를 포함할 것으로 예측되는 하나 이상의 영상 중 적어도 일부로서 획득되고, 상기 제2영상은, 상기 적성 목표의 표지와 관련된 상기 표적을 포함하는, 단일 예시 객체 분할 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 적성 목표는, 적성 그룹의 인물, 장비 및 시설물 중 적어도 일부를 포함하고, 상기 적성 목표의 표지는, 상기 인물의 안면 형상 및 복장 패턴, 상기 장비 및 상기 시설물의 형상 및 위장 패턴 중 적어도 일부를 포함하고,상기 표지 중 어느 하나의 선택을 확인하는 단계;상기 선택된 표지 중 어느 하나를 상기 표적으로서 포함하는 상기 제2영상을 확인하는 단계를 포함하는, 단일 예시 객체 분할 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제2영상을 확인하는 단계는,상기 선택된 표지의 3차원 모델링 정보를 확인하는 단계; 및상기 3차원 모델링 정보에 기반한, 상기 제1영상의 촬영 각도 및 거리에 대응하는 상기 선택된 표지의 투상도를 상기 제2영상으로서 확인하는 단계를 포함하는, 단일 예시 객체 분할 방법. </claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 제1영상의 촬영 각도 및 거리, 상기 선택된 표지 및 상기 제1영상의 소스 정보에 기반하여, 상기 분할 정보의 신뢰도를 계산하는 단계를 더 포함하는, 단일 예시 객체 분할 방법.</claim></claimInfo><claimInfo><claim>12. 전자 장치의 단일 예시 객체 분할 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한, 컴퓨터로 읽을 수 있는 비일시적 기록매체로서,상기 단일 예시 객체 분할 방법은,제1영상을 획득하는 단계;상기 제1영상에 대응하는 적어도 하나의 제1특징맵을 획득하는 단계;표적과 관련된 단일한 제2영상에 대응하는 제2특징맵 및 상기 적어도 하나의 제1특징맵에 기반하여 적어도 하나의 통합 특징맵을 획득하는 단계;상기 적어도 하나의 통합 특징맵을 인공신경망에 입력하여, 상기 제1영상에서 상기 표적의 분할(Segmentation) 정보를 출력하는 단계를 포함하는, 비일시적 기록매체.</claim></claimInfo><claimInfo><claim>13. 전자 장치로서,프로세서; 및하나 이상의 인스트럭션을 저장하는 메모리를 포함하고,상기 프로세서는, 상기 하나 이상의 인스트럭션을 수행함으로써, 분석될 제1영상을 획득하고, 상기 제1영상에 대응하는 적어도 하나의 제1특징맵을 획득하고, 표적과 관련된 단일한 제2영상에 대응하는 단일한 제2특징맵 및 상기 적어도 하나의 제1특징맵에 기반하여 적어도 하나의 통합 특징맵을 획득하고, 상기 통합 특징맵을 인공신경망에 입력하여, 상기 제1영상에서 상기 표적의 분할(Segmentation) 정보를 출력하도록 설정된, 전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 과천시 ...</address><code>220070077938</code><country>대한민국</country><engName>Republic Of Korea(Defense Acquisition Program Administration)</engName><name>대한민국(방위사업청장)</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>HEO, Yuk</engName><name>허육</name></inventorInfo><inventorInfo><address>서울특별시 성북구...</address><code> </code><country> </country><engName>KIM, Chang Su</engName><name>김창수</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 남대문로 **, *층(소공동, 한진빌딩 본관)</address><code>920151000211</code><country>대한민국</country><engName>Lee &amp; Ko IP</engName><name>특허법인광장리앤고</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.12.05</receiptDate><receiptNumber>1-1-2023-1362500-28</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230174594.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934103e335b430701823865a8927b2372a702dbb4ff9cf540eee43ea6a6ac4f8ebacb21cf470e3cde5539348c2d7f1ce5a9ee3ed4ce8c1541e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfc25226d5de4f95cd42b5b038f5c9b4dfa070eb4b855e73c586fbdbcb0465839686868260144efda25fec01f8172d23fe4374049417895cb9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>