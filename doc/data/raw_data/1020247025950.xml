<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:53.5153</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7025950</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>방법, 장치 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>METHOD, APPARATUS AND COMPUTER PROGRAM</inventionTitleEng><openDate>2024.09.30</openDate><openNumber>10-2024-0142448</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.07.31</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 21/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/30</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 컴퓨터로 구현된 방법은 사용자 디바이스로부터 사용자로부터의 비디오 데이터를 수신하는 단계와, 비디오 데이터에 기초하여 제1 머신 러닝 모델을 트레이닝시켜 제2 머신 러닝 모델을 생성하는 단계 - 제2 머신 러닝 모델은 사용자에게 개인화되고, 제2 머신 러닝 모델은 오디오 데이터에 기초하여 사용자의 움직임을 예측하도록 트레이닝됨 - 와, 사용자로부터 추가 오디오 데이터를 수신하는 단계와, 추가 오디오 데이터 및 제2 머신 러닝 모델에 기초하여 사용자의 예측된 움직임을 결정하는 단계와, 사용자의 예측된 움직임을 사용하여 사용자의 아바타의 애니메이션을 생성하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.08.03</internationOpenDate><internationOpenNumber>WO2023146741</internationOpenNumber><internationalApplicationDate>2023.01.06</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/010261</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터로 구현되는 방법으로서, 사용자 디바이스로부터 사용자의 비디오 데이터를 수신하는 단계 - 상기 비디오 데이터는 오디오 데이터 및 상기 오디오 데이터에 대응하는 이미지 데이터를 포함함 - 와, 상기 비디오 데이터에 기초하여 제1 머신 러닝 모델을 트레이닝시켜 제2의 트레이닝된 머신 러닝 모델을 생성하는 단계 - 상기 제2의 트레이닝된 머신 러닝 모델은 상기 사용자에게 개인화되고(personalized), 상기 제2의 트레이닝된 머신 러닝 모델은 상기 사용자의 움직임을 예측하도록 구성됨 - 와, 상기 사용자 디바이스로부터 추가 오디오 데이터를 수신하는 단계와,  상기 추가 오디오 데이터를 상기 제2의 트레이닝된 머신 러닝 모델에 입력하여 상기 사용자의 예측된 움직임을 생성하는 단계와, 상기 사용자 디바이스로부터 상기 사용자의 예측된 움직임 중 적어도 하나의 움직임의 정도를 변경하는 적어도 하나의 입력을 수신하여, 상기 사용자에 대한 맞춤형 움직임(customized movement)을 생성하는 단계와, 상기 사용자에 대한 상기 맞춤형 움직임을 사용하여 상기 사용자의 아바타의 애니메이션을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 사용자의 예측된 움직임은 상기 사용자의 입술 움직임, 상기 사용자의 머리 자세의 변화, 상기 사용자의 얼굴 표정의 변화 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2 항에 있어서, 추가 사용자 디바이스와 통신하는 단계를 포함하되, 상기 추가 사용자 디바이스와 통신하는 동안 상기 아바타의 애니메이션이 사용되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 비디오 데이터에 기초하여 상기 제1 머신 러닝 모델을 트레이닝시키는 것은 적어도 부분적으로 클라우드 컴퓨팅 디바이스에 의해 수행되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 비디오 데이터에 기초하여 상기 제1 머신 러닝 모델을 트레이닝시키는 것은 적어도 부분적으로 상기 사용자 디바이스에 의해 수행되는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 비디오 데이터는 상기 사용자의 하나 초과의 비디오를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 방법은, 상기 예측된 움직임에 기초하여, 그리고 상기 사용자 장치로부터의 상기 아바타의 애니메이션의 제1 맞춤화(customization)에 기초하여 상기 사용자의 제1 페르소나(persona)를 생성하는 단계와, 상기 사용자의 상기 비디오 데이터 및 상기 사용자 디바이스로부터의 상기 아바타의 애니메이션의 제2 맞춤화에 기초한 상기 예측된 움직임과, 상기 비디오 데이터와 상이한 제2 비디오 데이터를 사용한 상기 사용자의 다른 예측된 움직임과,  상기 비디오 데이터와 상이한 상기 사용자의 제3 비디오 데이터 및 상기 사용자 디바이스로부터의 상기 아바타의 애니메이션의 제3 맞춤화를 사용한 상기 사용자의 다른 예측된 움직임 중 적어도 하나에 기초하여 상기 사용자의 제2 페르소나를 생성하는 단계를 포함하며, 상기 방법은,  상기 사용자의 제2 페르소나를 저장하는 단계와,  상기 아바타의 애니메이션을 제공하기 위해 상기 사용자에게 상기 사용자의 제1 페르소나 또는 상기 사용자의 제2 페르소나를 선택할 수 있는 옵션을 제공하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 상기 사용자 디바이스로부터 아바타의 외모를 편집하는 정보를 수신하는 단계와, 상기 사용자 디바이스로부터의 상기 아바타의 외모를 편집하는 상기 수신된 정보에 기초하여 상기 아바타를 업데이트하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 방법은, 상기 사용자와 유사한 외모를 갖는 표현을 결정하는 단계와, 상기 표현에 기초하여 상기 아바타의 외모를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서, 트레이닝 데이터세트가 복수의 사용자 각각에 대한 둘 이상의 비디오를 포함하고, 상기 비디오 각각은 제각기의 사용자의 머리의 적어도 하나의 라벨링된 정점(vertex)을 가지며, 상기 방법은, i) 상기 복수의 사용자 중 사용자의 적어도 하나의 비디오에 기초하여 제3 머신 러닝 모델을 트레이닝시켜 제4 머신 러닝 모델을 제공하는 단계와, ii) 오디오 데이터의 적어도 하나의 부분 및 상기 제4 머신 러닝 모델에 기초하여 상기 복수의 사용자 중 상기 사용자의 머리 움직임을 예측하는 단계 - 상기 오디오 데이터의 상기 적어도 하나의 부분 각각은 대응하는 비디오를 가짐 - 와, iii) 상기 예측된 머리 움직임 및 상기 오디오 데이터의 적어도 하나의 부분 각각에 대한 상기 대응하는 비디오 내의 상기 사용자의 머리의 적어도 하나의 라벨링된 정점을 사용하여, 상기 오디오 데이터의 적어도 하나의 부분에 대한 상기 예측된 머리 움직임에 대한 오차를 계산하는 단계와, iv) 상기 복수의 사용자 중 상기 사용자의 상기 예측된 머리 움직임에 대한 상기 오차를 역전파하여 상기 제3 머신 러닝 모델의 파라미터를 업데이트하는 단계를 포함하며, 상기 방법은,  상기 복수의 사용자들의 무작위 샘플에 대해, 상기 오차가 상기 샘플의 한 사용자로부터 다음 사용자로 수렴될 때까지 i) 내지 iv) 단계를 반복하는 단계와,  이어서, 상기 제3 머신 러닝 모델을 상기 제1 머신 러닝 모델로 사용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 제1 머신 러닝 모델, 상기 제2의 트레이닝된 머신 러닝 모델, 상기 제3 머신 러닝 모델 및 상기 제4 머신 러닝 모델 중 적어도 하나는 상기 사용자의 머리 자세의 변화, 상기 사용자의 표정의 변화 및 상기 사용자의 입술 움직임을 예측하도록 구성된 콘볼루션 신경망(convolutional neural network), 상기 사용자의 머리 자세의 변화, 상기 사용자의 표정의 변화 및 상기 사용자의 입술 움직임을 예측하도록 구성된 순차적 신경망 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 제1 머신 러닝 모델은, 오디오 데이터에 대해 작동하여 상기 사용자의 머리 자세의 변화, 상기 사용자의 표정의 변화 및 상기 사용자의 입술 움직임을 예측하도록 구성된 콘볼루션 신경망과, 오디오 데이터에 대해 작동하여 상기 사용자의 머리 자세의 변화, 상기 사용자의 표정의 변화 및 상기 사용자의 입술 움직임을 예측하도록 구성된 순차적 신경망 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 비디오 데이터에 기초하여 상기 제 1 머신 러닝 모델을 트레이닝시키는 것은 적어도 하나의 퓨 샷(few-shot) 학습 기법을 사용하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 장치로서, 적어도 하나의 프로세서와, 컴퓨터 프로그램 코드를 포함하는 적어도 하나의 메모리를 포함하되, 상기 적어도 하나의 메모리 및 컴퓨터 프로그램 코드는 상기 적어도 하나의 프로세서에 의해 상기 장치로 하여금,  사용자 디바이스로부터 사용자로부터의 비디오 데이터를 수신하는 것 - 상기 비디오 데이터는 오디오 데이터 및 상기 오디오 데이터에 대응하는 이미지 데이터를 포함함 - 과,  상기 비디오 데이터에 기초하여 제1 머신 러닝 모델을 트레이닝시켜 제2의 트레이닝된 머신 러닝 모델을 생성하는 것 - 상기 제2의 트레이닝된 머신 러닝 모델은 상기 사용자에게 개인화되고, 상기 제2의 트레이닝된 머신 러닝 모델은 상기 사용자의 움직임을 예측하도록 트레이닝됨 - 과,  상기 사용자 디바이스로부터 추가 오디오 데이터를 수신하는 것과,   상기 추가 오디오 데이터를 상기 제2의 트레이닝된 머신 러닝 모델에 입력하여 상기 사용자의 예측된 움직임을 생성하는 것과,  상기 사용자 디바이스로부터 상기 사용자의 예측된 움직임 중 적어도 하나의 움직임의 정도를 변경하는 적어도 하나의 입력을 수신하여, 상기 사용자에 대한 맞춤형 움직임(customized movement)을 생성하는 것과,  상기 사용자에 대한 상기 맞춤형 움직임을 사용하여 상기 사용자의 아바타의 애니메이션을 생성하는 것을 수행하게 하는, 장치.</claim></claimInfo><claimInfo><claim>15. 프로세서에 의해 실행 가능한 명령어를 포함하는 컴퓨터 판독 가능 저장 디바이스로서, 상기 명령어는, 사용자 디바이스로부터 사용자의 비디오 데이터를 수신하고 - 상기 비디오 데이터는 오디오 데이터 및 상기 오디오 데이터에 대응하는 이미지 데이터를 포함함 -, 상기 비디오 데이터에 기초하여 제1 머신 러닝 모델을 트레이닝시켜 제2의 트레이닝된 머신 러닝 모델을 생성하며 - 상기 제2의 트레이닝된 머신 러닝 모델은 상기 사용자에게 개인화되고, 상기 제2의 트레이닝된 머신 러닝 모델은 상기 사용자의 움직임을 예측할 수 있음 -, 상기 사용자 디바이스로부터 추가 오디오 데이터를 수신하고,  상기 추가 오디오 데이터를 상기 제2의 트레이닝된 머신 러닝 모델에 입력하여 상기 사용자의 예측된 움직임을 생성하며, 상기 사용자 디바이스로부터 상기 사용자의 예측된 움직임 중 적어도 하나의 움직임의 정도를 변경하는 적어도 하나의 입력을 수신하여, 상기 사용자에 대한 맞춤형 움직임(customized movement)을 생성하고, 상기 사용자에 대한 상기 맞춤형 움직임을 사용하여 상기 사용자의 아바타의 애니메이션을 생성하기 위한 것인, 컴퓨터 판독 가능 저장 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 워싱턴주 (우편번호 : *****) 레드몬드 원 마이크로소프트 웨이</address><code>520140606680</code><country>미국</country><engName>Microsoft Technology Licensing, LLC</engName><name>마이크로소프트 테크놀로지 라이센싱, 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 워싱턴주 *****-**** 레드몬드 ...</address><code> </code><country> </country><engName>CAMERON, Pashmina Jonathan</engName><name>카메론 파슈미나 조나단  </name></inventorInfo><inventorInfo><address>미국 워싱턴주 *****-**** 레드몬드 ...</address><code> </code><country> </country><engName>MORRISON, Cecily Peregrine Borgatti</engName><name>모리슨 세실리 페레그린 보르가티</name></inventorInfo><inventorInfo><address>미국 워싱턴주 *****-**** 레드몬드 ...</address><code> </code><country> </country><engName>GRAYSON, Martin Philip</engName><name>그레이슨 마틴 필립</name></inventorInfo><inventorInfo><address>미국 워싱턴주 *****-**** 레드몬드 ...</address><code> </code><country> </country><engName>MASSICETI, Daniela</engName><name>마시세티 다니엘라</name></inventorInfo><inventorInfo><address>미국 워싱턴주 *****-**** 레드몬드 ...</address><code> </code><country> </country><engName>JOHNSON, Matthew Alastair</engName><name>존슨 매튜 알라스테어</name></inventorInfo><inventorInfo><address>미국 워싱턴주 *****-**** 레드몬드 ...</address><code> </code><country> </country><engName>RINTEL, Edward Sean Lloyd</engName><name>린텔 에드워드 숀 로이드</name></inventorInfo><inventorInfo><address>미국 워싱턴주 *****-**** 레드몬드 ...</address><code> </code><country> </country><engName>FAIA MARQUES, Rita</engName><name>파이아 마르케스 리타</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2022.01.31</priorityApplicationDate><priorityApplicationNumber>22154373.9</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.07.31</receiptDate><receiptNumber>1-1-2024-0835787-86</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.09.03</receiptDate><receiptNumber>1-5-2024-0144574-32</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247025950.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=348aaf18c46825cf02d6c2de1c78338e2bd3a9276dafcb92dc6a11d646e8743981674da086c6f46f6e38dea57ce442578d0c6f8e7e8253c58d87edd23389cdb460f0268651898ac6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf29f3a01beb4bd35d85082d3306cccec2e22652ce29ac13e5bddc2642cb17fac907ff9c2ecee8c5c7e4a00c2e510896478f41c87c17d1009f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>