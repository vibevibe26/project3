<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:23.3723</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0145630</applicationNumber><claimCount>19</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공지능 기반 분류 모델의 온라인 점진 학습 방법 및 이를 수행하기 위한 컴퓨팅 장치</inventionTitle><inventionTitleEng>Online incremental learning method of artificial  intelligence-based classification model and computing  device for performing the same</inventionTitleEng><openDate>2025.05.08</openDate><openNumber>10-2025-0061319</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/24</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 인공지능 기반 분류 모델의 온라인 점진 학습 방법 및 이를 수행하기 위한 컴퓨팅 장치가 개시된다. 개시되는 일 실시예에 따른 학습 방법은, 하나 이상의 프로세서들, 및 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되고, 인공지능 기반의 분류 모델을 학습하기 위한 방법으로서, 학습 데이터 셋 내의 모든 데이터들을 기 설정된 제1 비율에 따라 제1 타입의 데이터와 제2 타입의 데이터로 구분하는 단계, 제1 타입의 데이터들에 대해 기 설정된 제2 비율에 따라 각 태스크에 나누어 분배하는 단계, 제1 타입의 데이터와 제2 타입의 데이터를 합하여 각 태스크에 대한 학습 데이터를 생성하는 단계, 및 생성한 학습 데이터를 분류 모델에 입력하여 분류 모델을 학습시키는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되고, 인공지능 기반 분류 모델의 온라인 점진 학습 방법으로서, 학습 데이터 셋 내의 모든 데이터들을 기 설정된 제1 비율에 따라 제1 타입의 데이터와 제2 타입의 데이터로 구분하는 단계;상기 제1 타입의 데이터들에 대해 기 설정된 제2 비율에 따라 각 태스크에 나누어 분배하는 단계; 상기 제1 타입의 데이터와 상기 제2 타입의 데이터를 합하여 각 태스크에 대한 학습 데이터를 생성하는 단계; 및상기 생성한 학습 데이터를 분류 모델에 입력하여 상기 분류 모델을 학습시키는 단계를 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서, 상기 제1 타입의 데이터는, 해당 데이터가 여러 개의 태스크에 걸쳐서 등장하는 데이터이고, 상기 제2 타입의 데이터는, 해당 데이터가 하나의 태스크에만 등장하는 데이터인, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>3. 청구항 2에 있어서, 상기 제2 비율은, 각 태스크에서 제1 타입의 데이터가 메이저 클래스(major class)로 분류되는 데이터와 마이너 클래스(minor class)로 분류되는 데이터 간의 비율인, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>4. 청구항 1에 있어서, 상기 분류 모델을 학습시키는 단계는, 상기 학습 데이터에서 특징을 추출하고, 상기 추출한 특징에 기초하여 기 설정된 프롬프트 풀에서 하나 이상의 프롬프트를 선택하는 단계를 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>5. 청구항 4에 있어서, 상기 프롬프트를 선택하는 단계는, 상기 추출한 특징과 상기 프롬프트 풀에 저장된 키 벡터들 간의 유사도에 기초하여 하나 이상의 키 벡터를 선택하고, 상기 선택된 키 벡터에 대응하는 프롬프트를 추출하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>6. 청구항 5에 있어서, 상기 분류 모델을 학습시키는 단계는, 상기 프롬프트 풀의 키 벡터들이 학습이 될수록 특징 공간(feature space)에서 움직임이 둔해지도록 하면서 키 벡터들 간의 거리가 유지되도록 상기 프롬프트 풀을 학습하는 단계를 더 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>7. 청구항 6에 있어서, 상기 프롬프트 풀의 학습은 하기의 수학식에 따른 제1 손실 함수(LCVPT)에 기초하여 수행되는, 분류 모델의 학습 방법.(수학식)P : 프롬프트 풀의 사이즈B : 학습 데이터의 개수δ : 코사인 거리kp : p번째 프롬프트에 대응하는 키 벡터qq : q번째 학습 데이터의 특징Cp : p번째 프롬프트가 선택되는 횟수</claim></claimInfo><claimInfo><claim>8. 청구항 4에 있어서, 상기 분류 모델을 학습시키는 단계는, 상기 학습 데이터의 토큰과 함께 상기 학습 데이터에 대한 CLS(Classification) 토큰을 상기 분류 모델의 입력단으로 입력하는 단계; 및상기 선택한 프롬프트를 상기 분류 모델의 일부 레이어로 직접 입력하는 단계를 더 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>9. 청구항 8에 있어서, 상기 분류 모델을 학습시키는 단계는, 상기 분류 모델의 출력단에서 상기 CLS 토큰의 특징을 출력하고, 상기 CLS 토큰의 특징을 분류기에 통과시켜 CLS 토큰의 출력 분포를 생성하는 단계;상기 선택된 프롬프트와 대응되는 마스크를 추출하는 단계; 및상기 CLS 토큰의 출력 분포에 상기 마스크를 적용하여 상기 CLS 토큰의 마스크 된 출력 분포를 생성하는 단계를 더 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>10. 청구항 8에 있어서, 상기 분류 모델을 학습시키는 단계는, 상기 분류 모델의 상기 학습 데이터 전체에 대한 평균 그래디언트 벡터(average gradient vector)와 상기 분류 모델의 각 학습 데이터의 그래디언트 벡터에 기초하여 각 학습 데이터의 무시 스코어(ignorance score)를 산출하는 단계; 및상기 무시 스코어에 기초하여 소수(minor) 분류로 분류된 학습 데이터에 대한 손실을 강조하는 단계를 더 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>11. 청구항 10에 있어서, 상기 무시 스코어는, 상기 분류 모델의 학습 중 다른 학습 데이터가 해당 학습 데이터를 무시하는 정도를 나타낸 것이고, 상기 무시 스코어는, 상기 학습 데이터 전체에 대한 평균 그래디언트 벡터(average gradient vector)와 각 학습 데이터의 그래디언트 벡터 간의 유사도에 기초하여 산출되는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>12. 청구항 11에 있어서, 상기 소수 분류로 분류된 학습 데이터에 대한 손실을 강조하는 단계는, 하기 수학식에 따른 제2 손실 함수(LGSF)에 기초하여 수행되는, 분류 모델의 학습 방법.(수학식)B : 배치 당 학습 데이터의 개수Scoreiign : i번째 학습 데이터에 대한 무시 스코어LCE : 교차 엔트로피 손실yi : i번째 학습 데이터의 분류에 대한 정답 값: i번째 학습 데이터의 분류 모델의 분류에 대한 예측 값: 기 설정되는 하이퍼 파라미터</claim></claimInfo><claimInfo><claim>13. 청구항 8에 있어서, 상기 분류 모델을 학습시키는 단계는, 각 학습 데이터에 대해 마진 이익 스코어(marginal benefit score)를 산출하는 단계; 및상기 마진 이익 스코어에 기초하여 해당 학습 데이터의 CLS 토큰의 특징 크기를 조절하는 단계를 더 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>14. 청구항 13에 있어서, 상기 마진 이익 스코어는, 각 학습 데이터가 상기 분류 모델의 학습에 얼마나 이익이 되는지를 나타내는 정도이고, 상기 마진 이익 스코어는, 각 학습 데이터의 CLS 토큰의 특징과 해당 학습 데이터의 정답 값에 대한 분류기의 가중치에 기초하여 산출되는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>15. 청구항 14에 있어서, 상기 마진 이익 스코어(ScoreMB)는 하기 수학식에 의해 산출되는, 분류 모델의 학습 방법.(수학식)δ : 코사인 거리(cosine distance): i번째 학습 데이터의 정답 값에 대응하는 분류기의 가중치xi : i번째 학습 데이터f(xi): i번째 학습 데이터의 CLS 토큰의 특징m : 기 설정되는 마진(margin)</claim></claimInfo><claimInfo><claim>16. 청구항 13에 있어서, 상기 CLS 토큰의 특징 크기를 조절하는 단계는, 상기 마진 이익 스코어가 클수록 해당 학습 데이터의 상기 CLS 토큰의 특징 크기가 작도록 조절하고, 상기 마진 이익 스코어가 작을수록 해당 학습 데이터의 CLS 토큰의 특징 크기가 크도록 조절하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>17. 하나 이상의 프로세서들;메모리; 및하나 이상의 프로그램들을 포함하고,상기 하나 이상의 프로그램들은 상기 메모리에 저장되고, 상기 하나 이상의 프로세서들에 의해 실행되도록 구성되며, 상기 하나 이상의 프로그램들은, 학습 데이터 셋 내의 모든 데이터들을 기 설정된 제1 비율에 따라 제1 타입의 데이터와 제2 타입의 데이터로 구분하기 위한 명령;상기 제1 타입의 데이터들에 대해 기 설정된 제2 비율에 따라 각 태스크에 나누어 분배하기 위한 명령;상기 제1 타입의 데이터와 상기 제2 타입의 데이터를 합하여 각 태스크에 대한 학습 데이터를 생성하기 위한 명령; 및상기 생성한 학습 데이터를 분류 모델에 입력하여 상기 분류 모델을 학습시키기 위한 명령을 포함하는, 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>18. 하나 이상의 프로세서들, 및상기 하나 이상의 프로세서들에 의해 실행되는 하나 이상의 프로그램들을 저장하는 메모리를 구비한 컴퓨팅 장치에서 수행되고, 인공지능 기반의 분류 모델을 학습하기 위한 방법으로서, 학습 데이터 셋 내의 모든 데이터들을 기 설정된 제1 비율에 따라 제1 타입의 데이터와 제2 타입의 데이터로 구분하는 단계;상기 제1 타입의 데이터들에 대해 기 설정된 제2 비율에 따라 각 태스크에 나누어 분배하는 단계; 상기 제1 타입의 데이터와 상기 제2 타입의 데이터를 합하여 각 태스크에 대한 학습 데이터를 생성하는 단계;상기 학습 데이터에서 특징을 추출하고, 상기 추출한 특징에 기초하여 기 설정된 프롬프트 풀에서 하나 이상의 프롬프트를 선택하는 단계; 및상기 선택한 프롬프트를 상기 분류 모델의 일부 레이어로 입력하여 상기 학습 데이터와 함께 상기 분류 모델을 학습시키는 단계를 포함하는, 분류 모델의 학습 방법.</claim></claimInfo><claimInfo><claim>19. 하나 이상의 프로세서들;메모리; 및하나 이상의 프로그램들을 포함하고,상기 하나 이상의 프로그램들은 상기 메모리에 저장되고, 상기 하나 이상의 프로세서들에 의해 실행되도록 구성되며, 상기 하나 이상의 프로그램들은, 학습 데이터 셋 내의 모든 데이터들을 기 설정된 제1 비율에 따라 제1 타입의 데이터와 제2 타입의 데이터로 구분하기 위한 명령;상기 제1 타입의 데이터들에 대해 기 설정된 제2 비율에 따라 각 태스크에 나누어 분배하기 위한 명령;상기 제1 타입의 데이터와 상기 제2 타입의 데이터를 합하여 각 태스크에 대한 학습 데이터를 생성하기 위한 명령;상기 학습 데이터에서 특징을 추출하고, 상기 추출한 특징에 기초하여 기 설정된 프롬프트 풀에서 하나 이상의 프롬프트를 선택하기 위한 명령; 및상기 선택한 프롬프트를 상기 분류 모델의 일부 레이어로 입력하여 상기 학습 데이터와 함께 상기 분류 모델을 학습시키기 위한 명령을 포함하는, 컴퓨팅 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 용인시 기흥구...</address><code>220040073623</code><country>대한민국</country><engName>University-Industry Cooperation Group of Kyung Hee  University</engName><name>경희대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 화성시 삼성*...</address><code> </code><country> </country><engName>PARK, Gyeong-Moon</engName><name>박경문</name></inventorInfo><inventorInfo><address>강원특별자치도 춘천시 안마산로 ***...</address><code> </code><country> </country><engName>MOON, Jun Yeong</engName><name>문준영</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>PARK, Keon Hee</engName><name>박건희</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로***, *층(논현동,시그너스빌딩)</address><code>920141000411</code><country>대한민국</country><engName>DooHo IP Law Firm</engName><name>두호특허법인</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.27</receiptDate><receiptNumber>1-1-2023-1185343-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2024.05.10</receiptDate><receiptNumber>4-1-2024-5148916-30</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230145630.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93036444d076c976119a1e75cee10acf7eaa97c5570e8a037a87e5079ae50096110486e465ca96341112a2769b5829a61c7762c3637bac73f3</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf79c7f827b03b71df533052fe73ce8c3cf47233c58996b103bdbcaa3f3b0fe385d4a92c8f8934af81e4b5835b9229f79286dd9eabcbf88863</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>