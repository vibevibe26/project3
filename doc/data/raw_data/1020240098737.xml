<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:11.1011</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.07.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0098737</applicationNumber><claimCount>9</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>확률적 대칭화 학습 방법 및 시스템</inventionTitle><inventionTitleEng>METHOD FOR LEARNING PROBABILISTIC SYMMETRIZATION AND THE  SYSTEM THEREOF</inventionTitleEng><openDate>2025.05.28</openDate><openNumber>10-2025-0075432</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.03.26</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/047</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/042</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 등변성 아키텍처에 구애받지 않는(agnostic) 확률적 대칭화 학습 방법 및 시스템에 관한 것으로서, 입력 데이터로부터 대칭변환 연산자를 확률적으로 샘플링하는 단계, 상기 샘플링된 각 대칭변환 연산자에 따라 상기 입력 데이터를 대칭 변환하며, 각 입력 변환을 기저 신경망을 통해 출력하는 단계 및 상기 출력을 상기 입력 변환에 대해 역변환한 후, 평균하여 최종 출력을 산출하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 프로세서에 의해 수행되는 확률적 대칭화 학습 방법에 있어서,입력 데이터로부터 대칭변환 연산자를 확률적으로 샘플링하는 단계;상기 샘플링된 각 대칭변환 연산자에 따라 상기 입력 데이터를 대칭 변환하며, 각 입력 변환을 기저 신경망을 통해 출력하는 단계; 및 상기 출력을 상기 입력 변환에 대해 역변환한 후, 평균하여 최종 출력을 산출하는 단계를 포함하는 확률적 대칭화 학습 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 샘플링하는 단계는상기 입력 데이터로부터 이에 대한 상기 대칭변환 연산자를 확률적으로 추정하는 확률추정 신경망을 이용하여 상기 대칭변환 연산자를 적어도 한 번 이상 샘플링하는, 확률적 대칭화 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 대칭변환 연산자는대칭화 과정에 사용되는 연산자를 나타내는 것을 특징으로 하는, 확률적 대칭화 학습 방법. </claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 출력하는 단계는상기 샘플링된 각 대칭변환 연산자에 따라 상기 입력 데이터를 대칭 변환한 후, 변환된 입력으로부터 출력을 계산하는 상기 기저 신경망을 이용하여 상기 입력 변환에 대한 출력을 산출하는, 확률적 대칭화 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 최종 출력을 산출하는 단계는역변환 모듈을 이용하여 상기 기저 신경망을 통해 산출된 상기 출력을 상기 입력 변환에 대해 역변환하며, 역변환된 값을 평균화하여 최종 출력을 산출하는, 확률적 대칭화 학습 방법.</claim></claimInfo><claimInfo><claim>6. 입력 데이터로부터 대칭변환 연산자를 확률적으로 샘플링하는 샘플링부;상기 샘플링된 각 대칭변환 연산자에 따라 상기 입력 데이터를 대칭 변환하며, 각 입력 변환을 기저 신경망을 통해 출력하는 제1 처리부; 및 상기 출력을 상기 입력 변환에 대해 역변환한 후, 평균하여 최종 출력을 산출하는 제2 처리부를 포함하는 확률적 대칭화 학습 시스템. </claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 샘플링부는상기 입력 데이터로부터 이에 대한 상기 대칭변환 연산자를 확률적으로 추정하는 확률추정 신경망을 이용하여 상기 대칭변환 연산자를 적어도 한 번 이상 샘플링하는, 확률적 대칭화 학습 시스템.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 제1 처리부는상기 샘플링된 각 대칭변환 연산자에 따라 상기 입력 데이터를 대칭 변환한 후, 변환된 입력으로부터 출력을 계산하는 상기 기저 신경망을 이용하여 상기 입력 변환에 대한 출력을 산출하는, 확률적 대칭화 학습 시스템.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,상기 제2 처리부는역변환 모듈을 이용하여 상기 기저 신경망을 통해 산출된 상기 출력을 상기 입력 변환에 대해 역변환하며, 역변환된 값을 평균화하여 최종 출력을 산출하는, 확률적 대칭화 학습 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980988661</code><country>대한민국</country><engName>Korea Advanced Institute of Science and Technology</engName><name>한국과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Hong, Seunghoon</engName><name>홍승훈</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Kim, Jinwoo</engName><name>김진우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로***길 ** (논현동) 삼성빌딩 *층(피앤티특허법률사무소)</address><code>920050004530</code><country>대한민국</country><engName>Yang,Sung Bo</engName><name>양성보</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.11.21</priorityApplicationDate><priorityApplicationNumber>1020230162420</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.07.25</receiptDate><receiptNumber>1-1-2024-0812726-28</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>1-1-2025-0342132-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240098737.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9385f595290fd0a5aef241e42035d03e67b07aa16b79c8877b6ac30af2c52d15a6dc776f5467c8180d38775cde583fff8f7e8d1f3eddaa992f</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfc17d465d221df212e078f3bcce9ae5dc5de747c0ccc01ce0a5d84406d15f69c5ed8353b68a44e57e0506ede36eeb109585c8a8c8d2b96a18</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>