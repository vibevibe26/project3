<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:18.618</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0009540</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>콘텐트를 제공하는 방법 및 디스플레이 장치</inventionTitle><inventionTitleEng>CONTENT PROVIDING METHOD AND DISPLAY DEVICE FOR  PROVIDING CONTENT</inventionTitleEng><openDate>2024.04.25</openDate><openNumber>10-2024-0054139</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04S 7/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04S 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04R 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/439</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 디스플레이 장치가 콘텐트를 제공하는 방법이 제공된다. 상기 방법은, 가상 공간을 나타내는 비디오 콘텐트를 획득하는 단계; 상기 비디오 콘텐트에 대응하는 제1 오디오 콘텐트를 획득하는 단계; 사용자 공간의 오디오와 관련된 특징을 나타내는 공간 정보를 획득하는 단계; 상기 비디오 콘텐트의 메타데이터, 상기 제1 오디오 콘텐트의 메타데이터 및 상기 공간 정보에 기초하여 상기 제1 오디오 콘텐트를 변환함으로써, 상기 공간 정보에 따라 상기 사용자 공간에 최적화된 사운드로 변환된 공간 맞춤형 오디오 콘텐트인 제2 오디오 콘텐트를 생성하는 단계; 상기 디스플레이 장치와 연결된 하나 이상의 스피커들의 위치 또는 사양 중 적어도 하나를 획득하는 단계; 상기 하나 이상의 스피커들의 위치 또는 상기 하나 이상의 스피커들의 사양 중 적어도 하나 및 상기 공간 정보에 기초하여, 상기 제2 오디오 콘텐트에 대한 상기 하나 이상의 스피커들의 출력 설정을 결정하는 단계; 및 상기 비디오 콘텐트가 상기 디스플레이 장치의 화면에 표시되는 동안, 상기 출력 설정에 기초하여 상기 제2 오디오 콘텐트를 출력하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디스플레이 장치가 콘텐트를 제공하는 방법에 있어서,가상 공간을 나타내는 비디오 콘텐트를 획득하는 단계(S210);상기 비디오 콘텐트에 대응하는 제1 오디오 콘텐트를 획득하는 단계(S220);사용자 공간의 오디오와 관련된 특징을 나타내는 공간 정보를 획득하는 단계(S230);상기 비디오 콘텐트의 메타데이터, 상기 제1 오디오 콘텐트의 메타데이터 및 상기 공간 정보에 기초하여 상기 제1 오디오 콘텐트를 변환함으로써 제2 오디오 콘텐트를 생성하되, 상기 제2 오디오 콘텐트는 상기 공간 정보에 따라 상기 사용자 공간에 최적화된 사운드로 변환된 공간 맞춤형 오디오 콘텐트인, 단계(S240);상기 디스플레이 장치와 연결된 하나 이상의 스피커들의 위치 또는 사양 중 적어도 하나를 획득하는 단계(S250);상기 하나 이상의 스피커들의 위치 또는 상기 하나 이상의 스피커들의 사양 중 적어도 하나 및 상기 공간 정보에 기초하여, 상기 제2 오디오 콘텐트에 대한 상기 하나 이상의 스피커들의 출력 설정을 결정하는 단계(S260); 및상기 비디오 콘텐트가 상기 디스플레이 장치의 화면에 표시되는 동안, 상기 출력 설정에 기초하여 상기 제2 오디오 콘텐트를 출력하는 단계(S270)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 오디오 콘텐트의 메타데이터는,사운드 등장/사라짐 시간, 사운드 크기, 가상 공간 상의 객체 위치, 객체 위치 이동 궤적, 객체의 종류 및 객체에 대응하는 사운드 중 적어도 하나를 포함하는 것인, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 비디오 콘텐트의 메타데이터는,상기 비디오 콘텐트 내 존재하는 객체의 종류, 사운드 발생 위치, 객체 이동 궤적, 장소, 시간대 중 적어도 하나를 포함하는 것인, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 공간 정보는,상기 공간의 3차원 공간 레이아웃, 공간 내 객체 및 공간 내 베이스트랩(bass trap), 사운드 흡수재(sound absorber), 사운드 분산재(sound diffuser)와 관련된 정보 중 적어도 하나를 포함하는 것인, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 방법은,상기 제1 오디오 콘텐트의 메타데이터의 존재 여부를 식별하는 단계; 및상기 제1 오디오 콘텐트의 메타데이터가 존재하지 않는 것에 기초하여, 상기 제1 오디오 콘텐트의 메타데이터를 생성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 제1 오디오 콘텐트의 메타데이터를 생성하는 단계는,상기 비디오 콘텐트, 상기 비디오 콘텐트의 메타데이터 및 상기 제1 오디오 콘텐트 중 적어도 하나에 기초하여 상기 제1 오디오 콘텐트의 메타데이터를 생성하는 것인, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 제2 오디오 콘텐트를 생성하는 단계는,상기 비디오 콘텐트의 메타데이터 및 상기 제1 오디오 콘텐트의 메타데이터에 기초하여, 상기 제1 오디오 콘텐트를 가상 공간에 맵핑하는 단계; 및상기 공간 정보에 기초하여, 상기 가상 공간 내 사용자의 캐릭터 위치에서 상기 사용자의 캐릭터에게 들리는 상기 제1 오디오 콘텐트를 상기 사용자 공간 내에서 사용자의 위치에서 사용자에게 들리는 상기 제2 오디오 콘텐트로 변경하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 하나 이상의 스피커들의 위치 또는 사양 중 적어도 하나를 획득하는 단계는,하나 이상의 마이크를 이용하여 상기 하나 이상의 스피커들로부터 테스트 사운드를 수신하는 단계; 및상기 테스트 사운드에 기초하여 상기 하나 이상의 스피커들의 위치를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 방법은,하나 이상의 센서를 이용하여 상기 디스플레이 장치의 사용자의 위치를 식별하는 단계를 더 포함하고,상기 하나 이상의 스피커들의 출력 설정을 결정하는 단계는,상기 사용자의 위치에 더 기초하여 상기 하나 이상의 스피커들의 출력 설정을 결정하는 것인, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 사용자의 위치를 식별하는 단계는,실시간으로 상기 사용자의 위치를 식별하는 것이고,상기 하나 이상의 스피커들의 출력 설정을 결정하는 단계는,상기 사용자의 위치가 실시간으로 변경됨에 따라 상기 하나 이상의 스피커들의 출력 설정이 변경되는 것인, 방법.</claim></claimInfo><claimInfo><claim>11. 디스플레이 장치(2000)에 있어서,통신 인터페이스(2100);디스플레이(2200);하나 이상의 인스트럭션들을 저장하는 메모리(2400); 및상기 메모리(2400)에 저장된 상기 하나 이상의 인스트럭션을 실행하는 적어도 하나의 프로세서(2500)를 포함하고,상기 적어도 하나의 프로세서(2500)는 상기 하나 이상의 인스트럭션을 실행함으로써,가상 공간을 나타내는 비디오 콘텐트를 획득하고,상기 비디오 콘텐트에 대응하는 제1 오디오 콘텐트를 획득하고,사용자 공간의 오디오와 관련된 특징을 나타내는 공간 정보를 획득하고,상기 비디오 콘텐트의 메타데이터, 상기 제1 오디오 콘텐트의 메타데이터 및 상기 공간 정보에 기초하여 상기 제1 오디오 콘텐트를 변환함으로써 제2 오디오 콘텐트를 생성하되, 상기 제2 오디오 콘텐트는 상기 공간 정보에 따라 상기 사용자 공간에 최적화된 사운드로 변환된 공간 맞춤형 오디오 콘텐트이고,상기 디스플레이 장치와 연결된 하나 이상의 스피커들의 위치 또는 사양 중 적어도 하나를 획득하고,상기 하나 이상의 스피커들의 위치 또는 상기 하나 이상의 스피커들의 사양 중 적어도 하나 및 상기 공간 정보에 기초하여, 상기 제2 오디오 콘텐트에 대한 상기 하나 이상의 스피커들의 출력 설정을 결정하고,상기 비디오 콘텐트가 상기 디스플레이 장치의 상기 디스플레이에 표시되는 동안, 상기 출력 설정에 기초하여 상기 제2 오디오 콘텐트를 출력하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 제1 오디오 콘텐트의 메타데이터는,사운드 등장/사라짐 시간, 사운드 크기, 가상 공간 상의 객체 위치, 객체 위치 이동 궤적, 객체의 종류 및 객체에 대응하는 사운드 중 적어도 하나를 포함하는 것인, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 비디오 콘텐트의 메타데이터는,상기 비디오 콘텐트 내 존재하는 객체의 종류, 사운드 발생 위치, 객체 이동 궤적, 장소, 시간대 중 적어도 하나를 포함하는 것인, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 공간 정보는,상기 공간의 3차원 공간 레이아웃, 공간 내 객체 및 공간 내 베이스트랩(bass trap), 사운드 흡수재(sound absorber), 사운드 분산재(sound diffuser)와 관련된 정보 중 적어도 하나를 포함하는 것인, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>15. 제11항 내지 제14항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 제1 오디오 콘텐트의 메타데이터의 존재 여부를 식별하고,상기 제1 오디오 콘텐트의 메타데이터가 존재하지 않는 것에 기초하여, 상기 제1 오디오 콘텐트의 메타데이터를 생성하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>16. 제11항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 비디오 콘텐트의 메타데이터 및 상기 제1 오디오 콘텐트의 메타데이터에 기초하여, 상기 제1 오디오 콘텐트를 가상 공간에 맵핑하고,상기 공간 정보에 기초하여, 상기 가상 공간 내 사용자의 캐릭터 위치에서 상기 사용자의 캐릭터에게 들리는 상기 제1 오디오 콘텐트를 상기 사용자 공간 내에서 사용자의 위치에서 사용자에게 들리는 상기 제2 오디오 콘텐트로 변경하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>17. 제11항 내지 제15항 중 어느 한 항에 있어서,상기 디스플레이 장치는,하나 이상의 마이크를 더 포함하고,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,상기 하나 이상의 마이크를 이용하여 상기 하나 이상의 스피커들로부터 테스트 사운드를 수신하고,상기 테스트 사운드에 기초하여 상기 하나 이상의 스피커들의 위치를 결정하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>18. 제11항 내지 제17항 중 어느 한 항에 있어서,상기 디스플레이 장치는,하나 이상의 카메라를 더 포함하고,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,하나 이상의 센서를 이용하여 상기 디스플레이 장치의 사용자의 위치를 식별하고,상기 사용자의 위치에 더 기초하여 상기 하나 이상의 스피커들의 출력 설정을 결정하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 적어도 하나의 프로세서는 상기 하나 이상의 인스트럭션을 실행함으로써,실시간으로 상기 사용자의 위치를 식별하고,상기 사용자의 위치가 실시간으로 변경됨에 따라 상기 하나 이상의 스피커들의 출력 설정을 변경하는, 디스플레이 장치.</claim></claimInfo><claimInfo><claim>20.  제1항 내지 제10항 중 어느 한 항의 방법을 컴퓨터에서 실행시키기 위한 프로그램을 기록한 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Jae Sung</engName><name>박재성</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, Seong Su</engName><name>박성수</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2022.10.18</priorityApplicationDate><priorityApplicationNumber>1020220134466</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.01.25</receiptDate><receiptNumber>1-1-2023-0088829-59</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230009540.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938d45359b3eade85b7fc14659b5c4666060559fe37fa832e1fc8b3a60334fc702c20a2eed63fe94150ca689b63970d11a52de6568a54fe756</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfdb30c28d6c233b9ff7b5d67cb91174f948fb49c7398fa1902112e9e0de047721c5363d1407c8281413d959b286a54e25af689b315054173a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>