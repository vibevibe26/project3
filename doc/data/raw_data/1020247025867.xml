<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:14:01.141</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.03</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7025867</applicationNumber><claimCount>32</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>디바이스에서의 다수의 피사체들에 대한 영상 통화 경험</inventionTitle><inventionTitleEng>VIDEO CALLING EXPERIENCE FOR MULTIPLE SUBJECTS ON A DEVICE</inventionTitleEng><openDate>2024.11.11</openDate><openNumber>10-2024-0160564</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.07.31</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 7/14</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>H04N 21/431</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>H04N 21/442</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>H04N 21/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/63</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 영상 통화를 위한 시스템들, 방법들, 및 컴퓨터 판독가능 매체들이 제공된다. 예시적인 방법은 제1 디바이스와 제2 디바이스 사이에 영상 통화를 확립하는 단계; 제1 카메라 피드 및 제2 카메라 피드의 미리보기를 디스플레이하는 단계로서, 제1 카메라 피드는 제1 디바이스의 제1 이미지 캡처 디바이스에 의해 캡처된 제1 비디오 프레임 및 제1 디바이스의 제2 이미지 캡처 디바이스에 의해 캡처된 제2 비디오 프레임을 포함하고, 제1 비디오 프레임 및 제2 비디오 프레임은 미리보기 내에서 시각적으로 분리되는, 상기 미리보기를 디스플레이하는 단계; 미리보기에 묘사된 피사체 세트의 선택을 수신하는 단계; 및 제1 카메라 피드 및 제2 카메라 피드에 기초하여, 피사체 세트를 묘사하는 단일 프레임을 생성하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.09.07</internationOpenDate><internationOpenNumber>WO2023168136</internationOpenNumber><internationalApplicationDate>2023.01.03</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/060046</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 영상 통화들을 프로세싱하기 위한 장치로서,메모리; 및상기 메모리에 커플링된 하나 이상의 프로세서들을 포함하고, 상기 하나 이상의 프로세서들은, 상기 장치와 원격 디바이스 사이에 영상 통화를 확립하고; 제1 카메라 피드 및 제2 카메라 피드의 미리보기를 디스플레이하는 것으로서, 상기 제1 카메라 피드는 상기 장치의 제1 이미지 캡처 디바이스에 의해 캡처된 제1 비디오 프레임 및 상기 장치의 제2 이미지 캡처 디바이스에 의해 캡처된 제2 비디오 프레임을 포함하고, 상기 제1 비디오 프레임 및 상기 제2 비디오 프레임은 상기 미리보기 내에서 시각적으로 분리되는, 상기 미리보기를 디스플레이하고; 상기 미리보기에 묘사된 피사체 세트의 선택을 수신하고; 그리고 상기 제1 카메라 피드 및 상기 제2 카메라 피드에 기초하여, 상기 피사체 세트를 묘사하는 단일 프레임을 생성하도록 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 비디오 프레임 및 상기 제2 비디오 프레임은 상기 피사체 세트를 포함하는 복수의 피사체들을 묘사하고, 상기 피사체 세트의 선택은 상기 단일 프레임에 포함될 상기 복수의 피사체들의 서브세트로서 상기 피사체 세트를 선택하는 제1 입력 및 상기 단일 프레임으로부터 배제될 상기 복수의 피사체들의 하나 이상의 피사체들을 선택하는 제2 입력 중 적어도 하나를 포함하고, 상기 하나 이상의 피사체들은 상기 피사체 세트와 상이한, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 단일 프레임을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 입력 및 상기 제2 입력 중 적어도 하나에 기초하여, 상기 단일 프레임으로부터, 상기 복수의 피사체들의 상기 하나 이상의 피사체들을 배제하고; 그리고상기 단일 프레임을 상기 원격 디바이스로 전송하도록 추가로 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 단일 프레임으로부터 상기 하나 이상의 피사체들을 배제하기 위해, 상기 하나 이상의 프로세서들은, 상기 미리보기, 상기 제1 비디오 프레임, 상기 제2 비디오 프레임, 및 상기 단일 프레임 중 적어도 하나로부터 상기 하나 이상의 피사체들을 제거하도록 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 단일 프레임을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 상기 단일 프레임으로 결합하도록 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 상기 단일 프레임으로 결합하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 상기 단일 프레임의 개별 프레임 영역들에 배열하도록 구성되고, 각각의 프레임 영역은 상기 피사체 세트로부터 개별 피사체를 묘사하는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 제1 비디오 프레임은 상기 피사체 세트로부터 하나 이상의 제1 피사체들을 포함하고, 상기 제2 비디오 프레임은 상기 피사체 세트로부터 하나 이상의 제2 피사체들을 포함하고, 상기 단일 프레임을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 비디오 프레임과 연관된 제1 메타데이터에 기초하여, 상기 제1 비디오 프레임 내의 하나 이상의 제1 피사체들 각각의 개별 위치를 결정하는 것으로서, 상기 제1 메타데이터는 상기 하나 이상의 제1 피사체들과 연관된 좌표들을 포함하는, 상기 제1 피사체들 각각의 개별 위치를 결정하고;상기 제2 비디오 프레임과 연관된 제2 메타데이터에 기초하여, 상기 제2 비디오 프레임 내의 하나 이상의 제2 피사체들 각각의 개별 위치를 결정하는 것으로서, 상기 제2 메타데이터는 상기 하나 이상의 제2 피사체들과 연관된 좌표들을 포함하는, 상기 제2 피사체들 각각의 개별 위치를 결정하고; 그리고상기 제1 비디오 프레임 내의 상기 하나 이상의 제1 피사체들 각각의 개별 위치 및 상기 제2 비디오 프레임 내의 상기 하나 이상의 제2 피사체들 각각의 개별 위치에 기초하여, 상기 하나 이상의 제1 피사체들을 묘사하는 제1 비디오 프레임의 제1 부분 및 상기 하나 이상의 제2 피사체들을 묘사하는 제2 비디오 프레임의 제2 부분을 결정하도록 추가로 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 단일 프레임을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 비디오 프레임의 제1 부분 및 상기 제2 비디오 프레임의 제2 부분을 상기 단일 프레임으로 결합하도록 추가로 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 제1 비디오 프레임의 제1 부분 및 상기 제2 비디오 프레임의 제2 부분을 상기 단일 프레임으로 결합하기 위해, 상기 하나 이상의 프로세서들은,상기 제1 비디오 프레임의 제1 부분 및 상기 제2 비디오 프레임의 제2 부분을 상기 단일 프레임의 개별 프레임 영역들 내에 배치하도록 구성되고, 상기 개별 프레임 영역들의 제1 영역은 상기 하나 이상의 제1 피사체들을 묘사하고, 상기 개별 프레임 영역들의 제2 영역은 상기 하나 이상의 제2 피사체들을 묘사하는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 단일 프레임을 생성하기 위해, 상기 하나 이상의 프로세서들은,상기 단일 프레임 내에서 상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 렌더링하도록 추가로 구성되고, 상기 제1 비디오 프레임의 상기 적어도 일부 및 상기 제2 비디오 프레임의 상기 적어도 일부는 시각적으로 분리되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 제1 비디오 프레임의 상기 적어도 일부 및 상기 제2 비디오 프레임의 상기 적어도 일부는 시각적 마커에 의해 시각적으로 분리되고, 상기 시각적 마커는 라인, 윤곽, 박스, 하이라이트, 라벨, 컬러, 음영, 및 시각적 표시 중 적어도 하나를 포함하는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 상기 하나 이상의 프로세서들은,상기 제1 이미지 캡처 디바이스로부터 상기 제1 비디오 프레임을 획득하고 상기 제2 이미지 캡처 디바이스로부터 상기 제2 비디오 프레임을 획득하도록 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제1 이미지 캡처 디바이스 및 상기 제2 이미지 캡처 디바이스 중 적어도 하나를 더 포함하는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서, 상기 하나 이상의 프로세서들은,하나 이상의 피사체들이 상기 제1 이미지 캡처 디바이스의 FOV(field-of-view) 내에 있다는 것을 결정하고; 그리고상기 제1 비디오 프레임을 캡처하기 위해 상기 제1 이미지 캡처 디바이스를 트리거하도록 구성되고, 상기 제1 비디오 프레임은 상기 하나 이상의 피사체들을 묘사하는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 하나 이상의 프로세서들은,상기 제1 이미지 캡처 디바이스에 의해 캡처된 하나 이상의 비디오 프레임들에 기초하여 상기 하나 이상의 피사체들을 추적하고;상기 추적에 기초하여, 상기 하나 이상의 피사체들이 더 이상 상기 제1 이미지 캡처 디바이스의 FOV 내에 있지 않다는 것을 결정하고; 그리고상기 하나 이상의 피사체들이 더 이상 상기 제1 이미지 캡처 디바이스의 FOV 내에 있지 않다는 것을 결정하는 것에 기초하여, 상기 제1 이미지 캡처 디바이스로부터 상기 원격 디바이스로 비디오 데이터를 송신하는 것을 중단하기로 결정하도록 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 하나 이상의 프로세서들은,적어도 하나의 피사체가 상기 제2 이미지 캡처 디바이스의 FOV 내에 있다는 것을 결정하는 것에 응답하여, 상기 제2 이미지 캡처 디바이스를 통해, 상기 적어도 하나의 피사체를 묘사하는 제3 비디오 프레임을 획득하고; 그리고상기 제3 비디오 프레임을 상기 원격 디바이스로 전송하도록 구성되는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제1항에 있어서, 상기 장치는 모바일 디바이스를 포함하는, 영상 통화들을 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 영상 통화들을 프로세싱하기 위한 방법으로서, 상기 방법은,디바이스와 원격 디바이스 사이에 영상 통화를 확립하는 단계;제1 카메라 피드 및 제2 카메라 피드의 미리보기를 디스플레이하는 단계로서, 상기 제1 카메라 피드는 상기 디바이스의 제1 이미지 캡처 디바이스에 의해 캡처된 제1 비디오 프레임 및 상기 디바이스의 제2 이미지 캡처 디바이스에 의해 캡처된 제2 비디오 프레임을 포함하고, 상기 제1 비디오 프레임 및 상기 제2 비디오 프레임은 상기 미리보기 내에서 시각적으로 분리되는, 상기 미리보기를 디스플레이하는 단계;상기 미리보기에 묘사된 피사체 세트의 선택을 수신하는 단계; 및상기 제1 카메라 피드 및 상기 제2 카메라 피드에 기초하여, 상기 피사체 세트를 묘사하는 단일 프레임을 생성하는 단계를 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 제1 비디오 프레임 및 상기 제2 비디오 프레임은 상기 피사체 세트를 포함하는 복수의 피사체들을 묘사하고, 상기 피사체 세트의 선택은 상기 단일 프레임에 포함될 상기 복수의 피사체들의 서브세트로서 상기 피사체 세트를 선택하는 제1 입력 및 상기 단일 프레임으로부터 배제될 상기 복수의 피사체들의 하나 이상의 피사체들을 선택하는 제2 입력 중 적어도 하나를 포함하고, 상기 하나 이상의 피사체들은 상기 피사체 세트와 상이한, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 단일 프레임을 생성하는 단계는,상기 제1 입력 및 상기 제2 입력 중 적어도 하나에 기초하여, 상기 단일 프레임으로부터, 상기 복수의 피사체들의 상기 하나 이상의 피사체들을 배제하는 것; 및상기 단일 프레임을 상기 원격 디바이스로 전송하는 것을 더 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 단일 프레임으로부터 상기 하나 이상의 피사체들을 배제하는 것은, 상기 미리보기, 상기 제1 비디오 프레임, 상기 제2 비디오 프레임, 및 상기 단일 프레임 중 적어도 하나로부터 상기 하나 이상의 피사체들을 제거하는 것을 더 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>22. 제18항에 있어서, 상기 단일 프레임을 생성하는 단계는,상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 상기 단일 프레임으로 결합하는 것을 더 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 상기 단일 프레임으로 결합하는 것은,상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 상기 단일 프레임의 개별 프레임 영역들에 배열하는 것을 포함하고, 각각의 프레임 영역은 상기 피사체 세트로부터 개별 피사체를 묘사하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>24. 제18항에 있어서, 상기 제1 비디오 프레임은 상기 피사체 세트로부터 하나 이상의 제1 피사체들을 포함하고, 상기 제2 비디오 프레임은 상기 피사체 세트로부터 하나 이상의 제2 피사체들을 포함하고, 상기 단일 프레임을 생성하는 단계는,상기 제1 비디오 프레임과 연관된 제1 메타데이터에 기초하여, 상기 제1 비디오 프레임 내의 하나 이상의 제1 피사체들 각각의 개별 위치를 결정하는 것으로서, 상기 제1 메타데이터는 상기 하나 이상의 제1 피사체들과 연관된 좌표들을 포함하는, 상기 제1 피사체들 각각의 개별 위치를 결정하는 것;상기 제2 비디오 프레임과 연관된 제2 메타데이터에 기초하여, 상기 제2 비디오 프레임 내의 하나 이상의 제2 피사체들 각각의 개별 위치를 결정하는 것으로서, 상기 제2 메타데이터는 상기 하나 이상의 제2 피사체들과 연관된 좌표들을 포함하는, 상기 제2 피사체들 각각의 개별 위치를 결정하는 것; 및상기 제1 비디오 프레임 내의 상기 하나 이상의 제1 피사체들 각각의 개별 위치 및 상기 제2 비디오 프레임 내의 상기 하나 이상의 제2 피사체들 각각의 개별 위치에 기초하여, 상기 하나 이상의 제1 피사체들을 묘사하는 제1 비디오 프레임의 제1 부분 및 상기 하나 이상의 제2 피사체들을 묘사하는 제2 비디오 프레임의 제2 부분을 결정하는 것을 더 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 단일 프레임을 생성하는 단계는,상기 제1 비디오 프레임의 제1 부분 및 상기 제2 비디오 프레임의 제2 부분을 상기 단일 프레임으로 결합하는 것을 더 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 제1 비디오 프레임의 제1 부분 및 상기 제2 비디오 프레임의 제2 부분을 상기 단일 프레임으로 결합하는 것은,상기 제1 비디오 프레임의 제1 부분 및 상기 제2 비디오 프레임의 제2 부분을 상기 단일 프레임의 개별 프레임 영역들 내에 배치하는 것을 포함하고, 상기 개별 프레임 영역들의 제1 영역은 상기 하나 이상의 제1 피사체들을 묘사하고, 상기 개별 프레임 영역들의 제2 영역은 상기 하나 이상의 제2 피사체들을 묘사하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>27. 제18항에 있어서, 상기 단일 프레임을 생성하는 단계는,상기 단일 프레임 내에서 상기 제1 비디오 프레임의 적어도 일부 및 상기 제2 비디오 프레임의 적어도 일부를 렌더링하는 것을 더 포함하고, 상기 제1 비디오 프레임의 상기 적어도 일부 및 상기 제2 비디오 프레임의 상기 적어도 일부는 시각적으로 분리되는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>28. 제27항에 있어서, 상기 제1 비디오 프레임의 상기 적어도 일부 및 상기 제2 비디오 프레임의 상기 적어도 일부는 시각적 마커에 의해 시각적으로 분리되고, 상기 시각적 마커는 라인, 윤곽, 박스, 하이라이트, 라벨, 컬러, 음영, 및 시각적 표시 중 적어도 하나를 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>29. 제18항에 있어서,상기 제1 이미지 캡처 디바이스로부터 상기 제1 비디오 프레임을 획득하고 상기 제2 이미지 캡처 디바이스로부터 상기 제2 비디오 프레임을 획득하는 단계를 더 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>30. 제18항에 있어서,하나 이상의 피사체들이 상기 제1 이미지 캡처 디바이스의 FOV(field-of-view) 내에 있다는 것을 결정하는 단계; 및상기 제1 비디오 프레임을 캡처하기 위해 상기 제1 이미지 캡처 디바이스를 트리거하는 단계를 더 포함하고, 상기 제1 비디오 프레임은 상기 하나 이상의 피사체들을 묘사하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서,상기 제1 이미지 캡처 디바이스에 의해 캡처된 하나 이상의 비디오 프레임들에 기초하여 상기 하나 이상의 피사체들을 추적하는 단계;상기 추적에 기초하여, 상기 하나 이상의 피사체들이 더 이상 상기 제1 이미지 캡처 디바이스의 FOV 내에 있지 않다는 것을 결정하는 단계; 및상기 하나 이상의 피사체들이 더 이상 상기 제1 이미지 캡처 디바이스의 FOV 내에 있지 않다는 것을 결정하는 것에 기초하여, 상기 제1 이미지 캡처 디바이스로부터 상기 원격 디바이스로 비디오 데이터를 송신하는 것을 중단하기로 결정하는 단계를 더 포함하는, 영상 통화들을 프로세싱하기 위한 방법.</claim></claimInfo><claimInfo><claim>32. 명령들을 포함하는 적어도 하나의 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 명령들은, 하나 이상의 프로세서들에 의해 실행될 때, 상기 하나 이상의 프로세서들로 하여금,디바이스와 원격 디바이스 사이에 영상 통화를 확립하고;제1 카메라 피드 및 제2 카메라 피드의 미리보기를 디스플레이하는 것으로서, 상기 제1 카메라 피드는 상기 디바이스의 제1 이미지 캡처 디바이스에 의해 캡처된 제1 비디오 프레임 및 상기 디바이스의 제2 이미지 캡처 디바이스에 의해 캡처된 제2 비디오 프레임을 포함하고, 상기 제1 비디오 프레임 및 상기 제2 비디오 프레임은 상기 미리보기 내에서 시각적으로 분리되는, 상기 미리보기를 디스플레이하고;상기 미리보기에 묘사된 피사체 세트의 선택을 수신하고; 그리고상기 제1 카메라 피드 및 상기 제2 카메라 피드에 기초하여, 상기 피사체 세트를 묘사하는 단일 프레임을 생성하게 하는, 적어도 하나의 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>BALDE, ANSH ABHAY</engName><name>발데 안쉬 아바이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>ANAND, SANTOSH</engName><name>아난드 산토쉬</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.03.04</priorityApplicationDate><priorityApplicationNumber>17/686,805</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.07.31</receiptDate><receiptNumber>1-1-2024-0833327-51</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.10.11</receiptDate><receiptNumber>1-5-2024-0163651-40</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247025867.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f23b655bf20cbb3633c9c9e441666c0560ea030dafba0a1f2db2a860261bfda5cbaf1e7b9735819f0aab62037b124f9560bb0e8d05381863</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf002077c29e94db139a285cf19e988fa89dec5760fb22dd652ec7f3c162d9309135447ad5e94772e66ffc8d104f40847e8c9663716a599a75</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>