<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:38:37.3837</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.06.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0083058</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>효율적인 데이터 시맨틱 세그멘태이션을 위한 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR DATA EFFICIENT  SEMANTIC SEGMENTATION</inventionTitleEng><openDate>2022.01.11</openDate><openNumber>10-2022-0003968</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.06.25</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 5/025</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/772</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 신경 네트워크 트레이닝 방법 및 시스템이 제공된다. 방법은 입력 이미지를 수신하는 것, 데이터 증강 방법들의 풀로부터 적어도 하나의 데이터 증강 방법을 선택하는 것, 선택된 상기 적어도 하나의 데이터 증강 방법을 상기 입력 이미지에 적용하여 증강된 이미지를 생성하는 것, 및 상기 입력 이미지 및 상기 증강된 이미지로부터 혼합된 이미지를 생성하는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 이미지를 수신하는 것;데이터 증강 방법들의 풀로부터 적어도 하나의 데이터 증강 방법을 선택하는 것;선택된 상기 적어도 하나의 데이터 증강 방법을 상기 입력 이미지에 적용하여 증강된 이미지를 생성하는 것; 및상기 입력 이미지 및 상기 증강된 이미지로부터 혼합된 이미지를 생성하는 것을 포함하는 신경 네트워크 트레이닝 방법.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 입력 이미지 및 생성된 상기 혼합된 이미지 사이의 잰슨 샤넌 다이버전스 컨시스턴시를 수행하는 것을 더 포함하는 신경 네트워크 트레이닝 방법.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,상기 데이터 증강 방법들의 풀은 오토 콘트라스트 데이터 증강 방법, 이퀄라이즈 데이터 증강 방법, 포스터라이즈 데이터 증강 방법, 솔라라이즈 데이터 증강 방법, 컬러 데이터 증강 방법, 콘트라스트 데이터 증강 방법, 밝기 데이터 증강 방법, 및 샤프니스 데이터 증강 방법 중 적어도 하나를 포함하는 신경 네트워크 트레이닝 방법. </claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,선택된 상기 적어도 하나의 데이터 증강 방법은 임의로 선택되는 신경 네트워크 트레이닝 방법.</claim></claimInfo><claimInfo><claim>5. 제1 항에 있어서,상기 입력 이미지 및 생성된 상기 혼합된 이미지에 대응되는 소프트맥스 로짓들을 생성하는 것을 더 포함하는 신경 네트워크 트레이닝 방법. </claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,선택된 상기 적어도 하나의 데이터 증강 방법을 적용하는 것은 상기 증강된 이미지 생성을 위한 브런치들의 개수로 혼합 폭을 정의하는 것을 포함하는 신경 네트워크 트레이닝 방법. </claim></claimInfo><claimInfo><claim>7. 제6 항에 있어서,선택된 상기 적어도 하나의 데이터 증강 방법을 적용하는 것은 상기 증강된 이미지 생성을 위한 연속 데이터 증강들의 최대 개수로 혼합 뎁스를 정의하는 것을 포함하는 신경 네트워크 트레이닝 방법.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 혼합 폭 및 상기 혼합 뎁스는 상기 복수개의 브런치들의 각각의 브런치에 대한 디리클레 분포로부터 임의로 생성되는 신경 네트워크 트레이닝 방법. </claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,Augmix 데이터 증강 기술 및 Mixup 데이터 증강 기술의 결합에 기초하여 상기 입력 이미지를 분류하는 것을 더 포함하는 신경 네트워크 트레이닝 방법.</claim></claimInfo><claimInfo><claim>10. 메모리; 및프로세스를 포함하고,상기 프로세서는:입력 이미지를 수신하고;데이터 증강 방법들의 풀로부터 적어도 하나의 데이터 증강 방법을 선택하고;선택된 상기 적어도 하나의 데이터 증강 방법을 상기 입력 이미지에 적용하여 증강된 이미지를 생성하고; 및상기 입력 이미지 및 상기 증강된 이미지로부터 혼합된 이미지를 생성하도록 구성되는 신경 네트워크 트레이닝 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>***** 미국 캘리포니아...</address><code> </code><country> </country><engName>BABAGHOLAMI MOHAMADABADI, Behnam</engName><name>바바호라미 모하마다바디, 베남</name></inventorInfo><inventorInfo><address>***** 미국 뉴욕주...</address><code> </code><country> </country><engName>LEE, Jung Won</engName><name>이정원 </name></inventorInfo><inventorInfo><address>***** 미국 캘리포니아...</address><code> </code><country> </country><engName>ELKHAMY, Mostafa</engName><name>엘 카미, 모스타파 </name></inventorInfo><inventorInfo><address>***** 미국 캘리포니아주 샌디에고...</address><code> </code><country> </country><engName>LIU, Qingfeng</engName><name>리우, 칭펑 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.07.02</priorityApplicationDate><priorityApplicationNumber>63/047,438</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.04.27</priorityApplicationDate><priorityApplicationNumber>17/241,848</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.06.25</receiptDate><receiptNumber>1-1-2021-0735477-11</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2021.06.29</receiptDate><receiptNumber>9-1-2021-9007487-33</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2021.06.29</receiptDate><receiptNumber>9-1-2021-9007489-24</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2022.06.27</receiptDate><receiptNumber>1-1-2022-0669641-55</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.06.25</receiptDate><receiptNumber>1-1-2024-0688604-35</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210083058.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c939f0fed7b14e7e104f547896188e47b6bfa4e9c903f704475edfc6b1ebeb4923972b638adbe4c58f1fcd117a85ee5a611812fde31ded4b429</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf722767524a8073944030d7b8458c35eb2b2e9d46dc376a35ca7c18f092a162c2abef77a197041de968be79d381dd6ef5929f2567b4462929</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>