<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:33.4133</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0160747</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>DMS에서 객체를 검출하기 위한 인공지능 기반의 모델을 학습시키기 위한 방법 및 장치</inventionTitle><inventionTitleEng>APPARATUS AND METHOD FOR TRAINING ARTIFICIAL INTELLIGENCE  BASED MODEL FOR DETECTING OBJECT IN DRIVER MONITORING  SYSTEMS</inventionTitleEng><openDate>2025.05.28</openDate><openNumber>10-2025-0074782</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/59</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/772</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/422</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> DMS(Driver Monitoring Systems)에서 객체를 인식하기 위한 인공지능 기반의 모델을 학습시키기 위한 방법이 개시된다. 상기 방법은, 참조(reference) 이미지를 획득하는 단계, 데이터 증강을 위하여, 상기 참조 이미지로부터 상기 객체가 포함된 제 1 렌더링 이미지를 생성하는 단계, 상기 제 1 렌더링 이미지를 이용하여 상기 모델의 제 1 학습을 수행함으로써, 상기 제 1 학습에 대응되는 제 1 학습 결과를 획득하는 단계, 상기 제 1 학습 결과와 상기 제 1 렌더링 이미지를 이용하여, 상기 제 1 학습에 후속되는 제 2 학습에 이용될 렌더링 조건을 결정하는 단계 및 상기 렌더링 조건을 이용하여, 상기 모델의 상기 제 2 학습을 수행하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. DMS(Driver Monitoring Systems)에서 객체를 인식하기 위한 인공지능 기반의 모델을 학습시키기 위한 방법으로서,참조(reference) 이미지를 획득하는 단계;데이터 증강을 위하여, 상기 참조 이미지로부터 상기 객체가 포함된 제 1 렌더링 이미지를 생성하는 단계;상기 제 1 렌더링 이미지를 이용하여 상기 모델의 제 1 학습을 수행함으로써, 상기 제 1 학습에 대응되는 제 1 학습 결과를 획득하는 단계;상기 제 1 학습 결과와 상기 제 1 렌더링 이미지를 이용하여, 상기 제 1 학습에 후속되는 제 2 학습에 이용될 렌더링 조건을 결정하는 단계; 및상기 렌더링 조건을 이용하여, 상기 모델의 상기 제 2 학습을 수행하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제 2 학습에 이용될 렌더링 조건을 결정하는 단계는,상기 제 1 렌더링 이미지의 객체 영역과 상기 제 1 렌더링 이미지에 응답하여 상기 모델로부터 획득되는 히트맵 데이터의 객체 영역을 비교함으로써, 상기 제 2 학습에 이용될 렌더링 파라미터(parameter)를 결정하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 렌더링 파라미터는, 객체의 렌더링 밝기, 객체의 렌더링 강도, 또는 객체의 각도 조건에 대한 렌더링 적용 빈도 중 적어도 하나를 포함하는,방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,상기 모델은 복수 회 반복하여 학습되는 모델이며, 상기 제 1 학습은 복수 회의 학습들 중 N 번째 학습이고, 제 2 학습은 복수 회의 학습들 중 N+1 번째 학습에 대응되며, 상기 N 번째 학습의 결과를 이용하여 결정되는 렌더링 조건은, 상기 N+1 번째 학습에 이용될 렌더링 이미지에 적용되며, 그리고상기 N은 자연수를 나타내는,방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 모델의 상기 제 2 학습을 수행하는 단계는,상기 제 1 학습 결과와 상기 제 1 렌더링 이미지 간의 비교에 기초하여 결정되는 상기 렌더링 조건을 상기 참조 이미지 또는 상기 제 1 렌더링 이미지에 적용함으로써 획득되는 제 2 렌더링 이미지를 이용하여, 상기 모델의 상기 제 2 학습을 수행하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제 1 항에 있어서,상기 제 2 학습에 이용될 렌더링 조건을 결정하는 단계는:복수의 렌더링 조건들 각각에 대응되는 통계 데이터를 획득하는 단계;상기 통계 데이터를 이용하여, 상기 복수의 렌더링 조건들에 대한 적용 빈도 또는 적용 비율을 결정하는 단계; 및상기 결정된 적용 빈도 또는 적용 비율에 기초하여, 상기 제 2 학습에 이용될 상기 렌더링 조건을 결정하는 단계;를 포함하는,방법,</claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서,상기 렌더링 조건을 이용하여, 상기 모델의 상기 제 2 학습을 수행하는 단계는:상기 결정된 렌더링 조건을 상기 참조 이미지 또는 상기 제 1 렌더링 이미지에 적용함으로써, 상기 모델의 상기 제 2 학습에서 이용되는 제 2 렌더링 이미지를 획득하는 단계; 및상기 제 2 렌더링 이미지를 이용하여 상기 모델의 상기 제 2 학습을 수행하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서,상기 제 1 렌더링 이미지를 생성하는 단계는:상기 참조 이미지에 추가될 안전벨트의 형상을 정의하기 위한 복수의 안전벨트 포인트들을 결정하는 단계; 및상기 안전벨트 포인트들에 기초하여 상기 참조 이미지 상에 상기 안전벨트를 렌더링함으로써 상기 제 1 렌더링 이미지를 생성하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 복수의 안전벨트 포인트들을 결정하는 단계는:상기 참조 이미지로부터 운전자의 바디(body)에 대응되는 바디 영역 및 상기 운전자의 얼굴에 대응되는 얼굴 영역을 검출하는 단계; 및상기 바디 영역을 이용하여 상기 복수의 안전벨트 포인트들 중 제 1 포인트 및 제 2 포인트를 결정하고, 그리고 상기 얼굴 영역을 이용하여 상기 복수의 안전벨트 포인트들 중 제 3 포인트를 결정하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 제 1 포인트 및 상기 제 2 포인트는, 상기 운전자의 바디를 대각으로 가로지르는 제 1 안전벨트 라인(line)을 형성하기 위한 포인트들이며 그리고 상기 바디 영역의 경계 라인 상에 위치하거나 또는 상기 바디 영역의 경계 라인 내부에 위치하며, 그리고상기 제 3 포인트는, 상기 제 1 포인트 및 상기 제 2 포인트 중 하나와 연결되어 상기 제 1 안전벨트 라인과 연결되는 제 2 안전벨트 라인을 형성하기 위한 포인트이며, 그리고 상기 얼굴 영역의 외부에 위치하는,방법.</claim></claimInfo><claimInfo><claim>11. 제 8 항에 있어서,상기 복수의 안전벨트 포인트들을 결정하는 단계는:상기 참조 이미지 상에서, 운전자의 바디를 대각으로 가로지르는 제 1 안전벨트 라인을 형성하기 위한 포인트들에 대응되는 제 1 포인트 및 제 2 포인트를 검출하는 단계; 및상기 참조 이미지 상에서, 상기 제 1 포인트 및 상기 제 2 포인트 보다 상부에 위치하는 제 3 포인트를 검출하는 단계 - 상기 제 3 포인트는, 상기 제 1 포인트 및 상기 제 2 포인트 중 하나와 연결되어 상기 제 1 안전벨트 라인과 연결되는 제 2 안전벨트 라인을 형성하기 위한 포인트임 -;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>12. 제 8 항에 있어서,상기 안전벨트는:렌더링되는 라인의 알파 채널 값을 이용하여 결정되는 광택 효과 및 흔들림 효과 중 적어도 하나의 효과;사전 저장된 안전벨트 패턴; 및 사전 저장된 안전벨트 색상;에 기초하여 상기 참조 이미지 상에서 렌더링되는,방법.</claim></claimInfo><claimInfo><claim>13. 제 1 항에 있어서,상기 제 1 렌더링 이미지를 생성하는 단계는:상기 참조 이미지로부터 상기 참조 이미지의 증강을 위한 3차원 공간(space)을 생성하는 단계; 및상기 3차원 공간 상에서 얼굴의 랜드마크(landmark) 및 상기 얼굴을 바라보는 카메라 각도 중 적어도 하나를 조정함으로써, 상기 얼굴의 표정 및 상기 얼굴의 각도 중 적어도 하나가 변경된 상기 제 1 렌더링 이미지를 생성하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 제 1 렌더링 이미지를 생성하는 단계는:상기 참조 이미지로부터 상기 참조 이미지에 포함된 얼굴에 대응되는 3차원 재구성(reconstruction)을 통해 3차원 모델을 생성하고, 그리고 상기 참조 이미지로부터 상기 얼굴에 대응되는 2차원 텍스쳐(texture)를 생성하는 단계; 상기 3차원 모델에 상기 2차원 텍스쳐를 맵핑시킴으로써, 상기 참조 이미지의 증강을 위한 3차원 공간을 생성하는 단계; 및상기 3차원 공간 상에서 상기 얼굴의 랜드마크 및 상기 얼굴을 바라보는 카메라 각도 중 적어도 하나를 조정함으로써, 상기 얼굴의 표정 및 상기 얼굴의 각도 중 적어도 하나가 변경된 상기 제 1 렌더링 이미지를 생성하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>15. 제 1 항에 있어서,상기 객체는 안전벨트를 포함하며,상기 제 2 학습에 이용될 렌더링 조건을 결정하는 단계는:상기 제 1 렌더링 이미지의 안전벨트 영역과 상기 제 1 렌더링 이미지로부터 상기 모델로부터 획득된 히트맵 데이터의 안전벨트 영역 간의 중첩 정도가 사전 결정된 임계값 이상인 경우, 상기 제 2 학습에 이용될 제 2 렌더링 이미지의 렌더링 밝기 및 강도 중 적어도 하나를 감소시킬 것을 결정하는 단계; 및 상기 제 1 렌더링 이미지의 상기 안전벨트 영역과 상기 히트맵 데이터의 상기 안전벨트 영역 간의 중첩 정도가 상기 사전 결정된 임계값 미만인 경우, 상기 제 2 렌더링 이미지에 포함될 안전벨트의 텍스쳐 타입(texture type)을 결정하고, 그리고 상기 결정된 텍스쳐 타입에 매핑되는 통계 데이터를 이용하여, 상기 제 2 렌더링 이미지에서 상기 결정된 텍스쳐 타입에 대응되는 텍스쳐의 렌더링 밝기 및 강도 중 적어도 하나를 조정할 것을 결정하는 단계;를 포함하며, 그리고복수의 텍스쳐 타입(texture type)들 각각에 대하여, 렌더링 밝기 및 강도 중 적어도 하나에 대한 통계 데이터가 매핑되는,방법.</claim></claimInfo><claimInfo><claim>16. 제 1 항에 있어서,상기 객체는 안전벨트를 포함하며, 그리고상기 제 2 학습에 이용될 렌더링 조건을 결정하는 단계는:복수의 텍스쳐 타입들 각각에 대응되는 통계 데이터를 획득하는 단계;상기 통계 데이터를 이용하여, 상기 복수의 텍스쳐 타입들 중에서, 임계 개수 또는 임계 비율 미만의 양을 가지는 타겟(target) 텍스쳐 타입을 결정하는 단계; 및상기 제 2 학습에서 상기 타겟 텍스쳐 타입에 대응되는 텍스쳐의 렌더링 비율 또는 렌더링 빈도를 증가시킬 것을 결정하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>17. 제 1 항에 있어서,상기 객체는 얼굴을 포함하며, 그리고상기 제 2 학습에 이용될 렌더링 조건을 결정하는 단계는:복수의 얼굴 각도 조건들 각각에 대응되는 통계 데이터를 획득하는 단계;상기 통계 데이터를 이용하여, 상기 복수의 얼굴 각도 조건들 중에서, 임계 개수 또는 임계 비율 미만의 양을 가지는 타겟(target) 얼굴 각도 조건을 결정하는 단계; 및상기 제 2 학습에서 상기 타겟 얼굴 각도 조건에 대응되는 얼굴 각도의 렌더링 비율 또는 렌더링 빈도를 증가시킬 것을 결정하는 단계;를 포함하는,방법.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,상기 복수의 얼굴 각도 조건들 각각은, 사전 결정된 요(yaw) 값 및 피치(pitch) 값의 조합에 기초하여 결정되는,방법. </claim></claimInfo><claimInfo><claim>19. 컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램으로서, 상기 컴퓨터 프로그램은, 적어도 하나의 프로세서에 의해 실행 시, 상기 적어도 하나의 프로세서로 하여금 DMS(Driver Monitoring Systems)에서 객체를 인식하기 위한 인공지능 기반의 모델을 학습시키기 위한 동작을 수행하도록 허용하며,상기 동작은:참조 이미지를 획득하는 동작;데이터 증강을 위하여, 상기 참조 이미지로부터 상기 객체가 포함된 제 1 렌더링 이미지를 생성하는 동작;상기 제 1 렌더링 이미지를 이용하여 상기 모델의 제 1 학습을 수행함으로써, 상기 제 1 학습에 대응되는 제 1 학습 결과를 획득하는 동작;상기 제 1 학습 결과와 상기 제 1 렌더링 이미지를 이용하여, 상기 제 1 학습에 후속되는 제 2 학습에 이용될 렌더링 조건을 결정하는 동작; 및상기 렌더링 조건을 이용하여, 상기 모델의 상기 제 2 학습을 수행하는 동작;을 포함하는,컴퓨터 판독가능 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>20. 컴퓨팅 디바이스로서,적어도 하나의 프로세서; 및메모리;를 포함하며, 상기 적어도 하나의 프로세서는:참조 이미지를 획득하는 동작;데이터 증강을 위하여, 상기 참조 이미지로부터 객체가 포함된 제 1 렌더링 이미지를 생성하는 동작;상기 제 1 렌더링 이미지를 이용하여 인공지능 기반의 모델의 제 1 학습을 수행함으로써, 상기 제 1 학습에 대응되는 제 1 학습 결과를 획득하는 동작;상기 제 1 학습 결과와 상기 제 1 렌더링 이미지를 이용하여, 상기 제 1 학습에 후속되는 제 2 학습에 이용될 렌더링 조건을 결정하는 동작; 및상기 렌더링 조건을 이용하여, 상기 모델의 상기 제 2 학습을 수행하는 동작;을 수행하는,컴퓨팅 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>120150372683</code><country>대한민국</country><engName>NOTA, INC.</engName><name>주식회사 노타</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 화성...</address><code> </code><country> </country><engName>KIM, Sangtae</engName><name>김상태</name></inventorInfo><inventorInfo><address>서울특별시 영등포구...</address><code> </code><country> </country><engName>JUNG, Eunsik</engName><name>정은식</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>SHIN, Wheemyung</engName><name>신휘명</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920090037635</code><country>대한민국</country><engName>LEE, Dae Ho</engName><name>이대호</name></agentInfo><agentInfo><address>서울특별시 강남구 강남대로 *** (논현동,어반하이브빌딩) **층(파이특허법률사무소)</address><code>920120001378</code><country>대한민국</country><engName>Park, Gun Hong</engName><name>박건홍</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.20</receiptDate><receiptNumber>1-1-2023-1287295-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2025.04.25</receiptDate><receiptNumber>4-1-2025-5112974-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230160747.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9385f595290fd0a5ae9795b1d907314b62885fa9f117aaabe382b897dd68f58f7d36564b0f38d275399cfee7f9dceaada29c4ce2a17de780fc</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfc17d465d221df212c0fc5c1d392d0b3ba006bc4a46222a1e87bbad7dd1d0c91fcfb7d713feb995b966e7e4b370a337c2c55128ac17cf3ee7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>