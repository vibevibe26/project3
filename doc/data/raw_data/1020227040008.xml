<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:08:31.831</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.05.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7040008</applicationNumber><claimCount>35</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자동 카메라 가이던스 및 설정 조정</inventionTitle><inventionTitleEng>AUTOMATIC CAMERA GUIDANCE AND SETTINGS ADJUSTMENT</inventionTitleEng><openDate>2023.01.31</openDate><openNumber>10-2023-0015341</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.05.02</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.11.15</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/611</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/63</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 7/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/24</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미지 캡처 및 프로세싱 디바이스는 이미지를 캡처한다. 이미지 및/또는 하나 이상의 추가적인 이미지들에 기초하여, 이미지 캡처 및 프로세싱 디바이스는 이미지 조성, 이미지 캡처 설정들, 및/또는 이미지 프로세싱 설정들을 최적화하기 위한 가이던스를 생성 및 출력한다. 가이던스는 이미지의 피사체가 향하고 있는 방향의 결정에 기초하여, 수평선이 비스듬할 수도 있음을 표시하는 센서 측정들, 광각 렌즈를 사용하여 캡처된 동일한 장면의 다른 이미지, 동일한 피사체의 다른 이미지, 상이한 피사체의 다른 이미지, 및/또는 이미지들의 세트를 사용하여 트레이닝된 머신 러닝 모델의 출력들에 기초하여 생성될 수 있다. 이미지 캡처 및 프로세싱 디바이스는 이미지 캡처 설정들 및/또는 이미지 프로세싱 설정들과 같은 생성된 가이던스의 특정 양태들을 자동으로 적용할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.11.25</internationOpenDate><internationOpenNumber>WO2021236844</internationOpenNumber><internationalApplicationDate>2021.05.19</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/033263</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 캡처를 안내하기 위한 장치로서,명령들을 저장하는 하나 이상의 메모리 유닛들; 및상기 명령들을 실행하는 하나 이상의 프로세서들을 포함하고,상기 하나 이상의 프로세서들에 의한 상기 명령들의 실행은 상기 하나 이상의 프로세서들로 하여금이미지 센서에 의해 캡처된 장면의 제 1 이미지를 수신하게 하고;상기 제 1 이미지에서 묘사된 피사체를 식별하게 하고;상기 제 1 이미지를 머신 러닝 모델에 입력하게 하는 것으로서, 상기 머신 러닝 모델은 식별된 피사체들을 갖는 복수의 트레이닝 이미지들을 사용하여 트레이닝되는, 상기 제 1 이미지를 머신 러닝 모델에 입력하게 하고;상기 머신 러닝 모델을 사용하여, 상기 제 1 이미지와 상기 제 1 이미지를 캡처한 이후 상기 이미지 센서에 의해 캡처될 제 2 이미지와의 사이의 시각적 차이를 야기하는 이미지 캡처와 연관된 하나 이상의 속성들에 대한 하나 이상의 변경들을 식별하게 하고; 그리고 상기 이미지 센서가 상기 제 2 이미지를 캡처하기 전에 상기 시각적 차이를 생성하기 위해 상기 하나 이상의 변경들을 나타내는 가이던스를 출력하게 하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 장치는 모바일 디바이스, 무선 통신 디바이스, 및 카메라 중 적어도 하나인, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,상기 장치는 적어도 상기 제 2 이미지를 디스플레이하도록 구성된 디스플레이를 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서,상기 이미지 센서에 커플링된 하나 이상의 커넥터들을 더 포함하고,상기 하나 이상의 프로세서들은 상기 하나 이상의 커넥터들을 통해 상기 이미지 센서로부터 상기 제 1 이미지를 수신하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 이미지 센서를 더 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>6. 제 1 항에 있어서,상기 제 1 이미지에서 묘사된 피사체를 식별하는 것은 피처 검출, 오브젝트 검출, 얼굴 검출, 피처 인식, 오브젝트 인식, 얼굴 인식, 및 샐리언시 맵의 생성 중 적어도 하나를 수행하는 것을 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서,상기 하나 이상의 프로세서들에 의한 상기 명령들의 실행은 상기 하나 이상의 프로세서들로 하여금, 추가로,상기 가이던스를 출력한 이후 상기 이미지 센서로부터 상기 제 2 이미지를 수신하게 하고; 그리고상기 제 2 이미지를 출력하게 하며,상기 제 2 이미지를 출력하는 것은 디스플레이를 사용하여 상기 제 2 이미지를 디스플레이하는 것 및 송신기를 사용하여 상기 제 2 이미지를 송신하는 것 중 적어도 하나를 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>8. 제 1 항에 있어서,상기 이미지 캡처와 연관된 하나 이상의 속성들에 대한 하나 이상의 변경들을 식별하는 것은 제 1 포지션으로부터 제 2 포지션으로의 상기 장치의 이동을 식별하는 것을 포함하고, 상기 가이던스를 출력하는 것은 상기 장치를 상기 제 1 포지션으로부터 상기 제 2 포지션으로 이동시키기 위한 표시자를 출력하는 것을 포함하고, 상기 표시자는 상기 이동의 병진 방향, 상기 이동의 병진 거리, 상기 이동의 회전 방향, 및 상기 이동의 회전 각도 중 적어도 하나를 식별하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 제 2 포지션은 상기 머신 러닝 모델을 사용하여 식별되는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>10. 제 8 항에 있어서,상기 표시자는 시각적 표시자, 오디오 표시자, 및 진동 표시자 중 적어도 하나를 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>11. 제 8 항에 있어서,상기 표시자는 상기 제 2 포지션의 하나 이상의 위치 좌표들을 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>12. 제 8 항에 있어서,상기 제 1 이미지와 상기 제 2 이미지와의 사이의 상기 시각적 차이는 상기 제 2 이미지에서 수평선을 레벨링하고, 상기 수평선은 상기 제 1 이미지에서 묘사된 레벨은 아닌, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>13. 제 8 항에 있어서,상기 하나 이상의 프로세서들에 의한 상기 명령들의 실행은 상기 하나 이상의 프로세서들로 하여금, 추가로,하나 이상의 포즈 센서들로부터 포즈 센서 측정 데이터를 수신하게 하고; 그리고상기 포즈 센서 측정 데이터에 기초하여 상기 장치의 포즈를 결정하게 하며,상기 제 1 포지션으로부터 제 2 포지션으로의 상기 장치의 이동을 식별하는 것은 상기 장치의 상기 포즈에 기초하고, 상기 장치의 상기 포즈는 상기 장치의 위치 및 상기 장치의 배향 중 적어도 하나를 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>14. 제 8 항에 있어서,상기 하나 이상의 프로세서들에 의한 상기 명령들의 실행은 상기 하나 이상의 프로세서들로 하여금, 추가로,상기 제 1 이미지에서의 상기 피사체의 포지션을 결정하게 하고; 그리고상기 피사체의 2개의 피처들의 상대적 포지셔닝, 및 상기 피사체가 상기 제 1 이미지와 상기 이미지 센서에 의해 캡처된 제 3 이미지와의 사이에서 이동하는 이동 방향 중 적어도 하나에 기초하여 상기 제 1 이미지에서 상기 피사체가 향하고 있는 방향을 결정하게 하며,상기 제 1 포지션으로부터 상기 제 2 포지션으로의 상기 장치의 이동을 식별하는 것은 상기 제 1 이미지에서의 상기 피사체의 상기 포지션 및 상기 제 1 이미지에서 상기 피사체가 향하고 있는 상기 방향에 기초하고, 상기 제 1 이미지와 상기 제 2 이미지와의 사이의 상기 시각적 차이는 상기 피사체가 향하고 있는 상기 방향에서 상기 피사체에 인접한 네거티브 공간의 양에서의 조정을 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>15. 제 1 항에 있어서,상기 하나 이상의 프로세서들에 의한 상기 명령들의 실행은 상기 하나 이상의 프로세서들로 하여금, 추가로,제 2 이미지 센서에 의해 캡처된 장면의 제 3 이미지를 수신하게 하며,상기 장면의 상기 제 1 이미지 및 상기 장면의 상기 제 3 이미지는 시간 윈도우 내에서 캡처되고, 상기 제 2 이미지 센서는 상기 이미지 센서보다 더 넓은 시야를 가지며, 상기 가이던스는 상기 제 1 이미지에 묘사되지 않은 상기 제 3 이미지에서의 상기 장면의 일부의 묘사에 기초하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>16. 제 1 항에 있어서,상기 가이던스는, 상기 장치가 상기 제 1 이미지의 캡처와 상기 제 2 이미지의 캡처 사이에서 정지된 채로 유지해야 함을 표시하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제 1 항에 있어서,상기 복수의 트레이닝 이미지들은 상기 피사체 및 상기 피사체와 하나 이상의 유사성들을 공유하는 제 2 피사체 중 적어도 하나를 묘사하는 트레이닝 이미지를 포함하고, 상기 가이던스에 의해 표시된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들은 상기 트레이닝 이미지의 캡처에 사용된 상기 하나 이상의 속성들에 대한 하나 이상의 설정들에 기초하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,상기 제 2 피사체와 상기 피사체 사이에 공유된 상기 하나 이상의 유사성들은 상기 제 2 피사체와 연관된 하나 이상의 샐리언시 값들이 상기 피사체와 연관된 하나 이상의 샐리언시 값들의 미리결정된 범위 내에 있는 것을 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>19. 제 17 항에 있어서,상기 제 1 이미지와 상기 제 2 이미지와의 사이의 상기 시각적 차이는, 상기 제 1 이미지가 상기 트레이닝 이미지에 대한 것보다 상기 제 2 이미지가 상기 트레이닝 이미지와 더 유사한 것을 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>20. 제 1 항에 있어서,상기 이미지 캡처와 연관된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들은 상기 이미지 센서가 상기 제 2 이미지를 캡처하기 전에 이미지 캡처 설정을 적용하는 것을 포함하고, 상기 이미지 캡처 설정은 줌, 포커스, 노출 시간, 애퍼처 사이즈, ISO, 피사계 심도, 아날로그 이득, 및 f/스톱 중 적어도 하나에 대응하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서,상기 가이던스를 출력하는 것은, 상기 이미지 캡처 설정을 적용하는 것에 대응하는 이미지 캡처와 연관된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들을 식별하는 표시자를 출력하는 것을 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>22. 제 20 항에 있어서,상기 가이던스를 출력하는 것은, 상기 이미지 캡처 설정을 적용하는 것에 대응하는 이미지 캡처와 연관된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들을 자동으로 적용하는 것을 포함하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>23. 제 1 항에 있어서,상기 하나 이상의 프로세서들에 의한 상기 명령들의 실행은 상기 하나 이상의 프로세서들로 하여금, 추가로,상기 이미지 센서에 의해 캡처된 상기 제 2 이미지를 수신하게 하며,상기 이미지 캡처와 연관된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들은 이미지 프로세싱 설정을 상기 제 2 이미지에 적용하는 것을 포함하고, 상기 이미지 프로세싱 설정은 명도, 콘트라스트, 채도, 감마, 레벨들, 히스토그램, 컬러 조정들, 블러, 선예도, 레벨들, 곡선들, 필터링, 및 크롭핑 중 적어도 하나에 대응하는, 이미지 캡처를 안내하기 위한 장치.</claim></claimInfo><claimInfo><claim>24. 이미지 캡처를 안내하는 방법으로서,이미지 캡처 디바이스의 이미지 센서에 의해 캡처된 장면의 제 1 이미지를 수신하는 단계;상기 제 1 이미지에서 묘사된 피사체를 식별하는 단계;상기 제 1 이미지를 머신 러닝 모델에 입력하는 단계로서, 상기 머신 러닝 모델은 식별된 피사체들을 갖는 복수의 트레이닝 이미지들을 사용하여 트레이닝되는, 상기 제 1 이미지를 머신 러닝 모델에 입력하는 단계;상기 머신 러닝 모델을 사용하여, 상기 제 1 이미지와 상기 제 1 이미지를 캡처한 이후 상기 이미지 센서에 의해 캡처될 제 2 이미지와의 사이의 시각적 차이를 야기하는 상기 이미지 캡처 디바이스의 하나 이상의 속성들에 대한 하나 이상의 변경들을 식별하는 단계; 및상기 이미지 센서가 상기 제 2 이미지를 캡처하기 전에 상기 시각적 차이를 생성하기 위해 상기 하나 이상의 변경들을 나타내는 가이던스를 출력하는 단계를 포함하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>25. 제 24 항에 있어서,상기 방법은 상기 이미지 캡처 디바이스에 의해 수행되고, 상기 이미지 캡처 디바이스는 모바일 디바이스, 무선 통신 디바이스, 및 카메라 중 적어도 하나인, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>26. 제 24 항에 있어서,상기 제 1 이미지에서 묘사된 피사체를 식별하는 단계는 피처 검출, 오브젝트 검출, 얼굴 검출, 피처 인식, 오브젝트 인식, 얼굴 인식, 및 샐리언시 맵의 생성 중 적어도 하나를 수행하는 단계를 포함하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>27. 제 24 항에 있어서,상기 이미지 캡처와 연관된 하나 이상의 속성들에 대한 하나 이상의 변경들을 식별하는 단계는 제 1 포지션으로부터 제 2 포지션으로의 상기 이미지 캡처 디바이스의 이동을 식별하는 단계를 포함하고, 상기 가이던스를 출력하는 단계는 상기 이미지 캡처 디바이스를 상기 제 1 포지션으로부터 상기 제 2 포지션으로 이동시키기 위한 표시자를 출력하는 단계를 포함하고, 상기 표시자는 상기 이동의 병진 방향, 상기 이동의 병진 거리, 상기 이동의 회전 방향, 및 상기 이동의 회전 각도 중 적어도 하나를 식별하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>28. 제 27 항에 있어서,상기 제 2 포지션은 상기 머신 러닝 모델을 사용하여 식별되는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>29. 제 27 항에 있어서,상기 제 1 이미지와 상기 제 2 이미지와의 사이의 상기 시각적 차이는 상기 제 2 이미지에서 수평선을 레벨링하고, 상기 수평선은 상기 제 1 이미지에서 묘사된 레벨은 아닌, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>30. 제 27 항에 있어서,상기 제 1 이미지에서의 상기 피사체의 포지션을 결정하는 단계; 및상기 피사체의 2개의 피처들의 상대적 포지셔닝, 및 상기 피사체가 상기 제 1 이미지와 상기 이미지 센서에 의해 캡처된 제 3 이미지와의 사이에서 이동하는 이동 방향 중 적어도 하나에 기초하여 상기 제 1 이미지에서 상기 피사체가 향하고 있는 방향을 결정하는 단계를 더 포함하고,상기 제 1 포지션으로부터 상기 제 2 포지션으로의 상기 이미지 캡처 디바이스의 이동을 식별하는 단계는 상기 제 1 이미지에서의 상기 피사체의 상기 포지션 및 상기 제 1 이미지에서 상기 피사체가 향하고 있는 상기 방향에 기초하고, 상기 제 1 이미지와 상기 제 2 이미지와의 사이의 상기 시각적 차이는 상기 피사체가 향하고 있는 상기 방향에서 상기 피사체에 인접한 네거티브 공간의 양에서의 조정을 포함하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>31. 제 24 항에 있어서,제 2 이미지 센서에 의해 캡처된 장면의 제 3 이미지를 수신하는 단계를 더 포함하고,상기 장면의 상기 제 1 이미지 및 상기 장면의 상기 제 3 이미지는 시간 윈도우 내에서 캡처되고, 상기 제 2 이미지 센서는 상기 이미지 센서보다 더 넓은 시야를 가지며, 상기 가이던스는 상기 제 1 이미지에 묘사되지 않은 상기 제 3 이미지에서의 상기 장면의 일부의 묘사에 기초하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>32. 제 24 항에 있어서,상기 복수의 트레이닝 이미지들은 상기 피사체 및 상기 피사체와 하나 이상의 유사성들을 공유하는 제 2 피사체 중 적어도 하나를 묘사하는 트레이닝 이미지를 포함하고, 상기 가이던스에 의해 표시된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들은 상기 트레이닝 이미지의 캡처에 사용된 상기 하나 이상의 속성들에 대한 하나 이상의 설정들에 기초하고, 상기 제 1 이미지와 상기 제 2 이미지와의 사이의 상기 시각적 차이는, 상기 제 1 이미지가 상기 트레이닝 이미지에 대한 것보다 상기 제 2 이미지가 상기 트레이닝 이미지와 더 유사한 것을 포함하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>33. 제 32 항에 있어서,상기 제 2 피사체와 상기 피사체 사이에 공유된 상기 하나 이상의 유사성들은 상기 제 2 피사체와 연관된 하나 이상의 샐리언시 값들이 상기 피사체와 연관된 하나 이상의 샐리언시 값들의 미리결정된 범위 내에 있는 것을 포함하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>34. 제 24 항에 있어서,상기 이미지 캡처와 연관된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들은 상기 이미지 센서가 상기 제 2 이미지를 캡처하기 전에 이미지 캡처 설정을 적용하는 것을 포함하고, 상기 이미지 캡처 설정은 줌, 포커스, 노출 시간, 애퍼처 사이즈, ISO, 피사계 심도, 아날로그 이득, 및 f/스톱 중 적어도 하나에 대응하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo><claimInfo><claim>35. 제 24 항에 있어서,상기 이미지 센서에 의해 캡처된 상기 제 2 이미지를 수신하는 단계를 더 포함하고,상기 이미지 캡처와 연관된 상기 하나 이상의 속성들에 대한 상기 하나 이상의 변경들은 이미지 프로세싱 설정을 상기 제 2 이미지에 적용하는 것을 포함하고, 상기 이미지 프로세싱 설정은 명도, 콘트라스트, 채도, 감마, 레벨들, 히스토그램, 컬러 조정들, 블러, 선예도, 레벨들, 곡선들, 필터링, 및 크롭핑 중 적어도 하나에 대응하는, 이미지 캡처를 안내하는 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>LI, MUHUA</engName><name>리 무화</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country> </country><engName>CHEN, AN</engName><name>천 안</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.05.22</priorityApplicationDate><priorityApplicationNumber>63/029,214</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.10.15</priorityApplicationDate><priorityApplicationNumber>17/071,971</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.11.15</receiptDate><receiptNumber>1-1-2022-1216316-53</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.12.27</receiptDate><receiptNumber>1-5-2022-0197190-65</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.05.02</receiptDate><receiptNumber>1-1-2024-0482726-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.05.02</receiptDate><receiptNumber>1-1-2024-0482727-77</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227040008.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93ebdc161471941beedbf5296e291d7601731c199b3dc52dde38e54c69706a0e21a227b5df31b60565c4013b8a7c8538d1b9c9bba66a15f458</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf8488c372247c7a18c170436b870b10eade300e361a54b6ae9cfa783793ba4d28ec3b573843a9068b7b77ef26d75b62cca675afc96f10dc49</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>