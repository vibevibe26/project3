<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:01.371</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0164587</applicationNumber><claimCount>14</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>편향 제거된 세그멘테이션 방법 및 이를 수행하는 서버</inventionTitle><inventionTitleEng>Debiased segmentation method and server that performs  the same method</inventionTitleEng><openDate>2025.05.30</openDate><openNumber>10-2025-0077131</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.11.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G06T 7/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/762</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0895</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/66</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/33</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 편향이 제거된 세그멘테이션 방법에 관한 것이다. 본 발명의 일 실시예에 따른 적어도 하나의 프로세서에 의해 수행되는 이미지 세그멘테이션 방법은 대상 이미지를 입력 받는 단계; 입력된 대상 이미지에 대한 제1 세그멘테이션 맵 및 제1 특징 맵을 생성하는 단계; 상기 제1 세그멘테이션 맵을 상기 특징 맵에 매핑하여 제2 특징 맵을 생성하는 단계; 상기 제2 특징맵을 클러스터링 하여 각 클러스터 별 제1 중심을 산출하는 단계; 및 상기 산출된 제1 중심 간의 거리로 결정된 제2 중심과 상기 제1 특징 맵 내 픽셀 간 유사도에 따라 제1 세그멘테이션 맵의 일부 영역을 제외한 제2 세그멘테이션 맵을 생성하는 단계를 포함한다. 본 발명에 따르면 약지도 또는 비지도 학습을 사용함으로써, 본 발명은 세그멘테이션 모델에서 데이터 편향의 영향을 크게 줄일 수 있다. 이는 모델이 다양한 상황과 환경에서 보다 균형 잡힌 방식으로 작동하게 하며, 이로 인해 세그멘테이션의 정확도와 신뢰성이 향상될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 프로세서에 의해 수행되는 이미지 세그멘테이션 방법에 있어서,대상 이미지를 입력 받는 단계;입력된 대상 이미지에 대한 제1 세그멘테이션 맵 및 제1 특징 맵을 생성하는 단계;상기 제1 세그멘테이션 맵을 상기 특징 맵에 매핑하여 제2 특징 맵을 생성하는 단계;상기 제2 특징맵을 클러스터링 하여 각 클러스터 별 제1 중심을 산출하는 단계; 및상기 산출된 제1 중심 간의 거리로 결정된 제2 중심과 상기 제1 특징 맵 내 픽셀 간 유사도에 따라 제1 세그멘테이션 맵의 일부 영역을 제외한 제2 세그멘테이션 맵을 생성하는 단계를 포함하는 이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제1 세그멘테이션 맵 및 제1 특징 맵을 생성하는 단계는,상기 대상 이미지에 대한 약지도 학습된 신경망을 통해 제1 세그멘테이션 맵을 생성하는 단계; 및상기 대상 이미지에 대한 비지도 학습된 신경망을 통해 제1 특징 맵을 생성하는 단계를 포함하는 것을 특징으로 하는 이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>3. 제 1 항에 있어서,상기 제2 특징 맵을 생성하는 단계는,상기 제1 세그멘테이션 맵을 픽셀 단위로 상기 제1 특징 맵에 투영시킴으로써 제2 특징 맵을 생성하는 것을 특징으로 하는 이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>4. 제 3 항에 있어서,상기 중심을 산출하는 단계는,상기 제2 특징맵의 픽셀을 전경 클러스터와 배경 클러스터로 클러스터링하는 단계; 및상기 전경 클러스터와 배경 클러스터의 각각의 중심을 산출하는 단계를 포함하는 것을 특징으로 하는 이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,상기 전경 클러스터는 클래스 별 제1 전경 클러스터 및 제2 전경 클러스터를 포함하는 것을 특징으로 하는 이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서,상기 제2 세그멘테이션 맵을 생성하는 단계는,상기 배경 클러스터의 중심과 상기 제1 전경 클러스터 및 제2 전경 클러스터거리의 제1 중심 간의 거리 순으로 결정된 중심 그룹의 제2 중심을 산출하는 단계;상기 산출된 제2 중심과 상기 제1 특징 맵 내 픽셀 간 유사도를 산출하는 단계; 및상기 산출된 유사도에 따라 편향된 픽셀에 대응하는 제1 세그멘테이션 맵 내 픽셀을 제외한 제2 세그멘테이션 맵을 생성하는 단계를 포함하는 이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>7. 제 1 항에 있어서,상기 제2 세그멘테이션 맵에 비편향 영역을 보완한 제3 세그멘테이션 맵을 생성하는 단계를 더 포함하는 이미지 세그멘테이션 방법.</claim></claimInfo><claimInfo><claim>8. 프로세서, 및상기 프로세서와 통신하는 메모리를 포함하고,상기 메모리는 상기 프로세서로 하여금 동작들을 수행하게 하는 명령들을 저장하고,상기 동작들은, 대상 이미지를 입력 받는 동작,입력된 대상 이미지에 대한 제1 세그멘테이션 맵 및 제1 특징 맵을 생성하는 동작,상기 제1 세그멘테이션 맵을 상기 특징 맵에 매핑하여 제2 특징 맵을 생성하는 동작,상기 제2 특징맵을 클러스터링 하여 각 클러스터 별 제1 중심을 산출하는 동작,상기 산출된 제1 중심 간의 거리로 결정된 제2 중심과 상기 제1 특징 맵 내 픽셀 간 유사도에 따라 제1 세그멘테이션 맵의 일부 영역을 제외한 제2 세그멘테이션 맵을 생성하는 동작을 포함하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 제1 세그멘테이션 맵 및 제1 특징 맵을 생성하는 동작은,상기 대상 이미지에 대한 약지도 학습된 신경망을 통해 제1 세그멘테이션 맵을 생성하는 동작, 및상기 대상 이미지에 대한 비지도 학습된 신경망을 통해 제1 특징 맵을 생성하는 동작을 포함하는 것을 특징으로 하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>10. 제 8 항에 있어서,상기 제2 특징 맵을 생성하는 동작은,상기 제1 세그멘테이션 맵을 픽셀 단위로 상기 제1 특징 맵에 투영시킴으로써 제2 특징 맵을 생성하는 것을 특징으로 하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>11. 제 10 항에 있어서,상기 중심을 산출하는 동작은,상기 제2 특징맵의 픽셀을 전경 클러스터와 배경 클러스터로 클러스터링하는 동작, 및상기 전경 클러스터와 배경 클러스터의 각각의 중심을 산출하는 동작을 포함하는 것을 특징으로 하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>12. 제 11 항에 있어서,상기 전경 클러스터는 클래스 별 제1 전경 클러스터 및 제2 전경 클러스터를 포함하는 것을 특징으로 하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서,상기 제2 세그멘테이션 맵을 생성하는 동작은,상기 배경 클러스터의 중심과 상기 제1 전경 클러스터 및 제2 전경 클러스터거리의 제1 중심 간의 거리 순으로 결정된 중심 그룹의 제2 중심을 산출하는 동작,상기 산출된 제2 중심과 상기 제1 특징 맵 내 픽셀 간 유사도를 산출하는 동작, 및상기 산출된 유사도에 따라 편향된 픽셀에 대응하는 제1 세그멘테이션 맵 내 픽셀을 제외한 제2 세그멘테이션 맵을 생성하는 동작을 포함하는 컴퓨팅 장치.</claim></claimInfo><claimInfo><claim>14. 제 8 항에 있어서,상기 제2 세그멘테이션 맵에 비편향 영역을 보완한 제3 세그멘테이션 맵을 생성하는 동작을 더 포함하는 컴퓨팅 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강남구...</address><code>120140408899</code><country>대한민국</country><engName>OGQ Corporation</engName><name>오지큐 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>KIM, Kyung Su</engName><name>김경수</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>YOO, In Jea</engName><name>유인재</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>JO, Sang Hyun</engName><name>조상현</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>BANG, Seung On</engName><name>방승온</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 테헤란로**길 ** (역삼동) *층(특허법률사무소베젤)</address><code>920140005243</code><country>대한민국</country><engName>JANG HOON LEE</engName><name>이장훈</name></agentInfo><agentInfo><address>서울 강남구 테헤란로**길 ** (역삼동) *층(특허법률사무소베젤)</address><code>920130019909</code><country>대한민국</country><engName>PARK JEONGWOO</engName><name>박정우</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.23</receiptDate><receiptNumber>1-1-2023-1311140-11</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230164587.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a91394be4864215886416e35d82aa5edab94dd08e5b543d7b7f03327a623fc19144b8f6137a552ccaa4eb2088697a4439c7cece66aaf28d7</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6a29009236fe986f984eb9f5000a5fff0376c02d0e6481928ce59a1af60646e7eedcf17f4da39546d68a223f80cf0be0229da85aaebff98d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>