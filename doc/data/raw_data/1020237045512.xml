<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:14:59.1459</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.07.07</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7045512</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>멀티-포인트 깊이 감지 시스템 정보를 사용한 이미지 데이터 프로세싱</inventionTitle><inventionTitleEng>PROCESSING IMAGE DATA USING MULTI-POINT DEPTH SENSING SYSTEM INFORMATION</inventionTitleEng><openDate>2024.03.05</openDate><openNumber>10-2024-0029003</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.06.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.12.29</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/959</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/76</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/67</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/88</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/69</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 하나 이상의 이미지들을 프로세싱하기 위한 시스템들 및 기법들이 제공된다. 예를 들어, 양태들은 적어도 하나의 카메라를 사용하여 획득된 이미지에 묘사된 제1 객체에 대응하는 제1 관심 영역을 결정하는 것을 포함할 수 있는 프로세스를 포함한다. 제1 관심 영역은 멀티-포인트 깊이 감지 시스템과 연관된 멀티-포인트 그리드의 적어도 하나의 엘리먼트와 연관된다. 프로세스는 제1 객체에 대한 제1 확장된 관심 영역을 결정하는 것을 포함할 수 있다. 제1 확장된 관심 영역은 멀티-포인트 그리드의 적어도 하나의 엘리먼트 및 하나 이상의 추가적인 엘리먼트들을 포함하는 복수의 엘리먼트들과 연관된다. 프로세스는 제1 확장된 관심 영역과 연관된 복수의 엘리먼트들에 기초하여, 적어도 하나의 카메라와 이미지에 묘사된 제1 객체 사이의 제1 거리를 표현하는 대표 깊이 정보를 결정하는 것을 더 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.01.12</internationOpenDate><internationOpenNumber>WO2023279289</internationOpenNumber><internationalApplicationDate>2021.07.07</internationalApplicationDate><internationalApplicationNumber>PCT/CN2021/104992</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 데이터를 프로세싱하는 방법으로서,적어도 하나의 카메라를 사용하여 획득된 이미지에 묘사된 제1 객체에 대응하는 제1 관심 영역을 결정하는 단계로서, 상기 제1 관심 영역은 멀티-포인트 깊이 감지 시스템과 연관된 멀티-포인트 그리드의 적어도 하나의 엘리먼트와 연관되는, 상기 제1 관심 영역을 결정하는 단계;상기 제1 객체에 대한 제1 확장된 관심 영역을 결정하는 단계로서, 상기 제1 확장된 관심 영역은 상기 멀티-포인트 그리드의 상기 적어도 하나의 엘리먼트 및 하나 이상의 추가적인 엘리먼트들을 포함하는 복수의 엘리먼트들과 연관되는, 상기 제1 확장된 관심 영역을 결정하는 단계; 및상기 제1 확장된 관심 영역과 연관된 상기 복수의 엘리먼트들에 기초하여, 상기 적어도 하나의 카메라와 상기 이미지에 묘사된 상기 제1 객체 사이의 제1 거리를 표현하는 대표 깊이 정보를 결정하는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 거리를 표현하는 상기 대표 깊이 정보에 기초하여 상기 이미지를 프로세싱하는 단계를 더 포함하고, 상기 이미지를 프로세싱하는 단계는 적어도 상기 이미지의 상기 제1 관심 영역에 대해 자동 노출, 자동 포커스, 자동 화이트 밸런스 및 자동 줌 중 적어도 하나를 수행하는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하는 단계는,상기 제1 관심 영역의 크기 및 상기 이미지에서의 기준 포인트에 대한 상기 제1 관심 영역의 위치 중 적어도 하나를 결정하는 단계; 및상기 제1 관심 영역의 상기 크기 및 상기 위치 중 적어도 하나에 기초하여 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 또는 제2항에 있어서, 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하는 단계는,상기 멀티-포인트 그리드의 상기 하나 이상의 추가적인 엘리먼트들 중 제1 엘리먼트와 연관된 제1 깊이를 결정하는 단계로서, 상기 제1 엘리먼트는 상기 제1 관심 영역과 연관된 상기 적어도 하나의 엘리먼트에 이웃하는, 상기 제1 깊이를 결정하는 단계;상기 제1 깊이와 상기 제1 관심 영역과 연관된 상기 적어도 하나의 엘리먼트의 깊이 사이의 차이가 임계 차이 미만이라고 결정하는 단계; 및상기 제1 깊이와 상기 제1 관심 영역과 연관된 상기 적어도 하나의 엘리먼트의 깊이 사이의 차이가 상기 임계 차이 미만이라고 결정하는 것에 기초하여, 상기 제1 엘리먼트를 상기 제1 확장된 관심 영역과 연관시키는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 제1 거리를 표현하는 상기 대표 깊이 정보를 결정하는 단계는,상기 제1 확장된 관심 영역과 연관된 상기 복수의 엘리먼트들의 깊이 값들에 기초하여 상기 제1 확장된 관심 영역에 대한 대표 깊이 값을 결정하는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,상기 제1 관심 영역이 상기 이미지에 대해 결정된 유일한 관심 영역인 것에 기초하여, 상기 제1 거리를 표현하는 상기 대표 깊이 정보에 기초하여 상기 이미지를 프로세싱하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 제1 거리를 표현하는 상기 대표 깊이 정보에 기초하여 상기 이미지를 프로세싱하는 단계는 적어도 상기 이미지의 상기 제1 관심 영역에 대해 자동 노출, 자동 포커스, 자동 화이트 밸런스 및 자동 줌 중 적어도 하나를 수행하는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 이미지에 묘사된 제2 객체에 대응하는 제2 관심 영역을 결정하는 단계로서, 상기 제2 관심 영역은 상기 멀티-포인트 깊이 감지 시스템과 연관된 상기 멀티-포인트 그리드의 적어도 하나의 추가적인 엘리먼트와 연관되는, 상기 제2 관심 영역을 결정하는 단계;상기 제2 객체에 대한 제2 확장된 관심 영역을 결정하는 단계로서, 상기 제2 확장된 관심 영역은 상기 멀티-포인트 그리드의 상기 적어도 하나의 추가적인 엘리먼트 및 제2 하나 이상의 추가적인 엘리먼트들을 포함하는 복수의 엘리먼트들과 연관되는, 상기 제2 확장된 관심 영역을 결정하는 단계; 및상기 제2 확장된 관심 영역과 연관된 상기 복수의 엘리먼트들에 기초하여, 상기 적어도 하나의 카메라와 상기 이미지에 묘사된 상기 제2 객체 사이의 제2 거리를 표현하는 대표 깊이 정보를 결정하는 단계를 더 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>9. 이미지 데이터를 프로세싱하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 적어도 하나의 카메라를 사용하여 획득된 이미지에 묘사된 제1 객체에 대응하는 제1 관심 영역을 결정하는 것으로서, 상기 제1 관심 영역은 멀티-포인트 깊이 감지 시스템과 연관된 멀티-포인트 그리드의 적어도 하나의 엘리먼트와 연관되는, 상기 제1 관심 영역을 결정하고; 상기 제1 객체에 대한 제1 확장된 관심 영역을 결정하는 것으로서, 상기 제1 확장된 관심 영역은 상기 멀티-포인트 그리드의 상기 적어도 하나의 엘리먼트 및 하나 이상의 추가적인 엘리먼트들을 포함하는 복수의 엘리먼트들과 연관되는, 상기 제1 확장된 관심 영역을 결정하고; 그리고 상기 제1 확장된 관심 영역과 연관된 상기 복수의 엘리먼트들에 기초하여, 상기 적어도 하나의 카메라와 상기 이미지에 묘사된 상기 제1 객체 사이의 제1 거리를 표현하는 대표 깊이 정보를 결정하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 적어도 하나의 프로세서는,상기 제1 거리를 표현하는 상기 대표 깊이 정보에 기초하여 상기 이미지를 프로세싱하도록 구성되고, 상기 이미지를 프로세싱하는 것은 적어도 상기 이미지의 상기 제1 관심 영역에 대해 자동 노출, 자동 포커스, 자동 화이트 밸런스 및 자동 줌 중 적어도 하나를 수행하는 것을 포함하는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>11. 제9항 또는 제10항에 있어서, 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 제1 관심 영역의 크기 및 상기 이미지에서의 기준 포인트에 대한 상기 제1 관심 영역의 위치 중 적어도 하나를 결정하고; 그리고상기 제1 관심 영역의 상기 크기 및 상기 위치 중 적어도 하나에 기초하여 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 제1 관심 영역의 상기 크기에 기초하여 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 제1 관심 영역의 상기 위치에 기초하여 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 제1 관심 영역의 상기 크기 및 상기 위치에 기초하여 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>15. 제9항 또는 제10항에 있어서, 상기 제1 객체에 대한 상기 제1 확장된 관심 영역을 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 멀티-포인트 그리드의 상기 하나 이상의 추가적인 엘리먼트들 중 제1 엘리먼트와 연관된 제1 깊이를 결정하는 것으로서, 상기 제1 엘리먼트는 상기 제1 관심 영역과 연관된 상기 적어도 하나의 엘리먼트에 이웃하는, 상기 제1 깊이를 결정하고;상기 제1 깊이와 상기 제1 관심 영역과 연관된 상기 적어도 하나의 엘리먼트의 깊이 사이의 차이가 임계 차이 미만이라고 결정하고;상기 제1 깊이와 상기 제1 관심 영역과 연관된 상기 적어도 하나의 엘리먼트의 깊이 사이의 차이가 상기 임계 차이 미만이라고 결정하는 것에 기초하여, 상기 제1 엘리먼트를 상기 제1 확장된 관심 영역과 연관시키도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 적어도 하나의 프로세서는 상기 제1 깊이의 신뢰도가 신뢰도 임계치보다 큰 것에 추가로 기초하여 상기 제1 엘리먼트를 상기 제1 확장된 관심 영역과 연관시키도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제15항 또는 제16항에 있어서, 상기 적어도 하나의 프로세서는,상기 멀티-포인트 그리드의 상기 하나 이상의 추가적인 엘리먼트들 중 제2 엘리먼트와 연관된 제2 깊이를 결정하는 것으로서, 상기 제2 엘리먼트는 상기 하나 이상의 추가적인 엘리먼트들 중 상기 제1 엘리먼트에 이웃하는, 상기 제2 깊이를 결정하고;상기 제2 깊이와 상기 제1 깊이 사이의 차이가 상기 임계 차이 미만이라고 결정하고;상기 제2 깊이와 상기 제1 깊이 사이의 차이가 상기 임계 차이 미만이라고 결정하는 것에 기초하여, 상기 제2 엘리먼트를 상기 제1 확장된 관심 영역과 연관시키도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제15항 또는 제16항에 있어서, 상기 적어도 하나의 프로세서는,상기 멀티-포인트 그리드의 상기 하나 이상의 추가적인 엘리먼트들 중 제2 엘리먼트와 연관된 제2 깊이를 결정하는 것으로서, 상기 제2 엘리먼트는 상기 하나 이상의 추가적인 엘리먼트들 중 상기 제1 엘리먼트에 이웃하는, 상기 제2 깊이를 결정하고;상기 제2 깊이와 상기 제1 깊이 사이의 차이가 상기 임계 차이보다 크다고 결정하고;상기 제2 깊이와 상기 제1 깊이 사이의 차이가 상기 임계 차이보다 크다고 결정하는 것에 기초하여, 상기 제2 엘리먼트를 상기 제1 확장된 관심 영역으로부터 배제하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>19. 제9항 내지 제18항 중 어느 한 항에 있어서, 상기 제1 거리를 표현하는 상기 대표 깊이 정보를 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 제1 확장된 관심 영역과 연관된 상기 복수의 엘리먼트들의 깊이 값들에 기초하여 상기 제1 확장된 관심 영역에 대한 대표 깊이 값을 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 대표 깊이 값은 상기 제1 확장된 관심 영역과 연관된 상기 복수의 엘리먼트들의 깊이 값들의 평균을 포함하는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>21. 제9항 내지 제20항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서는,상기 제1 관심 영역이 상기 이미지에 대해 결정된 유일한 관심 영역인 것에 기초하여, 상기 제1 거리를 표현하는 상기 대표 깊이 정보에 기초하여 상기 이미지를 프로세싱하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 제1 거리를 표현하는 상기 대표 깊이 정보에 기초하여 상기 이미지를 프로세싱하기 위해, 상기 적어도 하나의 프로세서는, 적어도 상기 이미지의 상기 제1 관심 영역에 대해 자동 노출, 자동 포커스, 자동 화이트 밸런스 및 자동 줌 중 적어도 하나를 수행하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>23. 제9항 내지 제22항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서는,상기 이미지에 묘사된 제2 객체에 대응하는 제2 관심 영역을 결정하는 것으로서, 상기 제2 관심 영역은 상기 멀티-포인트 깊이 감지 시스템과 연관된 상기 멀티-포인트 그리드의 적어도 하나의 추가적인 엘리먼트와 연관되는, 상기 제2 관심 영역을 결정하고;상기 제2 객체에 대한 제2 확장된 관심 영역을 결정하는 것으로서, 상기 제2 확장된 관심 영역은 상기 멀티-포인트 그리드의 상기 적어도 하나의 추가적인 엘리먼트 및 제2 하나 이상의 추가적인 엘리먼트들을 포함하는 복수의 엘리먼트들과 연관되는, 상기 제2 확장된 관심 영역을 결정하고; 그리고상기 제2 확장된 관심 영역과 연관된 상기 복수의 엘리먼트들에 기초하여, 상기 적어도 하나의 카메라와 상기 이미지에 묘사된 상기 제2 객체 사이의 제2 거리를 표현하는 대표 깊이 정보를 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 적어도 하나의 프로세서는,상기 제1 거리를 표현하는 상기 대표 깊이 정보 및 상기 제2 거리를 표현하는 상기 대표 깊이 정보에 기초하여 조합된 깊이 정보를 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서, 상기 조합된 깊이 정보를 결정하기 위해, 상기 적어도 하나의 프로세서는, 상기 제1 거리를 표현하는 상기 대표 깊이 정보 및 상기 제2 거리를 표현하는 상기 대표 깊이 정보의 가중된 평균을 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>26. 제24항 또는 제25항에 있어서, 상기 적어도 하나의 프로세서는,상기 조합된 깊이 정보에 기초하여 상기 이미지를 프로세싱하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 조합된 깊이 정보에 기초하여 상기 이미지를 프로세싱하기 위해, 상기 적어도 하나의 프로세서는, 적어도 상기 이미지의 상기 제1 관심 영역에 대해 자동 노출, 자동 포커스, 자동 화이트 밸런스 및 자동 줌 중 적어도 하나를 수행하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>28. 제9항 내지 제27항 중 어느 한 항에 있어서, 상기 멀티-포인트 깊이 감지 시스템은 복수의 광원들을 포함하는 송신기 및 상기 복수의 광원들에 의해 방출된 광의 반사들을 수신하도록 구성된 수신기를 포함하고, 상기 대표 깊이 정보는 상기 광의 수신된 반사들에 기초하여 결정되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>29. 이미지 데이터를 프로세싱하는 방법으로서,적어도 하나의 카메라를 사용하여 획득된 이미지에 묘사된 적어도 하나의 객체에 대응하는 관심 영역을 결정하는 단계로서, 상기 관심 영역은 멀티-포인트 깊이 감지 시스템과 연관된 멀티-포인트 그리드의 복수의 엘리먼트들과 연관되는, 상기 관심 영역을 결정하는 단계;상기 복수의 엘리먼트들과 연관된 깊이 정보에 기초하여 상기 관심 영역이 멀티-깊이 정보를 포함하는지 여부를 결정하는 단계; 및상기 관심 영역이 멀티-깊이 정보를 포함하는지 여부에 기초하여, 상기 적어도 하나의 카메라와 상기 이미지에 묘사된 상기 적어도 하나의 객체 사이의 거리를 표현하는 대표 깊이 정보를 결정하는 단계를 포함하는, 이미지 데이터를 프로세싱하는 방법.</claim></claimInfo><claimInfo><claim>30. 이미지 데이터를 프로세싱하기 위한 장치로서,적어도 하나의 메모리; 및상기 적어도 하나의 메모리에 커플링된 적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 적어도 하나의 카메라를 사용하여 획득된 이미지에 묘사된 적어도 하나의 객체에 대응하는 관심 영역을 결정하는 것으로서, 상기 관심 영역은 멀티-포인트 깊이 감지 시스템과 연관된 멀티-포인트 그리드의 복수의 엘리먼트들과 연관되는, 상기 관심 영역을 결정하고; 상기 복수의 엘리먼트들과 연관된 깊이 정보에 기초하여 상기 관심 영역이 멀티-깊이 정보를 포함하는지 여부를 결정하고; 상기 관심 영역이 멀티-깊이 정보를 포함하는지 여부에 기초하여, 상기 적어도 하나의 카메라와 상기 이미지에 묘사된 상기 적어도 하나의 객체 사이의 거리를 표현하는 대표 깊이 정보를 결정하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서, 상기 적어도 하나의 프로세서는,상기 복수의 엘리먼트들과 연관된 상기 대표 깊이 정보에 따라 상기 복수의 엘리먼트들을 분류하도록 구성되고, 상기 복수의 엘리먼트들은 최소 깊이로부터 최대 깊이까지 분류되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>32. 제30항 또는 제31항에 있어서, 상기 관심 영역이 상기 멀티-깊이 정보를 포함하는지 여부를 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 복수의 엘리먼트들의 가장 작은 깊이 값과 상기 복수의 엘리먼트들의 가장 큰 깊이 값 사이의 차이가 멀티-깊이 임계치보다 크다고 결정하고;상기 가장 작은 깊이 값과 상기 가장 큰 깊이 값 사이의 차이가 상기 멀티-깊이 임계치보다 크다고 결정하는 것에 기초하여 상기 관심 영역이 멀티-깊이 정보를 포함한다고 결정하도록구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>33. 제30항 또는 제31항에 있어서, 상기 관심 영역이 상기 멀티-깊이 정보를 포함하는지 여부를 결정하기 위해, 상기 적어도 하나의 프로세서는,상기 복수의 엘리먼트들의 가장 작은 깊이 값과 상기 복수의 엘리먼트들의 가장 큰 깊이 값 사이의 차이가 멀티-깊이 임계치 미만이라고 결정하고;상기 가장 작은 깊이 값과 상기 가장 큰 깊이 값 사이의 차이가 상기 멀티-깊이 임계치 미만이라고 결정하는 것에 기초하여 상기 관심 영역이 멀티-깊이 정보를 포함하지 않는다고 결정하도록 구성되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>34. 제30항 내지 제33항 중 어느 한 항에 있어서, 상기 적어도 하나의 프로세서는,상기 거리를 표현하는 상기 대표 깊이 정보에 기초하여 상기 이미지를 프로세싱하도록 구성되고, 상기 이미지를 프로세싱하는 것은 적어도 상기 이미지의 상기 관심 영역에 대해 자동 노출, 자동 포커스, 자동 화이트 밸런스 및 자동 줌 중 적어도 하나를 수행하는 것을 포함하는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo><claimInfo><claim>35. 제30항 내지 제34항 중 어느 한 항에 있어서, 상기 멀티-포인트 깊이 감지 시스템은 복수의 광원들을 포함하는 송신기 및 상기 복수의 광원들에 의해 방출된 광의 반사들을 수신하도록 구성된 수신기를 포함하고, 상기 대표 깊이 정보는 상기 광의 수신된 반사들에 기초하여 결정되는, 이미지 데이터를 프로세싱하기 위한 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>FENG, WEN-CHUN</engName><name>펑 원-춘 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>LI, MIAN</engName><name>리 몐 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>KAO, HUI SHAN</engName><name>카오 후이 산 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.12.29</receiptDate><receiptNumber>1-1-2023-1479345-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.02.08</receiptDate><receiptNumber>1-5-2024-0025589-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.02.27</receiptDate><receiptNumber>1-1-2024-0224699-02</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.06.21</receiptDate><receiptNumber>1-1-2024-0673657-04</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.06.21</receiptDate><receiptNumber>1-1-2024-0673658-49</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237045512.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930ed22d8c8bba50f6b106b0d4bdaeb3f479590a2bdcdbe4ee6f51de1ace455bfc3dc41dfbe1fd5cdb005c5b5d2b198168dabd7980473de87e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe31374294b14df7b30622def449fd7bfda6c1e53a87dd301c047c76cce233abb42b56a37524130224283092439c031e18f69a34e617aae75</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>