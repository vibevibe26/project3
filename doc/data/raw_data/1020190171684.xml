<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:16:43.1643</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2019.12.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2019-0171684</applicationNumber><claimCount>16</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>음향 모델을 학습시키기 위한 인공 지능 장치</inventionTitle><inventionTitleEng>ARTIFICIAL INTELLIGENCE APPARATUS FOR TRAINING  ACOUSTIC MODEL</inventionTitleEng><openDate>2021.06.30</openDate><openNumber>10-2021-0079666</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.12.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/14</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 15/183</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/082</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0455</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0442</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 음향 모델을 학습시키기 위한 인공 지능 장치로서, 공유 네트워크 및 공유 네트워크와 연결된 브랜치 네트워크를 포함하는 음향 모델을 음성 데이터 및 음성 데이터에 대응하는 음소셋을 이용하여 학습시키는 인공 지능 장치를 개시한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 음성을 인식하는 인공 지능 장치에 있어서,사용자 발화에 상응하는 음성 데이터를 획득하는 입력부; 및상기 음성 데이터 및 상기 음성 데이터에 대응하는 음소셋(phonemes)을 이용하여, 공유 네트워크 및 상기 공유 네트워크와 연결된 브랜치 네트워크를 포함하는 음향 모델을 학습시키는 프로세서를 포함하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서상기 공유 네트워크는 학습시 사용된 복수의 음성 데이터의 공통된 음향 정보를 반영하여 은닉 표현(hidden representation)을 출력하고, 상기 은닉 표현(hidden representation)을 상기 브랜치 네트워크의 레이어(layer)로 전달하는 제1 인공 지능 모델을 포함하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 복수의 음성 데이터는 원어민 음성 데이터 또는 비원어민 음성 데이터를 포함하고,상기 프로세서는상기 원어민 음성 데이터가 수신되면 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 원어민 브랜치 네트워크를 학습시키고,상기 비원어민 음성 데이터가 수신되면, 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 비원어민 브랜치 네트워크를 학습시키는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 브랜치 네트워크는 상기 공유 네트워크의 레이어(layer)가 전달한 은닉 표현(hidden representation)에 기초하여 상기 음성 데이터에 대응하는 음소셋을 출력하는 제2 인공 지능 모델을 포함하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 프로세서는,상기 음성 데이터가 원어민이 발화한 음성 데이터인 경우, 원어민 음성 데이터 및 상기 원어민 음성 데이터에 대응하는 원어민 음소 셋을 이용하여 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 원어민 브랜치 네트워크를 학습시키는인공 지능 장치.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,상기 프로세서는,상기 음성 데이터가 비원어민이 발화한 음성 데이터인 경우, 비원어민 음성 데이터 및 상기 비원어민 음성 데이터에 대응하는 비원어민 음소셋(phonemes of a foreign language)을 이용하여, 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 비원어민 브랜치 네트워크를 학습시키는,인공 지능 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 입력부는 제2 음성 데이터를 수신하고,상기 프로세서는상기 학습에 따라 업데이트된 공유 네트워크 및 원어민 브랜치 네트워크를 포함하는 업데이트된 음향 모델에 상기 제2 음성 데이터를 입력하고, 상기 업데이트된 음향 모델이 출력한 원어민 음소셋을 이용하여 음성 인식을 수행하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 제2 음성 데이터는 비원어민 음성 데이터를 포함하고,상기 프로세서는상기 제2 음성 데이터를 상기 업데이트된 음향 모델에 입력하고, 상기 업데이트된 음향 모델이 출력한 원어민 음소셋을 이용하여 음성 인식을 수행하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 입력부는 원어민 또는 비원어민을 선택하는 사용자 입력을 수신하고,상기 프로세서는 상기 사용자의 선택에 기초하여 상기 공유 네트워크와 상기 사용자의 선택에 대응되는 브랜치 네트워크가 연결되도록 상기 업데이트된 음향 모델을 변경하고, 상기 제2 음성 데이터를 변경된 음향 모델에 입력하고,상기 변경된 음향 모델이 출력한 음소셋을 이용하여 음성 인식을 수행하는, 인공 지능 장치.</claim></claimInfo><claimInfo><claim>10. 음성을 인식하는 인공 지능 장치의 동작 방법에 있어서,사용자 발화에 상응하는 음성 데이터를 획득하는 단계; 및상기 음성 데이터 및 상기 음성 데이터에 대응하는 음소셋(phonemes)을 이용하여, 공유 네트워크 및 상기 공유 네트워크와 연결된 브랜치 네트워크를 포함하는 음향 모델을 학습시키는 단계를 포함하는, 인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서상기 음향 모델을 학습시키는 단계는,상기 공유 네트워크가 학습시 사용된 복수의 음성 데이터의 공통된 음향 정보를 반영하여 은닉 표현(hidden representation)을 출력하는 단계 및 상기 은닉 표현(hidden representation)을 상기 브랜치 네트워크의 레이어(layer)로 전달하는 단계를 포함하는,인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 복수의 음성 데이터는 원어민 음성 데이터 또는 비원어민 음성 데이터를 포함하고,상기 음향 모델을 학습시키는 단계는,상기 원어민 음성 데이터가 수신되면 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 원어민 브랜치 네트워크를 학습시키는 단계; 및상기 비원어민 음성 데이터가 수신되면, 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 비원어민 브랜치 네트워크를 학습시키는 단계를 포함하는,인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>13. 제10항에 있어서,음향 모델을 학습시키는 단계는상기 브랜치 네트워크가 상기 공유 네트워크의 레이어(layer)가 전달한 은닉 표현(hidden representation)에 기초하여 상기 음성 데이터에 대응하는 음소셋을 출력하는 단계를 포함하는, 인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>14. 제10항에 있어서,상기 음향 모델을 학습시키는 단계는,상기 음성 데이터가 원어민이 발화한 음성 데이터인 경우, 원어민 음성 데이터 및 상기 원어민 음성 데이터에 대응하는 원어민 음소 셋을 이용하여 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 원어민 브랜치 네트워크를 학습시키는 단계를 포함하는,인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>15. 제10 항에 있어서,상기 음향 모델을 학습시키는 단계는,상기 음성 데이터가 비원어민이 발화한 음성 데이터인 경우, 비원어민 음성 데이터 및 상기 비원어민 음성 데이터에 대응하는 비원어민 음소셋(phonemes of a foreign language)을 이용하여, 상기 공유 네트워크 및 상기 공유 네트워크와 연결된 비원어민 브랜치 네트워크를 학습시키는 단계를 포함하는,인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>16. 제10항에 있어서,상기 인공 지능 장치의 동작 방법은,제2 음성 데이터를 수신하는 단계; 상기 학습에 따라 업데이트된 공유 네트워크 및 원어민 브랜치 네트워크를 포함하는 업데이트된 음향 모델에 상기 제2 음성 데이터를 입력하는 단계; 및 상기 업데이트된 음향 모델이 출력한 원어민 음소셋을 이용하여 음성 인식을 수행하는 단계를 더 포함하는, 인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 음성 인식을 수행하는 단계는,상기 제2 음성 데이터가 비원어민이 발화한 음성 데이터인 경우, 상기 업데이트된 음향 모델이 출력한 원어민 음소셋을 이용하여 음성 인식을 수행하는 단계를 포함하는,인공 지능 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>18. 제16항에 있어서,원어민 또는 비원어민을 선택하는 사용자 입력을 수신하는 단계;상기 사용자의 선택에 기초하여 상기 공유 네트워크와 상기 사용자의 선택에 대응되는 브랜치 네트워크가 연결되도록 상기 업데이트된 음향 모델을 변경하는 단계를 더 포함하고,상기 제2 음성 데이터를 입력하는 단계는,상기 제2 음성 데이터를 변경된 음향 모델에 입력하는 단계를 포함하고,상기 음성 인식을 수행하는 단계는,상기 변경된 음향 모델이 출력한 음소셋을 이용하여 음성 인식을 수행하는 단계를 포함하는, 인공 지능 장치의 동작 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 영등포구...</address><code>120020128403</code><country>대한민국</country><engName>LG Electronics Inc.</engName><name>엘지전자 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>Jeehye Lee</engName><name>이지혜</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 *** 혜천빌딩 ***호(선영특허법률사무소)</address><code>919980006169</code><country>대한민국</country><engName>Haw, Yong Noke</engName><name>허용록</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2019.12.20</receiptDate><receiptNumber>1-1-2019-1320756-08</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Notification of change of applicant's information</documentEngName><documentName>출원인정보변경(경정)신고서</documentName><receiptDate>2020.05.28</receiptDate><receiptNumber>4-1-2020-5118228-40</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.12.09</receiptDate><receiptNumber>1-1-2022-1326469-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.07.21</receiptDate><receiptNumber>9-5-2025-0688867-17</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[거절이유 등 통지에 따른 의견]의견서·답변서·소명서</documentName><receiptDate>2025.10.13</receiptDate><receiptNumber>1-1-2025-1138464-08</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName> </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.10.13</receiptDate><receiptNumber>1-1-2025-1138465-43</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020190171684.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93965aeb7e7414abb3d3b07c927e9e7f2a1710555b5e248fdde881c79e80c441e801476f7afa4cba44b53fd3540effd0c1eaa2e56a13a06ca9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf8b07c42cde31248227c4957923890382c3746607374e45f1415c9616784e5094e01a68d6e7f019970fae536fe7f6df0abdd7d8f03714198d</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>