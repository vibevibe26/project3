<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:18.4118</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.02.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0021872</applicationNumber><claimCount>13</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다중 오브젝트 추적 방법 및 이를 수행하는 전자 장치</inventionTitle><inventionTitleEng>METHOD FOR TRACKING MULTIPLE OBJECTS AND ELECTRONIC DEVICE  PERFORMING THE SAME</inventionTitleEng><openDate>2025.08.22</openDate><openNumber>10-2025-0125713</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.08.21</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/74</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/94</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 전자 장치의 동작 방법은, 현재 시점의 프레임에서 적어도 하나의 오브젝트를 검출하는 동작을 포함할 수 있다. 상기 동작 방법은 뉴럴 네트워크 모델을 활용하여, 상기 검출된 적어도 하나의 오브젝트에 대한 정보, 상기 현재 시점보다 이전 시점의 프레임들에서 추적된 적어도 하나의 오브젝트에 대한 정보, 상기 프레임의 프레임 특징, 및 상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여, 상기 검출된 적어도 하나의 오브젝트와 상기 추적된 적어도 하나의 오브젝트 간의 매칭 결과를 획득하는 동작을 포함할 수 있다. 상기 동작 방법은 상기 매칭 결과에 기초하여, 상기 검출된 적어도 하나의 오브젝트의 상기 현재 시점까지의 궤적 정보를 획득하는 동작을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치의 동작 방법에 있어서,현재 시점의 프레임에서 적어도 하나의 오브젝트를 검출하는 동작;뉴럴 네트워크 모델을 활용하여, 상기 검출된 적어도 하나의 오브젝트에 대한 정보, 상기 현재 시점보다 이전 시점의 프레임들에서 추적된 적어도 하나의 오브젝트에 대한 정보, 상기 프레임의 프레임 특징, 및 상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여, 상기 검출된 적어도 하나의 오브젝트와 상기 추적된 적어도 하나의 오브젝트 간의 매칭 결과를 획득하는 동작; 및상기 매칭 결과에 기초하여, 상기 검출된 적어도 하나의 오브젝트의 상기 현재 시점까지의 궤적 정보를 획득하는 동작을 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 뉴럴 네트워크 모델은,상기 프레임 특징 및 상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여, 상기 현재 시점의 오브젝트-인식 프레임 특징을 출력하는 트랜스포머;상기 현재 시점의 오브젝트-인식 프레임 특징 및 상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여, 상기 검출된 적어도 하나의 오브젝트의 ReID(Re-identification) 특징을 출력하는 ReID 임베딩 모듈;상기 현재 시점의 오브젝트-인식 프레임 특징 및 상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여, 상기 추적된 적어도 하나의 오브젝트 각각에 대한 상기 현재 시점의 추정 위치에 대한 정보를 포함하는 히트맵을 출력하는 모션 추정 모듈; 및상기 추적된 적어도 하나의 오브젝트에 대한 정보, 상기 검출된 적어도 하나의 오브젝트에 대한 정보, 상기 ReID 특징, 및 상기 히트맵에 기초하여, 상기 검출된 적어도 하나의 오브젝트와 상기 추적된 적어도 하나의 오브젝트를 매칭하는 매칭 모듈을 포함하는, 전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 트랜스포머는,상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여 제1 특징 매트릭스들을 획득하고,상기 프레임 특징에 기초하여 제2 특징 매트릭스를 획득하고,상기 제1 특징 매트릭스들, 상기 제2 특징 매트릭스, 및 상기 프레임 특징에 기초하여, 상기 현재 시점의 오브젝트-인식 프레임 특징을 출력하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 트랜스포머는,상기 이전 시점의 오브젝트-인식 프레임 특징 상의 상기 추적된 적어도 하나의 오브젝트에 대해 관심 영역 정렬(ROI Align)을 수행함으로써, 제1 오브젝트 특징을 획득하고,상기 제1 오브젝트 특징에 기초하여 상기 제1 특징 매트릭스들을 획득하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 트랜스포머는,크로스 어텐션 레이어에 기초하여, 상기 제1 특징 매트릭스들 및 상기 제2 특징 매트릭스로부터 융합된 오브젝트 특징을 획득하고,상기 융합된 오브젝트 특징 및 상기 프레임 특징에 기초하여, 상기 현재 시점의 오브젝트-인식 프레임 특징을 출력하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>6. 제2항에 있어서,상기 ReID 임베딩 모듈은,상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여 제1 특징 매트릭스들을 획득하고,상기 현재 시점의 오브젝트-인식 프레임 특징에 기초하여 제3 특징 매트릭스를 획득하고,상기 제1 특징 매트릭스들 및 상기 제3 특징 매트릭스에 기초하여, 상기 검출된 적어도 하나의 오브젝트의 상기 ReID 특징을 출력하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 ReID 임베딩 모듈은,상기 현재 시점의 오브젝트-인식 프레임 특징 상의 상기 검출된 적어도 하나의 오브젝트에 대해 관심 영역 정렬(ROI Align)을 수행함으로써, 제2 오브젝트 특징을 획득하고,상기 제2 오브젝트 특징에 기초하여 상기 제3 특징 매트릭스를 획득하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>8. 제2항에 있어서,상기 모션 추정 모듈은,상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여, 제3 오브젝트 특징을 획득하고,상기 현재 시점의 오브젝트-인식 프레임 특징에 기초하여, 제4 오브젝트 특징을 획득하고,상기 제3 오브젝트 특징 및 상기 제4 오브젝트 특징에 기초하여, 상기 히트맵을 출력하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 모션 추정 모듈은,상기 현재 시점의 오브젝트-인식 프레임 특징 상의 검색 영역에 대해 관심 영역 정렬(ROI Align)을 수행함으로써 상기 제4 오브젝트 특징을 획득하고,상기 검색 영역은,상기 검출된 적어도 하나의 오브젝트의 바운딩 박스의 스케일을 조정한 것인,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>10. 제2항에 있어서,상기 매칭 모듈은, 상기 ReID 특징에 기초하여, 상기 추적된 적어도 하나의 오브젝트와 상기 검출된 적어도 하나의 오브젝트 간의 제1 유사도를 계산하고,상기 히트맵에 포함된 상기 추적된 적어도 하나의 오브젝트 각각에 대한 상기 현재 시점의 추정 위치에 대한 정보에 기초하여, 상기 추적된 적어도 하나의 오브젝트와 상기 검출된 적어도 하나의 오브젝트 간의 제2 유사도를 계산하고,상기 제1 유사도 및 상기 제2 유사도의 가중합에 기초하여, 상기 매칭 결과를 출력하는,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 제1 유사도는,상기 현재 시점의 ReID 특징과 상기 이전 시점의 ReID 특징 간의, 양방향 소프트맥스 유사도 및 코사인 유사도에 기초한 것인,전자 장치의 동작 방법.</claim></claimInfo><claimInfo><claim>12. 하드웨어와 결합되어 제1항 내지 제11항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 전자 장치에 있어서,프로세서; 및인스트럭션들을 저장하는 메모리를 포함하고,상기 인스트럭션들은 상기 프로세서에 의해 실행될 때 상기 전자 장치로 하여금,현재 시점의 프레임에서 적어도 하나의 오브젝트를 검출하고,뉴럴 네트워크 모델을 활용하여, 상기 검출된 적어도 하나의 오브젝트에 대한 정보, 상기 현재 시점보다 이전 시점의 프레임들에서 추적된 적어도 하나의 오브젝트에 대한 정보, 상기 프레임의 프레임 특징, 및 상기 이전 시점의 오브젝트-인식 프레임 특징에 기초하여, 상기 검출된 적어도 하나의 오브젝트와 상기 추적된 적어도 하나의 오브젝트 간의 매칭 결과를 획득하고,상기 매칭 결과에 기초하여, 상기 검출된 적어도 하나의 오브젝트의 상기 현재 시점까지의 궤적 정보를 획득하도록 하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 강남구...</address><code>120190323502</code><country>대한민국</country><engName>42dot Inc.</engName><name>포티투닷 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>JEONG Seong Gyun</engName><name>정성균</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.02.15</receiptDate><receiptNumber>1-1-2024-0177237-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.08.21</receiptDate><receiptNumber>1-1-2024-0913696-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2024.09.10</receiptDate><receiptNumber>1-1-2024-0993940-37</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240021872.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d0d5d272aeaf525ab0198569efeed3102873e281149700b2652aee1dd429d12fe0316cb246d80fbda989a9a06b69305dc3d5c454c0d47ad1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfcb0f3c0a19724e933a971f3c1e825310e2d0746c481e2f505098afbd8608f2f407e4640110b6d03edcc4b562de76a47492538c2248607e69</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>