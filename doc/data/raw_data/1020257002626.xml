<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:29:54.2954</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7002626</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>뉴럴 래디언스 필드를 이용한 배경 대체</inventionTitle><inventionTitleEng>BACKGROUND REPLACEMENT USING NEURAL RADIANCE FIELD</inventionTitleEng><openDate>2025.02.28</openDate><openNumber>10-2025-0028436</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.01.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.01.23</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/32</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 51/046</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 5/265</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 5/272</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 가상 경험들을 제공하기 위한 시스템을 수반한다. 시스템은 사람을 묘사하는 이미지 및 이미지를 캡처하기 위해 사용되는 카메라와 연관된 관점을 나타내는 하나 이상의 카메라 파라미터에 액세스한다. 시스템은 사람의 묘사를 포함하는 이미지의 부분을 추출한다. 시스템은, NeRF(neural radiance field) 머신 러닝 모델에 의해, 이미지를 캡처하기 위해 사용되는 카메라와 연관된 관점으로부터 장면의 추정된 묘사를 렌더링하도록 하나 이상의 카메라 파라미터를 처리한다. 시스템은 사람의 묘사를 포함하는 이미지의 부분을 장면의 추정된 묘사와 조합하여 출력 이미지를 생성하고 출력 이미지가 클라이언트 디바이스 상에 제시되게 한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.01.04</internationOpenDate><internationOpenNumber>WO2024006275</internationOpenNumber><internationalApplicationDate>2023.06.27</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/026341</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,하나 이상의 프로세서에 의해, 사람을 묘사하는 이미지 및 이미지를 캡처하기 위해 사용되는 카메라와 연관된 관점을 표현하는 하나 이상의 카메라 파라미터에 액세스하는 단계;상기 사람의 묘사를 포함하는 상기 이미지의 부분을 추출하는 단계;NeRF(neural radiance field) 머신 러닝 모델에 의해, 상기 이미지를 캡처하기 위해 사용되는 상기 카메라와 연관된 관점으로부터 장면의 추정된 묘사를 렌더링하도록 상기 하나 이상의 카메라 파라미터를 처리하는 단계;상기 사람의 묘사를 포함하는 상기 이미지의 부분을 상기 장면의 추정된 묘사와 조합하여 출력 이미지를 생성하는 단계; 및상기 출력 이미지가 클라이언트 디바이스 상에 제시되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 이미지는 상기 클라이언트 디바이스 상에 구현된 메시징 애플리케이션에 의해 액세스되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 사람을 묘사하는 이미지 및 상기 장면의 추정된 묘사를 재조명 머신 러닝 모델에 의해 처리하여 상기 출력 이미지의 조명 속성들을 조정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 재조명 머신 러닝 모델에 기초하여 상기 이미지의 추출된 부분의 조명 속성들의 세트를 조정하여 상기 장면의 추정된 묘사의 조명 속성들과 일치시키는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 추가로, 상기 재조명 머신 러닝 모델은 동작들을 수행하는 것에 의해 훈련되고, 상기 동작들은 복수의 훈련 이미지 쌍들 및 상기 복수의 훈련 이미지 쌍들에 대응하는 실측 정보 이미지들을 포함하는 훈련 데이터를 수신하는 동작- 상기 복수의 훈련 이미지 쌍들 내의 각각의 쌍은 제1 세트의 조명 조건 하에서 캡처된 하나 이상의 훈련 객체를 묘사하는 제1 이미지 및 제2 세트의 조명 조건 하에서 캡처된 훈련 장면을 묘사하는 제2 이미지를 포함함 -; 상기 복수의 훈련 이미지 쌍들 중 제1 훈련 이미지 쌍에 상기 재조명 머신 러닝 모델을 적용하여 상기 복수의 훈련 이미지 쌍들 중 상기 제2 이미지의 상기 제2 세트의 조명 조건들과 일치시키기 위한 상기 제1 훈련 이미지 쌍의 상기 제1 이미지의 조명 속성들에 대한 조정을 추정하는 동작;상기 조명 속성들에 대한 상기 추정된 조정에 기초하여 상기 제1 훈련 이미지 쌍의 상기 제1 이미지의 하나 이상의 조명 속성을 수정하여 조명 조정된 제1 훈련 이미지를 생성하는 동작; 상기 조명 조정된 제1 훈련 이미지와 상기 제1 훈련 이미지 쌍과 연관된 상기 실측 정보 이미지 사이의 편차를 계산하는 동작; 및 상기 계산된 편차에 기초하여 상기 재조명 머신 러닝 모델의 파라미터들을 업데이트하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 제1 훈련 이미지 쌍 및 상기 제1 훈련 이미지 쌍에 대응하는 대응하는 실측 정보 이미지를 생성하는 단계를 더 포함하고, 이 단계는 상기 제2 세트의 조명 조건들 하에서 상기 하나 이상의 훈련 객체 중의 객체를 묘사하는 훈련 이미지를 캡처하는 단계; 상기 훈련 이미지로부터 상기 제2 세트의 조명 조건 하에서 상기 객체의 묘사를 추출하는 단계; 상기 제1 세트의 조명 조건들을 사용하여, 상기 객체의 추출된 묘사의 조명 속성들을 인위적으로 수정하여 상기 제1 훈련 이미지 쌍의 상기 제1 이미지를 생성하는 단계; 상기 훈련 이미지로부터 상기 객체의 묘사를 제거함으로써 상기 제2 이미지를 생성하는 단계; 및 상기 제2 세트의 조명 조건들 하에서의 상기 객체의 묘사를 상기 제1 훈련 이미지 쌍에 대응하는 실측 정보 이미지로서 저장하는 단계에 의해 이루어지는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 하나 이상의 카메라 파라미터는 가속도계 측정, 자이로스코프 측정, 또는 높이 중 적어도 하나를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,복수의 장면들로부터 상기 장면을 선택하는 입력을 수신하는 단계- 상기 복수의 장면들 각각은 각각의 NeRF 머신 러닝 모델과 연관됨 -; 및상기 입력의 수신에 응답하여 상기 장면과 연관된 상기 NeRF 머신 러닝 모델에 액세스하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 이미지의 부분을 추출하는 단계는 객체 검출 머신 러닝 모델로 상기 사람을 묘사하는 이미지를 처리하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 객체 검출 머신 러닝 모델에 의해 출력된 값들은 상기 이미지에 묘사된 상기 사람의 픽셀 좌표들에 대응하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 카메라로부터 실시간 비디오 피드를 수신하는 단계를 더 포함하고, 상기 이미지는 상기 실시간 비디오 피드로부터 액세스되는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서,상기 이미지를 캡처하기 위해 사용되는 카메라 위치와 상기 NeRF 머신 러닝 모델과 연관된 디폴트 높이 파라미터 사이의 차이에 기초하여 상기 이미지를 정규화하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 사람의 묘사를 포함하는 이미지의 부분을 상기 장면의 추정된 묘사와 조합하는 단계는 상기 사람의 묘사를 포함하는 상기 이미지의 상기 부분을 상기 장면의 상기 추정된 묘사와 연결시키는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 상기 NeRF 머신 러닝 모델은 동작들을 수행하는 것에 의해 훈련되고, 상기 동작들은상기 장면을 포함하는 현실 세계 환경의 상이한 투영들을 묘사하는 실측 정보 이미지들을 포함하는 훈련 데이터를 수신하는 동작;훈련 관점과 연관된 카메라 파라미터들의 훈련 세트를 생성하는 동작;상기 NeRF 머신 러닝 모델에 의해, 상기 훈련 관점으로부터 상기 현실 세계 환경의 추정된 묘사를 렌더링하도록 상기 카메라 파라미터들의 훈련 세트를 처리하는 동작;상기 훈련 관점과 연관된 상기 실측 정보 이미지에 액세스하는 동작;상기 훈련 관점으로부터의 상기 현실 세계 환경의 상기 추정된 묘사와 상기 훈련 관점과 연관된 상기 실측 정보 이미지 사이의 편차를 계산하는 동작; 및상기 계산된 편차에 기초하여 상기 NeRF 머신 러닝 모델의 파라미터들을 업데이트하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 사람을 실시간으로 묘사하는 후속하여 수신된 이미지에서의 관점에 대한 변경들에 기초하여 상기 출력 이미지에 묘사된, 상기 NeRF 머신 러닝 모델에 의해 생성된, 배경을 업데이트하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 시스템으로서,동작들을 수행하도록 구성된 프로세서를 포함하고, 상기 동작들은 사람을 묘사하는 이미지 및 이미지를 캡처하기 위해 사용되는 카메라와 연관된 관점을 표현하는 하나 이상의 카메라 파라미터에 액세스하는 동작; 상기 사람의 묘사를 포함하는 상기 이미지의 부분을 추출하는 동작; NeRF(neural radiance field) 머신 러닝 모델에 의해, 상기 이미지를 캡처하기 위해 사용되는 상기 카메라와 연관된 관점으로부터 장면의 추정된 묘사를 렌더링하도록 상기 하나 이상의 카메라 파라미터를 처리하는 동작; 상기 사람의 묘사를 포함하는 상기 이미지의 상기 부분을 상기 장면의 추정된 묘사와 조합하여 출력 이미지를 생성하는 동작; 및 상기 출력 이미지가 클라이언트 디바이스 상에 제시되게 하는 동작을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 이미지는 상기 클라이언트 디바이스 상에 구현된 메시징 애플리케이션에 의해 액세스되는, 시스템.</claim></claimInfo><claimInfo><claim>18. 제16항 내지 제17항 중 어느 한 항에 있어서, 상기 동작들은상기 사람을 묘사하는 이미지 및 상기 장면의 추정된 묘사를 재조명 머신 러닝 모델에 의해 처리하여 상기 출력 이미지의 조명 속성들을 조정하는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 동작들은상기 재조명 머신 러닝 모델에 기초하여 상기 이미지의 추출된 부분의 조명 속성들의 세트를 조정하여 상기 장면의 추정된 묘사의 조명 속성들과 일치시키는 동작을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>20. 명령어들을 포함하는 비일시적 머신 판독가능 저장 매체로서, 상기 명령어들은, 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 하고, 상기 동작들은 사람을 묘사하는 이미지 및 이미지를 캡처하기 위해 사용되는 카메라와 연관된 관점을 표현하는 하나 이상의 카메라 파라미터에 액세스하는 동작; 상기 사람의 묘사를 포함하는 상기 이미지의 부분을 추출하는 동작; NeRF(neural radiance field) 머신 러닝 모델에 의해, 상기 이미지를 캡처하기 위해 사용되는 상기 카메라와 연관된 관점으로부터 장면의 추정된 묘사를 렌더링하도록 상기 하나 이상의 카메라 파라미터를 처리하는 동작; 상기 사람의 묘사를 포함하는 상기 이미지의 상기 부분을 상기 장면의 추정된 묘사와 조합하여 출력 이미지를 생성하는 동작; 및 상기 출력 이미지가 클라이언트 디바이스 상에 제시되게 하는 동작을 포함하는, 비일시적 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>이스라엘</country><engName>ASSOULINE, Avihay</engName><name>아술린, 아비하이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>이스라엘</country><engName>BERGER, Itamar</engName><name>버거, 이타마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>이스라엘</country><engName>DUDOVITCH, Gal</engName><name>두도비치, 갈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>이스라엘</country><engName>MISHIN SHUVI, Ma'ayan</engName><name>미신 슈비, 마아얀</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.06.29</priorityApplicationDate><priorityApplicationNumber>17/852,919</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.01.23</receiptDate><receiptNumber>1-1-2025-0093614-37</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.01.23</receiptDate><receiptNumber>1-1-2025-0096094-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.02.03</receiptDate><receiptNumber>1-5-2025-0017965-70</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257002626.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9311487273ec768278367f2b3b9b97f09f2e3b4fe032418245a3f0484d49a110046f90672678585c275278863d71384fd63ade049140a45edd</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf3ad4c6fb2b259ee804e8c0db3483dbb75bb963d257f1e54254c55afdc8dc8ddb76d4ba294543a136dc2e6b731e4c816db2e36adfd81ab6fe</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>