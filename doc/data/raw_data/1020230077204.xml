<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:10.5110</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.06.16</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0077204</applicationNumber><claimCount>15</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법, 이를 수행하는 장치 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>Anomaly recognition method using vision transformer  attention with multi-reservoir echo state network,  apparatus and computer program for performing the  method</inventionTitleEng><openDate>2024.12.24</openDate><openNumber>10-2024-0176509</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.06.16</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명의 바람직한 실시예에 따른 비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법, 이를 수행하는 장치 및 컴퓨터 프로그램은, 비전 트랜스포머 어텐션(vision transformer attention)과 멀티-리저보이어 에코 스테이트 네트워크(multi-reservoir echo state network)를 이용하여 감시 영상에서 이상을 감지하고 인식함으로써, 감시 영상에서 이상을 인식하는 정확도를 향상시킬 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 감시 영상을 획득하는 단계;미리 학습되어 구축된 이상 감지 모델을 이용하여 상기 감시 영상을 기반으로 이상 이벤트를 감지하는 단계; 및미리 학습되어 구축된 이상 인식 모델을 이용하여 상기 이상 이벤트에 대응되는 클래스를 인식하는 단계;를 포함하는 비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에서,상기 이상 이벤트 감지 단계는,원-클래스(one-class) 심층 신경망을 포함하는 상기 이상 감지 모델을 이용하여 상기 감시 영상에서 상기 이상 이벤트를 감지하는 것으로 이루어지는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에서,상기 이상 감지 모델은,기하학적 중앙값(geometric median)을 기반으로 하는 필터 가지치기(filter pruning)를 이용하여 크기가 압축된 모델인,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에서,상기 클래스 인식 단계는,비전 트랜스포머 어텐션(vision transformer attention)과 멀티-리저보이어 에코 스테이트 네트워크(multi-reservoir echo state network)를 포함하는 상기 이상 인식 모델을 이용하여 상기 이상 이벤트에 대응되는 클래스를 인식하는 것으로 이루어지는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에서,상기 클래스 인식 단계는,상기 감시 영상에서 상기 비전 트랜스포머 어텐션을 통해 비전 트랜스포머 특징을 획득하고, 상기 비전 트랜스포머 특징을 기반으로 병목 어텐션(bottleneck attention) 메커니즘을 이용하여 정제된 특징을 획득하며, 상기 정제된 특징을 기반으로 상기 멀티-리저보이어 에코 스테이트 네트워크를 통해 상기 이상 이벤트에 대응되는 클래스를 인식하는 것으로 이루어지는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에서,상기 이상 인식 모델은,멀티 헤드 셀프 어텐션 블록(multi-head self-attention block)과 완전 연결된 피드 포워드 고밀도 블록(fully connected feed-forward dense block)을 포함하고 상기 감시 영상에서 상기 비전 트랜스포머 특징을 획득하는 트랜스포머 인코더(transformer encoder) 모듈, 상기 비전 트랜스포머 특징을 기반으로 상기 정제된 특징을 획득하는 병목 어텐션 모듈(bottleneck attention module, BAM), 및 상기 정제된 특징을 기반으로 상기 이상 이벤트에 대응되는 클래스를 인식하는 상기 멀티-리저보이어 에코 스테이트 네트워크를 포함하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에서,상기 멀티 헤드 셀프 어텐션 블록은,선형(linear) 레이어, 셀프-어텐션(self-attention) 레이어, 연결(concatenation) 레이어, 및 최종 선형(final linear) 레이어를 포함하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 기재된 비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 방법을 컴퓨터에서 실행시키기 위하여 컴퓨터 판독 가능한 저장 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>9. 비전 트랜스포머 어텐션(vision transformer attention)과 멀티-리저보이어 에코 스테이트 네트워크(multi-reservoir echo state network)를 이용하여 감시 영상에서 이상을 감지하고 인식하기 위한 하나 이상의 프로그램을 저장하는 메모리; 및상기 메모리에 저장된 상기 하나 이상의 프로그램에 따라 상기 감시 영상에서 이상을 감지하고 인식하기 위한 동작을 수행하는 하나 이상의 프로세서;를 포함하며,상기 프로세서는,감시 영상을 획득하고,미리 학습되어 구축된 이상 감지 모델을 이용하여 상기 감시 영상을 기반으로 이상 이벤트를 감지하며,미리 학습되어 구축된 이상 인식 모델을 이용하여 상기 이상 이벤트에 대응되는 클래스를 인식하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에서,상기 프로세서는,원-클래스(one-class) 심층 신경망을 포함하는 상기 이상 감지 모델을 이용하여 상기 감시 영상에서 상기 이상 이벤트를 감지하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 장치.</claim></claimInfo><claimInfo><claim>11. 제10항에서,상기 이상 감지 모델은,기하학적 중앙값(geometric median)을 기반으로 하는 필터 가지치기(filter pruning)를 이용하여 크기가 압축된 모델인,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 장치.</claim></claimInfo><claimInfo><claim>12. 제10항에서,상기 프로세서는,상기 비전 트랜스포머 어텐션과 상기 멀티-리저보이어 에코 스테이트 네트워크를 포함하는 상기 이상 인식 모델을 이용하여 상기 이상 이벤트에 대응되는 클래스를 인식하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에서,상기 프로세서는,상기 감시 영상에서 상기 비전 트랜스포머 어텐션을 통해 비전 트랜스포머 특징을 획득하고, 상기 비전 트랜스포머 특징을 기반으로 병목 어텐션(bottleneck attention) 메커니즘을 이용하여 정제된 특징을 획득하며, 상기 정제된 특징을 기반으로 상기 멀티-리저보이어 에코 스테이트 네트워크를 통해 상기 이상 이벤트에 대응되는 클래스를 인식하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에서,상기 이상 인식 모델은,멀티 헤드 셀프 어텐션 블록(multi-head self-attention block)과 완전 연결된 피드 포워드 고밀도 블록(fully connected feed-forward dense block)을 포함하고 상기 감시 영상에서 상기 비전 트랜스포머 특징을 획득하는 트랜스포머 인코더(transformer encoder) 모듈, 상기 비전 트랜스포머 특징을 기반으로 상기 정제된 특징을 획득하는 병목 어텐션 모듈(bottleneck attention module, BAM), 및 상기 정제된 특징을 기반으로 상기 이상 이벤트에 대응되는 클래스를 인식하는 상기 멀티-리저보이어 에코 스테이트 네트워크를 포함하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에서,상기 멀티 헤드 셀프 어텐션 블록은,선형(linear) 레이어, 셀프-어텐션(self-attention) 레이어, 연결(concatenation) 레이어, 및 최종 선형(final linear) 레이어를 포함하는,비전 트랜스포머 어텐션과 멀티-리저보이어 에코 스테이트 네트워크를 이용한 이상 인식 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 광진구 능동로 *** (군...</address><code>220050114702</code><country>대한민국</country><engName>INDUSTRY ACADEMY COOPERATION FOUNDATION OF SEJONG UNIVERSITY</engName><name>세종대학교산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>Baik, Sung Wook</engName><name>백성욱</name></inventorInfo><inventorInfo><address>서울특별시 강남구...</address><code> </code><country> </country><engName>Lee, Mi Young</engName><name>이미영</name></inventorInfo><inventorInfo><address>서울특별시 광진구...</address><code> </code><country> </country><engName>Waseem Ullah</engName><name>와심 울라</name></inventorInfo><inventorInfo><address>서울특별시 광진구...</address><code> </code><country> </country><engName>Samee Ullah Khan</engName><name>사미 울라 칸</name></inventorInfo><inventorInfo><address>서울특별시 광진구...</address><code> </code><country> </country><engName>Kim, Min Je</engName><name>김민제</name></inventorInfo><inventorInfo><address>경기도 안산시 단원구...</address><code> </code><country> </country><engName>Lee, Su Min</engName><name>이수민</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서대문구 경기대로 **,  진양빌딩 *층(충정로*가)</address><code>920191001412</code><country>대한민국</country><engName>WeThePeople IP &amp; Law Firm</engName><name>특허법인위더피플</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.06.16</receiptDate><receiptNumber>1-1-2023-0662038-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.24</receiptDate><receiptNumber>9-5-2025-1033065-56</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230077204.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9330c74598a2c8757e268dfae945e2ec6d02fe977514e9cdbf9c30150bbaf35f97d5d4251872540ba2aff4ae6e35c70270c946d34f0571ed30</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf052faa187564542d83008c9f297b01bd3fac60e114501e612a0eea34168c49c94e26731922b4db9379637c76b28c78dc89cfedc49ec798e2</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>