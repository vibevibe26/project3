<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:37:23.3723</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.30</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0146704</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>속성-객체 식별 장치 및 방법</inventionTitle><inventionTitleEng>Apparatus and Method for Identifying Attribute and  Object</inventionTitleEng><openDate>2025.05.08</openDate><openNumber>10-2025-0062118</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 이미지를 백본 네트워크를 통해 신경망 연산하여 획득되는 객체 임베딩 벡터를 가이드로 이용하여, 객체 임베딩 벡터를 획득하는 과정에서 추출된 다수의 중간 특징맵을 강조하고, 강조된 다수의 중간 특징맵을 기반으로 객체 문맥을 고려한 속성 임베딩 벡터를 생성하며, 객체 임베딩 벡터와 속성 임베딩 벡터를 결합하고 임베딩하여 속성-객체 특징 벡터를 획득하여, 이미지에서 학습되지 않은 조합의 속성-객체를 정확하게 식별할 수 있는 속성-객체 식별 장치 및 방법을 제공한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 메모리; 및 상기 메모리에 저장된 프로그램에 따른 동작의 적어도 일부를 실행하는 프로세서를 포함하는 장치로서, 상기 프로세서는 이미지를 백본 네트워크를 통해 신경망 연산하여 획득되는 객체 임베딩 벡터를 가이드로 이용하여, 상기 객체 임베딩 벡터를 획득하는 과정에서 추출된 다수의 중간 특징맵을 강조하고, 강조된 다수의 중간 특징맵을 기반으로 객체 문맥을 고려한 속성 임베딩 벡터를 생성하며, 상기 객체 임베딩 벡터와 상기 속성 임베딩 벡터를 결합하고 임베딩하여 속성-객체 특징 벡터를 획득하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 프로세서는 각각 신경망 연산을 수행하는 다수의 연산 레이어를 포함하는 백본 네트워크를 이용하여 이미지에서 특징맵을 추출하고, 상기 백본 네트워크의 최종 연산 레이어에서 출력되는 최종 특징맵을 인코딩하여 객체 임베딩 벡터를 획득하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 프로세서는 상기 객체 임베딩 벡터를 가이드로 이용하여 상기 백본 네트워크의 다수의 중간 연산 레이어에서 추출된 다수의 중간 특징맵을 강조하고 인코딩하여 속성 임베딩 벡터를 생성하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 프로세서는 상기 다수의 중간 특징맵 각각과 상기 객체 임베딩 벡터를 동일한 크기로 스케일링 및 결합하여 다수의 결합 특징맵을 획득하고, 상기 다수의 결합 특징맵 각각에 대해 풀링 및 신경망 연산하여 다수의 속성 강조맵을 획득하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 프로세서는 상기 다수의 속성 강조맵을 대응하는 상기 중간 특징맵에 가중하고, 다시 상기 중간 특징맵에 가산하여 다수의 속성 특징맵을 획득하고, 상기 다수의 속성 특징맵을 결합 및 인코딩하여 상기 속성 임베딩 벡터를 획득하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서, 상기 프로세서는 상기 다수의 결합 특징맵 각각을 2차원 공간축 방향 및 채널축 방향에서 각각 평균값 풀링하고, 신경망 연산하여 채널 강조맵 및 공간 강조맵을 획득하고, 상기 채널 강조맵과 공간 강조맵을 곱하여 상기 속성 강조맵을 획득하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 프로세서는 다수의 후보 속성 워드와 다수의 후보 객체 워드 각각을 벡터로 변환하고, 변환된 벡터를 다수의 조합으로 결합한 후 임베딩하여 다수의 속성-객체 워드 벡터를 획득하며, 상기 다수의 속성-객체 워드 벡터 각각과 상기 속성-객체 특징 벡터 사이의 유사도를 기반으로 속성 워드와 객체 워드의 조합을 식별하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 프로세서는 미리 획득된 다수의 후보 속성 워드와 다수의 후보 객체 워드를 각각 신경망 연산하여 다수의 속성 워드 벡터와 다수의 객체 워드 벡터를 획득하고, 상기 다수의 속성 워드 벡터와 상기 다수의 객체 워드 벡터를 가능한 모든 조합에 따라 결합하여, 각 조합에 따라 결합된 속성 워드 벡터와 객체 워드 벡터를 인코딩하여 상기 다수의 속성-객체 워드 벡터를 획득하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서, 상기 프로세서는 상기 속성-객체 특징 벡터와 상기 다수의 속성-객체 워드 벡터 각각 사이의 유사도를 계산하고, 계산된 유사도가 가장 높은 속성-객체 워드 벡터를 판별하며, 상기 다수의 후보 속성 워드와 상기 다수의 후보 객체 워드 중 판별된 속성-객체 워드 벡터에 따른 속성 워드와 객체 워드를 조합하여 출력하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 프로세서는 상기 속성-객체 특징 벡터와 상기 다수의 속성-객체 워드 벡터 각각 사이의 유사도와 함께 상기 속성-객체 워드 벡터에 따른 상기 속성 워드 벡터 및 상기 객체 워드 벡터 각각과 속성 임베딩 벡터 및 상기 객체 임베딩 벡터 각각 사이의 유사도를 함께 계산하여 합산하고, 합산된 유사도가 가장 높은 속성-객체 워드 벡터를 판별하며, 상기 다수의 후보 속성 워드와 상기다수의 후보 객체 워드 중 판별된 속성-객체 워드 벡터에 따른 속성 워드와 객체 워드를 조합하여 출력하는 속성-객체 식별 장치.</claim></claimInfo><claimInfo><claim>11. 프로세서에 의해 수행되는 방법으로서, 이미지를 백본 네트워크를 통해 신경망 연산하여 획득되는 객체 임베딩 벡터를 가이드로 이용하여, 상기 객체 임베딩 벡터를 획득하는 과정에서 추출된 다수의 중간 특징맵을 강조하는 단계; 강조된 다수의 중간 특징맵을 기반으로 객체 문맥을 고려한 속성 임베딩 벡터를 생성하는 단계; 및 상기 객체 임베딩 벡터와 상기 속성 임베딩 벡터를 결합하고 임베딩하여 속성-객체 특징 벡터를 획득하는 단계를 포함하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 중간 특징맵을 강조하는 단계는 각각 신경망 연산을 수행하는 다수의 연산 레이어를 포함하는 백본 네트워크를 이용하여 이미지에서 특징맵을 추출하고, 상기 백본 네트워크의 최종 연산 레이어에서 출력되는 최종 특징맵을 인코딩하여 객체 임베딩 벡터를 획득하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 중간 특징맵을 강조하는 단계는 상기 객체 임베딩 벡터를 가이드로 이용하여 상기 백본 네트워크의 다수의 중간 연산 레이어에서 추출된 다수의 중간 특징맵을 강조하고 인코딩하여 속성 임베딩 벡터를 생성하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 중간 특징맵을 강조하는 단계는 상기 다수의 중간 특징맵 각각과 상기 객체 임베딩 벡터를 동일한 크기로 스케일링 및 결합하여 다수의 결합 특징맵을 획득하고, 상기 다수의 결합 특징맵 각각에 대해 풀링 및 신경망 연산하여 다수의 속성 강조맵을 획득하며, 상기 다수의 속성 강조맵을 대응하는 상기 중간 특징맵에 가중하고, 다시 상기 중간 특징맵에 가산하여 다수의 속성 특징맵을 획득하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 중간 특징맵을 강조하는 단계는 상기 다수의 결합 특징맵 각각을 2차원 공간축 방향 및 채널축 방향에서 각각 평균값 풀링하고, 신경망 연산하여 채널 강조맵 및 공간 강조맵을 획득하고, 상기 채널 강조맵과 공간 강조맵을 곱하여 상기 속성 강조맵을 획득하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서, 상기 속성 임베딩 벡터를 생성하는 단계는 상기 다수의 속성 특징맵을 결합 및 인코딩하여 상기 속성 임베딩 벡터를 획득하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 속성-객체 식별 방법은 다수의 후보 속성 워드와 다수의 후보 객체 워드 각각을 벡터로 변환하고, 변환된 벡터를 다수의 조합으로 결합한 후 임베딩하여 다수의 속성-객체 워드 벡터를 획득하는 단계; 및 상기 다수의 속성-객체 워드 벡터 각각과 상기 속성-객체 특징 벡터 사이의 유사도를 기반으로 속성 워드와 객체 워드의 조합을 식별하는 단계를 더 포함하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 속성-객체 워드 벡터를 획득하는 단계는 미리 획득된 다수의 후보 속성 워드와 다수의 후보 객체 워드를 각각 신경망 연산하여 다수의 속성 워드 벡터와 다수의 객체 워드 벡터를 획득하고, 상기 다수의 속성 워드 벡터와 상기 다수의 객체 워드 벡터를 가능한 모든 조합에 따라 결합하여, 각 조합에 따라 결합된 속성 워드 벡터와 객체 워드 벡터를 인코딩하여 상기 다수의 속성-객체 워드 벡터를 획득하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>19. 제17항에 있어서, 상기 식별하는 단계는 상기 속성-객체 특징 벡터와 상기 다수의 속성-객체 워드 벡터 각각 사이의 유사도를 계산하고, 계산된 유사도가 가장 높은 속성-객체 워드 벡터를 판별하며, 상기 다수의 후보 속성 워드와 상기 다수의 후보 객체 워드 중 판별된 속성-객체 워드 벡터에 따른 속성 워드와 객체 워드를 조합하여 출력하는 속성-객체 식별 방법.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서, 상기 식별하는 단계는 상기 속성-객체 특징 벡터와 상기 다수의 속성-객체 워드 벡터 각각 사이의 유사도와 함께 상기 속성-객체 워드 벡터에 따른 상기 속성 워드 벡터 및 상기 객체 워드 벡터 각각과 속성 임베딩 벡터 및 상기 객체 임베딩 벡터 각각 사이의 유사도를 함께 계산하여 합산하고, 합산된 유사도가 가장 높은 속성-객체 워드 벡터를 판별하며, 상기 다수의 후보 속성 워드와 상기다수의 후보 객체 워드 중 판별된 속성-객체 워드 벡터에 따른 속성 워드와 객체 워드를 조합하여 출력하는 속성-객체 식별 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 서대문구...</address><code>220050095099</code><country>대한민국</country><engName>UIF (University Industry Foundation), Yonsei University</engName><name>연세대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>SOHN, Kwang Hoon</engName><name>손광훈</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>KIM, Han Jae</engName><name>김한재</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 남부순환로 **** (도곡동, 차우빌딩) *층(맥스국제특허법률사무소)</address><code>920010001018</code><country>대한민국</country><engName>MIN YOUNG JOON</engName><name>민영준</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.30</receiptDate><receiptNumber>1-1-2023-1192491-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230146704.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93036444d076c976119a1e75cee10acf7efda9c7df655f5e5c38c812a13af508e2be7e48adcf08c0f19856039849865d6616f007b00805a15b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf79c7f827b03b71df533052fe73ce8c3c103e17ee0c8ddd94f79b2241436f913cefd101d83025c4500bb6defc3dd00f3775f9b4cd2493ca36</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>