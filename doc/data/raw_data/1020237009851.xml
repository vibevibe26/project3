<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:43.4043</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.09.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7009851</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>에너지 효율적인 딥 러닝을 위한 동적 양자화</inventionTitle><inventionTitleEng>DYNAMIC QUANTIZATION FOR ENERGY EFFICIENT DEEP LEARNING</inventionTitleEng><openDate>2023.06.02</openDate><openNumber>10-2023-0078655</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.12</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.03.22</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/082</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/063</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/2413</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/21</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 딥 신경망 (deep neural network; DNN) 에 의해 수행되는 방법은 추론 스테이지 동안 DNN 의 계층에서, DNN 에서 수신된 DNN 입력과 연관된 컨텐츠를 포함하는 계층 입력을 수신하는 단계를 포함한다. 본 방법은 또한, 계층 입력의 컨텐츠에 기초하여 계층과 연관된 복수의 파라미터들 중 하나 이상의 파라미터들을 양자화하는 단계를 포함한다. 본 방법은 DNN 입력에 대응하는 태스크를 수행하는 단계를 더 포함하고, 태스크는 하나 이상의 양자화된 파라미터들로 수행된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.04.07</internationOpenDate><internationOpenNumber>WO2022072547</internationOpenNumber><internationalApplicationDate>2021.09.29</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/052721</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 딥 신경망 (DNN; deep neural network) 에 의해 수행되는 방법으로서,추론 스테이지 동안 상기 DNN 의 계층에서, 상기 DNN 에서 수신된 DNN 입력과 연관된 컨텐츠를 포함하는 계층 입력을 수신하는 단계;상기 계층 입력의 상기 컨텐츠에 기초하여 상기 계층과 연관된 복수의 파라미터들 중 하나 이상의 파라미터들을 양자화하는 단계; 및상기 DNN 입력에 대응하는 태스크를 수행하는 단계로서, 상기 태스크는 하나 이상의 양자화된 파라미터들로 수행되는, 상기 태스크를 수행하는 단계를 포함하는, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 복수의 파라미터들은 가중치들의 세트 및 활성화들의 세트를 포함하는, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 상기 하나 이상의 파라미터들을 양자화하는 단계는 상기 계층과 연관된 하나 이상의 출력 채널들의 활성화들의 개별적인 세트 또는 가중치들의 개별적인 세트 중 일방 또는 양방을 양자화하는 단계를 포함하는, 딥 신경망에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>4. 제 1 항에 있어서, 상기 복수의 파라미터들 중 제 1 파라미터의 제 1 양자화 양은 상기 복수의 파라미터들 중 제 2 파라미터의 제 2 양자화 양과 상이한, 딥 신경망에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서, 상기 하나 이상의 파라미터들을 양자화하는 단계는 상기 하나 이상의 파라미터들과 연관된 원래 비트-폭의 사이즈를 조정하는 것에 의해 조정된 비트-폭을 생성하는 단계를 포함하는, 딥 신경망에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서, 상기 조정된 비트-폭을 생성하는 단계는 원래 비트-폭의 사이즈가 상기 계층 입력의 컨텐츠에 기초하여 결정된 상기 조정된 비트-폭의 사이즈와 동일할 때까지 최하위 비트들로부터 최상위 비트들까지 원래 비트-폭의 비트들을 폐기하는 단계를 포함하는, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>7. 제 6 항에 있어서, 총 손실에 기초하여 원래 비트-폭을 조정하기 위한 사이즈를 결정하도록 DNN 을 트레이닝하는 단계를 더 포함하며, 총 손실은 성능 손실 및 정규화 손실의 함수인, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>8. 제 7 항에 있어서, 상기 성능 손실은 크로스-엔트로피 손실 (mean-squared error) 또는 평균 제곱 오차 (mean-squared error) 를 결정하는, 딥 신경망에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>9. 제 8 항에 있어서,상기 정규화 손실은: 비트-레벨 동작과 연관된 조정된 비트-폭 및 복잡도 메트릭; 또는 조정된 비트-폭에 할당된 비트들의 수중 하나에 패널티를 부과하는 비트와이즈 L0 정규화 손실인, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서,상기 복잡도 메트릭은 DNN 의 다수의 이진 동작들, DNN의 메모리 풋프린트, 또는 DNN의 컴퓨터 파워 중 하나 이상을 포함하는, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>11. 제 9 항에 있어서,Bernoulli 분포로서 비트와이즈 L0 정규화 손실을 재공식화하는 단계;시그모이드 함수에 기초하여 재공식화된 비트와이즈 L0 재정규화 손실을 완화하는 단계; 및조정된 비트-폭에 대하여 선택된 비트들의 수에 기초하여 성능 손실 및 정규화된 손실을 최소화하는 단계를 더 포함하는, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>12. 제 1 항에 있어서, 상기 계층은 상기 DNN 의 복수의 계층들 중 하나의 계층이고, 상기 방법은 개별적인 계층 입력의 컨텐츠에 기초하여 상기 복수의 계층들의 각각의 계층의 개별적인 복수의 파라미터들의 하나 이상의 파라미터들을 양자화하는 단계를 더 포함하는, 딥 신경망에 의해 수행되는 방법.</claim></claimInfo><claimInfo><claim>13. 제 12 항에 있어서, 양자화 양은 상기 복수의 계층들의 각각의 계층에 대해 상이한, 딥 신경망에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>14. 딥 신경망 (DNN; deep neural network) 을 구현하기 위한 장치로서,프로세서; 및 상기 프로세서와 커플링된 메모리; 및상기 메모리에 저장된 명령들을 포함하고, 상기 명령들은, 상기 프로세서에 의해 실행될 때, 상기 장치로 하여금:추론 스테이지 동안 상기 DNN 의 계층에서, 상기 DNN 에서 수신된 DNN 입력과 연관된 컨텐츠를 포함하는 계층 입력을 수신하게 하고;상기 계층 입력의 상기 컨텐츠에 기초하여 상기 계층과 연관된 복수의 파라미터들 중 하나 이상의 파라미터들을 양자화하게 하고; 그리고상기 DNN 입력에 대응하는 태스크를 수행하게 하는 것으로서, 상기 태스크는 하나 이상의 양자화된 파라미터들로 수행되는, 상기 태스크를 수행하게 하도록 동작가능한, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서, 상기 복수의 파라미터들은 가중치들의 세트 및 활성화들의 세트를 포함하는, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서, 상기 명령들은 상기 장치로 하여금 또한, 상기 계층과 연관된 하나 이상의 출력 채널들의 활성화들의 개별적인 세트 또는 가중치들의 개별적인 세트 중 일방 또는 양방을 양자화하는 것에 의해 상기 하나 이상의 파라미터들을 양자화하게 하는, 딥 신경망을 구현하기 위한 장치.</claim></claimInfo><claimInfo><claim>17. 제 14 항에 있어서, 상기 복수의 파라미터들 중 제 1 파라미터의 제 1 양자화 양은 상기 복수의 파라미터들 중 제 2 파라미터의 제 2 양자화 양과 상이한, 딥 신경망을 구현하기 위한 장치.</claim></claimInfo><claimInfo><claim>18. 제 14 항에 있어서,상기 명령들은 상기 장치로 하여금 또한, 상기 하나 이상의 파라미터들과 연관된 원래 비트-폭의 사이즈를 조정하는 것에 의해 조정된 비트-폭을 생성하는 것에 의해 상기 하나 이상의 파라미터들을 양자화하게 하는, 딥 신경망을 구현하기 위한 장치.</claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서, 상기 명령들은 상기 장치로 하여금 또한, 원래 비트-폭의 사이즈가 상기 계층 입력의 컨텐츠에 기초하여 결정된 상기 조정된 비트-폭의 사이즈와 동일할 때까지 최하위 비트들로부터 최상위 비트들까지 원래 비트-폭의 비트들을 폐기하는 것에 의해 상기 조정된 비트-폭을 생성하게 하는, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>20. 제 19 항에 있어서, 상기 명령들은 상기 장치로 하여금 또한, 트레이닝 스테이지 동안, 총 손실에 기초하여 원래 비트-폭을 조정하기 위한 사이즈를 결정하게 하며, 상기 총 손실은 성능 손실 및 정규화 손실의 함수인, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서,상기 정규화 손실은: 비트-레벨 동작과 연관된 조정된 비트-폭 및 복잡도 메트릭; 또는 조정된 비트-폭에 할당된 비트들의 수중 하나에 패널티를 부과하는 비트와이즈 L0 정규화 손실인, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>22. 제 21 항에 있어서,상기 복잡도 메트릭은 DNN 의 다수의 이진 동작들, DNN의 메모리 풋프린트, 또는 DNN 의 컴퓨터 파워 중 하나 이상을 포함하는, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>23. 제 21 항에 있어서, 상기 명령들은 또한 상기 DNN 으로 하여금:Bernoulli 분포로서 비트와이즈 L0 정규화 손실을 재공식화하게 하고;시그모이드 함수에 기초하여 재공식화된 비트와이즈 L0 재정규화 손실을 완화하게 하고; 그리고조정된 비트-폭에 대하여 선택된 비트들의 수에 기초하여 성능 손실 및 정규화된 손실을 최소화하게 하는, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>24. 제 14 항에 있어서,상기 계층은 상기 DNN 의 복수의 계층들 중 하나의 계층이고, 상기 명령들은 또한 상기 DNN 으로 하여금, 개별적인 계층 입력의 컨텐츠에 기초하여 상기 복수의 계층들의 각각의 계층의 개별적인 복수의 파라미터들의 하나 이상의 파라미터들을 양자화하게 하는, 딥 신경망을 구현하기 위한 장치.</claim></claimInfo><claimInfo><claim>25. 제 24 항에 있어서, 양자화 양은 복수의 계층들의 각각의 계층에 대해 상이한, 딥 신경망을 구현하기 위한 장치. </claim></claimInfo><claimInfo><claim>26. 딥 신경망 (DNN; deep neural network) 을 위한 프로그램 코드가 기록된 비일시적 컴퓨터 판독가능 저장 매체로서, 상기 프로그램 코드는 프로세서에 의해 실행되고,추론 스테이지 동안 상기 DNN 의 계층에서, 상기 DNN 에서 수신된 DNN 입력과 연관된 컨텐츠를 포함하는 계층 입력을 수신하는 프로그램 코드;상기 계층 입력의 상기 컨텐츠에 기초하여 상기 계층과 연관된 복수의 파라미터들 중 하나 이상의 파라미터들을 양자화하는 프로그램 코드; 및상기 DNN 입력에 대응하는 태스크를 수행하는 프로그램 코드로서, 상기 태스크는 하나 이상의 양자화된 파라미터들로 수행되는, 상기 태스크를 수행하는 프로그램 코드를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체. </claim></claimInfo><claimInfo><claim>27. 제 26 항에 있어서, 상기 복수의 파라미터들은 가중치들의 세트 및 활성화들의 세트를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체. </claim></claimInfo><claimInfo><claim>28. 제 27 항에 있어서, 상기 하나 이상의 파라미터들을 양자화하는 프로그램 코드는 상기 계층과 연관된 하나 이상의 출력 채널들의 활성화들의 개별적인 세트 또는 가중치들의 개별적인 세트 중 일방 또는 양방을 양자화하는 프로그램 코드를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>29. 딥 신경망 (DNN; deep neural network) 을 구현하는 장치로서,추론 스테이지 동안 상기 DNN 의 계층에서, 상기 DNN 에서 수신된 DNN 입력과 연관된 컨텐츠를 포함하는 계층 입력을 수신하기 위한 수단;상기 계층 입력의 상기 컨텐츠에 기초하여 상기 계층과 연관된 복수의 파라미터들 중 하나 이상의 파라미터들을 양자화하기 위한 수단; 및상기 DNN 입력에 대응하는 태스크를 수행하기 위한 수단으로서, 상기 태스크는 하나 이상의 양자화된 파라미터들로 수행되는, 상기 태스크를 수행하기 위한 수단을 포함하는, 딥 신경망을 구현하는 장치. </claim></claimInfo><claimInfo><claim>30. 제 29 항에 있어서, 상기 하나 이상의 파라미터들을 양자화하기 위한 수단은 상기 계층과 연관된 하나 이상의 출력 채널들의 활성화들의 개별적인 세트 또는 가중치들의 개별적인 세트 중 일방 또는 양방을 양자화하기 위한 수단을 포함하는, 딥 신경망을 구현하는 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>ARDYWIBOWO, RANDY</engName><name>아르디위보워 랜디 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>DAYANA, VENKATA RAVI KIRAN</engName><name>다야나 벤카타 라비 키란</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>HWANG, HAU</engName><name>황 하우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.09.29</priorityApplicationDate><priorityApplicationNumber>63/084,902</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.09.28</priorityApplicationDate><priorityApplicationNumber>17/488,261</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.03.22</receiptDate><receiptNumber>1-1-2023-0323906-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.05.03</receiptDate><receiptNumber>1-5-2023-0071693-32</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.09.12</receiptDate><receiptNumber>1-1-2024-1007302-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2024.09.12</receiptDate><receiptNumber>1-1-2024-1007303-93</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237009851.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c936def61e395fd88b113a93a48d9d7d2ed2f2a23d7c2b43032be3ab05d815c431885783ce757779d44ce9a10e792e356d0ced27f122184f3ad</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe72a049bb82bb232d9f1cdd80616df416712ae9708d051d1b0769ba5f697247127a7f6822a4f5be63e8a316fca0696f7e29cd34e26f73551</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>