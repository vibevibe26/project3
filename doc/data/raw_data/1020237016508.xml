<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:14.214</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.10.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7016508</applicationNumber><claimCount>26</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인공 지능을 사용한 자동 초점 및 자동화 세포 계수를 위한 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEMS AND METHODS FOR AUTOFOCUS AND AUTOMATED CELL COUNT USING ARTIFICIAL INTELLIGENCE</inventionTitleEng><openDate>2023.09.18</openDate><openNumber>10-2023-0132764</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.05.15</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>G02B 7/38</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G01N 15/1434</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 21/24</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 21/36</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/69</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G01N 15/14</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G01N 15/1434</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G01N 15/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G01N 15/14</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 인공 지능을 사용한 자동 초점을 위한 시스템 및 방법은 (i) 공칭 초점 범위에 걸쳐 복수의 단색 이미지를 캡처하는 단계, (ii) 각 단색 이미지 내에서 하나 이상의 연결형 구성요소를 식별하는 단계, (iii) 식별된 연결형 구성요소를 각 연결형 구성요소와 연관된 다수의 픽셀에 기초하여 정렬하는 단계, (iv) 기계 학습 모듈을 사용하여 정렬된 연결형 구성요소의 적어도 일부의 초점 품질 추정치를 생성하는 단계, 및 (iv) 평가된 연결형 구성요소의 초점 품질 추정치에 기초하여 목표 초점 위치를 계산하는 단계를 포함한다. 계산된 목표 초점 위치는, 예를 들어 (i) 합성곱 신경망의 출력에 기초하여 시드 우도 이미지 및 전체 세포 우도 이미지를 생성하고 (ii) 시드 우도 이미지에 기초하여 객체의 마스크 표시 수량 및/또는 픽셀 위치를 생성함으로써, 인공 지능을 사용하여 세포 계수를 수행하는 데 사용될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.04.21</internationOpenDate><internationOpenNumber>WO2022081863</internationOpenNumber><internationalApplicationDate>2021.10.14</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/055008</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 자동 초점 방법으로서,선택적으로 이미징 시스템에서 샘플 홀더를 수용하는 단계;선택적으로 상기 샘플 홀더에 적어도 부분적으로 기초하여 공칭 초점 범위에 대한 z축 단계 크기를 자동으로 결정하는 단계;상기 공칭 초점 범위에 걸쳐 복수의 이미지를 수신하는 단계;상기 복수의 이미지에 기초하여 입력 데이터를 생성하는 단계로서, 상기 입력 데이터는 하나 이상의 이미지 처리 작업을 통해 생성되는, 단계;하나 이상의 공칭 초점 범위와 연관된 이미지로부터 생성된 입력에 응답하여 목표 초점 위치 출력을 제공하도록 구성된 기계 학습 모듈에 대한 입력으로서 상기 입력 데이터를 이용하는 단계;상기 기계 학습 모듈의 출력에 기초하여 목표 초점 위치를 획득하는 단계; 및상기 목표 초점 위치를 사용하여 이미지를 캡처하도록 상기 이미징 시스템을 구성하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 이미지 처리 작업은 연결형 구성요소 분석을 포함하고, 상기 입력 데이터는 하나 이상의 연결형 구성요소를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,각 이미지 내에서 하나 이상의 연결형 구성요소를 식별하는 단계;각 연결형 구성요소와 연관된 픽셀의 수에 기초하여 상기 식별된 연결형 구성요소들을 정렬하는 단계;상기 기계 학습 모듈을 사용하여 상기 정렬된 연결형 구성요소의 적어도 일부의 초점 품질 추정치를 생성하는 단계; 및상기 정렬된 연결형 구성요소의 초점 품질 추정치에 기초하여 목표 초점 위치를 식별하는 단계;를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 복수의 이미지를 캡처하는 단계는 상기 공칭 초점 범위에 걸쳐 각각의 z축 단계에서 1280 x 960 8비트 이미지를 캡처하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 각 z축 단계는 상기 이미징 시스템에서 검출된 샘플 홀더에 기초하여 자동으로 결정된 소정 크기를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제3항 또는 제4항에 있어서, 각 이미지에서 하나 이상의 연결형 구성요소를 식별하는 단계는,각 이미지를 임계화하여 각 이미지에 대한 결과적인 바이너리 이미지를 획득하는 단계;상기 결과적인 바이너리 이미지에 하나 이상의 형태학적 연산자를 적용하는 단계; 및상기 결과적인 바이너리 이미지 내에서 하나 이상의 연결형 구성요소를 정의하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 임계화는 상기 공칭 초점 범위에 대한 최소 이미지와 최대 이미지 사이의 차이에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서, 상기 하나 이상의 형태학적 연산자를 적용하는 단계는 형태학적 폐쇄, 형태학적 개방, 및/또는 전경 홀 채우기 중 하나 이상을 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 형태학적 폐쇄는 2×2 형태학적 폐쇄를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제8항 또는 제9항에 있어서, 상기 형태학적 개구는 2×2 형태학적 개구를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제8항 내지 제10항 중 어느 한 항에 있어서, 상기 전경 홀 채우기는 8-연결 전경 홀 채우기를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제6항 내지 제11항 중 어느 한 항에 있어서, 각 이미지에서 하나 이상의 연결형 구성요소를 식별하는 단계는,각 연결형 구성요소의 제1 및 제2 바이너리 모멘트를 측정하는 단계;등가 모멘트를 갖는 대응하는 타원을 각 연결형 구성요소에 적합시키는 단계; 및상기 대응하는 타원을 포함하는 제2 바이너리 이미지를 생성하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제2 바이너리 이미지에서 각 연결형 구성요소를 측정하는 단계 및 10 μm 미만, 바람직하게는 7 μm 미만, 더 바람직하게는 5 μm 미만의 타원 단축을 갖는 임의의 연결형 구성요소를 제거하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제3항 내지 제13항 중 어느 한 항에 있어서, 상기 식별된 하나 이상의 연결형 구성요소들을 정렬하는 단계는,각 연결형 구성요소의 픽셀 수를 계수하는 단계;상기 하나 이상의 연결형 구성요소에 대한 중앙 픽셀 카운트를 계산하는 단계; 및상기 중앙 픽셀 카운트로부터 픽셀 수의 대응하는 절대 차이에 기초하여 상기 하나 이상의 연결형 구성요소들을 정렬하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 하나 이상의 연결형 구성요소는 상기 중앙 픽셀 카운트로부터 상기 픽셀 수의 대응하는 절대 차이에 의해 오름차순으로 정렬되는, 방법.</claim></claimInfo><claimInfo><claim>16. 제3항 내지 제15항 중 어느 한 항에 있어서, 상기 식별된 하나 이상의 연결형 구성요소들을 정렬하는 단계는,각 연결형 구성요소의 원형도 또는 밝기 중 하나 이상을 결정하는 단계; 및상기 연결형 구성요소 각각에 대해 결정된 비교 원형도 및/또는 밝기에 기초하여 상기 하나 이상의 연결형 구성요소들을 정렬하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 제3항 내지 제16항 중 어느 한 항에 있어서, 각 연결형 구성요소에 대한 32 x 32-픽셀 z-스택을 형성하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 제3항 내지 제17항 중 어느 한 항에 있어서, 상기 기계 학습 모듈은 각 연결형 구성요소에 대한 상기 32 x 32-픽셀 z-스택을 입력으로 수신하는 인공 신경망을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 인공 신경망은 합성곱 계층, 선형 계층, 및 최대 풀링 계층의 디자인 패턴을 갖는 복수의 피처 식별 계층을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 합성곱 계층은 3x3 합성곱 계층을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제19항에 있어서, 상기 선형 계층은 ReLu 비선형성 함수를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제19항 내지 제21항 중 어느 한 항에 있어서, 상기 최대 풀링 계층은 2×2 최대 풀링 계층을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제19항 내지 제22항 중 어느 한 항에 있어서, 상기 인공 신경망은 상기 복수의 피처 식별 계층 뒤에 장단기 메모리(LSTM) 프로세스 계층을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 LSTM 계층은 양방향 방식으로 각 연결형 구성요소에 대한 상기 z-스택을 처리하는, 방법.</claim></claimInfo><claimInfo><claim>25. 제23항 또는 제24항에 있어서, 상기 인공 신경망은 최종 선형 계층을 포함하고, 상기 최종 선형 계층은 상기 초점 품질 추정치를 정의하기 위해 상기 LSTM 계층의 출력과 조합되는, 방법.</claim></claimInfo><claimInfo><claim>26. 이미지 자동 초점 방법으로서,이미징 시스템에서 샘플 홀더를 수용하는 단계;상기 샘플 홀더에 적어도 부분적으로 기초하여 공칭 초점 범위에 대한 z축 단계 크기를 자동으로 결정하는 단계;상기 공칭 초점 범위에 걸쳐 복수의 이미지를 수신하는 단계;목표 초점 위치를 획득하는 단계; 및상기 목표 초점 위치를 사용하여 이미지를 캡처하도록 상기 이미징 시스템을 구성하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>27. 이미징 시스템을 자동 초점화하도록 구성된 컴퓨터 시스템으로서, 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의해 실행될 때 상기 컴퓨터 시스템을, 제1항 내지 제26항 중 어느 한 항의 방법을 수행하도록 구성하는 컴퓨터 실행 가능 명령어가 저장된 하나 이상의 하드웨어 저장 장치;를 포함하는, 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>28. 이미징 시스템의 하나 이상의 처리 장치에 의해 실행 가능한 명령어로서, 상기 이미징 시스템을, 제1항 내지 제26항 중 어느 한 항의 방법을 수행하도록 구성하는 명령어를 저장하는 하나 이상의 하드웨어 저장 장치.</claim></claimInfo><claimInfo><claim>29. 자동화 세포 생존도 계수를 수행하는 방법으로서,목표 초점 위치에서 이미지를 캡처하는 단계로서, 상기 목표 초점 위치는 제1항 내지 제26항 중 어느 한 항에서와 같이 계산되는, 단계;상기 캡처된 이미지를 공간적으로 다운샘플링하여 다운샘플링된 이미지를 형성하는 단계;상기 다운샘플링된 이미지를 복수의 타일로 분해하는 단계;상기 복수의 타일을 텐서 어레이에 저장하는 단계;합성곱 신경망을 사용하여 상기 텐서 어레이를 처리하는 단계;상기 합성곱 신경망의 출력에 기초하여 복수의 의사 확률 맵을 구성하는 단계;상기 복수의 의사 확률 맵을 임계화하여 이진화된 위치 맵 및 이진화된 마스크 맵을 생성하는 단계;시딩을 위한 상기 이진화된 위치 맵 및 세포 영역을 한정하기 위한 상기 이진화된 마스크 맵을 사용하여 상기 다운샘플링된 이미지를 분할함으로써 분할된 다운샘플링된 이미지를 생성하는 단계로서, 상기 분할된 다운샘플링된 이미지는 세포 생존도 카운트를 나타내고/제공하는, 단계; 및상기 세포 생존도 카운트의 표현을 표시하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서, 상기 합성곱 신경망은, 바람직하게는 -2에서 +2까지의 z-위치 범위인, 상기 초점 위치에 대한 다수의 초점면으로부터의 이미지로 훈련되는, 방법.</claim></claimInfo><claimInfo><claim>31. 제29항에 있어서, 상기 이미지는 픽셀 크기가 0.871 μm인 2592 x 1944 8비트 이미지를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>32. 제29항 또는 제30항에 있어서, 상기 캡처된 이미지를 공간적으로 다운샘플링하는 단계는 상기 캡처된 이미지를 픽셀 데시메이션을 통해 2배로 다운샘플링하여 선택적으로 1296 x 972 다운샘플링된 이미지를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>33. 제29항 내지 제32항 중 어느 한 항에 있어서, 상기 다운샘플링된 이미지를 복수의 타일로 분해하는 단계는,상기 다운샘플링된 이미지를 그의 가장자리가 복수의 픽셀만큼 확장되도록 반사하여, 반사된 이미지를 형성하는 단계; 및상기 반사된 이미지를 픽셀 중첩이 있는 상기 복수의 타일로 분해하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서, 상기 다운샘플링된 이미지를 반사하는 단계는 그 이미지의 가장자리를 4-12개 픽셀, 또는 6-10개 픽셀, 또는 약 8개 픽셀만큼 확장하는, 방법.</claim></claimInfo><claimInfo><claim>35. 제33항 또는 제34항에 있어서, 상기 반사된 이미지는 80-190개 타일, 또는 90-180개 타일, 또는 100-170개 타일, 또는 110-160개 타일, 또는 120-150개 타일, 또는 약 130개 타일로 분해되고, 선택적으로 픽셀 중첩이 있는 128 x 128 픽셀 크기를 갖는, 방법.</claim></claimInfo><claimInfo><claim>36. 제33항 내지 제35항 중 어느 한 항에 있어서, 상기 텐서 어레이는 130 x 1 x 128 x 128 텐서 어레이를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>37. 제29항 내지 제36항 중 어느 한 항에 있어서, 상기 합성곱 신경망은 U-net 합성곱 신경망을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>38. 제29항 내지 제37항 중 어느 한 항에 있어서, 상기 합성곱 신경망의 출력은 130 x 4 x 128 x 128 텐서 어레이에 저장되는, 방법.</claim></claimInfo><claimInfo><claim>39. 제29항 내지 제38항 중 어느 한 항에 있어서, 상기 복수의 의사 확률 맵을 구성하는 단계는 상기 합성곱 신경망의 출력을 8비트 형식 텐서로 변환하고 상기 8비트 형식 텐서를 이미지 스티칭하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>40. 제39항에 있어서, 상기 출력을 상기 8비트 형식 텐서로 변환하는 단계는 상기 130 x 4 x 128 x 128 텐서 어레이에 승수를 곱하는 단계를 포함하며, 선택적으로 상기 승수는 약 255인, 방법.</claim></claimInfo><claimInfo><claim>41. 제39항 또는 제40항에 있어서, 상기 8비트 형식 텐서를 이미지 스티칭하는 단계는 상기 텐서 어레이로부터 4개의 전체 크기 의사 확률 맵을 구성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>42. 제41항에 있어서, 상기 합성곱 신경망의 출력은 (i) 생세포의 위치, (ii) 생세포의 마스크, (iii) 사세포의 위치, 및 (iv) 사세포의 마스크와 연관된 의사 확률 맵을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>43. 제29항 내지 제42항 중 어느 한 항에 있어서, 임계화는 50%보다 큰 임계 값을 90% 의사 확률 또는 약 75% 의사 확률에 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>44. 제29항 내지 제42항 중 어느 한 항에 있어서, 상기 다운샘플링된 이미지는 생세포/사세포의 각각의 위치로부터 계산되고 상기 생세포/사세포의 각각의 마스크에 의해 한정되는 거리 맵에 적용된 유역 변환에 의해 분할되는, 방법.</claim></claimInfo><claimInfo><claim>45. 제29항 내지 제44항 중 어느 한 항에 있어서, 상기 분할된 다운샘플링된 이미지 내의 세포를 타원 적합하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>46. 제45항에 있어서, 타원 적합은 제6항 내지 제13항 중 어느 한 항에서와 같이 하나 이상의 객체 식별을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>47. 제46항에 있어서, 타원 적합은 객체 크기 측정, 객체 크기의 히스토그램 구성, 픽셀 강도, 및 객체 원형도 계산을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>48. 자동화 세포 생존도 계수를 수행하도록 구성된 컴퓨터 시스템으로서, 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의해 실행될 때 상기 컴퓨터 시스템을, 제29항 내지 제47항 중 어느 한 항의 방법을 수행하도록 구성하는 컴퓨터 실행 가능 명령어가 저장된 하나 이상의 하드웨어 저장 장치;를 포함하는, 컴퓨터 시스템.</claim></claimInfo><claimInfo><claim>49. 자동화 세포 계수를 수행하는 방법으로서,이미지를 획득하는 단계;상기 이미지에 기초하여 하나 이상의 타일 세트를 정의하는 단계;합성곱 신경망을 사용하여 상기 하나 이상의 타일을 처리하는 단계;상기 합성곱 신경망의 출력에 기초하여 복수의 의사 확률 맵을 생성하는 단계로서, 상기 복수의 의사 확률 맵은 적어도 하나 이상의 시드 우도 이미지를 포함하는, 단계; 및상기 하나 이상의 시드 우도 이미지에 기초하여 하나 이상의 마스크를 생성하는 단계;를 포함하고, 상기 하나 이상의 마스크는 상기 하나 이상의 시드 우도 이미지에 표현된 하나 이상의 객체에 대한 픽셀 위치를 정의하고, 상기 하나 이상의 마스크는 세포 카운트를 나타내고/제공하는, 방법.</claim></claimInfo><claimInfo><claim>50. 제49항에 있어서, 상기 세포 카운트를 결정하기 위해 연결형 구성요소 분석을 상기 하나 이상의 시드 우도 이미지에 대해 수행하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>51. 제49항 또는 제50항에 있어서,상기 복수의 의사 확률 맵은 하나 이상의 전체 세포 우도 이미지를 더 포함하고,상기 방법은 적어도 상기 하나 이상의 전체 세포 우도 이미지 및 상기 하나 이상의 마스크에 기초하여 하나 이상의 분할된 이미지를 생성하는 단계를 더 포함하며, 상기 하나 이상의 분할된 이미지는 세포 카운트를 나타내고/제공하는, 방법.</claim></claimInfo><claimInfo><claim>52. 제49항 내지 제51항 중 어느 한 항에 있어서, 상기 이미지는 목표 초점 위치에서 캡처되고, 상기 목표 초점 위치는 제1항 내지 제25항 중 어느 한 항에서와 같이 계산되는, 방법.</claim></claimInfo><claimInfo><claim>53. 제49항 내지 제52항 중 어느 한 항에 있어서, 상기 합성곱 신경망은, 바람직하게는 -2에서 +2까지의 z-위치 범위인, 초점 위치에 대한 다수의 초점면으로부터의 이미지를 포함하는 훈련 데이터 세트로 훈련되는, 방법.</claim></claimInfo><claimInfo><claim>54. 제53항에 있어서, 상기 훈련 데이터 세트는 하나 이상의 전체 세포 바이너리 마스크 및/또는 하나 이상의 시드 마스크를 포함하는 실측 자료 출력을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>55. 제53항 또는 제54항에 있어서, 상기 훈련 데이터 세트의 이미지는 전처리된 이미지를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>56. 제49항에 있어서, 상기 이미지는 픽셀 크기가 0.871 μm인 2592 x 1944 8비트 이미지를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>57. 제49항 내지 제56항 중 어느 한 항에 있어서, 하나 이상의 전처리 작업을 수행하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>58. 제57항에 있어서, 상기 하나 이상의 전처리 작업은 상기 이미지에 기초하여 수행되어 전처리된 이미지를 생성하고, 상기 하나 이상의 타일 세트는 상기 전처리된 이미지로부터 분해되고, 또는 상기 하나 이상의 전처리 작업은 상기 하나 이상의 타일에 대해 수행되는, 방법.</claim></claimInfo><claimInfo><claim>59. 제57항 또는 제58항에 있어서, 상기 하나 이상의 전처리 작업은 다운샘플링 작업을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>60. 제59항에 있어서, 상기 다운샘플링 작업은 평균화 필터를 이용하는, 방법.</claim></claimInfo><claimInfo><claim>61. 제60항에 있어서, 상기 다운샘플링 작업은 적어도 2배만큼 이미지 크기를 축소시키는, 방법.</claim></claimInfo><claimInfo><claim>62. 제57항 내지 제61항 중 어느 한 항에 있어서, 상기 하나 이상의 전처리 작업은 배경 제거 작업을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>63. 제62항에 있어서, 상기 배경 제거 작업은,각 픽셀의 반경 내에서 픽셀당 국부 평균을 계산하여 배경을 추정하는 단계; 및상기 이미지로부터 상기 배경을 차감하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>64. 제62항에 있어서, 상기 배경 제거 작업은,상기 이미지 또는 다운샘플링된 이미지의 각 이미지 영역에서 각각의 최소 값을 계산하는 단계; 및상기 각각의 최소 값을 통해 표면을 적합시키는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>65. 제57항 내지 제64항 중 어느 한 항에 있어서, 상기 하나 이상의 전처리 작업은 픽셀 또는 복셀 강도 정규화 작업을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>66. 제65항에 있어서, 상기 픽셀 또는 복셀 강도 정규화 작업은 전역 정규화 작업을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>67. 제65항에 있어서, 상기 픽셀 또는 복셀 강도 정규화 작업은 커널 기반 정규화 작업을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>68. 제57항 내지 제67항 중 어느 한 항에 있어서, 상기 하나 이상의 전처리 작업 중 적어도 일부는 상기 합성곱 신경망에 대한 입력으로서 제공된 상기 하나 이상의 타일에 대한 배치 프로세스로서 수행되는, 방법.</claim></claimInfo><claimInfo><claim>69. 제49항 내지 제68항 중 어느 한 항에 있어서, 상기 하나 이상의 타일 세트를 정의하는 단계는,상기 이미지 또는 전처리된 이미지를 그의 가장자리가 복수의 픽셀만큼 확장되도록 반사하여, 반사된 이미지를 형성하는 단계;상기 반사된 이미지를 픽셀 중첩이 있는 상기 하나 이상의 타일 세트는 타일로 분해하는 단계; 및상기 하나 이상의 타일 세트를 텐서 어레이에 저장하는 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>70. 제69항에 있어서, 상기 이미지 또는 전처리된 이미지를 반사하는 단계는 그 이미지의 가장자리를 4-12개 픽셀, 또는 6-10개 픽셀, 또는 약 8개 픽셀만큼 확장하는, 방법.</claim></claimInfo><claimInfo><claim>71. 제69항 또는 제70항에 있어서, 상기 반사된 이미지는 80-190개 타일, 또는 90-180개 타일, 또는 100-170개 타일, 또는 110-160개 타일, 또는 120-150개 타일, 또는 약 130개 타일로 분해되고, 선택적으로 픽셀 중첩이 있는 128 x 128 픽셀 크기를 갖는, 방법.</claim></claimInfo><claimInfo><claim>72. 제69항 내지 제71항 중 어느 한 항에 있어서, 상기 텐서 어레이는 130 x 1 x 128 x 128 텐서 어레이를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>73. 제49항 내지 제72항 중 어느 한 항에 있어서, 상기 합성곱 신경망은 U-net 합성곱 신경망을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>74. 제49항 내지 제73항 중 어느 한 항에 있어서, 상기 합성곱 신경망의 출력은 130 x 4 x 128 x 128 텐서 어레이에 저장되는, 방법.</claim></claimInfo><claimInfo><claim>75. 제49항 내지 제74항 중 어느 한 항에 있어서, 상기 복수의 의사 확률 맵을 생성하는 단계는 상기 합성곱 신경망의 출력을 8비트 형식 텐서로 변환하고 상기 8비트 형식 텐서를 이미지 스티칭하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>76. 제75항에 있어서, 상기 출력을 상기 8비트 형식 텐서로 변환하는 단계는 상기 130 x 4 x 128 x 128 텐서 어레이에 승수를 곱하는 단계를 포함하며, 선택적으로 상기 승수는 약 255인, 방법.</claim></claimInfo><claimInfo><claim>77. 제75항 또는 제76항에 있어서, 상기 8비트 형식 텐서를 이미지 스티칭하는 단계는 상기 텐서 어레이로부터 복수의 전체 크기 의사 확률 맵을 구성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>78. 제77항에 있어서, 상기 복수의 의사 확률 맵은 (i) 하나 이상의 생세포 시드 우도 이미지, (ii) 하나 이상의 살아있는 전체 세포 우도 이미지, (iii) 하나 이상의 사세포 시드 우도 이미지, 및 (iv) 하나 이상의 죽은 전체 세포 우도 이미지를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>79. 제49항 내지 제78항 중 어느 한 항에 있어서, 상기 하나 이상의 마스크를 생성하는 단계는 50%보다 큰 임계 값을 90% 우도 또는 약 75% 우도에 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>80. 제79항에 있어서, 상기 임계 값은 상기 복수의 의사 확률 맵에서 픽셀 강도가 192(0.75 x 255)인 임계 값에 대응하는, 방법.</claim></claimInfo><claimInfo><claim>81. 제79항 또는 제80항에 있어서, 상기 하나 이상의 마스크를 생성하는 단계는 연결된 영역을 검출하기 위해 연결형 구성요소 레이블링을 적용하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>82. 제49항 내지 제81항 중 어느 한 항에 있어서, 상기 하나 이상의 마스크는 딥 러닝 알고리즘을 이용하여 생성되는, 방법.</claim></claimInfo><claimInfo><claim>83. 제51항 내지 제82항 중 어느 한 항에 있어서, 상기 하나 이상의 분할된 이미지를 생성하는 단계는 상기 하나 이상의 시드 우도 이미지에 표현되고 상기 하나 이상의 전체 세포 우도 이미지에 의해 한정된 상기 하나 이상의 객체의 픽셀 위치로부터 계산된 거리 맵에 유역 변환을 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>84. 제49항 내지 제83항 중 어느 한 항에 있어서, 상기 합성곱 신경망의 출력에 기초하여 상기 세포 카운트를 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>85. 제49항 내지 제84항 중 어느 한 항에 있어서, 상기 세포 카운트를 표시하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>86. 제51항 내지 제85항 중 어느 한 항에 있어서, 상기 하나 이상의 분할된 이미지를 사용하여 하나 이상의 피처 식별 작업을 수행하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>87. 제86항에 있어서, 상기 하나 이상의 피처 계산 작업은 상기 하나 이상의 분할된 이미지 내의 세포를 타원 적합하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>88. 제87항에 있어서, 타원 적합은 객체 크기 측정, 객체 크기 또는 픽셀 강도의 히스토그램 구성, 또는 객체 원형도 계산 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>89. 제49항 내지 제88항 중 어느 한 항에 있어서, 상기 이미지는 단색 이미지를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>90. 자동화 세포 계수를 수행하도록 구성된 세포 카운터로서, 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의해 실행될 때 상기 세포 카운터를, 제49항 내지 제89항 중 어느 한 항의 방법을 수행하도록 구성하는 컴퓨터 실행 가능 명령어가 저장된 하나 이상의 하드웨어 저장 장치;를 포함하는, 세포 카운터.</claim></claimInfo><claimInfo><claim>91. 자동화 세포 계수를 수행하도록 구성된 유세포 분석기로서, 하나 이상의 프로세서; 및 상기 하나 이상의 프로세서에 의해 실행될 때 상기 유세포 분석기를, 제49항 내지 제89항 중 어느 한 항의 방법을 수행하도록 구성하는 컴퓨터 실행 가능 명령어가 저장된 하나 이상의 하드웨어 저장 장치;를 포함하는, 유세포 분석기.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 ***** 칼스베드 뉴톤 드라이브 ****</address><code>520030344089</code><country>미국</country><engName>Life Technologies Corporation</engName><name>라이프 테크놀로지스 코포레이션</name></applicantInfo><applicantInfo><address>미국 캘리포니아주 ***** 칼스배드 뉴톤 드라이브 ****</address><code>520200284409</code><country>미국</country><engName>CELLOMICS, INC.</engName><name>셀로믹스 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 ***** 칼스베드 ...</address><code> </code><country> </country><engName>ROGNIN, Nicolas</engName><name>로그닌 니콜라스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 칼스베드 ...</address><code> </code><country> </country><engName>RYSTROM, Larry</engName><name>리스트롬 래리</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 칼스베드 ...</address><code> </code><country> </country><engName>GOLUB, Ognjen</engName><name>골업 오그니엔</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 칼스베드 ...</address><code> </code><country> </country><engName>PAULLIN, Jonathan</engName><name>파울린 조나단</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 칼스베드 ...</address><code> </code><country> </country><engName>DILIANI, Nicholas</engName><name>딜리아니 니콜라스</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 칼스베드 뉴톤 드라...</address><code> </code><country> </country><engName>IPPOLITO, Kim</engName><name>이폴리토 김</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.10.16</priorityApplicationDate><priorityApplicationNumber>63/092,783</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.10.11</priorityApplicationDate><priorityApplicationNumber>63/254,338</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.05.15</receiptDate><receiptNumber>1-1-2023-0538931-97</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2023.05.26</receiptDate><receiptNumber>1-5-2023-0084782-02</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[지정기간연장]기간 연장신청서·기간 단축신청서·기간 경과 구제신청서·절차 계속신청서</documentName><receiptDate>2023.07.26</receiptDate><receiptNumber>1-1-2023-0823324-01</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.08.24</receiptDate><receiptNumber>1-1-2023-0936226-41</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.08.30</receiptDate><receiptNumber>1-5-2023-0138535-31</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.10.08</receiptDate><receiptNumber>1-1-2024-1094951-76</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.10.08</receiptDate><receiptNumber>1-1-2024-1094970-33</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237016508.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93941dc4cd34986d9c1c7f1d981246822909b53433c04e611e2a245f63d5650e0ab47fdb806db005617d6a2a0a03872fc8274ea65e1a337f72</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf206ccda87f849f1c0f3b252fd19de67249f582c3bfca59511a8ec9329cf61396d5b3fb1ee22b2b1a70409c9cc45322addcee6c0accaee605</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>