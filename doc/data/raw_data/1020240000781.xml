<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:46.546</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.01.03</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0000781</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>영상 기반 보행자 안전 정보 예측 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEM AND METHOD FOR PREDICTING PEDESTRIAN SAFETY  INFORMATION BASED ON VIDEO</inventionTitleEng><openDate>2025.02.05</openDate><openNumber>10-2025-0018351</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.01.03</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/52</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/762</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G08B 31/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명에 따른 영상 기반 보행자 안전 정보 예측 방법은 영상 정보를 기반으로 보행자의 궤적 예측 정보를 생성하는 단계; 상기 영상 정보를 기반으로 보행자의 행동 예측 정보를 생성하는 단계; 및 상기 궤적 예측 정보와 행동 예측 정보 및 상기 영상 정보 내 지면 분류 결과에 기초하여 위험도를 추정하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터에 의해 수행되는 방법에 있어서,영상 정보를 기반으로 보행자의 궤적 예측 정보를 생성하는 단계;상기 영상 정보를 기반으로 보행자의 행동 예측 정보를 생성하는 단계; 및상기 궤적 예측 정보와 행동 예측 정보 및 상기 영상 정보 내 지면 분류 결과에 기초하여 위험도를 추정하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 영상 정보를 기반으로 보행자의 궤적 예측 정보를 생성하는 단계는,상기 영상 정보와 보행자의 과거 궤적 정보를 주의집중 메커니즘 기반의 제1 시각주의 특징 모듈에 입력하여, 상기 영상 정보 내 보행자에 해당하는 바운딩 박스 및 상기 바운딩 박스의 주변부 영상 영역을 재귀적 인코더에 제공하는 단계; 및상기 영상 정보와 상기 재귀적 인코더에서 추출한 과거 상태 특징 벡터를 제2 시각주의 특징 모듈에 입력하여, 미래의 보행자 궤적 예측을 위한 시각적 특징 정보를 출력하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 영상 정보를 기반으로 보행자의 궤적 예측 정보를 생성하는 단계는,상기 바운딩 박스 및 상기 바운딩 박스의 주변부 영상 영역과 상기 과거 궤적 정보를 상기 재귀적 인코더에 입력하여 보행자의 과거 상태 특징 벡터를 출력하는 단계; 및상기 시각적 특징 정보를 재귀적 디코더에 입력하여 상기 보행자의 궤적 예측 정보를 생성하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 영상 정보를 기반으로 보행자의 행동 예측 정보를 생성하는 단계는,현재부터 과거의 일정 시간 동안의 영상 정보를 관찰 대상 영상으로 설정하는 단계;상기 관찰 대상 영상으로부터 다중 시각적 입력 특징정보 및 비시각적 입력 특징정보를 추출하는 단계;상기 다중 시각적 입력 특징정보 및 비시각적 입력 특징정보를 그룹화하는 단계; 및상기 그룹화된 특징정보를 각각 분리된 처리 모듈에 입력하고 각 처리 모듈의 출력 결과를 결합하여 상기 보행자의 행동 예측 정보를 생성하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 관찰 대상 영상으로부터 다중 시각적 입력 특징정보 및 비시각적 입력 특징정보를 추출하는 단계는,상기 보행자의 자세 특징 정보, 보행자의 바운딩 박스 및 차량의 속도 정보를 상기 비시각적 입력 특징정보로 추출하는 단계; 및상기 바운딩 박스의 소정 배수 크기를 갖는 이미지인 지역 컨텍스트 정보, 영상 분할 정보가 포함된 전역 컨텍스트 정보, 영상의 전체 영역 정보가 포함된 장면 컨텍스트 정보, 상기 영상 정보로부터 획득한 보행자 영역 및 보행자 영역이 제거된 주변부 영상 영역을 상기 시각적 입력 특징 정보로 추출하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 다중 시각적 입력 특징정보 및 비시각적 입력 특징정보를 그룹화하는 단계는,상기 보행자의 자세 특징 정보, 보행자의 바운딩 박스 및 차량의 속도 정보를 제1 그룹 특징정보로 생성하는 단계;상기 바운딩 박스의 소정 배수 크기를 갖는 이미지인 지역 컨텍스트 정보, 영상 분할 정보가 포함된 전역 컨텍스트 정보, 영상의 전체 영역 정보가 포함된 장면 컨텍스트 정보를 제2 그룹 특징정보로 생성하는 단계; 및상기 영상 정보로부터 획득한 보행자 영역 및 보행자 영역이 제거된 주변부 영상 영역을 제3 그룹 특징정보로 생성하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 그룹화된 특징정보를 각각 분리된 처리 모듈에 입력하고 각 처리 모듈의 출력 결과를 결합하여 상기 보행자의 행동 예측 정보를 생성하는 단계는,상기 보행자의 자세 특징 정보를 제1 GRU 모듈에 입력하는 단계;상기 제1 GRU 모듈로부터 보행자의 자세 특징 정보에 대한 예측값을 획득하는 단계;상기 보행자의 자세 특징 정보에 대한 예측값과 상기 보행자의 바운딩 박스 정보를 결합하여 제2 GRU 모듈에 입력하는 단계;상기 제2 GRU 모듈로부터 상기 바운딩 박스에 포함된 보행자의 자세 특징 정보에 대한 예측값을 획득하는 단계;상기 바운딩 박스에 포함된 보행자의 자세 특징 정보에 대한 예측값과 상기 차량의 속도 정보를 제3 GRU 모듈에 입력하는 단계; 및상기 제3 GRU 모듈로부터 상기 바운딩 박스에 포함된 보행자의 차량의 속도 정보에 상응하는 자세 특징 정보에 대한 예측값을 획득하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 그룹화된 특징정보를 각각 분리된 처리 모듈에 입력하고 각 처리 모듈의 출력 결과를 결합하여 상기 보행자의 행동 예측 정보를 생성하는 단계는,상기 지역 컨텍스트 정보, 전역 컨텍스트 정보 및 장면 컨텍스트 정보를 각각 CNN에 입력하는 단계;상기 CNN으로부터 출력되는 상기 지역 컨텍스트 정보, 전역 컨텍스트 정보 및 장면 컨텍스트 정보 각각에 대한 이미지 특징 정보를 제1 내지 제3 GRU 모듈에 입력하는 단계;  및상기 제1 내지 제3 GRU 모듈로부터 출력되는 상기 지역 컨텍스트 정보, 전역 컨텍스트 정보 및 장면 컨텍스트 정보 각각에 대한 예측 정보를 결합하여 제4 GRU 모듈에 입력하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,상기 그룹화된 특징정보를 각각 분리된 처리 모듈에 입력하고 각 처리 모듈의 출력 결과를 결합하여 상기 보행자의 행동 예측 정보를 생성하는 단계는,상기 영상 정보로부터 획득한 보행자 영역 및 보행자 영역이 제거된 주변부 영상 영역을 각각 컨볼루션 3D 네트워크에 입력하는 단계;상기 컨볼루션 3D 네트워크의 출력 결과를 맥스 풀링 계층에 입력하여 각 이미지의 차원을 축소시키는 단계;상기 차원이 축소된 각 이미지를 1차원 벡터로 변환한 후 완전 연결 계층에 전달하는 단계; 및상기 완전 연결 계층에서 각 입출력 뉴런을 결합한 결과를 출력하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>10. 제6항에 있어서,상기 그룹화된 특징정보를 각각 분리된 처리 모듈에 입력하고 각 처리 모듈의 출력 결과를 결합하여 상기 보행자의 행동 예측 정보를 생성하는 단계는,상기 제1 그룹 정보를 처리하기 위한 제1 처리 모듈의 출력 결과를 제1 어텐션 모듈에 입력하는 단계;상기 제2 그룹 정보를 처리하기 위한 제2 처리 모듈의 출력 결과를 제2 어텐션 모듈에 입력하는 단계;상기 제2 어텐션 모듈의 출력 결과를 상기 제3 그룹 정보와 결합한 후 제3 어텐션 모듈에 입력하는 단계; 및상기 제1 내지 제3 어텐션 모듈의 출력 결과를 결합한 후 제4 어텐션 모듈에 입력하여 상기 보행자의 행동 예측 정보를 생성하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 궤적 예측 정보와 행동 예측 정보 및 상기 영상 정보 내 지면 분류 결과에 기초하여 위험도를 추정하는 단계는,상기 영상 정보에 대한 의미론적 분할을 수행하여 복수의 분할맵을 생성하는 단계;상기 복수의 분할맵 중 지면 영역을 식별하여 지면 영역 맵을 생성하는 단계; 및상기 영상 정보 내 보행자에 대응하는 바운딩 박스의 주변 영역인 주변부 영상 영역과 상기 지면 영역 맵을 기반으로 보행자 위험도를 추정하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 복수의 분할맵 중 지면 영역을 식별하여 지면 영역 맵을 생성하는 단계는,상기 지면 영역에 속한 픽셀이 참으로 설정된 지면 영역 마스크를 생성하는 단계;상기 분할맵에 상기 지면 영역 마스크를 적용하여 시간에 따른 지면 영역에 대한 누적 확률을 산출하는 단계; 및상기 누적 확률에 기반하여 각 픽셀이 어떤 지면 영역에 속하는지를 나타내는 상기 지면 영역 맵을 생성하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 궤적 예측 정보와 행동 예측 정보 및 상기 영상 정보 내 지면 분류 결과에 기초하여 위험도를 추정하는 단계는,상기 영상 및 바운딩 박스로부터 보행자의 주변부 영상 영역을 추출하는 단계를 포함하되,상기 보행자의 주변부 영상 영역을 추출하는 단계는,상기 영상 및 바운딩 박스에 기반하여 보행자 주변부에 대한 시각적 특징을 포함하는 제1 특징맵을 추출하는 단계; 및상기 영상, 바운딩 박스 및 지면 영역 맵에 기반하여 보행자 및 보행자 주변부에 대한 지면 특징을 포함하는 제2 특징맵을 추출하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 제1 특징맵을 추출하는 단계는,상기 영상으로부터 상기 바운딩 박스를 포함하되, 상기 바운딩 박스의 소정 배수 크기에 해당하는 영역을 크롭하여 제1 크롭 영상을 생성하는 단계; 상기 제1 크롭 영상에서의 바운딩 박스에 해당하는 영역을 제거하는 단계; 및상기 바운딩 박스에 해당하는 영역이 제거된 영상을 미리 학습된 시각특징 추출 네트워크에 입력하여 보행자 주변부에 대한 시각적 특징을 포함하는 제1 특징맵을 추출하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 제2 특징맵을 추출하는 단계는,상기 지면 영역 맵을 RGB 영상으로 변환한 후, 상기 제1 크롭 영상과 동일 영역을 크롭하여 제2 크롭 영상을 생성하는 단계;상기 제2 크롭 영상을 미리 학습된 도로영역 특징 추출 네트워크에 입력하여 보행자 및 보행자 주변부에 대한 지면 특징을 포함하는 제2 특징맵을 추출하는 단계; 및상기 제1 및 제2 특징맵을 결합하여 확률 기반의 보행자 위험도를 출력하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서,상기 궤적 예측 정보와 행동 예측 정보 및 상기 영상 정보 내 지면 분류 결과에 기초하여 위험도를 추정하는 단계는,상기 바운딩 박스와 상기 지면 영역 맵에 기초하여 상기 보행자에 대한 의미론적 위치 정보를 추정하는 단계를 더 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 바운딩 박스와 상기 지면 영역 맵에 기초하여 상기 보행자에 대한 의미론적 위치 정보를 추정하는 단계는,상기 바운딩 박스로부터 보행자의 발 영역을 추정하는 단계; 및상기 보행자의 발 영역과 접하는 상기 지면 영역 맵 상에서의 화소가 가장 많이 해당되는 클래스를 상기 보행자에 대한 의미론적 위치 정보로 추정하는 단계를 포함하는,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 바운딩 박스로부터 보행자의 발 영역을 추정하는 단계는,상기 바운딩 박스의 크기 정보로부터 소정 비율을 갖는 하단 영역을 상기 보행자의 발 영역으로 추정하는 것인,영상 기반 보행자 안전 정보 예측 방법.</claim></claimInfo><claimInfo><claim>19. 소정의 위치에 설치된 카메라를 통해 촬영된 영상 정보를 수신하는 통신모듈,상기 촬영된 영상 정보를 기반으로 보행자 위험도를 추정하기 위한 프로그램이 저장된 메모리 및상기 메모리에 저장된 프로그램을 실행시킴에 따라, 상기 영상 정보를 기반으로 보행자의 궤적 예측 정보를 생성하고, 상기 영상 정보를 기반으로 보행자의 행동 예측 정보를 생성한 후, 상기 궤적 예측 정보와 행동 예측 정보 및 상기 영상 정보 내 지면 분류 결과에 기초하여 위험도를 추정하는 프로세서를 포함하는,영상 기반 보행자 안전 예측 시스템.</claim></claimInfo><claimInfo><claim>20. 소정의 위치에 설치된 카메라를 통해 촬영된 영상 정보를 수신하는 통신모듈,상기 촬영된 영상 정보를 기반으로 보행자 위험도를 추정하기 위한 프로그램이 저장된 메모리 및상기 메모리에 저장된 프로그램을 실행시킴에 따라, 상기 영상 정보를 기반으로 미래의 보행자 궤적 예측을 위한 시각적 특징 정보를 추출하고, 상기 시각적 특징 정보를 재귀적 인코더 및 디코더에 입력하여 보행자의 궤적 예측 정보를 생성하며, 상기 영상 정보로부터 다중 시각적 입력 특징정보 및 비시각적 입력 특징정보를 추출하고, 추출된 각 입력 특징정보를 그룹화하여 각 처리 모듈에 입력 후 출력 결과를 결합하여 보행자의 행동 예측 정보를 생성하며, 상기 궤적 예측 정보와 행동 예측 정보 및 상기 영상 정보 내 지면 분류 결과에 기초하여 보행자에 대한 의미론적 위치 정보 및 위험도를 추정하는 프로세서를 포함하는,영상 기반 보행자 안전 예측 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980077638</code><country>대한민국</country><engName>Electronics and Telecommunications Research Institute</engName><name>한국전자통신연구원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>OH, Sung Chan</engName><name>오성찬</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>KIM, Dae Hoe</engName><name>김대회</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>HAM, Je Seok</engName><name>함제석</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>MOON, Jin Young</engName><name>문진영</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>KWON, Yong Jin</engName><name>권용진</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>KIM, Jong Hee</engName><name>김종희</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 남부순환로**** 차우빌딩*층</address><code>920071000215</code><country>대한민국</country><engName>JIMYUNG Patent Firm</engName><name>특허법인지명</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.07.27</priorityApplicationDate><priorityApplicationNumber>1020230098385</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.01.03</receiptDate><receiptNumber>1-1-2024-0007727-14</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240000781.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c933a1d068230ed44807a23d373719469f73725271f7d13f351f2d599dfb1e4b501bcde6c80f237cfe8fc1e1ed6e9585e3b9acb14ad738b9e57</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf2a2d8b47e58bb48b276319f486ac652970c3099a29ad89e026b899ebba0cfd32d1b0f289159934688226a9f7e078b51d14dfc2ac6ddb83fe</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>