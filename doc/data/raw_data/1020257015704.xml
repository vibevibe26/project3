<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:14.3314</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.02</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7015704</applicationNumber><claimCount>57</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>카메라 보조 LiDAR 데이터 검증</inventionTitle><inventionTitleEng>CAMERA ASSISTED LIDAR DATA VERIFICATION</inventionTitleEng><openDate>2025.06.16</openDate><openNumber>10-2025-0087675</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.05.13</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/80</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/776</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/894</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G01S 17/931</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B60W 40/02</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 카메라 보조 LiDAR 데이터 검증을 위한 방법들이 제공된다. 차량(예를 들어, 자율 주행 차량)은 차량 상의 다양한 위치에 장착된 다수의 센서를 갖는다. 이러한 센서로부터의 데이터가 대상체 검출에 사용될 수 있다. 대상체 검출에서, 센서에 의해 캡처된 데이터의 각 부분 내의 특정 대상체 클래스 인스턴스의 존재를 나타내는 신뢰도 점수로 센서 데이터의 부분에 주석을 달기 위해 센서 데이터가 분석된다. 시스템 및 컴퓨터 프로그램 제품이 또한 제공된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.04.18</internationOpenDate><internationOpenNumber>WO2024081126</internationOpenNumber><internationalApplicationDate>2023.10.02</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/034305</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 시스템으로서,적어도 하나의 프로세서, 및명령어들을 저장한 적어도 하나의 비일시적 저장 매체를 포함하며, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 제1 시맨틱 세그먼트화 네트워크 및 제2 시맨틱 세그먼트화 네트워크를 실행하고 — 실행할 때, 상기 제1 시맨틱 세그먼트화 네트워크는 제1 센서 데이터를 입력으로서 획득하고, 상기 제2 시맨틱 세그먼트화 네트워크는 제2 센서 데이터를 입력으로서 획득함 —; 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력되는 제1 위치와 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력되는 제2 위치 사이의 차이를 결정하고; 상기 제1 위치와 상기 제2 위치 사이의 차이가 제1 미리 결정된 문턱치를 충족시키고 상기 제2 시맨틱 세그먼트화에 의해 출력되는 데이터가 상기 제2 위치에서의 알려진 저반사도를 나타낼 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 제1 신뢰도 점수를 업데이트하며 — 상기 업데이트는 상기 제2 신뢰도 점수에 기초하여 상기 제1 신뢰도 점수를 수정함 —; 상기 제1 시맨틱 세그먼트화 네트워크 및 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 데이터에 기초하여 대상체 유형을 결정하게 하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 신뢰도 점수를 업데이트하는 것은, 상기 제1 신뢰도 점수를 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 제2 신뢰도 점수와 동일하게 설정하는 것을 포함하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 데이터는 색상 데이터이며, 상기 시스템은,상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 색상 데이터와 참조 색상 데이터 사이의 차이를 결정함으로써 상기 색상 데이터를 평가하는 것; 및상기 색상 데이터와 상기 참조 색상 데이터 사이의 차이가 제2 미리 결정된 문턱치를 충족시킬 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 제1 신뢰도 점수를 업데이트하는 것을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 데이터는 속성 데이터이며, 상기 시스템은,상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 속성 정보와 참조 속성 정보 사이의 차이를 결정함으로써 상기 속성 데이터를 평가하는 것, 및상기 속성 정보와 상기 참조 속성 정보 사이의 차이가 제3 미리 결정된 문턱치 미만일 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 제1 신뢰도 점수를 업데이트하는 것을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 제1 시맨틱 세그먼트화 네트워크는 그 환경 내의 대상체들과 연관된 제1 경계 박스 세트를 생성하는 LiDAR 시맨틱 네트워크이며, 상기 제1 경계 박스 세트는 상기 제1 위치 및 상기 제1 신뢰도 점수를 포함하는 상기 제1 경계 박스 세트 내의 대상체 클래스 인스턴스의 존재를 나타내는 것인, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 제2 시맨틱 세그먼트화 네트워크는 그 환경 내의 대상체들과 연관된 제2 경계 박스 세트를 생성하는 이미지 시맨틱 네트워크이며, 상기 제2 경계 박스 세트는 상기 제2 위치 및 상기 제2 신뢰도 점수를 포함하는 상기 제2 경계 박스 세트 내의 대상체 클래스 인스턴스의 존재를 나타내는 것인, 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력되는 상기 제1 위치는 3차원 위치이고;상기 제1 위치와 상기 제2 위치 사이의 차이를 결정하는 것은 상기 제1 위치를 2차원 표면 상으로 투영하는 것 및 상기 투영된 제1 위치를 상기 제2 위치와 비교하는 것을 포함하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서, 조감도 네트워크가 상기 제1 시맨틱 세그먼트화 네트워크 및 상기 제2 시맨틱 세그먼트화 네트워크의 출력을 입력으로서 수신하고, 검출된 대상체의 표시를 출력하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서, 상기 제2 시맨틱 세그먼트화 네트워크는 상기 대상체를 검출하기 위해 사용되는 주변 광 정보를 출력하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>10. 제3항에 있어서, 상기 참조 색상은 상기 알려진 저반사도와 연관된 색상에 대응하도록 선택되는 것인, 시스템.</claim></claimInfo><claimInfo><claim>11. 제4항에 있어서, 상기 참조 속성은 상기 알려진 저반사도와 연관된 속성 유형에 대응하도록 선택되는 것인, 시스템.</claim></claimInfo><claimInfo><claim>12. 방법으로서,적어도 하나의 프로세서를 이용해, 제1 시맨틱 세그먼트화 네트워크 및 제2 시맨틱 세그먼트화 네트워크를 실행하는 단계 — 실행할 때, 상기 제1 시맨틱 세그먼트화 네트워크는 제1 센서 데이터를 입력으로서 획득하고, 상기 제2 시맨틱 세그먼트화 네트워크는 제2 센서 데이터를 입력으로서 획득함 —;상기 적어도 하나의 프로세서를 이용해, 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력되는 제1 위치와 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력되는 제2 위치 사이의 차이를 결정하는 단계;상기 적어도 하나의 프로세서를 이용해, 상기 제1 위치와 상기 제2 위치 사이의 차이가 제1 미리 결정된 문턱치를 충족시키고 상기 제2 시맨틱 세그먼트화에 의해 출력되는 데이터가 상기 제2 위치에서의 알려진 저반사도를 나타낼 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 제1 신뢰도 점수를 업데이트하는 단계 — 상기 업데이트는 상기 제2 신뢰도 점수에 기초하여 상기 제1 신뢰도 점수를 수정함 —;상기 적어도 하나의 프로세서를 이용해, 상기 제1 시맨틱 세그먼트화 네트워크 및 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 데이터에 기초하여 대상체 유형을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제1 신뢰도 점수를 업데이트하는 단계는, 상기 제1 신뢰도 점수를 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 제2 신뢰도 점수와 동일하게 설정하는 단계를 포함하는 것인, 방법.</claim></claimInfo><claimInfo><claim>14. 제12항 또는 제13항에 있어서, 상기 데이터는 색상 데이터이며, 상기 방법은,상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 색상 데이터와 참조 색상 데이터 사이의 차이를 결정함으로써 상기 색상 데이터를 평가하는 단계; 및상기 색상 데이터와 상기 참조 색상 데이터 사이의 차이가 제2 미리 결정된 문턱치를 충족시킬 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 제1 신뢰도 점수를 업데이트하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제12항 내지 제14항 중 어느 한 항에 있어서, 상기 데이터는 속성 데이터이며, 상기 방법은,상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 속성 정보와 참조 속성 정보 사이의 차이를 결정함으로써 상기 속성 데이터를 평가하는 단계, 및상기 속성 정보와 상기 참조 속성 정보 사이의 차이가 제3 미리 결정된 문턱치 미만일 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 제1 신뢰도 점수를 업데이트하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제12항 내지 제15항 중 어느 한 항에 있어서, 상기 제1 시맨틱 세그먼트화 네트워크는 그 환경 내의 대상체들과 연관된 제1 경계 박스 세트를 생성하는 LiDAR 시맨틱 네트워크이며, 상기 제1 경계 박스 세트는 상기 제1 위치 및 상기 제1 신뢰도 점수를 포함하는 상기 제1 경계 박스 세트 내의 대상체 클래스 인스턴스의 존재를 나타내는 것인, 방법.</claim></claimInfo><claimInfo><claim>17. 제12항 내지 제16항 중 어느 한 항에 있어서, 상기 제2 시맨틱 세그먼트화 네트워크는 그 환경 내의 대상체들과 연관된 제2 경계 박스 세트를 생성하는 이미지 시맨틱 네트워크이며, 상기 제2 경계 박스 세트는 상기 제2 위치 및 상기 제2 신뢰도 점수를 포함하는 상기 제2 경계 박스 세트 내의 대상체 클래스 인스턴스의 존재를 나타내는 것인, 방법.</claim></claimInfo><claimInfo><claim>18. 제12항 내지 제17항 중 어느 한 항에 있어서, 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력되는 상기 제1 위치는 3차원 위치이고;상기 제1 위치와 상기 제2 위치 사이의 차이를 결정하는 단계는 상기 제1 위치를 2차원 표면 상으로 투영하는 단계 및 상기 투영된 제1 위치를 상기 제2 위치와 비교하는 단계를 포함하는 것인, 방법.</claim></claimInfo><claimInfo><claim>19. 제12항 내지 제18항 중 어느 한 항에 있어서, 조감도 네트워크가 상기 제1 시맨틱 세그먼트화 네트워크 및 상기 제2 시맨틱 세그먼트화 네트워크의 출력을 입력으로서 수신하고, 검출된 대상체의 표시를 출력하는 것인, 방법.</claim></claimInfo><claimInfo><claim>20. 제12항 내지 제19항 중 어느 한 항에 있어서, 상기 제2 시맨틱 세그먼트화 네트워크는 상기 대상체를 검출하기 위해 사용되는 주변 광 정보를 출력하는 것인, 방법.</claim></claimInfo><claimInfo><claim>21. 제14항에 있어서, 상기 참조 색상은 상기 알려진 저반사도와 연관된 색상에 대응하도록 선택되는 것인, 방법.</claim></claimInfo><claimInfo><claim>22. 제15항에 있어서, 상기 참조 속성은 상기 알려진 저반사도와 연관된 속성 유형에 대응하도록 선택되는 것인, 방법.</claim></claimInfo><claimInfo><claim>23. 명령어들을 저장한 적어도 하나의 비일시적 저장 매체로서, 상기 명령어들은 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 제1 시맨틱 세그먼트화 네트워크 및 제2 시맨틱 세그먼트화 네트워크를 실행하고 — 실행할 때, 상기 제1 시맨틱 세그먼트화 네트워크는 제1 센서 데이터를 입력으로서 획득하고, 상기 제2 시맨틱 세그먼트화 네트워크는 제2 센서 데이터를 입력으로서 획득함 —; 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력되는 제1 위치와 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력되는 제2 위치 사이의 차이를 결정하고; 상기 제1 위치와 상기 제2 위치 사이의 차이가 제1 미리 결정된 문턱치를 충족시키고 상기 제2 시맨틱 세그먼트화에 의해 출력되는 데이터가 상기 제2 위치에서의 알려진 저반사도를 나타낼 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 제1 신뢰도 점수를 업데이트하며 — 상기 업데이트는 상기 제2 신뢰도 점수에 기초하여 상기 제1 신뢰도 점수를 수정함 —; 상기 제1 시맨틱 세그먼트화 네트워크 및 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 데이터에 기초하여 대상체 유형을 결정하게 하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 제1 신뢰도 점수를 업데이트하는 것은, 상기 제1 신뢰도 점수를 상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 제2 신뢰도 점수와 동일하게 설정하는 것을 포함하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>25. 제23항 또는 제24항에 있어서, 상기 데이터는 색상 데이터이며, 상기 적어도 하나의 비일시적 저장 매체는,상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 색상 데이터와 참조 색상 데이터 사이의 차이를 결정함으로써 상기 색상 데이터를 평가하는 것; 및상기 색상 데이터와 상기 참조 색상 데이터 사이의 차이가 제2 미리 결정된 문턱치를 충족시킬 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 제1 신뢰도 점수를 업데이트하는 것을 더 포함하는, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>26. 제23항 내지 제25항 중 어느 한 항에 있어서, 상기 데이터는 속성 데이터이며, 상기 적어도 하나의 비일시적 저장 매체는,상기 제2 시맨틱 세그먼트화 네트워크에 의해 출력된 속성 정보와 참조 속성 정보 사이의 차이를 결정함으로써 상기 속성 데이터를 평가하는 것; 및상기 속성 정보와 상기 참조 속성 정보 사이의 차이가 제3 미리 결정된 문턱치 미만일 때 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력된 상기 제1 신뢰도 점수를 업데이트하는 것을 더 포함하는, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>27. 제23항 내지 제26항 중 어느 한 항에 있어서, 상기 제1 시맨틱 세그먼트화 네트워크는 그 환경 내의 대상체들과 연관된 제1 경계 박스 세트를 생성하는 LiDAR 시맨틱 네트워크이며, 상기 제1 경계 박스 세트는 상기 제1 위치 및 상기 제1 신뢰도 점수를 포함하는 상기 제1 경계 박스 세트 내의 대상체 클래스 인스턴스의 존재를 나타내는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>28. 제23항 내지 제27항 중 어느 한 항에 있어서, 상기 제2 시맨틱 세그먼트화 네트워크는 그 환경 내의 대상체들과 연관된 제2 경계 박스 세트를 생성하는 이미지 시맨틱 네트워크이며, 상기 제2 경계 박스 세트는 상기 제2 위치 및 상기 제2 신뢰도 점수를 포함하는 상기 제2 경계 박스 세트 내의 대상체 클래스 인스턴스의 존재를 나타내는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>29. 제23항 내지 제28항 중 어느 한 항에 있어서, 상기 제1 시맨틱 세그먼트화 네트워크에 의해 출력되는 상기 제1 위치는 3차원 위치이고;상기 제1 위치와 상기 제2 위치 사이의 차이를 결정하는 것은 상기 제1 위치를 2차원 표면 상으로 투영하는 것 및 상기 투영된 제1 위치를 상기 제2 위치와 비교하는 것을 포함하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>30. 제23항 내지 제29항 중 어느 한 항에 있어서, 조감도 네트워크가 상기 제1 시맨틱 세그먼트화 네트워크 및 상기 제2 시맨틱 세그먼트화 네트워크의 출력을 입력으로서 수신하고, 검출된 대상체의 표시를 출력하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>31. 제23항 내지 제30항 중 어느 한 항에 있어서, 상기 제2 시맨틱 세그먼트화 네트워크는 상기 대상체를 검출하기 위해 사용되는 주변 광 정보를 출력하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>32. 제25항에 있어서, 상기 참조 색상은 상기 알려진 저반사도와 연관된 색상에 대응하도록 선택되는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>33. 제26항에 있어서, 상기 참조 속성은 상기 알려진 저반사도와 연관된 속성 유형에 대응하도록 선택되는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>34. 시스템으로서,적어도 하나의 프로세서, 및명령어들을 저장한 적어도 하나의 비일시적 저장 매체를 포함하며, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 제1 시맨틱 세그먼트화 네트워크를 실행하고 — 실행할 때, 상기 제1 시맨틱 세그먼트화 네트워크는 카메라 데이터를 입력으로서 획득하고, 대상체의 제1 공간적 위치와 연관된 데이터, 상기 대상체와 연관된 대상체 속성 정보, 상기 대상체와 연관된 대상체 색상 정보, 및 상기 대상체와 연관된 제1 검출 신뢰도 점수를 출력함 —; 상기 대상체의 상기 제1 공간적 위치, 맵 정보, 및 카메라 캘리브레이션 정보에 기초하여 각도 정보를 결정하고; 제2 시맨틱 세그먼트화 네트워크를 실행하며 — 실행할 때, 상기 제2 시맨틱 세그먼트화 네트워크는 제2 센서 데이터, 상기 각도 정보, 상기 대상체 속성 정보, 상기 대상체 색상 정보, 및 상기 제1 검출 신뢰도 점수를 입력으로서 획득하고, 제2 공간적 위치 및 제2 검출 신뢰도 점수와 연관된 데이터를 출력함 —; 상기 제1 공간적 위치, 제1 검출 신뢰도 점수, 제2 공간적 위치 및 제2 검출 신뢰도 점수에 기초하여 차량이 제어되게 하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>35. 제34항에 있어서, 상기 각도 정보는 맵 정보 및 카메라 캘리브레이션 정보에 기초하여 결정되는 것인, 시스템.</claim></claimInfo><claimInfo><claim>36. 제34항 또는 제35항에 있어서, 상기 대상체 속성 정보는 상기 대상체의 대상체 분류와 연관된 모델에 기초하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>37. 제34항 내지 제36항 중 어느 한 항에 있어서, 상기 대상체 색상 정보는 상기 카메라 데이터에서 캡처되는 상기 대상체의 적색, 녹색, 및 청색 색상 값들인 것인, 시스템.</claim></claimInfo><claimInfo><claim>38. 제34항 내지 제37항 중 어느 한 항에 있어서, 상기 대상체의 상기 대상체 속성 정보 또는 상기 대상체의 상기 대상체 색상 정보는 상기 대상체와 연관된 저반사율을 나타내는 것인, 시스템.</claim></claimInfo><claimInfo><claim>39. 제38항에 있어서, 상기 대상체와 연관된 상기 제1 검출 신뢰도 점수는 상기 대상체와 연관된 저반사율에 기초하여 상기 제2 검출 신뢰도 점수보다 더 정확하고, 상기 제2 시맨틱 세그먼트화 네트워크는 상기 제1 검출 신뢰도 점수에 기초하여 상기 제2 검출 신뢰도 점수를 업데이트하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>40. 제34항 내지 제39항 중 어느 한 항에 있어서, 상기 대상체는 흑색 차량이고, 상기 속성 정보는 흑색 차량들과 연관된 차량 모델에 기초하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>41. 제34항 내지 제40항 중 어느 한 항에 있어서, 상기 대상체는 어두운 옷을 입은 보행자이고, 상기 속성 정보는 보행자 모델에 기초하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>42. 방법으로서,적어도 하나의 프로세서를 이용해, 제1 시맨틱 세그먼트화 네트워크를 실행하는 단계 — 실행할 때, 상기 제1 시맨틱 세그먼트화 네트워크는 카메라 데이터를 입력으로서 획득하고, 대상체의 제1 공간적 위치와 연관된 데이터, 상기 대상체와 연관된 대상체 속성 정보, 상기 대상체와 연관된 대상체 색상 정보, 및 상기 대상체와 연관된 제1 검출 신뢰도 점수를 출력함 —;상기 적어도 하나의 프로세서를 이용해, 상기 대상체의 상기 제1 공간적 위치, 맵 정보, 및 카메라 캘리브레이션 정보에 기초하여 각도 정보를 결정하는 단계;상기 적어도 하나의 프로세서를 이용해, 제2 시맨틱 세그먼트화 네트워크를 실행하는 단계 — 실행할 때, 상기 제2 시맨틱 세그먼트화 네트워크는 제2 센서 데이터, 상기 각도 정보, 상기 대상체 속성 정보, 상기 대상체 색상 정보, 및 상기 제1 검출 신뢰도 점수를 입력으로서 획득하고, 제2 공간적 위치 및 제2 검출 신뢰도 점수와 연관된 데이터를 출력함 —; 및상기 적어도 하나의 프로세서를 이용해, 상기 제1 공간적 위치, 제1 검출 신뢰도 점수, 제2 공간적 위치 및 제2 검출 신뢰도 점수에 기초하여 차량이 제어되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>43. 제42항에 있어서, 상기 각도 정보는 맵 정보 및 카메라 캘리브레이션 정보에 기초하여 결정되는 것인, 방법.</claim></claimInfo><claimInfo><claim>44. 제42항 또는 제43항에 있어서, 상기 대상체 속성 정보는 상기 대상체의 대상체 분류와 연관된 모델에 기초하는 것인, 방법.</claim></claimInfo><claimInfo><claim>45. 제42항 내지 제44항 중 어느 한 항에 있어서, 상기 대상체 색상 정보는 상기 카메라 데이터에서 캡처되는 상기 대상체의 적색, 녹색, 및 청색 색상 값들인 것인, 방법.</claim></claimInfo><claimInfo><claim>46. 제42항 내지 제45항 중 어느 한 항에 있어서, 상기 대상체의 상기 대상체 속성 정보 또는 상기 대상체의 상기 대상체 색상 정보는 상기 대상체와 연관된 저반사율을 나타내는 것인, 방법.</claim></claimInfo><claimInfo><claim>47. 제46항에 있어서, 상기 대상체와 연관된 상기 제1 검출 신뢰도 점수는 상기 대상체와 연관된 저반사율에 기초하여 상기 제2 검출 신뢰도 점수보다 더 정확하고, 상기 제2 시맨틱 세그먼트화 네트워크는 상기 제1 검출 신뢰도 점수에 기초하여 상기 제2 검출 신뢰도 점수를 업데이트하는 것인, 방법.</claim></claimInfo><claimInfo><claim>48. 제42항 내지 제47항 중 어느 한 항에 있어서, 상기 대상체는 흑색 차량이고, 상기 속성 정보는 흑색 차량들과 연관된 차량 모델에 기초하는 것인, 방법.</claim></claimInfo><claimInfo><claim>49. 제42항 내지 제48항 중 어느 한 항에 있어서, 상기 대상체는 어두운 옷을 입은 보행자이고, 상기 속성 정보는 보행자 모델에 기초하는 것인, 방법.</claim></claimInfo><claimInfo><claim>50. 명령어들을 저장한 적어도 하나의 비일시적 저장 매체로서, 상기 명령어들은 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 제1 시맨틱 세그먼트화 네트워크를 실행하고 — 실행할 때, 상기 제1 시맨틱 세그먼트화 네트워크는 카메라 데이터를 입력으로서 획득하고, 대상체의 제1 공간적 위치와 연관된 데이터, 상기 대상체와 연관된 대상체 속성 정보, 상기 대상체와 연관된 대상체 색상 정보, 및 상기 대상체와 연관된 제1 검출 신뢰도 점수를 출력함 —; 상기 대상체의 상기 제1 공간적 위치, 맵 정보, 및 카메라 캘리브레이션 정보에 기초하여 각도 정보를 결정하고; 제2 시맨틱 세그먼트화 네트워크를 실행하며 — 실행할 때, 상기 제2 시맨틱 세그먼트화 네트워크는 제2 센서 데이터, 상기 각도 정보, 상기 대상체 속성 정보, 상기 대상체 색상 정보, 및 상기 제1 검출 신뢰도 점수를 입력으로서 획득하고, 제2 공간적 위치 및 제2 검출 신뢰도 점수와 연관된 데이터를 출력함 —; 상기 제1 공간적 위치, 제1 검출 신뢰도 점수, 제2 공간적 위치 및 제2 검출 신뢰도 점수에 기초하여 차량이 제어되게 하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>51. 제50항에 있어서, 상기 각도 정보는 맵 정보 및 카메라 캘리브레이션 정보에 기초하여 결정되는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>52. 제50항 또는 제51항에 있어서, 상기 대상체 속성 정보는 상기 대상체의 대상체 분류와 연관된 모델에 기초하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>53. 제50항 내지 제52항 중 어느 한 항에 있어서, 상기 대상체 색상 정보는 상기 카메라 데이터에서 캡처되는 상기 대상체의 적색, 녹색, 및 청색 색상 값들인 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>54. 제50항 내지 제53항 중 어느 한 항에 있어서, 상기 대상체의 상기 대상체 속성 정보 또는 상기 대상체의 상기 대상체 색상 정보는 상기 대상체와 연관된 저반사율을 나타내는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>55. 제54항에 있어서, 상기 대상체와 연관된 상기 제1 검출 신뢰도 점수는 상기 대상체와 연관된 저반사율에 기초하여 상기 제2 검출 신뢰도 점수보다 더 정확하고, 상기 제2 시맨틱 세그먼트화 네트워크는 상기 제1 검출 신뢰도 점수에 기초하여 상기 제2 검출 신뢰도 점수를 업데이트하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>56. 제50항 내지 제55항 중 어느 한 항에 있어서, 상기 대상체는 흑색 차량이고, 상기 속성 정보는 흑색 차량들과 연관된 차량 모델에 기초하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo><claimInfo><claim>57. 제50항 내지 제56항 중 어느 한 항에 있어서, 상기 대상체는 어두운 옷을 입은 보행자이고, 상기 속성 정보는 보행자 모델에 기초하는 것인, 적어도 하나의 비일시적 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 매사추세츠주 보스턴 노던 애비뉴 ***</address><code>520200342330</code><country>미국</country><engName>Motional AD LLC</engName><name>모셔널 에이디 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 매사추세츠주 **...</address><code> </code><country>중국</country><engName>LUO, Lin</engName><name>루오 린</name></inventorInfo><inventorInfo><address>미국 매사추세츠주 **...</address><code> </code><country>미국</country><engName>WANG, Ting</engName><name>왕 팅</name></inventorInfo><inventorInfo><address>미국 매사추세츠주 **...</address><code> </code><country>중국</country><engName>FU, Geng</engName><name>푸 겡</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.10.14</priorityApplicationDate><priorityApplicationNumber>63/416,487</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.05.13</receiptDate><receiptNumber>1-1-2025-0534427-73</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.05.21</receiptDate><receiptNumber>1-5-2025-0084870-91</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257015704.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930df2a32458d87f3b59212d130651a3fedd8fa54f2dc02778f706c042eea7e8dcaac93bf405ed88564e75135f5eab63a473b0cb7669719e78</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa53785a25e63a6bdf2cbb8d797d231b3f542e393eed4b46d2f0df6152164b6031f606ab39b1d2bc1e14234e9d922b662759d0683f0a03ef3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>