<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:34:59.3459</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.04.14</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0046172</applicationNumber><claimCount>18</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전자 장치 및 그 제어 방법</inventionTitle><inventionTitleEng>Electronic device and control method thereof</inventionTitleEng><openDate>2023.04.24</openDate><openNumber>10-2023-0054242</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/28</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/58</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치가 개시된다. 전자 장치는 마이크, 통신 회로를 포함하는 통신 인터페이스, 제1 언어에 대응되는 제1 인코더 및 제1 디코더를 저장하는 메모리 및 마이크를 통해 제1 언어의 사용자 음성이 수신되면, 사용자 음성에 대응되는 제1 언어의 텍스트를 획득하고, 제1 언어의 텍스트를 제1 인코더에 입력하여 제1 특징 벡터를 획득하고, 통신 인터페이스를 통해 제1 특징 벡터를 외부 장치로 전송하며, 통신 인터페이스를 통해 외부 장치로부터 제2 특징 벡터가 수신되면, 제2 특징 벡터를 제1 디코더에 입력하여 제2 특징 벡터에 대응되는 제1 언어의 텍스트를 획득하는 프로세서를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치에 있어서,마이크;통신 회로를 포함하는 통신 인터페이스;제1 언어에 대응되는 제1 인코더 및 제1 디코더를 저장하는 메모리; 및상기 마이크를 통해 상기 제1 언어의 사용자 음성이 수신되면, 상기 사용자 음성에 대응되는 상기 제1 언어의 텍스트를 획득하고, 상기 제1 언어의 텍스트를 상기 제1 인코더에 입력하여 제1 특징 벡터를 획득하고,상기 통신 인터페이스를 통해 상기 제1 특징 벡터를 외부 장치로 전송하며,상기 통신 인터페이스를 통해 상기 외부 장치로부터 제2 특징 벡터가 수신되면, 상기 제2 특징 벡터를 상기 제1 디코더에 입력하여 상기 제2 특징 벡터에 대응되는 상기 제1 언어의 텍스트를 획득하는 프로세서;를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 인코더는,제1 언어의 제1 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트 및 상기 벡터 공간 상의 상기 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제2 언어에 대응되는 상기 제2 인코더는, 상기 외부 장치에 포함되며, 상기 제2 언어의 사용자 음성에 대응되는 텍스트가 입력되면, 상기 제2 특징 벡터를 출력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 제1 디코더는,벡터 공간 상의 특징 벡터 및 제1 언어의 제1 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 상기 벡터 공간 상의 상기 특징 벡터 및 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 전자 장치. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 제2 언어에 대응되는 상기 제2 디코더는, 상기 외부 장치에 포함되며, 상기 전자 장치로부터 수신된 상기 제1 특징 벡터가 입력되면, 상기 제2 언어의 텍스트를 출력하는, 전자 장치. </claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 프로세서는,상기 외부 장치와 통신을 수행하여 상기 외부 장치가 상기 제2 언어에 대응되는 제2 디코더를 포함하는지 여부를 식별하고, 상기 외부 장치가 상기 제2 디코더를 포함하는 것으로 식별되면, 상기 제1 특징 벡터를 상기 외부 장치로 전송하고, 상기 외부 장치가 상기 제2 디코더를 포함하지 않는 것으로 식별되면, 상기 제1 특징 벡터를 서버로 전송하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,스피커;를 더 포함하며, 상기 프로세서는,TTS(Text to speech)를 이용하여 상기 제1 언어의 텍스트에 대응되는 상기 제1 언어의 사운드를 획득하고, 상기 제1 언어의 사운드를 상기 스피커를 통해 출력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 메모리는,컴프레서(compressor) 및 디컴프레서(decompressor)를 더 포함하며,상기 프로세서는,상기 컴프레서에 기초하여 상기 제1 특징 벡터를 압축하며, 상기 압축된 제1 특징 벡터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하고, 상기 외부 장치로부터 압축된 제2 특징 벡터가 수신되면, 상기 디컴프레서에 기초하여 상기 압축된 제2 특징 벡터를 압축 해제하고, 상기 압축 해제된 제2 특징 벡터를 상기 제1 디코더에 입력하는, 전자 장치. </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 인코더 및 상기 제1 디코더는,신경망 기계 번역(Neural machine translation, NMT) 모델에 포함되며,상기 신경망 기계 번역 모델은, 상기 사용자 음성이 입력되면, 상기 사용자 음성에 대응되는 텍스트를 벡터 값으로 변환하여 상기 제1 특징 벡터를 획득하며,상기 제2 특징 벡터가 입력되면, 상기 제2 특징 벡터를 상기 제1 언어의 텍스트로 변환하는, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 전자 장치의 제어 방법에 있어서,상기 제1 언어의 사용자 음성이 수신되면, 상기 사용자 음성에 대응되는 상기 제1 언어의 텍스트를 획득하는 단계;상기 제1 언어의 텍스트를 상기 제1 언어에 대응되는 제1 인코더에 입력하여 제1 특징 벡터를 획득하는 단계;상기 제1 특징 벡터를 외부 장치로 전송하는 단계; 및상기 외부 장치로부터 제2 특징 벡터가 수신되면, 상기 제2 특징 벡터를 상기 제1 언어에 대응되는 제1 디코더에 입력하여 상기 제2 특징 벡터에 대응되는 상기 제1 언어의 텍스트를 획득하는 단계;를 포함하는 제어 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 제1 인코더는,제1 언어의 제1 텍스트 및 벡터 공간 상의 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 인코더는, 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트 및 상기 벡터 공간 상의 상기 특징 벡터를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 제어 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 제2 언어에 대응되는 상기 제2 인코더는, 상기 외부 장치에 포함되며, 상기 제2 언어의 사용자 음성에 대응되는 텍스트가 입력되면, 상기 제2 특징 벡터를 출력하는, 제어 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 제1 디코더는,벡터 공간 상의 특징 벡터 및 제1 언어의 제1 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델이고,상기 제1 언어와 상이한 제2 언어에 대응되는 제2 디코더는, 상기 벡터 공간 상의 상기 특징 벡터 및 상기 제1 텍스트와 임계 값 이상의 유사도를 가지는 제2 언어의 제2 텍스트를 입력 데이터 및 출력 데이터로 하여 학습된 모델인, 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 제2 언어에 대응되는 상기 제2 디코더는, 상기 외부 장치에 포함되며, 상기 전자 장치로부터 수신된 상기 제1 특징 벡터가 입력되면, 상기 제2 언어의 텍스트를 출력하는, 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 외부 장치와 통신을 수행하여 상기 외부 장치가 상기 제2 언어에 대응되는 제2 디코더를 포함하는지 여부를 식별하는 단계;상기 외부 장치가 상기 제2 디코더를 포함하는 것으로 식별되면, 상기 제1 특징 벡터를 상기 외부 장치로 전송하는 단계; 및 상기 외부 장치가 상기 제2 디코더를 포함하지 않는 것으로 식별되면, 상기 제1 특징 벡터를 서버로 전송하는 단계;를 더 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>16. 제10항에 있어서,TTS(Text to speech)를 이용하여 상기 제1 언어의 텍스트에 대응되는 상기 제1 언어의 사운드를 획득하는 단계; 및상기 제1 언어의 사운드를 출력하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제10항에 있어서,컴프레서에 기초하여 상기 제1 특징 벡터를 압축하는 단계;상기 압축된 제1 특징 벡터를 상기 통신 인터페이스를 통해 상기 외부 장치로 전송하는 단계;상기 외부 장치로부터 압축된 제2 특징 벡터가 수신되면, 디컴프레서에 기초하여 상기 압축된 제2 특징 벡터를 압축 해제하는 단계; 및상기 압축 해제된 제2 특징 벡터를 상기 제1 디코더에 입력하는 단계;를 더 포함하는, 전자 장치. </claim></claimInfo><claimInfo><claim>18. 제11항에 있어서,상기 제1 인코더 및 상기 제1 디코더는,신경망 기계 번역(Neural machine translation, NMT) 모델에 포함되며,상기 신경망 기계 번역 모델은, 상기 사용자 음성이 입력되면, 상기 사용자 음성에 대응되는 텍스트를 벡터 값으로 변환하여 상기 제1 특징 벡터를 획득하며,상기 제2 특징 벡터가 입력되면, 상기 제2 특징 벡터를 상기 제1 언어의 텍스트로 변환하는, 제어 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, So Yoon</engName><name>박소윤</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LIM, Sung Jun</engName><name>임성준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Jong Hyun</engName><name>김종현</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Ji Wan</engName><name>김지완</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KIM, Hak Jung</engName><name>김학중</name></inventorInfo><inventorInfo><address>경기도 수원시 권선구...</address><code> </code><country> </country><engName>KIM, Hyun Kyung</engName><name>김현경</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>PARK, So Hyun</engName><name>박소현</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>LEE, In Dong</engName><name>이인동</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2021.10.15</priorityApplicationDate><priorityApplicationNumber>1020210137491</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.04.14</receiptDate><receiptNumber>1-1-2022-0398735-69</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.02.20</receiptDate><receiptNumber>1-1-2025-0196947-63</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220046172.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9366ec45828b6ee5bb44145bf297176300692dabb868bda34431967360abdfb4e1a67e17c6a7bced5ad30ea1f6742be52171da27b8f059f8b8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf8aadde06030388be8c8c1e1d343a7b36de3f0411905761c299a0236c3362022e6d4df322f8e1d0b98b7d025e69fdad20f2b5c3a79b1e39e8</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>