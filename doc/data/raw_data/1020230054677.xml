<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:56.1056</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.04.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0054677</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>이미지의 부분 영역을 뉴럴 네트워크로 입력한 것에 기반하여 외부 객체를 식별하기 위한 전자 장치 및 그 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE FOR IDENTIFYING EXTERNAL OBJECT  BASED ON INPUTTING PARTIAL AREA OF IMAGE TO NEURAL  NETWORK</inventionTitleEng><openDate>2024.11.05</openDate><openNumber>10-2024-0158411</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/26</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/12</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/24</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06V 10/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/56</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/422</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/62</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G08B 3/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G08B 5/22</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시 예에 따른, 전자 장치(electronic device)는, 카메라, 및 프로세서를 포함할 수 있다. 상기 프로세서는, 상기 카메라를 통하여 획득된 이미지의 FOV(field of view)에 기반하여, 상기 이미지의 분할에 이용될 윈도우의 너비(width)를 식별할 수 있다. 상기 프로세서는, 기준 면(reference surface)에 대응하는 시각적 객체를 포함하는 제1 영역에 기반하여 상기 윈도우의 높이(height)를 식별할 수 있다. 상기 프로세서는, 상기 너비 및 상기 높이에 기반하여, 상기 윈도우를 이용하여, 상기 제1 영역을 복수의 부분 영역들로 분할할 수 있다. 상기 프로세서는, 상기 복수의 부분 영역들 중 제1 부분 영역이 입력된 뉴럴 네트워크로부터, 외부 객체가 상기 제1 부분 영역에 포함되는지 여부를 식별할 수 있다. 상기 프로세서는, 상기 외부 객체가 상기 제1 부분 영역에 포함되는지 여부에 기반하여 식별된 간격에 기반하여, 상기 이미지에서 상기 제1 부분 영역으로부터 이격된 제2 부분 영역을 획득할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 전자 장치(electronic device)에 있어서,  카메라; 및  프로세서를 포함하고;  상기 프로세서는,  상기 카메라를 통하여 획득된 이미지의 FOV(field of view)에 기반하여, 상기 이미지의 분할에 이용될 윈도우의 너비(width)를 식별하고;  기준 면(reference surface)에 대응하는 시각적 객체를 포함하는 제1 영역에 기반하여 상기 윈도우의 높이(height)를 식별하고;  상기 너비 및 상기 높이에 기반하여, 상기 윈도우를 이용하여, 상기 제1 영역을 복수의 부분 영역들로 분할하고;  상기 복수의 부분 영역들 중 제1 부분 영역이 입력된 뉴럴 네트워크로부터, 외부 객체가 상기 제1 부분 영역에 포함되는지 여부를 식별하고;  상기 외부 객체가 상기 제1 부분 영역에 포함되는지 여부에 기반하여 식별된 간격에 기반하여, 상기 이미지에서 상기 제1 부분 영역으로부터 이격된 제2 부분 영역을 획득하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,  상기 프로세서는,  상기 카메라에 의한, 제1 이미지인 상기 이미지의 왜곡(distortion)을 식별하고; 및  상기 제1 이미지와 상이하고, 상기 왜곡을 보상한 제2 이미지에 기반하여, 상기 외부 객체를 식별하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,  상기 프로세서는,  상기 복수의 부분 영역들을 상기 너비의 제1 비율만큼 부분적으로 중첩하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>4. 제3 항에 있어서,  센서를 더 포함하고;  상기 프로세서는,  상기 센서에 기반하여, 제1 기준 속력 이하인, 상기 전자 장치의 제1 속력의 식별하고; 및  상기 제1 속력의 식별에 기반하여, 상기 이미지의 가장자리를 포함하는 제1 서브 영역에서, 상기 복수의 부분 영역들을, 상기 제1 비율보다 작은 제2 비율만큼 중첩하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>5. 제3 항에 있어서,  센서를 더 포함하고;  상기 프로세서는,  상기 센서에 기반하여, 제2 기준 속력 이상인, 상기 전자 장치의 제2 속력의 식별하고; 및  상기 제2 속력의 식별에 기반하여, 상기 이미지의 가장자리를 포함하는 제1 부분 영역과 상이한 제2 부분 영역에서, 상기 복수의 부분 영역들을, 상기 제1 비율보다 작은 제2 비율만큼 중첩하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,  스피커를 더 포함하고;  상기 프로세서는,  상기 외부 객체를 식별한 것에 기반하여, 상기 외부 객체가 식별됨을 알리기 위한 오디오 신호를 출력하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,  디스플레이를 더 포함하고;  상기 프로세서는,  상기 외부 객체를 식별한 것에 기반하여, 상기 외부 객체에 대응하는 시각적 객체를 표시하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>8. 제1 항에 있어서,  센서를 더 포함하고,  상기 프로세서는,  상기 센서를 이용하여 식별된 상기 카메라가 향하는 방향을 식별하고;  지정된 범위 내의 상기 방향을 식별한 것에 기반하여, 상기 높이를 식별하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,  상기 높이는 제1 높이이고,  상기 프로세서는,  상기 제2 영역의 제2 높이를 식별하고;  상기 제2 높이 및 상기 제1 높이의 차이를 식별한 것에 기반하여, 상기 이미지의 일부를 캡쳐한 상기 복수의 부분 영역들의 사이즈를 조절하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>10. 제9 항에 있어서,  상기 프로세서는,  상기 제2 높이 보다 작은 상기 제1 높이를 식별한 것에 기반하여, 상기 제2 영역의 일 꼭지점(vertex)을 포함하는, 제1 부분 영역을 식별하고;  상기 제1 부분 영역과 부분적으로 중첩되고, 상기 제1 부분 영역과 동일한 사이즈를 가지는 제2 부분 영역을 식별하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>11. 전자 장치(electronic device)에 있어서,  메모리; 및  프로세서를 포함하고,  상기 프로세서는,  상기 메모리에 저장된 이미지에서, 차선(line)에 의해 구분되는 복수의 차로들(lanes) 중에서 제1 차로에서 차량을 식별한 것에 기반하여, 상기 제1 차량에 관련된 제1 데이터 세트를 획득하고;  상기 복수의 차로들 중에서, 상기 제1 차로와 상이한 제2 차로에서 제2 차량을 식별한 것에 기반하여, 상기 제2 차량과 관련된 제2 데이터 세트를 획득하고;  상기 복수의 차로들 중에서, 상기 제1 차로 및 상기 제2 차로와 상이한 제3 차로에서 제3 차량을 식별한 것에 기반하여, 상기 제3 차량과 관련된 제3 데이터 세트를 획득하고;  상기 제1 데이터 세트, 상기 제2 데이터 세트, 및 상기 제3 데이터 세트 각각에 기반하는 진리 데이터(truth data)를 이용하여, 뉴럴 네트워크를 트레이닝하도록, 구성된,  전자 장치.  </claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,  상기 뉴럴 네트워크는,  상기 제1 데이터 세트, 상기 제2 데이터 세트 및 상기 제3 데이터 세트 각각에서 식별된 차량의 형태를 이용하여 트레이닝된,  전자 장치.  </claim></claimInfo><claimInfo><claim>13. 제11 항에 있어서,  상기 뉴럴 네트워크는,  상기 차량으로 식별된 제1 바운딩 박스 내에 포함된 하나 이상의 텍스트들을 포함하는 제1 바운딩 박스 내의 차량 번호판을 이용하여 트레이닝된,  전자 장치.  </claim></claimInfo><claimInfo><claim>14. 제13 항에 있어서,  상기 뉴럴 네트워크는,  상기 제2 영역에 포함된 하나 이상의 텍스트들에 대한 라벨링(labeling)을 이용하여 트레이닝된,  전자 장치.  </claim></claimInfo><claimInfo><claim>15. 전자 장치(electronic device)의 방법에 있어서,  카메라를 통하여 획득된 이미지의 FOV(field of view)에 기반하여, 상기 이미지의 분할에 이용될 윈도우의 너비(width)를 식별하는 동작;  기준 면(reference surface)에 대응하는 시각적 객체를 포함하는 제1 영역에 기반하여 상기 윈도우의 높이(height)를 식별하는 동작;  상기 너비 및 상기 높이에 기반하여, 상기 이미지에서 서로 부분적으로 중첩된 복수의 부분 영역들을 분할하는 동작;  상기 복수의 부분 영역들 중 제1 부분 영역이 입력된 뉴럴 네트워크로부터, 외부 객체가 상기 제1 부분 영역에 포함되는지 여부를 식별하는 동작; 및  상기 외부 객체가 상기 제1 부분 영역에 포함되는지 여부에 기반하여 식별된 간격에 기반하여, 상기 이미지에서 상기 제1 부분 영역으로부터 이격된 제2 부분 영역을 획득하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>16. 제15 항에 있어서,  상기 방법은,  상기 카메라에 의한, 제1 이미지인 상기 이미지의 왜곡(distortion)을 식별하는 동작; 및  상기 제1 이미지와 상이하고, 상기 왜곡을 보상한 제2 이미지에 기반하여, 상기 외부 객체를 식별하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>17. 제15 항에 있어서,  상기 방법은,  상기 복수의 부분 영역들을 상기 너비의 제1 비율만큼 부분적으로 중첩하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>18. 제17 항에 있어서,  상기 방법은,  센서에 기반하여, 제1 기준 속력 이하인, 상기 전자 장치의 제1 속력을 식별하는 동작; 및  상기 제1 속력의 식별에 기반하여, 상기 이미지의 가장자리를 포함하는 제1 부분 영역에서, 상기 복수의 부분 영역들을, 상기 제1 비율보다 작은 제2 비율만큼 중첩하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>19. 제17 항에 있어서,  상기 방법은,  센서에 기반하여, 제2 기준 속력 이상인, 상기 전자 장치의 제2 속력을 식별하는 동작; 및  상기 제2 속력의 식별에 기반하여, 상기 이미지의 가장자리를 포함하는 제1 부분 영역과 상이한 제2 부분 영역에서, 상기 복수의 부분 영역들을, 상기 제1 비율보다 작은 제2 비율만큼 중첩하는 동작을 포함하는,  방법.  </claim></claimInfo><claimInfo><claim>20. 제15 항에 있어서,  상기 방법은,  상기 외부 객체를 식별한 것에 기반하여, 상기 외부 객체가 식별됨을 알리기 위한 오디오 신호를 출력하는 방법을 포함하는,  방법.  </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>119990173084</code><country>대한민국</country><engName>THINKWARE CORPORATION</engName><name>팅크웨어(주)</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>Haejun JUNG</engName><name>정해준</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code> </code><country> </country><engName>Yosep PARK</engName><name>박요셉</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구  논현로**길  **, *층, *층 (도곡동, 덕영빌딩)</address><code>920191001617</code><country>대한민국</country><engName>KWANG AND JANG PATENT LAW FIRM</engName><name>특허법인광앤장</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.04.26</receiptDate><receiptNumber>1-1-2023-0469372-77</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230054677.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93d4c396a94fe92668e41448f0a106a177ef869fc4e2f9b2d53a8181ba9a9513a07e0352e484512bb094938ba4f58eacbff8cc0159e0134e43</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbc2473614032e46f3582fedb30d2b7b280f39c1909c227309fc6ee55bcd1a3c77c83a5b2e68ec8efbbd44773ca0de174a51c78788d777c9a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>