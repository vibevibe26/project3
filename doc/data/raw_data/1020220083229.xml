<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:10.4110</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.07.06</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0083229</applicationNumber><claimCount>43</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>정보 검색을 위한 희소 표현을 생성하는 뉴럴 랭킹 모델</inventionTitle><inventionTitleEng>NEURAL RANKING MODEL FOR GENERATING SPARSE  REPRESENTATIONS FOR INFORMATION RETRIEVAL</inventionTitleEng><openDate>2023.07.07</openDate><openNumber>10-2023-0103895</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.08.31</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/2457</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/284</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/237</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/048</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 뉴럴 정보 검색 모델의 랭커에서 어휘에 대한 입력 시퀀스를 표현하기 위한 뉴럴 모델이다. 입력 시퀀스는 적어도 상기 어휘에 기초하여 임베딩된다. 상기 어휘에 대한 각 토큰의 중요성은 상기 임베딩된 입력 시퀀스의 각 토큰에 대해 예측된다. 상기 어휘에 대한 상기 입력 시퀀스의 예측된 용어 중요도는 상기 임베딩된 입력 시퀀스에 대한 활성화 수행에 의해 결정된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 뉴럴 정보 검색 모델의 랭커에서 어휘에 대한 입력 시퀀스의 표현을 제공하기 위한 프로세서 및 메모리를 갖는 컴퓨터에 의해 구현되는 방법에 있어서, 상기 방법은: 임베딩된 입력 시퀀스를 제공하기 위해 적어도 상기 어휘에 기초하여 토큰화된 입력 시퀀스의 각 토큰을 임베딩하는 단계-상기 토큰화된 입력 시퀀스는 상기 어휘를 이용하여 토큰화됨-; 상기 임베딩된 입력 시퀀스의 각 토큰과 관련하여 상기 어휘에 대한 각 토큰의 중요도의 예측을 결정하는 단계; 상기 임베딩된 입력 시퀀스에 대한 활성화를 수행함으로써 상기 어휘에 대한 입력 시퀀스의 표현으로서 상기 입력 시퀀스의 예측된 용어 중요도를 획득하는 단계; 및 상기 뉴럴 정보 검색 모델의 상기 랭커에서 상기 어휘에 대한 상기 입력 시퀀스의 상기 표현으로 상기 입력 시퀀스의 상기 예측된 용어 중요도를 출력하는 단계를 포함하고, 상기 임베딩하는 단계 및 상기 예측을 결정하는 단계는 미리 훈련된 언어 모델에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 활성화는 오목 활성화 함수(concave activation function)를 포함하는 방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 오목 활성화 함수는 대수 활성화 함수(logarithmic activation function) 또는 라디칼 함수(radical function)를 포함하는 방법. </claim></claimInfo><claimInfo><claim>4. 제2항에 있어서, 상기 오목 활성화 함수는 대수 활성화 함수를 포함하고, 상기 대수 활성화는:상기 어휘의 각 토큰에 대해, 상기 임베딩된 입력 시퀀스에 대한 상기 어휘의 상기 결정된 토큰 중요도의 최대 로그 포화를 결정하는 것을 포함하고, 상기 로그 포화는 상기 어휘의 일부 용어들이 지배적인 것(dominating)을 방지하고 상기 표현의 희소성을 보장하는 방법. </claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 오목 활성화 함수는 대수 활성화 함수를 포함하고, 상기 대수 활성화는: 상기 어휘의 각 토큰에 대해, 상기 임베딩된 입력 시퀀스에 대한 상기 어휘의 상기 결정된 토큰 중요도의 로그 포화를 결합하는 것을 포함하고, 상기 로그 포화는 상기 어휘의 일부 용어들이 지배적인 것을 방지하고 상기 표현의 희소성을 보장하는 방법. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 어휘를 사용하여 수신된 쿼리를 토큰화하는 단계; 복수의 후보 시퀀스들 각각에 대한 랭킹 점수를 결정하는 단계; 상기 결정된 랭킹 점수에 기초하여 상기 복수의 후보 시퀀스들을 랭킹화하는 단계; 및 가장 높은 랭킹을 갖는 후보 문서들의 서브세트를 검색하는 단계를 더 포함하고, 상기 후보 시퀀스들은 후보 문서들과 각각 연관되고, 상기 랭킹 순위를 결정하는 단계는:상기 토큰화된 쿼리의 각 어휘 토큰에 대해 상기 후보 시퀀스에 대한 상기 출력 예측 용어 중요도(output predicted term importance)를 결정하는 단계; 및상기 결정된 출력 예측 용어 중요도를 결합하는 단계를 포함하는 방법. </claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 랭커는 상기 정보 검색 모델의 제1 스테이지에 있고, 상기 정보 검색 모델은 재랭커 스테이지(re-ranker stage)인 제2 스테이지를 더 포함하는 방법. </claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 입력 시퀀스에 대한 출력 예측 용어 중요도를 복수의 후보 시퀀스들 각각에 대해 미리 결정된 예측 용어 중요도(predicted term importance)와 비교하는 단계-상기 후보 시퀀스들은 후보 문서들과 각각 연관됨-; 상기 비교하는 단계에 기초하여 상기 복수의 후보 시퀀스들을 랭킹화하는 단계; 및 가장 높은 랭킹을 갖는 상기 후보 문서들의 서브세트를 검색하는 단계를 더 포함하는 방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 비교하는 단계는 상기 입력 시퀀스의 출력 예측 용어 중요도와 상기 복수의 후보 시퀀스들 각각에 대한 상기 예측 용어 중요도 간의 내적을 계산하는 단계를 포함하는 방법. </claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 토큰화된 입력 시퀀스의 각 토큰을 임베딩하는 단계는 컨텍스트 임베딩된 토큰들(context embedded tokens)을 제공하기 위해 적어도 어휘 및 상기 입력 시퀀스 내의 토큰의 위치에 기초하는 방법. </claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 예측을 결정하는 단계는: 상기 임베딩된 입력 시퀀스의 각 토큰에 관한 상기 어휘의 각 토큰의 중요도를 예측하기 위해 적어도 하나의 로짓 함수(logit function)를 사용하여 상기 컨텍스트 임베딩된 토큰들을 변환하는 단계를 포함하는 방법. </claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 적어도 하나의 로짓 함수는 활성화 및 정규화 레이어를 각각 포함하는 하나 이상의 선형 레이어들에 의해 제공되고; 상기 하나 이상의 선형 레이어는 상기 임베딩된 입력 시퀀스의 상기 각 어휘 토큰을 갖는 변환(transformation)과 토큰 레벨 바이어스(token-level bias)를 결합하는 방법. </claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 미리 훈련된 언어 모델은 트랜스포머 아키텍처(transformer architecture)를 포함하는 방법. </claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 언어 모델은 마스킹된 언어 모델링 방법을 사용하여 미리 훈련되는방법. </claim></claimInfo><claimInfo><claim>15. 제1항에 있어서, 오목 활성화 함수를 수행하는 단계는, 상기 임베딩된 입력 시퀀스의 각 토큰에 대해, 상기 결정된 용어 가중치들의 긍정(positivity)을 보장하기 위해 상기 임베딩된 입력 시퀀스에 대한 상기 어휘의 결정된 토큰 중요도에 활성화 함수를 적용하는 단계; 및 상기 활성화 함수의 결과에 대해 오목 함수를 수행하는 단계를 포함하는 방법. </claim></claimInfo><claimInfo><claim>16. 뉴럴 정보 검색 모델의 랭커에서 어휘에 대한 입력 시퀀스의 표현을 제공하기 위한 프로세서 및 메모리를 갖는 컴퓨터에 의해 구현되는 뉴럴 모델에 있어서, 상기 모델은: 컨텍스트 임베딩된 토큰들(context embedded tokens)을 제공하기 위해 임베딩된 입력 시퀀스 내의 컨텍스트 특징들(contextual features)로 토큰화된 입력 시퀀스의 각 토큰을 임베딩하고, 하나 이상의 선형 레이어들을 사용하여 상기 컨텍스트 임베딩된 토큰들을 변환함으로써 상기 어휘에 대해 상기 임베딩된 입력 시퀀스의 각 토큰에 관한 중요도를 예측하도록 구성되는 미리 훈련된 언어 모델 레이어-상기 토큰화된 입력 시퀀스는 상기 어휘를 사용하여 토큰화됨-; 및 상기 어휘에 대한 각 토큰에 관하여 예측된 중요도를 수신하고 상기 어휘에 대한 상기 입력 시퀀스의 예측된 용어 중요도를 획득하도록 구성되는 표현 레이어-상기 표현 레이어는 상기 임베딩된 입력 시퀀스에 대해 예측된 중요도의 오목 활성화를 수행하도록 구성된 오목 활성화 레이어를 포함함-; 상기 표현 레이어는 상기 뉴럴 정보 검색 모델의 랭커에서 상기 어휘에 대한 상기 입력 시퀀스의 표현으로서 상기 입력 시퀀스의 예측된 용어 중요도를 출력하는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 입력 시퀀스의 예측된 용어 중요도는 문서를 검색하기 위해 사용되고; 그리고상기 미리 훈련된 언어 모델 레이어는 상기 입력 시퀀스 내의 토큰의 위치 상에 적어도 부분적으로 기초하여 토큰화된 입력 시퀀스의 각 토큰을 임베딩하도록 추가로 구성되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>18. 제16항에 있어서, 상기 미리 훈련된 언어 모델 레이어는 MLM(Masked Language Model) 훈련 방법을 사용하여 미리 훈련되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>19. 제16항에 있어서, 상기 미리 훈련된 언어 모델 레이어는 BERT(Bidirectional Encoder Representations from Transformers) 모델을 포함하는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>20. 제16항에 있어서, 상기 하나 이상의 선형 레이어 각각은 활성화 및 정규화 레이어를 포함하는 로짓 함수(logit function)를 포함하고, 상기 선형 레이어들은 상기 임베딩된 입력 시퀀스의 각 어휘 토큰을 갖는 변환(transformation)과 토큰-레벨 바이어스(token-level bias)를 결합하는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>21. 제16항에 있어서, 상기 오목 활성화 레이어는, 상기 어휘의 각 토큰에 대해, 상기 어휘 및 상기 임베딩된 입력 시퀀스에 대해 결정된 토큰 중요도의 로그 포화를 결합하거나 최대화하도록 구성되고, 상기 로그 포화는 상기 어휘의 용어들이 지배적인 것을 방지하고 상기 표현에 희소성을 제공하는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>22. 제16항에 있어서,상기 오목 활성화 레이어는 상기 결정된 토큰 중요도의 긍정(positivity)을 보장하기 위해 상기 임베딩된 입력 시퀀스에 대한 상기 어휘의 결정된 토큰 중요도에 활성화 함수를 적용하고, 상기 활성화 함수의 결과에 대해 오목 함수를 적용하도록 구성되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>23. 제16항에 있어서, 상기 뉴럴 모델은 제1 스테이지 랭커(first-stage ranker)에 통합되고; 상기 제1 스테이지 랭커는:상기 입력 시퀀스에 대해 예측된 용어 중요도를 상기 뉴럴 모델에 의해 생성되는 복수의 후보 시퀀스들 각각에 대해 예측된 용어 중요도와 비교하고, 상기 후보 시퀀스들은 후보 문서들과 각각 연관되고; 상기 비교에 기초하여 상기 복수의 후보 시퀀스들을 랭크하고; 가장 높은 랭킹을 갖는 문서들의 서브세트를 검색하도록 추가로 구성되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 비교하는 단계는 상기 복수의 후보 시퀀스들 각각에 대해 상기 예측된 용어 중요도와 상기 출력 예측 용어 중요도(output predicted term importance) 간의 내적을 계산하는 단계를 포함하는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>25. 제16항에 있어서, 상기 뉴럴 모델은 상기 제1 스테이지 랭커에 통합되고; 상기 제1 스테이지 랭커는: 상기 뉴럴 모델을 사용하여 복수의 후보 문서들 각각에 대한 랭킹 점수를 결정하고; 상기 결정된 랭킹 점수에 기초하여 상기 복수의 후보 문서들을 랭킹화하도록 추가로 구성되고; 상기 랭킹 점수를 결정하는 단계는: 상기 어휘에 대한 각 후보 문서의 표현을 결정하고; 상기 랭킹 점수를 결정하기 위해 상기 결정된 표현을 수신된 입력 시퀀스의 표현과 비교하고; 상기 제1 스테이지 랭커는 가장 높은 랭킹을 갖는 상기 문서들의 서브세트를 검색하도록 추가로 구성되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 새로운 입력 시퀀스의 표현은 상기 뉴럴 모델을 사용하여 결정되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>27. 제25항에 있어서, 상기 새로운 입력 시퀀스의 표현은 적어도 상기 어휘에 대해 상기 새로운 입력 시퀀스를 토큰화함으로써 결정되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>28. 제25항에 있어서, 상기 어휘의 각 후보 문서에 대한 표현을 결정하는 단계는 오프라인으로 수행되는 뉴럴 모델. </claim></claimInfo><claimInfo><claim>29. 정보 검색기의 랭커에서 어휘에 대한 입력 시퀀스의 표현을 제공하기 위한 뉴럴 모델의 훈련을 위한 컴퓨터 구현 방법에 있어서, 상기 방법은: 상기 뉴럴 모델을 제공하는 단계 -상기 뉴럴 모델은: (i) 상기 어휘를 사용하여 입력 시퀀스를 토큰화하도록 구성되는 토크나이저 레이어; (ii) 적어도 상기 어휘에 기초하여 상기 토큰화된 입력 시퀀스의 각 토큰을 임베딩하도록 구성되는 입력 임베딩 레이어; (iii) 상기 어휘에 대한 상기 입력 시퀀스의 각 토큰에 대한 중요도를 예측하도록 구성되는 예측기 레이어; 및 (iv) 상기 어휘에 대한 각 토큰에 대해 상기 예측된 중요도를 수신하고, 상기 어휘에 대한 상기 입력 시퀀스의 예측된 용어 중요도를 획득하도록 구성되는 표현 레이어를 갖고, 상기 표현 레이어는 상기 입력 시퀀스에 대해 예측된 중요도의 오목 활성화를 수행하도록 구성되는 오목 활성화 레이어를 포함함-; 상기 뉴럴 모델의 파라미터들을 초기화하는 단계; 및 복수의 문서들을 포함하는 데이터세트를 사용하여 상기 뉴럴 모델을 훈련하는 단계를 포함하고, 상기 뉴럴 모델을 훈련하는 단계는 랭킹 손실 및 적어도 하나의 희소 정규화 손실을 포함하는 손실을 공동으로 최적화하고; 상기 랭킹 손실 및/또는 상기 적어도 하나의 희소 정규화 손실은 가중치 파라미터에 의해 가중되는 방법. </claim></claimInfo><claimInfo><claim>30. 제29항에 있어서, 상기 데이터세트는 복수의 문서들을 포함하는 방법. </claim></claimInfo><claimInfo><claim>31. 제29항에 있어서, 상기 데이터세트는 복수의 쿼리들을 포함하고, 각 쿼리들에 대해, 상기 쿼리와 연관된 적어도 하나의 긍정(positive) 문서 및 상기 쿼리와 연관되지 않은 적어도 하나의 부정(negative) 문서를 포함하는 방법. </claim></claimInfo><claimInfo><claim>32. 제31항에 있어서,상기 훈련은 복수의 배치들을 사용하고; 상기 각 배치는 복수의 쿼리들을 포함하고, 각 쿼리들에 대해, 각각은: 상기 쿼리와 연관된 긍정 문서, 다른 쿼리들과 연관된 긍정 문서인 적어도 하나의 부정 문서, 및 상기 배치 내의 어떠한 쿼리들과 연관되지 않은 적어도 하나의 하드 부정(hard negative) 문서를 포함하고, 상기 적어도 하나의 하드 부정 문서는 모델을 샘플링하여 생성되는 방법. </claim></claimInfo><claimInfo><claim>33. 제32항에 있어서, 상기 쿼리와 연관되지 않은 상기 적어도 하나의 부정 문서는 랭킹 모델에 의해 생성되는 방법. </claim></claimInfo><claimInfo><claim>34. 제29항에 있어서,상기 희소 정규화 손실이 각 쿼리들 및 문서들에 대해 계산되고, 각각은 가중치 파라미터에 의해 가중되는 방법. </claim></claimInfo><claimInfo><claim>35. 제29항에 있어서, 상기 희소 정규화 손실은: 상기 뉴럴 모델에 의해 생성되는 희소 표현의  놈(norm)을 최소화하기 위한  정규화 손실; 또는문서들의 점수를 계산하기 위한 부동 소수점 연산들(floating-point operations)의 평균 수를 완화하기 위한 FLOPS 정규화 손실중 하나 이상을 포함하는 방법. </claim></claimInfo><claimInfo><claim>36. 제29항에 있어서,생선된 훈련 트리플릿들(triplets)을 사용하여 제1스테이지 랭커 및 재랭커를 정제(distillation) 훈련하는 단계-각 트리플릿은 쿼리, 관련 구절 및 비-관련 구절을 포함함-; 새로운 훈련 트리플릿들을 생성하기 위해 상기 훈련된 제1스테이지 랭커를 사용하는 단계-상기 생성된 트리플릿들은 더 하드한 부정들(harder negatives)을 포함함-;상기 생성된 새로운 트레이닝 트리플릿들로부터 원하는 점수들을 생성하기 위해 상기 훈련된 재랭커를 사용하는 단계; 및 상기 생성된 새로운 훈련 트리플릿들 및 원하는 점수들을 사용하여 제1 스테이지 랭커를 2차 훈련하는 단계를 포함하는 방법. </claim></claimInfo><claimInfo><claim>37. 제36항에 있어서, 상기 2차 훈련은 처음(scratch)부터 시작하는 방법. </claim></claimInfo><claimInfo><claim>38. 제36항에 있어서,상기 훈련은 오프라인으로 수행되는 방법. </claim></claimInfo><claimInfo><claim>39. 뉴럴 정보 검색 모델의 제1 스테이지 랭커의 어휘에 대한 입력 시퀀스의 표현을 제공하는 방법을 구현하기 위한 프로세서 및 메모리로 인해 실행 가능한 명령어들이 저장된 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 방법은: 토큰들의 임베딩된 입력 시퀀스를 제공하기 위해 적어도 상기 어휘에 기초하여 토큰화된 입력 시퀀스의 각 토큰을 임베딩하는 단계-상기 토큰화된 입력 시퀀스는 상기 어휘를 사용하여 토큰화됨-;상기 임베딩된 입력 시퀀스의 각 토큰과 관련하여 상기 어휘에 대한 각 토큰의 중요도의 예측을 결정하는 단계;상기 임베딩된 입력 시퀀스에 대해 오목 활성화 함수를 사용하여 활성화를 수행함으로써 상기 어휘에 대한 입력 시퀀스의 표현으로서 상기 입력 시퀀스의 예측된 용어 중요도를 획득하는 단계; 및상기 예측된 용어 중요도를 출력하는 단계를 포함하고,  상기 임베딩하는 단계 및 상기 예측을 결정하는 단계는 미리 훈련된 언어 모델에 의해 수행되는 방법. </claim></claimInfo><claimInfo><claim>40. 입력 시퀀스를 처리하기 위한 계산 구현 방법에 있어서, 상기 방법은: 토큰들의 임베딩된 입력 시퀀스를 제공하기 위해 적어도 미리 결정된 어휘에 기초하여 토큰화된 입력 시퀀스의 각 토큰을 임베딩하는 단계; 상기 미리 결정된 어휘에 대한 토큰들의 임베딩된 입력 시퀀스의 용어 중요도를 예측하는 단계; 및 상기 토큰들의 입력 시퀀스의 예측된 용어 중요도를 출력하는 단계를 포함하고, 상기 토큰들의 입력 시퀀스의 상기 예측된 용어 중요도는 뉴럴 정보 검색 모델의 제1 스테이지 랭커에서 미리 결정된 어휘에 대한 상기 입력 시퀀스의 표현을 제공하는 방법. </claim></claimInfo><claimInfo><claim>41. 제40항에 있어서, 상기 임베딩하는 단계 및 상기 예측하는 단계는 미리 훈련된 언어 모델을 사용하는 방법. </claim></claimInfo><claimInfo><claim>42. 제40항에 있어서, 상기 예측하는 단계는 상기 어휘에 대한 각 토큰의 중요도에 의해 상기 어휘에 대한 입력 시퀀스의 표현으로서 상기 입력 시퀀스의 예측된 용어 중요도를 획득하는 방법. </claim></claimInfo><claimInfo><claim>43. 제42항에 있어서, 상기 입력 시퀀스는 쿼리 및 문서 시퀀스 중 어느 하나인 방법. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 성남시 분당구...</address><code>119990373888</code><country>대한민국</country><engName>NAVER Corporation</engName><name>네이버 주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>프랑스 메일랑 ***** 체...</address><code> </code><country> </country><engName>CLINCHANT, Stephane</engName><name>클린찬트, 스테판 </name></inventorInfo><inventorInfo><address>프랑스 메일랑 ***** 체...</address><code> </code><country> </country><engName>FORMAL, Thibault</engName><name>포말, 티보</name></inventorInfo><inventorInfo><address>프랑스 메일랑 ***** 체...</address><code> </code><country> </country><engName>LASSANCE, Carlos</engName><name>라상스, 카를로스</name></inventorInfo><inventorInfo><address>프랑스 파리 ****...</address><code> </code><country> </country><engName>PIWOWARSKI, Benjamin</engName><name>피보바르스키, 벤자민</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로***길 ** (논현동) 삼성빌딩 *층(피앤티특허법률사무소)</address><code>920050004530</code><country>대한민국</country><engName>Yang,Sung Bo</engName><name>양성보</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.30</priorityApplicationDate><priorityApplicationNumber>63/266,194</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.06.01</priorityApplicationDate><priorityApplicationNumber>17/804,983</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.07.06</receiptDate><receiptNumber>1-1-2022-0705579-56</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.07.12</receiptDate><receiptNumber>9-1-2022-9008113-97</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2022.07.12</receiptDate><receiptNumber>9-1-2022-9008103-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName> </documentEngName><documentName>외국어특허출원의 국어번역문 제출 안내서</documentName><receiptDate>2022.07.12</receiptDate><receiptNumber>1-5-2022-0103689-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2022.08.31</receiptDate><receiptNumber>1-1-2022-0914687-25</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName> </documentEngName><documentName>[특허법 제42조의3제2항,제42조의3제3항에 따른 국어번역문]서류제출서</documentName><receiptDate>2022.08.31</receiptDate><receiptNumber>1-1-2022-0914582-30</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2023.07.18</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220083229.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a2debee5e8f2b96544df136ccc7c883904db15532ebf1c8f4133ecda769bd3d0fd49fa117b025f2f319296d94cd5b11902c750381b5b82c1</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf08875553779b8c112a32ee21bf7098a411996988f8a97f53266de8baf744fbff54d32371a034e366df3846f91a077c637c4ed9c41f148cb7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>