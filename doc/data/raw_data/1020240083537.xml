<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:33:10.3310</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.06.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0083537</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>픽셀들의 깊이 값을 설정하기 위한 웨어러블 장치, 방법, 및 비일시적 컴퓨터 판독 가능 저장 매체</inventionTitle><inventionTitleEng>WEARABLE DEVICE, METHOD AND COMPUTER READABLE STORAGE MEDIUM  FOR SETTING DEPTH VALUE OF PIXELS</inventionTitleEng><openDate>2025.10.21</openDate><openNumber>10-2025-0151103</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/128</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/239</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/271</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/268</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/344</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/383</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 웨어러블 장치는, 하나 이상의 디스플레이들을 포함하는 디스플레이 어셈블리, 카메라들, 센서들, 인스트럭션들을 저장하고 하나 이상의 저장 매체들을 포함하는 메모리, 프로세싱 회로를 포함하는 적어도 하나의 프로세서를 포함할 수 있다. 상기 인스트럭션들은, 상기 적어도 하나의 프로세서에 의해 실행될 시, 이미지를 획득하고, 획득된 깊이 정보를 이용하여, 픽셀들이 각각 가지는 깊이 값들을 식별하고, 픽셀들의 개수를 식별하고, 상기 깊이 값들 중에서 기준 깊이 값을 식별하고, 상기 픽셀들의 제1 일부를 식별하고, 상기 픽셀들의 제2 일부를 식별하고, 및 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고 상기 픽셀들의 상기 제2 일부가 가지는 깊이 값들을 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리를 통해 표시하도록, 상기 웨어러블 장치를 야기할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 웨어러블 장치(110)에 있어서,하나 이상의 디스플레이들을 포함하는 디스플레이 어셈블리(230);하나 이상의 카메라들(130);하나 이상의 센서들(240);인스트럭션들을 저장하고, 하나 이상의 저장 매체들을 포함하는, 메모리(220); 및프로세싱 회로를 포함하는 적어도 하나의 프로세서(200)를 포함하고,상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  상기 하나 이상의 카메라들(130)을 통해 이미지를 획득하고,  상기 하나 이상의 카메라들(130) 및/또는 상기 하나 이상의 센서들(240)을 통해 획득된 깊이 정보를 이용하여, 상기 이미지 내의 픽셀들이 각각 가지는 깊이 값들을 식별하고,  상기 깊이 값들 각각을 가지는 하나 이상의 픽셀들의 개수를 식별하고,  상기 깊이 값들 중에서 극대 값(511-1)에 대응하는 상기 개수와 관련된 깊이 값을 이용하여 기준 깊이 값을 식별하고,  상기 기준 깊이 값에 대하여 기준 범위 내에 있는 깊이 값들을 가지는 상기 픽셀들의 제1 일부를 식별하고, 상기 픽셀들의 상기 제1 일부와 다른 상기 픽셀들의 제2 일부를 식별하고, 및상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고 상기 픽셀들의 상기 제2 일부가 가지는 깊이 값들을 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록, 상기 웨어러블 장치(110)를 야기하는,웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>2. 청구항 1에 있어서, 상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시, 상기 이미지 내의 픽셀들이 각각 가지는 상기 깊이 값들 중에서 다른 극대 값(511-2)에 대응하는 상기 개수와 관련된 다른 깊이 값을 이용하여 다른 기준 깊이 값을 식별하고,  상기 다른 기준 깊이 값에 대하여 상기 기준 범위 내에 있는 깊이 값들을 가지고, 상기 픽셀들의 상기 제1 일부와 다른 상기 픽셀들의 제3 일부를 식별하고, 및 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고, 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 미리 결정된 깊이 값으로 설정하고, 및 상기 픽셀들의 상기 제3 일부가 가지는 상기 깊이 값들을 상기 다른 기준 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록,상기 웨어러블 장치(110)를 야기하는, 웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>3. 청구항 1에 있어서, 상기 미리 결정된 깊이 값은,제1 미리 결정된 깊이 값이고,  상기 웨어러블 장치(110)는 하나 이상의 눈들의 시선(gaze)에 관한 아이 트래킹 데이터를 획득하도록 구성된 하나 이상의 다른 센서들(250)을 더 포함하고,  상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시, 상기 하나 이상의 다른 센서들(250)을 이용하여 획득된 상기 아이 트래킹 데이터를 이용하여, 상기 이미지의 포비티드 영역(foveated area)(810) 및 상기 이미지의 상기 포비티드 영역(810)을 감싸는 상기 이미지의 주변 영역(peripheral area)(820)을 결정하고,  상기 기준 깊이 값에 대하여 상기 기준 범위 내에 있는 깊이 값들을 가지고 상기 이미지의 상기 포비티드 영역(810) 내에 위치된 상기 픽셀들의 상기 제1 일부를 식별하고,  상기 기준 깊이 값에 대하여 상기 기준 범위 밖에 있는 깊이 값들을 가지고 상기 이미지의 상기 포비티드 영역(810) 내에 위치된 상기 픽셀들의 상기 제2 일부를 식별하고,상기 이미지의 상기 주변 영역(820) 내에 위치된 상기 픽셀들의 제3 일부를 식별하고, 및 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고, 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 제1 미리 결정된 깊이 값으로 설정하고, 및 상기 픽셀들의 상기 제3 일부가 가지는 깊이 값들을 제2 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록,상기 웨어러블 장치(110)를 야기하는, 웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>4. 청구항 1에 있어서, 상기 미리 결정된 깊이 값은,제1 미리 결정된 깊이 값이고,  상기 웨어러블 장치(110)는 하나 이상의 눈들의 시선(gaze)에 관한 아이 트래킹 데이터를 획득하도록 구성된 하나 이상의 다른 센서들(250)을 더 포함하고,  상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  상기 하나 이상의 다른 센서들(250)을 이용하여 획득된 상기 아이 트래킹 데이터를 이용하여, 상기 이미지의 포비티드 영역(foveated area)(810) 및 상기 이미지의 상기 포비티드 영역(810)을 감싸는 상기 이미지의 주변 영역(peripheral area)(820)을 결정하고,  다른 기준 범위 밖에 있고 상기 기준 깊이 값에 대하여 상기 기준 범위 내에 있는 깊이 값들을 가지고 상기 이미지의 상기 포비티드 영역(810) 내에 위치된 상기 픽셀들의 상기 제1 일부를 식별하고,  상기 다른 기준 범위 밖에 있고 상기 기준 깊이 값에 대하여 상기 기준 범위 밖에 있는 깊이 값들을 가지고 상기 이미지의 상기 포비티드 영역(810) 내에 위치된 상기 픽셀들의 상기 제2 일부를 식별하고,  상기 다른 기준 범위 내에 있는 깊이 값들을 가지고 상기 이미지의 상기 포비티드 영역(810) 내에 위치된 상기 픽셀들의 제3 일부를 식별하고,  상기 이미지의 상기 주변 영역(820) 내에 위치된 상기 픽셀들의 제4 일부를 식별하고, 및 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고, 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 제1 미리 결정된 깊이 값으로 설정하고, 및 상기 픽셀들의 상기 제4 일부가 가지는 깊이 값들을 제2 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록,  상기 웨어러블 장치(110)를 야기하고,  상기 픽셀들의 상기 제3 일부에 대응하는 상기 화면 내의 영역이 가지는 깊이 값들은,  상기 픽셀들의 상기 제3 일부가 가지는 상기 다른 기준 범위 내의 상기 깊이 값들에 대응하는,  웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>5. 청구항 4에 있어서, 상기 하나 이상의 센서들(240)은 D-TOF(direct time of flight) 센서 및 I-TOF(indirect time of flight) 센서를 포함하고,  상기 화면 내의 상기 영역은,  제1 부분 영역 및 제2 부분 영역을 포함하고,  상기 화면 내의 상기 영역 내에 포함된 상기 제1 부분 영역은,  상기 D-TOF 센서 및 상기 I-TOF 센서 중 상기 D-TOF 센서를 이용하여 식별된 깊이 값들에 대응하는 깊이 값들을 가지고,  상기 화면 내의 상기 영역 내에 포함된 상기 제2 부분 영역은, 상기 D-TOF 센서 및 상기 I-TOF 센서 중 상기 I-TOF 센서를 이용하여 식별된 깊이 값들에 대응하는 깊이 값들을 가지는,  웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>6. 청구항 1에 있어서,상기 미리 결정된 깊이 값은, 상기 이미지 내의 상기 픽셀들이 각각 가지는 상기 깊이 값들의 평균 값을 이용하여 획득되는,  웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>7. 청구항 1에 있어서, 상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  상기 개수와 관련된 상기 깊이 값 및 상기 웨어러블 장치(110)의 부착된 상기 하나 이상의 카메라들(130)의 위치와 상기 웨어러블 장치(110)를 착용한 사용자의 눈의 위치 사이의 차이를 이용하여, 상기 기준 깊이 값을 식별하도록, 상기 웨어러블 장치(110)를 야기하는,  웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>8. 웨어러블 장치(110)에 있어서,하나 이상의 디스플레이들을 포함하는 디스플레이 어셈블리(230);하나 이상의 카메라들(130);하나 이상의 센서들(240);하나 이상의 눈들의 시선(gaze)에 관한 아이 트래킹 데이터를 획득하도록 구성된 하나 이상의 다른 센서들(250);인스트럭션들을 저장하고, 하나 이상의 저장 매체들을 포함하는, 메모리(220); 및프로세싱 회로를 포함하는 적어도 하나의 프로세서(200)를 포함하고,상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  상기 하나 이상의 카메라들(130)을 통해 이미지를 획득하고,  상기 하나 이상의 다른 센서들(250)을 이용하여 획득된 상기 아이 트래킹 데이터를 이용하여, 상기 이미지의 포비티드 영역(foveated area)(810) 및 상기 이미지의 상기 포비티드 영역(810)을 감싸는 상기 이미지의 주변 영역(peripheral area)(820)을 결정하고,  상기 하나 이상의 카메라들(130) 및/또는 상기 하나 이상의 센서들(240)을 통해 획득된 깊이 정보를 이용하여, 상기 이미지의 상기 포비티드 영역(810) 내의 픽셀들이 각각 가지는 깊이 값들을 식별하고,  상기 깊이 값들 각각을 가지는 하나 이상의 픽셀들의 개수를 식별하고,  상기 깊이 값들 중에서 극대 값(511-1)에 대응하는 상기 개수와 관련된 깊이 값을 이용하여 기준 깊이 값을 식별하고,  상기 기준 깊이 값에 대하여 기준 범위 내에 있는 깊이 값들을 가지는 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 제1 일부를 식별하고,  상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제1 일부와 다른, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 제2 일부를 식별하고, 및 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제2 일부가 가지는 깊이 값들을 제1 미리 결정된 깊이 값으로 설정하고, 및 상기 이미지의 상기 주변 영역(820) 내의 픽셀들 각각이 가지는 깊이 값들을 제2 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록, 상기 웨어러블 장치(110)를 야기하는,웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>9. 청구항 8에 있어서, 상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시, 상기 이미지의 상기 포비티드 영역(810) 내의 픽셀들이 각각 가지는 상기 깊이 값들 중에서 다른 극대 값(511-2)에 대응하는 상기 개수와 관련된 다른 깊이 값을 이용하여 다른 기준 깊이 값을 식별하고,  상기 다른 기준 깊이 값에 대하여 상기 기준 범위 내에 있는 깊이 값들을 가지고, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제1 일부와 다른, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 제3 일부를 식별하고, 및 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 제1 미리 결정된 깊이 값으로 설정하고, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제3 일부가 가지는 상기 깊이 값들을 상기 다른 기준 깊이 값으로 설정하고, 및 상기 이미지의 상기 주변 영역(820) 내의 상기 픽셀들 각각이 가지는 상기 깊이 값들을 상기 제2 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록, 상기 웨어러블 장치(110)를 야기하는,웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>10. 청구항 8에 있어서, 상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  다른 기준 범위 밖에 있고 상기 기준 깊이 값에 대하여 상기 기준 범위 내에 있는 깊이 값들을 가지는 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제1 일부를 식별하고,  상기 다른 기준 범위 밖에 있고 상기 기준 깊이 값에 대하여 상기 기준 범위 밖에 있는 깊이 값들을 가지는 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제2 일부를 식별하고,  상기 다른 기준 범위 내에 있는 깊이 값들을 가지고 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 제3 일부를 식별하고, 및 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 제1 미리 결정된 깊이 값으로 설정하고, 및 상기 이미지의 상기 주변 영역(820) 내의 상기 픽셀들 각각이 가지는 상기 깊이 값들을 상기 제2 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록,  상기 웨어러블 장치(110)를 야기하고,  상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제3 일부에 대응하는 상기 화면 내의 영역이 가지는 깊이 값들은,  상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들의 상기 제3 일부가 가지는 상기 다른 기준 범위 내의 상기 깊이 값들에 대응하는,  웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>11. 청구항 10에 있어서, 상기 하나 이상의 센서들(240)은 D-TOF(direct time of flight) 센서 및 I-TOF(indirect time of flight) 센서를 포함하고,  상기 화면 내의 상기 영역은,  제1 부분 영역 및 제2 부분 영역을 포함하고,  상기 화면 내의 상기 영역 내에 포함된 상기 제1 부분 영역은,  상기 D-TOF 센서 및 상기 I-TOF 센서 중 상기 D-TOF 센서를 이용하여 식별된 깊이 값들에 대응하는 깊이 값들을 가지고,  상기 화면 내의 상기 영역 내에 포함된 상기 제2 부분 영역은, 상기 D-TOF 센서 및 상기 I-TOF 센서 중 상기 I-TOF 센서를 이용하여 식별된 깊이 값들에 대응하는 깊이 값들을 가지는,  웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>12. 청구항 8에 있어서,상기 제1 미리 결정된 깊이 값은, 상기 이미지의 상기 포비티드 영역(810) 내의 상기 픽셀들이 각각 가지는 상기 깊이 값들의 평균 값을 이용하여 획득되는,  웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>13. 청구항 8에 있어서,상기 제2 미리 결정된 깊이 값은, 상기 이미지의 상기 주변 영역(820) 내의 상기 픽셀들이 각각 가지는 상기 깊이 값들의 평균 값을 이용하여 획득되는,  웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>14. 청구항 8에 있어서, 상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  상기 개수와 관련된 상기 깊이 값 및 상기 웨어러블 장치(110)의 부착된 상기 하나 이상의 카메라들(130)의 위치와 상기 웨어러블 장치(110)를 착용한 사용자의 눈의 위치 사이의 차이를 이용하여, 상기 기준 깊이 값을 식별하도록, 상기 웨어러블 장치(110)를 야기하는,  웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>15. 웨어러블 장치(110)에 있어서,하나 이상의 디스플레이들을 포함하는 디스플레이 어셈블리(230);하나 이상의 카메라들(130);하나 이상의 센서들(240);인스트럭션들을 저장하고, 하나 이상의 저장 매체들을 포함하는, 메모리(220); 및프로세싱 회로를 포함하는 적어도 하나의 프로세서(200)를 포함하고,상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  상기 하나 이상의 카메라들(130)을 통해 이미지를 획득하고,  상기 이미지 내의 객체를 식별하고,  상기 하나 이상의 카메라들(130) 및/또는 상기 하나 이상의 센서들(240)을 통해 획득된 깊이 정보를 이용하여, 상기 객체에 의해 점유되는 상기 이미지 내의 영역 내의 픽셀들의 제1 일부가 가지는 깊이 값들을 식별하고,   상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들의 적어도 일부를 이용하여 기준 깊이 값을 식별하고, 상기 픽셀들의 상기 제1 일부와 다른 상기 픽셀들의 제2 일부를 식별하고, 및 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고 상기 픽셀들의 상기 제2 일부가 가지는 깊이 값들을 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록, 상기 웨어러블 장치(110)를 야기하는,웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>16. 청구항 15에 있어서, 상기 기준 깊이 값은,  제1 기준 깊이 값이고,  상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시, 상기 이미지 내의 다른 객체를 식별하고,  상기 깊이 정보를 이용하여 상기 다른 객체에 의해 점유되는 상기 이미지 내의 영역 내의 상기 픽셀들의 제3 일부가 가지는 깊이 값들을 식별하고,  상기 픽셀들의 상기 제3 일부가 가지는 상기 깊이 값들을 이용하여 제2 기준 깊이 값을 식별하고, 및 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 제1 기준 깊이 값으로 설정하고, 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 미리 결정된 깊이 값으로 설정하고, 및 상기 픽셀들의 상기 제3 일부가 가지는 상기 깊이 값들을 상기 제2 기준 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록, 상기 웨어러블 장치(110)를 야기하는, 웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>17. 청구항 15에 있어서, 상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시, 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들 각각을 가지는 상기 이미지의 상기 영역 내의 하나 이상의 픽셀들의 개수를 식별하고, 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들 증에서 극대 값(511-1)에 대응하는 상기 개수와 관련된 깊이 값을 이용하여 상기 기준 깊이 값을 식별하고, 및상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 기준 깊이 값으로 설정하고 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록, 상기 웨어러블 장치(110)를 야기하는,웨어러블 장치(110).  </claim></claimInfo><claimInfo><claim>18. 청구항 15에 있어서, 상기 웨어러블 장치(110)는 하나 이상의 눈들의 시선(gaze)에 관한 아이 트래킹 데이터를 획득하도록 구성된 하나 이상의 다른 센서들(250)을 더 포함하고,  상기 기준 깊이 값은,  제1 기준 깊이 값이고,  상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시, 상기 하나 이상의 다른 센서들(250)을 이용하여 획득된 상기 아이 트래킹 데이터를 이용하여, 상기 이미지의 포비티드 영역(foveated area)(810) 및 상기 이미지의 상기 포비티드 영역(810)을 감싸는 상기 이미지의 주변 영역(peripheral area)(820)을 결정하고, 상기 이미지 내의 상기 객체가 상기 이미지 내의 상기 포비티드 영역(810) 내에 위치됨을 식별하는 것에 기반하여: 상기 이미지의 상기 포비티드 영역(810)이 가지는 깊이 값들을 식별하고,  상기 이미지의 상기 포비티드 영역(810)이 가지는 상기 깊이 값들 각각을 가지는 상기 이미지의 상기 포비티드 영역(810) 내의 하나 이상의 픽셀들의 개수를 식별하고,  상기 이미지의 상기 포비티드 영역(810)이 가지는 상기 깊이 값들 중에서 극대 값(511-1)에 대응하는 상기 개수와 관련된 깊이 값을 이용하여 제2 기준 깊이 값을 식별하고, 및  상기 이미지의 상기 포비티드 영역(810)이 가지는 상기 깊이 값들을 상기 제2 기준 깊이 값으로 설정하고 상기 이미지의 상기 주변 영역(820)이 가지는 깊이 값들을 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하고, 및  상기 이미지 내의 상기 객체의 적어도 일부가 상기 이미지 내의 상기 주변 영역(820) 내에 위치됨을 식별하는 것에 기반하여, 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들을 상기 제1 기준 깊이 값으로 설정하고 상기 픽셀들의 상기 제2 일부가 가지는 상기 깊이 값들을 상기 미리 결정된 깊이 값으로 설정하는 것에 기반하여, 상기 이미지에 대응하는 화면을 상기 디스플레이 어셈블리(230)를 통해 표시하도록, 상기 웨어러블 장치(110)를 야기하는, 웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>19. 청구항 15에 있어서, 상기 기준 깊이 값은, 상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들의 평균 값에 대응하는, 웨어러블 장치(110).</claim></claimInfo><claimInfo><claim>20. 청구항 15에 있어서, 상기 인스트럭션들은, 상기 적어도 하나의 프로세서(200)에 의해 개별적으로 또는 집합적으로 실행될 시,  상기 픽셀들의 상기 제1 일부가 가지는 상기 깊이 값들의 적어도 일부 및 상기 웨어러블 장치(110)의 부착된 상기 하나 이상의 카메라들(130)의 위치와 상기 웨어러블 장치(110)를 착용한 사용자의 눈의 위치 사이의 차이를 이용하여, 상기 기준 깊이 값을 식별하도록, 상기 웨어러블 장치(110)를 야기하는,  웨어러블 장치(110).  </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Dongheon YOO</engName><name>유동헌</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Wonjoon DO</engName><name>도원준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Donghyun YEOM</engName><name>염동현</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Sungoh KIM</engName><name>김성오</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Kihwan KIM</engName><name>김기환</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Sanghun LEE</engName><name>이상훈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구  논현로**길  **, *층, *층 (도곡동, 덕영빌딩)</address><code>920191001617</code><country>대한민국</country><engName>KWANG AND JANG PATENT LAW FIRM</engName><name>특허법인광앤장</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2024.04.12</priorityApplicationDate><priorityApplicationNumber>1020240049677</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2024.05.09</priorityApplicationDate><priorityApplicationNumber>1020240061484</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.06.26</receiptDate><receiptNumber>1-1-2024-0692389-52</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240083537.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937e31a9d382147516792268b47f5f59f6282c226240d83b05188e39b8ca99863ccfa0586784fcde8aed339626ae3da43987470ab3f2eba3fe</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf247b5c78e370b4b9b4c02fcdb46a4195569985a418ee5381d0da27496c7315feeee118c883346fc2ca3fa52df7dd572a85a8351a8d5f6708</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>