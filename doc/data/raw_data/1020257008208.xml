<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:14.4014</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.20</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7008208</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>희소 훈련을 위한 레이어 동결 및 데이터 선별</inventionTitle><inventionTitleEng>LAYER FREEZING AND DATA SIEVING FOR SPARSE TRAINING</inventionTitleEng><openDate>2025.04.25</openDate><openNumber>10-2025-0056207</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.03.12</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 엔드-투-엔드 데이터세트-효율적 훈련을 제공하는, 객체 인식을 위한 희소 훈련 도메인에서 사용되는 레이어 동결 및 데이터 선별 기법. 레이어 동결 및 데이터 선별 방법들은 희소 훈련 알고리즘에 끊김없이(seamlessly) 통합되어 일반 프레임워크를 형성한다. 일반 프레임워크는 이전 접근법들을 일관되게 능가하고, 높은 정확도를 유지하면서 훈련 FLOPs(floating point operations per second) 및 메모리 비용들을 상당히 감소시킨다. 훈련 FLOPs의 감소는 3 개의 소스들: 가중치 희소성, 동결된 레이어들 및 축소된 데이터세트로부터 비롯된다. 훈련 가속은 상이한 팩터들, 예를 들어, 희소 컴퓨테이션의 지원, 레이어 타입 및 사이즈, 및 시스템 오버헤드에 의존한다. 동결된 레이어들 및 축소된 데이터세트로부터의 FLOPs 감소는 가중치 희소성보다 더 높은 실제 훈련 가속으로 이어진다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.02.29</internationOpenDate><internationOpenNumber>WO2024044004</internationOpenNumber><internationalApplicationDate>2023.07.20</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/028253</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 희소 네트워크(sparse network)를 훈련시키기 위한 프레임워크로서,프로세서를 포함하며,상기 프로세서는, 상기 희소 네트워크를 초기화하도록 — 상기 희소 네트워크는 희소 구조를 가짐 — ; 훈련 샘플들을 포함하는 부분 훈련 데이터세트를 사용하여 상기 희소 네트워크의 모든 레이어들을 액티브하게(actively) 훈련시키도록; 상기 부분 훈련 데이터세트를 업데이트하기 위해 상기 훈련 샘플들을 데이터 선별(data sieve)하도록; 그리고 훈련된 희소 네트워크를 획득하기 위해 순차적 방식으로 상기 희소 네트워크의 레이어들을 점진적으로 동결(freeze)시키도록 구성되는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>2. 제1 항에 있어서,상기 프로세서는 추가로, 전체 훈련 데이터세트로부터 일정 비율의 훈련 샘플들을 랜덤으로 제거함으로써 상기 부분 훈련 데이터세트를 획득하도록 구성되는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>3. 제1 항에 있어서,레이어는 상기 레이어 앞의 모든 레이어들이 동결되는 경우에만 동결되는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>4. 제1 항에 있어서,상기 동결된 레이어들의 희소 구조 및 가중치 값들은 변화되지 않은 상태로 유지되는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>5. 제4 항에 있어서,상기 동결된 레이어들에서의 모든 가중치 그래디언트들 및 활성화 그래디언트들이 제거되는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>6. 제1 항에 있어서,상기 데이터 선별은 각각의 에포크(epoch)에서의 훈련 반복 횟수를 감소시키는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>7. 제1 항에 있어서,상기 데이터 선별은 순환 데이터 선별을 포함하는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>8. 제7 항에 있어서,상기 순환 데이터 선별은, 상기 부분 훈련 데이터세트 및 제거된 데이터세트를 생성하기 위해 훈련 데이터세트의 총 훈련 샘플들 중 일정 비율의 훈련 샘플들을 랜덤으로 선택하는 것; 상기 부분 훈련 데이터세트로부터 다수의 훈련 샘플들을 제거하고 상기 제거된 훈련 샘플들을 상기 제거된 데이터세트에 추가함으로써, 매 에포크마다 상기 부분 훈련 데이터세트를 업데이트하는 것; 및 상기 부분 훈련 데이터세트에서의 총 훈련 샘플 수를 변화되지 않게 유지하기 위해, 상기 제거된 데이터세트로부터 동일한 수의 제거된 훈련 샘플들을 리트리브(retrieve)하고 상기 리트리브된 훈련 샘플들을 상기 부분 훈련 데이터세트에 다시 추가하는 것을 포함하는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>9. 제1 항에 있어서,상기 프로세서는, MEST(Memory-Economic Sparse Training)로부터의 DST(Dynamic Sparse Training)를 적용함으로써 상기 레이어들을 액티브하게 훈련시키도록 구성되는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>10. 제1 항에 있어서,상기 프로세서는 레이어 동결 인터벌(interval)을 DST 인터벌과 결합하도록 구성되는, 희소 네트워크를 훈련시키기 위한 프레임워크.</claim></claimInfo><claimInfo><claim>11. 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법으로서,상기 희소 네트워크를 초기화하는 단계;훈련 샘플들을 포함하는 부분 훈련 데이터세트를 사용하여 상기 희소 네트워크의 모든 레이어들을 액티브하게 훈련시키는 단계;상기 부분 훈련 데이터세트를 업데이트하기 위해 상기 훈련 샘플들을 데이터 선별하는 단계; 및훈련된 희소 네트워크를 획득하기 위해 순차적 방식으로 상기 희소 네트워크의 레이어들을 점진적으로 동결시키는 단계를 포함하는, 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11 항에 있어서,전체 훈련 데이터세트로부터 일정 비율의 훈련 샘플들을 랜덤으로 제거함으로써 상기 부분 훈련 데이터세트를 획득하는 단계를 더 포함하는, 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법.</claim></claimInfo><claimInfo><claim>13. 제11 항에 있어서,레이어는 상기 레이어 앞의 모든 레이어들이 동결되는 경우에만 동결되는, 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법.</claim></claimInfo><claimInfo><claim>14. 제11 항에 있어서,상기 동결된 레이어들의 희소 구조 및 가중치 값들은 변화되지 않은 상태로 유지되는, 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법.</claim></claimInfo><claimInfo><claim>15. 제14 항에 있어서,상기 동결된 레이어들에서의 모든 가중치 그래디언트들 및 활성화 그래디언트들이 제거되는, 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법.</claim></claimInfo><claimInfo><claim>16. 제11 항에 있어서,상기 데이터 선별은 각각의 에포크에서의 훈련 반복 횟수를 감소시키는, 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법.</claim></claimInfo><claimInfo><claim>17. 제11 항에 있어서,상기 데이터 선별은 순환 데이터 선별을 포함하는, 희소 구조를 갖는 희소 네트워크를 훈련시키도록 구성된 프로세서를 갖는 프레임워크를 사용하는 방법.</claim></claimInfo><claimInfo><claim>18. 프로그램 코드를 저장하는 비일시적 컴퓨터 판독 가능 매체로서,상기 프로그램 코드는, 실행될 때, 프레임워크의 프로세서로 하여금, 희소 네트워크를 초기화하는 단계; 훈련 샘플들을 포함하는 부분 훈련 데이터세트를 사용하여 상기 희소 네트워크의 모든 레이어들을 액티브하게 훈련시키는 단계; 상기 부분 훈련 데이터세트를 업데이트하기 위해 상기 훈련 샘플들을 데이터 선별하는 단계; 및 훈련된 희소 네트워크를 획득하기 위해 순차적 방식으로 상기 희소 네트워크의 레이어들을 점진적으로 동결시키는 단계를 수행하도록 희소 구조를 갖는 희소 네트워크를 훈련시키게 하도록 동작 가능한, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>19. 제18 항에 있어서,상기 코드는, 프로세서로 하여금, 전체 훈련 데이터세트로부터 일정 비율의 훈련 샘플들을 랜덤으로 제거함으로써 상기 부분 훈련 데이터세트를 획득하게 하도록 동작 가능한, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>20. 제18 항에 있어서,상기 코드는, 프로세서로 하여금, 레이어 앞의 모든 레이어들이 동결되는 경우에만 레이어를 동결시키게 하도록 동작 가능한, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>REN, Jian</engName><name>런, 지안</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>벨라루스</country><engName>TULYAKOV, Sergey</engName><name>툴리아코프, 세르게이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>LI, Yanyu</engName><name>리, 옌위</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country>중국</country><engName>YUAN, Geng</engName><name>위안, 겅</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.23</priorityApplicationDate><priorityApplicationNumber>17/893,241</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.03.12</receiptDate><receiptNumber>1-1-2025-0280862-85</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>1-5-2025-0050983-11</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257008208.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9394bba7dc0958ae506f4c830fb1da12f677eabff96b696687990bd2d074155c6addb044c04abedb246a4ab0b09cb124a9c782274a1512890c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf0a7545679e173d3131f11cbded193f72bf57fcd4f1dbceff1793383f0df73488bacf7bd27d7e5859f3b21428da51e4f1d59cd7344a35c2c0</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>