<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:40.4140</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.10.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2021-0143629</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>뉴럴 네트워크의 압축 장치 및 방법</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR COMPRESSING A NEURAL NETWORK</inventionTitleEng><openDate>2023.05.03</openDate><openNumber>10-2023-0059435</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.07.18</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/082</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0495</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 뉴럴 네트워크의 압축 장치 및 방법이 개시된다. 일 실시 예에 따른 뉴럴 네트워크(neural network)의 압축 방법은 사전 학습된(pre-trained) 제1 뉴럴 네트워크를 파인튜닝(fine-tuning)하여 제2 뉴럴 네트워크를 획득하는 단계, 제1 뉴럴 네트워크의 가중치와 제2 뉴럴 네트워크의 가중치의 차이에 대응하는 델타 가중치를 획득하는 단계, 델타 가중치를 압축하는 단계, 압축된 델타 가중치 및 제1 뉴럴 네트워크의 가중치에 기초한, 압축된 제2 뉴럴 네트워크를 재학습시키는 단계, 및 압축된 제2 뉴럴 네트워크의 재학습에 따라 갱신된 델타 가중치를 인코딩하여 저장하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 특정 목적을 위한 학습 데이터에 기초하여, 사전 학습된 제1 뉴럴 네트워크를 파인튜닝(fine-tuning)하여 제2 뉴럴 네트워크를 획득하는 단계;상기 제1 뉴럴 네트워크의 가중치와 상기 제2 뉴럴 네트워크의 가중치의 차이에 대응하는 델타 가중치를 획득하는 단계;상기 델타 가중치를 압축하는 단계;상기 압축된 델타 가중치 및 상기 제1 뉴럴 네트워크의 가중치에 기초하여 갱신된 제2 뉴럴 네트워크를 재학습시키는 단계; 및상기 제2 뉴럴 네트워크의 재학습에 따라 갱신된 상기 델타 가중치를 인코딩하여 저장하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 갱신된 상기 델타 가중치를 인코딩하여 저장하는 단계는상기 제2 뉴럴 네트워크에 관하여 미리 설정된 정확도 기준에 기초하여, 상기 제2 뉴럴 네트워크의 재학습의 종료 여부를 결정하는 단계; 및상기 제2 뉴럴 네트워크의 재학습을 종료하는 것으로 결정함에 따라, 상기 제2 뉴럴 네트워크의 재학습에 따라 갱신된 상기 델타 가중치를 인코딩하여 저장하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제2 뉴럴 네트워크의 재학습을 종료하지 않는 것으로 결정함에 따라,상기 델타 가중치를 압축하는 단계, 및 상기 압축된 델타 가중치 및 상기 제1 뉴럴 네트워크의 가중치에 기초하여 갱신된 제2 뉴럴 네트워크를 재학습시키는 단계를 반복하여 수행하는 단계를 더 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 델타 가중치를 인코딩하여 저장하는 단계는상기 델타 가중치 중 0이 아닌 델타 가중치의 위치 정보를 포함하는 메타 데이터로 상기 델타 가중치를 인코딩하는 단계; 및상기 메타 데이터를 상기 제2 뉴럴 네트워크에 대응하여 저장하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 델타 가중치를 압축하는 단계는상기 델타 가중치 중 미리 정해진 임계치 이하인 가중치를 0으로 변경하는 프루닝(pruning)을 수행하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 델타 가중치를 압축하는 단계는상기 델타 가중치를 미리 정해진 비트 수로 줄이는 양자화(quantization)을 수행하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,인코딩되어 저장된 상기 델타 가중치 및 상기 제1 뉴럴 네트워크의 가중치에 기초하여, 상기 특정 목적을 수행하도록 학습된 상기 제2 뉴럴 네트워크를 획득하는 단계를 더 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>8. 복수의 목적들을 위한 복수의 학습 데이터 세트들 각각에 대응하여, 사전 학습된 베이스 모델을 파인튜닝함으로써, 복수의 태스크 별 모델들을 획득하는 단계;상기 복수의 태스크 별 모델들 각각에 대응하여, 상기 베이스 모델의 가중치와 해당 태스크 별 모델의 가중치의 차이  에 대응하는 델타 가중치를 획득하는 단계; 및 상기 해당 태스크 별 모델에 대응하여 미리 설정된 기준에 기초하여, 상기 획득된 델타 가중치를 압축하는 단계; 및상기 복수의 태스크 별 모델들에 대응하는 상기 압축된 델타 가중치들에 기초하여, 상기 복수의 태스크 별 모델들을 압축하여 저장하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 획득된 델타 가중치를 압축하는 단계는상기 델타 가중치 중 미리 정해진 임계치 이하인 가중치를 0으로 변경하는 프루닝(pruning)을 수행하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서,상기 획득된 델타 가중치를 압축하는 단계는상기 델타 가중치를 미리 정해진 비트 수로 줄이는 양자화(quantization)을 수행하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>11. 제8항에 있어서,상기 복수의 태스크 별 모델들을 압축하여 저장하는 단계는상기 복수의 태스크 별 모델들 각각에 대응하여,해당 태스크 별 모델에 대응하는 상기 압축된 델타 가중치 및 상기 베이스 모델의 가중치에 기초하여 갱신된 상기 해당 태스크 별 모델을 재학습시키는 단계; 및상기 재학습에 따라 갱신된 상기 해당 태스크 별 모델에 대응하는 델타 가중치를 인코딩하여 저장하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 델타 가중치를 인코딩하여 저장하는 단계는상기 델타 가중치 중 0이 아닌 델타 가중치의 위치 정보를 포함하는 메타 데이터로 상기 델타 가중치를 인코딩하는 단계; 및상기 메타 데이터를 상기 해당 태스크 별 모델에 대응하여 저장하는 단계를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>13. 제8항에 있어서,상기 미리 설정된 기준은프루닝 비율(pruing ratio)에 관한 기준 및 양자화 비트수(bit-width)에 관한 기준 중 적어도 하나를 포함하는,뉴럴 네트워크의 압축 방법.</claim></claimInfo><claimInfo><claim>14. 하드웨어와 결합되어 제1항 내지 제13항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>15. 특정 목적을 위한 학습 데이터에 기초하여, 사전 학습된 제1 뉴럴 네트워크를 파인튜닝(fine-tuning)하여 제2 뉴럴 네트워크를 획득하고,상기 제1 뉴럴 네트워크의 가중치와 상기 제2 뉴럴 네트워크의 가중치의 차이에 대응하는 델타 가중치를 획득하고,상기 델타 가중치를 압축하고,상기 압축된 델타 가중치 및 상기 제1 뉴럴 네트워크의 가중치에 기초하여 갱신된 제2 뉴럴 네트워크를 재학습시키며,상기 제2 뉴럴 네트워크의 재학습에 따라 갱신된 상기 델타 가중치를 인코딩하여 저장하는,적어도 하나의 프로세서를 포함하는,뉴럴 네트워크 압축 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 프로세서는,상기 갱신된 상기 델타 가중치를 인코딩하여 저장함에 있어서,상기 제2 뉴럴 네트워크에 관하여 미리 설정된 정확도 기준에 기초하여, 상기 제2 뉴럴 네트워크의 재학습의 종료 여부를 결정하며,상기 제2 뉴럴 네트워크의 재학습을 종료하는 것으로 결정함에 따라, 상기 제2 뉴럴 네트워크의 재학습에 따라 갱신된 상기 델타 가중치를 인코딩하여 저장하는,뉴럴 네트워크 압축 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 프로세서는,상기 제2 뉴럴 네트워크의 재학습을 종료하지 않는 것으로 결정함에 따라,상기 델타 가중치를 압축하는 단계, 및 상기 압축된 델타 가중치 및 상기 제1 뉴럴 네트워크의 가중치에 기초하여 갱신된 제2 뉴럴 네트워크를 재학습시키는 단계를 반복하여 수행하는,뉴럴 네트워크 압축 장치.</claim></claimInfo><claimInfo><claim>18. 복수의 목적들을 위한 복수의 학습 데이터 세트들 각각에 대응하여, 사전 학습된 베이스 모델을 파인튜닝함으로써, 복수의 태스크 별 모델들을 획득하고,상기 복수의 태스크 별 모델들 각각에 대응하여, 상기 베이스 모델의 가중치와 해당 태스크 별 모델의 가중치의 차이  에 대응하는 델타 가중치를 획득하고, 상기 해당 태스크 별 모델에 대응하여 미리 설정된 기준에 기초하여, 상기 획득된 델타 가중치를 압축하며,상기 복수의 태스크 별 모델들에 대응하는 상기 압축된 델타 가중치들에 기초하여, 상기 복수의 태스크 별 모델들을 압축하여 저장하는,적어도 하나의 프로세서를 포함하는,뉴럴 네트워크의 압축 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 프로세서는,상기 획득된 델타 가중치를 압축함에 있어서,상기 델타 가중치 중 미리 정해진 임계치 이하인 가중치를 0으로 변경하는 프루닝을 수행하는,뉴럴 네트워크 압축 장치.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 획득된 델타 가중치를 압축함에 있어서,상기 델타 가중치를 미리 정해진 비트 수로 줄이는 양자화를 수행하는,뉴럴 네트워크 압축 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo><applicantInfo><address>대전광역시 유성구...</address><code>319980988661</code><country>대한민국</country><engName>Korea Advanced Institute of Science and Technology</engName><name>한국과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420170626273</code><country>대한민국</country><engName>JANG, Jun Woo</engName><name>장준우</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>SHIN Jae Kang</engName><name>신재강</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>KIM Lee Sup</engName><name>김이섭</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>CHOI Seung Kyu</engName><name>최승규</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2021.10.26</receiptDate><receiptNumber>1-1-2021-1228336-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2023.01.31</receiptDate><receiptNumber>4-1-2023-5023571-05</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>특허고객번호 정보변경(경정)신고서·정정신고서</documentName><receiptDate>2023.05.04</receiptDate><receiptNumber>4-1-2023-5110236-33</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.07.18</receiptDate><receiptNumber>1-1-2023-0787437-16</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020210143629.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9344035906f8c58b80da619130ccc730d9429bb7fd37b1473d8da713a35306d7b0fe174b3e1f5dbcbc7c9dba70aa623da98572d300dbc2369b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfaec1677c112fbac7cbfa7ea20bd77a59abfd0e7a5437f89fb3c309b43a636ff8a355e98083e6274f046c1b87ebe8427f65a1612bff4dc8d3</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>