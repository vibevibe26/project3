<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:11:16.1116</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0138994</applicationNumber><claimCount>14</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>옵티컬 플로우를 추정하는 전자 장치 및 이의 동작 방법</inventionTitle><inventionTitleEng>ELECTRONIC APPARATUS OF ESTIMATING OPTICAL FLOW  AND OPERATING METHOD THEREOF</inventionTitleEng><openDate>2024.05.21</openDate><openNumber>10-2024-0070400</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/269</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/762</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 옵티컬 플로우를 추정하는 전자 장치 및 이의 동작 방법이 개시된다. 실시예에 따른 방법은, 제1 이미지 및 제2 이미지를 이미지 처리 패스(image processing pass)를 통해 각각 처리하는 동작과, 상기 이미지 처리 패스를 통해 처리된 상기 제1 이미지의 제2 어텐션 특징 맵(attention feature map) 및 상기 이미지 처리 패스를 통해 처리된 상기 제2 이미지의 제2 어텐션 특징 맵에 기초하여, 상기 옵티컬 플로우를 추정하는 동작을 포함할 수 있다. 그 외에도 다양한 실시예들이 가능할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 옵티컬 플로우(optical flow)를 추정하는 방법에 있어서,제1 이미지 및 제2 이미지를 이미지 처리 패스(image processing pass)를 통해 각각 처리하는 동작; 및상기 이미지 처리 패스를 통해 처리된 상기 제1 이미지의 제2 어텐션 특징 맵(attention feature map) 및 상기 이미지 처리 패스를 통해 처리된 상기 제2 이미지의 제2 어텐션 특징 맵에 기초하여, 상기 옵티컬 플로우를 추정하는 동작을 포함하고,상기 이미지 처리 패스는,이미지를 인코딩(encoding)하여, 상기 이미지에 대한 특징 맵(feature map)을 추출하고,상기 특징 맵에 상기 이미지의 수평축 방향의 행 관계 정보를 융합하여, 제1 융합 어텐션 특징 맵(fusion attention feature map)을 출력하고,상기 제1 융합 어텐션 특징 맵 및 상기 특징 맵에 기초하여, 상기 이미지의 제1 어텐션 특징 맵(attention feature map)을 출력하고,상기 제1 어텐션 특징맵에 상기 이미지의 수직축 방향의 열 관계 정보를 융합하여, 제2 융합 어텐션 특징 맵을 출력하고,상기 제2 융합 어텐션 특징 맵 및 상기 제1 어텐션 특징 맵에 기초하여, 상기 이미지의 제2 어텐션 특징 맵을 생성하는 패스인, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 옵티컬 플로우를 추정하는 동작은,상기 제1 이미지의 제2 어텐션 특징 맵, 및 상기 제2 이미지의 특징 맵에 기초하여, 상기 제1 이미지의 제2 어텐션 특징 맵에 상기 제2 이미지의 상기 행 관계 정보를 융합한 상기 제1 이미지의 제3 융합 어텐션 특징 맵을 생성하는 동작;상기 제1 이미지의 제3 융합 어텐션 특징 맵 및 상기 제1 이미지의 제2 어텐션 특징 맵에 기초하여, 상기 제1 이미지의 제3 어텐션 특징 맵을 획득하는 동작;상기 제3 어텐션 특징 맵에 상기 제2 이미지의 상기 열 관계 정보를 융합하여, 상기 제1 이미지의 제4 융합 어텐션 특징 맵을 생성하는 동작; 및상기 제1 이미지의 제4 융합 어텐션 특징 맵 및 상기 제1 이미지의 제3 어텐션 특징 맵에 기초하여, 상기 제1 이미지의 제4 어텐션 특징 맵을 획득하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 옵티컬 플로우를 추정하는 동작은,상기 제2 이미지의 제2 어텐션 특징 맵, 및 상기 제1 이미지의 특징 맵에 기초하여, 상기 제2 이미지의 제2 어텐션 특징 맵에 상기 제1 이미지의 행 관계 정보를 융합한 상기 제2 이미지의 제3 융합 어텐션 특징 맵을 생성하는 동작;상기 제2 이미지의 제3 융합 어텐션 특징 맵 및 상기 제2 이미지의 제2 어텐션 특징 맵에 기초하여, 상기 제2 이미지의 제3 어텐션 특징 맵을 획득하는 동작;상기 제3 어텐션 특징 맵에 상기 제1 이미지의 열 관계 정보를 융합하여, 상기 제2 이미지의 제4 융합 어텐션 특징 맵을 생성하는 동작; 및상기 제2 이미지의 제4 융합 어텐션 특징 맵 및 상기 제2 이미지의 제3 어텐션 특징 맵에 기초하여, 상기 제2 이미지의 제4 어텐션 특징 맵을 획득하는 동작을 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 옵티컬 플로우를 추정하는 동작은,상기 제1 이미지의 제4 어텐션 특징 맵, 및 상기 제2 이미지의 제4 어텐션 특징 맵에 기초하여, 상기 옵티컬 플로우를 추정하는 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 이미지 처리 패스는,상기 이미지의 특징 맵에 상기 행 관계 정보를 추출하기 위한 행 벡터를 결합하고,상기 행 벡터가 결합된 상기 이미지의 특징 맵에 기초하여, 상기 이미지의 수평축 방향으로 분리되고 어텐션 학습이 가능한 제1 벡터 특징 맵을 획득하고,상기 제1 벡터 특징 맵을, 상기 이미지의 수평축 방향으로 분리된 특징 맵 및 상기 행 관계 정보에 대응되는 제1 정보 맵으로 분리하고,상기 이미지의 수평축 방향으로 분리된 특징 맵 및 제1 정보 맵에 기초하여, 상기 제1 융합 어텐션 특징 맵을 생성하는 패스인, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 이미지 처리 패스는,상기 이미지의 제1 어텐션 특징 맵에 상기 열 관계 정보를 추출하기 위한 열 벡터를 결합하고,상기 열 벡터가 결합된 상기 이미지의 제1 어텐션 특징 맵에 기초하여, 상기 이미지의 수직축 방향으로 분리되고 어텐션 학습이 가능한 제2 벡터 특징 맵을 획득하고,상기 제2 벡터 특징 맵을, 상기 이미지의 수직축 방향으로 분리된 특징 맵 및 상기 열 관계 정보에 대응되는 제2 정보 맵으로 분리하고,상기 이미지의 수직축 방향으로 분리된 특징 맵 및 상기 제2 정보 맵에 기초하여, 상기 제2 융합 어텐션 특징 맵을 생성하는 패스인, 방법.</claim></claimInfo><claimInfo><claim>7. 옵티컬 플로우(optical flow)를 추정하는 장치에 있어서,하나 이상의 인스트럭션을 저장하는 메모리; 및상기 인스트럭션을 실행시키기 위한 프로세서를 포함하고,상기 인스트럭션이 실행될 때, 상기 프로세서는 복수의 동작들을 수행하고,상기 복수의 동작들은,제1 이미지 및 제2 이미지를 이미지 처리 패스를 통해 각각 처리하는 동작; 및상기 이미지 처리 패스를 통해 획득된 상기 제1 이미지의 제2 어텐션 특징 맵(attention feature map) 및 상기 이미지 처리 패스를 통해 획득된 상기 제2 이미지의 제2 어텐션 특징 맵에 기초하여, 상기 옵티컬 플로우를 추정하는 동작을 포함하고,상기 이미지 처리 패스는,이미지를 인코딩(encoding)하여, 상기 이미지에 대한 특징 맵(feature map)을 추출하고,상기 특징 맵에 상기 이미지의 수평축 방향의 행 관계 정보를 융합하여, 제1 융합 어텐션 특징 맵(fusion attention feature map)을 출력하고,상기 제1 융합 어텐션 특징 맵 및 상기 특징 맵에 기초하여, 상기 이미지의 제1 어텐션 특징 맵(attention feature map)을 출력하고,상기 제1 어텐션 특징맵에 상기 이미지의 수직축 방향의 열 관계 정보를 융합하여, 제2 융합 어텐션 특징 맵을 출력하고,상기 제2 융합 어텐션 특징 맵 및 상기 제1 어텐션 특징 맵에 기초하여, 상기 이미지의 제2 어텐션 특징 맵을 생성하는 패스인, 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 옵티컬 플로우를 추정하는 동작은,상기 제1 이미지의 제2 어텐션 특징 맵, 및 상기 제2 이미지의 특징 맵에 기초하여, 상기 제1 이미지의 제2 어텐션 특징 맵에 상기 제2 이미지의 상기 행 관계 정보를 융합한 상기 제1 이미지의 제3 융합 어텐션 특징 맵을 생성하는 동작;상기 제1 이미지의 제3 융합 어텐션 특징 맵 및 상기 제1 이미지의 제2 어텐션 특징 맵에 기초하여, 상기 제1 이미지의 제3 어텐션 특징 맵을 획득하는 동작;상기 제3 어텐션 특징 맵에 상기 제2 이미지의 상기 열 관계 정보를 융합하여, 상기 제1 이미지의 제4 융합 어텐션 특징 맵을 생성하는 동작; 및상기 제1 이미지의 제4 융합 어텐션 특징 맵 및 상기 제1 이미지의 제3 어텐션 특징 맵에 기초하여, 상기 제1 이미지의 제4 어텐션 특징 맵을 획득하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 옵티컬 플로우를 추정하는 동작은,상기 제2 이미지의 제2 어텐션 특징 맵, 및 상기 제1 이미지의 특징 맵에 기초하여, 상기 제2 이미지의 제2 어텐션 특징 맵에 상기 제1 이미지의 행 관계 정보를 융합한 상기 제2 이미지의 제3 융합 어텐션 특징 맵을 생성하는 동작;상기 제2 이미지의 제3 융합 어텐션 특징 맵 및 상기 제2 이미지의 제2 어텐션 특징 맵에 기초하여, 상기 제2 이미지의 제3 어텐션 특징 맵을 획득하는 동작;상기 제3 어텐션 특징 맵에 상기 제1 이미지의 열 관계 정보를 융합하여, 상기 제2 이미지의 제4 융합 어텐션 특징 맵을 생성하는 동작; 및상기 제2 이미지의 제4 융합 어텐션 특징 맵 및 상기 제2 이미지의 제3 어텐션 특징 맵에 기초하여, 상기 제2 이미지의 제4 어텐션 특징 맵을 획득하는 동작을 더 포함하는, 장치.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 옵티컬 플로우를 추정하는 동작은,상기 제1 이미지의 제4 어텐션 특징 맵, 및 상기 제2 이미지의 제4 어텐션 특징 맵에 기초하여, 상기 옵티컬 플로우를 추정하는 동작을 포함하는, 장치.</claim></claimInfo><claimInfo><claim>11. 제7항에 있어서,상기 이미지 처리 패스는,상기 이미지의 특징 맵에 상기 행 관계 정보를 추출하기 위한 행 벡터를 결합하고,상기 행 벡터가 결합된 상기 이미지의 특징 맵에 기초하여, 상기 이미지의 수평축 방향으로 분리되고 어텐션 학습이 가능한 제1 벡터 특징 맵을 획득하고,상기 제1 벡터 특징 맵을, 상기 이미지의 수평축 방향으로 분리된 특징 맵 및 상기 행 관계 정보에 대응되는 제1 정보 맵으로 분리하고,상기 이미지의 수평축 방향으로 분리된 특징 맵 및 제1 정보 맵에 기초하여, 상기 제1 융합 어텐션 특징 맵을 생성하는 패스인, 장치.</claim></claimInfo><claimInfo><claim>12. 제7항에 있어서,상기 이미지 처리 패스는,상기 이미지의 제1 어텐션 특징 맵에 상기 열 관계 정보를 추출하기 위한 열 벡터를 결합하고,상기 열 벡터가 결합된 상기 이미지의 제1 어텐션 특징 맵에 기초하여, 상기 이미지의 수직축 방향으로 분리되고 어텐션 학습이 가능한 제2 벡터 특징 맵을 획득하고,상기 제2 벡터 특징 맵을, 상기 이미지의 수직축 방향으로 분리된 특징 맵 및 상기 열 관계 정보에 대응되는 제2 정보 맵으로 분리하고,상기 이미지의 수직축 방향으로 분리된 특징 맵 및 상기 제2 정보 맵에 기초하여, 상기 제2 융합 어텐션 특징 맵을 생성하는 패스인, 장치.</claim></claimInfo><claimInfo><claim>13. 옵티컬 플로우(optical flow)를 추정하는 방법에 있어서,제1 이미지를 나타내는 제1 특징 맵을 클러스터링(clustering)하여 제1 특징 맵의 특징들을 포함하는 복수의 제1 클러스터들을 생성하는 동작;제2 이미지를 나타내는 제2 특징 맵으로부터 상기 제1 클러스터들 각각에 포함되는 특징들 중 중심 특징에 대응되는 상기 제2 이미지의 픽셀을 결정하는 동작;상기 제1 클러스터들 및 상기 결정된 제2 이미지의 픽셀에 기초하여, 손실 매트릭스(loss matrix)를 획득하는 동작; 및상기 손실 매트릭스에 기초하여, 상기 제1 이미지 및 상기 제2 이미지의 옵티컬 플로우를 추정하는 동작를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 손실 매트릭스를 획득하는 동작은,상기 중심 특징과 상기 제2 이미지의 픽셀 사이의 상관성을 계산하는 동작를 포함하는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 산시성 ...</address><code> </code><country> </country><engName>Zhaohui LV</engName><name>자오후이 뤼</name></inventorInfo><inventorInfo><address>중국 ***** 산시성 시...</address><code> </code><country> </country><engName>Pei YOU</engName><name>페이 유</name></inventorInfo><inventorInfo><address>중국 ****** 산시성 ...</address><code> </code><country> </country><engName>Penghui SUN</engName><name>펑후이 쑨</name></inventorInfo><inventorInfo><address>중국 ****** 산시성 ...</address><code> </code><country> </country><engName>Feng ZHU</engName><name>펑 주</name></inventorInfo><inventorInfo><address>중국 ****** 산시성 ...</address><code> </code><country> </country><engName>Ran YANG</engName><name>란 양</name></inventorInfo><inventorInfo><address>중국 광둥성 ****** ...</address><code> </code><country> </country><engName>Huisi WU</engName><name>후이쓰 우</name></inventorInfo><inventorInfo><address>중국 광둥성 ****** ...</address><code> </code><country> </country><engName>Wende XIE</engName><name>원더 셰</name></inventorInfo><inventorInfo><address>중국 광둥성 ****** ...</address><code> </code><country> </country><engName>Jingyin LIN</engName><name>징윈 린</name></inventorInfo><inventorInfo><address>중국 광둥성 ****** ...</address><code> </code><country> </country><engName>Zebin ZHAO</engName><name>쩌빈 자오</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170490362</code><country>대한민국</country><engName>Nam, Dongkyung</engName><name>남동경</name></inventorInfo><inventorInfo><address>경기도 용인시 기흥구...</address><code>420170491439</code><country>대한민국</country><engName>Heo, Jingu</engName><name>허진구</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2022.11.14</priorityApplicationDate><priorityApplicationNumber>202211424815.3</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.10.17</receiptDate><receiptNumber>1-1-2023-1139021-95</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2023.11.02</receiptDate><receiptNumber>9-1-2023-9011958-55</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230138994.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934b8b2c27e59c3efc72f7d1b33b8747a6ad071a45fde8ef3ce04ca0e45768686ed1c991f5860138fab1940fcf88e50a4f42b71b8e89787dc4</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfe16f6e1574f300aeef5bd766a2127999a19bd560e68003e51f2a74daa1faa3e4cb78f221bc525086c430adcc55f5199ffb13da9677ea5b49</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>