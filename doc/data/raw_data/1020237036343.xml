<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:14.214</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.11.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7036343</applicationNumber><claimCount>33</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>자동화된 어시스턴트를 위한 소프트 엔드포인팅을 사용한 자연스러운 대화 활성화</inventionTitle><inventionTitleEng>ENABLING NATURAL CONVERSATIONS WITH SOFT ENDPOINTING FOR AN AUTOMATED ASSISTANT</inventionTitleEng><openDate>2023.11.20</openDate><openNumber>10-2023-0158615</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.10.23</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.10.23</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/22</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/87</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 15/187</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>G06F 3/16</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 사용자와 자동화된 어시스턴트 사이의 대화 세션의 일부로서, 구현예는 ASR 출력을 생성하기 위해 스트리밍 ASR 모델을 사용하여 음성 발화의 일부를 캡처하는 오디오 데이터의 스트림을 프로세싱하고, NLU 출력을 생성하기 위해 NLU 모델을 사용하여 ASR 출력을 프로세싱하며, NLU 출력에 기초하여 이행 데이터의 스트림이 생성되게 할 수 있다. 또한, 구현예는 오디오 데이터의 스트림의 프로세싱에 기초하여, 오디오 데이터의 스트림에서 캡처된 음성 발화의 일부와 연관된 오디오 기반 특성들을 추가로 결정할 수 있다. 오디오 기반 특성들 및/NLU 출력의 스트림에 기초하여, 구현예는 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정할 수 있다. 사용자가 일시정지한 경우, 구현예는 자연스러운 대화 출력이 사용자에게 제시되도록 제공되게 할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.02.23</internationOpenDate><internationOpenNumber>WO2023022743</internationOpenNumber><internationalApplicationDate>2021.11.29</internationalApplicationDate><internationalApplicationNumber>PCT/US2021/060987</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 프로세서들에 의해 구현되는 방법으로서, 상기 방법은:자동 스피치 인식(ASR) 모델을 사용하여, ASR 출력의 스트림을 생성하기 위해 오디오 데이터의 스트림을 프로세싱하는 단계, 상기 오디오 데이터의 스트림은 사용자 클라이언트 디바이스의 하나 이상의 마이크로폰들에 의해 생성되고, 그리고 상기 오디오 데이터의 스트림은 클라이언트 디바이스에서 적어도 부분적으로 구현되는 자동화된 어시스턴트로 향하는 사용자에 의해 제공되는 음성 발화의 일부를 캡처하며,자연어 이해(NLU) 모델을 사용하여, NLU 출력의 스트림을 생성하기 위해 상기 ASR 출력의 스트림을 프로세싱하는 단계; 상기 오디오 데이터의 스트림의 프로세싱에 기초하여, 음성 발화의 일부와 연관된 오디오 기반 특성들을 결정하는 단계;상기 음성 발화의 일부와 연관된 오디오 기반 특성들에 기초하여, 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계; 및사용자가 음성 발화 제공을 일시정지했다고 결정하는 것에 응답하여, 그리고 자동화된 어시스턴트가 적어도 상기 NLU 출력의 스트림에 기초하여 음성 발화의 이행을 개시할 수 있다고 결정하는 것에 응답하여: 사용자에게 청각적 제시를 위해 제공될 자연스러운 대화 출력을 결정하는 단계, 상기 자연스러운 대화 출력은 자동화된 어시스턴트가 사용자가 음성 발화 제공을 완료하기를 기다리고 있음을 나타내기 위해 사용자에게 청각적 제시를 위해 제공되며, 및 상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시로 제공되게 하는 단계는 사용자가 임계 기간 동안 음성 발화 제공을 일시정지했다고 결정하는 것에 응답하여 추가로 수행되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 음성 발화의 일부와 연관된 오디오 기반 특성들에 기초하여, 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계는:오디오 기반 분류 기계 학습(ML) 모델을 사용하여, 출력을 생성하기 위해 상기 음성 발화의 일부와 연관된 오디오 기반 특성들을 프로세싱하는 단계; 및상기 오디오 기반 분류 ML 모델을 사용하여 생성된 출력에 기초하여, 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 선행하는 어느 한 항에 있어서,상기 NLU 출력의 스트림에 기초하여 이행 데이터의 스트림이 생성되게 하는 단계를 더 포함하고, 상기 자동화된 어시스턴트가 음성 발화의 이행을 개시할 수 있다고 결정하는 것은 상기 이행 데이터의 스트림에 더 기초하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,사용자가 음성 발화 제공을 완료했다고 결정하는 것에 응답하여: 자동화된 어시스턴트가 상기 이행 데이터의 스트림에 기초하여 음성 발화의 이행을 개시하게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제4항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하면서 ASR 모델을 활용하는 하나 이상의 자동화된 어시스턴트 구성요소들을 활성화 상태로 유지하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제4항에 있어서,상기 ASR 출력의 스트림에 기초하여, 음성 발화가 특정 단어 또는 문구를 포함하는지 여부를 결정하는 단계; 및음성 발화가 특정 단어 또는 문구를 포함하고 있다고 결정하는 것에 응답하여: 상기 음성 발화의 일부와 연관된 오디오 기반 특성들에 기초하여, 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계를 억제(refraining)하는 단계; 및 자동화된 어시스턴트가 상기 이행 데이터의 스트림에 기초하여 음성 발화의 이행을 개시하게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제4항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 한 후, 사용자가 임계 기간 내에 음성 발화 제공을 계속했는지 여부를 결정하는 단계; 및사용자가 임계 기간 내에 하나 이상의 음성 발화들 제공을 계속하지 않았다고 결정하는 것에 응답하여: 상기 NLU 출력의 스트림 및 상기 이행 데이터의 스트림에 기초하여, 자동화된 어시스턴트가 음성 발화의 이행을 개시할 수 있는지 여부를 결정하는 단계; 및  자동화된 어시스턴트가 상기 이행 데이터의 스트림에 기초하여 음성 발화의 이행을 개시할 수 있다고 결정하는 것에 응답하여:  자동화된 어시스턴트가 상기 이행 데이터의 스트림에 기초하여 음성 발화의 이행을 개시하게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 선행하는 어느 한 항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 한 후, 사용자가 임계 기간 내에 음성 발화 제공을 계속했는지 여부를 결정하는 단계; 및사용자가 임계 기간 내에 하나 이상의 음성 발화들 제공을 계속하지 않았다고 결정하는 것에 응답하여: 사용자에게 청각적 제시를 위해 제공될 추가적인 자연스러운 대화 출력을 결정하는 단계; 및 상기 추가적인 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 선행하는 어느 한 항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하면서 하나 이상의 그래픽 요소들이 클라이언트 디바이스의 디스플레이를 통해 사용자에게 시각적 제시를 위해 제공되게 하는 단계를 더 포함하고, 상기 하나 이상의 그래픽 요소들은 자동화된 어시스턴트가 사용자가 음성 발화 제공을 완료하기를 기다리고 있음을 나타내기 위해 사용자에게 시각적 제시를 위해 제공되는, 방법.</claim></claimInfo><claimInfo><claim>11. 제 10항에 있어서,상기 ASR 출력은 상기 오디오 데이터의 스트림에서 캡처된 음성 발화의 일부에 대응하는 스트리밍 전사(transcription)를 포함하고, 상기 방법은:상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하면서 상기 스트리밍 전사가 클라이언트 디바이스의 디스플레이를 통해 사용자에게 시각적 제시를 위해 제공되게 하는 단계를 더 포함하고, 상기 하나 이상의 그래픽 요소들은 클라이언트 디바이스의 디스플레이를 통해 사용자에게 시각적 제시를 위해 제공되는 상기 스트리밍 전사에 프리펜딩(pre-pending)되거나 어펜딩(appending)되는, 방법.</claim></claimInfo><claimInfo><claim>12. 선행하는 어느 한 항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하면서 클라이언트 디바이스의 하나 이상의 발광 다이오드(LED)들이 조명되게 하는 단계를 더 포함하고, 상기 하나 이상의 LED들은 자동화된 어시스턴트가 사용자가 음성 발화 제공을 완료하기를 기다리고 있음을 나타내기 위해 조명되는, 방법.</claim></claimInfo><claimInfo><claim>13. 선행하는 어느 한 항에 있어서,상기 음성 발화의 일부와 연관된 오디오 기반 특성들은 억양, 톤, 강세, 리듬, 템포, 음높이, 일시정지, 일시정지와 연관된 하나 이상의 문법들, 및 긴 음절들 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 선행하는 어느 한 항에 있어서,상기 사용자에게 청각적 제시를 위해 제공될 자연스러운 대화 출력을 결정하는 단계는:클라이언트 디바이스의 온디바이스 메모리에 자연스러운 대화 출력들의 세트를 유지하는 단계; 및상기 음성 발화의 일부와 연관된 오디오 기반 특성들에 기초하여, 상기 자연스러운 대화 출력들의 세트 중에서, 상기 자연스러운 대화 출력을 선택하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 선행하는 어느 한 항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계는:사용자에게 청각적 제시를 위해 제공되는 다른 출력보다 낮은 볼륨으로 상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 선행하는 어느 한 항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계는:텍스트 스피치 변환(TTS) 모델을 사용하여, 상기 자연스러운 대화 출력을 포함하는 합성 스피치 오디오 데이터를 생성하기 위해 상기 자연스러운 대화 출력을 프로세싱하는 단계; 및상기 합성 스피치 오디오 데이터가 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 선행하는 어느 한 항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계는:클라이언트 디바이스의 온디바이스 메모리로부터, 상기 자연스러운 대화 출력을 포함하는 합성 스피치 오디오 데이터를 획득하는 단계; 및상기 합성 스피치 오디오 데이터가 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>18. 선행하는 어느 한 항에 있어서,상기 하나 이상의 프로세서들은 사용자의 클라이언트 디바이스에서 로컬로 구현되는, 방법.</claim></claimInfo><claimInfo><claim>19. 하나 이상의 프로세서들에 의해 구현되는 방법으로서, 상기 방법은:자동 스피치 인식(ASR) 모델을 사용하여, ASR 출력의 스트림을 생성하기 위해 오디오 데이터의 스트림을 프로세싱하는 단계, 상기 오디오 데이터의 스트림은 클라이언트 디바이스의 하나 이상의 마이크로폰들에 의해 생성되고, 그리고 상기 오디오 데이터의 스트림은 클라이언트 디바이스에서 적어도 부분적으로 구현되는 자동화된 어시스턴트로 향하는 사용자에 의해 제공되는 음성 발화의 일부를 캡처하며,자연어 이해(NLU) 모델을 사용하여, NLU 출력의 스트림을 생성하기 위해 상기 ASR 출력의 스트림을 프로세싱하는 단계;적어도 상기 NLU 출력의 스트림에 기초하여, 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계; 및사용자가 음성 발화 제공을 일시정지하고 음성 발화 제공을 완료하지 않았다고 결정하는 것에 응답하여: 사용자에게 청각적 제시를 위해 제공될 자연스러운 대화 출력을 결정하는 단계, 상기 자연스러운 대화 출력은 자동화된 어시스턴트가 사용자가 음성 발화 제공을 완료하기를 기다리고 있음을 나타내기 위해 사용자에게 청각적 제시를 위해 제공되며, 및 상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서, 상기 NLU 출력의 스트림에 기초하여, 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계는:상기 NLU 출력의 스트림에 기초하여, 자동화된 어시스턴트가 음성 발화의 이행을 개시할 수 있는지 여부를 결정하는 단계를 포함하고,상기 사용자가 음성 발화 제공을 일시정지했다고 결정하는 것은 자동화된 어시스턴트가 상기 NLU 출력의 스트림에 기초하여 음성 발화의 이행을 개시할 수 없다고 결정하는 것을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서,상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 한 후, 사용자가 임계 기간 내에 음성 발화 제공을 계속했는지 여부를 결정하는 단계; 및사용자가 음성 발화 제공을 계속하지 않았다고 결정하는 것에 응답하여: 사용자에게 청각적 제시를 위해 제공될 추가적인 자연스러운 대화 출력을 결정하는 단계, 상기 추가적인 자연스러운 대화 출력은 사용자가 음성 발화 제공을 완료하도록 요청하기 위해 사용자에게 청각적 제시를 위해 제공되며; 및 상기 추가적인 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 사용자에게 청각적 제시를 위해 제공될 추가적인 자연스러운 대화 출력은 음성 발화의 추가적인 부분이 NLU 데이터의 스트림에 기초한 특정 데이터를 포함하도록 요청하는, 방법.</claim></claimInfo><claimInfo><claim>23. 하나 이상의 프로세서들에 의해 구현되는 방법으로서, 상기 방법은:자동 스피치 인식(ASR) 모델을 사용하여, ASR 출력의 스트림을 생성하기 위해 오디오 데이터의 스트림을 프로세싱하는 단계, 상기 오디오 데이터의 스트림은 클라이언트 디바이스의 하나 이상의 마이크로폰들에 의해 생성되고, 그리고 상기 오디오 데이터의 스트림은 클라이언트 디바이스에서 적어도 부분적으로 구현되는 자동화된 어시스턴트로 향하는 사용자에 의해 제공되는 음성 발화의 일부를 캡처하며,자연어 이해(NLU) 모델을 사용하여, NLU 출력의 스트림을 생성하기 위해 상기 ASR 출력의 스트림을 프로세싱하는 단계;사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계; 및사용자가 음성 발화 제공을 일시정지하고 음성 발화 제공을 완료하지 않았다고 결정하는 것에 응답하여: 사용자에게 청각적 제시를 위해 제공될 자연스러운 대화 출력을 결정하는 단계, 상기 자연스러운 대화 출력은 자동화된 어시스턴트가 사용자가 음성 발화 제공을 완료하기를 기다리고 있음을 나타내기 위해 사용자에게 청각적 제시를 위해 제공되며,  상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계; 및 상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 한 후, 사용자가 임계 기간 내에 음성 발화 제공을 완료하지 않았다고 결정하는 것에 응답하여:  적어도 NLU 데이터의 스트림에 기초하여, 자동화된 어시스턴트가 음성 발화의 이행을 개시할 수 있는지 여부를 결정하는 단계; 및  자동화된 어시스턴트가 상기 NLU 데이터의 스트림에 기초하여, 음성 발화의 이행을 개시할 수 있다고 결정하는 것에 응답하여:   자동화된 어시스턴트가 음성 발화의 이행을 개시하게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 오디오 데이터의 스트림의 프로세싱에 기초하여, 음성 발화의 일부와 연관된 오디오 기반 특성들을 결정하는 단계를 더 포함하고,상기 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계는 음성 발화의 일부와 연관된 오디오 기반 특성들에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>25. 제23항 또는 제24항에 있어서, 상기 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계는 상기 NLU 데이터의 스트림에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>26. 제23항 내지 제25항 중 어느 한 항에 있어서,자동화된 어시스턴트가 상기 NLU 데이터의 스트림에 기초하여 음성 발화의 이행을 개시할 수 없다고 결정하는 것에 응답하여: 사용자에게 청각적 제시를 위해 제공될 자연스러운 대화 출력을 결정하는 단계, 상기 자연스러운 대화 출력은 사용자가 음성 발화 제공을 완료하도록 요청하기 위해 사용자에게 청각적 제시를 위해 제공되며; 및 추가적인 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서, 상기 사용자에게 청각적 제시를 위해 제공될 자연스러운 대화 출력은 음성 발화의 추가적인 부분이 NLU 데이터의 스트림에 기초한 특정 데이터를 포함하도록 요청하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제23항 내지 제27항 중 어느 한 항에 있어서, 자동화된 어시스턴트가 음성 발화의 이행을 개시할 수 있는지 여부를 결정하는 단계는 음성 발화의 이행과 연관된 하나 이상의 계산 비용들에 더 기초하는, 방법.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서,음성 발화의 이행과 연관된 하나 이상의 계산 비용들은: 음성 발화의 이행을 수행하는 것과 연관된 계산 비용 및 음성 발화의 수행된 이행을 취소하는 것과 연관된 계산 비용 중 하나 이상을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>30. 제23항 내지 제29항 중 어느 한 항에 있어서,상기 NLU 출력의 스트림에 기초하여, 이행 데이터의 스트림이 생성되게 하는 단계를 더 포함하고,상기 자동화된 어시스턴트가 음성 발화의 이행을 개시할 수 있다고 결정하는 것은 상기 이행 데이터의 스트림에 더 기초하는, 방법.</claim></claimInfo><claimInfo><claim>31. 하나 이상의 프로세서들에 의해 구현되는 방법으로서, 상기 방법은:오디오 데이터의 스트림을 수신하는 단계, 상기 오디오 데이터의 스트림은 클라이언트 디바이스의 하나 이상의 마이크로폰들에 의해 생성되고, 그리고 상기 오디오 데이터의 스트림은 클라이언트 디바이스에서 적어도 부분적으로 구현되는 자동화된 어시스턴트로 향하는 사용자에 의해 제공되는 음성 발화의 일부를 캡처하며,상기 오디오 데이터의 스트림의 프로세싱에 기초하여, 음성 발화의 일부와 연관된 오디오 기반 특성들을 결정하는 단계;상기 음성 발화의 일부와 연관된 오디오 기반 특성들에 기초하여, 사용자가 음성 발화 제공을 일시정지했는지 또는 음성 발화 제공을 완료했는지 여부를 결정하는 단계; 및사용자가 음성 발화 제공을 일시정지하고 음성 발화 제공을 완료하지 않았다고 결정하는 것에 응답하여: 사용자에게 청각적 제시를 위해 제공될 자연스러운 대화 출력을 결정하는 단계, 상기 자연스러운 대화 출력은 자동화된 어시스턴트가 사용자가 음성 발화 제공을 완료하기를 기다리고 있음을 나타내기 위해 사용자에게 청각적 제시를 위해 제공되며, 및 상기 자연스러운 대화 출력이 클라이언트 디바이스의 하나 이상의 스피커들을 통해 사용자에게 청각적 제시를 위해 제공되게 하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>32. 시스템으로서,적어도 하나의 프로세서; 및실행될 때, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제31항 중 어느 한 항에 대응하는 동작들을 수행하게 하는 명령어들을 저장하는 메모리를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>33. 비일시적 컴퓨터 판독가능 저장 매체로서, 실행될 때 적어도 하나의 프로세서로 하여금 제1항 내지 제31항 중 어느 한 항에 대응하는 동작들을 수행하게 하는 명령어들을 저장하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아 마운틴 뷰 엠피시어터 파크웨이 **** (우:*****)</address><code>520050013456</code><country>미국</country><engName>Google LLC</engName><name>구글 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>KONZELMANN, Jaclyn</engName><name>콘젤만 재클린</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>STROHMAN, Trevor</engName><name>스트로만 트레버</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>BLOOM, Jonathan</engName><name>블룸 조나단</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SCHALKWYK, Johan</engName><name>샬크윅 요한</name></inventorInfo><inventorInfo><address>미국 캘리포니아 마운틴 뷰 엠...</address><code> </code><country> </country><engName>SMARR, Joseph</engName><name>스마 조셉</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 강남대로 *** (논현동) *-*F(박장원특허법률사무소)</address><code>919980002023</code><country>대한민국</country><engName>PARK, Jang Won</engName><name>박장원</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.08.17</priorityApplicationDate><priorityApplicationNumber>63/233,877</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.11.22</priorityApplicationDate><priorityApplicationNumber>17/532,819</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.10.23</receiptDate><receiptNumber>1-1-2023-1162160-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.10.25</receiptDate><receiptNumber>1-5-2023-0169331-40</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237036343.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93a2d678329cfea7459f4b409ed5d921f5095da3907ba87914b2491825ddf8215e9388539fed650a9f5f694ae27b605f46066c78e0a971d832</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbc7079a1a6748d76e767b8d8c237844f99bfea40ad8f5876c6e6eb997abb8732650e09ee4388831fe2935ff5c13aa146865db48a97c6f7e7</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>