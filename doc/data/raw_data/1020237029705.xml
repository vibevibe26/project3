<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:42.4042</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.03.03</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7029705</applicationNumber><claimCount>65</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>다중-센서 이미지 캡처 디바이스들을 위한 변환 행렬 학습</inventionTitle><inventionTitleEng>TRANSFORM MATRIX LEARNING FOR MULTI-SENSOR IMAGE CAPTURE DEVICES</inventionTitleEng><openDate>2023.11.14</openDate><openNumber>10-2023-0156326</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.08.31</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/571</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/521</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2016.01.01)</ipcDate><ipcNumber>H04N 5/268</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>H04N 23/90</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미지 프레임들의 시퀀스 내의 아티팩트들은, 예를 들어, 이미지 프레임을 갖는 프레임들의 시퀀스 내의 다른 프레임에 매칭되는 시야를 갖는 정정된 이미지 프레임을 생성하기 위해 기하학적으로 와핑함으로써, 시퀀스 내의 다른 이미지 프레임과 매칭되도록 입력 이미지 프레임의 수정을 통해 감소되거나 제거될 수 있다. 와핑은 다중-센서 디바이스에 대한 데이터로부터 생성된 모델에 기반하여 수행될 수 있다. 이러한 이미지 프레임들 사이의 디스패리티는 다양한 깊이들에서의 장면들에 대한 제 1 이미지 센서 및 제 2 이미지 센서로부터의 이미지 캡처들에 기반하여 모델링될 수 있다. 모델은 캡처된 이미지들에 대한 디스패리티 값들을 예측하는데 사용될 수 있고, 이러한 예측된 디스패리티 값들은 이미지 센서 스위칭으로부터 초래되는 아티팩트들을 감소시키는데 사용된다. 예측된 디스패리티 값들은 잘못된 실제 디스패리티 값들을 초래하는 이미지 조건들에서 사용될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.09.22</internationOpenDate><internationOpenNumber>WO2022198168</internationOpenNumber><internationalApplicationDate>2022.03.03</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/070948</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서,제 1 이미지 센서와 제 2 이미지 센서 사이의 시야 (field of view) 차이를 나타내는 제 1 디스패리티 (disparity) 값을 수신하는 단계,상기 제 1 디스패리티 값에 대응하는 제 1 깊이 값을 수신하는 단계, 및복수의 깊이 값들에서 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 디스패리티에 대한 모델을 결정하는 단계로서, 상기 모델은 상기 제 1 디스패리티 값 및 상기 제 1 깊이에 적어도 부분적으로 기반하는, 상기 모델을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서,상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 하나의 이미지 센서로부터 입력 이미지 프레임을 수신하는 단계,상기 입력 이미지 프레임에 대응하는 입력 이미지 깊이를 수신하는 단계,상기 모델에 적어도 부분적으로 기반하여 상기 입력 이미지 깊이에 대응하는 예측된 디스패리티 값을 결정하는 단계, 및상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 정정된 이미지 프레임을 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는, 상기 예측된 디스패리티 값에 기반하여, 상기 정정된 이미지 프레임이 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야와 매칭하도록 와핑된 것으로 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제 2 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는,상기 입력 이미지 프레임을 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야로 와핑하기 위한 변환 행렬을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제 4 항에 있어서,상기 변환 행렬을 결정하는 단계는, 컴퓨터 비전 프로세싱 (CVP) 을 사용하여 상기 변환 행렬을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제 4 항에 있어서,상기 방법은,상기 변환 행렬과 연관된 신뢰 레벨이 임계 레벨 미만인지 여부를 결정하는 단계를 더 포함하고,상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 변환 행렬의 신뢰 레벨이 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 방법.</claim></claimInfo><claimInfo><claim>7. 제 2 항에 있어서,상기 방법은,상기 입력 이미지 프레임의 이미지 특성이 임계 레벨 미만임을 결정하는 단계를 더 포함하고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 이미지 특성이 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 방법.</claim></claimInfo><claimInfo><claim>8. 제 2 항에 있어서,상기 방법은,상기 입력 이미지 프레임의 밝기가 임계 레벨 미만임을 결정하는 단계를 더 포함하고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 밝기가 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 방법.</claim></claimInfo><claimInfo><claim>9. 제 2 항에 있어서, 상기 방법은,상기 제 1 이미지 센서로부터의 제 1 이미지 프레임, 상기 제 2 이미지 센서로부터의 제 2 이미지 프레임, 및 상기 정정된 이미지 프레임을 포함하는 비디오 시퀀스를 결정하는 단계를 더 포함하고,상기 정정된 이미지 프레임은 상기 제 1 이미지 프레임과 상기 제 2 이미지 프레임 사이의 상기 비디오 시퀀스에 나타나는, 방법.</claim></claimInfo><claimInfo><claim>10. 제 2 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 이미지 프레임에 추가로 기반하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제 1 항에 있어서,상기 제 1 디스패리티 값은 제 1 축을 따른 시야 차이를 나타내고,상기 방법은,상기 제 1 축과 상이한 제 2 축을 따라 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 시야 차이를 나타내는 제 2 디스패리티 값을 수신하는 단계를 더 포함하고,상기 모델을 결정하는 단계는 상기 제 2 디스패리티 값에 적어도 부분적으로 더 기반하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제 1 항에 있어서,상기 모델을 결정하는 단계는,복수의 디스패리티 값들을 저장하는 단계로서, 상기 모델은 상기 복수의 디스패리티 값들에 기반하는, 상기 복수의 디스패리티 값들을 저장하는 단계, 및상기 복수의 디스패리티 값들에서의 값들의 수 또는 이전 값과 연관된 시간 중 적어도 하나에 기반하여 상기 복수의 디스패리티 값들의 상기 이전 값을 상기 제 1 디스패리티 값으로 대체하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제 1 항에 있어서,상기 제 1 깊이 값은 상기 제 1 이미지 센서에 의해 캡처된 제 1 입력 이미지 프레임에 대응하는 자동 초점 깊이를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제 1 항에 있어서,레인지 이미징 (range imaging) 에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제 14 항에 있어서,상기 제 1 깊이 값을 결정하는 단계는 비행 시간 (ToF) 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제 14 항에 있어서,상기 제 1 깊이 값을 결정하는 단계는 광 검출 및 레이징 (LIDAR) 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>17. 디바이스로서,프로세서, 및상기 프로세서에 결합되고 명령을 저장하는 메모리를 포함하고,상기 명령은, 상기 프로세서에 의해 실행될 때, 상기 디바이스로 하여금 제 1 이미지 센서와 제 2 이미지 센서 사이의 시야 차이를 나타내는 제 1 디스패리티 값을 수신하는 단계, 상기 제 1 디스패리티 값에 대응하는 제 1 깊이 값을 수신하는 단계, 및 복수의 깊이 값들에서 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 디스패리티에 대한 모델을 결정하는 단계로서, 상기 모델은 상기 제 1 디스패리티 값 및 상기 제 1 깊이에 적어도 부분적으로 기반하는, 상기 모델을 결정하는 단계를 포함하는 동작들을 수행하게 하는, 디바이스.</claim></claimInfo><claimInfo><claim>18. 제 17 항에 있어서,명령들은 상기 디바이스로 하여금 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 하나의 이미지 센서로부터 입력 이미지 프레임을 수신하는 단계, 상기 입력 이미지 프레임에 대응하는 입력 이미지 깊이를 수신하는 단계, 상기 모델에 적어도 부분적으로 기반하여 상기 입력 이미지 깊이에 대응하는 예측된 디스패리티 값을 결정하는 단계, 및 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 정정된 이미지 프레임을 결정하는 단계를 더 포함하는 동작들을 수행하도록 하는, 디바이스.</claim></claimInfo><claimInfo><claim>19. 제 18 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는, 상기 예측된 디스패리티 값에 기반하여, 정정된 이미지 프레임이 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야와 매칭하도록 와핑된 것으로 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>20. 제 18 항에 있어서,  상기 정정된 이미지 프레임을 결정하는 단계는,상기 입력 이미지 프레임을 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야로 와핑하기 위한 변환 행렬을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>21. 제 20 항에 있어서,상기 변환 행렬을 결정하는 단계는, 컴퓨터 비전 프로세싱 (CVP) 을 사용하여 상기 변환 행렬을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>22. 제 20 항에 있어서,상기 명령들은 상기 디바이스로 하여금 상기 변환 행렬과 연관된 신뢰 레벨이 임계 레벨 미만인지 여부를 결정하는 단계를 더 포함하는 동작들을 수행하게 하고,상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 변환 행렬의 신뢰 레벨이 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 디바이스.</claim></claimInfo><claimInfo><claim>23. 제 18 항에 있어서,상기 명령들은 상기 디바이스로 하여금 상기 입력 이미지 프레임의 이미지 특성이 임계 레벨 미만임을 결정하는 단계를 더 포함하는 동작들을 수행하게 하고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 이미지 특성이 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 디바이스.</claim></claimInfo><claimInfo><claim>24. 제 18 항에 있어서,상기 명령들은 상기 디바이스로 하여금 상기 입력 이미지 프레임의 밝기가 임계 레벨 미만임을 결정하는 단계를 더 포함하는 동작들을 수행하게 하고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 밝기가 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 디바이스.</claim></claimInfo><claimInfo><claim>25. 제 18 항에 있어서,상기 명령들은 상기 디바이스로 하여금 상기 제 1 이미지 센서로부터의 제 1 이미지 프레임, 상기 제 2 이미지 센서로부터의 제 2 이미지 프레임, 및 상기 정정된 이미지 프레임을 포함하는 비디오 시퀀스를 결정하는 단계를 더 포함하는 동작들을 수행하게 하고,상기 정정된 이미지 프레임은 상기 제 1 이미지 프레임과 상기 제 2 이미지 프레임 사이의 상기 비디오 시퀀스에 나타나는, 디바이스.</claim></claimInfo><claimInfo><claim>26. 제 18 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 이미지 프레임에 추가로 기반하는, 디바이스.</claim></claimInfo><claimInfo><claim>27. 제 17 항에 있어서,상기 제 1 디스패리티 값은 제 1 축을 따른 시야 차이를 나타내고,상기 명령들은 디바이스로 하여금 상기 제 1 축과 상이한 제 2 축을 따라 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 시야 차이를 나타내는 제 2 디스패리티 값을 수신하는 단계를 더 포함하는 동작들을 수행하게 하고,상기 모델을 결정하는 단계는 상기 제 2 디스패리티 값에 적어도 부분적으로 더 기반하는, 디바이스.</claim></claimInfo><claimInfo><claim>28. 제 17 항에 있어서,상기 모델을 결정하는 단계는,복수의 디스패리티 값들을 저장하는 단계로서, 상기 모델은 상기 복수의 디스패리티 값들에 기반하는, 상기 복수의 디스패리티 값들을 저장하는 단계, 및상기 복수의 디스패리티 값들에서의 값들의 수 또는 이전 값과 연관된 시간 중 적어도 하나에 기반하여 상기 복수의 디스패리티 값들의 상기 이전 값을 상기 제 1 디스패리티 값으로 대체하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>29. 제 17 항에 있어서,상기 제 1 깊이 값은 상기 제 1 이미지 센서에 의해 캡처된 제 1 입력 이미지 프레임에 대응하는 자동 초점 깊이를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>30. 제 17 항에 있어서,상기 명령들은 상기 디바이스로 하여금 레인지 이미징에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 더 포함하는 동작들을 수행하게 하는, 디바이스.</claim></claimInfo><claimInfo><claim>31. 제 30 항에 있어서,상기 제 1 깊이 값을 결정하는 단계는 비행 시간 (ToF) 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>32. 제 30 항에 있어서,상기 제 1 깊이 값을 결정하는 단계는 광 검출 및 레이징 (LIDAR) 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>33. 명령들을 포함하는 비일시적 컴퓨터 판독가능 저장 매체로서,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 제 1 이미지 센서와 제 2 이미지 센서 사이의 시야 차이를 나타내는 제 1 디스패리티 값을 수신하는 단계, 상기 제 1 디스패리티 값에 대응하는 제 1 깊이 값을 수신하는 단계, 및 복수의 깊이 값들에서 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 디스패리티에 대한 모델을 결정하는 단계로서, 상기 모델은 상기 제 1 디스패리티 값 및 상기 제 1 깊이에 적어도 부분적으로 기반하는, 상기 모델을 결정하는 단계를 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>34. 제 33 항에 있어서,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 하나의 이미지 센서로부터 입력 이미지 프레임을 수신하는 단계, 상기 입력 이미지 프레임에 대응하는 입력 이미지 깊이를 수신하는 단계, 상기 모델에 적어도 부분적으로 기반하여 상기 입력 이미지 깊이에 대응하는 예측된 디스패리티 값을 결정하는 단계, 및 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 정정된 이미지 프레임을 결정하는 단계를 더 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>35. 제 34 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는, 상기 예측된 디스패리티 값에 기반하여, 정정된 이미지 프레임이 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야와 매칭하도록 와핑된 것으로 결정하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>36. 제 34 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는,상기 입력 이미지 프레임을 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야로 와핑하기 위한 변환 행렬을 결정하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>37. 제 36 항에 있어서,상기 변환 행렬을 결정하는 단계는, 컴퓨터 비전 프로세싱 (CVP) 을 사용하여 상기 변환 행렬을 결정하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>38. 제 36 항에 있어서,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 변환 행렬과 연관된 신뢰 레벨이 임계 레벨 미만인지 여부를 결정하는 단계를 더 포함하는 동작들을 수행하게 하고,상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 변환 행렬의 신뢰 레벨이 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>39. 제 34 항에 있어서,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 입력 이미지 프레임의 이미지 특성이 임계 레벨 미만임을 결정하는 단계를 더 포함하는 동작들을 수행하게 하고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 이미지 특성이 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>40. 제 34 항에 있어서,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 입력 이미지 프레임의 밝기가 임계 레벨 미만임을 결정하는 단계를 더 포함하는 동작들을 수행하게 하고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 밝기가 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>41. 제 34 항에 있어서,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 제 1 이미지 센서로부터의 제 1 이미지 프레임, 상기 제 2 이미지 센서로부터의 제 2 이미지 프레임, 및 상기 정정된 이미지 프레임을 포함하는 비디오 시퀀스를 결정하는 단계를 더 포함하는 동작들을 수행하게 하고,상기 정정된 이미지 프레임은 상기 제 1 이미지 프레임과 상기 제 2 이미지 프레임 사이의 상기 비디오 시퀀스에 나타나는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>42. 제 34 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 이미지 프레임에 추가로 기반하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>43. 제 33 항에 있어서,상기 제 1 디스패리티 값은 제 1 축을 따른 시야 차이를 나타내고,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금, 상기 제 1 축과 상이한 제 2 축을 따라 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 시야 차이를 나타내는 제 2 디스패리티 값을 수신하는 단계를 더 포함하는 동작들을 수행하게 하고,상기 모델을 결정하는 단계는 상기 제 2 디스패리티 값에 적어도 부분적으로 더 기반하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>44. 제 33 항에 있어서,상기 모델을 결정하는 단계는,복수의 디스패리티 값들을 저장하는 단계로서, 상기 모델은 상기 복수의 디스패리티 값들에 기반하는, 상기 복수의 디스패리티 값들을 저장하는 단계, 및상기 복수의 디스패리티 값들에서의 값들의 수 또는 이전 값과 연관된 시간 중 적어도 하나에 기반하여 상기 복수의 디스패리티 값들의 상기 이전 값을 상기 제 1 디스패리티 값으로 대체하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>45. 제 33 항에 있어서,상기 제 1 깊이 값은 상기 제 1 이미지 센서에 의해 캡처된 제 1 입력 이미지 프레임에 대응하는 자동 초점 깊이를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>46. 제 33 항에 있어서,상기 명령들은, 디바이스의 프로세서에 의해 실행될 때, 상기 디바이스로 하여금,  레인지 이미징에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 더 포함하는 동작들을 수행하게 하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>47. 제 46 항에 있어서,상기 제 1 깊이 값을 결정하는 단계는 비행 시간 (ToF) 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>48. 제 46 항에 있어서,상기 제 1 깊이 값을 결정하는 단계는 광 검출 및 레이징 (LIDAR) 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>49. 디바이스로서,제 1 시야로 구성된 제 1 이미지 센서,상기 제 1 시야와 적어도 부분적으로 중첩되는 제 2 시야로 구성된 제 2 이미지 센서,상기 제 1 이미지 센서에 커플링되고 상기 제 2 이미지 센서에 커플링된 프로세서, 및상기 프로세서에 커플링된 메모리를 포함하고, 상기 프로세서는, 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 시야 차이를 나타내는 제 1 디스패리티 값을 수신하는 단계, 상기 제 1 디스패리티 값에 대응하는 제 1 깊이 값을 수신하는 단계, 및 복수의 깊이 값들에서 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 디스패리티에 대한 모델을 결정하는 단계로서, 상기 모델은 상기 제 1 디스패리티 값 및 상기 제 1 깊이에 적어도 부분적으로 기반하는, 상기 모델을 결정하는 단계를 포함하는 단계들을 수행하도록 구성되는, 디바이스.</claim></claimInfo><claimInfo><claim>50. 제 49 항에 있어서,상기 프로세서는, 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 하나의 이미지 센서로부터 입력 이미지 프레임을 수신하는 단계, 상기 입력 이미지 프레임에 대응하는 입력 이미지 깊이를 수신하는 단계, 상기 모델에 적어도 부분적으로 기반하여 상기 입력 이미지 깊이에 대응하는 예측된 디스패리티 값을 결정하는 단계, 및 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 정정된 이미지 프레임을 결정하는 단계를 포함하는 단계들을 수행하도록 추가로 구성되는, 디바이스.</claim></claimInfo><claimInfo><claim>51. 제 50 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는, 상기 예측된 디스패리티 값에 기반하여, 정정된 이미지 프레임이 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야와 매칭하도록 와핑된 것으로 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>52. 제 50 항에 있어서,  상기 정정된 이미지 프레임을 결정하는 단계는,상기 입력 이미지 프레임을 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 시야로 와핑하기 위한 상기 입력 이미지 프레임에 대한 변환 행렬을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>53. 제 52 항에 있어서,상기 변환 행렬을 결정하는 단계는, 컴퓨터 비전 프로세싱 (CVP) 을 사용하여 상기 변환 행렬을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>54. 제 52 항에 있어서,상기 프로세서는, 상기 변환 행렬과 연관된 신뢰 레벨이 임계 레벨 미만인지 여부를 결정하는 단계를 포함하는 단계들을 수행하도록 추가로 구성되고,상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 변환 행렬의 신뢰 레벨이 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 디바이스.</claim></claimInfo><claimInfo><claim>55. 제 50 항에 있어서,상기 프로세서는, 상기 입력 이미지 프레임의 이미지 특성이 임계 레벨 미만임을 결정하는 단계를 포함하는 단계들을 수행하도록 추가로 구성되고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 이미지 특성이 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 디바이스.</claim></claimInfo><claimInfo><claim>56. 제 50 항에 있어서,상기 프로세서는, 상기 입력 이미지 프레임의 밝기가 임계 레벨 미만임을 결정하는 단계를 포함하는 단계들을 수행하도록 추가로 구성되고, 상기 입력 이미지 프레임 및 상기 예측된 디스패리티 값에 적어도 부분적으로 기반하여 상기 정정된 이미지 프레임을 결정하는 단계는 상기 밝기가 상기 임계 레벨 미만이라고 결정하는 것에 기반하여 수행되는, 디바이스.</claim></claimInfo><claimInfo><claim>57. 제 50 항에 있어서,상기 프로세서는, 상기 제 1 이미지 센서로부터의 제 1 이미지 프레임, 상기 제 2 이미지 센서로부터의 제 2 이미지 프레임, 및 상기 정정된 이미지 프레임을 포함하는 비디오 시퀀스를 결정하는 단계를 포함하는 단계들을 수행하도록 추가로 구성되고,상기 정정된 이미지 프레임은 상기 제 1 이미지 프레임과 상기 제 2 이미지 프레임 사이의 상기 비디오 시퀀스에 나타나는, 디바이스.</claim></claimInfo><claimInfo><claim>58. 제 50 항에 있어서,상기 정정된 이미지 프레임을 결정하는 단계는 상기 제 1 이미지 센서 또는 상기 제 2 이미지 센서 중 다른 이미지 센서의 이미지 프레임에 추가로 기반하는, 디바이스.</claim></claimInfo><claimInfo><claim>59. 제 49 항에 있어서,상기 제 1 디스패리티 값은 제 1 축을 따른 시야 차이를 나타내고,상기 프로세서는, 상기 제 1 축과 상이한 제 2 축을 따라 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 시야 차이를 나타내는 제 2 디스패리티 값을 수신하는 단계를 더 포함하는 단계들을 수행하도록 구성되고,상기 모델을 결정하는 단계는 상기 제 2 디스패리티 값에 적어도 부분적으로 더 기반하는, 디바이스.</claim></claimInfo><claimInfo><claim>60. 제 49 항에 있어서,상기 모델을 결정하는 단계는,복수의 디스패리티 값들을 저장하는 단계로서, 상기 모델은 상기 복수의 디스패리티 값들에 기반하는, 상기 복수의 디스패리티 값들을 저장하는 단계, 및상기 복수의 디스패리티 값들에서의 값들의 수 또는 이전 값과 연관된 시간 중 적어도 하나에 기반하여 상기 복수의 디스패리티 값들의 상기 이전 값을 상기 제 1 디스패리티 값으로 대체하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>61. 제 49 항에 있어서,상기 디바이스는 깊이 센서를 더 포함하고,상기 프로세서는 상기 깊이 센서에 커플링되고, 상기 깊이 센서로부터 상기 제 1 깊이 값을 수신하도록 구성되는, 디바이스.</claim></claimInfo><claimInfo><claim>62. 제 61 항에 있어서,상기 깊이 센서는 레인지 이미징 시스템을 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>63. 제 62 항에 있어서,상기 깊이 센서는 비행 시간 (ToF) 시스템을 포함하고,상기 제 1 깊이 값을 결정하는 단계는 상기 ToF 시스템으로부터의 ToF 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>64. 제 62 항에 있어서,상기 깊이 센서는 광 검출 및 레이징 (LIDAR) 시스템을 포함하고,상기 제 1 깊이 값을 결정하는 단계는 상기 LIDAR 시스템으로부터의 LIDAR 측정에 기반하여 상기 제 1 깊이 값을 결정하는 단계를 포함하는, 디바이스.</claim></claimInfo><claimInfo><claim>65. 제 49 항에 있어서, 상기 디바이스는,상기 프로세서에 커플링된 컴퓨터 비전 프로세서 (CVP) 를 더 포함하고,상기 CVP 는,  상기 제 1 이미지 센서로부터 제 1 이미지 프레임을 수신하는 단계, 상기 제 2 이미지 센서로부터 제 2 이미지 프레임을 수신하는 단계, 및 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 시야 차이를 결정하기 위해 상기 제 1 이미지 프레임과 상기 제 2 이미지 프레임 사이의 특징 매칭하는 단계를 포함하는 동작들을 수행하도록 구성되고, 상기 프로세서는 상기 CVP 로부터 상기 제 1 디스패리티 값으로서 상기 제 1 이미지 센서와 상기 제 2 이미지 센서 사이의 시야 차이를 수신하도록 구성되는, 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>LIU, SHIZHONG</engName><name>리우 시종</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>HUANG, JINCHENG</engName><name>황 진청 </name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>LIU, WEILIANG</engName><name>리우 웨이량</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>REN, JIANFENG</engName><name>렌 지안펑</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>PHANIRAJ VENKATESH, SAHUL MADANAYAKANAHALLI</engName><name>파니라즈 벤카테쉬 사훌 마다나야카날리 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.03.15</priorityApplicationDate><priorityApplicationNumber>17/201,660</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.08.31</receiptDate><receiptNumber>1-1-2023-0961803-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.10.18</receiptDate><receiptNumber>1-5-2023-0164663-21</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.02.17</receiptDate><receiptNumber>1-1-2025-0182747-66</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.02.17</receiptDate><receiptNumber>1-1-2025-0182748-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.02.17</receiptDate><receiptNumber>1-1-2025-0182749-57</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237029705.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c937075e17ea58c44997171354483ddf4f1da9d5ec0ba4bc52d387aaa91b56355c6bdd950f0066d7627a84af4cd8dfbfecdc58b99c5043a9788</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd0792bd55b5756e0e653380920458b93a799ce4b4ed16dc10d30494f9b4805cfd9c54b0fd13382754ad3255499ec5a8fcca8c8d41804177f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>