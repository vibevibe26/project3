<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:37.5337</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.01.11</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0004300</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>분산 학습 시스템을 위한 데이터 로딩 방법 및 장치</inventionTitle><inventionTitleEng>DATA LOADING METHOD FOR DISTRIBUTED TRAINING SYSTEM  AND APPARATUS THEREOF</inventionTitleEng><openDate>2024.07.18</openDate><openNumber>10-2024-0112119</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/098</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/063</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 분산 학습 시스템을 위한 데이터 로딩 방법 및 장치가 개시된다. 일 실시예에 따른 복수의 프로세서들을 포함하는 분산 학습 시스템을 위한 데이터 로딩 방법은 학습 데이터 셋에 포함된 복수의 데이터 파일들의 크기들에 기초하여, 학습 데이터 셋을 복수의 서브 셋들로 분할하는 단계, 각 서브 셋 내 일부 데이터 파일을 복수의 프로세서들에 로딩하는 단계, 및 복수의 서브 셋들 간 데이터 파일 수의 비율 및 분산 학습의 배치 사이즈(batch size)에 기초하여, 복수의 프로세서들 중 동일한 그룹 내 프로세서들에 로딩된 데이터 파일들의 패킹(packing) 조합을 결정하는 단계, 패킹 조합에 따라 데이터를 패킹하여 패킹 데이터 파일들을 결정하는 단계 및 동일한 그룹 내 프로세서들에 패킹 데이터 파일들을 재할당하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 복수의 프로세서들을 포함하는 분산 학습 시스템을 위한 데이터 로딩 방법에 있어서,학습 데이터 셋에 포함된 복수의 데이터 파일들의 크기들에 기초하여, 상기 학습 데이터 셋을 복수의 서브 셋들로 분할하는 단계;각 서브 셋 내 일부 데이터 파일을 상기 복수의 프로세서들에 로딩하는 단계;상기 복수의 서브 셋들 간 데이터 파일 수의 비율 및 분산 학습의 배치 사이즈(batch size)에 기초하여, 상기 복수의 프로세서들 중 동일한 그룹 내 프로세서들에 로딩된 데이터 파일들의 패킹(packing) 조합을 결정하는 단계;상기 패킹 조합에 따라 데이터 파일을 패킹하여 패킹 데이터 파일들을 결정하는 단계; 및상기 동일한 그룹 내 프로세서들에 상기 패킹 데이터 파일들을 재할당하는 단계를 포함하는 데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 패킹 조합을 결정하는 단계는분산 학습의 배치 사이즈에 따라 최대 데이터 파일 크기 내에서 패킹할 수 있는 후보 패킹 조합들을 추출하는 단계; 및상기 복수의 서브 셋들 간 데이터 파일 수의 비율에 기초하여, 상기 후보 패킹 조합들 중에서 상기 패킹 조합을 결정하는 단계를 포함하는, 데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 패킹 조합을 결정하는 단계는상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율을 획득하는 단계;상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율을 상기 복수의 서브 셋들 간 데이터 파일 수의 비율과 비교하는 단계; 및상기 비교 결과에 기초하여, 상기 패킹 조합을 결정하는 단계를 포함하는, 데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>4. 제2항에 있어서,상기 패킹 조합을 결정하는 단계는상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율을 획득하는 단계; 및상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율 및 후보 패킹 조합들 각각에 대응하는 패킹 배치 사이즈에 기초하여, 상기 패킹 조합을 결정하는 단계를 포함하는, 데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 재할당하는 단계는상기 패킹 데이터 파일들의 크기에 기초하여, 상기 동일한 그룹 내 프로세서들에 상기 패킹 데이터 파일들을 재할당하는 단계를 포함하는, 데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 로딩하는 단계는상기 복수의 서브 셋들 간 데이터 파일 수의 비율 및 분산 학습의 배치 사이즈에 기초하여, 각 서브 셋 내 일부 데이터 파일을 상기 복수의 프로세서들에 로딩하는 단계를 포함하는, 데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 패킹 데이터 파일들을 재할당하는 단계는상기 패킹 데이터 파일들을 크기 순서로 정렬하는 단계; 및상기 정렬된 패킹 데이터 파일들을 상기 동일한 그룹 내 프로세서들에 미리 정해진 제1 순서로 분배한 후, 상기 제1 순서의 역순인 제2 순서로 분배하는 단계를 포함하는,데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 제1 순서로 분배한 후, 상기 제2 순서로 분배하는 단계는상기 배치 사이즈 내에서 반복적으로 수행되는,데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 동일한 그룹은동일한 서버 내 프로세서들의 집합을 포함하는,데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 학습 데이터 셋은자연어 처리 모델의 학습을 위한 자연어 텍스트 데이터; 및자연어 처리 모델의 학습을 위한 발화 데이터중 적어도 하나를 포함하는,데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서,상기 프로세서는 GPU를 포함하는,데이터 로딩 방법.</claim></claimInfo><claimInfo><claim>12. 하드웨어와 결합되어 제1항 내지 제12항 중 어느 하나의 항의 방법을 실행시키기 위하여 매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>13. 복수의 프로세서들을 포함하는 분산 학습 시스템을 위한 데이터 로딩 장치에 있어서,적어도 하나의 명령어를 저장하는 메모리; 및상기 메모리에 저장된 명령어를 실행함으로써,학습 데이터 셋에 포함된 복수의 데이터 파일들의 크기들에 기초하여, 상기 학습 데이터 셋을 복수의 서브 셋들로 분할하고,각 서브 셋 내 일부 데이터 파일을 상기 복수의 프로세서들에 로딩하고,상기 복수의 서브 셋들 간 데이터 파일 수의 비율 및 분산 학습의 배치 사이즈(batch size)에 기초하여, 상기 복수의 프로세서들 중 동일한 그룹 내 프로세서들에 로딩된 데이터 파일들의 패킹(packing) 조합을 결정하고,상기 패킹 조합에 따라 데이터 파일을 패킹하여 패킹 데이터 파일들을 결정하고,상기 동일한 그룹 내 프로세서들에 상기 패킹 데이터 파일들을 재할당하는 적어도 하나의 프로세서를 포함하는, 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 프로세서는분산 학습의 배치 사이즈에 따라 최대 데이터 파일 크기 내에서 패킹할 수 있는 후보 패킹 조합들을 추출하고,상기 복수의 서브 셋들 간 데이터 파일 수의 비율에 기초하여, 상기 후보 패킹 조합들 중에서 상기 패킹 조합을 결정하는, 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 프로세서는상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율을 획득하고,상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율을 상기 복수의 서브 셋들 간 데이터 파일 수의 비율과 비교하고,상기 비교 결과에 기초하여, 상기 패킹 조합을 결정하는, 장치.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,상기 프로세서는상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율을 획득하고,상기 후보 패킹 조합들 각각에 대응하는 데이터 파일 수의 비율 및 후보 패킹 조합들 각각에 대응하는 패킹 배치 사이즈에 기초하여, 상기 패킹 조합을 결정하는, 장치.</claim></claimInfo><claimInfo><claim>17. 제14항에 있어서,상기 프로세서는상기 패킹 데이터 파일들의 크기에 기초하여, 상기 동일한 그룹 내 프로세서들에 상기 패킹 데이터 파일들을 재할당하는, 장치.</claim></claimInfo><claimInfo><claim>18. 제14항에 있어서,상기 프로세서는상기 패킹 데이터 파일들을 크기 순서로 정렬하고,상기 정렬된 패킹 데이터 파일들을 상기 동일한 그룹 내 프로세서들에 미리 정해진 제1 순서로 분배한 후, 상기 제1 순서의 역순인 제2 순서로 분배하는, 장치.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 프로세서는상기 배치 사이즈 내에서 반복적으로 수행되는, 장치.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 학습 데이터 셋은자연어 처리 모델의 학습을 위한 자연어 텍스트 데이터; 및자연어 처리 모델의 학습을 위한 발화 데이터중 적어도 하나를 포함하고,상기 프로세서는 GPU를 포함하는, 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420200299705</code><country>대한민국</country><engName>KIM, Myeong Woo</engName><name>김명우</name></inventorInfo><inventorInfo><address>경기도 화성...</address><code>420210837345</code><country>대한민국</country><engName>Kim, Yongdeok</engName><name>김용덕</name></inventorInfo><inventorInfo><address>경기도 용인시 수지구...</address><code>420190282361</code><country>대한민국</country><engName>CHOI,Chang In</engName><name>최창인</name></inventorInfo><inventorInfo><address>경기도 화성시  영통로**번길  *...</address><code>419990462827</code><country>대한민국</country><engName>LEE SEUNG WON</engName><name>이승원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.01.11</receiptDate><receiptNumber>1-1-2023-0041406-15</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230004300.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9302a02d0175b4ee99c35a69c5ab44ada014818032df84b2fe27ada2897fa217047f00f9128db783ae6b1ea72d043ba4c2d1f546e009fc8a7e</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd05e72d5bf722dddfe38d1408b54b79e917c69681743078be3eb3a98a9d03cae224091efe778800f78278a5cdecac292c25e3f78f00be6e8</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>