<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:55:41.5541</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0093745</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>양식화된 아바타로의 표정 전사</inventionTitle><inventionTitleEng>EXPRESSION TRANSFER TO STYLIZED AVATARS</inventionTitleEng><openDate>2024.01.30</openDate><openNumber>10-2024-0013685</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 향상된 현실 애플리케이션을 위해 양식화된 아바타를 개인화하는 방법이 제공된다. 방법은, 제1 대상의 얼굴 표정의 이미지를 캡처하는 단계, 이미지에서, 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하는 단계, 사람 모델에서의 표준 표정의 세트로부터, 제1 대상의 얼굴 표정에 기초하여 선택된 표정을 식별하는 단계, 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 사람 모델에서의 선택된 표정에 전사하는 단계, 및 클라이언트 디바이스 상의 디스플레이를 위해 몰입형 현실 애플리케이션에 사람 모델을 제공하는 단계를 포함한다. 명령어를 저장하는 메모리, 프로세서, 및 명령어를 실행할 때 프로세서가 위의 방법을 수행하도록 하는 시스템이 또한 제공된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터 구현 방법에 있어서,제1 대상(subject)의 얼굴 표정의 이미지를 캡처하는 단계;상기 이미지에서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하는 단계;사람 모델에서의 표준 표정의 세트로부터, 상기 제1 대상의 얼굴 표정에 기초하여 선택된 표정을 식별하는 단계;상기 제1 대상의 개인적 특성을 나타내는 상기 하나 이상의 특징을 상기 사람 모델에서의 상기 선택된 표정에 전사(transfer)하는 단계; 및클라이언트 디바이스 상의 디스플레이를 위해 몰입형 현실 애플리케이션에 상기 사람 모델을 제공하는 단계를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 대상은 향상된 현실 헤드셋의 사용자이고, 상기 제1 대상의 얼굴 표정의 이미지를 캡처하는 단계는, 상기 향상된 현실 헤드셋 상에 장착된 카메라를 이용해 상기 이미지를 캡처하는 단계를 포함하는 것인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하는 단계는, 상기 제1 대상의 얼굴 표정의 이미지 상에 겹쳐진 메쉬로부터, 선택된 임계값보다 더 큰 양만큼 이동된 정점 그룹을 선택하는 단계를 포함하는 것인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하는 단계는, 상기 제1 대상의 얼굴 표정의 이미지에 대한 메쉬의 모션과 연관된 미분 텐서(derivative tensor)에서의 하나 이상의 임계점을 찾는 단계를 포함하는 것인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하는 단계는, 상기 제1 대상의 이미지와 연관된 3차원 메쉬 내의 하나 이상의 키 포인트의 변위를 식별하는 단계를 포함하는 것인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 제1 대상의 얼굴 표정에 기초하여 선택된 표정을 식별하는 단계는, 상기 제1 대상의 얼굴 표정과 연관된 메쉬 내의 다수의 정점과, 상기 선택된 표정을 갖는 상기 사람 모델과 연관된 메쉬 내의 다수의 정점 사이의 거리의 측정치를 찾는 단계를 포함하는 것인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 사람 모델을 상기 사람 모델의 양식화된 아바타로서 선택하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 상기 하나 이상의 특징을 상기 사람 모델에서의 상기 선택된 표정에 전사하는 단계는, 상기 제1 대상에 대한 메쉬 내의 정점 그룹의 움직임을 상기 사람 모델에 대한 메쉬 내의 대응하는 정점 그룹에 복사하는 단계를 포함하는 것인, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 클라이언트 디바이스는 사용자와 함께 있고, 상기 방법은, 상기 제1 대상과 함께 있는 제2 클라이언트 디바이스 상의 디스플레이를 위해 상기 몰입형 현실 애플리케이션에 상기 사용자의 얼굴 표정으로 수정된 제2 양식화된 사람 모델을 제공하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 몰입형 현실 애플리케이션은 상기 제1 대상과 제2 대상 사이에 공유되고, 상기 방법은, 상기 클라이언트 디바이스 상의 상기 디스플레이에 상기 제2 대상의 얼굴 표정으로 수정된 제2 양식화된 사람 모델을 제공하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>11. 시스템에 있어서,다수의 명령어를 저장하는 메모리; 및동작을 수행하기 위해 상기 명령어를 실행하도록 구성된 하나 이상의 프로세서를 포함하고, 상기 동작은, 제1 대상의 얼굴 표정의 이미지를 캡처하는 것; 상기 이미지에서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하는 것; 사람 모델에서의 표준 표정의 세트로부터, 상기 제1 대상의 얼굴 표정에 기초하여 선택된 표정을 식별하는 것; 상기 제1 대상의 개인적 특성을 나타내는 상기 하나 이상의 특징을 상기 사람 모델에서의 상기 선택된 표정에 전사하는 것; 및 클라이언트 디바이스 상의 디스플레이를 위해 몰입형 현실 애플리케이션에 상기 사람 모델을 제공하는 것을 포함하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 제1 대상은 향상된 현실 헤드셋의 사용자이고, 상기 제1 대상의 얼굴 표정의 이미지를 캡처하기 위해 상기 하나 이상의 프로세서는, 상기 향상된 현실 헤드셋 상에 장착된 카메라를 이용해 상기 이미지를 캡처하기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하기 위해 상기 하나 이상의 프로세서는, 상기 제1 대상의 얼굴 표정의 이미지 상에 겹쳐진 메쉬로부터, 선택된 임계값보다 더 큰 양만큼 이동된 정점 그룹을 선택하기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하기 위해 상기 하나 이상의 프로세서는, 상기 제1 대상의 얼굴 표정의 이미지에 대한 메쉬의 모션과 연관된 미분 텐서에서의 하나 이상의 임계점을 찾기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 하나 이상의 특징을 식별하기 위해 상기 하나 이상의 프로세서는, 상기 제1 대상의 이미지와 연관된 3차원 메쉬 내의 하나 이상의 키 포인트의 변위를 식별하기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>16. 제11항에 있어서, 상기 제1 대상의 얼굴 표정에 기초하여 선택된 표정을 식별하기 위해 상기 하나 이상의 프로세서는, 상기 제1 대상의 얼굴 표정과 연관된 메쉬 내의 다수의 정점과, 상기 선택된 표정을 갖는 상기 사람 모델과 연관된 메쉬 내의 다수의 정점 사이의 거리의 측정치를 찾기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 하나 이상의 프로세서는 또한, 상기 사람 모델을 상기 사람 모델의 양식화된 아바타로서 선택하기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서, 상기 제1 대상의 개인적 특성을 나타내는 상기 하나 이상의 특징을 상기 사람 모델에서의 상기 선택된 표정에 전사하기 위해 상기 하나 이상의 프로세서는, 상기 제1 대상에 대한 메쉬 내의 정점 그룹의 움직임을 상기 사람 모델에 대한 메쉬 내의 대응하는 정점 그룹에 복사하기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서, 상기 클라이언트 디바이스는 사용자와 함께 있고, 상기 하나 이상의 프로세서는 또한, 상기 제1 대상과 함께 있는 제2 클라이언트 디바이스 상의 디스플레이를 위해 상기 몰입형 현실 애플리케이션에 상기 사용자의 얼굴 표정으로 수정된 제2 양식화된 사람 모델을 제공하기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서, 상기 몰입형 현실 애플리케이션은 상기 제1 대상과 제2 대상 사이에 공유되고, 상기 하나 이상의 프로세서는 또한, 상기 클라이언트 디바이스 상의 상기 디스플레이에 상기 제2 대상의 얼굴 표정으로 수정된 제2 양식화된 사람 모델을 제공하기 위한 명령어를 실행하는 것인, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국, 캘리포니아 *****, 멘로파크, 윌로우로드 ****</address><code>520180769611</code><country>미국</country><engName>Meta Platforms Technologies, LLC</engName><name>메타 플랫폼즈 테크놀로지스, 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아주 ...</address><code> </code><country> </country><engName>OCAMPO, Christopher John</engName><name>오캄포 크리스토퍼 존</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ...</address><code> </code><country> </country><engName>CADOGAN, Milton</engName><name>카도간 밀턴</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ...</address><code> </code><country> </country><engName>GUO, Peihong</engName><name>구오 페이홍</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.07.22</priorityApplicationDate><priorityApplicationNumber>63/391,645</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.11.18</priorityApplicationDate><priorityApplicationNumber>18/056,986</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.07.19</receiptDate><receiptNumber>1-1-2023-0795093-46</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.07.19</receiptDate><receiptNumber>9-1-2023-9008317-38</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2023.07.19</receiptDate><receiptNumber>9-1-2023-9008323-13</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230093745.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c939488af79abe4596872213aaf3d1219ffc3fa783469113a8abcbd3baec34aa596c5d0976b5a35a5cb0371e960ec524160c92667053f64b5ef</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb02913d211c65d9987b7aa29c7fae4ceab8062077cca70a604a18c6b65a8762c85b19d0e1519eb6f78f58821d8c46cd5ef6a8953f5345137</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>