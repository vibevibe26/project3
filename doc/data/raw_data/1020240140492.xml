<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:06:56.656</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.10.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0140492</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>새로운 뷰의 3D 재구성 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND DEVICE FOR 3D RECONSTRUCTION OF A NOVEL VIEW</inventionTitleEng><openDate>2025.06.27</openDate><openNumber>10-2025-0096556</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.15</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/268</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/264</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/156</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/128</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 15/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2018.01.01)</ipcDate><ipcNumber>H04N 13/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 소정의 영역이 겹치는 두 개의 2D 영상의 특징 벡터를 이용하여 상기 두 개의 2D 영상 간의 정합점들을 결정하는 단계, 상기 결정된 정합점들에 대한 특징 벡터들을 이용하여 카메라의 새로운 뷰에 대한 포즈를 예측하는 단계, 상기 예측된 포즈를 이용하여 상기 정합점들에 대한 특징 벡터들 중 상기 두 개의 2D 영상 각각에 생성된 에피폴라 라인 상에 위치하는 특징 벡터들을 추출하는 단계, 및 상기 추출된 상기 에피폴라 라인 상에 위치하는 특징 벡터들을 이용하여 상기 새로운 뷰에 대한 렌더링된 3D 영상을 생성하는 단계를 포함하는, 새로운 뷰의 3D 재구성 방법을 공개한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나 이상의 명령을 저장하는 메모리; 상기 적어도 하나 이상의 명령을 실행하는 프로세서; 정합 추정 모듈;카메라 포즈 추정 모듈; 및렌더링 모듈;을 포함하며,상기 프로세서는, 상기 정합 추정 모듈에 소정의 영역이 겹치는 두 개의 2D 영상의 특징 벡터를 입력하여 상기 두 개의 2D 영상 간의 정합점들을 결정하고, 상기 결정된 정합점들에 대한 특징 벡터들을 상기 카메라 포즈 추정 모듈에 입력하여 상기 카메라의 새로운 뷰에 대한 포즈를 예측하고,상기 예측된 포즈와 상기 정합점들에 대한 특징 벡터들을 상기 렌더링 모듈에 입력하여, 상기 예측된 포즈를 이용하여 상기 정합점들에 대한 특징 벡터들 중 상기 두 개의 2D 영상 각각에 생성된 에피폴라 라인 상에 위치하는 특징 벡터들을 추출하고, 상기 추출된 상기 에피폴라 라인 상에 위치하는 특징 벡터들을 이용하여 상기 새로운 뷰에 대한 렌더링된 3D 영상을 생성하는,새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 프로세서는, 상기 두 개의 2D 영상 간의 정합점들을 결정하기 이전에 상기 두 개의 2D 영상 각각의 특징 벡터들을 추출하는, 새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 프로세서는, 상기 추출된 두 개의 2D 영상의 특징 벡터에 대한 초기 비용 볼륨을 구성하고, 상기 초기 비용 볼륨을 이용하여 상기 두 개의 2D 영상의 특징 간의 코사인 유사도를 계산하여 4D 비용 볼륨을 획득하는,새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 정합점들을 결정할 때, 상기 프로세서는, 상기 두 개의 2D 영상의 특징 벡터 각각과 상기 두 개의 2D 영상의 특징 벡터들을 이용하여 생성한 4D 비용 볼륨을 연결하여 증강된 비용 볼륨을 생성하고, 상기 증강된 비용 볼륨을 이용하여 셀프 어텐션 작업을 수행하여 필터링된 비용 볼륨을 생성하고, 상기 필터링된 비용 볼륨에 소프트맥스를 적용하여 크로스 어텐션 맵을 생성하고 상기 크로스 어텐션 맵을 이용하여 상기 두 개의 2D 영상의 특징 맵들을 정렬하여 최종 비용 볼륨을 생성하는,  새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 카메라의 새로운 뷰에 대한 포즈를 예측하기 이전에, 상기 프로세서는, 상기 최종 비용 볼륨을 이용하여 상기 두 개의 2D 영상의 특징 벡터들 간의 가장 높은 점수를 갖는 대응관계를 결정하고, 상기 두 개의 2D 영상 특징 맵들 간의 신뢰도 맵을 계산하는,새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서, 상기 신뢰도 맵을 계산할 때, 상기 프로세서는, 순환 일관성 맵 및 역 순환 일관성 맵을 획득하되, 상기 두 개의 2D 영상 간의 상기 대응관계에 해당하는 픽셀 간의 순 필드 및 역필드 흐름 맵이 소정의 조건을 충족하는 지 판정하는, 새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 새로운 뷰에 대한 렌더링된 3D 영상을 생성할 때, 상기 프로세서는,상기 추출된 상기 에피폴라 라인 상에 위치하는 특징 벡터들을 상기 새로운 뷰의 영상에 증강시키고, 상기 두 개의 2D 영상과 상기 새로운 뷰의 영상 간의 삼각 측량을 이용하여 깊이를 계산하고,상기 에피폴라 라인 상에 위치하는 특징 벡터들, 상기 깊이, 및 상기 예측된 포즈를 이용하여 상기 새로운 뷰에 대한 렌더링된 3D 영상을 생성하는,새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 프로세서는 상기 정합 추정 모듈, 상기 카메라 포즈 추정 모듈, 상기 렌더링 모듈을 포함하는 신경망의 학습 시에, 상기 카메라 포즈 추정 모듈에서 상기 두 개의 2D 영상 중 어느 하나의 영상에서 다른 하나의 영상으로 워핑되는 고밀도 흐름 필드를 추정하고,  상기 어느 하나의 영상과 상기 다른 하나의 영상 간의 상대적인 포즈를 추정하고, 상기 추정된 고밀도 흐름 필드, 상기 추정된 상대적인 포즈, 상기 계산된 깊이, 및 상기 렌더링된 3D 영상에 대한 통합 손실을 계산하고,상기 계산된 통합 손실을 이용하여 상기 신경망을 학습시키는, 새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 신경망의 학습 시에, 상기 카메라 포즈 추정 모듈에는 상기 추정된 상대적인 포즈를 이용하여 계산한 포즈 손실을 적용하고, 상기 렌더링 모듈에는 미리 준비된 정답 포즈를 제공하는,새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 깊이에 대한 손실은 상기 추정된 고밀도 흐름 필드, 상기 추정된 상대적인 포즈, 상기 계산된 깊이를 통합하여 생성된 손실인, 새로운 뷰의 3D 재구성 장치.</claim></claimInfo><claimInfo><claim>11. 소정의 영역이 겹치는 두 개의 2D 영상의 특징 벡터를 이용하여 상기 두 개의 2D 영상 간의 정합점들을 결정하는 단계;상기 결정된 정합점들에 대한 특징 벡터들을 이용하여 카메라의 새로운 뷰에 대한 포즈를 예측하는 단계;상기 예측된 포즈를 이용하여 상기 정합점들에 대한 특징 벡터들 중 상기 두 개의 2D 영상 각각에 생성된 에피폴라 라인 상에 위치하는 특징 벡터들을 추출하는 단계; 및상기 추출된 상기 에피폴라 라인 상에 위치하는 특징 벡터들을 이용하여 상기 새로운 뷰에 대한 렌더링된 3D 영상을 생성하는 단계;를 포함하는, 새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 정합점들을 결정하는 단계 이전에, 상기 두 개의 2D 영상 각각의 특징 벡터들을 추출하는 단계를 더 포함하는, 새로운 뷰의 3D 재구성 방법. </claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 정합점들을 결정하는 단계 이전에, 상기 추출된 두 개의 2D 영상의 특징 벡터에 초기 비용 볼륨을 구성하는 단계; 및상기 초기 비용 볼륨을 이용하여 상기 두 개의 2D 영상의 특징 간의 코사인 유사도를 계산하여 4D 비용 볼륨을 획득하는 단계;를 더 포함하는, 새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>14. 제11항에 있어서, 상기 정합점들을 결정하는 단계는, 상기 두 개의 2D 영상의 특징 벡터 각각과 상기 두 개의 2D 영상의 특징 벡터들을 이용하여 생성한 4D 비용 볼륨을 연결하여 증강된 비용 볼륨을 생성하는 단계; 상기 증강된 비용 볼륨을 이용하여 셀프 어텐션 작업을 수행하여 필터링된 비용 볼륨을 생성하는 단계; 상기 필터링된 비용 볼륨에 소프트맥스를 적용하여 크로스 어텐션 맵을 생성하는 단계; 및 상기 크로스 어텐션 맵을 이용하여 상기 두 개의 2D 영상의 특징 맵들을 정렬하여 최종 비용 볼륨을 생성하는 단계;를 포함하는,새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서, 상기 새로운 뷰에 대한 포즈를 예측하는 단계 이전에, 상기 최종 비용 볼륨을 이용하여 상기 두 개의 2D 영상의 특징 벡터들 간의 가장 높은 점수를 갖는 대응관계를 결정하는 단계; 및 상기 두 개의 2D 영상 특징 맵들 간의 신뢰도 맵을 계산하는 단계;를 더 포함하는,새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 신뢰도 맵을 계산하는 단계는,순환 일관성 맵 및 역 순환 일관성 맵을 획득하는 단계; 및상기 두 개의 2D 영상 간의 상기 대응관계에 해당하는 픽셀 간의 순 필드 및 역필드 흐름 맵이 소정의 조건을 충족하는 지 판정하는 단계;를 포함하는,새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>17. 제11항에 있어서, 상기 새로운 뷰에 대한 렌더링된 3D 영상을 생성하는 단계는, 상기 추출된 상기 에피폴라 라인 상에 위치하는 특징 벡터들을 상기 새로운 뷰의 영상에 증강시키는 단계;상기 두 개의 2D 영상과 상기 새로운 뷰의 영상 간의 삼각 측량을 이용하여 깊이를 계산하는 단계; 및상기 에피폴라 라인 상에 위치하는 특징 벡터들, 상기 깊이, 및 상기 예측된 포즈를 이용하여 상기 새로운 뷰에 대한 렌더링된 3D 영상을 생성하는 단계;를 포함하는, 새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 정합 추정 모듈, 상기 카메라 포즈 추정 모듈, 상기 렌더링 모듈은 하나의 신경망에 포함되며, 상기 신경망을 학습시키는 단계를 더 포함하며,상기 신경망을 학습시키는 단계는, 상기 카메라 포즈 추정 모듈에서 상기 두 개의 2D 영상 중 어느 하나의 영상에서 다른 하나의 영상으로 워핑되는 고밀도 흐름 필드를 추정하는 단계;상기 어느 하나의 영상과 상기 다른 하나의 영상 간의 상대적인 포즈를 추정하는 단계; 상기 추정된 고밀도 흐름 필드, 상기 추정된 상대적인 포즈, 상기 계산된 깊이, 및 상기 렌더링된 3D 영상에 대한 통합 손실을 계산하는 단계; 및상기 계산된 통합 손실을 이용하여 상기 신경망을 학습시키는 단계;를 포함하는,새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 신경망을 학습시키는 단계는,상기 카메라 포즈 추정 모듈에 상기 추정된 상대적인 포즈를 이용하여 계산한 포즈 손실을 제공하는 단계; 및상기 렌더링 모듈에는 미리 준비된 정답 포즈를 제공하는 단계;를 포함하는,새로운 뷰의 3D 재구성 방법.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서, 상기 신경망을 학습시키는 단계는, 상기 추정된 고밀도 흐름 필드, 상기 추정된 상대적인 포즈, 상기 계산된 깊이를 통합하여 상기 깊이에 대한 손실을 계산하는 단계를 더 포함하는, 새로운 뷰의 3D 재구성 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경상북도 포항시 남구...</address><code>220040433361</code><country>대한민국</country><engName>POSTECH Research and Business Development Foundation</engName><name>포항공과대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 중랑구...</address><code> </code><country> </country><engName>HONG, Sung  Hwan</engName><name>홍성환</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code> </code><country> </country><engName>JUNG, Jae Woo</engName><name>정재우</name></inventorInfo><inventorInfo><address>서울특별시 노원구...</address><code> </code><country> </country><engName>SHIN, Hee Seong</engName><name>신희성</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code> </code><country> </country><engName>KIM, Seung Ryong</engName><name>김승룡</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 바우뫼로 ***(양재동, 우도빌딩 *층)</address><code>920081000210</code><country>대한민국</country><engName>E-Sang Patent &amp; Trademark Law Firm</engName><name>특허법인이상</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.12.20</priorityApplicationDate><priorityApplicationNumber>1020230187727</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.10.15</receiptDate><receiptNumber>1-1-2024-1119569-68</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Request for Prior Art Search</documentEngName><documentName>선행기술조사의뢰서</documentName><receiptDate>2025.10.29</receiptDate><receiptNumber>9-1-9999-9999999-89</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240140492.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93077b17865ae086e1d74859538d5bd8faea72bb31cf32fa415f3d1c366ea46b24d5ff0399915d612e6a57f432c7f30368f85bb89e522224eb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf23fa01a3efe0f671f5cc816db49e1aa25361c2fe3039020731bd628a46813a205955c86c6dad559f3e8abb5d8d8c823df78c79334e53e57e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>