<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:02:12.212</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2021.12.17</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7024184</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>설명 가능 트랜스듀서 변환기</inventionTitle><inventionTitleEng>EXPLAINABLE TRANSDUCER TRANSFORMERS</inventionTitleEng><openDate>2023.09.05</openDate><openNumber>10-2023-0128492</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.12.17</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.07.14</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 5/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/092</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/084</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/088</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06N 3/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/086</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 5/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 설명 가능 트랜스듀서 변환기(XTT)는, 설명 가능 변환기와 함께, 유한 상태 트랜스듀서일 수도 있다. XTT의 변형예는 설명 가능 변환기 인코더 및 설명 가능 변환기 디코더를 포함할 수도 있다. 예시적인 설명 가능 트랜스듀서는 트레이닝된 설명 가능 신경망(XNN) 아키텍쳐 또는 논리적으로 등가의 아키텍쳐에서 부분적 대체물로서 사용될 수도 있다. 설명 가능 변환기는, 변환기의 인코더 및 디코더 레이어의 하위 레이어 둘 모두에서, 변환기의 블랙박스 모델 컴포넌트를 화이트박스 모델 등가물로 대체할 수도 있다. XTT는 설명 및 해석 생성 시스템(EIGS)을 활용하여, 설명을 생성하고 그러한 설명을 필터링하여 답변, 설명 및 그것의 정당성의 해석을 생성할 수도 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.06.23</internationOpenDate><internationOpenNumber>WO2022129610</internationOpenNumber><internationalApplicationDate>2021.12.17</internationalApplicationDate><internationalApplicationNumber>PCT/EP2021/086646</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 설명 가능 머신 러닝 시스템(explainable machine learning system)으로서,상기 머신 러닝 시스템이 입력 언어로부터의 데이터를 제2 출력 언어로 번역, 매핑, 및 변환하는 것을 허용하도록 구성되는 유한 상태 트랜스듀서(finite state transducer; FST) - 상기 유한 상태 트랜스듀서는 변환을 위해 사용되는 하나 이상의 입력 피쳐를 포함하는 또는 상기 하나 이상의 입력 피쳐를 변환하는 상기 입력 언어로부터의 상기 데이터를 수신하도록 적응되고, 상기 유한 상태 트랜스듀서는 또한, 상기 제2 출력 언어로서 상기 하나 이상의 입력 피쳐에 기초하여 번역된, 매핑된, 및/또는 변환된 데이터를 제공하도록 구성됨 - ; 및/또는상기 입력 언어로부터의 상기 데이터와 관련하여 형성되는 디코더 및 인코더 컴포넌트의 조합에 기초한 어텐션 기반의 아키텍쳐(attention-based architecture)를 갖는 설명 가능 변환기를 포함하고,상기 유한 상태 트랜스듀서 및 상기 설명 가능 변환기는 결합되어 상기 입력 언어로부터의 상기 데이터를 번역, 매핑, 및 변환하도록 구성되는 설명 가능 트랜스듀서 변환기(explainable transducer transformer; XTT)를 생성하도록 구성되는 것인, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 설명 가능 변환기는:상기 입력 언어로부터의 상기 데이터와 연관되는 입력을 수신하도록 그리고 상기 하나 이상의 입력 피쳐를 식별하도록 구성되는 입력 레이어;조건부 네트워크 - 상기 조건부 네트워크는: 하나 이상의 파티션 - 상기 하나 이상의 파티션 각각은 규칙을 포함함 - 에 기초하여 상기 하나 이상의 입력 피쳐를 모델링하도록 구성되는 조건부 레이어; 하나 이상의 규칙을 하나 이상의 집성된 파티션으로 집성하도록 구성되는 집성 레이어(aggregation layer); 및 상기 집성 레이어로부터의 상기 집성된 파티션을 상기 조건부 레이어로부터의 상기 하나 이상의 파티션과 함께 선택적으로 풀링하도록 구성되는 스위치 출력 레이어를 포함함- ;예측 네트워크 - 상기 예측 네트워크는: 하나 이상의 변환을 상기 하나 이상의 입력 피쳐에 적용하도록 구성되는 하나 이상의 변환 뉴런을 포함하는 피쳐 생성 및 변환 네트워크; 하나 이상의 피쳐 및 하나 이상의 파티션: 중 적어도 하나에 연관되는 하나 이상의 계수를 식별하기 위해 상기 피쳐 생성 및 변환 네트워크에 의해 변환된 피쳐를 결합하도록 구성되는 적합 레이어; 상기 하나 이상의 계수를 분석하도록 구성되고 상기 하나 이상의 피쳐 또는 상기 하나 이상의 파티션 중 적어도 하나에 연관되는 값을 출력하도록 구성되는 값 출력 레이어를 포함하고, 상기 디코더 및 상기 인코더 컴포넌트는 상기 입력을 인코딩하기 위한 적어도 하나의 레이어 및 상기 입력을 디코딩하기 위한 적어도 하나의 레이어를 포함하고, 디코더 및 인코더 컴포넌트는 상기 입력으로부터 형성되는 설명 가능 아키텍쳐를 포함함 - ;머신 프로그램 또는 인간 중 적어도 하나에 의해 해석 가능한 그리고 설명 가능한 출력을 생성하도록 구성되는 출력 레이어 - 상기 파티션 전체에 걸친 하나 이상의 실행 경로는 외부 프로세스에 의해 식별 가능함 - 를 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 XTT는 설명 가능 변환기 인코더(explainable transformer-encoder) 또는 설명 가능 변환기 디코더(explainable transformer-decoder)로서 동작하도록 구성되고, 상기 시스템은, 옵션 사항으로, 상기 XTT의 내부 계수에 대한 조건부 제약을 더 포함하고, 상기 조건부 제약은, 옵션 사항으로, 상기 XTT의 공칭 동작 사이클 동안 모니터링되도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 설명 가능 트랜스듀서는 상기 디코더 컴포넌트 및/또는 상기 인코더 컴포넌트의 하위 레이어에서 화이트박스 모델 컴포넌트(white-box model component)를 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,설명 가능 신경망(explainable neural network; XNN)을 포함하는 설명 가능 아키텍쳐가 상기 XTT에서 활용되고,상기 XNN은 옵션 사항으로: 입력 레이어 - 상기 입력 레이어는:  조건부 레이어, 집성 레이어, 및 스위치 출력 레이어를 포함하는 조건부 네트워크; 및  피쳐 생성 및 변환 레이어, 적합 레이어, 및 예측 출력 레이어를 포함하는 예측 네트워크 에 입력되도록 구성됨 - 및 상기 스위치 출력 레이어의 출력 및 상기 예측 출력 레이어의 출력을 곱하여 순위가 매겨진 또는 점수가 매겨진 출력을 생성하도록 구성되는 선택 및 순위 매김 레이어를 포함하고, 상기 XNN은, 옵션 사항으로, 빠른 가중치(Fast Weight)를 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,해석 가능 신경망(interpretable neural network; INN)을 포함하는 설명 가능 아키텍쳐가 상기 XTT에서 활용되고; 및/또는설명 가능 아키텍쳐는 설명 가능 보강 학습(explainable reinforcement learning; XRL) 시스템을 포함하고; 및/또는상기 XTT는 와이드 학습 모델(wide learning model)을 지원하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>7. 제2항 내지 제6항에 있어서,상기 설명 가능 아키텍쳐는: 답변으로 구성되는 설명 가능 또는 해석 가능 출력을 생성하도록; 그 답변의 옵션 사항의(optional) 모델 설명을 생성하도록, 옵션 사항으로, 상기 답변 및/또는 상기 모델 설명의 정당성을 생성하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 XTT는 상기 하나 이상의 입력 피쳐를 프로세싱하도록 구성되는 파티션 - 상기 파티션은 규칙 및/또는 거리 유사도 함수에 따라 옵션 사항으로 데이터 포인트를 그룹화하는 클러스터이고, 상기 파티션은 그들의 값이 정적 값으로 설정된 잠긴 파티션이거나 또는 상기 XTT의 각각의 역방향 트레이닝 패스(backward training pass)에 대해 동적으로 이동 가능한 이동 가능 파티션임 - 을 포함하거나, 상기 파티션은 상기 XTT를 처음 생성하는 외부 프로세스에 의해 상기 XTT의 일부로서 초기에 생성되거나, 또는상기 파티션은 파티셔닝 정보를 제공하는 링크된 분류법(taxonomy) 또는 온톨로지(ontology)로부터 적절하게 초기화되거나 또는 사전 트레이닝되고, 상기 XTT는, 옵션 사항으로, 상기 파티션이 사전 트레이닝된 이후 사전 미세 튜닝되고, 그리고 일단 상기 파티션이 생성되면, 상기 XTT는 경사 하강 방법(gradient descent method)을 사용하여 상기 파티션을 적합시키거나 또는 추가로 개선하도록 구성되고, 그리고 상기 파티션 구조는, 옵션 사항으로, 그래프 또는 하이퍼그래프로 배열되고 상기 시스템은, 옵션 사항으로, 그래프 대 시퀀스, 시퀀스 대 그래프, 및 그래프 대 그래프 변환 모드를 프로세싱하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 XTT는 상기 XTT가 파티션을 선택, 병합 또는 분할하는 방법을 결정하기 위해 순위 매김 함수(ranking function)를 구현하도록 구성되고, 상기 파티션은, 옵션 사항으로, 상이한 레벨의 의미론적(semantic) 및 기호학적(semiotic) 세부 사항에서 심볼을 표현하기 위해 사용 가능한 계층적 본질에 따라 배열되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>10. 제8항 또는 제9항에 있어서,상기 파티션은, 다중 목표 최적화 기술(multiple objective optimisation technique), 유전 알고리즘(genetic algorithm), 몬테 카를로(Monte Carlo) 시뮬레이션 방법, 및/또는 캐주얼 로직 및 시뮬레이션 기술: 중 하나 이상을 사용하여 변경 가능한, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>11. 제8항 내지 제10항 중 어느 한 항에 있어서,상기 파티션은: 두 개 이상의 중첩 파티션 및 상기 중첩 파티션 중 어떤 것을 활성화할지를 결정하도록 구성되는 우선 순위 함수(priority function); 두 개 이상의 비중첩 파티션; 및/또는다수의 활성화된 파티션으로부터의 결과를 결합 또는 분할하도록 구성되는 집성 함수(aggregate function)를 포함하고, 상기 파티션은, 옵션 사항으로, 희소(sparse) XNN 또는 INN을 사용하여 구현되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>12. 제8항 내지 제11항 중 어느 한 항에 있어서,각각의 파티션은, 선형 모델에 맞는 데이터; 및 선형 모델을 상기 데이터에 적합시키기 이전에, 다항식 확장, 회전, 차원 스케일링, 무차원(dimensionless) 스케일링, 상태 공간 변환(state-space transform), 위상 공간 변환(phase-space transform), 정수 변환, 실수 변환, 복소수 변환, 쿼터니언(quaternion) 변환, 옥토니언(octonion) 변환, 푸리에(Fourier) 변환, 월시(Walsh) 함수, 연속 데이터 버킷화(continuous data bucketization), Haar(하르) 웨이블릿, non-Haar(비 하르) 웨이블릿, 일반화된 L2 함수, 프랙탈 기반의 변환, Hadamard(아다마르) 변환, 타입 1 또는 타입 2 퍼지 로직 지식 그래프 네트워크, 카테고리형 인코딩(categorical encoding), Kolmogorov(콜모고로프) 공간, Frechet(프레쳇) 공간, Hausdorff(하우스도르프) 공간 또는 Tychonoff(타이초노프) 공간의 위상 변환, 차이 분석, 정규화, 표준화, 및 조건부 피쳐: 중 적어도 하나가 적용된 데이터: 중 하나 이상을 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>13. 제8항 내지 제12항 중 어느 한 항에 있어서,상기 파티션은 파티셔닝 함수에 따른 계층 구조로 배열되되, 상기 파티셔닝 함수는, k 평균(k-means) 함수, Bayesian(베이지안) 함수, 연결성 기반의 파티셔닝 함수, 중심 기반의 파티셔닝 함수(centroid based partitioning function), 분포 기반의 파티셔닝 함수, 그리드 기반의 파티셔닝 함수, 밀도 기반의 파티셔닝 함수, 퍼지 로직 기반의 파티셔닝 함수, 엔트로피 기반의 함수, 또는 상호 정보 기반의 방법:으로부터의 하나 이상을 포함하는 클러스터링 알고리즘을 포함하고; 상기 파티션 함수는, 옵션 사항으로, 복수의 중첩 및/또는 비중첩 파티션을 생성하는 앙상블 방법(ensemble method)을 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>14. 제8항 내지 제13항 중 어느 한 항에 있어서,상기 XTT는 상기 파티션 중 하나 이상의 파티션에 대해 하나 이상의 반복적 최적화 단계를 실행하도록 구성되고, 상기 하나 이상의 반복적 최적화 단계는, 옵션 사항으로: 적절한 집성, 분할 또는 최적화 방법을 사용하여 상기 파티션을 병합 및 분할하는 것을 수반하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서,상기 XTT는 상기 파티션과 연관되는 상기 모델 설명 및 정보를 예측하도록 구성되는 XTT 디코더 아키텍쳐(XTT-Decoder architecture)를 포함하고, 상기 XTT 디코더 아키텍쳐는 다음 번 모델 설명을 예측하기 위해 생성된 모델 설명을 사용하여 사전 트레이닝되고, 상기 XTT 디코더 아키텍쳐는, 옵션 사항으로, 다음 번 설명 그래디언트를 예측하여 상기 모델 설명에서의 차이 또는 변화를 예측하기 위해 설명 그래디언트의 세트에 대해 추가로 사전 트레이닝되고, 상기 XTT 디코더 아키텍쳐는, 옵션 사항으로, 트레이닝 동안 유사도(similarity) 및 대비(contrast) 둘 모두의 엘리먼트를 고려하기 위해 입력 및 출력 데이터의 임베딩된 표현에 대해 사전 트레이닝되며, 상기 임베딩된 표현은, 옵션 사항으로, 희소 임베딩인, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서,상기 설명 가능 변환기는 외부 설명 가능 모델로부터의 파티셔닝 정보를 상기 설명 가능 변환기의 상기 인코더 컴포넌트의 입력 임베딩에 그리고, 옵션 사항으로, 상기 설명 가능 변환기의 상기 디코더 컴포넌트의 출력 임베딩에 추가하는 것에 의해 트레이닝되거나; 또는상기 설명 가능 변환기는 상기 인코더 및 디코더 컴포넌트에 병렬인 두 개의 추가적인 레이어 - 상기 두 개의 추가적인 레이어는 상기 설명 가능 변환기의 입력 공간으로부터 설명 가능 아키텍쳐를 구성하도록 구성됨 - 를 포함하거나; 또는상기 설명 가능 변환기는 멀티 헤드 어텐션 컴포넌트(multi-head-attention component) 또는 추가 및 정규화 컴포넌트(add-and-normalization component)를 포함하는 병렬의 설명 가능 인코더 레이어 - 상기 병렬의 설명 가능 인코더 레이어는 상기 멀티 헤드 어텐션 컴포넌트의 출력 또는 상기 추가 및 정규화 컴포넌트의 출력, 및 파티셔닝 또는 설명 가능 정보를 입력으로서 수신하도록 구성됨 - 를 포함하고, 상기 설명 가능 변환기는, 옵션 사항으로, 상기 병렬의 설명 가능 인코더 레이어의 출력을 입력으로서 수신하도록 구성되는 병렬의 설명 가능 디코더 레이어를 더 포함하고, 상기 병렬의 설명 가능 인코더 레이어는, 옵션 사항으로, 하나 이상의 모델 설명, 상기 하나 이상의 모델 설명의 하나 이상의 그래디언트, 또는 하나 이상의 파티션과 연관되는 정보를 입력으로서 수신하도록 구성되는 설명 가능 아키텍쳐를, 옵션 사항으로, 포함하고, 상기 병렬의 설명 가능 디코더는, 옵션 사항으로, 설명 가능 아키텍쳐, 및 추가 및 정규화 컴포넌트를 포함하고, 상기 병렬의 설명 가능 인코더 레이어는, 옵션 사항으로, 상기 병렬의 설명 가능 인코더 레이어의 출력을 상기 디코더 컴포넌트의 멀티 헤드 어텐션 레이어로 전송하도록 구성되고, 상기 병렬의 설명 가능 인코더 레이어는, 옵션 사항으로, 상기 출력을 상기 디코더 컴포넌트의 상기 멀티 헤드 어텐션 레이어로 전송하기 이전에, 상기 출력을, 상기 설명 가능 변환기의 상기 인코더 컴포넌트의 출력과 병합하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서,상기 설명 가능 변환기의 상기 디코더 컴포넌트는 피드백 루프의 일부로서 입력으로서 상기 XTT의 출력을 수신하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제17항 중 어느 한 항에 있어서,상기 설명 가능 변환기의 상기 인코더 및 또는 디코더 컴포넌트는 설명 가능 자동 인코더 디코더(explainable Auto-Encoder-Decoder; XAED)로서 동작하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>19. 제1항 내지 제18항 중 어느 한 항에 있어서,상기 XTT는 트레이닝 데이터세트의 하나 이상의 피쳐 변환을 포함하고, 상기 하나 이상의 피쳐 변환은, 옵션 사항으로, 다항식 확장, 회전 변환, 차원 스케일링, 무차원 스케일링, 푸리에 변환, 월시 함수, 상태 공간 변환, 위상 공간 변환, 하르 웨이블릿, 비 하르 웨이블릿, 일반화된 L2 함수, 프랙탈 기반의 변환, 아다마르 변환, 타입 1 퍼지 로직 그래프 네트워크, 타입 2 퍼지 로직 그래프 네트워크, 콜모고로프 공간, 프레쳇 공간, 하우스도르프 공간 또는 타이초노프 공간의 카테고리형 인코딩 위상 변환, 차이 분석, 데이터의 정규화, 및 데이터의 표준화: 중 하나 이상을 포함하고, 상기 하나 이상의 피쳐 변환은, 옵션 사항으로, 변환의 파이프라인으로서 배열되되, 상기 파이프라인은 옵션 사항으로: 하나 이상의 변수의 값에 따라 정렬되는 데이터의 시퀀스 - 데이터의 상기 시퀀스는, 옵션 사항으로, 시간적으로 정렬된 데이터 시퀀스를 포함함 - 를 분석하도록 구성되는 변환; 및/또는 경사 하강 방법 및 다른 설명 가능 아키텍쳐를 통해 획득되는 변환을 더 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>20. 제1항 내지 제19항 중 어느 한 항에 있어서,상기 XTT는, 인과 GAN 기반의 생성(causal GAN based generation), 유전 공학(genetic engineering), 몬테 카를로 시뮬레이션, 페트리 넷(Petri Net), 보강 학습 기술, 화이트박스 모델 및 연관된 글로벌 모델을 사용한 시뮬레이션, 및/또는 이용 가능할 수도 있는 임의의 다른 방법: 중 하나 이상의 기술을 사용하여 생성되는 상기 XTT를 트레이닝시키기 위한 트레이닝 데이터세트 샘플을 수신하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>21. 제1항 내지 제20항 중 어느 한 항에 있어서,상기 XTT는 또한, 인간 지식 주입(human knowledge injection; HKI), 또는 시스템 지식 주입을 입력으로서 수신하도록 추가로 구성되고, 상기 XTT 내의 설명 가능 아키텍쳐의 계수는 인간 유저와 상기 머신 러닝 시스템 사이의 더욱 효과적인 협업으로 이어질 특정한 규칙을 시행하도록 수정 가능하고, 상기 XTT는, 옵션 사항으로, 제로샷(zero-shot) 학습 또는 퓨샷(few-shot) 학습을 위해 상기 HKI 또는 시스템 지식 주입을 사용하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>22. 제1항 내지 제21항 중 어느 한 항에 있어서,상기 XTT는 상기 XTT의 적응성을 향상시키기 위해 귀납적(inductive), 연역적(deductive), 귀추적(abductive), 및 인과적(causal) 로직 중 하나 이상을 구현하도록 구성되고, 상기 XTT는, 옵션 사항으로, 무모델(model-free) 및 모델 기반의 최적화 방법의 조합을 활용하도록 또한 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>23. 제1항 내지 제22항 중 어느 한 항에 있어서,상기 XTT는 상기 XTT의 상기 하나 이상의 입력 피쳐가 설명 가능할 정도까지 상기 XTT의 출력으로부터 설명 가능하지 않은 잠재적 공간의 완전한 제거를 가능하게 하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>24. 제1항 내지 제23항 중 어느 한 항에 있어서,상기 XTT는, 상기 XTT의 출력에, 푸리에 변환, 정수 변환, 실수 변환, 복소수 변환, 쿼터니언 변환, 옥토니언 변환, 월시 함수, 상태 공간 변환, 위상 공간 변환, 하르 웨이블릿, 비 하르 웨이블릿, 일반화된 L&quot; 함수, 프랙탈 기반의 변환, 아다마르 변환, 퍼지 로직 그래프 네트워크, 카테고리형 인코딩, 차이 분석, 정규화, 표준화, 다차원 베지어 곡선(multi-dimensional Bezier curve), 회귀 관계, 및 인과 연산자(causal operator): 중 하나 이상을 적용하도록 구성되거나; 또는상기 XTT는 상기 XTT의 출력에 활성화 함수 또는 변환 함수를 적용하도록 구성되되, 상기 활성화 함수 또는 변환 함수는, 시그모이드(sigmoid) 함수, SoftMax(소프트맥스) 함수, 계층적 트리 또는 네트워크, 인과 다이어그램, 방향성 그래프, 무방향성 그래프, 하이퍼그래프, 단순체 복합체(simplicial complex), 멀티미디어 구조, 또는 하이퍼링크된 그래프의 세트: 중 하나 이상을 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>25. 제1항 내지 제24항 중 어느 한 항에 있어서,상기 XTT는 구조화된 데이터 및 구조화되지 않은 데이터 둘 모두를 프로세싱하도록, 그리고 계층적으로 구조화된 데이터를 프로세싱하도록 구성되고, 상기 계층적으로 구조화된 데이터는, 옵션 사항으로, 트리, 그래프, 하이퍼그래프 및/또는 단순체 복합체의 형태로 구조화되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>26. 제1항 내지 제25항 중 어느 한 항에 있어서,상기 XTT는,상기 XTT의 입력 레이어에 의해 수신되기 이전에 또는 상기 입력 레이어로부터 출력된 이후 복수의 입력을 정규화하도록 구성되는 정규화 모듈;상기 입력 레이어에 의해 수신되기 이전에 또는 상기 입력 레이어로부터 출력된 이후 상기 입력을 스케일링하도록 구성되는 스케일링 모듈; 및상기 입력 레이어에 의해 수신되기 이전에 또는 상기 입력 레이어로부터 출력된 이후 상기 입력을 표준화하도록 구성되는 표준화 모듈을 더 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>27. 제26항에 있어서,상기 입력의 상기 정규화는 편향 및 그들의 소스의 적절한 리포트 및 분석을 생성하는 것, 및 감독(supervised), 비감독(unsupervised), 또는 반감독(semi-supervised) 수단을 통해 편향 감소, 완화, 또는 제거를 위한 전략을 공식화하는 것을 수반하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>28. 제1항 내지 제27항 중 어느 한 항에 있어서,상기 XTT는 분산된 설명 가능 아키텍쳐(distributed explainable architecture; DEA)에 걸쳐 분산되고, 상기 DEA는 설명 가능 아키텍쳐의 동종(homogeneous) 또는 이종(heterogeneous) 혼합물로 구성되고, 상기 DEA는, 상기 DEA의 상기 설명 가능 아키텍쳐 각각을 트레이닝시키기 위해, 데이터세트를 데이터의 다수의 서브세트로 분할하도록 구성되고, 상기 DEA의 각각의 설명 가능 아키텍쳐는, 옵션 사항으로, 집합적 동작 기술을 비롯하여, 상기 DEA 내의 동종 및 이종 설명 가능 모델 혼합물에 적용되는 분산 트레이닝 기술을 사용하여 트레이닝 가능한, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>29. 제30항에 있어서,상기 DEA는:상기 DEA의 상기 모델이 설명 가능 인공 지능(eXplainable Artificial Intelligence; XAI), 해석 가능 신경망(Interpretable Neural Net; INN), 설명 가능 신경망(eXplainable Neural Net; XNN), 설명 가능 스파이킹 네트(eXplainable Spiking Net; XSN) 및 설명 가능 메모리 네트(eXplainable Memory Net; XMN), 및/또는 설명 가능 보강 학습(eXplainable Reinforcement Learning; XRL)의 혼합물이 되도록 하는 하이브리드 모델;복수의 독립 모델 - 주어진 독립 모델은, 일단 트레이닝되면, 상기 DEA에 의존하지 않고도, 독립적으로 작동하도록 구성 가능하고, 상기 DEA는 트레이닝을 위해 최적화됨 -중 하나 이상을 포함할 수도 있는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>30. 제1항 내지 제29항 중 어느 한 항에 있어서,상기 XTT는 설명 및 해석 생성 시스템(Explanation and Interpretation Generation System; EIGS) 내에서 사용 가능하고, 입력 질의를 프로세싱하기 위한 그리고 상기 입력 질의에 관련이 있는 적절한 답변, 설명 및 옵션 사항의 정당성을 생성하기 위한 모델을 제공하도록 구성되고,상기 XTT는, 옵션 사항으로, 상기 EIGS의 하나 이상의 부분을 변환하도록 구성되고, 상기 EIGS의 하나 이상의 부분을 변환하는 것은, 프리젠테이션 출력의 변환, 유저 고유의 출력 개인화(user-specific output personalization), 컨텍스트 고유의 출력 변환, 목표 고유의 출력 변환, 계획 고유의 출력 변환, 및 액션 고유의 변환: 중 하나 이상을 포함하고,상기 XTT는, 옵션 사항으로, 상기 EIGS 내에서: 설명 스캐폴딩(explanation scaffolding)의 적절한 필터링을 생성하기 위한 적절한 모델을 필터에 제공하도록, 또는 해석 프레이밍(interpretation framing), 프로토콜 컨텍스트, 해석 규칙, 해석 프로시져, 해석 시나리오, 및 충돌 해결 정보의 조합을 활용하여 상기 EIGS의 하나 이상의 부분을 필터링하도록, 또는 상기 EIGS 내에서 필터내 및/또는 필터간 합의 프로세스를 구현하도록, 또는 적절한 해석을 생성하고 해석 스캐폴딩의 엘리먼트를 생성하기 위한 적절한 모델을 인터프리터에 제공하도록, 또는 EIGS에서 해석 스캐폴딩의 적절한 부분을 변환하도록, 또는 프레이밍, 프로토콜, 해석 규칙, 해석 프로시져, 해석 템플릿, 해석 개요, 시나리오 모델, 도메인, 상호 작용식 컨텍스트, 및 충돌 해결 정보의 조합에 기초하여 EIGS의 해석 출력을 변환하도록, 또는 EIGS 내에서 인터프리터내 및/또는 인터프리터간 합의 프로세스를 구현하도록, 또는 적절한 선택 모델 및 선택 프로세스에 기초하여 EIGS 해석 출력을 변환하도록사용 가능한, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>31. 제1항 내지 제30항 중 어느 한 항에 있어서,상기 XTT는, 옵션 사항으로 파티셔닝 정보, 상기 XTT의 내부 계수 및 상기 XTT의 입력 공간의 피쳐 속성을 비롯하여, 다수의 레벨의 설명을 생성하도록: 구성되는 설명 가능 셀프 어텐션 메커니즘(explainable self-attention mechanism)을 포함하고, 상기 설명은 인터프리터에 대한 출력으로서 사용 가능한, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>32. 제1항 내지 제31항 중 어느 한 항에 있어서,상기 XTT는 자기 감독 기술(self-supervised technique)을 사용하여 트레이닝 가능한, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>33. 제2항 내지 제32항에 있어서,상기 XTT는 단일의 벡터 - 상기 벡터는 상기 XTT의 임의의 레이어에 대한 피드백으로서 사용 가능함 - 로 병합하기 위해 모든 디코더 또는 인코더 컴포넌트로부터의 과거 학습된 표현 또는 과거의 상태를 사용하도록 구성되고, 상기 XTT는, 옵션 사항으로, 상기 단일의 벡터로 병합하기 위해 상기 화이트박스 모델의 임의의 내부 계수를 사용하도록 추가로 구성되고, 상기 XTT는, 옵션 사항으로, 인과적으로 타당하지 않은 추론을 생성하는 것 또는 통계적으로 유효하지만 그러나 인과적으로 타당하지 않을 수도 있는 예측 경로를 생성하는 것을 방지하기 위해, 상기 과거 학습된 표현에 대해 인과적 제약을 부과하도록 추가로 구성되고, 상기 XTT는, 옵션 사항으로, 상기 과거 학습된 표현에 대해 환경적으로 타당한 제약을 추가로 부과하여 설명 가능하고 인과적으로 그리고 환경적으로 타당한 피드백 메모리를 달성하기 위해, 거동 모델 및 연관된 조건, 이벤트, 트리거, 및 액션 상태 표현을 활용하도록 추가로 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>34. 제1항 내지 제33항 중 어느 한 항에 있어서,상기 시스템은:적절한 형식 언어(formal language)로 작성되는 현존하는 형식 컴퓨터 프로그램(formal computer program)을 분석 및 파싱하도록, 그리고 일단 로딩되면, 상기 XTT 어텐션 모델을 사용하여 그것을 추가로 개선하도록 - 상기 XTT의 설명 가능 모델 내의 계층적 파티션 구조는, 옵션 사항으로, 상기 형식 언어 프로그램의 구조를 직접적으로 모델링하기 위해 사용 가능함 - ; 또는사전 정의된 문체 표준에 따라 코드를 변환하고, 불일치 또는 에러를 강조 표시하고, 코드의 더 나은 대안 및 리팩토링(re-factoring) 및 재작성을 제안하고, 난독화된 코드를 난독화 해제하고, 그리고, 알파 변환, 베타 감소, 및 에타 감소(eta-reduction)와 같은 기능적 프로그래밍 언어 개념을 생성된 코드에 적용하도록; 또는처음부터 또는 증명된 명령문(statement) 및/또는 불완전한 명령문의 현존하는 콜렉션을 통해, 수학적 표현, 명령문, 및 증명을 분석, 생성 및 자동 완성하기 위해, 적절한 수학적 형식 언어 시스템과 함께 자동화된 이론 증명 시스템(Automated Theorem Proving system)과 연계하여 사용되도록; 또는상기 XTT에 의해 적용되는 입력-출력 변환 사이의 기저의 가정의 설명을 제공하면서, 단백질 또는 다른 적절한 분자 형상과 연계하여 DNA 코드를 분석하여 DNA 유전자 발현, 단백질 접힘(protein folding) 및 다른 관련된 생화학적 애플리케이션에서의 규제 변화를 설명하도록; 또는옵션 사항으로, 음성 오디오 파형을 대응하는 텍스트로 번역하기 위해, 종단간 자동 음성 인식 아키텍쳐에서 사용되도록; 또는음성을 프로세싱하기 위해 종단간 딥 러닝 아키텍쳐에서 사용되도록 - 상기 머신 러닝 시스템은, 옵션 사항으로, 상기 음성을 잠재적인 이산 표현으로 변환하도록 구성되는 XAED 인코더를 더 포함함 - ; 또는다중 오브젝트 추적을 위해 사용되도록; 또는디지털 표면 모델 또는 깊이 맵 생성을 위해, 위성, 항공 또는 다른 타입의 조감도(bird-eye-view) 이미지를 매치시키도록; 또는단안(monocular), 입체(stereoscope), 및 다중 뷰 입력 데이터의 화상(imagery)을 프로세싱하도록; 또는오디오가 비디오에서 존재하는지를 예측하기 위한 오디오-비주얼 분류 태스크를 위해 사용되도록; 또는다음의 것: 진짜 이미지로부터 딥페이크 이미지를 검출 및 분류하는 것, 또는 머신 러닝 시스템을 혼란시키기 위해 데이터에 추가된 적대적 공격 정보의 존재를 검출하는 것 - 상기 XTT가 설명 가능 모델을 포함함 -중 하나 이상을 포함하는 합성하여 생성된 다차원 데이터의 생성 및 검출을 위해 사용되도록; 또는실제 화상 및 컴퓨터 생성 화상의 조합 내에서 인간 및 오브젝트의 정확하게 배치된 프레임화된, 스케일링된, 조명된, 및 렌더링된 합성 이미지를 자동적으로 생성, 삽입 및 혼합하도록 - 상기 머신 러닝 시스템은 카메라 프로세싱 시스템 내에서 구현됨 - ; 또는실제 화상 및 컴퓨터 생성 화상의 조합 내에서 인간 및 오브젝트의 정확하게 배치된 프레임화된, 스케일링된, 조명된, 및 렌더링된 합성 이미지를 자동적으로 생성, 삽입 및 혼합하도록 - 상기 머신 러닝 시스템은 의료 이미지의 분석 또는 수술 내에서의 사용을 위해 의료 하드웨어 내에서 구현됨 - ; 또는실제 화상 및 컴퓨터 생성 화상의 조합 내에서 인간 및 오브젝트의 정확하게 배치된 프레임화된, 스케일링된, 조명된, 및 렌더링된 합성 이미지를 자동적으로 생성, 삽입 및 혼합하도록 - 상기 머신 러닝 시스템은 기기 검사 프로세스 및 제조 검사 프로세스에서의 사용을 위해 엔지니어링 애플리케이션 내에서 구현됨 - ; 또는인간이 판독 가능하고 해석 가능한 포맷으로 데이터를 송신하는 의료용 임플란트 내에서 구현되도록; 또는생물학적 뉴런으로부터 입력 신호를 수신하도록 그리고 신호를 적절하게 인코딩된 포맷으로 생물학적 뉴런으로 출력하도록 - 상기 XTT는 손상된 생물학적 신경 시스템 연결을 연결하기 위한 또는 고급 인공 장구 디바이스(advanced prosthetic device)에서 인공 디바이스의 이식 및 연결을 돕기 위한 실용적인 솔루션을 제공하기 위해 두 개 이상의 생물학적 뉴런을 연결하는 의학적으로 이식된 디바이스의 일부로서 구현됨 - ; 또는상기 XTT의 일부로서 XGAIL 시스템의 시뮬레이터 및 데이터 샘플 합성을 구현하여 환경 세계 컨텍스트 및 상이한 모달리티의 관련된 시퀀스 순서에 따라 적절하게 동기화되는 다중 모드 혼합 출력을 생성하도록; 또는생성된 데이터 샘플을 적절하게 수정하기 위해 사용될 수 있는 다양한 학습된 스타일을 사용하여 새로운 데이터 샘플, 화상, 디지털 및 아날로그 혼합 미디어 그림, 및 3D 조각을 생성하도록 - 상기 머신 러닝 시스템은, 옵션 사항으로, 상기 생성된 데이터를, 보안성이 있는 추적 가능한 디지털 코드, 분산 원장 엔트리(distributed ledger entry) 또는 대체 불가능한 토큰(non-fungible token)을 사용하여 태깅하도록 추가로 구성됨 - ; 또는형식 음악 표기법 및 합성, 사운드 샘플 믹싱, 텍스트 대 음성 생성, 및 일반적인 오디오 샘플 생성의 조합을 사용하여, 음악을 생성하도록 - 상기 머신 러닝 시스템은, 옵션 사항으로, 상이한 모달리티의 입력을 분석하기 위해 다중 모드 XTT를 구현하도록 추가로 구성됨 - ; 또는비디오 프레임에 대한 주석을 예측하도록 - 상기 XTT는 종단간 딥 러닝 아키텍쳐에서 XTT 인코더로서 구현됨 - ; 또는온톨로지에서 미리 정의되는 대신 대화의 상태를 추적하고 보이지 않는 슬롯을 학습하도록; 또는입력 시퀀스에서 엔티티를 식별하도록; 또는입력 질문에 대한 답변의 시작 포지션 및 종료 포지션을 식별하도록; 또는텍스트에서의 엔티티의 언급을 지식 베이스의 대응하는 엔티티에 링크하도록; 또는이전 출력에 기초하여 출력을 예측하도록; 또는워크플로우 시스템 내에 통합되도록, 그리고 옵션 사항으로, 로봇 프로세스 자동화 시스템(Robotic Process Automation system), 결정 지원 시스템(Decision Support System), 또는 데이터 레이크 시스템(Data Lake system) 내에서 추가로 통합되도록; 또는인과적 설명 - 상기 인과적 설명은 반사실적 언어 표현 아키텍쳐(counterfactual language representation architecture)를 사용함 - 을 사용하도록; 또는원인과 결과를 핸들링하기 위해, 관련성, 중재, 및 반사실적 인과 로직을 핸들링하기 위해, 환경 모델 입력을 통해 타당성 체크를 수행하기 위해, 그리고 인과적으로 타당한 동형 사상(causally plausible isomorphism)을 통해 트레이닝 데이터를 증강하기 위해, 인과 모델 고유의 기능성을 구현하도록; 또는자연어 문서로부터 초안 인과 모델(draft causal model)을 자동적으로 생성하도록 - 상기 XTT는 인과 XTT 시스템을 정의함 - ; 또는제약 및 예측 로직 구현의 기초로서 계산 및 지식 표현 구조 - 상기 계산 및 지식 표현 구조는, 옵션 사항으로, 리소스 디스크립션 프레임워크(Resource Description Framework; RDF) 트리, RDF 그래프, Levi(레비) 그래프, 하이퍼그래프 구조, 또는 단순체 복합체를 포함함 - 를 사용하도록; 또는감사 로그 기능성(audit log functionality)을 구현하도록 - 감사 로그 기능성을 구현하는 것은: 상기 XTT의 흐름, 상호 작용 및 거동 및 그것의 관련된 조건, 이벤트, 트리거 및 액션 및 전반적인 역학을 설명하는 결정 로그 및 경로 트레이스를 생성하는 것을 수반하고, 상기 경로 트레이스는, 옵션 사항으로, 전문가 시스템 및 규칙 기반의 시스템에서, 트리거되고 실행된 규칙의 주석이 달린 시퀀스로서 구현되고, 또는 상기 경로 트레이스는, 옵션 사항으로, 워크플로우 시스템에서 워크플로우 엔진에 의해 실행된 워크플로우 노드 및 경로의 주석이 달린 시퀀스로서 구현되고, 그리고 상기 경로 트레이스는 상기 XTT의 정확한 시퀀스 및 거동을 설명하기 위해 사용 가능하고, 옵션 사항으로, 유저가 관심을 갖는 경로를 따라 가장 가까운 이웃을 상기 시스템의 유저에게 디스플레이하도록 구성되고, 상기 XTT는, 옵션 사항으로, 자기 자신의 감사 시스템 로그를 활용하도록 그리고 무단 변경 방지 및 추적 가능한 방식으로 상기 로그를 저장하도록 추가로 구성됨 - ; 또는액션의 시간 로직, 추상 머신 표기법, 페트리넷, 계산 트리 로직, 또는 모달 로직, 직관주의 로직(intuitionistic logic), 및/또는 관계형 의미론(relational semantic)을 형식적으로 표현할 수 있는 구현 방법 중 하나 이상에 기초한 시스템의 조합에 의해 구현되고 그에 의해 검증되도록; 또는앵커 용어(anchor term) - 상기 앵커 용어는 매우 중요한 노드, 에지, 이벤트, 트리거, 제약 또는 액션을 정의함 - 를 활용하도록; 또는성능을 증가시키기 위해 양자화 방법을 적용하도록 - 상기 시스템은, 옵션 사항으로, 상기 XTT의 정확도에 대한 양자화의 임의의 불리한 효과를 부분적으로 상쇄하고 트레이닝 동안 불안정성을 감소시키기 위해 불안정성 감소 기술을 적용하도록 추가로 구성됨 - ; 또는데이터 프라이버시 보호 솔루션의 실질적인 구현을 가능하게 하도록; 또는what-if, what-if-not, but-for 및 조건부 시나리오에 기초하여 생성된 구조화된 설명을 활용하여 그러한 시나리오를 XTT 시스템 입력에 적용한 결과에 대응하는 시나리오 기반의 설명 및 설명된 전략을 생성하도록; 또는외인성 및 내인성 변수 및 인과 모델을 사용하여 액션의 총 비용을 추정하도록 - 상기 총 비용을 추정하는 것은, 옵션 사항으로, 임의의 특정한 관련성, 중재 또는 반사실적 규칙을 적용하는 것을 포함하고, 옵션 사항으로, 부분적으로 누락된 값을 갖는 데이터에 대한 총 비용을 추정하는 것을 포함하고, 상기 시스템은, 옵션 사항으로, 그러한 애플리케이션의 가상 평균 또는 소망되는 시나리오 결과를 가진 애플리케이션의 실제 예를 제공하기 위해 최근접 이웃 방법(nearest-neighbor method)을 활용하도록 추가로 구성됨 - ; 또는예측 및/또는 트레이닝 성능을 증가시키기 위해, 내적의 근사 또는 완전한 제거, 희소 로컬 어텐션 모델(sparse local attention model), 적응형 어텐션 윈도우, 다차원 어텐션 매트릭스 근사, 지능형 가중치 공유 및 지능형 파라미터화: 중 하나 이상을 활용하도록; 또는보행 분석, 움직임 예측 및 감정 상태 예측을 포함하는 인간 거동을 분석하도록; 또는스포츠 영상 및 운동 성과를 예측 및 분석하도록; 또는의학적 상태를 검출 및 예측하도록; 또는금융 주식 거래 패턴을 분석하고 시장 거동을 예측하도록, 그리고 후속하여 특정한 주식에 대한 매수, 매도, 또는 롱 포지션 또는 숏 포지션과 같은 자동화된 액션을 실행하도록; 또는인더스트리 4.0 애플리케이션 내에서 동작하도록; 또는소스 언어로부터 타겟 언어로 문장을 번역하도록; 또는프리젠테이션 지향 변환 및 설명 및/또는 해석 출력의 향상을 수행하도록; 또는법적 문서를 프로세싱하고 수반되는 상이한 당사자 및 엔티티에 적용 가능하며 상기 법적 문서에 대한 참고 자료(reference)가 되는 텍스트 섹션 및 참고 자료를 정확하게 결정하도록; 또는대화 프로세싱, 챗봇, 콜 센터 관리 시스템, 사례 관리 시스템, 고객 지원 시스템, 클라이언트 관계 관리 시스템, 대화형 시스템, 질문 및 답변 시스템과 같은 애플리케이션에서 일반적으로 사용되는 상호 작용식 설명 및/또는 해석 프로세스의 흐름을 제어하도록; 또는피드백 제어 타입의 메커니즘을 필요로 하는 보강 학습 타입의 애플리케이션에서 사용되도록구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>35. 제1항 내지 제34항 중 어느 한 항에 있어서,상기 시스템은:유연한 아키텍쳐 - 상기 유연한 아키텍쳐는, 옵션 사항으로, FPGA를 포함함 - , 또는정적 아키텍쳐 - 상기 정적 아키텍쳐는, 옵션 사항으로, ASIC을 포함함 - , 또는이산 컴포넌트, 또는스핀트로닉 또는 멤리스터, 또는옵션 사항으로, 스파이킹 뉴런(spiking neuron)을 활용하는 뉴로모픽 아키텍쳐(neuromorphic architecture),또는 양자 컴퓨팅 하드웨어중 어느 하나를 사용하여 하드웨어 회로로서 구현되고, 상기 양자 컴퓨팅 하드웨어는, 옵션 사항으로: 다수의 큐비트 상태, 큐비트 기본 상태, 혼합 상태, 앤실라(Ancilla) 비트, 및 얽힘 및/또는 디코히어런스에 기인하는 다른 관련 양자 효과의 올바른 해석을 허용하도록, 또는 옵션 사항으로, 양자 로직 게이트를 비롯하여, XNN 내에서 양자 로직 고유의 연산자 및/또는 하드웨어 로직 게이트의 도입을 허용하도록, 또는 양자 효과를 이용하는 것에 의해 다수의 액션을 실행하거나, 또는 다수의 조건을 평가하거나, 또는 대규모 제약 시스템을 평가하도록 - 상기 양자 컴퓨팅 하드웨어는, 옵션 사항으로, 양자 알고리즘을 활용하도록 또는 하이브리드 솔루션을 활용하도록 구성됨 - , 또는 복수의 모달리티 및/또는 태스크에 대한 힐버트 공간(Hilbert space)을 정의하도록 - 상기 다중 모드 또는 멀티태스크 힐버트 공간은 태스크와 모달리티 사이의 모든 상기 상호 작용을 나타내기 위해 사용될 수 있고 크로스오버 학습의 양자 버전과 함께 모달리티 및/또는 태스크의 서브세트에 대한 트레이닝 둘 모두를 구현하기 위해 사용될 수 있음 - 구성되는 확장 기능(extension)을 포함하는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>36. 제1항 내지 제35항 중 어느 한 항에 있어서,상기 XTT는: 신경 심볼 제약(neuro-symbolic constraint)을, 상기 XTT와 관련되는 이전 이력 활성화 레이트 및/또는 상기 XTT와 관련되는 현재 및/또는 이전 이력 상태의 일부 또는 모두와 링크하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>37. 제4항 내지 제36항에 있어서,명명된 참조 라벨(named reference label)이 상기 설명 가능 아키텍쳐 내의 특정한 컴포넌트에 할당되고, 상기 명명된 참조 라벨은, 옵션 사항으로, 메타데이터를 포함하고, 옵션 사항으로, 심볼 표현 및/또는 수학식으로 구성될 수도 있고,상기 명명된 참조 라벨은, 옵션 사항으로, 안전 관련 제약에서 사용 가능하고, 그리고상기 머신 러닝 시스템은, 옵션 사항으로, 상기 시스템 내에서 발생하는 역학의 안정적이고 장기적인 설명을 생성하기 위해 상기 명명된 참조 라벨의 불변성을 활용하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>38. 제1항 내지 제37항 중 어느 한 항에 있어서,상기 머신 러닝 시스템은 식별 평가 추천(Identify-Assess-Recommend) 프레임워크에 의해 적어도 부분적으로 정의되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>39. 제1항 내지 제38항 중 어느 한 항에 있어서,상기 머신 러닝 시스템은 AutoXAI 시스템을 더 포함하고, 상기 시스템은 시나리오 기반의 설명을 생성하도록 구성되는, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>40. 제1항 내지 제39항 중 어느 한 항에 있어서,동일한 파라미터를 공유하는 다수의 태스크 및 다수의 모달리티를 프로세싱하기 위해,상기 XTT는 설명 가능 모델을 활용하도록, 상기 하나 이상의 입력 피쳐와 관련되는 하나 이상의 태스크에 대응하는 다수의 입력을 수신하도록, 그리고 상기 태스크에 대한 출력에 대응하는 다수의 출력을 생성하도록 구성되고,상기 설명 가능 모델은, 옵션 사항으로, 계층적 크로스오버 구조(hierarchical crossover structure)에 의해 정의되고, 옵션 사항으로, 복수의 크로스오버 서브시스템으로 구성되며, 상이한 태스크에 대해 학습되는 상이한 지식 사이의 크로스오버가 효율적으로 발생하는 것을 허용하도록 구성되고,상기 계층적 크로스오버 구조는 하나 이상의 단방향 링크 노드 및/또는 하나 이상의 양방향 링크 노드 및, 옵션 사항으로, 크로스오버 노이즈 노드 및/또는 크로스오버 노드간 링크를 포함하고, 그리고상기 설명 가능 모델은, 옵션 사항으로, 희소한 설명 가능 모델 또는 DEA인, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>41. 제40항에 있어서,상기 XTT의 입력에 커플링되어 CNN-XTT 아키텍쳐를 정의하는 컨볼루션 신경망(convolutional neural network; CNN)을 더 포함하고, 상기 CNN-XTT는 질의에 대한 상기 CNN-XTT에서의 활성화 경로를 시각화하기 위해 백맵(backmap)을 사용하도록, 옵션 사항으로, 정당성의 일부로서 상기 백맵을 통합하도록 구성되고, 상기 CNN-XTT는, 옵션 사항으로, 본질적으로 텍스트가 아닌 데이터 포맷을 사용하여 커널 라벨링 방법(kernel labelling method)을 관련된 인간이 판독 가능한 라벨에 통합하도록 구성되고, 상기 커널 라벨링 방법과 관련되는 커널 타입은, 옵션 사항으로, 근사 커널이고, 상기 CNN은, 옵션 사항으로, 시간적으로 최적화된 CNN인, 설명 가능 머신 러닝 시스템.</claim></claimInfo><claimInfo><claim>42. 제1항 내지 제41항 중 어느 한 항에 있어서,상기 시스템은, 인간이 판독 가능한 자연어, 그래픽 또는 시각적 포맷, 오디오, 음성, 햅틱, 비디오, 시계열, 다중 스펙트럼 데이터, 계층적으로 정렬된 멀티미디어 콘텐츠, 및 3D 데이터: 중 하나 이상인 포맷 또는 레이아웃으로 데이터를 출력하도록 구성되고,상기 출력 데이터는, 옵션 사항으로, 2D 데이터, 3D 데이터, 다차원 데이터 어레이, 트랜잭션 데이터, 시계열, 디지털화된 샘플, 센서 데이터, 이미지 데이터, 초분광 데이터, 자연어 텍스트, 비디오 데이터, 오디오 데이터, 햅틱 데이터, LIDAR(라이다) 데이터, RADAR(레이더) 데이터, SONAR(소나) 데이터: 중 하나 이상인 순차적 포맷 또는 레이아웃으로 되어 있는, 설명 가능 머신 러닝 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>몰타 엑스비엑스 **** 타슈비에시 어베잇 리고르 스트리트 ** 퀀텀 하우스 레벨 *</address><code>520230459643</code><country>몰타</country><engName>UMNAI LIMITED</engName><name>엄나이 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>몰타 에프알엔 **** 플...</address><code> </code><country> </country><engName>DALLI, Angelo</engName><name>달리 안젤로</name></inventorInfo><inventorInfo><address>몰타 에스지엔 ***...</address><code> </code><country> </country><engName>GRECH, Matthew</engName><name>그레치 매튜</name></inventorInfo><inventorInfo><address>몰타 케이케이알 **** 칼카...</address><code> </code><country> </country><engName>PIRRONE, Mauro</engName><name>피로네 마우로</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.12.17</priorityApplicationDate><priorityApplicationNumber>63/126,694</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.07.14</receiptDate><receiptNumber>1-1-2023-0778175-48</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2023.07.26</receiptDate><receiptNumber>1-5-2023-0119625-52</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2023.08.02</receiptDate><receiptNumber>1-1-2023-0853602-36</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.08.04</receiptDate><receiptNumber>1-5-2023-0125282-81</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.12.17</receiptDate><receiptNumber>1-1-2024-1401856-50</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.12.17</receiptDate><receiptNumber>1-1-2024-1401857-06</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237024184.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93da6e2d1e635397a9c6ddb41152b90a6f4b047938b805f5f9975ba5f4dda0b3f93f4bee13f829c9fe01eb32f4fa23bbde321aa1a6b3e2ee2b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf89f47133f07bfbb9f0b4a800400e3eb47b97d77d5ea232862d8d99653819190bba9447ef987967d6033c538d776ede12bce1aa2811c2cfe8</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>