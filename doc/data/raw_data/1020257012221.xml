<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:20.5120</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7012221</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>IOT 원격 제어기로서의 AR 안경</inventionTitle><inventionTitleEng>AR GLASSES AS IOT REMOTE CONTROL</inventionTitleEng><openDate>2025.05.20</openDate><openNumber>10-2025-0069912</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.15</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/03</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G06F 3/0346</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06K 7/14</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 67/125</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G16Y 40/30</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 스마트 안경과 같은 AR-가능 웨어러블 전자 디바이스들이 IoT(Internet of Things) 원격 제어 디바이스로의 사용을 위해 적응되며, 여기서 사용자는, 항목들을 보고 제스처들을 사용하여 선택들을 함으로써, 텔레비전 스크린, 컴퓨터 스크린, 또는 다른 IoT 가능 디바이스 상의 포인터를 제어하여 항목들을 선택할 수 있다. 내장된 6DoF(six-degrees-of-freedom) 추적 기능들은 탐색을 용이하게 하기 위해 스크린 상의 포인터를 이동시키는 데 사용된다. 디스플레이 스크린은 레이캐스팅 기법들을 사용하여 스크린과 사용자의 뷰의 교차점을 결정하기 위해 실세계 좌표들로 추적된다. 손 및 머리 제스처 검출은 사용자가 상이한 제스처들을 수행함으로써 다양한 제어 액션들을 실행할 수 있게 하는 데 사용된다. 기법들은 AR-가능 웨어러블 전자 디바이스들의 디스플레이들에서 시청될 수 있는 AR-강화 콘텐츠를 제공하는 스마트 디스플레이들에 특히 유용하다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.28</internationOpenDate><internationOpenNumber>WO2024063865</internationOpenNumber><internationalApplicationDate>2023.07.31</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/029076</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. IoT(Internet of Things) 디스플레이를 갖는 IoT 가능(enabled) 디바이스를 원격으로 제어하도록 적응된 안경류(eyewear) 디바이스로서,카메라;명령들을 저장하는 메모리; 및상기 카메라 및 상기 메모리에 커플링된 프로세서를 포함하고, 상기 프로세서는 상기 명령들을 실행하여,  상기 IoT 가능 디바이스와 상기 안경류 디바이스 사이의 통신 인터페이스를 통한 통신들을 위해 상기 IoT 가능 디바이스와 상기 안경류 디바이스를 페어링하고; 상기 안경류 디바이스를 상기 IoT 디스플레이의 실세계 좌표 포지션(real-world coordinate position)으로 보정하고; 상기 IoT 디스플레이와 상기 안경류 디바이스의 FOV(field of view)의 교차점을 결정하고; 그리고 상기 통신 인터페이스를 통해, 상기 교차점에 기초하여 커서 포지션 업데이트를 상기 IoT 가능 디바이스로 전송하도록 상기 안경류 디바이스를 구성하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 프로세서는 명령들을 추가로 실행하여,손 제스처 또는 머리 제스처 중 적어도 하나를 검출하고; 그리고상기 통신 인터페이스를 통해 제스처 이벤트를 상기 IoT 가능 디바이스로 전송하도록 상기 안경류 디바이스를 구성하고,상기 제스처 이벤트는 상기 검출된 적어도 하나의 손 제스처 또는 머리 제스처의 적어도 하나의 제스처 ID(identification)를 포함하고, 상기 적어도 하나의 제스처 ID는 상기 적어도 하나의 제스처 ID에 대응하는 액션들을 수행하기 위해 상기 IoT 가능 디바이스에 의해 사용되는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,디스플레이를 더 포함하고,상기 프로세서는 명령들을 추가로 실행하여, 상기 제스처 ID에 대응하는 증강 데이터를 상기 디스플레이 상에서 수신하도록 상기 안경류 디바이스를 구성하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 프로세서는 명령들을 추가로 실행하여, 상기 카메라로부터의 카메라 프레임들을 프로세싱하고, 상기 카메라 프레임들에서 상기 IoT 디바이스를 검출하고, 상기 카메라 프레임들 내의 상기 IoT 디스플레이의 경계 상자(bounding box)를 리턴(return)하고, 상기 카메라 프레임들에서 상기 경계 상자의 깊이 맵을 획득하고, 실세계 좌표들에서 상기 안경류 디바이스에 대한 상기 IoT 디스플레이의 현재 포지션을 결정하기 위해 상기 경계 상자와 깊이 맵을 결합하고, 그리고 상기 IoT 디스플레이의 결정된 현재 포지션을 사용하여 센서 오프셋에 대해 조정함으로써, 상기 안경류 디바이스를 재보정하도록 상기 안경류 디바이스를 구성하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 프로세서는 명령들을 추가로 실행하여, 상기 통신 인터페이스 상에서 손 제스처들 또는 머리 제스처들 중 적어도 하나와 관련된 메시지들을 포함하는 동적 이벤트들을 구독하도록 상기 안경류 디바이스를 구성함으로써, 상기 IoT 가능 디바이스와 상기 안경류 디바이스를 페어링하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 프로세서는 명령들을 추가로 실행하여, HTTP(hypertext transfer protocol), REST(representational state transfer) API, 웹소켓들, 또는 MQTT(message queue telemetry transport) 중 적어도 하나를 포함하는 프로토콜로 상기 통신 인터페이스를 통해 요청들을 전송함으로써 상기 IoT 가능 디바이스와 상기 안경류 디바이스를 페어링하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,IMU(inertial measurement unit)를 더 포함하고,상기 프로세서는 명령들을 추가로 실행하여, 상기 IoT 디스플레이의 적어도 세 개의 코너들에 디스플레이된 QR(quick response) 코드들을 검출하고, 상기 카메라의 카메라 프레임 데이터 및 상기 IMU의 IMU 데이터로부터 상기 검출된 QR 코드들의 3D(three-dimensional) 좌표 포지션들을 획득하고, 그리고 상기 3D 좌표 포지션들로부터 실세계 좌표들에서의 상기 IoT 디스플레이의 포지션을 결정함으로써, 상기 안경류 디바이스를 상기 IoT 디스플레이의 실세계 좌표 포지션으로 보정하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 프로세서는 명령들을 추가로 실행하여, 상기 통신 인터페이스를 통해 상기 QR 코드들을 상기 IoT 가능 디바이스로 통신하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 프로세서는 명령들을 추가로 실행하여, 실세계 좌표들에서 상기 안경류 디바이스에 대한 상기 IoT 디스플레이의 포지션을 추적하고, 상기 IoT 디스플레이의 추적된 포지션과 상기 안경류 디바이스의 FOV의 교차점을 결정하기 위해 레이캐스팅(raycasting)을 사용함으로써, 상기 IoT 디스플레이와 상기 안경류 디바이스의 FOV의 교차점을 결정하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 프로세서는 명령들을 추가로 실행하여, 상기 안경류 디바이스의 사용자가 자신의 머리를 움직이거나 상기 IoT 가능 디바이스를 포함하는 방 주위를 이동할 때 커서 포지션 업데이트들을 상기 IoT 디바이스로 전송하도록 상기 안경류 디바이스를 구성하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 프로세서는 명령들을 추가로 실행하여,  상기 IoT 디스플레이와 상기 안경류 디바이스의 FOV의 교차점이 결정될 수 없을 때, (a) 디폴트 커서 포지션 또는 (b) 에러 메시지 중 적어도 하나를 상기 IoT 가능 디바이스로 전송하도록 상기 안경류 디바이스를 구성하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 IoT 가능 디바이스는 스마트 텔레비전을 포함하는,안경류 디바이스.</claim></claimInfo><claimInfo><claim>13. AR(augmented reality)-가능 안경류 디바이스를 사용하여 IoT(Internet of Things) 디스플레이를 갖는 IoT 가능 디바이스를 원격으로 제어하는 방법으로서,상기 IoT 가능 디바이스와 상기 AR-가능 안경류 디바이스 사이의 통신 인터페이스를 통한 통신들을 위해 상기 IoT 가능 디바이스와 상기 AR-가능 안경류 디바이스를 페어링하는 단계;상기 AR-가능 안경류 디바이스를 상기 IoT 디스플레이의 실세계 좌표 포지션으로 보정하는 단계;상기 IoT 디스플레이와 상기 AR-가능 안경류 디바이스의 FOV(field of view)의 교차점을 결정하는 단계; 및상기 통신 인터페이스를 통해, 상기 교차점에 기초하여 커서 포지션 업데이트를 상기 IoT 가능 디바이스로 전송하는 단계를 포함하는,IoT 가능 디바이스를 원격으로 제어하는 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,손 제스처 또는 머리 제스처 중 적어도 하나를 검출하는 단계; 및상기 통신 인터페이스를 통해 제스처 이벤트를 상기 IoT 가능 디바이스로 전송하는 단계를 더 포함하고,상기 제스처 이벤트는 상기 검출된 적어도 하나의 손 제스처 또는 머리 제스처의 적어도 하나의 제스처 ID(identification)를 포함하고, 상기 적어도 하나의 제스처 ID는 상기 적어도 하나의 제스처 ID에 대응하는 액션들을 수행하기 위해 상기 IoT 가능 디바이스에 의해 사용되는,IoT 가능 디바이스를 원격으로 제어하는 방법.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 카메라로부터의 카메라 프레임들을 프로세싱하고, 상기 카메라 프레임들에서 상기 IoT 디바이스를 검출하고, 상기 카메라 프레임들 내의 상기 IoT 디스플레이의 경계 상자를 리턴하고, 상기 카메라 프레임들에서 상기 경계 상자의 깊이 맵을 획득하고, 실세계 좌표들에서 상기 AR-가능 안경류 디바이스에 대한 상기 IoT 디스플레이의 현재 포지션을 결정하기 위해 상기 경계 상자와 깊이 맵을 결합하고, 상기 IoT 디스플레이의 결정된 현재 포지션을 사용하여 상기 AR-가능 안경류 디바이스의 센서 오프셋들에 대해 조정함으로써, 상기 AR-가능 안경류 디바이스를 재보정하는 단계를 더 포함하는,IoT 가능 디바이스를 원격으로 제어하는 방법.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,상기 AR-가능 안경류 디바이스를 상기 IoT 디스플레이의 실세계 좌표 포지션으로 보정하는 단계는, 상기 IoT 디스플레이의 적어도 세 개의 코너들에 디스플레이된 QR(quick response) 코드들을 검출하는 단계, 상기 AR-가능 안경류 디바이스의 카메라의 카메라 프레임 데이터 및 상기 AR-가능 안경류 디바이스의 IMU(inertial measurement unit)로부터의 IMU 데이터로부터 상기 검출된 QR 코드들의 3D(three-dimensional) 좌표 포지션들을 획득하는 단계, 및 상기 3D 좌표 포지션들로부터 실세계 좌표들에서의 상기 IoT 디스플레이의 포지션을 결정하는 단계를 포함하는, IoT 가능 디바이스를 원격으로 제어하는 방법.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서,상기 IoT 디스플레이와 상기 AR-가능 안경류 디바이스의 FOV의 교차점을 결정하는 단계는, 실세계 좌표들에서 상기 AR-가능 안경류 디바이스에 대한 상기 IoT 디스플레이의 포지션을 추적하는 단계, 및 상기 IoT 디스플레이의 추적된 포지션과 상기 AR-가능 안경류 디바이스의 FOV의 교차점을 결정하기 위해 레이캐스팅을 사용하는 단계를 포함하는,IoT 가능 디바이스를 원격으로 제어하는 방법.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서,상기 AR-가능 안경류 디바이스의 사용자가 자신의 머리를 움직이거나 상기 IoT 가능 디바이스를 포함하는 방 주위를 이동할 때 커서 포지션 업데이트들을 상기 IoT 디바이스로 전송하는 단계를 더 포함하는,IoT 가능 디바이스를 원격으로 제어하는 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 IoT 디스플레이와 상기 안경류 디바이스의 FOV의 교차점이 결정될 수 없을 때, (a) 디폴트 커서 포지션 또는 (b) 에러 메시지 중 적어도 하나를 상기 IoT 가능 디바이스로 전송하는 단계를 더 포함하는,IoT 가능 디바이스를 원격으로 제어하는 방법.</claim></claimInfo><claimInfo><claim>20. 명령들을 저장하는 비-일시적인 컴퓨터-판독가능 저장 매체로서, 상기 명령들은 적어도 하나의 프로세서에 의해 실행될 때 상기 적어도 하나의 프로세서로 하여금, 동작들을 수행함으로써 AR(augmented reality)-가능 안경류 디바이스를 사용하여 IoT(Internet of Things) 디스플레이를 갖는 IoT 가능 디바이스를 원격으로 제어하게 하고, 상기 동작들은: 상기 IoT 가능 디바이스와 상기 AR-가능 안경류 디바이스 사이의 통신 인터페이스를 통한 통신들을 위해 상기 IoT 가능 디바이스와 상기 AR-가능 안경류 디바이스를 페어링하는 동작;상기 AR-가능 안경류 디바이스를 상기 IoT 디스플레이의 실세계 좌표 포지션으로 보정하는 동작;상기 IoT 디스플레이와 상기 AR-가능 안경류 디바이스의 FOV(field of view)의 교차점을 결정하는 동작; 및상기 통신 인터페이스를 통해, 상기 교차점에 기초하여 커서 포지션 업데이트를 상기 IoT 가능 디바이스로 전송하는 동작을 포함하는,비-일시적인 컴퓨터-판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>스위스</country><engName>MOLL, Sharon</engName><name>몰, 샤론</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아...</address><code> </code><country>폴란드</country><engName>GURGUL, Piotr</engName><name>구르굴, 피오트르</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 서소문로 **, *층(서소문동)</address><code>920241000417</code><country>대한민국</country><engName>NAM IP GROUP</engName><name>특허법인(유)남아이피그룹</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.19</priorityApplicationDate><priorityApplicationNumber>17/947,607</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.15</receiptDate><receiptNumber>1-1-2025-0422038-77</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.04.23</receiptDate><receiptNumber>1-5-2025-0068270-31</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257012221.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9372a0444bb10194dc695dff0177b6f0a40b31a02d0c685915da0f05385155cf773d2570c37716950fa3ca6ef48a39fa33e04f293af57879f8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfb64526f5b1ad5d341b9599b63059f67e96111d600f52ea2353207c0ffee29499b91d605a322611074763da45aa69a89c67168c4d29ceec4e</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>