<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:40:34.4034</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.05.26</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-7043726</applicationNumber><claimCount>159</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신경 활동으로부터의 실시간 단어 및 음성 디코딩을 위한 방법들 및 디바이스들</inventionTitle><inventionTitleEng>METHODS AND DEVICES FOR REAL-TIME WORD AND SPEECH DECODING FROM NEURAL ACTIVITY</inventionTitleEng><openDate>2024.02.23</openDate><openNumber>10-2024-0024095</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.05.22</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2023.12.18</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/37</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/372</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2021.01.01)</ipcDate><ipcNumber>A61B 5/293</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 개인들의 의사소통을 지원하기 위한 방법들, 디바이스들 및 시스템들이 제공된다. 특히, 개인의 신경 활동으로부터 직접 단어 및 문장을 디코딩하기 위한 방법들, 디바이스들, 및 시스템들이 제공된다. 개인이 단어를 말하거나 철자를 말하려 시도하는 동안 음성 처리에 관여하는 뇌 영역의 피질 활동이 기록된다. 기록된 뇌 활동으로부터 단어를 검출하고 분류하기 위해 딥 러닝 계산 모델이 사용된다. 뇌 활동으로부터의 음성 디코딩은 단어의 특정 시퀀스가 발생할 가능성을 예측하는 언어 모델의 사용에 의해 도움을 받는다. 또한, 신경 활동으로부터 시도된 비음성 운동 동작의 디코딩은 의사소통을 추가로 보조하기 위해 사용될 수 있다. 이 신경기술은 발화 능력을 상실하고 자율성 및 삶의 질을 향상시킬 잠재력을 갖는 환자에게 의사소통을 회복하는데 활용될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2022.12.01</internationOpenDate><internationOpenNumber>WO2022251472</internationOpenNumber><internationalApplicationDate>2022.05.26</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/031101</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 대상체의 의사소통을 보조하는 방법으로서, 상기 방법은:상기 대상체의 뇌의 감각운동 피질 영역(sensorimotor cortex region) 내의 위치에 전극을 포함하는 신경 기록 디바이스를 위치시켜, 상기 대상체에 의해 시도된 음성과 연관된 뇌 전기 신호 데이터를 기록하는 단계;상기 대상체의 머리 상의 위치에 컴퓨팅 디바이스와 통신하는 인터페이스를 위치시키는 단계로서, 상기 인터페이스는 신경 기록 디바이스에 연결되는 단계;상기 신경 기록 디바이스를 사용하여 상기 대상체에 의해 시도된 음성과 연관된 뇌 전기 신호 데이터를 기록하는 단계로서, 상기 인터페이스는 신경 기록 디바이스로부터 뇌 전기 신호 데이터를 수신하고 뇌 전기 신호 데이터를 컴퓨팅 디바이스의 프로세서로 전송하는 단계; 및프로세서를 사용하여 상기 기록된 뇌 전기 신호 데이터로부터 단어, 어구 또는 문장을 디코딩하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 대상체는 관절염, 뇌졸중, 외상성 뇌손상, 뇌종양 또는 근위축성 측삭 경화증으로 인해 상기 의사소통이 어려운, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 대상체는 마비되어있는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 신경 기록 디바이스의 위치는 복측 감각운동 피질(ventral sensorimotor cortex) 내에 있는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 전극은 상기 감각운동 피질 영역의 표면 상에 또는 상기 감각운동 피질 영역 내에 위치하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 전극은 경막하 공간에서 뇌의 감각운동 피질 영역의 표면에 위치하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌-침투 전극 어레이(brain-penetrating electrode array)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제1항 내지 제7항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌피질전도(ECoG) 전극 어레이를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서상기 전극은 심부 전극 또는 표면 전극인, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 전기 신호 데이터는 고감마 주파수 컨텐츠 특성을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 전기 신호 데이터는 70 Hz 내지 150 Hz 범위의 신경 진동을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서,상기 뇌 전기 신호 데이터를 기록하는 단계는, 중심전회(precentral gyrus), 중심후회(postcentral gyrus), 후중전두회(posterior middle frontal gyrus), 후상전두회(posterior superior frontal gyrus) 또는 후하전두회(posterior inferior frontal gyrus) 영역, 또는 이들의 임의의 조합으로부터 선택된 감각운동 피질 영역으로부터 뇌 전기 신호 데이터를 기록하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제1항 내지 제12항 중 어느 한 항에 있어서,상기 대상체의 뇌를 매핑하여 상기 대상체에 의해 시도된 음성과 연관된 상기 뇌 전기 신호를 기록하기 위해 상기 전극을 위치시키기 위한 최적의 위치를 식별하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서,상기 인터페이스는 대상체의 두개골에 부착된 경피 페데스탈 커넥터(percutaneous pedestal connector)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 인터페이스는 상기 경피 페데스탈 커넥터에 연결된 헤드스테이지를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서,상기 프로세서는 컴퓨터 또는 핸드헬드 디바이스에 의해 제공되는, 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 핸드헬드 디바이스는 휴대폰 또는 태블릿인, 방법.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제17항 중 어느 한 항에 있어서,상기 프로세서는 시도된 단어 생성과 연관된 기록된 뇌 전기 신호 데이터 내의 전기 신호의 신경 활동 패턴 식별에 기초하여 음성 검출, 단어 분류, 및 문장 디코딩을 자동화하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 프로세서는 음성 검출, 단어 분류, 및 문장 디코딩을 위해 기계 학습 알고리즘을 사용하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 음성 검출 및 상기 단어 분류를 위해 인공 신경망(ANN) 모델이 이용되고, 문장 디코딩을 위해 은닉 마르코프 모델(HMM), 비터비(Viterbi) 디코딩 모델 또는 자연어 처리 기법이 이용되는, 방법.</claim></claimInfo><claimInfo><claim>21. 제1항 내지 제20항 중 어느 한 항에 있어서,상기 프로세서는 상기 대상체에 의해 시도된 음성 중에 단어 생성의 온셋(onset) 및 오프셋(offset) 검출을 자동화하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,준비, 음성 및 휴식에 대한 이벤트 라벨을 상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 할당하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>23. 제21항 또는 제22항에 있어서,상기 프로세서는 단어 분류의 검출된 온셋 무렵의 시간 윈도우 내에서 상기 기록된 뇌 전기 신호 데이터를 사용하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>24. 제1항 내지 제23항 중 어느 한 항에 있어서,상기 대상체는 상기 시도된 음성에 대해 지정된 단어 세트로 제한되는, 방법.</claim></claimInfo><claimInfo><claim>25. 제24항에 있어서,상기 프로세서는 상기 단어 세트의 단어가 상기 시도된 음성 중 상기 대상체가 생성하려고 시도한 의도된 단어일 확률을 계산하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서,상기 프로세서는 상기 단어 세트의 단어가 상기 단어 세트의 모든 단어에 대해 상기 시도된 음성 중 상기 대상체가 생성하려고 시도한 의도된 단어일 확률을 계산하도록 프로그래밍된, 방법.</claim></claimInfo><claimInfo><claim>27. 제24항 내지 제26항 중 어느 한 항에 있어서,상기 단어 세트는 이다(am), 이다(are), 나쁜, 가져오다, 깨끗한, 가까운, 편안한, 오다, 컴퓨터, 하다, 믿음, 가족, 느끼다, 안경, 가다, 좋은, 안녕히 가세요, 갖다, 안녕하세요, 돕다, 여기, 바라다, 어떻게, 배고픈, 저는, 이다(is), 그것, 좋아하다, 음악, 저의, 필요하다, 아니요(no), 아니다(not), 간호사, 좋아요, 밖, 해주세요, 바로, 성공, 말하다, 저것, 그들, 목마른, 피곤한, 위, 매우, 무엇, 어디, 예 및 당신을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>28. 제1항 내지 제27항 중 어느 한 항에 있어서,상기 대상체는 상기 단어 세트의 단어를 제한 없이 사용하여 문장을 생성할 수 있는, 방법.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서,상기 프로세서는 단어의 시퀀스가 상기 시도된 음성 중 상기 대상체가 생성하려고 시도한 의도된 문장일 확률을 계산하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>30. 제1항 내지 제29항 중 어느 한 항에 있어서,상기 프로세서는 예측된 단어 시퀀스 확률을 결정함으로써 디코딩을 돕기 위해 단어의 시퀀스 내의 이전 단어 또는 어구를 고려하여 다음 단어 확률을 제공하는 언어 모델을 사용하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>31. 제30항에 있어서,더 빈번하게 발생하는 단어에는 상기 언어 모델에 따라 덜 빈번하게 발생하는 단어보다 더 많은 가중치가 할당되는, 방법.</claim></claimInfo><claimInfo><claim>32. 제30항 또는 제31항에 있어서,상기 프로세서는 비터비 디코딩 모델을 사용하여, 상기 시도된 음성과 연관된 뇌 전기 신호 데이터, 상기 기계 학습 알고리즘을 사용하는 상기 단어 분류 모델로부터의 상기 예측된 단어 확률, 및 상기 언어 모델을 사용하는 상기 단어 시퀀스 확률을 고려하여 상기 대상체의 의도된 음성에서 가장 가능성 있는 단어의 시퀀스를 결정하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>33. 제1항 내지 제32항 중 어느 한 항에 있어서,상기 대상체의 시도된 비음성 운동 동작과 연관된 뇌 전기 신호 데이터를 기록하는 단계로서, 상기 대상체는 시도된 음성의 개시 또는 종료를 나타내거나 외부 디바이스를 제어하기 위해 시도된 비음성 운동 동작을 수행하는 단계; 및상기 시도된 비음성 운동 동작과 연관된 상기 기록된 뇌 전기 신호 데이터에서 전기 신호의 패턴을 식별하고 상기 대상체가 비음성 운동 동작을 시도했을 확률을 계산하는 비음성 운동 동작 분류 모델을 사용하여 뇌 전기 신호 데이터를 분석하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서,상기 시도된 비음성 운동 동작은 시도된 머리, 팔, 손, 발 또는 다리 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>35. 제34항에 있어서,상기 시도된 손 동작은 상상된 손 제스처 또는 상상된 손 스퀴즈(squeeze)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>36. 제33항 내지 제35항 중 어느 한 항에 있어서,상기 프로세서는 상기 시도된 비음성 운동 동작과 연관된 상기 기록된 뇌 전기 신호 데이터 내의 전기 신호의 신경 활동 패턴 식별에 기초하여 상기 대상체에 의해 시도된 음성의 종료를 시그널링하는 상기 대상체의 시도된 비음성 운동 동작의 검출을 자동화하도록 추가로 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서,상기 프로세서는 상기 시도된 비음성 운동 동작에 대한 이벤트 라벨을 상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 할당하도록 추가로 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>38. 제1항 내지 제37항 중 어느 한 항에 있어서,상기 방법은 디코딩의 정확도를 평가하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>39. 대상체에 의해 시도된 음성과 연관된 기록된 뇌 전기 신호 데이터로부터 문장을 디코딩하기 위한 컴퓨터 구현 방법으로서, 상기 컴퓨터는:상기 대상체에 의해 시도된 음성과 연관된 상기 기록된 뇌 전기 신호 데이터를 수신하는 단계;음성 검출 모델을 사용하여 상기 기록된 뇌 전기 신호 데이터를 분석하여 상기 뇌 전기 신호 데이터를 기록하는 동안 임의의 시점에서 시도된 음성이 발생할 확률을 계산하고, 상기 대상체에 의해 시도된 음성 중 단어 생성의 온셋 및 오프셋을 검출하는 단계;상기 대상체에 의해 시도된 단어 생성과 연관된 상기 기록된 뇌 전기 신호 데이터에서 전기 신호의 패턴을 식별하고 예측된 단어 확률을 계산하는 단어 분류 모델을 사용하여 상기 뇌 전기 신호 데이터를 분석하는 단계;단어의 시퀀스에서 이전 단어 또는 어구를 고려하여 다음 단어 확률을 제공하는 언어 모델을 사용하여 단어 분류 모델로부터의 계산된 단어 확률을 문장 내의 예측된 단어 시퀀스 확률과 조합하여 사용함으로써 문장 디코딩을 수행하여 예측 단어 시퀀스 확률을 계산하고, 단어 분류 모델 및 언어 모델을 사용하여 결정된 예측된 단어 확률에 기초하여 문장 내의 가장 가능성 있는 단어의 시퀀스를 결정하는 단계; 및상기 기록된 뇌 전기 신호 데이터로부터 디코딩된 문장을 표시하는 단계를 수행하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>40. 제39항에 있어서,기계 학습 알고리즘이 음성 검출, 단어 분류, 및 문장 디코딩을 위해 사용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>41. 제40항에 있어서,상기 음성 검출 및 상기 단어 분류를 위해 인공 신경망(ANN) 모델이 이용되고, 문장 디코딩을 위해 은닉 마르코프 모델(HMM), 비터비(Viterbi) 디코딩 모델 또는 자연어 처리 기법이 이용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>42. 제39항 내지 제41항 중 어느 한 항에 있어서,상기 대상체는 상기 시도된 음성에 대해 지정된 단어 세트로 제한되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>43. 제42항에 있어서,상기 단어 세트의 단어가 상기 대상체가 단어 세트의 모든 단어마다 상기 시도된 음성 중 생성하려고 시도한 의도된 단어일 확률을 계산하고, 상기 대상체가 시도된 음성 중 생성하려고 시도한 의도된 단어일 가장 높은 확률을 갖는 단어 세트의 단어를 선택하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>44. 제39항 내지 제43항 중 어느 한 항에 있어서,상기 대상체는 상기 단어 세트의 단어를 제한 없이 사용하여 문장을 생성하거나 상기 시도된 음성에 대해 지정된 문장 세트로 제한되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>45. 제39항 내지 제44항 중 어느 한 항에 있어서,단어의 시퀀스가 상기 시도된 음성 중 상기 대상체가 생성하려고 시도한 의도된 문장일 확률을 계산하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>46. 제45항에 있어서,상기 가장 가능성 있는 문장 및 하나 이상의 가능성 적은 문장을 유지하고, 단어의 시퀀스가 각각의 단어를 디코딩한 후에 상기 시도된 음성 중 상기 대상체가 생성하려고 시도한 의도된 문장일 확률을 재계산하는 단계를 추가로 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>47. 제46항에 있어서,상기 가장 가능성 있는 문장 및 상기 하나 이상의 가능성 적은 문장은 상기 시도된 음성을 위해 상기 대상체에 의해 사용되는 단어 세트로부터의 단어로만 구성되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>48. 제39항 내지 제47항 중 어느 한 항에 있어서,준비, 음성 및 휴식에 대한 이벤트 라벨을 상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 할당하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>49. 제48항에 있어서,단어 분류의 검출된 온셋 무렵의 시간 윈도우 내의 상기 기록된 뇌 전기 신호 데이터만을 사용하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>50. 제39항 내지 제49항 중 어느 한 항에 있어서,상기 언어 모델에 따라 덜 빈번하게 발생하는 단어보다 더 빈번하게 발생하는 단어에 더 많은 가중치가 할당되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>51. 제39항 내지 제50항 중 어느 한 항에 있어서,상기 대상체에 의해 시도된 단어 생성과 연관된 상기 기록된 뇌 전기 신호 데이터 내의 전기 신호의 패턴에 관한 정보를 포함하는 상기 대상체에 대한 사용자 프로파일을 저장하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>52. 제39항 내지 제51항 중 어느 한 항에 있어서,상기 대상체의 시도된 비음성 운동 동작과 연관된 기록된 뇌 전기 신호 데이터를 수신하는 단계로서, 상기 대상체는 시도된 음성의 개시 또는 종료를 나타내거나 외부 디바이스를 제어하기 위해 시도된 비음성 운동 동작을 수행하는 단계; 및 상기 시도된 비음성 운동 동작과 연관된 상기 기록된 뇌 전기 신호 데이터에서 전기 신호의 패턴을 식별하고 상기 대상체가 비음성 운동 동작을 시도했을 확률을 계산하는 분류 모델을 사용하여 뇌 전기 신호 데이터를 분석하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>53. 제52항에 있어서,상기 시도된 비음성 운동 동작은 시도된 머리, 팔, 손, 발 또는 다리 동작을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>54. 제53항에 있어서,상기 시도된 손 동작은 상상된 손 제스처 또는 상상된 손 스퀴즈(squeeze)를 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>55. 제52항 내지 제54항 중 어느 한 항에 있어서,상기 시도된 비음성 운동 동작에 대한 이벤트 라벨을 상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 할당하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>56. 컴퓨터 내의 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 제39항 내지 제55항 중 어느 한 항의 방법을 수행하게 하는 프로그램 명령어들을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>57. 제56항의 비일시적 컴퓨터 판독가능 매체 및 대상체에 의해 시도된 음성과 연관된 뇌 전기 신호 데이터를 디코딩하기 위한 명령어들을 포함하는, 키트.</claim></claimInfo><claimInfo><claim>58. 대상체의 의사소통을 보조하는 시스템으로서, 상기 시스템은:상기 대상체의 뇌의 감각운동 피질 영역(sensorimotor cortex region) 내의 위치에 위치하여 상기 대상체에 의해 시도된 음성 또는 시도된 비음성 운동 동작과 연관된 뇌 전기 신호 데이터를 기록하도록 구성된 전극을 포함하는 신경 기록 디바이스;제39항 내지 제55항 중 어느 한 항의 컴퓨터 구현 방법에 따른 기록된 뇌 전기 신호 데이터로부터 문장을 디코딩하도록 프로그래밍된 프로세서;컴퓨팅 디바이스와 통신하는 인터페이스로서, 상기 인터페이스는 상기 대상체의 머리 상의 위치에 위치되도록 구성되고, 상기 인터페이스는 상기 신경 기록 디바이스로부터 상기 뇌 전기 신호 데이터를 수신하고 상기 뇌 전기 신호 데이터를 상기 프로세서로 전송하는, 인터페이스; 및상기 기록된 뇌 전기 신호 데이터로부터 디코딩된 문장을 표시하기 위한 디스플레이 컴포넌트를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>59. 제58항에 있어서,상기 대상체는 관절염, 뇌졸중, 외상성 뇌손상, 뇌종양 또는 근위축성 측삭 경화증으로 인해 상기 의사소통에 어려움을 겪는, 시스템.</claim></claimInfo><claimInfo><claim>60. 제58항 또는 제59항에 있어서,상기 신경 기록 디바이스의 위치는 복측 감각운동 피질(ventral sensorimotor cortex) 내에 있는, 시스템.</claim></claimInfo><claimInfo><claim>61. 제58항 내지 제60항 중 어느 한 항에 있어서,상기 전극은 감각운동 피질 영역의 표면 상에 또는 감각운동 피질 영역 내에 위치하도록 구성된, 시스템.</claim></claimInfo><claimInfo><claim>62. 제61항에 있어서,상기 전극은 경막하 공간에서 뇌의 감각운동 피질 영역의 표면에 위치하도록 구성된, 시스템.</claim></claimInfo><claimInfo><claim>63. 제58항 내지 제62항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌-침투 전극 어레이를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>64. 제58항 내지 제63항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌피질전도(ECoG) 전극 어레이를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>65. 제58항 내지 제63항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 심부 전극 또는 표면 전극인, 시스템.</claim></claimInfo><claimInfo><claim>66. 제58항 내지 제65항 중 어느 한 항에 있어서,상기 전기 신호 데이터는 고감마 주파수 컨텐츠 특성을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>67. 제66항에 있어서,상기 전기 신호 데이터는 70 Hz 내지 150 Hz 범위의 신경 진동을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>68. 제58항 내지 제67항 중 어느 한 항에 있어서,상기 인터페이스는 대상체의 두개골에 부착된 경피 페데스탈 커넥터(percutaneous pedestal connector)를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>69. 제68항에 있어서,상기 인터페이스는 상기 경피 페데스탈 커넥터에 연결 가능한 헤드스테이지를 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>70. 제58항 내지 제69항 중 어느 한 항에 있어서,상기 프로세서는 컴퓨터 또는 핸드헬드 디바이스에 의해 제공되는, 시스템.</claim></claimInfo><claimInfo><claim>71. 제70항에 있어서,상기 핸드헬드 디바이스는 휴대폰 또는 태블릿인, 시스템.</claim></claimInfo><claimInfo><claim>72. 제58항 내지 제71항 중 어느 한 항에 있어서,기계 학습 알고리즘이 음성 검출, 단어 분류 및 문장 디코딩에 사용되는, 시스템.</claim></claimInfo><claimInfo><claim>73. 제72항에 있어서,상기 음성 검출 및 상기 단어 분류를 위해 인공 신경망(ANN) 모델이 이용되고, 문장 디코딩을 위해 은닉 마르코프 모델(HMM), 비터비(Viterbi) 디코딩 모델 또는 자연어 처리 기법이 이용되는, 시스템.</claim></claimInfo><claimInfo><claim>74. 제58항 내지 제73항 중 어느 한 항에 있어서,상기 프로세서는 상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 준비, 음성 및 휴식에 대한 이벤트 라벨을 할당하도록 추가로 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>75. 제74항에 있어서,상기 프로세서는 단어 분류의 검출된 온셋 무렵의 시간 윈도우 내에서 상기 기록된 뇌 전기 신호 데이터를 사용하도록 추가로 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>76. 제58항 내지 제75항 중 어느 한 항에 있어서,상기 대상체는 상기 시도된 음성에 대해 지정된 단어 세트로 제한되는, 시스템.</claim></claimInfo><claimInfo><claim>77. 제76항에 있어서,상기 프로세서는 상기 단어 세트의 단어가 상기 대상체가 단어 세트의 모든 단어마다 상기 시도된 음성 중 생성하려고 시도한 의도된 단어일 확률을 계산하고, 상기 대상체가 시도된 음성 중 생성하려고 시도한 의도된 단어일 가장 높은 확률을 갖는 단어 세트의 단어를 선택하도록 추가로 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>78. 제76항 또는 제77항에 있어서,상기 단어 세트는 이다(am), 이다(are), 나쁜, 가져오다, 깨끗한, 가까운, 편안한, 오다, 컴퓨터, 하다, 믿음, 가족, 느끼다, 안경, 가다, 좋은, 안녕히 가세요, 갖다, 안녕하세요, 돕다, 여기, 바라다, 어떻게, 배고픈, 저는, 이다(is), 그것, 좋아하다, 음악, 저의, 필요하다, 아니요(no), 아니다(not), 간호사, 좋아요, 밖, 해주세요, 바로, 성공, 말하다, 저것, 그들, 목마른, 피곤한, 위, 매우, 무엇, 어디, 예 및 당신을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>79. 제76항 내지 제78항 중 어느 한 항에 있어서,상기 대상체는 상기 선택된 단어 세트의 단어들의 임의의 선택된 시퀀스를 사용할 수 있는, 시스템.</claim></claimInfo><claimInfo><claim>80. 제79항에 있어서,상기 프로세서는 단어의 시퀀스가 상기 시도된 음성 중 상기 대상체가 생성하려고 시도한 의도된 문장일 확률을 계산하도록 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>81. 제80항에 있어서,상기 프로세서는 가장 가능성 있는 문장 및 하나 이상의 가능성 적은 문장을 유지하고, 단어의 시퀀스가 각 단어의 디코딩 후에 상기 시도된 음성 중 상기 대상체가 생성하려고 시도한 의도된 문장일 확률을 재계산하도록 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>82. 제81항에 있어서,상기 가장 가능성 있는 문장 및 상기 하나 이상의 가능성 적은 문장은 상기 시도된 음성을 위해 상기 대상체에 의해 사용된 단어 세트로부터의 단어로만 구성되는, 시스템.</claim></claimInfo><claimInfo><claim>83. 제58항 내지 제82항 중 어느 한 항에 있어서,상기 프로세서는 상기 시도된 비음성 운동 동작과 연관된 상기 기록된 뇌 전기 신호 데이터 내의 전기 신호의 신경 활동 패턴 식별에 기초하여 상기 대상체에 의해 시도된 음성의 개시 또는 종료를 시그널링하는 상기 대상체의 시도된 비음성 운동 동작의 검출을 자동화하도록 추가로 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>84. 제83항에 있어서,상기 프로세서는 상기 시도된 비음성 운동 동작에 대한 이벤트 라벨을 상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 할당하도록 추가로 프로그래밍되는, 시스템.</claim></claimInfo><claimInfo><claim>85. 제58 내지 제84항 중 어느 한 항의 시스템 및 대상체에 의해 시도된 음성과 연관된 뇌 전기 신호 데이터를 기록 및 디코딩하기 위한 시스템을 사용하기 위한 명령어들을 포함하는, 키트.</claim></claimInfo><claimInfo><claim>86. 대상체의 의사소통을 보조하는 방법으로서, 상기 방법은:상기 대상체의 뇌의 감각운동 피질 영역(sensorimotor cortex region) 내의 위치에 전극을 포함하는 신경 기록 디바이스를 위치시켜, 상기 대상체에 의해 의도된 문장의 단어의 시도된 글자의 철자와 연관된 뇌 전기 신호 데이터를 기록하는 단계;상기 대상체의 머리 상의 위치에 컴퓨팅 디바이스와 통신하는 인터페이스를 위치시키는 단계로서, 상기 인터페이스는 신경 기록 디바이스에 연결되는 단계;신경 기록 디바이스를 사용하여 대상체에 의해 상기 시도된 철자와 연관된 뇌 전기 신호 데이터를 기록하는 단계로서, 상기 인터페이스는 신경 기록 디바이스로부터 뇌 전기 신호 데이터를 수신하고 뇌 전기 신호 데이터를 컴퓨팅 디바이스의 프로세서로 전송하는 단계; 및프로세서를 사용하여 상기 기록된 뇌 전기 신호 데이터로부터 상기 의도된 문장의 철자된 단어를 디코딩하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>87. 제86항에 있어서,상기 대상체는 관절염, 뇌졸중, 외상성 뇌손상, 뇌종양 또는 근위축성 측삭 경화증으로 인해 상기 의사소통이 어려운, 방법.</claim></claimInfo><claimInfo><claim>88. 제86항 또는 제87항에 있어서,상기 대상체는 마비되어있는, 방법.</claim></claimInfo><claimInfo><claim>89. 제86항 내지 제88항 중 어느 한 항에 있어서,상기 신경 기록 디바이스의 위치는 복측 감각운동 피질(ventral sensorimotor cortex) 내에 있는, 방법.</claim></claimInfo><claimInfo><claim>90. 제86항 내지 제89항 중 어느 한 항에 있어서,상기 전극은 상기 감각운동 피질 영역의 표면 상에 또는 상기 감각운동 피질 영역 내에 위치하는, 방법.</claim></claimInfo><claimInfo><claim>91. 제90항에 있어서,상기 전극은 경막하 공간에서 뇌의 감각운동 피질 영역의 표면에 위치하는, 방법.</claim></claimInfo><claimInfo><claim>92. 제86항 내지 제91항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌-침투 전극 어레이(brain-penetrating electrode array)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>93. 제86항 내지 제92항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌피질전도(ECoG) 전극 어레이를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>94. 제86항 내지 제93항 중 어느 한 항에 있어서,상기 전극은 심부 전극 또는 표면 전극인, 방법.</claim></claimInfo><claimInfo><claim>95. 제86항 내지 제94항 중 어느 한 항에 있어서,상기 전기 신호 데이터는 고감마 주파수 컨텐츠 특성 및 저주파수 컨텐츠 특성을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>96. 제95항에 있어서,상기 전기 신호 데이터는 70 Hz 내지 150 Hz의 고감마 주파수 범위 및 0.3 Hz 내지 100 Hz의 저주파수 범위에서의 신경 진동을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>97. 제86항 내지 제96항 중 어느 한 항에 있어서,상기 뇌 전기 신호 데이터를 기록하는 단계는, 중심전회(precentral gyrus) 영역, 중심후회(postcentral gyrus) 영역, 후중전두회(posterior middle frontal gyrus) 영역, 후상전두회(posterior superior frontal gyrus) 영역 또는 후하전두회(posterior inferior frontal gyrus) 영역, 또는 이들의 임의의 조합으로부터 선택된 감각운동 피질 영역으로부터 뇌 전기 신호 데이터를 기록하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>98. 제86항 내지 제97항 중 어느 한 항에 있어서,상기 대상체의 뇌를 매핑하여 상기 대상체에 의해 시도된 단어의 철자 또는 시도된 비음성 운동 동작과 연관된 상기 뇌 전기 신호를 기록하기 위해 상기 전극을 위치시키기 위한 최적의 위치를 식별하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>99. 제86항 내지 제98항 중 어느 한 항에 있어서,상기 인터페이스는 대상체의 두개골에 부착된 경피 페데스탈 커넥터(percutaneous pedestal connector)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>100. 제99항에 있어서,상기 인터페이스는 상기 경피 페데스탈 커넥터에 연결된 헤드스테이지를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>101. 제86항 내지 제100항 중 어느 한 항에 있어서,상기 프로세서는 컴퓨터 또는 핸드헬드 디바이스에 의해 제공되는, 방법.</claim></claimInfo><claimInfo><claim>102. 제101항에 있어서,상기 핸드헬드 디바이스는 휴대폰 또는 태블릿인, 방법.</claim></claimInfo><claimInfo><claim>103. 제86항 내지 제102항 중 어느 한 항에 있어서,상기 프로세서는 상기 대상체에 의해 시도된 단어의 철자와 연관된 상기 기록된 뇌 전기 신호 데이터 내의 전기 신호의 신경 활동 패턴 식별에 기초하여 시도된 철자, 글자 분류, 단어 분류 및 문장 디코딩의 검출을 자동화하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>104. 제103항에 있어서,상기 프로세서는 음성 검출, 글자 분류, 단어 분류 및 문장 디코딩을 위해 기계 학습 알고리즘을 사용하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>105. 제104항에 있어서,상기 프로세서는 상기 대상체에 의한 시도된 단어의 철자와 연관된 신경 활동에서 디코딩된 글자 시퀀스로부터의 단어 분류를 상기 대상체에 의해 사용된 언어의 어휘 내의 단어로만 제한하도록 추가로 프로그래밍된, 방법.</claim></claimInfo><claimInfo><claim>106. 제86항 내지 제105항 중 어느 한 항에 있어서,상기 프로세서는 준비, 시도된 철자 및 휴식에 대한 이벤트 라벨을 상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 할당하도록 추가로 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>107. 제106항에 있어서,상기 프로세서는 상기 대상체에 의해 시도된 글자의 철자의 검출된 온셋 무렵의 시간 윈도우 내에서 상기 기록된 뇌 전기 신호 데이터를 사용하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>108. 제86항 내지 제107항 중 어느 한 항에 있어서,상기 대상체가 상기 의도된 문장의 단어의 시도된 각각의 글자의 철자를 개시해야 하는 경우를 나타내는 일련의 시행 신호(go cue)를 상기 대상체에게 제공하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>109. 제108 항에 있어서,상기 일련의 시행 신호는 디스플레이 상에 시각적으로 제공되는, 방법.</claim></claimInfo><claimInfo><claim>110. 제109항에 있어서, 각 시행 신호는 상기 시행 신호의 제시에 대한 카운트다운이 선행되고, 다음 철자된 글자에 대한 카운트다운은 상기 디스플레이 상에 시각적으로 제공되고 각 시행 신호 이후에 자동으로 시작되는, 방법.</claim></claimInfo><claimInfo><claim>111. 제108항 내지 제110항 중 어느 한 항에 있어서, 상기 일련의 시행 신호는 각 시행 신호 사이에 설정된 시간 간격이 제공되는, 방법.</claim></claimInfo><claimInfo><claim>112. 제111항에 있어서,상기 대상체는 각 시행 신호 사이에 설정된 시간 간격을 제어할 수 있는, 방법.</claim></claimInfo><claimInfo><claim>113. 제108항 내지 제112항 중 어느 한 항에 있어서,상기 프로세서는 상기 시행 신호 다음의 시간 윈도우 내에서 상기 기록된 뇌 전기 신호 데이터를 사용하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>114. 제86항 내지 제113항 중 어느 한 항에 있어서,상기 프로세서는 디코딩된 글자의 시퀀스로부터의 디코딩된 단어의 시퀀스가 상기 대상체가 상기 대상체에 의해 의도된 문장의 단어의 시도된 글자의 철자 중 생성하려한 의도된 문장일 확률을 계산하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>115. 제86항 내지 제114항 중 어느 한 항에 있어서,상기 프로세서는 예측된 단어 시퀀스 확률을 결정함으로써 디코딩을 돕기 위해 단어의 시퀀스 내의 이전 단어 또는 어구를 고려하여 다음 단어 확률을 제공하는 언어 모델을 사용하도록 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>116. 제115항에 있어서,더 빈번하게 발생하는 단어에는 상기 언어 모델에 따라 덜 빈번하게 발생하는 단어보다 더 많은 가중치가 할당되는, 방법.</claim></claimInfo><claimInfo><claim>117. 제86항 내지 제116항 중 어느 한 항에 있어서,상기 프로세서는 예측된 글자 확률의 시퀀스를 사용하여 잠재적 문장 후보를 계산하고 상기 문장 후보 내의 예측된 단어 사이의 글자 시퀀스에 공백을 자동으로 삽입하도록 추가로 프로그래밍되는, 방법.</claim></claimInfo><claimInfo><claim>118. 제86항 내지 제117항 중 어느 한 항에 있어서,상기 대상체의 시도된 비음성 운동 동작과 연관된 뇌 전기 신호 데이터를 기록하는 단계로서, 상기 대상체는 의도된 문장의 단어의 시도된 철자의 개시 또는 종료를 나타내거나 외부 디바이스를 제어하기 위해 시도된 비음성 운동 동작을 수행하는 단계; 및 상기 시도된 비음성 운동 동작과 연관된 상기 기록된 뇌 전기 신호 데이터에서 전기 신호의 패턴을 식별하고 상기 대상체가 비음성 운동 동작을 시도했을 확률을 계산하는 분류 모델을 사용하여 뇌 전기 신호 데이터를 분석하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>119. 제118항에 있어서,상기 시도된 비음성 운동 동작은 시도된 머리, 팔, 손, 발 또는 다리 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>120. 제119항에 있어서,상기 시도된 손 동작은 상상된 손 제스처 또는 상상된 손 스퀴즈(squeeze)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>121. 제118항 내지 제120항 중 어느 한 항에 있어서,상기 뇌 전기 신호 데이터를 기록하는 동안의 시점에 상기 시도된 비음성 운동 동작에 대한 이벤트 라벨을 할당하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>122. 제86항 내지 제121항 중 어느 한 항에 있어서,디코딩의 정확도를 평가하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>123. 제86항 내지 제122항 중 어느 한 항에 있어서,상기 신경 기록 디바이스를 사용하여 상기 대상체에 의해 시도된 음성과 연관된 뇌 전기 신호 데이터를 기록하는 단계로서, 상기 인터페이스는 상기 신경 기록 디바이스로부터 상기 뇌 전기 신호 데이터를 수신하고, 상기 뇌 전기 신호 데이터를 상기 컴퓨팅 디바이스의 프로세서로 전송하는 단계; 및 상기 프로세서를 사용하여 상기 대상체에 의해 시도된 음성과 연관된 상기 기록된 뇌 전기 신호 데이터로부터 단어, 어구 또는 문장을 디코딩하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>124. 대상체에 의한 의도된 문장의 단어의 시도된 글자의 철자와 연관된 기록된 뇌 전기 신호 데이터로부터 문장을 디코딩하기 위한 컴퓨터 구현 방법으로서, 상기 컴퓨터는:상기 대상체에 의해 의도된 문장의 단어의 시도된 글자의 철자와 연관된 상기 기록된 뇌 전기 신호 데이터를 수신하는 단계;음성 검출 모델을 사용하여 상기 기록된 뇌 전기 신호 데이터를 분석하여 상기 뇌 전기 신호 데이터를 기록하는 동안 임의의 시점에서 시도된 철자가 발생할 확률을 계산하고, 상기 대상체에 의해 시도된 철자 중 글자 생성의 온셋 및 오프셋을 검출하는 단계;상기 대상체에 의해 시도된 글자 생성과 연관된 상기 기록된 뇌 전기 신호 데이터에서 전기 신호의 패턴을 식별하고 예측된 글자 확률의 시퀀스를 계산하는 글자 분류 모델을 사용하여 상기 뇌 전기 신호 데이터를 분석하는 단계;상기 예측된 글자 확률의 시퀀스에 기초하여 잠재적 문장 후보를 계산하고, 상기 문장 후보 내의 예측된 단어 사이의 글자 시퀀스에 공백을 자동으로 삽입하는 단계로서, 상기 글자 시퀀스 내의 디코딩된 단어는 상기 대상체에 의해 사용되는 언어의 어휘 내의 단어로만 제한되는 단계;단어의 시퀀스 내의 이전 단어 또는 어구를 고려하여 다음 단어 확률을 제공하는 언어 모델을 사용하는 잠재적 문장 후보를 분석하여 예측된 단어 문장 확률을 계산하고, 문장 내의 단어의 가장 가능성 있는 시퀀스를 결정하는 단계; 및상기 기록된 뇌 전기 신호 데이터로부터 디코딩된 문장을 표시하는 단계를 수행하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>125. 제124항에 있어서,상기 기록된 뇌 전기 신호 데이터는 상기 대상체에 의해 시도된 글자의 철자의 검출된 온셋 무렵의 시간 윈도우 내에서만 사용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>126. 제124항 또는 제125항에 있어서,상기 대상체가 상기 의도된 문장의 단어의 시도된 각각의 글자의 철자를 언제 시도해야 하는지를 나타내는 일련의 시행 신호를 상기 대상체에게 표시하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>127. 제126 항에 있어서,각 시행 신호는 상기 시행 신호의 제시에 대한 카운트다운을 표시하는 것에 의해 선행되며, 다음 철자된 글자를 위한 카운트다운은 각 실행 이후에 자동으로 시작되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>128. 제126항 또는 제127항에 있어서,상기 일련의 시행 신호는 각 시행 신호 사이에 설정된 시간 간격이 제공되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>129. 제128항에 있어서,상기 대상체는 각 시행 신호 사이에 설정된 시간 간격을 제어할 수 있는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>130. 제122항 내지 제127항 중 어느 한 항에 있어서,상기 시행 신호 다음의 시간 윈도우 내의 기록된 뇌 전기 신호 데이터는 글자 분류를 위해 사용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>131. 제124항 내지 제130항 중 어느 한 항에 있어서,상기 대상체의 시도된 비음성 운동 동작과 연관된 기록된 뇌 전기 신호 데이터를 수신하는 단계로서, 상기 대상체는 의도된 문장의 단어의 시도된 철자의 개시 또는 종료를 나타내거나 외부 디바이스를 제어하기 위해 시도된 비음성 운동 동작을 수행하는 단계; 및상기 시도된 비음성 운동 동작과 연관된 상기 기록된 뇌 전기 신호 데이터에서 전기 신호의 패턴을 식별하고 상기 대상체가 비음성 운동 동작을 시도했을 확률을 계산하는 분류 모델을 사용하여 뇌 전기 신호 데이터를 분석하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>132. 제131항에 있어서,상기 시도된 비음성 운동 동작은 시도된 머리, 팔, 손, 발 또는 다리 동작을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>133. 제132항에 있어서,상기 시도된 손 동작은 상상된 손 제스처 또는 상상된 손 스퀴즈(squeeze)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>134. 제124항 내지 제133항 중 어느 한 항에 있어서,기계 학습 알고리즘은 시도된 철자 또는 시도된 비음성 운동 동작 또는 글자 분류를 위해 사용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>135. 제124항 내지 제134항 중 어느 한 항에 있어서,상기 언어 모델에 따라 덜 빈번하게 발생하는 단어보다 더 빈번하게 발생하는 단어에 더 많은 가중치를 할당하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>136. 제124항 내지 제135항 중 어느 한 항에 있어서,상기 대상체에 의해 시도된 철자 중 글자 생성과 연관된 상기 기록된 뇌 전기 신호 데이터 내의 전기 신호의 패턴에 관한 정보를 포함하는 상기 대상체에 대한 사용자 프로파일을 저장하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>137. 제124항 내지 제136항 중 어느 한 항에 있어서,상기 전기 신호 데이터는 고감마 주파수 컨텐츠 특성 및 저주파수 컨텐츠 특성을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>138.  제137항에 있어서,상기 전기 신호 데이터는 70 Hz 내지 150 Hz의 고감마 주파수 범위 및 0.3 Hz 내지 100 Hz의 저주파수 범위에서의 신경 진동을 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>139. 제124항 내지 제138항 중 어느 한 항에 있어서,디코딩의 정확도를 평가하는 단계를 더 포함하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>140. 제124항 내지 제139항 중 어느 한 항에 있어서,상기 대상체에 의해 시도된 음성과 연관된 기록된 뇌 전기 신호 데이터로부터 문장을 디코딩하는 단계를 더 포함하고, 상기 컴퓨터는:상기 대상체에 의해 시도된 음성과 연관된 상기 기록된 뇌 전기 신호 데이터를 수신하는 단계;음성 검출 모델을 사용하여 상기 기록된 뇌 전기 신호 데이터를 분석하여 상기 시도된 음성이 임의의 시점에 발생할 확률을 계산하고, 상기 대상체에 의해 시도된 음성 중 단어 생성의 온셋 및 오프셋을 검출하는 단계;상기 대상체에 의해 시도된 단어 생성과 연관된 상기 기록된 뇌 전기 신호 데이터에서 전기 신호의 패턴을 식별하고 예측된 단어 확률을 계산하는 단어 분류 모델을 사용하여 상기 뇌 전기 신호 데이터를 분석하는 단계;단어의 시퀀스에서 이전 단어 또는 어구를 고려하여 다음 단어 확률을 제공하는 언어 모델을 사용하여 단어 분류 모델로부터의 계산된 단어 확률을 문장 내의 예측된 단어 시퀀스 확률과 조합하여 사용함으로써 문장 디코딩을 수행하여 예측 단어 시퀀스 확률을 계산하고, 단어 분류 모델 및 언어 모델을 사용하여 결정된 예측된 단어 확률에 기초하여 문장 내의 가장 가능성 있는 단어의 시퀀스를 결정하는 단계; 및상기 기록된 뇌 전기 신호 데이터로부터 디코딩된 문장을 표시하는 단계를 수행하는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>141. 제140항에 있어서,기계 학습 알고리즘은 음성 검출, 단어 분류 및 문장 디코딩을 위해 사용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>142. 제141항에 있어서,상기 음성 검출 및 상기 단어 분류를 위해 인공 신경망(ANN) 모델이 이용되고, 문장 디코딩을 위해 은닉 마르코프 모델(HMM), 비터비(Viterbi) 디코딩 모델 또는 자연어 처리 기법이 이용되는, 컴퓨터 구현 방법.</claim></claimInfo><claimInfo><claim>143. 컴퓨터 내의 프로세서에 의해 실행될 때, 상기 프로세서로 하여금 제124항 내지 제142항 중 어느 한 항의 방법을 수행하게 하는 프로그램 명령어들을 포함하는, 비일시적 컴퓨터 판독가능 매체.</claim></claimInfo><claimInfo><claim>144. 제143항의 비일시적 컴퓨터 판독가능 매체 및 대상체에 의해 의도된 문장의 단어의 시도된 글자의 철자와 연관된 뇌 전기 신호 데이터를 디코딩하기 위한 명령어들을 포함하는, 키트.</claim></claimInfo><claimInfo><claim>145. 대상체의 의사소통을 보조하는 시스템에 있어서, 상기 시스템은:상기 대상체의 뇌의 감각운동 피질 영역(sensorimotor cortex region) 내의 위치에 위치하여 상기 대상체에 의해 시도된 음성, 의도된 문장의 단어의 시도된 글자의 철자 또는 시도된 비음성 운동 동작, 또는 이들의 조합과 연관된 뇌 전기 신호 데이터를 기록하도록 구성된 전극을 포함하는 신경 기록 디바이스;제124항 내지 제142항 중 어느 한 항의 컴퓨터 구현 방법에 따른 상기 기록된 뇌 전기 신호 데이터로부터 문장을 디코딩하도록 프로그래밍된 프로세서;컴퓨팅 디바이스와 통신하는 인터페이스로서, 상기 인터페이스는 상기 대상체의 머리 상의 위치에 위치되도록 구성되고, 상기 인터페이스는 상기 신경 기록 디바이스로부터 상기 뇌 전기 신호 데이터를 수신하고 상기 뇌 전기 신호 데이터를 상기 프로세서로 전송하는, 인터페이스; 및상기 기록된 뇌 전기 신호 데이터로부터 디코딩된 문장을 표시하기 위한 디스플레이 컴포넌트를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>146. 제145항에 있어서,상기 대상체는 관절염, 뇌졸중, 외상성 뇌손상, 뇌종양 또는 근위축성 측삭 경화증으로 인해 상기 의사소통에 어려움을 겪는, 시스템.</claim></claimInfo><claimInfo><claim>147. 제145항 또는 제146항에 있어서,상기 신경 기록 디바이스의 위치는 복측 감각운동 피질(ventral sensorimotor cortex) 내에 있는, 시스템.</claim></claimInfo><claimInfo><claim>148. 제145항 내지 제147항 중 어느 한 항에 있어서,상기 전극은 감각운동 피질 영역의 표면 상에 또는 감각운동 피질 영역 내에 위치하도록 구성된, 시스템.</claim></claimInfo><claimInfo><claim>149. 제148항에 있어서,상기 전극은 경막하 공간에서 뇌의 감각운동 피질 영역의 표면에 위치하도록 구성된, 시스템.</claim></claimInfo><claimInfo><claim>150. 제145항 내지 제149항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌-침투 전극 어레이를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>151. 제145항 내지 제150항 중 어느 한 항에 있어서,상기 신경 기록 디바이스는 뇌피질전도(ECoG) 전극 어레이를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>152. 제145항 내지 제151항 중 어느 한 항에 있어서,상기 전극은 심부 전극 또는 표면 전극인, 시스템.</claim></claimInfo><claimInfo><claim>153. 제145항 내지 제152항 중 어느 한 항에 있어서,상기 전기 신호 데이터는 고감마 주파수 컨텐츠 특성 및 저주파수 컨텐츠 특성을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>154. 제153항에 있어서,상기 전기 신호 데이터는 70 Hz 내지 150 Hz의 고감마 주파수 범위 및 0.3 Hz 내지 100 Hz의 저주파수 범위에서의 신경 진동을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>155. 제145항 내지 제154항 중 어느 한 항에 있어서,상기 인터페이스는 대상체의 두개골에 부착된 경피 페데스탈 커넥터(percutaneous pedestal connector)를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>156. 제155항에 있어서,상기 인터페이스는 상기 경피 페데스탈 커넥터에 연결 가능한 헤드스테이지를 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>157. 제145항 내지 제156항 중 어느 한 항에 있어서,상기 프로세서는 컴퓨터 또는 핸드헬드 디바이스에 의해 제공되는, 시스템.</claim></claimInfo><claimInfo><claim>158. 제157항에 있어서,상기 핸드헬드 디바이스는 휴대폰 또는 태블릿인, 시스템.</claim></claimInfo><claimInfo><claim>159. 제145항 내지 제158항 중 어느 한 항의 시스템 및 대상체에 의해 시도된 음성, 시도된 단어의 철자 또는 시도된 비음성 운동 동작, 또는 이들의 조합과 연관된 뇌 전기 신호 데이터를 기록 및 디코딩하기 위한 시스템을 사용하기 위한 명령어들을 포함하는, 키트.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 캘리포니아주 *****-**** 프랭클린 스트리트 ****  **층</address><code>519986039914</code><country>미국</country><engName>THE REGENTS OF THE UNIVERSITY OF CALIFORNIA</engName><name>더 리전츠 오브 더 유니버시티 오브 캘리포니아</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아 ***** 샌프란시스코 스위트 에...</address><code> </code><country> </country><engName>MOSES, David</engName><name>모세, 데이비드</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 샌프란시스코 스위트 에...</address><code> </code><country> </country><engName>LIU, Jessie</engName><name>리우, 제시</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 샌프란시스코 스위트 에...</address><code> </code><country> </country><engName>METZGER, Sean</engName><name>메츠거, 션</name></inventorInfo><inventorInfo><address>미국 캘리포니아 ***** 샌프란시스코 스위트 에...</address><code> </code><country> </country><engName>CHANG, Edward</engName><name>창, 에드워드</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, **층 유니스특허법률사무소 (역삼동, 윤익빌딩)</address><code>919980003768</code><country>대한민국</country><engName>YOON, Eui Seoup</engName><name>윤의섭</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.05.26</priorityApplicationDate><priorityApplicationNumber>63/193,351</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2023.12.18</receiptDate><receiptNumber>1-1-2023-1418461-82</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[New Translation under Article 201 of Patent Act or Article 35 of Utility Model Act] Submission of Document</documentEngName><documentName>[특허법 제201조 또는 실용신안법 제35조에 따른 새로운 번역문]서류제출서</documentName><receiptDate>2024.01.18</receiptDate><receiptNumber>1-1-2024-0070737-26</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.01.29</receiptDate><receiptNumber>1-5-2024-0018726-19</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.05.22</receiptDate><receiptNumber>1-1-2025-0574899-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020237043726.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938a9faaabce11cc38151a3722b069ee49e973d122bf2e988772fc6b53b8731b032beec68c855e7839f431e9e7db872ce2efbbdda9e42f4e3c</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf3463920a7aeaf27f518d15e6392e8c8c60f7e2b4d617e13fe90d3d04fc5d48c8b35f228ecef1b5e4ec65af3447d5ac81931f9fa413a132eb</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>