<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:53.553</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.11.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0170030</applicationNumber><claimCount>22</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 장치 및 그 동작 방법</inventionTitle><inventionTitleEng>AUGMENTED REALITY DEVICE AND METHOD OF OPERATION  THEREOF</inventionTitleEng><openDate>2024.12.10</openDate><openNumber>10-2024-0173143</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G06F 3/0354</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04842</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G02B 27/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/041</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 증강 현실 장치가 카메라를 통해 획득한 제1 객체의 이미지에 기초하여 동작하는 방법을 제공한다. 방법은 이미지로부터 제1 객체를 식별하는 단계를 포함할 수 있다. 방법은 사용자가 제1 객체를 파지하는 파지 위치를 식별하는 단계를 포함할 수 있다. 방법은 식별된 파지 위치에 기초하여 대응되는 동작을 수행하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 증강 현실 장치(100)가 카메라를 통해 획득한 제1 객체(10)의 이미지에 기초하여 동작하는 방법에 있어서,이미지로부터 제1 객체(10)를 식별하는 단계;사용자가 상기 제1 객체(10)를 파지하는 파지 위치를 식별하는 단계;상기 식별된 파지 위치에 기초하여 대응되는 동작을 수행하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 파지 위치를 식별하는 단계는,상기 이미지로부터 적어도 하나의 특징점(feature point)을 검출하는 단계;상기 검출된 적어도 하나의 특징점에 기초하여 상기 사용자의 손을 식별하는 단계; 및상기 사용자의 손의 위치 및 상기 제1 객체(10)의 위치에 기초하여 상기 파지 위치를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 제1 객체(10)의 전체 길이 영역은 퍼센트(percent, %) 구간별로 구분되어 각각 증강 현실 장치(100)의 서로 다른 동작에 대응되는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 또는 제2항에 있어서,상기 제1 객체(10)는 기 설정된 구간별로 구분되어 각각 증강 현실 장치(100)의 서로 다른 동작에 대응되는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,가상 영상을 통해 상기 사용자에게 파지 위치 별로 대응되는 동작 유형에 대한 가이드(guide)를 제공하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,상기 사용자가 상기 제1 객체(10)에 접촉하는 영역이 복수인 경우, 상기 파지 위치를 식별하는 단계는;상기 복수의 접촉 영역들 중 우선 순위가 가장 높은 접촉 영역을 식별하는 단계; 및상기 우선 순위가 가장 높은 접촉 영역에 기초하여 상기 파지 위치를 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 제1 객체(10)의 회전을 식별하는 단계를 더 포함하고,상기 식별된 파지 위치에 기초하여 대응되는 동작을 수행하는 단계는, 상기 식별된 회전에 더 기초하는 것인, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 제1 객체(10)의 회전을 식별하는 단계는,상기 제1 객체(10)의 회전이 개시되는 제1 시점을 식별하는 단계;상기 제1 시점으로부터 현재 시점까지의 누적 운동량을 계산하는 단계; 및상기 누적 운동량에 기초하여 상기 회전을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 제1 시점은 시간당 운동량이 기 설정된 임계값보다 크거나 같은 연속된 시간 중 가장 빠른 시점으로 결정되는, 방법.</claim></claimInfo><claimInfo><claim>10. 제7항 내지 제9항 중 어느 한 항에 있어서,상기 제1 객체(10)는 터치 센서 또는 회전 감지 센서를 포함하고,상기 제1 객체(10)의 회전을 식별하는 단계는,상기 제1 객체(10)로부터 센싱 정보를 획득하는 단계; 및상기 획득된 센싱 정보에 기초하여 상기 회전을 결정하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서,상기 수행되는 동작에 대응되는 사용자 인터페이스(user interface, UI)를 디스플레이하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 카메라를 통해 획득한 제1 객체(10)의 이미지에 기초하여 동작하는 증강 현실 장치(100)에 있어서,현실 장면 이미지(real-world scene)를 획득하도록 구성되는 카메라(120);디스플레이부(162);적어도 하나의 명령어(instruction)를 포함하는 프로그램을 저장하는 메모리(150); 및적어도 하나의 프로세서(140)를 포함하고,상기 적어도 하나의 프로세서(140)는,이미지로부터 제1 객체(10)를 식별하고,사용자가 상기 제1 객체(10)를 파지하는 파지 위치를 식별하고,상기 식별된 파지 위치에 기초하여 대응되는 동작을 수행하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 이미지로부터 적어도 하나의 특징점(feature point)을 검출하고,상기 검출된 적어도 하나의 특징점에 기초하여 상기 사용자의 손을 식별하고,상기 사용자의 손의 위치 및 상기 제1 객체(10)의 위치에 기초하여 상기 파지 위치를 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>14. 제12항 또는 제13항에 있어서,상기 제1 객체(10)의 전체 길이 영역은 퍼센트(percent, %) 구간별로 구분되어 각각 증강 현실 장치(100)의 서로 다른 동작에 대응되는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>15. 제12항 또는 제13항에 있어서,상기 제1 객체(10)는 기 설정된 구간별로 구분되어 각각 증강 현실 장치(100)의 서로 다른 동작에 대응되는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>16. 제12항 내지 제15항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,가상 영상을 통해 상기 사용자에게 파지 위치 별로 대응되는 동작 유형에 대한 가이드(guide)를 제공하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>17. 제12항 내지 제16항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 사용자가 상기 제1 객체(10)에 접촉하는 영역이 복수인 경우, 상기 복수의 접촉 영역들 중 우선 순위가 가장 높은 접촉 영역을 식별하고, 상기 우선 순위가 가장 높은 접촉 영역에 기초하여 상기 파지 위치를 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>18. 제12항 내지 제17항 중 어느 한 항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 제1 객체(10)의 회전을 식별하고,상기 식별된 파지 위치 및 회전에 기초하여 대응되는 동작을 수행하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 적어도 하나의 프로세서(140)는,상기 제1 객체(10)의 회전이 개시되는 제1 시점을 식별하고,상기 제1 시점으로부터 현재 시점까지의 누적 운동량을 계산하고,상기 누적 운동량에 기초하여 상기 회전을 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>20. 제19항에 있어서,상기 적어도 하나의 프로세서(140)는,시간당 운동량이 기 설정된 임계값보다 크거나 같은 연속된 시간 중 가장 빠른 시점을 상기 제1 시점으로 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>21. 제18항 내지 제20항 중 어느 한 항에 있어서,상기 제1 객체(10)는 터치 센서 또는 회전 감지 센서를 포함하고,상기 적어도 하나의 프로세서(140)는,상기 제1 객체(10)로부터 센싱 정보를 획득하고,상기 획득된 센싱 정보에 기초하여 상기 회전을 결정하는, 증강 현실 장치(100).</claim></claimInfo><claimInfo><claim>22. 제1항 내지 제11항 중 어느 한 항의 방법을 컴퓨터에서 수행하기 위한 프로그램이 기록된 컴퓨터로 읽을 수 있는 기록매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>GO, Eun Jeong</engName><name>고은정</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>KWON, Tae Hyuk</engName><name>권태혁</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>JI, Seo Won</engName><name>지서원</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.06.02</priorityApplicationDate><priorityApplicationNumber>1020230071852</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.11.29</receiptDate><receiptNumber>1-1-2023-1338748-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230170030.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93c77104924888ba895126d1ad8b7485f8d77379f492dbc690dc0ae33f3266f664a0275e440fdeefa561a77a5f7ffb90f52576f2ee60b10cb6</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf5d2dd6f4b82256526c53857249964e1cc54629d373c536c55ba2301ccd7070ab27ab021b9bfc4025d1b10245b1f4e6079d174df458959137</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>