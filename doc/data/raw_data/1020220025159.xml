<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:40.540</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.02.25</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0025159</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>인식 모델의 트레이닝 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR TRAINING RECOGNITION MODEL</inventionTitleEng><openDate>2023.05.12</openDate><openNumber>10-2023-0065863</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.02.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06F 18/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 인식 모델의 트레이닝 방법 및 장치가 개시된다. 일 실시예에 따르면, 트레이닝 방법은 입력 트레이닝 영상에 관한 데이터 증강을 수행하여 제1 샘플 영상 및 제2 샘플 영상을 생성하고, 인코딩 모델을 통해 제1 샘플 영상 및 제2 샘플 영상의 특징 추출을 수행하여 제1 샘플 영상의 제1 특징 맵 및 제2 샘플 영상의 제2 특징 맵을 생성하고, 제1 특징 맵의 제1 특징 벡터들 및 제2 특징 맵의 제2 특징 벡터들의 관계에 따른 제1 손실 데이터를 결정하고, 관계 추정 모델을 통해 제1 특징 맵 및 제2 특징 맵의 상대 기하 정보를 추정하고, 입력 트레이닝 영상 내의 제1 샘플 영상 및 제2 샘플 영상의 기하학적인 배치에 따른 레이블 데이터에 기초하여 상대 기하 정보에 따른 제2 손실 데이터를 결정하고, 제1 손실 데이터 및 제2 손실 데이터에 기초하여 인코딩 모델 및 관계 추정 모델을 트레이닝하는 단계들을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 트레이닝 영상에 관한 데이터 증강을 수행하여 제1 샘플 영상 및 제2 샘플 영상을 생성하는 단계;인코딩 모델을 통해 상기 제1 샘플 영상 및 상기 제2 샘플 영상의 특징 추출을 수행하여 상기 제1 샘플 영상의 제1 특징 맵 및 상기 제2 샘플 영상의 제2 특징 맵을 생성하는 단계;상기 제1 특징 맵의 제1 특징 벡터들 및 상기 제2 특징 맵의 제2 특징 벡터들의 관계에 따른 제1 손실 데이터를 결정하는 단계;관계 추정 모델을 통해 상기 제1 특징 맵 및 상기 제2 특징 맵의 상대 기하 정보를 추정하는 단계;상기 입력 트레이닝 영상 내의 상기 제1 샘플 영상 및 상기 제2 샘플 영상의 기하학적인 배치에 따른 레이블 데이터에 기초하여 상기 상대 기하 정보에 따른 제2 손실 데이터를 결정하는 단계; 및상기 제1 손실 데이터 및 상기 제2 손실 데이터에 기초하여 상기 인코딩 모델 및 상기 관계 추정 모델을 트레이닝하는 단계를 포함하는 트레이닝 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 손실 데이터를 결정하는 단계는상기 제1 특징 벡터들 및 상기 제2 특징 벡터들 중에 상기 제1 샘플 영상과 상기 제2 샘플 영상의 중첩 영역에 대응하는 중첩 특징 벡터들을 선택하는 단계; 및상기 중첩 특징 벡터들 간의 차이에 기초하여 상기 제1 손실 데이터를 결정하는 단계를 포함하는, 트레이닝 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 상대 기하 정보는상기 제1 특징 벡터들 및 상기 제2 특징 벡터들에 따른 대응 격자 셀들의 상기 입력 트레이닝 영상 내 상대 위치 정보, 및 상기 제1 특징 맵 및 상기 제2 특징 맵에 따른 대응 영상들의 상대 스케일 정보 중 적어도 일부를 포함하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 상대 위치 정보는상기 대응 그리들 셀들 간의 오프셋을 x-축 성분 및 y-축 성분으로 특정하고,상기 상대 스케일 정보는상기 대응 영상들의 스케일 비율을 폭 성분 및 높이 성분으로 특정하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>5. 제3항에 있어서,상기 레이블 데이터는상기 제1 샘플 영상 및 상기 제2 샘플 영상의 격자 셀들에 따른 상기 상대 위치 정보의 레이블 데이터, 및 상기 제1 샘플 영상 및 상기 제2 샘플 영상에 따른 상기 상대 스케일 정보의 레이블 데이터 중 적어도 일부를 포함하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 상대 기하 정보는상기 제1 특징 맵 및 상기 제2 특징 맵에 따른 대응 영상들의 중첩 영역을 나타내는 마스크 정보를 포함하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 레이블 데이터는상기 제1 샘플 영상 및 상기 제2 샘플 영상에 따른 상기 마스크 정보의 레이블 데이터를 포함하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 레이블 데이터는상기 제1 샘플 영상 및 상기 제2 샘플 영상의 상기 기하학적인 배치에 따라 결정되고,상기 제2 손실 데이터를 결정하는 단계는상기 레이블 데이터와 상기 상대 기하 정보 간의 차이에 기초하여 상기 제2 손실 데이터를 결정하는 단계를 포함하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 인코딩 모델 및 상기 관계 추정 모델은 뉴럴 네트워크 모델에 해당하는,트레이닝 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 상대 기하 정보를 추정하는 단계는상기 제1 특징 맵 및 상기 제2 특징 맵을 연쇄화(concatenation)하여 입력 데이터를 결정하는 단계; 및상기 입력 데이터에 따른 컨볼루션 연산을 수행하여 상기 상대 기하 정보를 추정하는 단계를 포함하는, 트레이닝 방법.</claim></claimInfo><claimInfo><claim>11. 하드웨어와 결합되어 제1항 내지 제10항 중 어느 하나의 항의 방법을 실행시키기 위하여 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 프로세서; 및상기 프로세서에서 실행가능한 명령어들을 포함하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에서 실행되면, 상기 프로세서는입력 트레이닝 영상에 관한 데이터 증강을 수행하여 제1 샘플 영상 및 제2 샘플 영상을 생성하고,인코딩 모델을 통해 상기 제1 샘플 영상 및 상기 제2 샘플 영상의 특징 추출을 수행하여 상기 제1 샘플 영상의 제1 특징 맵 및 상기 제2 샘플 영상의 제2 특징 맵을 생성하고,상기 제1 특징 맵의 제1 특징 벡터들 및 상기 제2 특징 맵의 제2 특징 벡터들의 관계에 따른 제1 손실 데이터를 결정하고,관계 추정 모델을 통해 상기 제1 특징 맵 및 상기 제2 특징 맵의 상대 기하 정보를 추정하고,상기 입력 트레이닝 영상 내의 상기 제1 샘플 영상 및 상기 제2 샘플 영상의 기하학적인 배치에 따른 레이블 데이터에 기초하여 상기 상대 기하 정보에 따른 제2 손실 데이터를 결정하고,상기 제1 손실 데이터 및 상기 제2 손실 데이터에 기초하여 상기 인코딩 모델 및 상기 관계 추정 모델을 트레이닝하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 프로세서는상기 제1 특징 벡터들 및 상기 제2 특징 벡터들 중에 상기 제1 샘플 영상과 상기 제2 샘플 영상의 중첩 영역에 대응하는 중첩 특징 벡터들을 선택하고,상기 중첩 특징 벡터들 간의 차이에 기초하여 상기 제1 손실 데이터를 결정하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>14. 제12항에 있어서,상기 상대 기하 정보는상기 제1 특징 벡터들 및 상기 제2 특징 벡터들에 따른 대응 격자 셀들의 상기 입력 트레이닝 영상 내 상대 위치 정보, 및 상기 제1 특징 맵 및 상기 제2 특징 맵에 따른 대응 영상들의 상대 스케일 정보 중 적어도 일부를 포함하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 레이블 데이터는상기 제1 샘플 영상 및 상기 제2 샘플 영상의 격자 셀들에 따른 상기 상대 위치 정보의 레이블 데이터, 및 상기 제1 샘플 영상 및 상기 제2 샘플 영상에 따른 상기 상대 스케일 정보의 레이블 데이터를 포함하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>16. 제12항에 있어서,상기 상대 기하 정보는상기 제1 특징 맵 및 상기 제2 특징 맵에 따른 대응 영상들의 중첩 영역을 나타내는 마스크 정보를 포함하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 레이블 데이터는상기 제1 샘플 영상 및 상기 제2 샘플 영상에 따른 상기 마스크 정보의 레이블 데이터를 포함하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>18. 제12항에 있어서,상기 레이블 데이터는상기 제1 샘플 영상 및 상기 제2 샘플 영상의 상기 기하학적인 배치에 따라 결정되고,상기 프로세서는상기 레이블 데이터와 상기 상대 기하 정보 간의 차이에 기초하여 상기 제2 손실 데이터를 결정하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>19. 제12항에 있어서,상기 인코딩 모델 및 상기 관계 추정 모델은 뉴럴 네트워크 모델에 해당하는,트레이닝 장치.</claim></claimInfo><claimInfo><claim>20. 제12항에 있어서,상기 프로세서는상기 제1 특징 맵 및 상기 제2 특징 맵을 연쇄화(concatenation)하여 입력 데이터를 결정하고,상기 입력 데이터에 따른 컨볼루션 연산을 수행하여 상기 상대 기하 정보를 추정하는,트레이닝 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420180459477</code><country>대한민국</country><engName>LEE, HUI JIN</engName><name>이희진</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>Wissam Baddar</engName><name>바다르위삼</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code>420170474452</code><country>대한민국</country><engName>KO, MIN SU</engName><name>고민수</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code>420190080505</code><country>대한민국</country><engName>SUH, Sung Joo</engName><name>서성주</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2021.11.05</priorityApplicationDate><priorityApplicationNumber>1020210151298</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.02.25</receiptDate><receiptNumber>1-1-2022-0216344-08</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.02.20</receiptDate><receiptNumber>1-1-2025-0200832-62</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220025159.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93248f2995ab0a14ea7607353cfbc06515dd216481afec0517a73608718ffac15c4182fca36dd0ffd2d19d36f9678133302f982d2ea8a231f8</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa0cf375c17a85c4c308bee4317d447c34751e1eeaddbb127fbaa73e3777553e4b7e0b0257d85af99adb47cfdda96ee9b3d68b1f1e0d9226b</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>