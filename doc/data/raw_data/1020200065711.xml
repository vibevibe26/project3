<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:34:17.3417</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.06.01</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0065711</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>시간적 주의에 기초한 비디오 깊이 추정</inventionTitle><inventionTitleEng>VIDEO DEPTH ESTIMATION BASED ON TEMPORAL  ATTENTION</inventionTitleEng><openDate>2021.02.01</openDate><openNumber>10-2021-0011322</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.05.31</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/194</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/90</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 복수의 비디오 프레임에 기초한 깊이 검출 방법은 상이한 캡처 시간들에 각각 대응하는 제1 입력 프레임, 제2 입력 프레임 및 제3 입력 프레임을 포함하는 복수의 입력 프레임을 수신하고; 상기 상이한 캡처 시간들에 대응하는 제1 특징 맵, 제2 특징 맵 및 제3 특징 맵을 생성하기 위해 상기 제1 내지 제3 입력 프레임을 컨볼루션(convolving)하고, 상기 제1 내지 제3 특징 맵에 기초하여 시간적 주의 맵을 계산하고, 상기 시간적 주의 맵은 상기 제1 내지 제3 특징 맵 중에서 서로 상이한 특징 맵들의 쌍에 대응하는 복수의 가중치를 포함하며, 상기 복수의 가중치의 각각의 가중치는 대응하는 특징 맵들의 쌍의 유사성 레벨을 나타내고; 및 시간적 주의 맵을 상기 제1 내지 제3 특징 맵에 적용하여 시간적 주의를 갖는 특징 맵을 생성한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 상이한 캡처 시간들에 각각 대응하는 제1 입력 프레임, 제2 입력 프레임 및 제3 입력 프레임을 포함하는 복수의 입력 프레임을 수신하고;상기 상이한 캡처 시간들에 대응하는 제1 특징 맵, 제2 특징 맵 및 제3 특징 맵을 생성하기 위해 상기 제1 내지 제3 입력 프레임을 컨볼루션(convolving)하고, 상기 제1 내지 제3 특징 맵에 기초하여 시간적 주의 맵을 계산하고, 상기 시간적 주의 맵은 상기 제1 내지 제3 특징 맵 중에서 서로 상이한 특징 맵들의 쌍에 대응하는 복수의 가중치를 포함하며, 상기 복수의 가중치의 각각의 가중치는 대응하는 특징 맵들의 쌍의 유사성 레벨을 나타내고; 및시간적 주의 맵을 상기 제1 내지 제3 특징 맵에 적용하여 시간적 주의를 갖는 특징 맵을 생성하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 복수의 가중치는 학습 가능한 값에 기초한, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 시간적 주의 맵의 상기 복수의 가중치 중 각각의 가중치(Aij)는, 와 같이 표현되며,여기서, i와 j는 0보다 큰 인덱스 값이고, s는 학습 가능한 스케일링 계수이며, Mr은 제1 내지 제3 특징 맵을 기초로하는 재구성된 결합된 특징 맵이며, c는 제1 내지 제3 특징 맵 각각의 다수의 채널을 나타내는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 시간적 주의 맵을 적용하는 것은, 로서 시간적 주의를 갖는 특징 맵의 구성요소들 를 계산하는 것을 포함하며,여기서 i는 0보다 큰 인덱스 값인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 입력 프레임은 입력 비디오 시퀀스의 비디오 프레임들인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 입력 프레임은 비디오 프레임들에 기초한 모션-보상되고 워핑된 프레임인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,제1 워핑된 프레임, 제2 워핑된 프레임 및 제3 워핑된 프레임을 포함하는 복수의 워핑된 프레임을 수신하고; 및상기 제1 내지 제3 워핑된 프레임들 각각을 복수의 패치들로 공간적으로 분할하는 것을 더 포함하고;상기 제1 입력 프레임은 상기 제1 워핑된 프레임의 상기 복수의 패치들의 패치이고,상기 제2 입력 프레임은 상기 제2 워핑된 프레임의 상기 복수의 패치들의 패치이고, 및상기 제3 입력 프레임은 상기 제3 워핑된 프레임의 상기 복수의 패치들의 패치인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,비디오 시퀀스의 연속적인 프레임들인 제1 비디오 프레임, 제2 비디오 프레임 및 제3 비디오 프레임을 수신하고;광학적 흐름에 기초하여 상기 제1 내지 제3 비디오 프레임 사이의 모션을 보상하여 상기 제1 내지 제3 입력 프레임을 생성하고; 및시간적 주의를 갖는 상기 특징 맵에 기초하여 깊이 맵을 생성하는 것을 더 포함하고, 상기 깊이 맵은 상기 제2 비디오 프레임의 픽셀들의 깊이 값을 포함하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 모션을 보상하는 것은:상기 제1 및 제3 비디오 프레임의 픽셀들에 기초하여 상기 제2 비디오 프레임의 픽셀의 광학적 흐름을 결정하고; 및 상기 결정된 광학적 흐름에 기초하여 상기 제1 내지 제3 입력 프레임을 이미지 워핑하는 것을 포함하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,비디오 시퀀스의 연속적인 프레임들인 제1 비디오 프레임, 제2 비디오 프레임 및 제3 비디오 프레임을 수신하고;상기 제1 내지 제3 비디오 프레임들에 기초하여 제1 깊이 맵, 제2 깊이 맵 및 제3 깊이 맵을 생성하고;광학적 흐름에 기초하여 상기 제1 내지 제3 깊이 맵 사이의 모션들을 보상하여 상기 제1 내지 제3 입력 프레임을 생성하고; 및상기 시간적 주의와 상기 특징 맵을 컨볼루션하여(convolving) 깊이 맵을 생성하는 것을 더 포함하고, 상기 깊이 맵은 제2 비디오 프레임의 픽셀들의 깊이 값을 포함하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서, 상기 제1 내지 제3 입력 프레임은 상기 제1 내지 제3 깊이 맵에 대응하는 워핑된 깊이 맵들인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>12. 제10항에 있어서, 상기 제1 내지 제3 깊이 맵을 생성하는 것은:상기 제1 비디오 프레임에 기초하여 상기 제1 깊이 맵을 생성하고;상기 제2 비디오 프레임에 기초하여 상기 제2 깊이 맵을 생성하고; 및상기 제3 비디오 프레임에 기초하여 상기 제3 깊이 맵을 생성하는 것을 포함하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>13. 복수의 비디오 프레임에 기초한 깊이 검출 방법에 있어서,서로 상이한 캡처 시간에 대응하는 제1 워핑된 프레임, 제2 워핑된 프레임 및 제3 워핑된 프레임을 포함하는 복수의 워핑된 프레임을 수신하고; 상기 제1 내지 제3 워핑된 프레임 각각을 제1 패치를 포함하는 복수의 패치들로 분할하고;제1 입력 프레임, 제2 입력 프레임 및 제3 입력 프레임을 포함하는 복수의 입력 프레임들을 수신하고;상이한 캡처 시간들에 대응하는 제1 특징 맵, 제2 특징 맵 및 제3 특징 맵을 생성하기 위해 제1 워핑된 프레임의 상기 제1 패치, 제2 워핑된 프레임의 상기 제1 패치 및 제3 워핑된 프레임의 상기 제1 패치를 컨볼루션하고(convolving); 상기 제1 내지 제3 특징 맵에 기초하여 시간적 주의 맵을 계산하고, 상기 시간적 주의 맵은 상기 제1 내지 제3 특징 맵 중에서 서로 상이한 특징 맵들의 쌍에 대응하는 복수의 가중치를 포함하며, 상기 복수의 가중치의 각각의 가중치는 대응하는 특징 맵들의 쌍의 유사성 레벨을 나타내고; 및시간적 주의 맵을 상기 제1 내지 제3 특징 맵에 적용하여 시간적 주의를 갖는 특징 맵을 생성하는, 복수의 비디오 프레임에 기초한 깊이 검출 시스템.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 복수의 워핑된 프레임은 모션 보상된 비디오 프레임인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>15. 제13항에 있어서, 상기 복수의 워핑된 프레임은 비디오 시퀀스의 복수의 입력 비디오 프레임에 대응하는 모션 보상된 깊이 맵들인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>16. 제13항에 있어서,비디오 시퀀스의 연속적인 프레임들인 제1 비디오 프레임, 제2 비디오 프레임 및 제3 비디오 프레임을 수신하고;광학적 흐름에 기초하여 상기 제1 내지 제3 비디오 프레임 사이의 모션들을 보상하여 상기 제1 내지 제3 워핑된 프레임을 생성하고; 및시간적 주의를 갖는 상기 특징 맵에 기초하여 깊이 맵을 생성하고, 상기 깊이 맵은 상기 제2 비디오 프레임의 픽셀들의 깊이 값을 포함하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서, 상기 모션들을 보상하는 것은:상기 제 1 및 제 3 입력 프레임의 픽셀에 기초하여 상기 제 2 비디오 프레임의 픽셀의 광학적 흐름을 결정하고; 및 상기 결정된 광학적 흐름에 기초하여 상기 제1 내지 제3 비디오 프레임을 이미지 워핑하는 것을 포함하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>18. 제13항에 있어서,비디오 시퀀스의 연속적인 프레임들인 제1 비디오 프레임, 제2 비디오 프레임 및 제3 비디오 프레임을 수신하고;상기 제1 내지 제3 비디오 프레임들에 기초하여 제1 깊이 맵, 제2 깊이 맵 및 제3 깊이 맵을 생성하고;광학적 흐름에 기초하여 제1 내지 제3 깊이 맵 사이의 모션들을 보상하여 상기 제1 내지 제3 입력 프레임을 생성하고; 및상기 시간적 주의와 상기 특징 맵을 컨볼루션하여(convolving) 깊이 맵을 생성하는 것을 더 포함하고, 상기 깊이 맵은 제2 비디오 프레임의 픽셀들의 깊이 값을 포함하는, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서, 상기 제1 내지 제3 입력 프레임은 상기 제1 내지 제3 깊이 맵에 대응하는 워핑된 깊이 맵들인, 복수의 비디오 프레임에 기초한 깊이 검출 방법.</claim></claimInfo><claimInfo><claim>20. 프로세서; 및상기 프로세서에 로컬인 프로세서 메모리, 상기 프로세서 메모리는 상기 프로세서에 의해 실행될 때, 프로세서가 다음을 수행하게 하는 명령들을 저장하며:상이한 캡처 시간들에 각각 대응하는 제1 입력 프레임, 제2 입력 프레임 및 제3 입력 프레임을 포함하는 복수의 입력 프레임을 수신하고;상기 상이한 캡처 시간들에 대응하는 제1 특징 맵, 제2 특징 맵 및 제3 특징 맵을 생성하기 위해 상기 제1 내지 제3 입력 프레임을 컨볼루션(convolving)하고, 상기 제1 내지 제3 특징 맵에 기초하여 시간적 주의 맵을 계산하고, 상기 시간적 주의 맵은 상기 제1 내지 제3 특징 맵 중에서 서로 상이한 특징 맵들의 쌍에 대응하는 복수의 가중치를 포함하며, 상기 복수의 가중치의 각각의 가중치는 대응하는 특징 맵들의 쌍의 유사성 레벨을 나타내고; 및시간적 주의 맵을 상기 제1 내지 제3 특징 맵에 적용하여 시간적 주의를 갖는 특징 맵을 생성하는, 복수의 비디오 프레임에 기초한 깊이 검출 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>***** 미국 캘리포니아...</address><code> </code><country> </country><engName>REN, Haoyu</engName><name>런, 하오위 </name></inventorInfo><inventorInfo><address>***** 미국 캘리포니아...</address><code> </code><country> </country><engName>EL-KHAMY, Mostafa</engName><name>엘 카미, 모스타파 </name></inventorInfo><inventorInfo><address>***** 미국 캘리포니아...</address><code> </code><country> </country><engName>LEE, Jung Won</engName><name>이정원 </name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2019.07.22</priorityApplicationDate><priorityApplicationNumber>62/877,246</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.04.06</priorityApplicationDate><priorityApplicationNumber>16/841,618</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.06.01</receiptDate><receiptNumber>1-1-2020-0555840-70</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2020.06.03</receiptDate><receiptNumber>9-1-2020-9004979-35</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2020.06.03</receiptDate><receiptNumber>9-1-2020-9005003-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Appointment of Agent] Report on Agent (Representative)</documentEngName><documentName>[대리인선임]대리인(대표자)에 관한 신고서</documentName><receiptDate>2022.06.24</receiptDate><receiptNumber>1-1-2022-0663504-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.05.31</receiptDate><receiptNumber>1-1-2023-0602174-76</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.09.12</receiptDate><receiptNumber>9-5-2025-0886478-48</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200065711.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c931e428ab513e3692c8efe9d65092f0767033850eab076afdddeba70953e427147a2e6a1334ef278ddf45b15244ca1799e543a24827e05010b</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfd83696ff674e51f3e4088067dda7f2b62ecace47480c939bac033483d651c95b23ecd9a43bedd423c339ae90a6379450b6a9b0fc857925ec</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>