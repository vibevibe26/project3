<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:39:07.397</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2023-0094078</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>그립 대상 객체를 파지하기 위한 그리퍼를 포함하는 전자 장치 및 그 제어 방법</inventionTitle><inventionTitleEng>ELECTRONIC DEVICE COMPRISING A GRIPPER FOR GRASPING  A TARGET OBJECT AND CONTROL METHOD THEREOF</inventionTitleEng><openDate>2024.09.04</openDate><openNumber>10-2024-0133506</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 9/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 13/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B25J 19/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/50</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/90</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전자 장치가 개시된다. 전자 장치는, 제1 센서, 제2 센서, 그리퍼(gripper), 제1 센서를 통해 획득된 제1 이미지를 제1 신경망 모델에 입력하여 제1 이미지에 대응되는 제1 특징(feature) 맵을 획득하고, 제2 센서를 통해 획득된 제2 이미지를 제2 신경망 모델에 입력하여 제2 이미지에 대응되는 제2 특징 맵을 획득하고, 제1 특징 맵 및 제2 특징 맵을 병합하여 제3 이미지를 획득하고, 제3 이미지에 기초하여 그립 대상 객체를 식별하고, 그립 대상 객체를 파지하도록 그리퍼를 제어하는 하나 이상의 프로세서를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 제1 센서;제2 센서;그리퍼(gripper);상기 제1 센서를 통해 획득된 제1 이미지를 제1 신경망 모델에 입력하여 상기 제1 이미지에 대응되는 제1 특징(feature) 맵을 획득하고,상기 제2 센서를 통해 획득된 제2 이미지를 제2 신경망 모델에 입력하여 상기 제2 이미지에 대응되는 제2 특징 맵을 획득하고,상기 제1 특징 맵 및 상기 제2 특징 맵을 병합하여 제3 이미지를 획득하고,상기 제3 이미지에 기초하여 그립 대상 객체를 식별하고,상기 그립 대상 객체를 파지하도록 상기 그리퍼를 제어하는 하나 이상의 프로세서;를 포함하는 전자 장치.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 제1 센서는,RGB 센서이고,상기 하나 이상의 프로세서는,상기 RGB 센서를 통해 RGB 정보를 포함하는 상기 제1 이미지가 수신되면, 상기 제1 이미지를 상기 제1 신경망 모델에 입력하고,상기 제1 신경망 모델로부터 획득된 상기 제1 특징 맵은, 상기 그립 대상 객체에 대한 RGB 특징 정보를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제2 센서는,뎁스(Depth) 센서이고,상기 하나 이상의 프로세서는,상기 뎁스 센서를 통해 뎁스 정보를 포함하는 상기 제2 이미지가 수신되면, 상기 제2 이미지를 상기 제2 신경망 모델에 입력하고,상기 제2 신경망 모델로부터 획득된 상기 제2 특징 맵은, 상기 그립 대상 객체에 대한 뎁스 특징 정보를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 하나 이상의 프로세서는,상기 제2 이미지가 수신되면, 상기 제2 이미지를 전처리(pre-processing)하고, 상기 전처리된 제2 이미지를 상기 제2 신경망 모델에 입력하며,상기 전처리된 제2 이미지는, 상기 그립 대상 객체에 대한 포인트 클라우드 정보를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 하나 이상의 프로세서는,상기 제3 이미지를 제3 신경망 모델에 입력하여 상기 그리퍼가 상기 그립 대상 객체를 파지하도록 제어하기 위한 상기 그리퍼의 이동 정보를 획득하고,상기 제3 신경망 모델은,상기 제3 이미지에 포함된 상기 그립 대상 객체의 형태 정보에 기초하여 상기 그리퍼의 이동 방향, 이동 거리 및 회전 각도 중 적어도 하나를 포함하는 상기 이동 정보를 출력하는, 전자 장치.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 하나 이상의 프로세서는,상기 이동 방향 및 상기 이동 거리에 따라 상기 그리퍼를 상기 그립 대상 객체에 인접하게 위치시키며, 상기 회전 각도에 따라 상기 그립 대상 객체에 대한 측면 방향을 식별하고,상기 식별된 측면 방향으로 상기 그립 대상 객체를 파지하도록 상기 그리퍼를 제어하는, 전자 장치.</claim></claimInfo><claimInfo><claim>7. 제5항에 있어서,상기 제3 신경망 모델은,상기 형태 정보에 기초하여, 상기 그리퍼가 상기 그립 대상 객체를 파지하기 위한 상기 그리퍼의 복수의 이동 정보를 획득하고,상기 복수의 이동 정보 각각에 대응되는 신뢰도를 획득하고,가장 높은 신뢰도를 가지는 이동 정보를 출력하며,상기 신뢰도는,상기 그리퍼의 상기 그립 대상 객체의 파지 확률을 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서,상기 하나 이상의 프로세서는,실시간 또는 기 설정된 시간 간격으로 상기 제1 센서로부터 업데이트된 제1 이미지를 획득하고, 상기 제2 센서로부터 업데이트된 제2 이미지를 획득하고,상기 업데이트된 제1 이미지를 상기 제1 신경망 모델에 입력하여 업데이트된 제1 특징 맵을 획득하고,상기 업데이트된 제2 이미지를 상기 제2 신경망 모델에 입력하여 업데이트된 제2 특징 맵을 획득하고,상기 업데이트된 제1 특징 맵 및 상기 업데이트된 제2 특징 맵을 병합하여 업데이트된 제3 이미지를 획득하고,상기 업데이트된 제3 이미지에 기초하여 상기 그리퍼가 상기 그립 대상 객체를 파지하도록 제어하기 위한 상기 그리퍼의 이동 정보를 업데이트하고,상기 업데이트된 이동 정보에 기초하여 상기 그리퍼를 제어하는, 전자 장치.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 제1 이미지 및 상기 제2 이미지 각각은,상기 그리퍼의 적어도 일부 및 상기 그립 대상 객체를 포함하는 이미지인, 전자 장치.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 하나 이상의 프로세서는,상기 그리퍼를 6자유도(6 Degrees of Freedom)로 제어하는, 전자 장치.</claim></claimInfo><claimInfo><claim>11. 그리퍼(Gripper)를 포함하는 전자 장치의 제어 방법에 있어서,제1 센서를 통해 획득된 제1 이미지를 제1 신경망 모델에 입력하여 상기 제1 이미지에 대응되는 제1 특징(feature) 맵을 획득하는 단계;제2 센서를 통해 획득된 제2 이미지를 제2 신경망 모델에 입력하여 제2 이미지에 대응되는 제2 특징 맵을 획득하는 단계;상기 제1 특징 맵 및 상기 제2 특징 맵을 병합하여 제3 이미지를 획득하는 단계;상기 제3 이미지에 기초하여 그립 대상 객체를 식별하는 단계; 및상기 그립 대상 객체를 파지하도록 상기 그리퍼를 제어하는 단계;를 포함하는 제어 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 제1 센서는,RGB 센서이고,상기 제1 특징 맵을 획득하는 단계는, 상기 RGB 센서를 통해 RGB 정보를 포함하는 상기 제1 이미지가 수신되면, 상기 제1 이미지를 상기 제1 신경망 모델에 입력하는 단계;를 포함하고,상기 제1 신경망 모델로부터 획득된 상기 제1 특징 맵은, 상기 그립 대상 객체에 대한 RGB 특징 정보를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>13. 제11항에 있어서,상기 제2 센서는,뎁스(Depth) 센서이고,상기 제2 특징 맵을 획득하는 단계는,상기 뎁스 센서를 통해 뎁스 정보를 포함하는 상기 제2 이미지가 수신되면, 상기 제2 이미지를 상기 제2 신경망 모델에 입력하는 단계;를 포함하고,상기 제2 신경망 모델로부터 획득된 상기 제2 특징 맵은, 상기 그립 대상 객체에 대한 뎁스 특징 정보를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 제2 특징 맵을 획득하는 단계는,상기 제2 이미지가 수신되면, 상기 제2 이미지를 전처리(pre-processing)하는 단계; 및상기 전처리된 제2 이미지를 상기 제2 신경망 모델에 입력하는 단계;를 포함하고,상기 전처리된 제2 이미지는, 상기 그립 대상 객체에 대한 포인트 클라우드 정보를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>15. 제11항에 있어서,상기 그립 대상 객체를 식별하는 단계는,상기 제3 이미지를 제3 신경망 모델에 입력하여 상기 그리퍼가 상기 그립 대상 객체를 파지하도록 제어하기 위한 상기 그리퍼의 이동 정보를 획득하는 단계;를 포함하고,상기 제3 신경망 모델은,상기 제3 이미지에 포함된 상기 그립 대상 객체의 형태 정보에 기초하여 상기 그리퍼의 이동 방향, 이동 거리 및 회전 각도 중 적어도 하나를 포함하는 상기 이동 정보를 출력하는, 제어 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 그리퍼를 제어하는 단계는,상기 이동 방향 및 상기 이동 거리에 따라 상기 그리퍼를 상기 그립 대상 객체에 인접하게 위치시키는 단계;상기 회전 각도에 따라 상기 그립 대상 객체에 대한 측면 방향을 식별하는 단계; 및상기 식별된 측면 방향으로 상기 그립 대상 객체를 파지하도록 상기 그리퍼를 제어하는 단계;를 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 제3 신경망 모델은,상기 형태 정보에 기초하여, 상기 그리퍼가 상기 그립 대상 객체를 파지하기 위한 상기 그리퍼의 복수의 이동 정보를 획득하고,상기 복수의 이동 정보 각각에 대응되는 신뢰도를 획득하고,가장 높은 신뢰도를 가지는 이동 정보를 출력하며,상기 신뢰도는,상기 그리퍼의 상기 그립 대상 객체의 파지 확률을 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>18. 제11항에 있어서,실시간 또는 기 설정된 시간 간격으로 상기 제1 센서로부터 업데이트된 제1 이미지를 획득하고, 상기 제2 센서로부터 업데이트된 제2 이미지를 획득하는 단계;상기 업데이트된 제1 이미지를 상기 제1 신경망 모델에 입력하여 업데이트된 제1 특징 맵을 획득하는 단계;상기 업데이트된 제2 이미지를 상기 제2 신경망 모델에 입력하여 업데이트된 제2 특징 맵을 획득하는 단계;상기 업데이트된 제1 특징 맵 및 상기 업데이트된 제2 특징 맵을 병합하여 업데이트된 제3 이미지를 획득하는 단계;상기 업데이트된 제3 이미지에 기초하여 상기 그리퍼가 상기 그립 대상 객체를 파지하도록 제어하기 위한 상기 그리퍼의 이동 정보를 업데이트하는 단계; 및상기 업데이트된 이동 정보에 기초하여 상기 그리퍼를 제어하는 단계;를 더 포함하는, 제어 방법.</claim></claimInfo><claimInfo><claim>19. 제11항에 있어서,상기 제1 이미지 및 상기 제2 이미지 각각은,상기 그리퍼의 적어도 일부 및 상기 그립 대상 객체를 포함하는 이미지인, 제어 방법.</claim></claimInfo><claimInfo><claim>20. 제11항에 있어서,상기 그리퍼를 제어하는 단계는,상기 그리퍼를 6자유도(6 Degrees of Freedom)로 제어하는 단계;를 포함하는, 제어 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>YOON, Jae Min</engName><name>윤재민</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>AHN, Joon Mo</engName><name>안준모</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>CHUNG, Rak Joon</engName><name>정락준</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HA, Chang Su</engName><name>하창수</name></inventorInfo><inventorInfo><address>경기도 수원시 영통구...</address><code> </code><country> </country><engName>HAN, Heung woo</engName><name>한흥우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>919980005433</code><country>대한민국</country><engName>Jeong Hong Sik</engName><name>정홍식</name></agentInfo><agentInfo><address>서울시 서초구 강남대로 *** 신덕빌딩 *층(나우특허법률사무소)</address><code>920050001107</code><country>대한민국</country><engName>KIM TAEHUN</engName><name>김태헌</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.02.27</priorityApplicationDate><priorityApplicationNumber>1020230026026</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2023.07.19</receiptDate><receiptNumber>1-1-2023-0797615-26</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020230094078.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9302b6ccca3435e9c35ce89d8f9c2390fd5c3dc77d6a991de1aee83929c703e436e53d7394a39aa91a991ae993a71e29394ea82232d283cec7</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa2ac87768a49edaaeb8e6dbf09e12143f3fe18d4787b7f7615d217ef1df646ea5d9115f0be1a8e3bae34dd3c3b33dea18fb3b32abfd6aaad</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>