<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:53.453</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7013934</applicationNumber><claimCount>40</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>견고한 객체 검출, 위치 파악 및 모니터링 기능을 갖춘 물류 자율 주행 차량</inventionTitle><inventionTitleEng>LOGISTICS AUTONOMOUS VEHICLE WITH ROBUST OBJECT DETECTION, LOCALIZATION AND MONITORING</inventionTitleEng><openDate>2025.06.04</openDate><openNumber>10-2025-0078987</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.25</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/667</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/243</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/58</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>B65G 43/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>B65G 1/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 1/622</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 101/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 111/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 109/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 107/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 105/28</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G05D 111/63</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 자율 주행 차량(autonomous guided vehicle)은 프레임, 구동 섹션, 페이로드 핸들러, 비전 시스템, 및 제어기를 포함한다. 상기 비전 시스템은 객체(object)의 비디오 스트림 데이터 이미징을 생성하도록 배치된 카메라를 가진다. 상기 제어기는 적어도 하나의 카메라로부터의 비디오 스트림 데이터 이미징을 등록하도록 통신 가능하게 연결되고 상기 객체의 거리를 검출하는 거리 센서 및 비행 시간 센서 중 적어도 하나 이상에 통신 가능하게 연결된다. 상기 제어기는, 상기 비디오 스트림 데이터 이미징으로부터, 상기 비디오 스트림 데이터 이미징으로부터의 양안 비전과 단안 비전 둘 다를 교대로 사용하여 미리 결정된 기준 프레임 내에서 견고한 객체 검출 및 위치 파악(robust object detection and localization)을 수행하도록 구성되며, 상기 단안 비전을 통해 결정된 검출은 상기 양안 비전을 통해 결정된 검출과 상응하는 신뢰도를 가진다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.04.04</internationOpenDate><internationOpenNumber>WO2024073490</internationOpenNumber><internationalApplicationDate>2023.09.27</internationalApplicationDate><internationalApplicationNumber>PCT/US2023/075234</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 자율 주행 차량(autonomous guided vehicle)으로서, 상기 자율 주행 차량은:페이로드 홀드(payload hold)를 가진 프레임;상기 자율 주행 차량을 횡단 표면(traverse surface) 상에 지지하는 구동 바퀴들(drive wheels)을 가진 상기 프레임에 결합된 구동 섹션(drive section)으로서, 상기 구동 바퀴들은 시설 내의 횡단 표면 위에서 상기 자율 주행 차량을 이동시키는 횡단 표면 상의 차량 횡단을 수행하는, 구동 섹션;상기 프레임에 결합되며, 상기 페이로드 홀드 내에 안착된 평평한 비결정론적 안착 표면(flat undeterministic seating surface)을 가진 페이로드를 상기 자율 주행 차량의 페이로드 홀드와 저장 어레이 내의 페이로드의 저장 위치로 그리고 이로부터 이송하도록 구성된 페이로드 핸들러(payload handler); 상기 프레임에 장착되며, 물류 공간 내의 객체(object)의 비디오 스트림 데이터 이미징을 생성하도록 배치된 적어도 하나의 카메라를 가지는 비전 시스템(vision system)으로서, 상기 객체는 상기 프레임의 적어도 일부, 상기 페이로드의 적어도 일부, 상기 페이로드 핸들러의 적어도 일부, 및 상기 자율 주행 차량 너머의 물류 공간 내의 물류 물품 또는 구조물 중 적어도 일부 중 적어도 하나인, 비전 시스템; 및상기 적어도 하나의 카메라로부터의 비디오 스트림 데이터 이미징을 등록하도록 통신 가능하게 연결되고 상기 객체의 거리를 검출하는 거리 센서 및 비행 시간 센서 중 적어도 하나 이상에 통신 가능하게 연결된 제어기;를 포함하며, 상기 제어기는, 상기 비디오 스트림 데이터 이미징으로부터, 상기 비디오 스트림 데이터 이미징으로부터의 양안 비전(binocular vision)과 단안 비전(monocular vision) 둘 다를 교대로 사용하여 미리 결정된 기준 프레임 내에서 견고한 객체 검출 및 위치 파악(robust object detection and localization)을 수행하도록 구성되며, 상기 단안 비전을 통해 결정된 검출은 상기 양안 비전을 통해 결정된 검출과 상응하는 신뢰도를 가지는, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제어기는 심층 기계 학습 모델(deep machine learning model)을 사용하여 단안 비전을 통해 객체 검출을 수행하도록 구성되는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 제어기는 단안 비전과 심층 기계 학습 모델로부터 객체 검출을 결정하는 객체 검출 기능을 가지는 기계 학습 모듈과 인터페이스하도록 구성되는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 자율 주행 차량은 상기 적어도 하나의 카메라에 통신 가능하게 연결되어 비디오 스트림 데이터를 등록하는 미디어 서버(media server)를 더 포함하며, 상기 미디어 서버는 상기 제어기와 인터페이싱하고, 상기 제어기는 상기 자율 주행 차량에 탑재되도록 배치되거나 상기 자율 주행 차량으로부터 원격으로 배치되는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 페이로드 핸들러는 상기 저장 위치로부터 페이로드를 언더픽(underpick)하도록 구성되는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 비전 시스템의 적어도 하나의 카메라는 스테레오 비전 카메라 쌍을 형성하는 2개의 카메라들을 포함하고;상기 견고한 객체 검출 및 위치 파악은, 상기 스테레오 비전 카메라 쌍으로부터의 스테레오 비전의 이용 가능성과 관계없이, 인접한 저장 위치들에 홀딩된 2개 이상의 밀집된 페이로드들로부터 페이로드를 상기 페이로드 핸들러가 언더픽킹할 수 있도록 하는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 비전 시스템의 적어도 하나의 카메라는 스테레오 비전 카메라 쌍을 형성하는 2개의 카메라들을 포함하고;상기 견고한 객체 검출 및 위치 파악은, 상기 스테레오 비전 카메라 쌍으로부터의 스테레오 비전의 이용 가능성과 관계없이, 인접한 저장 위치들에 홀딩된 2개 이상의 밀집된 페이로드들로부터 변형된 페이로드를 상기 페이로드 핸들러가 언더픽킹할 수 있도록 하는, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 비전 시스템의 적어도 하나의 카메라는 스테레오 비전 카메라 쌍을 형성하는 2개의 카메라들을 포함하고;상기 견고한 객체 검출 및 위치 파악은, 상기 스테레오 비전 카메라 쌍으로부터의 스테레오 비전의 이용 가능성과 관계없이, 인접한 저장 위치들에 홀딩되고 상기 시설 내에서 동적 가우시안 케이스 크기 분포(dynamic Gaussian case size distribution)를 가지는 2개 이상의 페이로드들로부터 페이로드를 상기 페이로드 핸들러가 언더픽킹할 수 있도록 하는, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>9. 제1항에 있어서,상기 단안 비전에 의해 수행된 객체 위치 파악은 상기 양안 비전을 통해 결정된 객체 위치 파악과 상응하는 신뢰도를 가지는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>10. 제1항에 있어서, 상기 제어기는 양안 비전 객체 검출 및 위치 파악과 단안 비전 객체 검출 및 위치 파악이 상호 교환 가능하게 선택 가능하도록 구성되는, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>11. 제1항에 있어서, 상기 제어기는 상기 자율 주행 차량의 미리 결정된 작동 특성의 검출에 근거하여 필요에 따라 양안 비전 객체 검출 및 위치 파악과 단안 비전 객체 검출 및 위치 파악 중 하나를 선택하도록 배치된 선택기(selector)를 가지는, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서,상기 미리 결정된 특성은 상기 제어기에 의해 등록된 비디오 스트림 데이터가 상기 양안 비전 객체 검출 및 위치 파악을 지원하지 않는 것인, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>13. 자율 주행 차량을 위한 객체 검출 및 위치 파악 방법으로서, 상기 방법은: 자율 주행 차량을 제공하는 단계로서, 상기 자율 주행 차량은: 페이로드 홀드를 가진 프레임;상기 자율 주행 차량을 횡단 표면 상에 지지하는 구동 바퀴들을 가진 상기 프레임에 결합된 구동 섹션으로서, 상기 구동 바퀴들은 시설 내의 횡단 표면 위에서 상기 자율 주행 차량을 이동시키는 횡단 표면 상의 차량 횡단을 수행하는, 구동 섹션;상기 프레임에 결합되며, 상기 페이로드 홀드 내에 안착된 평평한 비결정론적 안착 표면을 가진 페이로드를 상기 자율 주행 차량의 페이로드 홀드와 저장 어레이 내의 페이로드의 저장 위치로 그리고 이로부터 이송하도록 구성된 페이로드 핸들러; 상기 프레임에 장착되며, 적어도 하나의 카메라를 가지는 비전 시스템; 및상기 비전 시스템에 통신 가능하게 연결된 제어기;를 가지는, 단계; 상기 비전 시스템의 적어도 하나의 카메라에 의해 물류 공간 내의 객체의 비디오 스트림 데이터 이미징을 생성하는 단계로서, 상기 객체는 상기 프레임의 적어도 일부, 상기 페이로드의 적어도 일부, 상기 페이로드 핸들러의 적어도 일부, 및 상기 자율 주행 차량 너머의 물류 공간 내의 물류 물품 또는 구조물 중 적어도 일부 중 적어도 하나인, 단계;상기 제어기에 의해 상기 적어도 하나의 카메라로부터의 비디오 스트림 데이터 이미징을 등록하는 단계; 및상기 제어기에 통신 가능하게 연결된 비행 시간 센서 및 거리 센서 중 적어도 하나 이상에 의해 객체의 거리를 검출하는 단계;를 포함하며, 상기 제어기는, 상기 비디오 스트림 데이터 이미징으로부터, 상기 비디오 스트림 데이터 이미징으로부터의 양안 비전과 단안 비전 둘 다를 교대로 사용하여 미리 결정된 기준 프레임 내에서 견고한 객체 검출 및 위치 파악을 수행하며, 상기 단안 비전을 통해 결정된 검출은 상기 양안 비전을 통해 결정된 검출과 상응하는 신뢰도를 가지는, 방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 제어기는 심층 기계 학습 모델(deep machine learning model)을 사용하여 단안 비전을 통해 객체 검출을 수행하는, 방법.  </claim></claimInfo><claimInfo><claim>15. 제13항에 있어서,상기 제어기는 단안 비전과 심층 기계 학습 모델로부터 객체 검출을 결정하는 객체 검출 기능을 가지는 기계 학습 모듈과 인터페이스하는, 방법. </claim></claimInfo><claimInfo><claim>16. 제13항에 있어서, 미디어 서버가 상기 적어도 하나의 카메라에 통신 가능하게 연결되어 비디오 스트림 데이터를 등록하며, 상기 미디어 서버는 상기 제어기와 인터페이스하고, 상기 제어기는 상기 자율 주행 차량에 탑재되도록 배치되거나 상기 자율 주행 차량으로부터 원격으로 배치되는, 방법.</claim></claimInfo><claimInfo><claim>17. 제13항에 있어서, 상기 페이로드 핸들러는 상기 저장 위치로부터 페이로드를 언더픽(underpick)하는, 방법. </claim></claimInfo><claimInfo><claim>18. 제13항에 있어서, 상기 비전 시스템의 적어도 하나의 카메라는 스테레오 비전 카메라 쌍을 형성하는 2개의 카메라들을 포함하고;상기 방법은:상기 견고한 객체 검출 및 위치 파악을 통해, 상기 스테레오 비전 카메라 쌍으로부터의 스테레오 비전의 이용 가능성과 관계없이, 인접한 저장 위치들에 홀딩된 2개 이상의 밀집된 페이로드들로부터 페이로드를 상기 페이로드 핸들러가 언더픽킹하는 단계를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>19. 제13항에 있어서, 상기 비전 시스템의 적어도 하나의 카메라는 스테레오 비전 카메라 쌍을 형성하는 2개의 카메라들을 포함하고;상기 방법은:상기 견고한 객체 검출 및 위치 파악을 통해, 상기 스테레오 비전 카메라 쌍으로부터의 스테레오 비전의 이용 가능성과 관계없이, 인접한 저장 위치들에 홀딩된 2개 이상의 밀집된 페이로드들로부터 변형된 페이로드를 상기 페이로드 핸들러가 언더픽킹하는 단계를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>20. 제13항에 있어서,상기 비전 시스템의 적어도 하나의 카메라는 스테레오 비전 카메라 쌍을 형성하는 2개의 카메라들을 포함하고;상기 방법은:상기 견고한 객체 검출 및 위치 파악을 통해, 상기 스테레오 비전 카메라 쌍으로부터의 스테레오 비전의 이용 가능성과 관계없이, 인접한 저장 위치들에 홀딩되고 상기 시설 내에서 동적 가우시안 케이스 크기 분포를 가지는 2개 이상의 페이로드들로부터 페이로드를 상기 페이로드 핸들러가 언더픽킹하는 단계를 더 포함하는, 방법. </claim></claimInfo><claimInfo><claim>21. 제13항에 있어서, 상기 단안 비전에 의해 수행된 객체 위치 파악은 상기 양안 비전을 통해 결정된 객체 위치 파악과 상응하는 신뢰도를 가지는, 방법.</claim></claimInfo><claimInfo><claim>22. 제13항에 있어서,상기 양안 비전 객체 검출 및 위치 파악과 단안 비전 객체 검출 및 위치 파악은 상기 제어기를 통해 상호 교환 가능하게 선택 가능한, 방법. </claim></claimInfo><claimInfo><claim>23. 제13항에 있어서, 상기 제어기는 상기 자율 주행 차량의 미리 결정된 작동 특성의 검출에 근거하여 필요에 따라 양안 비전 객체 검출 및 위치 파악과 단안 비전 객체 검출 및 위치 파악 중 하나를 선택하도록 배치된 선택기(selector)를 가지는, 방법.</claim></claimInfo><claimInfo><claim>24. 제23항에 있어서, 상기 미리 결정된 특성은 상기 제어기에 의해 등록된 비디오 스트림 데이터가 상기 양안 비전 객체 검출 및 위치 파악을 지원하지 않는 것인, 방법.</claim></claimInfo><claimInfo><claim>25. 자율 주행 차량으로서, 상기 자율 주행 차량은:페이로드 홀드를 가진 프레임;상기 자율 주행 차량을 횡단 표면 상에 지지하는 구동 바퀴들을 가진 상기 프레임에 결합된 구동 섹션으로서, 상기 구동 바퀴들은 시설 내의 횡단 표면 위에서 상기 자율 주행 차량을 이동시키는 횡단 표면 상의 차량 횡단을 수행하는, 구동 섹션;상기 프레임에 결합되며, 상기 페이로드 홀드 내에 안착된 평평한 비결정론적 안착 표면을 가진 페이로드를 상기 자율 주행 차량의 페이로드 홀드와 저장 어레이 내의 페이로드의 저장 위치로 그리고 이로부터 이송하도록 구성된 페이로드 핸들러; 상기 프레임에 장착되며, 물류 공간 내의 객체의 비디오 스트림 데이터 이미징을 생성하도록 배치된 적어도 하나의 카메라를 가지는 비전 시스템으로서, 상기 객체는 상기 프레임의 적어도 일부, 상기 페이로드의 적어도 일부, 상기 페이로드 핸들러의 적어도 일부, 및 상기 자율 주행 차량 너머의 물류 공간 내의 물류 물품 또는 구조물 중 적어도 일부 중 적어도 하나인, 비전 시스템; 및상기 적어도 하나의 카메라로부터의 비디오 스트림 데이터 이미징을 등록하도록 통신 가능하게 연결되고 상기 객체의 거리를 검출하는 거리 센서 및 비행 시간 센서 중 적어도 하나 이상에 통신 가능하게 연결된 제어기;를 포함하며, 상기 제어기는 미리 결정된 기준 프레임 내에서 객체 검출 및 위치 파악이 상기 비디오 스트림 데이터 이미징으로부터의 양안 비전과 단안 비전을 선택적으로 사용하여 상기 비디오 스트림 데이터 이미징으로부터 수행되도록 구성되며, 상기 양안 비전 객체 검출 및 위치 파악과 상기 단안 비전 객체 검출 및 위치 파악 각각은 상기 제어기에 의해 필요에 따라 선택 가능한, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>26. 제25항에 있어서, 상기 단안 비전 검출 및 위치 파악은 상기 양안 비전 객체 검출 및 위치 파악을 통해 결정된 검출과 상응하는 신뢰도를 가지는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>27. 제25항에 있어서, 상기 제어기는 상기 양안 비전 객체 검출 및 위치 파악과 상기 단안 비전 객체 검출 및 위치 파악이 상호 교환 가능하게 선택 가능하도록 구성되는, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>28. 제25항에 있어서, 상기 제어기는 상기 자율 주행 차량의 미리 결정된 작동 특성의 검출에 근거하여 필요에 따라 양안 비전 객체 검출 및 위치 파악과 단안 비전 객체 검출 및 위치 파악 중 하나를 선택하도록 배치된 선택기를 가지는, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>29. 제28항에 있어서,상기 미리 결정된 특성은 상기 제어기에 의해 등록된 비디오 스트림 데이터가 상기 양안 비전 객체 검출 및 위치 파악을 지원하지 않는 것인, 자율 주행 차량.</claim></claimInfo><claimInfo><claim>30. 제25항에 있어서, 상기 제어기는 심층 기계 학습 모델을 사용하여 단안 비전을 통해 객체 검출을 수행하도록 구성되는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>31. 제25항에 있어서, 상기 제어기는 단안 비전과 심층 기계 학습 모델로부터 객체 검출을 결정하는 객체 검출 기능을 가지는 기계 학습 모듈과 인터페이스하도록 구성되는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>32. 제25항에 있어서, 상기 자율 주행 차량은 상기 적어도 하나의 카메라에 통신 가능하게 연결되어 비디오 스트림 데이터를 등록하는 미디어 서버를 더 포함하며, 상기 미디어 서버는 상기 제어기와 인터페이싱하고, 상기 제어기는 상기 자율 주행 차량에 탑재되도록 배치되거나 상기 자율 주행 차량으로부터 원격으로 배치되는, 자율 주행 차량. </claim></claimInfo><claimInfo><claim>33. 자율 주행 차량을 위한 객체 검출 및 위치 파악 방법으로서, 상기 방법은: 자율 주행 차량을 제공하는 단계로서, 상기 자율 주행 차량은: 페이로드 홀드를 가진 프레임;상기 자율 주행 차량을 횡단 표면 상에 지지하는 구동 바퀴들을 가진 상기 프레임에 결합된 구동 섹션으로서, 상기 구동 바퀴들은 시설 내의 횡단 표면 위에서 상기 자율 주행 차량을 이동시키는 횡단 표면 상의 차량 횡단을 수행하는, 구동 섹션;상기 프레임에 결합되며, 상기 페이로드 홀드 내에 안착된 평평한 비결정론적 안착 표면을 가진 페이로드를 상기 자율 주행 차량의 페이로드 홀드와 저장 어레이 내의 페이로드의 저장 위치로 그리고 이로부터 이송하도록 구성된 페이로드 핸들러; 상기 프레임에 장착되며, 물류 공간 내의 객체의 비디오 스트림 데이터 이미징을 생성하도록 배치된 적어도 하나의 카메라를 가지는 비전 시스템으로서, 상기 객체는 상기 프레임의 적어도 일부, 상기 페이로드의 적어도 일부, 상기 페이로드 핸들러의 적어도 일부, 및 상기 자율 주행 차량 너머의 물류 공간 내의 물류 물품 또는 구조물 중 적어도 일부 중 적어도 하나인, 비전 시스템; 및상기 비전 시스템과, 상기 객체의 거리를 검출하는 거리 센서 및 비행 시간 센서 중 적어도 하나 이상에 통신 가능하게 연결된 제어기;를 가지는, 단계;상기 제어기에 의해, 상기 적어도 하나의 카메라로부터의 비디오 스트림 데이터 이미징을 등록하는 단계; 및상기 제어기에 의해, 상기 비디오 스트림 데이터 이미징으로부터의 양안 비전과 단안 비전을 선택적으로 사용하여 상기 비디오 스트림 데이터 이미징으로부터, 미리 결정된 기준 프레임 내에서, 객체 검출 및 위치 파악을 수행하는 단계로서, 상기 양안 비전 객체 검출 및 위치 파악과 상기 단안 비전 객체 검출 및 위치 파악 각각은 상기 제어기에 의해 필요에 따라 선택 가능한, 단계;를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서,상기 단안 비전 검출 및 위치 파악은 상기 양안 비전 객체 검출 및 위치 파악을 통해 결정된 검출과 상응하는 신뢰도를 가지는, 방법.</claim></claimInfo><claimInfo><claim>35. 제33항에 있어서,상기 양안 비전 객체 검출 및 위치 파악과 상기 단안 비전 객체 검출 및 위치 파악은 상기 제어기에 의해 상호 교환 가능하게 선택 가능한, 방법.</claim></claimInfo><claimInfo><claim>36. 제33항에 있어서, 상기 제어기는 상기 자율 주행 차량의 미리 결정된 작동 특성의 검출에 근거하여 필요에 따라 양안 비전 객체 검출 및 위치 파악과 단안 비전 객체 검출 및 위치 파악 중 하나를 선택하도록 배치된 선택기를 가지는, 방법.</claim></claimInfo><claimInfo><claim>37. 제36항에 있어서,상기 미리 결정된 특성은 상기 제어기에 의해 등록된 비디오 스트림 데이터가 상기 양안 비전 객체 검출 및 위치 파악을 지원하지 않는 것인, 방법.</claim></claimInfo><claimInfo><claim>38. 제33항에 있어서, 상기 제어기는 심층 기계 학습 모델을 사용하여 단안 비전을 통해 객체 검출을 수행하는, 방법.</claim></claimInfo><claimInfo><claim>39. 제33항에 있어서,상기 제어기는 단안 비전과 심층 기계 학습 모델로부터 객체 검출을 결정하는 객체 검출 기능을 가지는 기계 학습 모듈과 인터페이스하는, 방법.</claim></claimInfo><claimInfo><claim>40. 제33항에 있어서, 미디어 서버가 상기 적어도 하나의 카메라에 통신 가능하게 연결되어 비디오 스트림 데이터를 등록하며, 상기 미디어 서버는 상기 제어기와 인터페이스하고, 상기 제어기는 상기 자율 주행 차량에 탑재되도록 배치되거나 상기 자율 주행 차량으로부터 원격으로 배치되는, 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 메사추세츠 *****-**** 윌밍턴 리서치 드라이브 ***</address><code>520110504236</code><country>미국</country><engName>SYMBOTIC LLC</engName><name>심보틱 엘엘씨</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 매사추세츠 ***...</address><code> </code><country>미국</country><engName>SHOKRI, Maryam</engName><name>쇼크리 마리암</name></inventorInfo><inventorInfo><address>미국 매사추세츠 ***...</address><code> </code><country>미국</country><engName>BESL, Paul</engName><name>베즐 폴</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 강남구 언주로 **길 **, *층, **층, **층, **층(도곡동, 대림아크로텔)</address><code>920051000028</code><country>대한민국</country><engName>Y.P.LEE,MOCK&amp;PARTNERS</engName><name>리앤목특허법인</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.27</priorityApplicationDate><priorityApplicationNumber>63/377,271</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.09.26</priorityApplicationDate><priorityApplicationNumber>18/474,765</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.25</receiptDate><receiptNumber>1-1-2025-0474700-47</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.05.01</receiptDate><receiptNumber>1-5-2025-0073724-86</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257013934.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9351e454fd4c7cb381b1c0734e4eecc606150d846f6cd5d4a83ceb0740685649c79049f84cfa9f79a78138d11d61fb1185b52545d14b4d1575</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff3a2680d1840595990e57e90bd7f5ac803173802d0c7ee38ff473f76111eabc19313fe4a882220c7ef11fda3e32ecca4a624c307248f5c7f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>