<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:04:54.454</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.07.19</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7005245</applicationNumber><claimCount>195</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>얼굴 미세 움직임의 검출 및 이용</inventionTitle><inventionTitleEng>DETECTING AND UTILIZING FACIAL MICROMOVEMENTS</inventionTitleEng><openDate>2025.09.17</openDate><openNumber>10-2025-0137111</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.02.18</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/145</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/60</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 15/25</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 13/027</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/02</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/18</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G10L 15/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 25/84</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G06F 21/32</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 9/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2012.01.01)</ipcDate><ipcNumber>G06Q 20/40</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 얼굴 피부 미세 움직임을 검출하고 활용하기 위한 명령어를 포함하는 시스템, 방법 및 비일시적 컴퓨터 판독 가능 매체가 개시된다. 일부 비제한적인 실시예에서, 얼굴 피부 미세 움직임의 검출은 웨어러블 하우징, 광원(코히어런트 광원 또는 비-코히어런트 광원), 광 검출기 및 적어도 하나의 프로세서를 포함할 수 있는 스피치 검출 시스템을 사용하여 발생한다. 하나 이상의 프로세서는 얼굴 영역으로부터 수신된 광 반사를 분석하여 얼굴 피부 미세 움직임을 결정하고, 결정된 얼굴 피부 미세 움직임으로부터 의미를 추출하도록 구성될 수 있다. 결정된 얼굴 피부 미세 움직임으로부터 추출될 수 있는 의미의 예는, 개인에 의해 발화된 단어(무성으로 발화된 또는 발성적으로 발화된), 개인의 식별, 개인의 감정 상태, 개인의 심박수, 개인의 호흡률, 또는 임의의 다른 생체 인식, 감정 또는 스피치 관련 지표를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.01.25</internationOpenDate><internationOpenNumber>WO2024018400</internationOpenNumber><internationalApplicationDate>2023.07.19</internationalApplicationDate><internationalApplicationNumber>PCT/IB2023/057369</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 얼굴 피부 미세 움직임을 사용하여 개인을 식별하기 위한 머리 장착 가능 시스템에 있어서,개인의 머리에 착용되도록 구성된 웨어러블 하우징;상기 웨어러블 하우징과 연관되고 상기 머리의 얼굴 영역을 향해 광을 투영하도록 구성된 적어도 하나의 코히어런트 광원;상기 웨어러블 하우징과 연관되고, 상기 얼굴 영역으로부터 코히어런트 광 반사를 수신하도록 그리고 연관된 반사 신호를 출력하도록 구성된 적어도 하나의 검출기;적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 개인의 특정 얼굴 피부 미세 움직임을 결정하기 위해 상기 반사 신호를 분석하도록;  복수의 얼굴 피부 미세 움직임을 상기 개인과 상관(correlate)시키는 메모리에 액세스하도록; 상기 결정된 특정 얼굴 피부 미세 움직임과 상기 메모리 내의 상기 복수의 얼굴 피부 미세 움직임 중 적어도 하나의 얼굴 피부 미세 움직임 사이의 매치(match)를 검색하도록;  매치가 식별되는 경우, 제1 액션을 개시하도록; 그리고  매치가 식별되지 않는 경우, 상기 제1 액션과는 상이한 제2 액션을 개시하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 액션은 상기 개인과 연관된 적어도 하나의 미리 결정된 설정을 시작(institute)하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서, 상기 제1 액션은 컴퓨팅 디바이스를 잠금 해제하고, 상기 제2 액션은 상기 컴퓨팅 디바이스가 잠겨 있음을 표시하는 메시지의 제시(presentation)를 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서, 상기 제1 액션은 개인적 정보를 제공하고, 상기 제2 액션은 공개 정보(public information)를 제공하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서, 상기 제1 액션은 거래를 승인하고, 상기 제2 액션은 상기 거래가 승인되지 않았음을 표시하는 정보를 제공하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서, 상기 제1 액션은 애플리케이션에 대한 액세스를 허용하고, 상기 제2 액션은 상기 애플리케이션에 대한 액세스를 방지하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서, 상기 특정 얼굴 영역 내의 상기 특정 얼굴 피부 미세 움직임 중 적어도 일부는 100 미크론 미만의 미세 움직임인 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>8. 제1항에 있어서, 상기 특정 얼굴 피부 미세 움직임은 예비발성 근육 동원(prevocalization muscle recruitment)에 대응하는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>9. 제1항에 있어서, 상기 특정 얼굴 피부 미세 움직임은 적어도 하나의 단어의 발음 동안 근육 동원에 대응하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서, 상기 적어도 하나의 단어는 패스워드에 대응하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>11.  제1항에 있어서, 상기 메모리는 복수의 얼굴 피부 움직임을 복수의 개인과 상관시키도록 구성되고, 상기 적어도 하나의 프로세서는 상기 복수의 개인 각각에 고유한 반사 신호에 기초하여 상기 복수의 개인을 서로 구별하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>12. 제1항에 있어서, 통합 오디오 출력을 더 포함하며, 상기 제1 액션 중 적어도 하나 또는 상기 제2 액션 중 적어도 하나가 상기 오디오 출력을 통해 오디오를 출력하는 것을 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서, 상기 매치는 확실성 레벨이 적어도 하나의 프로세서에 의해 결정되면 식별되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>14. 제13항에 있어서, 상기 확실성 레벨이 초기에 도달되지 않을 때, 상기 적어도 하나의 프로세서는 추가적인 반사 신호를 분석하여 추가적인 얼굴 피부 미세 움직임을 결정하도록, 그리고 적어도 부분적으로 상기 추가적인 반사 신호의 분석에 기초하여 상기 확실성 레벨에 도달하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>15. 제13항에 있어서, 상기 적어도 하나의 프로세서는 또한, 새로운 얼굴 피부 미세 움직임을 상기 메모리 내의 상기 복수의 얼굴 피부 미세 움직임과 연속적으로 비교하여 순간적인 확실성 레벨을 결정하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 제1 액션을 개시한 후, 상기 순간적인 확실성 레벨이 임계치 미만일 때, 상기 적어도 하나의 프로세서는 상기 제1 액션을 중지하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서, 상기 순간적인 확실성 레벨이 임계치 미만일 때, 상기 적어도 하나의 프로세서는 연관된 액션을 개시하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서, 상기 제1 액션을 개시하는 것은 이벤트와 연관되고, 상기 적어도 하나의 프로세서는 상기 이벤트 동안 상기 새로운 얼굴 피부 미세 움직임을 연속적으로 비교하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>19. 얼굴 피부 미세 움직임을 사용하여 개인을 식별하기 위한 방법에 있어서,개인의 머리의 얼굴 영역을 향해 광을 투영하도록 구성된 웨어러블 코히어런트 광원을 동작시키는 단계;상기 얼굴 영역으로부터 코히어런트 광 반사를 수신하도록 그리고 연관된 반사 신호를 출력하도록 구성된 적어도 하나의 검출기를 동작시키는 단계;상기 개인의 특정 얼굴 피부 미세 움직임을 결정하기 위해 상기 반사 신호를 분석하는 단계; 복수의 얼굴 피부 미세 움직임을 상기 개인과 상관시키는 메모리에 액세스하는 단계;상기 결정된 특정 얼굴 피부 미세 움직임과 상기 메모리 내의 상기 복수의 얼굴 피부 미세 움직임 중 적어도 하나의 얼굴 피부 미세 움직임 사이의 매치를 검색하는 단계; 매치가 식별되는 경우, 제1 액션을 개시하는 단계; 및 매치가 식별되지 않는 경우, 상기 제1 액션과는 상이한 제2 액션을 개시하는 단계를 포함하는, 얼굴 피부 미세 움직임을 사용하여 개인을 식별하기 위한 방법.</claim></claimInfo><claimInfo><claim>20. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임을 사용하여 개인을 식별하기 위한 동작을 수행하게 하고, 상기 동작은:개인의 머리의 얼굴 영역을 향해 광을 투영하도록 구성된 웨어러블 코히어런트 광원을 동작시키는 단계;상기 얼굴 영역으로부터 코히어런트 광 반사를 수신하도록 그리고 연관된 반사 신호를 출력하도록 구성된 적어도 하나의 검출기를 동작시키는 단계;상기 개인의 특정 얼굴 피부 미세 움직임을 결정하기 위해 상기 반사 신호를 분석하는 단계; 복수의 얼굴 피부 미세 움직임을 상기 개인과 상관시키는 메모리에 액세스하는 단계;상기 결정된 특정 얼굴 피부 미세 움직임과 상기 메모리 내의 상기 복수의 얼굴 피부 미세 움직임 중 적어도 하나의 얼굴 피부 미세 움직임 사이의 매치를 검색하는 단계; 매치가 식별되는 경우, 제1 액션을 개시하는 단계; 및 매치가 식별되지 않는 경우, 상기 제1 액션과는 상이한 제2 액션을 개시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>21. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 움직임을 해석하기 위한 동작을 수행하게 하고, 상기 동작은:개인의 복수의 얼굴 영역 부위(facial region area)에 광을 투영하는 단계 - 상기 복수의 부위는 적어도 제1 부위와 제2 부위를 포함하며, 상기 제1 부위는 제2 부위보다 광대근(zygomaticus muscle) 및 입꼬리당김근(risorius muscle) 중, 적어도 하나에 더 가까움 - ;상기 복수의 부위로부터 반사를 수신하는 단계;상기 제1 부위로부터의 반사에 대응하는 제1 얼굴 피부 움직임과 상기 제2 부위로부터의 반사에 대응하는 제2 얼굴 피부 움직임을 검출하는 단계;상기 제1 얼굴 피부 움직임과 상기 제2 얼굴 피부 움직임 사이의 차이에 기초하여, 광대근 및 입꼬리당김근 중, 적어도 하나에 더 가까운 상기 제1 부위로부터의 반사가 상기 제2 부위로부터의 반사보다 더 강력한 의사소통의 지표임을 결정하는 단계;상기 제1 부위로부터의 반사가 더 강력한 의사소통의 지표라는 결정에 기초하여, 상기 제1 부위로부터의 반사를 프로세싱하여 의사소통을 확인하고, 상기 제2 부위로부터의 반사는 무시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서, 상기 제1 부위와 상기 제2 부위가 이격된 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>23. 제21항에 있어서, 상기 제1 부위로부터의 반사로부터 확인된 의사소통은 상기 개인의 의해 조음된 단어를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>24. 제21항에 있어서, 상기 제1 부위로부터의 반사로부터 확인된 의사소통은 상기 개인의 비언어적 신호(cue)를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>25. 제21항에 있어서, 상기 동작은 상기 복수의 얼굴 영역 부위의 조명을 가능하게 하는 방식으로 웨어러블 하우징 내에 위치된 코히어런트 광원을 동작시키는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>26. 제21항에 있어서, 상기 동작은 상기 복수의 얼굴 영역 부위의 조명을 가능하게 하는 방식으로 웨어러블 하우징으로부터 원격에 위치된 코히어런트 광원을 동작시키는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>27. 제21항에 있어서, 상기 동작은 상기 제1 부위의 적어도 일부 및 상기 제2 부위의 적어도 일부를 공통 광 스폿으로 조명하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>28. 제21항에 있어서, 상기 동작은 제1 스폿 그룹으로 상기 제1 부위를 조명하는 단계 및 상기 제1 스폿 그룹과 구별되는 제2 스폿 그룹으로 상기 제2 부위를 조명하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>29. 제21항에 있어서, 상기 동작은, 복수의 얼굴 영역 부위의 이중 모드 조명을 가능하게 하는 방식으로 코히어런트 광원을 동작시키는 단계, 제1 조명 모드와 연관된 반사를 분석하여 상기 제1 부위와 연관된 하나 이상의 광 스폿을 식별하는 단계, 및 제2 조명 모드와 연관된 반사를 분석하여 상기 의사소통을 확인하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>30. 제29항에 있어서, 상기 제1 조명 모드의 제1 광 강도는 상기 제2 조명 모드의 제2 광 강도와 상이한 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>31. 제29항에 있어서, 상기 제1 조명 모드의 제1 조명 패턴은 상기 제2 조명 모드의 제2 조명 패턴과 상이한 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>32. 제21항에 있어서, 상기 동작은, 상기 제1 얼굴 피부 움직임과 상기 제2 얼굴 피부 움직임 사이의 차이에 기초하여, 상기 제1 부위가 상기 제2 부위보다 뇌신경 V 또는 뇌신경 VII와 연관된 피하 조직에 더 가깝다는 것을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>33. 제21항에 있어서, 상기 제1 부위는 상기 제2 부위보다 상기 광대근에 더 가깝고, 상기 복수의 부위는 상기 제1 부위 및 상기 제2 부위 각각보다 상기 입꼬리당김근에 더 가까운 제3 부위를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>34. 제33항에 있어서, 상기 동작은, 인식 가능한 발성으로 스피치가 생성될 때 상기 제1 부위로부터 반사된 광을 분석하는 단계 및 인식 가능한 발성 없이 스피치가 생성될 때 상기 제3 부위로부터 반사된 광을 분석하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>35. 제21항에 있어서, 상기 제1 얼굴 피부 움직임과 상기 제2 얼굴 피부 움직임 사이의 차이가 100 미크론 미만의 차이를 포함하고, 상기 제1 부위로부터의 반사가 상기 제2 부위로부터의 반사보다 더 강력한 의사소통의 지표라는 결정은 상기 100 미크론 미만의 차이에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>36. 제21항에 있어서, 상기 제2 부위로부터의 반사를 무시하는 단계는, 상기 의사소통을 확인하기 위해 상기 제2 부위로부터의 반사의 사용을 생략하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>37. 제21항에 있어서, 상기 제1 얼굴 피부 움직임을 검출하는 단계는, 상기 제1 부위로부터 반사된 광에 대해 제1 스페클(speckle) 분석을 수행하는 단계를 수반하고, 상기 제2 얼굴 피부 움직임을 검출하는 단계는, 상기 제2 부위로부터 반사된 광에 대해 제2 스페클 분석을 수행하는 단계를 수반하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>38. 제37항에 있어서, 상기 제1 스페클 분석 및 상기 제2 스페클 분석은 상기 적어도 하나의 프로세서에 의해 동시에 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>39. 얼굴 피부 움직임을 해석하기 위한 방법에 있어서,개인의 복수의 얼굴 영역 부위(facial region area)에 광을 투영하는 단계 - 상기 복수의 부위는 적어도 제1 부위와 제2 부위를 포함하며, 상기 제1 부위는 제2 부위보다 광대근(zygomaticus muscle) 및 입꼬리당김근(risorius muscle) 중, 적어도 하나에 더 가까움 - ;상기 복수의 부위로부터 반사를 수신하는 단계;상기 제1 부위로부터의 반사에 대응하는 제1 얼굴 피부 움직임과 상기 제2 부위로부터의 반사에 대응하는 제2 얼굴 피부 움직임을 검출하는 단계;상기 제1 얼굴 피부 움직임과 상기 제2 얼굴 피부 움직임 사이의 차이에 기초하여, 광대근 및 입꼬리당김근 중, 적어도 하나에 더 가까운 상기 제1 부위로부터의 반사가 상기 제2 부위로부터의 반사보다 더 강력한 의사소통의 지표임을 결정하는 단계;상기 제1 부위로부터의 반사가 더 강력한 의사소통의 지표라는 결정에 기초하여, 상기 제1 부위로부터의 반사를 프로세싱하여 의사소통을 확인하고, 상기 제2 부위로부터의 반사는 무시하는 단계를 포함하는, 얼굴 피부 움직임을 해석하기 위한 방법.</claim></claimInfo><claimInfo><claim>40. 얼굴 피부 움직임을 해석하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 개인의 복수의 얼굴 영역 부위(facial region area)에 광을 투영하도록 - 상기 복수의 부위는 적어도 제1 부위와 제2 부위를 포함하며, 상기 제1 부위는 제2 부위보다 광대근(zygomaticus muscle) 및 입꼬리당김근(risorius muscle) 중, 적어도 하나에 더 가까움 - ; 상기 복수의 부위로부터 반사를 수신하도록; 상기 제1 부위로부터의 반사에 대응하는 제1 얼굴 피부 움직임과 상기 제2 부위로부터의 반사에 대응하는 제2 얼굴 피부 움직임을 검출하도록; 상기 제1 얼굴 피부 움직임과 상기 제2 얼굴 피부 움직임 사이의 차이에 기초하여, 상기 광대근 및 입꼬리당김근 중, 적어도 하나에 더 가까운 상기 제1 부위로부터의 반사가 상기 제2 부위로부터의 반사보다 더 강력한 의사소통의 지표임을 결정하도록; 상기 제1 부위로부터의 반사가 더 강력한 의사소통의 지표라는 결정에 기초하여, 상기 제1 부위로부터의 반사를 프로세싱하여 상기 의사소통을 확인하고, 상기 제2 부위로부터의 반사는 무시하도록 구성되는 것인, 얼굴 피부 움직임을 해석하기 위한 시스템.</claim></claimInfo><claimInfo><claim>41. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 미세 움직임에 기초하여 신원 검증 동작을 수행하게 하고, 상기 동작은:특정 개인과 기관의 계좌 간의 대응성(correspondence)을 검증하기 위한 참조 신호를 신뢰할 수 있는 방식으로 수신하는 단계 - 상기 참조 신호는 상기 특정 개인의 얼굴로부터 반사된 제1 코히어런트 광을 사용하여 검출된 참조 얼굴 미세 움직임에 기초하여 도출됨 - ;상기 특정 개인의 신원과 상기 얼굴 미세 움직임을 반영하는 참조 신호 간의 상관 관계를 보안 데이터 구조에 저장하는 단계;저장한 다음, 상기 기관을 통해, 상기 특정 개인을 인증하라는 요청을 수신하는 단계;상기 특정 개인의 제2 얼굴 미세 움직임으로부터 도출된 제2 코히어런트 광 반사를 나타내는 실시간 신호를 수신하는 단계;상기 실시간 신호를 상기 보안 데이터 구조에 저장된 참조 신호와 비교하여, 이에 의해 상기 특정 개인을 인증하는 단계; 및인증되면, 상기 특정 개인이 인증된다는 것을 상기 기관에 알리는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>42. 제41항에 있어서, 상기 인증은 상기 기관에서의 금융 거래와 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>43. 제42항에 있어서, 상기 금융 거래는, 자금 이체, 주식 매수, 주식 매도, 금융 데이터에 대한 액세스, 또는 상기 특정 개인의 계좌에 대한 액세스 중, 적어도 하나를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>44. 제41항에 있어서, 상기 실시간 신호를 수신하는 단계 및 상기 실시간 신호를 비교하는 단계는, 거래 동안 다수 회 발생하며, 상기 동작은 상기 알리는 단계 다음에 후속 차이가 검출되는 경우 미스매치를 보고하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>45. 제44항에 있어서, 상기 동작은 상기 실시간 신호와 연관된 개인이 상기 특정 개인이라는 확실성 레벨을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>46. 제45항에 있어서, 상기 확실성 레벨이 임계치 미만일 때, 상기 동작은 상기 거래를 종료하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>47. 제45항에 있어서, 상기 거래는 상기 특정 개인의 계좌에 대한 액세스를 제공하는 단계를 포함하는 금융 거래고, 확실성 레벨이 임계치 미만일 때, 상기 동작은 상기 특정 개인의 계좌로부터의 상기 실시간 신호와 연관된 상기 개인을 차단하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>48. 제41항에 있어서, 인증을 위한 상기 참조 신호는 적어도 하나의 단어의 발음 동안 근육 활성화에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>49. 제48항에 있어서, 상기 근육 활성화는, 광대근, 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 턱끝혀근(genioglossus muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)을 포함하는 적어도 하나의 특정 근육과 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>50. 제48항에 있어서, 상기 적어도 하나의 단어는 패스워드인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>51. 제48항에 있어서, 상기 동작은 발음을 위해 상기 특정 개인에게 상기 적어도 하나의 단어를 제시하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>52. 제51항에 있어서, 발음을 위해 상기 특정 개인에게 상기 적어도 하나의 단어를 제시하는 단계는, 상기 적어도 하나의 단어를 청각적으로 제시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>53. 제51항에 있어서, 발음을 위해 상기 특정 개인에게 상기 적어도 하나의 단어를 제시하는 단계는, 상기 적어도 하나의 단어를 텍스트로 제시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>54. 제41항에 있어서, 인증을 위한 상기 참조 신호는 하나 이상의 음절을 발음하는 동안 근육 활성화에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>55. 제41항에 있어서, 상기 기관은 온라인 활동과 연관되며, 인증되면, 상기 특정 개인에게 상기 온라인 활동을 수행하기 위한 액세스가 제공되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>56. 제55항에 있어서, 상기 온라인 활동은, 금융 거래, 내기(wagering) 세션, 계좌 액세스 세션, 게이밍 세션, 시험, 강의 또는 교육 세션 중, 적어도 하나인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>57. 제41항에 있어서, 상기 기관은 자원과 연관되고, 인증되면, 상기 특정 개인에게 상기 자원에 대한 액세스가 제공되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>58. 제57항에 있어서, 상기 자원은, 파일, 폴더, 데이터 구조, 컴퓨터 프로그램, 컴퓨터 코드, 또는 컴퓨터 설정 중, 적어도 하나인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>59. 얼굴 미세 움직임에 기초하여 신원 검증을 제공하기 위한 방법에 있어서,특정 개인과 기관의 계좌 간의 대응성(correspondence)을 검증하기 위한 참조 신호를 신뢰할 수 있는 방식으로 수신하는 단계 - 상기 참조 신호는 상기 특정 개인의 얼굴로부터 반사된 제1 코히어런트 광을 사용하여 검출된 참조 얼굴 미세 움직임에 기초하여 도출됨 - ;상기 특정 개인의 신원과 상기 얼굴 미세 움직임을 반영하는 상기 참조 신호 간의 상관 관계를 보안 데이터 구조에 저장하는 단계;저장한 다음, 상기 기관을 통해, 상기 특정 개인을 인증하라는 요청을 수신하는 단계;상기 특정 개인의 제2 얼굴 미세 움직임으로부터 도출된 제2 코히어런트 광 반사를 나타내는 실시간 신호를 수신하는 단계;상기 실시간 신호를 상기 보안 데이터 구조에 저장된 참조 신호와 비교하여, 이에 의해 상기 특정 개인을 인증하는 단계; 및인증되면, 상기 특정 개인이 인증된다는 것을 기관에 알리는 단계를 포함하는, 얼굴 미세 움직임에 기초하여 신원 검증을 제공하기 위한 방법.</claim></claimInfo><claimInfo><claim>60. 얼굴 미세 움직임에 기초하여 신원 검증을 제공하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 특정 개인과 기관의 계좌 간의 대응성(correspondence)을 검증하기 위한 참조 신호를 신뢰할 수 있는 방식으로 수신하도록 - 상기 참조 신호는 상기 특정 개인의 얼굴로부터 반사된 제1 코히어런트 광을 사용하여 검출된 참조 얼굴 미세 움직임에 기초하여 도출됨 - ; 상기 특정 개인의 신원과 상기 얼굴 미세 움직임을 반영하는 상기 참조 신호 간의 상관 관계를 보안 데이터 구조에 저장하도록; 저장한 다음, 상기 기관을 통해, 상기 특정 개인을 인증하라는 요청을 수신하도록; 상기 특정 개인의 제2 얼굴 미세 움직임으로부터 도출된 제2 코히어런트 광 반사를 나타내는 실시간 신호를 수신하도록; 상기 실시간 신호를 상기 보안 데이터 구조에 저장된 상기 참조 신호와 비교하여, 이에 의해 상기 특정 개인을 인증하도록; 그리고 인증되면, 상기 특정 개인이 인증된다는 것을 상기 기관에 알리도록 구성되는 것인, 신원 검증을 제공하기 위한 시스템.</claim></claimInfo><claimInfo><claim>61. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임에 기초하여 지속적인 인증을 위한 동작을 수행하게 하고, 상기 동작은:계속되는 전자 거래 동안, 제1 시간 기간 동안 제1 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제1 신호를 수신하는 단계; 상기 제1 신호를 사용하여, 상기 제1 얼굴 피부 미세 움직임과 연관된 특정 개인의 신원을 결정하는 단계;계속되는 전자 거래 동안, 제2 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제2 신호를 수신하는 단계 - 상기 제2 신호는 상기 제1 시간 기간 다음의 제2 시간 기간 동안 수신됨 - ;상기 제2 신호를 사용하여, 상기 특정 개인이 또한 상기 제2 얼굴 피부 미세 움직임과 연관된다고 결정하는 단계;계속되는 전자 거래 동안, 제3 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제3 신호를 수신하는 단계 - 상기 제3 신호는 상기 제2 시간 기간 다음의 제3 시간 기간 동안 수신됨 - ;상기 제3 신호를 사용하여, 상기 제3 얼굴 피부 미세 움직임이 상기 특정 개인과 연관되지 않는다고 결정하는 단계; 및 상기 제3 얼굴 피부 미세 움직임이 상기 특정 개인과 연관되지 않는다는 결정에 기초하여 액션을 개시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>62. 제61항에 있어서, 상기 계속되는 전자 거래는 전화 통화인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>63. 제61항에 있어서, 상기 제2 시간 기간 동안, 상기 동작은, 상기 특정 개인이 상기 제2 얼굴 피부 미세 움직임과 연관된다는 것을 확인하는 데이터를 연속적으로 출력하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>64. 제61항에 있어서, 상기 액션은, 상기 특정 개인이 상기 검출된 제3 얼굴 피부 미세 움직임에 대한 원인이 아니라는 표시를 제공하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>65. 제61항에 있어서, 상기 액션은 상기 제3 얼굴 피부 미세 움직임에 대한 원인인 또 다른 개인을 식별하기 위한 프로세스를 실행하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>66. 제61항에 있어서, 상기 제1 시간 기간, 상기 제2 시간 기간 및 상기 제3 시간 기간은 상기 계속되는 전자 거래와 연관된 단일 온라인 활동의 일부인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>67. 제66항에 있어서, 상기 온라인 활동은, 금융 거래, 내기(wagering) 세션, 계좌 액세스 세션, 게이밍 세션, 시험, 강의 또는 교육 세션 중, 적어도 하나인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>68. 제66항에 있어서, 상기 온라인 활동은 다수의 세션을 포함하고, 상기 동작은, 얼굴 피부 미세 움직임과 연관된 수신된 신호를 사용하여, 상기 특정 개인이 상기 다수의 세션 각각에 참여한다는 것을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>69. 제66항에 있어서, 상기 액션은, 상기 특정 개인 이외의 개인이 지금 상기 온라인 활동에 참여하고 있음을 상기 온라인 활동과 연관된 엔티티에 알리는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>70. 제66항에 있어서, 상기 액션은, 상기 특정 개인의 신원이 확인될 때까지 상기 온라인 활동에의 참여를 방지하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>71. 제61항에 있어서, 상기 제1 시간 기간, 상기 제2 시간 기간 및 상기 제3 시간 기간은 자원에 대한 액세스를 갖는 보안 세션의 일부인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>72. 제71항에 있어서, 상기 자원은, 파일, 폴더, 데이터베이스, 컴퓨터 프로그램, 컴퓨터 코드, 또는 컴퓨터 설정 중, 적어도 하나인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>73. 제71항에 있어서, 상기 액션은, 상기 특정 개인 이외의 개인이 상기 자원에 대한 액세스를 얻었다는 것을 상기 자원과 연관된 엔티티에 알리는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>74. 제71항에 있어서, 상기 액션은, 상기 자원에 대한 액세스를 종료하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>75. 제61항에 있어서, 상기 제1 시간 기간, 상기 제2 시간 기간, 및 상기 제3 기간은 단일 의사소통 세션의 일부이고, 상기 의사소통 세션은, 전화 통화, 텔레컨퍼런스, 비디오 컨퍼런스, 또는 실시간 가상 의사소통 중, 적어도 하나인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>76. 제75항에 있어서, 상기 액션은, 상기 특정 개인 이외의 개인이 상기 의사소통 세션에 합류했음을, 상기 의사소통 세션과 연관된 엔티티에 알리는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>77. 제61항에 있어서, 상기 특정 개인의 신원을 결정하는 단계는 복수의 참조 얼굴 피부 미세 움직임을 개인과 상관시키는 메모리에 액세스하는 단계 및 상기 제1 얼굴 피부 미세 움직임과 상기 복수의 참조 얼굴 피부 미세 움직임 중 적어도 하나의 참조 얼굴 피부 미세 움직임 사이의 매치를 결정하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>78. 제61항에 있어서, 상기 동작은, 스페클의 시간적 변화 및 강도 변화를 식별하기 위해, 수신된 코히어런트 광 반사를 나타내는 신호를 분석함으로써, 상기 제1 얼굴 피부 미세 움직임, 상기 제2 얼굴 피부 미세 움직임, 및 상기 제3 얼굴 피부 미세 움직임을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>79. 얼굴 피부 미세 움직임에 기초하여 지속적인 인증을 위한 방법에 있어서,계속되는 전자 거래 동안, 제1 시간 기간 동안 제1 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제1 신호를 수신하는 단계; 상기 제1 신호를 사용하여, 상기 제1 얼굴 피부 미세 움직임과 연관된 특정 개인의 신원을 결정하는 단계;계속되는 전자 거래 동안, 제2 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제2 신호를 수신하는 단계 - 상기 제2 신호는 제1 시간 기간 다음의 제2 시간 기간 동안 수신됨 - ;상기 제2 신호를 사용하여, 상기 특정 개인이 또한 상기 제2 얼굴 피부 미세 움직임과 연관된다고 결정하는 단계;계속되는 전자 거래 동안, 제3 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제3 신호를 수신하는 단계 - 상기 제3 신호는 제2 시간 기간 다음의 제3 시간 기간 동안 수신됨 - ;상기 제3 신호를 사용하여, 상기 제3 얼굴 피부 미세 움직임이 상기 특정 개인과 연관되지 않는다고 결정하는 단계; 및 상기 제3 얼굴 피부 미세 움직임이 상기 특정 개인과 연관되지 않는다는 결정에 기초하여 액션을 개시하는 단계를 포함하는, 얼굴 피부 미세 움직임에 기초하여 지속적인 인증을 위한 방법.</claim></claimInfo><claimInfo><claim>80. 얼굴 미세 움직임에 기초하여 신원 검증을 제공하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 계속되는 전자 거래 동안, 제1 시간 기간 동안 제1 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제1 신호를 수신하도록;  상기 제1 신호를 사용하여, 상기 제1 얼굴 피부 미세 움직임과 연관된 특정 개인의 신원을 결정하도록; 상기 계속되는 전자 거래 동안, 제2 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제2 신호를 수신하도록 - 상기 제2 신호는 상기 제1 시간 기간 다음의 제2 시간 기간 동안 수신됨 - ; 상기 제2 신호를 사용하여, 상기 특정 개인이 또한 상기 제2 얼굴 피부 미세 움직임과 연관된다고 결정하도록; 상기 계속되는 전자 거래 동안, 제3 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 제3 신호를 수신하도록 - 상기 제3 신호는 상기 제2 시간 기간 다음의 제3 시간 기간 동안 수신됨 - ; 상기 제3 신호를 사용하여, 상기 제3 얼굴 피부 미세 움직임이 상기 특정 개인과 연관되지 않는다고 결정하도록; 그리고  상기 제3 얼굴 피부 미세 움직임이 상기 특정 개인과 연관되지 않는다는 결정에 기초하여 액션을 개시하도록 구성되는 것인, 얼굴 미세 움직임에 기초하여 신원 검증을 제공하기 위한 시스템.</claim></claimInfo><claimInfo><claim>81. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임의 해석을 위한 임계 처리(thresholding) 동작을 수행하게 하고, 상기 동작은: 상기 얼굴 미세 움직임과 연관된 인식 가능한 발성 없이 얼굴 미세 움직임을 검출하는 단계;상기 얼굴 미세 움직임의 강도 레벨을 결정하는 단계;상기 결정된 강도 레벨을 임계치와 비교하는 단계;상기 강도 레벨이 상기 임계치를 초과할 때, 상기 얼굴 미세 움직임을 해석하는 단계; 및상기 강도 레벨이 임계치 아래로 떨어질 때, 상기 얼굴 미세 움직임을 무시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>82. 제81항에 있어서, 상기 동작은 상기 임계치의 조정을 가능하게 하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>83. 제81항에 있어서, 상기 임계치는 환경 조건에 따라 가변적인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>84. 제83항에 있어서, 상기 환경 조건은 백그라운드 노이즈 레벨을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>85. 제84항에 있어서, 상기 동작은 상기 백그라운드 노이즈 레벨을 나타내는 데이터를 수신하는 단계, 및 상기 수신된 데이터에 기초하여 상기 임계치에 대한 값을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>86. 제81항에 있어서, 상기 임계치는, 상기 얼굴 미세 움직임과 연관된 개인에 의해 관여되는 적어도 하나의 신체 활동에 의존하여, 가변적인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>87. 제86항에 있어서, 상기 적어도 하나의 신체 활동은 걷기, 달리기, 또는 호흡하기를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>88. 제87항에 있어서, 상기 동작은, 상기 개인이 관여하는 상기 적어도 하나의 신체 활동을 나타내는 데이터를 수신하는 단계, 및 상기 수신된 데이터에 기초하여 상기 임계치에 대한 값을 결정하는 단계를 더 포함하는 것이, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>89. 제81항에 있어서, 상기 임계치는 사용자에게 맞춤화되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>90. 제89항에 있어서, 특정 개인에 대한 개인화된 임계치를 수신하는 단계 및 상기 특정 개인과 연관된 설정에 상기 개인화된 임계치를 저장하는 단계를 더 포함하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>91. 제89항에 있어서, 특정 개인에 대한 복수의 임계치를 수신하는 단계를 더 포함하고, 상기 복수의 임계치 각각은 상이한 상태와 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>92. 제91항에 있어서, 상이한 상태 중 적어도 하나는 상기 특정 개인의 신체적 상태, 상기 특정 개인의 감정 상태, 또는 상기 특정 개인의 위치를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>93. 제92항에 있어서, 상기 동작은, 상기 특정 개인의 현재 상태를 나타내는 데이터를 수신하는 단계, 및 상기 수신된 데이터에 기초하여 상기 복수의 임계치 중 하나를 선택하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>94. 제91항에 있어서, 상기 얼굴 미세 움직임을 해석하는 단계는, 상기 얼굴 미세 움직임과 연관된 스피치를 합성하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>95. 제81항에 있어서, 상기 얼굴 미세 움직임을 해석하는 단계는 상기 얼굴 미세 움직임에 기초한 커맨드를 이해하고 실행하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>96. 제95항에 있어서, 상기 커맨드를 실행하는 단계는, 액션을 트리거하기 위한 신호를 생성하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>97. 제81항에 있어서, 상기 강도 레벨을 결정하는 단계는, 시간 기간 내의 일련의 미세 움직임과 연관된 값을 결정하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>98. 제81항에 있어서, 상기 임계치 아래로 떨어지는 강도 레벨을 갖는 상기 얼굴 미세 움직임은 해석 가능하지만 그럼에도 불구하고 무시되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>99. 얼굴 피부 미세 움직임의 임계 처리(thresholding) 해석을 위한 방법에 있어서,상기 얼굴 미세 움직임과 연관된 인식 가능한 발성 없이 얼굴 미세 움직임을 검출하는 단계;상기 얼굴 미세 움직임의 강도 레벨을 결정하는 단계;상기 결정된 강도 레벨을 임계치와 비교하는 단계;상기 강도 레벨이 상기 임계치를 초과할 때, 상기 얼굴 미세 움직임을 해석하는 단계; 및상기 강도 레벨이 임계치 아래로 떨어질 때, 상기 얼굴 미세 움직임을 무시하는 단계를 포함하는, 얼굴 피부 미세 움직임의 임계 처리 해석을 위한 방법.</claim></claimInfo><claimInfo><claim>100. 얼굴 피부 미세 움직임의 임계 처리(thresholding) 해석을 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 얼굴 미세 움직임과 연관된 인식 가능한 발성 없이 얼굴 미세 움직임을 검출하도록; 상기 얼굴 미세 움직임의 강도 레벨을 결정하도록; 상기 결정된 강도 레벨을 임계치와 비교하도록; 상기 강도 레벨이 상기 임계치를 초과할 때, 상기 얼굴 미세 움직임을 해석하도록; 그리고 상기 강도 레벨이 상기 임계치 아래로 떨어질 때, 상기 얼굴 미세 움직임을 무시하도록 구성되는 것인, 얼굴 피부 미세 움직임의 임계 처리 해석을 위한 시스템.</claim></claimInfo><claimInfo><claim>101. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 비발성(nonvocalized) 대화를 확립하기 위한 동작을 수행하게 하고, 상기 동작은:제1 웨어러블 디바이스 및 제2 웨어러블 디바이스를 통해 비발성 대화를 가능하게 하는 무선 통신 채널을 확립하는 단계 - 상기 제1 웨어러블 디바이스 및 상기 제2 웨어러블 디바이스는 각각 코히어런트 광원 및 코히어런트 광 반사로부터 얼굴 피부 미세 움직임을 검출하도록 구성된 광 검출기를 포함함 - ;상기 제1 웨어러블 디바이스에 의해, 인식 가능한 발성 없이 발생하는 제1 얼굴 피부 미세 움직임을 검출하는 단계;상기 제1 웨어러블 디바이스로부터 상기 제2 웨어러블 디바이스로 상기 무선 통신 채널을 통해 제1 통신을 송신하는 단계 - 상기 제1 통신은 상기 제1 얼굴 피부 미세 움직임으로부터 도출되고 상기 제2 웨어러블 디바이스를 통한 제시를 위해 송신됨 - ; 상기 제2 웨어러블 디바이스로부터 상기 무선 통신 채널을 통해 제2 통신을 수신하는 단계 - 상기 제2 통신은 상기 제2 웨어러블 디바이스에 의해 검출된 제2 얼굴 피부 미세 움직임으로부터 도출됨 - ; 및상기 제1 웨어러블 디바이스의 착용자에게 상기 제2 통신을 제시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>102. 제101항에 있어서, 상기 제1 통신은 상기 제1 얼굴 피부 미세 움직임을 반영하는 신호를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>103. 제101항에 있어서, 상기 동작은, 상기 제1 얼굴 피부 미세 움직임을 단어로 해석하는 단계를 더 포함하고, 상기 제1 통신은 상기 단어의 송신을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>104. 제101항에 있어서, 상기 제1 웨어러블 디바이스의 착용자에게 상기 제2 통신을 제시하는 단계는, 상기 제2 얼굴 피부 미세 움직임으로부터 도출된 단어를 합성하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>105. 제101항에 있어서, 상기 제1 웨어러블 디바이스의 착용자에게 상기 제2 통신을 제시하는 단계는, 상기 제2 얼굴 피부 미세 움직임으로부터 도출된 단어를 반영한 텍스트 출력을 제공하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>106. 제101항에 있어서, 제1 웨어러블 디바이스의 착용자에게 상기 제2 통신을 제시하는 단계는, 상기 제2 얼굴 피부 미세 움직임으로부터 도출된 적어도 하나의 얼굴 표정을 반영하는 그래픽 출력을 제공하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>107. 제106항에 있어서, 상기 그래픽 출력은 적어도 하나의 이모지를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>108. 제101항에 있어서, 상기 동작은, 상기 제2 웨어러블 디바이스가 상기 제1 웨어러블 디바이스에 근접하여 위치된다고 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>109. 제108항에 있어서, 상기 동작은, 상기 제1 웨어러블 디바이스와 상기 제2 웨어러블 디바이스 사이의 무선 통신 채널을 자동으로 확립하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>110. 제108항에 있어서, 상기 동작은, 상기 제2 웨어러블 디바이스와 비발성 대화를 확립하기 위한 제안을 상기 제1 웨어러블 디바이스를 통해 제시하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>111. 제101항에 있어서, 상기 동작은, 상기 제1 웨어러블 디바이스의 착용자가 상기 제2 웨어러블 디바이스의 착용자와 비발성 대화를 개시하려는 의도를 결정하는 단계, 및 상기 제1 웨어러블 디바이스와 상기 제2 웨어러블 디바이스 사이의 무선 통신 채널을 자동으로 확립하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>112. 제111항에 있어서, 상기 의도는 상기 제1 얼굴 피부 미세 움직임으로부터 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>113. 제101항에 있어서, 상기 무선 통신 채널은 상기 제1 웨어러블 디바이스와 상기 제2 웨어러블 디바이스 사이에 직접적으로 확립되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>114. 제101항에 있어서, 상기 무선 통신 채널은 적어도 하나의 중간 통신 디바이스를 통해 상기 제1 웨어러블 디바이스로부터 상기 제2 웨어러블 디바이스로 확립되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>115. 제114항에 있어서, 상기 적어도 하나의 통신 디바이스는 상기 제1 웨어러블 디바이스의 착용자와 연관된 제1 스마트폰, 상기 제2 웨어러블 디바이스의 착용자와 연관된 제2 스마트폰, 라우터, 또는 서버 중, 적어도 하나를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>116.  제101항에 있어서, 상기 제1 통신은 제1 언어로 발화된 제1 단어를 반영하는 신호를 포함하고, 상기 제2 통신은 제2 언어로 발화된 제2 단어를 반영하는 신호를 포함하고, 상기 제1 웨어러블 디바이스의 착용자에게 상기 제2 통신을 제시하는 단계는 상기 제2 단어를 상기 제1 언어로 번역하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>117. 제101항에 있어서, 상기 제1 통신은 상기 제1 웨어러블 디바이스의 착용자를 식별하는 세부 사항을 포함하고, 상기 제2 통신은 상기 제2 웨어러블 디바이스의 착용자를 식별하는 신호를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>118. 제101항에 있어서, 상기 제1 통신은 상기 제1 얼굴 피부 미세 움직임이 검출된 때를 표시하는 타임 스탬프를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>119. 비발성(nonvocalized) 대화를 확립하기 위한 방법에 있어서,제1 웨어러블 디바이스 및 제2 웨어러블 디바이스를 통해 비발성 대화를 가능하게 하는 무선 통신 채널을 확립하는 단계 - 상기 제1 웨어러블 디바이스 및 상기 제2 웨어러블 디바이스는 각각 코히어런트 광원 및 코히어런트 광 반사로부터 얼굴 피부 미세 움직임을 검출하도록 구성된 광 검출기를 포함함 - ;상기 제1 웨어러블 디바이스에 의해, 인식 가능한 발성 없이 발생하는 제1 얼굴 피부 미세 움직임을 검출하는 단계;상기 제1 웨어러블 디바이스로부터 상기 제2 웨어러블 디바이스로 상기 무선 통신 채널을 통해 제1 통신을 송신하는 단계 - 상기 제1 통신은 상기 제1 얼굴 피부 미세 움직임으로부터 도출되고 상기 제2 웨어러블 디바이스의 착용자에게 제시하기 위해 송신됨 - ; 상기 제2 웨어러블 디바이스로부터 상기 무선 통신 채널을 통해 제2 통신을 수신하는 단계 - 상기 제2 통신은 상기 제2 웨어러블 디바이스에 의해 검출된 제2 얼굴 피부 미세 움직임으로부터 도출됨 - ; 및상기 제1 웨어러블 디바이스의 착용자에게 상기 제2 통신을 제시하는 단계를 포함하는, 비발성 대화를 확립하기 위한 방법.</claim></claimInfo><claimInfo><claim>120. 비발성(nonvocalized) 대화를 확립하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 제1 웨어러블 디바이스 및 제2 웨어러블 디바이스를 통해 비발성 대화를 가능하게 하는 무선 통신 채널을 확립하도록 - 상기 제1 웨어러블 디바이스 및 상기 제2 웨어러블 디바이스는 각각 코히어런트 광원 및 코히어런트 광 반사로부터 얼굴 피부 미세 움직임을 검출하도록 구성된 광 검출기를 포함함 - ; 상기 제1 웨어러블 디바이스에 의해, 인식 가능한 발성 없이 발생하는 제1 얼굴 피부 미세 움직임을 검출하도록; 상기 제1 웨어러블 디바이스로부터 상기 제2 웨어러블 디바이스로 상기 무선 통신 채널을 통해 제1 통신을 송신하도록 - 상기 제1 통신은 상기 제1 얼굴 피부 미세 움직임으로부터 도출되고 상기 제2 웨어러블 디바이스의 착용자에게 제시하기 위해 송신됨 - ;  상기 제2 웨어러블 디바이스로부터 상기 무선 통신 채널을 통해 제2 통신을 수신하도록 - 상기 제2 통신은 상기 제2 웨어러블 디바이스에 의해 검출된 제2 얼굴 피부 미세 움직임으로부터 도출됨 - ; 그리고 상기 제1 웨어러블 디바이스의 착용자에게 상기 제2 통신을 제시하도록 구성되는 것인, 비발성 대화를 확립하기 위한 시스템.</claim></claimInfo><claimInfo><claim>121. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 해석될 콘텐츠의 발성 전에 콘텐츠 해석 동작을 개시하게 하고, 상기 동작은:얼굴 피부의 미세한 움직임을 나타내는 신호를 수신하는 단계; 원래의 언어로 적어도 하나의 단어를 발성하기 전에, 발화될 적어도 하나의 단어를 상기 신호로부터 결정하는 단계;상기 적어도 하나의 단어를 발성하기 전에, 상기 적어도 하나의 단어의 해석을 시작하는 단계; 및상기 적어도 하나의 단어가 발화될 때 상기 적어도 하나의 단어의 해석이 제시되도록 하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>122. 제121항에 있어서, 상기 해석은, 상기 원래의 언어로부터 상기 원래의 언어 이외의 적어도 하나의 타겟 언어로의 상기 적어도 하나의 단어의 번역인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>123. 제122항에 있어서, 상기 적어도 하나의 단어의 해석은, 상기 적어도 하나의 단어의, 상기 적어도 하나의 타겟 언어로 된 텍스트로의 전사(transcription)를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>124. 제122항에 있어서, 상기 적어도 하나의 단어의 해석은, 상기 적어도 하나의 타겟 언어로 된 상기 적어도 하나의 단어의 스피치 합성을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>125. 제122항에 있어서, 상기 적어도 하나의 타겟 언어의 선택을 수신하는 단계를 더 포함하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>126. 제125항에 있어서, 상기 적어도 하나의 타겟 언어의 선택은 복수의 타겟 언어의 선택을 포함하고, 상기 적어도 하나의 단어의 해석이 제시되도록 하는 단계는, 동시에 상기 복수의 언어로 제시하도록 하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>127. 제121항에 있어서, 상기 적어도 하나의 단어의 해석은, 상기 적어도 하나의 단어의, 상기 원래의 언어로 된 텍스트로의 전사를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>128. 제127항에 있어서, 상기 적어도 하나의 단어의 해석을 제시하는 단계는, 상기 얼굴 피부 미세 움직임과 연관된 개인의 비디오와 함께 상기 전사의 텍스트 디스플레이를 출력하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>129. 제121항에 있어서, 적어도 하나의 검출기를 통해, 상기 적어도 하나의 단어를 발성하는 사람의 얼굴 영역으로부터 코히어런트 광 반사의 신호를 수신하는 것이 발생하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>130. 제129항에 있어서, 상기 적어도 하나의 단어의 해석이 제시되도록 하는 단계는, 상기 적어도 하나의 단어가 상기 사람에 의해 발성되는 것과 동시에 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>131. 제121항에 있어서, 상기 적어도 하나의 단어의 해석이 제시되도록 하는 단계는, 웨어러블 스피커를 사용하여 상기 적어도 하나의 단어의 청각적(audible presentation) 제시를 출력하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>132. 제121항에 있어서, 적어도 하나의 단어의 해석이 제시되도록 하는 단계는, 네트워크를 통해 소리 신호를 송신하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>133. 제121항에 있어서, 상기 발화될 적어도 하나의 단어 다음에 발화될 적어도 하나의 예상 단어를 결정하고, 상기 적어도 하나의 단어의 발성 이전에 상기 적어도 하나의 예상 단어의 해석을 시작하는 단계; 및 상기 적어도 하나의 단어가 발화될 때 상기 적어도 하나의 단어의 제시 다음에 상기 적어도 하나의 예상 단어의 해석이 제시되도록 하는 단계를 더 포함하는, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>134. 제121항에 있어서, 상기 적어도 하나의 단어의 해석이 제시되도록 하는 단계는, 네트워크를 통해 상기 적어도 하나의 단어의 텍스트 번역을 송신하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>135. 제121항에 있어서, 상기 동작은, 상기 신호로부터 적어도 하나의 비언어적 감탄사를 결정하는 단계, 및 상기 비언어적 감탄사의 표현을 출력하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>136. 제121항에 있어서, 상기 신호로부터 적어도 하나의 단어를 결정하는 단계는, 스페클 분석을 사용하여 상기 얼굴 피부 미세 움직임을 해석하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>137. 제121항에 있어서, 얼굴 피부 미세 움직임을 나타내는 상기 신호는 상기 적어도 하나의 단어의 발성 이전의 근육 활성화에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>138. 제137항에 있어서, 상기 근육 활성화는, 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 턱끝혀근(genioglossus muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)을 포함하는 적어도 하나의 특정 근육과 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>139. 해석될 콘텐츠의 발성 이전에 콘텐츠 해석을 개시하기 위한 방법에 있어서,얼굴 피부의 미세한 움직임을 나타내는 신호를 수신하는 단계; 원래의 언어로 적어도 하나의 단어를 발성하기 전에, 발화될 적어도 하나의 단어를 상기 신호로부터 결정하는 단계;상기 적어도 하나의 단어를 발성하기 전에, 상기 적어도 하나의 단어의 해석을 시작하는 단계; 및상기 적어도 하나의 단어가 발화될 때 상기 적어도 하나의 단어의 해석이 제시되도록 하는 단계를 포함하는, 해석될 콘텐츠의 발성 이전에 콘텐츠 해석을 개시하기 위한 방법.</claim></claimInfo><claimInfo><claim>140. 해석될 콘텐츠의 발성 이전에 콘텐츠 해석을 개시하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 얼굴 피부의 미세한 움직임을 나타내는 신호를 수신하도록;  원래의 언어로 적어도 하나의 단어를 발성하기 전에, 발화될 적어도 하나의 단어를 상기 신호로부터 결정하도록; 상기 적어도 하나의 단어를 발성하기 전에, 상기 적어도 하나의 단어의 해석을 시작하도록; 그리고 상기 적어도 하나의 단어가 발화될 때 상기 적어도 하나의 단어의 해석이 제시되게 하도록 구성되는 것인, 해석될 콘텐츠의 발성 이전에 콘텐츠 해석을 개시하기 위한 시스템.</claim></claimInfo><claimInfo><claim>141. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 사적 음성 어시스턴스 동작을 수행하게 하고, 상기 동작은:어시스턴트에 대한 사적 요청을 반영하는 특정 얼굴 피부 미세 움직임을 나타내는 신호를 수신하는 단계 - 상기 사적 요청에 답변하는 것은, 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 개인의 식별을 요구함 - ; 상기 특정 개인과, 상기 특정 개인과 연관된 복수의 얼굴 피부 미세 움직임 사이의 상관 관계를 유지하는 데이터 구조에 액세스하는 단계; 상기 데이터 구조에서, 상기 특정 개인의 저장된 신원과 상기 특정 얼굴 피부 미세 움직임 사이의 상관 관계를 나타내는 매치를 검색하는 단계; 상기 데이터 구조 내의 매치의 존재의 결정에 응답하여, 상기 요청에 응답하는 제1 액션을 개시하는 단계 - 상기 제1 액션은 상기 특정 개인에게 고유한 정보에 대한 액세스를 가능하게 하는 것을 수반함 - ; 및 상기 데이터 구조 내에서 매치가 식별되지 않는 경우, 상기 제1 액션과는 상이한 제2 액션을 개시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>142. 제141항에 있어서, 상기 제2 액션은 비-사적 정보를 제공하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>143. 제141항에 있어서, 상기 제2 액션은 상기 특정 개인에게 고유한 정보에 대한 액세스가 거부된다는 알림을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>144. 제141항에 있어서, 상기 제2 액션은 상기 특정 개인에게 고유한 정보에 대한 액세스를 차단하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>145. 제141항에 있어서, 상기 제2 액션은 추가적인 데이터를 사용하여 상기 특정 개인을 인증하려고 시도하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>146. 제145항에 있어서, 상기 추가적인 데이터는 추가적인 검출된 얼굴 피부 미세 움직임을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>147. 제145항에 있어서, 상기 추가적인 데이터는 얼굴 피부 미세 움직임 이외의 데이터를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>148. 제141항에 있어서, 상기 매치가 식별되지 않을 때, 상기 동작은, 상기 특정 개인 이외의 또 다른 개인을 식별하기 위한 추가적인 액션을 개시하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>149. 제148항에 있어서, 상기 특정 개인 이외의 또 다른 개인의 식별에 응답하여, 상기 동작은, 상기 요청에 응답하는 제3 액션을 개시하는 것을 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>150. 제149항에 있어서, 상기 제3 액션은 상기 다른 개인에게 고유한 정보에 대한 액세스를 가능하게 하는 것을 수반하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>151. 제141항에 있어서, 상기 사적 요청은 소프트웨어 코드를 활성화하기 위한 것이고, 상기 제1 액션은 상기 소프트웨어 코드를 활성화하는 것이며, 상기 제2 액션은 상기 소프트웨어 코드의 활성화를 방지하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>152. 제141항에 있어서, 상기 사적 요청은 기밀 정보에 대한 것이며, 상기 동작은, 상기 특정 개인이 상기 기밀 정보에 액세스하기 위한 허가를 가진다고 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>153. 제141항에 있어서, 수신하는 단계, 액세스하는 단계 및 검색하는 단계는, 계속되는 세션 동안 반복적으로 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>154. 제153항에 있어서, 상기 계속되는 세션 동안의 제1 시간 기간 내에, 상기 특정 개인이 식별되고 상기 제1 액션이 개시되며, 상기 계속되는 세션 동안의 제2 시간 기간 내에, 상기 특정 개인이 식별되지 않고, 상기 제2 액션을 위하여 임의의 잔여 제1 액션이 종료되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>155. 제141항에 있어서, 상기 동작은, 상기 사적 요청을 하는 개인의 얼굴의 비입술 부분을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 동작시키는 단계를 더 포함하고, 상기 얼굴의 비입술 부분으로부터의 코히어런트 광 반사의 신호를 수신하는 것은 적어도 하나의 검출기를 통해 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>156. 제155항에 있어서, 상기 적어도 하나의 프로세서, 상기 적어도 하나의 코히어런트 광원, 및 상기 적어도 하나의 검출기는 상기 개인의 귀에 의해 지지되도록 구성된 웨어러블 하우징에 통합되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>157. 제155항에 있어서, 상기 동작은, 상기 수신된 신호를 분석하여 예비발성(prevocalization) 근육 동원을 결정하는 단계 및 상기 결정된 예비발성 근육 동원에 기초하여 상기 사적 요청을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>158. 제155항에 있어서, 상기 동작은 상기 사적 요청의 인식 가능한 발성 없이 상기 사적 요청을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>159. 사적 음성 어시스턴트를 동작시키기 위한 방법에 있어서,어시스턴트에 대한 사적 요청을 반영하는 특정 얼굴 피부 미세 움직임을 나타내는 신호를 수신하는 단계 - 상기 사적 요청에 답변하는 것은, 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 개인의 식별을 요구함 - ; 상기 특정 개인과, 상기 특정 개인과 연관된 복수의 얼굴 피부 미세 움직임 사이의 상관 관계를 유지하는 데이터 구조에 액세스하는 단계; 상기 데이터 구조에서, 상기 특정 개인의 저장된 신원과 상기 특정 얼굴 피부 미세 움직임 사이의 상관 관계를 나타내는 매치를 검색하는 단계; 상기 데이터 구조 내의 매치의 존재의 결정에 응답하여, 상기 요청에 응답하는 제1 액션을 개시하는 단계 - 상기 제1 액션은 상기 특정 개인에게 고유한 정보에 대한 액세스를 가능하게 하는 것을 수반함 - ; 및 상기 데이터 구조 내에서 매치가 식별되지 않는 경우, 상기 제1 액션과는 상이한 제2 액션을 개시하는 단계를 포함하는, 사적 음성 어시스턴트를 동작시키기 위한 방법.</claim></claimInfo><claimInfo><claim>160. 사적 음성 어시스턴트를 동작시키기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 어시스턴트에 대한 사적 요청을 반영하는 특정 얼굴 피부 미세 움직임을 나타내는 신호를 수신하도록 - 상기 사적 요청에 답변하는 것은, 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 개인의 식별을 요구함 - ; 상기 특정 개인과, 상기 특정 개인과 연관된 복수의 얼굴 피부 미세 움직임 사이의 상관 관계를 유지하는 데이터 구조에 액세스하도록;  상기 데이터 구조에서, 상기 특정 개인의 저장된 신원과 상기 특정 얼굴 피부 미세 움직임 사이의 상관 관계를 나타내는 매치(match)를 검색하도록;  상기 데이터 구조 내의 상기 매치의 존재의 결정에 응답하여, 상기 요청에 응답하는 제1 액션을 개시하도록 - 상기 제1 액션은 상기 특정 개인에게 고유한 정보에 대한 액세스를 가능하게 하는 것을 수반함 - ; 그리고 상기 데이터 구조 내에서 상기 매치가 식별되지 않는 경우, 상기 제1 액션과는 상이한 제2 액션을 개시하도록구성되는 것인, 사적 음성 어시스턴트를 동작시키기 위한 시스템.</claim></claimInfo><claimInfo><claim>161. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임으로부터 하위발성 음소(subvocalized phoneme)를 결정하기 위한 동작을 수행하게 하고, 상기 동작은:얼굴의 제1 영역과 얼굴의 제2 영역을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 제어하는 단계;상기 얼굴의 제1 영역에서 얼굴 피부의 제1 미세 움직임을 결정하기 위해, 상기 얼굴의 제1 영역으로부터 반사된 광에 대한 제1 패턴 분석을 수행하는 단계;상기 얼굴의 제2 영역에서 얼굴 피부의 제2 미세 움직임을 결정하기 위해, 상기 얼굴의 제2 영역으로부터 반사된 광에 대한 제2 패턴 분석을 수행하는 단계; 및상기 얼굴의 제1 영역에서의 얼굴 피부의 제1 미세 움직임과 상기 얼굴의 제2 영역에서의 얼굴 피부의 제2 미세 움직임을 사용하여, 적어도 하나의 하위발성 음소를 확인하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>162. 제161항에 있어서, 상기 제2 패턴 분석의 수행은 상기 제1 패턴 분석을 수행한 후에 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>163. 제161항에 있어서, 상기 제2 패턴 분석의 수행은 상기 제1 패턴 분석의 수행과 동시에 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>164. 제161항에 있어서, 상기 제1 영역은 상기 제2 영역으로부터 이격되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>165. 제161항에 있어서, 상기 적어도 하나의 하위발성 음소를 확인하는 것은, 음소의 시퀀스를 확인하는 것을 포함하며, 상기 동작은, 상기 음소의 시퀀스로부터 의미를 추출하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>166. 제165항에 있어서, 상기 음소의 시퀀스 내의 각 음소는 상기 제1 패턴 분석 및 상기 제2 패턴 분석으로부터 도출되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>167. 제165항에 있어서, 상기 동작은, 상기 음소의 시퀀스 내의 적어도 하나의 음소를 사적 음소로 식별하는 단계, 및 상기 적어도 하나의 사적 음소를 반영하는 오디오 출력의 생성을 생략하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>168. 제161항에 있어서, 상기 동작은, 공통 시간 기간 동안 상기 제1 미세 움직임 및 상기 제2 미세 움직임을 모두 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>169. 제161항에 있어서, 상기 동작은, 적어도 하나의 검출기를 통해, 상기 제1 광 반사 및 상기 제2 광 반사를 수신하는 단계를 더 포함하고, 상기 적어도 하나의 검출기 및 상기 적어도 하나의 코히어런트 광원은 웨어러블 하우징 내에 통합되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>170. 제161항에 있어서, 상기 적어도 하나의 코히어런트 광원을 제어하는 단계는, 상기 제1 영역 및 상기 제2 영역에 상이한 광 패턴을 투영하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>171. 제170항에 있어서, 상기 상이한 광 패턴은 복수의 광 스폿을 포함하며, 이에 의해 상기 얼굴의 제1 영역은 적어도 제1 광 스폿에 의해 조명되고, 상기 얼굴의 제2 영역은 상기 제1 광 스폿과는 상이한 적어도 제2 광 스폿에 의해 조명되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>172. 제161항에 있어서, 상기 적어도 하나의 코히어런트 광원을 제어하는 단계는, 상기 제1 영역과 상기 제2 영역을 공통 광 스폿으로 조명하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>173. 제161항에 있어서, 상기 얼굴 피부의 상기 제1 미세 움직임 및 상기 얼굴 피부의 상기 제2 미세 움직임은 동시적인 근육 동원에 대응하고, 상기 얼굴의 제1 영역에서 얼굴 피부의 결정된 제1 미세 움직임은, 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)으로부터 선택된 제1 근육의 동원에 대응하고, 상기 얼굴의 제2 영역에서 얼굴 피부의 결정된 제2 미세 움직임은, 상기 광대근, 상기 입둘레근, 상기 입꼬리당김근, 또는 상기 위입술콧방울올림근으로부터 선택된, 상기 제1 근육과는 상이한, 제2 근육의 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>174. 제161항에 있어서, 상기 동작은, 상기 얼굴 피부 미세 움직임과 연관된 개인의 기본 언어에 액세스하는 단계, 및 상기 기본 언어를 사용하여 상기 적어도 하나의 하위발성 음소로부터 의미를 추출하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>175. 제161항에 있어서, 상기 동작은, 합성된 음성을 사용하여 상기 적어도 하나의 하위발성 음소를 반영하는 오디오 출력을 생성하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>176. 제161항에 있어서, 상기 적어도 하나의 음소는 음소의 시퀀스를 포함하고, 상기 동작은, 상기 음소의 시퀀스와 연관된 운율(prosody)을 결정하는 단계, 및 상기 결정된 운율에 기초하여 의미를 추출하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>177. 제161항에 있어서, 상기 동작은, 상기 얼굴 피부 미세 움직임과 연관된 개인의 감정 상태를 결정하는 단계, 및 상기 적어도 하나의 하위발성 음소 및 상기 결정된 감정 상태로부터 의미를 추출하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>178. 제161항에 있어서, 상기 동작은, 채우기 위한 것(filler)의 일부로서 적어도 하나의 관련 없는 음소를 식별하는 단계 및 상기 관련 없는 음소를 반영하는 오디오 출력의 생성을 생략하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>179. 얼굴 피부 미세 움직임으로부터 하위발성 음소(subvocalized phoneme)를 결정하기 위한 방법에 있어서,얼굴의 제1 영역과 얼굴의 제2 영역을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 제어하는 단계;상기 얼굴의 제1 영역에서 얼굴 피부의 제1 미세 움직임을 결정하기 위해, 상기 얼굴의 제1 영역으로부터 반사된 광에 대한 제1 패턴 분석을 수행하는 단계;상기 얼굴의 제2 영역에서 얼굴 피부의 제2 미세 움직임을 결정하기 위해, 상기 얼굴의 제2 영역으로부터 반사된 광에 대한 제2 패턴 분석을 수행하는 단계; 및상기 얼굴의 제1 영역에서의 얼굴 피부의 제1 미세 움직임과 상기 얼굴의 제2 영역에서 얼굴 피부의 제2 미세 움직임을 사용하여, 적어도 하나의 하위발성 음소를 확인하는 단계를 포함하는, 얼굴 피부 미세 움직임으로부터 하위발성 음소를 결정하기 위한 방법.</claim></claimInfo><claimInfo><claim>180. 얼굴 피부 미세 움직임으로부터 하위발성 음소(subvocalized phoneme)를 결정하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 얼굴의 제1 영역과 상기 얼굴의 제2 영역을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 제어하도록; 상기 얼굴의 제1 영역에서 얼굴 피부의 제1 미세 움직임을 결정하기 위해, 상기 얼굴의 제1 영역으로부터 반사된 광에 대한 제1 패턴 분석을 수행하도록; 상기 얼굴의 제2 영역에서 얼굴 피부의 제2 미세 움직임을 결정하기 위해, 상기 얼굴의 제2 영역으로부터 반사된 광에 대한 제2 패턴 분석을 수행하도록; 그리고 상기 얼굴의 제1 영역에서 상기 얼굴 피부의 상기 제1 미세 움직임과 상기 얼굴의 제2 영역에서 상기 얼굴 피부의 상기 제2 미세 움직임을 사용하여, 적어도 하나의 하위발성 음소를 확인하도록구성되는 것인, 얼굴 피부 미세 움직임으로부터 하위발성 음소를 결정하기 위한 시스템.</claim></claimInfo><claimInfo><claim>181. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 표정의 합성된 표현을 생성하기 위한 동작을 수행하게 하고, 상기 동작은:얼굴의 일부를 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 제어하는 단계;광 검출기로부터 출력 신호를 수신하는 단계 - 상기 출력 신호는 상기 얼굴의 일부로부터 코히어런트 광의 반사에 대응함 - ;스페클 분석 기반 얼굴 피부 미세 움직임을 결정하기 위해 상기 출력 신호에 대해 스페클 분석을 적용하는 단계;상기 결정된 스페클 분석 기반 얼굴 피부 미세 움직임을 사용하여, 시간 기간 동안 예비발성된(prevocalized) 또는 발성된(vocalized) 적어도 하나의 단어를 식별하는 단계;상기 결정된 스페클 분석 기반 얼굴 피부 미세 움직임을 사용하여, 상기 시간 기간 동안 얼굴 표정에서 적어도 하나의 변화를 식별하는 단계; 및상기 시간 기간 동안, 상기 얼굴의 가상 표현이, 상기 적어도 하나의 단어의 오디오 제시와 함께, 상기 얼굴 표정의 적어도 하나의 변화를 모방하도록 하기 위한 데이터를 출력하는　단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>182. 제181항에 있어서, 상기 얼굴의 일부를 조명할 수 있는 방식으로 상기 적어도 하나의 코히어런트 광원을 제어하는 단계는, 상기 얼굴의 일부에 광 패턴을 투영하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>183. 제182항에 있어서, 상기 광 패턴은 복수의 스폿을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>184. 제182항에 있어서, 상기 얼굴의 일부는 뺨 피부를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>185. 제182항에 있어서, 상기 얼굴의 일부는 입술을 제외하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>186. 제181항에 있어서, 상기 광 검출기로부터의 출력 신호는 웨어러블 디바이스로부터 발산되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>187. 제181항에 있어서, 상기 광 검출기로부터의 출력 신호는 비-웨어러블 디바이스로부터 발산되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>188. 제181항에 있어서, 상기 결정된 스페클 분석 기반 얼굴 피부 미세 움직임은, 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 턱끝혀근(genioglossus muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle) 중, 적어도 하나의 동원과 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>189. 제181항에 있어서, 상기 시간 기간 동안 상기 얼굴 표정의 적어도 하나의 변화는 스피치 관련 얼굴 표정 및 스피치와 관련되지 않은 얼굴 표정을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>190. 제189항에 있어서, 상기 얼굴의 가상 표현은 출력 신호가 도출되는 개인의 아바타와 연관되고, 상기 얼굴 표정의 적어도 하나의 변화를 모방하는 것은, 상기 스피치 관련 얼굴 표정 및 상기 스피치와 관련되지 않은 얼굴 표정 중, 적어도 하나를 반영하는 상기 아바타에 대한 시각적 변화를 야기하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>191. 제190항에 있어서, 상기 아바타에 대한 시각적 변화는, 상기 아바타의 적어도 일부의 색상을 변화시키는 것을 수반하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>192. 제181항에 있어서, 상기 적어도 하나의 단어의 오디오 제시는, 개인의 레코딩에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>193. 제181항에 있어서, 상기 적어도 하나의 단어의 오디오 제시는, 합성된 음성에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>194. 제193항에 있어서, 상기 합성된 음성은 상기 출력 신호가 도출되는 개인의 음성에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>195. 제193항에 있어서, 상기 합성된 음성은 상기 출력 신호가 도출되는 개인에 의해 선택된 템플릿 음성에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>196. 제181항에 있어서, 상기 동작은, 적어도 부분적으로 상기 얼굴 피부 미세 움직임에 기초하여 상기 출력 신호가 도출되는 개인의 감정 상태를 결정하는 단계 및 상기 결정된 감정 상태를 반영하도록 상기 얼굴의 상기 가상 표현을 증강하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>197. 제181항에 있어서, 상기 동작은, 원하는 감정 상태의 선택을 수신하는 단계, 및 선택된 감정 상태를 반영하도록 상기 얼굴의 가상 표현을 증강하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>198. 제181항에 있어서, 상기 동작은, 바람직하지 않은 얼굴 표정을 식별하는 단계를 더 포함하고, 상기 가상 표현을 야기하기 위한 상기 출력된 데이터는 상기 바람직하지 않은 얼굴 표정을 야기하기 위한 데이터를 생략하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>199. 얼굴 표정의 합성된 표현을 생성하기 위한 방법에 있어서,얼굴의 일부를 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 제어하는 단계;광 검출기로부터 출력 신호를 수신하는 단계 - 상기 출력 신호는 상기 얼굴의 일부로부터 코히어런트 광의 반사에 대응함 - ;스페클 분석 기반 얼굴 피부 미세 움직임을 결정하기 위해 상기 출력 신호에 대해 스페클 분석을 적용하는 단계;상기 결정된 스페클 분석 기반 얼굴 피부 미세 움직임을 사용하여, 상기 시간 기간 동안 예비발성된(prevocalized) 또는 발성된(vocalized) 적어도 하나의 단어를 식별하는 단계;상기 결정된 스페클 분석 기반 얼굴 피부 미세 움직임을 사용하여, 상기 시간 기간 동안 얼굴 표정에서 적어도 하나의 변화를 식별하는 단계; 및상기 시간 기간 동안, 상기 얼굴의 가상 표현이, 상기 적어도 하나의 단어의 오디오 제시와 함께, 상기 얼굴 표정의 적어도 하나의 변화를 모방하도록 하기 위한 데이터를 출력하는 단계를 포함하는, 얼굴 표정의 합성된 표현을 생성하기 위한 방법.</claim></claimInfo><claimInfo><claim>200. 얼굴 표정의 합성된 표현을 생성하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 얼굴의 일부를 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 제어하도록; 광 검출기로부터 출력 신호를 수신하도록 - 상기 출력 신호는 상기 얼굴 일부로부터 코히어런트 광의 반사에 대응함 - ; 스페클 분석 기반 얼굴 피부 미세 움직임을 결정하기 위해 상기 출력 신호에 대한 스페클 분석을 적용하도록; 상기 결정된 스페클 분석 기반 얼굴 피부 미세 움직임을 사용하여, 시간 기간 동안 예비발성된(prevocalized) 또는 발성된(vocalized) 적어도 하나의 단어를 식별하도록; 상기 결정된 스페클 분석 기반 얼굴 피부 미세 움직임을 사용하여, 상기 시간 기간 동안 얼굴 표정에서 적어도 하나의 변화를 식별하도록; 그리고 상기 시간 기간 동안, 상기 얼굴의 가상 표현이, 상기 적어도 하나의 단어의 오디오 제시와 함께, 상기 얼굴 표정의 상기 적어도 하나의 변화를 모방하도록 하기 위한 데이터를 출력하도록 구성되는 것인, 얼굴 표정의 합성된 표현을 생성하기 위한 시스템.</claim></claimInfo><claimInfo><claim>201. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임에 기초하여 주의력 연관(attention-associated) 상호작용을 위한 동작을 수행하게 하고, 상기 동작은:개인의 얼굴 영역으로부터의 코히어런트 광의 반사에 기초하여 개인의 얼굴 피부 미세 움직임을 결정하는 단계;상기 얼굴 피부 미세 움직임을 사용하여, 상기 개인의 특정 관여 레벨을 결정하는 단계; 상기 개인과의 예상 상호작용과 연관된 데이터를 수신하는 단계; 상이한 제시 방식과 대안적인 관여 레벨을 반영하는 정보를 상관시키는 데이터 구조에 액세스하는 단계;상기 특정 관여 레벨 및 상기 상관 정보에 기초하여, 상기 예상 상호작용에 대한 특정 제시 방식을 결정하는 단계; 및상기 개인과의 후속 관여를 위한 상기 예상 상호작용과 상기 특정 제시 방식을 연관시키는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>202. 제201항에 있어서, 상기 동작은, 상기 결정된 특정 제시 방식에 따라 예상 상호작용을 반영하는 출력을 생성하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>203. 제201항에 있어서, 상기 동작은: 상기 개인의 얼굴의 비입술 부분을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 동작시키는 단계, 및 상기 얼굴의 비입술 부분으로부터 코히어런트 광의 반사를 나타내는 신호를 수신하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>204. 제203항에 있어서, 상기 동작은, 상기 얼굴의 비입술 부분으로부터의 코히어런트 광 반사에 대한 스페클 분석을 수행하여 상기 얼굴 피부 미세 움직임을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>205. 제201항에 있어서, 상기 특정 관여 레벨은 관여의 카테고리인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>206. 제201항에 있어서, 상기 특정 관여 레벨은 관여의 크기를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>207. 제201항에 있어서, 상기 특정 관여 레벨은 상기 개인이 대화, 생각, 및 휴식 중, 적어도 하나를 포함하는 활동에 관여되는 정도를 반영하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>208. 제207항에 있어서, 상기 동작은, 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)을 포함하는 근육의 그룹에서 적어도 하나의 근육의 동원에 대응하는 얼굴 피부 미세 움직임에 기초한 활동에 상기 개인이 관여되는 정도를 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>209. 제201항에 있어서, 상기 예상 상호작용과 연관된 상기 수신된 데이터는 수신 통화를 포함하며, 상기 연관된 상이한 제시 방식은 상기 수신 통화를 상기 개인에게 알리는 것, 및 상기 수신 통화를 음성 메일로 보내는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>210. 제201항에 있어서, 상기 예상 상호작용과 연관된 상기 수신된 데이터는 수신 문자 메시지를 포함하며, 상기 연관된 상이한 제시 방식은 실시간으로 상기 개인에게 상기 문자 메시지를 제시하는 것 및 상기 문자 메시지의 제시를 이후 시간으로 연기하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>211. 제201항에 있어서, 상기 예상 상호작용에 대한 상기 특정 제시 방식을 결정하는 단계는, 상기 예상 상호작용을 상기 개인에게 알리는 방법을 결정하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>212. 제211항에 있어서, 상기 개인에게 상기 예상 상호작용을 알리는 방법을 결정하는 단계는, 적어도 부분적으로 상기 개인에 의해 현재 사용되는 복수의 전자 디바이스의 식별에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>213. 제201항에 있어서, 상기 예상 상호작용과 연관된 상기 수신된 데이터는 상기 예상 상호작용의 중요도 레벨을 나타내며, 상기 특정 제시 방식은 적어도 부분적으로 상기 중요도 레벨에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>214. 제201항에 있어서, 상기 예상 상호작용과 연관된 상기 수신된 데이터는 상기 예상 상호작용의 긴급성 레벨을 나타내며, 상기 특정 제시 방식은 적어도 부분적으로 상기 긴급성 레벨에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>215. 제201항에 있어서, 상기 특정 제시 방식은 낮은 관여가 검출되는 시간 기간까지 콘텐츠의 제시를 연기하는 것을 포함하고, 상기 동작은, 후속 시간에 낮은 관여를 검출하는 단계 및 상기 후속 시간에 상기 콘텐츠를 제시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>216. 제201항에 있어서, 상기 동작은, 상기 얼굴 피부 미세 움직임을 사용하여 상기 개인이 또 다른 개인과의 대화에 관여되는지를 결정하는 단계, 상기 예상 상호작용이 상기 대화와 관련이 있는지 여부를 결정하는 단계를 더 포함하고, 상기 특정 제시 방식은 적어도 부분적으로 상기 예상 상호호작용의 상기 대화와의 관련성에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>217. 제216항에 있어서, 상기 동작은, 상기 얼굴 피부 미세 움직임을 사용하여 상기 대화의 주제를 결정하는 단계를 더 포함하고, 상기 예상 상호작용이 상기 대화와 관련이 있다고 결정하는 것은, 상기 대화의 주제 및 상기 예상 상호작용과 연관된 상기 수신된 데이터에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>218. 제216항에 있어서, 상기 예상 상호작용이 상기 대화와 관련이 있는 것으로 결정될 때, 상기 예상 상호작용을 위해 제1 제시 방식이 사용되고, 상기 예상 상호작용이 상기 대화와 관련이 없는 것으로 결정될 때, 상기 예상 상호작용을 위해 제2 제시 방식이 사용되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>219. 얼굴 피부 미세 움직임에 기초한 주의력 연관(attention-associated) 상호작용을 위한 방법에 있어서,개인의 얼굴 영역으로부터의 코히어런트 광의 반사에 기초하여 개인의 얼굴 피부 미세 움직임을 결정하는 단계;상기 얼굴 피부 미세 움직임을 사용하여, 상기 개인의 특정 관여 레벨을 결정하는 단계; 상기 개인과의 예상 상호작용과 연관된 데이터를 수신하는 단계; 상이한 제시 방식과 대안적인 관여 레벨을 반영하는 정보를 상관시키는 데이터 구조에 액세스하는 단계;상기 특정 관여 레벨 및 상기 상관 정보에 기초하여, 상기 예상 상호작용에 대한 특정 제시 방식을 결정하는 단계; 및상기 개인과의 후속 관여를 위한 상기 예상 상호작용과 상기 특정 제시 방식을 연관시키는 단계를 포함하는, 주의력 연관 상호작용을 위한 방법.</claim></claimInfo><claimInfo><claim>220. 얼굴 피부 미세 움직임에 기초한 주의력 연관(attention-associated) 상호작용을 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 개인의 얼굴 영역으로부터의 코히어런트 광의 반사에 기초하여 개인의 얼굴 피부 미세 움직임을 결정하도록; 상기 얼굴 피부 미세 움직임을 사용하여, 상기 개인의 특정 관여 레벨을 결정하도록;  상기 개인과의 예상 상호작용과 연관된 데이터를 수신하도록;  상이한 제시 방식과 대안적인 관여 레벨을 반영하는 정보를 상관시키는 데이터 구조에 액세스하도록; 상기 특정 관여 레벨 및 상기 상관 정보에 기초하여, 상기 예상 상호작용에 대한 특정 제시 방식을 결정하도록; 그리고 상기 개인과의 후속 관여를 위한 상기 예상 상호작용과 상기 특정 제시 방식을 연관시키도록 구성되는 것인, 주의력 연관 상호작용을 위한 시스템.</claim></claimInfo><claimInfo><claim>221. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 검출된 얼굴 피부 미세 움직임으로부터 음성 합성 동작을 수행하게 하고, 상기 동작은:제1 개인의 얼굴 영역으로부터의 광의 반사에 기초하여 제2 개인과 발화하는 제1 개인의 특정 얼굴 피부 미세 움직임을 결정하는 단계;얼굴 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하는 단계;데이터 구조에서 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 단어의 조회(lookup)를 수행하는 단계;상기 제2 개인의 선호 스피치 소비 특성(speech consumption characteristic)과 연관된 입력을 획득하는 단계; 상기 선호 스피치 소비 특성을 채택하는 단계; 및상기 채택된 선호 스피치 소비 특성을 사용하여, 상기 특정 단어의 청각적 출력을 합성하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>222. 제221항에 있어서, 상기 제1 개인 및 상기 제2 개인 중, 적어도 하나에 상기 선호 스피치 소비 특성을 변경하기 위한 사용자 인터페이스를 제시하는 단계를 더 포함하는, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>223. 제221항에 있어서, 상기 제2 개인의 상기 선호 스피치 소비 특성과 연관된 상기 입력을 획득하는 단계는, 상기 제1 개인으로부터 상기 입력을 수신하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>224. 제221항에 있어서, 상기 제2 개인의 상기 선호 스피치 소비 특성과 연관된 상기 입력을 획득하는 단계는, 상기 제2 개인으로부터 상기 입력을 수신하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>225. 제221항에 있어서, 상기 제2 개인의 상기 선호 스피치 소비 특성과 연관된 상기 입력을 획득하는 단계는, 상기 제2 개인에 대한 정보를 검색하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>226. 제225항에 있어서, 상기 제2 개인의 상기 선호 스피치 소비 특성과 연관된 상기 입력을 획득하는 단계는, 상기 제1 개인에 의해 착용된 이미지 센서에 의해 캡처된 이미지 데이터에 기초하여 상기 정보를 결정하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>227. 제221항에 있어서, 상기 제2 개인의 상기 선호 스피치 소비 특성과 연관된 상기 입력은 상기 제2 개인의 나이를 나타내는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>228. 제221항에 있어서, 상기 제2 개인의 상기 선호 스피치 소비 특성과 연관된 상기 입력은 상기 제2 개인과 연관된 환경 조건을 나타내는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>229. 제221항에 있어서, 상기 제2 개인의 상기 선호 스피치 소비 특성과 연관된 상기 입력은 상기 제2 개인의 청각 장애를 나타내는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>230. 제221항에 있어서, 상기 제2 개인은 복수의 개인 중 하나이고, 상기 동작은, 상기 복수의 개인으로부터 추가적인 입력을 획득하는 단계 및 상기 추가적인 입력에 기초하여 상기 복수의 개인을 분류하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>231. 제221항에 있어서, 상기 선호 스피치 소비 특성을 채택하는 단계는, 예상 얼굴 미세 움직임에 대해 음성 합성 제어를 사전 설정하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>232. 제221항에 있어서, 상기 선호 스피치 소비 특성과 연관된 상기 입력은 선호 스피치 속도를 포함하고, 상기 특정 단어의 상기 합성된 청각적 출력은 상기 선호 스피치 속도로 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>233. 제221항에 있어서, 상기 선호 스피치 소비 특성과 연관된 상기 입력은 스피치 볼륨을 포함하고, 상기 특정 단어의 상기 합성된 청각적 출력은 상기 선호 스피치 볼륨으로 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>234. 제221항에 있어서, 상기 선호 스피치 소비 특성과 연관된 상기 입력은 상기 특정 얼굴 피부 미세 움직임과 연관된 언어 이외의 타겟 스피치 언어를 포함하고, 상기 특정 단어의 상기 합성된 청각적 출력은 상기 타겟 스피치 언어로 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>235. 제221항에 있어서, 상기 선호 스피치 소비 특성과 연관된 상기 입력은 선호 음성을 포함하고, 상기 특정 단어의 상기 합성된 청각적 출력은 상기 선호 음성으로 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>236. 제235항에 있어서, 상기 선호 음성은, 유명 인사 음성, 악센트가 있는 음성, 또는 젠더 기반 음성 중, 적어도 하나인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>237. 제221항에 있어서, 상기 동작은, 상기 얼굴 미세 움직임에 기초하여 의도된 스피치의 제1 합성된 버전을 제시하는 단계 및 상기 선호 스피치 소비 특성과 조합하여 상기 얼굴 미세 움직임에 기초하여 스피치의 제2 합성된 버전을 제시하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>238. 제237항에 있어서, 상기 제1 합성된 버전 및 상기 제2 합성된 버전을 제시하는 단계는 상기 제1 개인에게 순차적으로 발생하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>239. 검출된 얼굴 미세 움직임으로부터 음성 합성을 수행하기 위한 방법에 있어서,제1 개인의 얼굴 영역으로부터의 광의 반사에 기초하여 제2 개인과 발화하는 제1 개인의 특정 얼굴 피부 미세 움직임을 결정하는 단계;얼굴 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하는 단계;데이터 구조에서 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 단어의 조회(lookup)를 수행하는 단계;상기 제2 개인의 선호 스피치 소비 특성(speech consumption characteristic)과 연관된 입력을 획득하는 단계; 상기 선호 스피치 소비 특성을 채택하는 단계; 및상기 채택된 선호 스피치 소비 특성을 사용하여, 상기 특정 단어의 청각적 출력을 합성하는 단계를 포함하는, 검출된 얼굴 미세 움직임으로부터 음성 합성을 수행하기 위한 방법.</claim></claimInfo><claimInfo><claim>240. 검출된 얼굴 미세 움직임으로부터 음성 합성을 수행하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 제1 개인의 얼굴 영역으로부터의 광의 반사에 기초하여 제2 개인과 발화하는 상기 제1 개인의 특정 얼굴 피부 미세 움직임을 결정하도록; 얼굴 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하도록; 상기 데이터 구조에서 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 단어의 조회(lookup)를 수행하도록; 상기 제2 개인의 선호 스피치 소비 특성(speech consumption characteristic)과 연관된 입력을 획득하도록; 상기 선호 스피치 소비 특성을 채택하도록; 그리고 상기 채택된 선호 스피치 소비 특성을 사용하여, 상기 특정 단어의 청각적 출력을 합성하도록 구성되는 것인, 검출된 얼굴 미세 움직임으로부터 음성 합성을 수행하기 위한 시스템.</claim></claimInfo><claimInfo><claim>241. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 예비발성(prevocalization)의 개인적 제시를 위한 동작을 수행하게 하고, 상기 동작은: 개인의 얼굴 영역으로부터 반사된 광에 대응하는 반사 신호를 수신하는 단계;상기 수신된 반사 신호를 사용하여 특정 얼굴 피부 미세 움직임과 연관된 인식 가능한 발성 없이 개인의 특정 얼굴 피부 미세 움직임을 결정하는 단계;얼굴 피부 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하는 단계;상기 데이터 구조에서 상기 특정 얼굴 피부 미세 움직임과 연관된 발성되지 않은 특정 단어의 조회를 수행하는 단계; 및상기 개인에 의한 상기 특정 단어의 발성 전에, 상기 개인에게, 상기 발성되지 않은 특정 단어의 청각적 제시를 야기하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>242. 제241항에 있어서, 상기 동작은, 미래의 사용을 위해 상기 발성되지 않은 특정 단어와 연관 데이터를 레코딩하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>243. 제242항에 있어서, 상기 데이터는 상기 발성되지 않은 특정 단어의 청각적 제시 또는 상기 발성되지 않은 특정 단어의 텍스트 제시 중, 적어도 하나를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>244. 제241항에 있어서, 상기 개인의 얼굴 영역으로부터 반사된 광은 코히어런트 광 반사를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>245. 제243항에 있어서, 상기 동작은, 상기 텍스트 제시에 구두점을 추가하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>246. 제241항에 있어서, 상기 동작은, 상기 개인으로부터의 입력에 기초하여 상기 발성되지 않은 특정 단어의 청각적 제시의 속도를 조정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>247. 제241항에 있어서, 상기 동작은, 상기 개인으로부터의 입력에 기초하여 상기 발성되지 않은 특정 단어의 청각적 제시의 볼륨을 조정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>248. 제241항에 있어서, 상기 청각적 제시를 야기하는 단계는, 상기 개인에 의해 착용되도록 구성된 개인 청각 디바이스로 오디오 신호를 출력하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>249. 제248항에 있어서, 상기 동작은, 상기 개인의 얼굴 영역의 조명을 가능하게 하는 방식으로 적어도 하나의 코히어런트 광원을 동작시키는 단계를 더 포함하고, 상기 적어도 하나의 코히어런트 광원은 상기 개인 청각 디바이스와 통합되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>250. 제241항에 있어서, 상기 발성되지 않은 특성 단어의 청각적 제시는 선택된 음성의 합성인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>251. 제250항에 있어서, 상기 선택된 음성은 상기 개인의 음성의 합성인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>252. 제250항에 있어서, 상기 선택된 음성은 상기 얼굴 피부 미세 움직임과 연관된 개인 이외의 또 다른 개인의 음성의 합성인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>253. 제241항에 있어서, 상기 발성되지 않은 특정 단어는 제1 언어로 된 발성 가능한 단어에 대응하고, 상기 청각적 제시는 상기 제1 언어와는 상이한 제2 언어로 상기 발성 가능한 단어의 합성을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>254. 제253항에 있어서, 상기 동작은, 상기 특정 얼굴 피부 미세 움직임을 상기 제2 언어로 된 복수의 발성 가능한 단어와 연관시키는 단계, 및 상기 복수의 발성 가능한 단어로부터 가장 적절한 발성 가능한 단어를 선택하는 단계를 더 포함하며, 상기 청각적 제시는 상기 제2 언어로 된 가장 적절한 발성 가능한 단어를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>255. 제241항에 있어서, 상기 동작은, 상기 특정 얼굴 피부 미세 움직임의 일부의 강도가 임계치 미만임을 결정하는 단계 및 상기 개인에게 연관된 피드백을 제공하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>256. 제241항에 있어서, 상기 발성되지 않은 특정 단어의 청각적 제시는 상기 개인에 의한 상기 특정 단어의 발성의 적어도 20밀리초 전에 상기 개인에게 제공되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>257. 제241항에 있어서, 상기 동작은, 검출된 트리거에 응답하여 상기 발성되지 않은 특정 단어의 청각적 제시를 중단하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>258. 제257항에 있어서, 상기 동작은, 상기 개인의 결정된 얼굴 피부 미세 움직임으로부터 상기 트리거를 검출하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>259. 예비발성(prevocalization)의 개인적 제시를 위한 방법에 있어서,개인의 얼굴 영역으로부터 반사된 광에 대응하는 반사 신호를 수신하는 단계;상기 수신된 반사 신호를 사용하여 특정 얼굴 피부 미세 움직임과 연관된 인식 가능한 발성 없이 개인의 특정 얼굴 피부 미세 움직임을 결정하는 단계;얼굴 피부 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하는 단계;상기 데이터 구조에서 상기 특정 얼굴 피부 미세 움직임과 연관된 발성되지 않은 특정 단어의 조회를 수행하는 단계; 및상기 개인에 의한 상기 특정 단어의 발성 전에, 상기 개인에게, 상기 발성되지 않은 특정 단어의 청각적 제시를 야기하는 단계를 포함하는, 예비발성의 개인적 제시를 위한 방법.</claim></claimInfo><claimInfo><claim>260. 예비발성(prevocalization)의 개인적 제시를 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 개인의 얼굴 영역으로부터 반사된 광에 대응하는 반사 신호를 수신하도록; 상기 수신된 반사 신호를 사용하여 특정 얼굴 피부 미세 움직임과 연관된 인식 가능한 발성 없이 개인의 상기 특정 얼굴 피부 미세 움직임을 결정하도록; 얼굴 피부 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하도록; 상기 데이터 구조에서 상기 특정 얼굴 피부 미세 움직임과 연관된 발성되지 않은 특정 단어의 조회(lookup)를 수행하도록; 그리고 상기 개인에 의한 상기 특정 단어의 발성 전에, 상기 개인에게, 상기 발성되지 않은 특정 단어의 청각적 제시가 이루어지게 하도록 구성되는 것인, 예비발성의 개인적 제시를 위한 시스템.</claim></claimInfo><claimInfo><claim>261. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임을 결정하기 위한 동작을 수행하게 하고, 상기 동작은:개인의 얼굴 영역에 복수의 광 스폿을 투영하기 위한 적어도 하나의 코히어런트 광원을 제어하는 단계 - 상기 복수의 광 스폿은 적어도 제1 광 스폿과 상기 제1 광 스폿으로부터 이격된 제2 광 스폿을 포함함 - ;상기 제1 광 스폿으로부터 반사된 광을 분석하여 제1 광 스폿 반사의 변화를 결정하는 단계;상기 제2 광 스폿으로부터 반사된 광을 분석하여 제2 광 스폿 반사의 변화를 결정하는 단계;상기 제1 스폿 반사와 상기 제2 스폿 반사에서 결정된 변화에 기초하여, 상기 얼굴 피부의 미세 움직임을 결정하는 단계;상기 제1 스폿 반사를 분석하는 것과 상기 제2 스폿 반사를 분석하는 것으로부터 도출된 상기 얼굴 피부 미세 움직임을 해석하는 단계; 및상기 해석의 출력을 생성하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>262. 제261항에 있어서, 상기 복수의 광 스폿은 제3 광 스폿 및 제4 광 스폿을 추가적으로 포함하며, 상기 제3 광 스폿 및 상기 제4 광 스폿 각각은 서로 이격되고 상기 제1 광 스폿 및 상기 제2 광 스폿으로부터 이격되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>263. 제262항에 있어서, 상기 얼굴 피부 미세 움직임은 상기 제1 스폿 반사 및 상기 제2 스폿 반사의 상기 결정된 변화 및 상기 제3 스폿 반사 및 상기 제4 스폿 반사의 변화에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>264. 제261항에 있어서, 상기 복수의 광 스폿은 적어도 16개의 이격된 광 스폿을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>265. 제261항에 있어서, 상기 복수의 광 스폿은 상기 개인의 비입술 영역에 투영되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>266. 제261항에 있어서, 상기 제1 스폿 반사의 변화 및 상기 제2 스폿 반사의 변화는 동시 근육 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>267. 제266항에 있어서, 상기 제1 스폿 반사 및 상기 제2 스폿 반사는 모두, 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 턱끝혀근(genioglossus muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)으로부터 선택된 단일 근육의 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>268. 제266항에 있어서, 상기 제1 스폿 반사는, 광대근, 입둘레근, 입꼬리당김근, 턱끝혀근, 또는 위입술콧방울올림근으로부터 선택된 근육의 동원에 대응하고, 상기 제2 스폿 반사는 상기 광대근, 상기 입둘레근, 상기 입꼬리당김근, 상기 턱끝혀근, 또는 상기 위입술콧방울올림근으로부터 선택된 또 다른 근육의 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>269. 제261항에 있어서, 상기 적어도 하나의 코히어런트 광원은 검출기와 연관되고, 상기 적어도 하나의 코히어런트 광원과 상기 검출기는 웨어러블 하우징 내에 통합되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>270. 제261항에 있어서, 상기 얼굴 피부 미세 움직임을 결정하는 단계는, 상기 제2 스폿 반사에서의 변화에 대해 상기 제1 스폿 반사에서의 변화를 분석하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>271. 제261항에 있어서, 상기 얼굴 영역에서 상기 결정된 얼굴 피부 미세 움직임은 100미크론 미만의 미세 움직임을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>272. 제261항에 있어서, 상기 해석은 상기 개인의 감정 상태를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>273. 제261항에 있어서, 상기 해석은 상기 개인의 심박수 및 호흡률 중, 적어도 하나를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>274. 제261항에 있어서, 상기 해석은 상기 개인의 식별을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>275. 제261항에 있어서, 상기 해석은 단어를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>276. 제275항에 있어서, 상기 출력은 상기 단어의 텍스트 제시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>277. 제275항에 있어서, 상기 출력은 상기 단어의 청각적 제시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>278. 제275항에 있어서, 상기 출력은 상기 단어와 연관된 운율 또는 얼굴 표정을 나타내는 메타데이터를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>279. 얼굴 피부 미세 움직임을 결정하기 위한 방법에 있어서,개인의 얼굴 영역에 복수의 광 스폿을 투영하기 위한 적어도 하나의 코히어런트 광원을 제어하는 단계 - 상기 복수의 광 스폿은 적어도 제1 광 스폿과 상기 제1 광 스폿으로부터 이격된 제2 광 스폿을 포함함 - ;상기 제1 광 스폿으로부터 반사된 광을 분석하여 제1 광 스폿 반사의 변화를 결정하는 단계;상기 제2 광 스폿으로부터 반사된 광을 분석하여 제2 광 스폿 반사의 변화를 결정하는 단계;상기 제1 스폿 반사와 상기 제2 스폿 반사에서 결정된 변화에 기초하여, 상기 얼굴 피부의 미세 움직임을 결정하는 단계;상기 제1 스폿 반사를 분석하는 것과 상기 제2 스폿 반사를 분석하는 것으로부터 도출된 상기 얼굴 피부 미세 움직임을 해석하는 단계; 및상기 해석의 출력을 생성하는 단계를 포함하는, 얼굴 피부 미세 움직임을 결정하기 위한 방법.</claim></claimInfo><claimInfo><claim>280. 얼굴 피부 미세 움직임을 결정하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 개인의 얼굴 영역에 복수의 광 스폿을 투영하기 위한 적어도 하나의 코히어런트 광원을 제어하도록 - 상기 복수의 광 스폿은 적어도 제1 광 스폿과 상기 제1 광 스폿으로부터 이격된 제2 광 스폿을 포함함 - ; 상기 제1 광 스폿으로부터 반사된 광을 분석하여 제1 광 스폿 반사의 변화를 결정하도록; 상기 제2 광 스폿으로부터 반사된 광을 분석하여 제2 광 스폿 반사의 변화를 결정하도록; 상기 제1 스폿 반사와 상기 제2 스폿 반사에서 결정된 변화에 기초하여, 상기 얼굴 피부의 미세 움직임을 결정하도록; 상기 제1 스폿 반사를 분석하는 것과 상기 제2 스폿 반사를 분석하는 것으로부터 도출된 상기 얼굴 피부 미세 움직임을 해석하도록; 그리고 상기 해석의 출력을 생성하도록 구성되는 것인, 얼굴 피부 미세 움직임을 결정하기 위한 시스템.</claim></claimInfo><claimInfo><claim>281. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 움직임에 기초하여 장애가 있는(impaired) 스피치를 해석하기 위한 동작을 수행하게 하고, 상기 동작은:개인이 복수의 단어를 발음하는 방식에 영향을 미치는 스피치 장애를 가진 상기 개인의 특정 얼굴 피부 움직임과 연관된 신호를 수신하는 단계; 상기 복수의 단어와, 개인이 복수의 단어를 발음하는 방식에 대응하는 복수의 얼굴 피부 움직임 사이의 상관 관계를 포함하는 데이터 구조에 액세스하는 단계; 상기 수신된 신호와 상기 상관 관계에 기초하여, 상기 특정 얼굴 피부 움직임과 연관된 특정 단어를 식별하는 단계; 및 제시를 위해 상기 특정 단어의 출력을 생성하는 단계 - 상기 출력은 상기 개인이 특정 단어를 발음하는 방법과는 상이함 - 를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>282. 제281항에 있어서, 상기 얼굴 피부 움직임은 얼굴 피부 미세 움직임인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>283. 제282항에 있어서, 상기 신호는 상기 개인의 얼굴의 비입술 부분으로부터의 광 반사를 검출하는 센서로부터 수신되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>284. 제283항에 있어서, 상기 얼굴 피부 미세 움직임은, 광대근(zygomaticus muscle), 턱끝혀근(genioglossus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)을 포함하는 근육의 그룹에서 적어도 하나의 근육의 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>285. 제281항에 있어서, 상기 신호는 비-코히어런트 광 반사를 측정하도록 구성된 이미지 센서로부터 수신되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>286. 제281항에 있어서, 상기 데이터 구조는 상기 개인의 고유한 얼굴 피부 움직임에 대해 개인화되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>287. 제281항에 있어서, 상기 동작은, 상기 데이터 구조를 채우기(populate) 위한 훈련 모델을 이용하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>288. 제281항에 있어서, 상기 특정 얼굴 피부 움직임은 상기 특정 단어의 발성과 연관되고, 상기 특정 단어의 발성은 기준을 따르지 않는 방식으로 된 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>289. 제281항에 있어서, 상기 특정 단어의 출력은 청각적인 것이며, 상기 개인의 스피치 장애를 정정하기 위해 사용되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>290. 제289항에 있어서, 상기 스피치 장애는 말을 더듬는 것이고, 상기 정정은 말더듬이 없는 형태로 발화된 상기 특정 단어를 출력하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>291. 제289항에 있어서, 상기 스피치 장애는 목이 쉼(hoarseness)이고, 상기 정정은 상기 특정 단어를 목 쉼 없는 형태로 출력하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>292. 제289항에 있어서, 상기 스피치 장애는 낮은 볼륨이고, 상기 정정은 상기 특정 단어를 상기 특정 단어가 발화된 것보다 높은 볼륨으로 출력하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>293. 제281항에 있어서, 상기 특정 단어의 출력은 텍스트로 된 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>294. 제293항에 있어서, 상기 동작은, 상기 특정 단어의 텍스트 출력에 구두점을 추가하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>295. 제281항에 있어서, 상기 데이터 구조는 이전에 상기 특정 단어를 발음한 상기 개인의 적어도 하나의 레코딩과 연관된 데이터를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>296. 제281항에 있어서, 상기 특정 얼굴 피부 움직임과 연관된 상기 식별된 특정 단어는 비발성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>297. 제281항에 있어서, 상기 특정 얼굴 피부 움직임은 상기 특정 단어의 하위발성과 연관되고, 상기 생성된 출력은 상기 개인에게 상기 하위발성된 단어의 사적인 청각적 제시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>298. 제281항에 있어서, 상기 특정 얼굴 피부 움직임은 상기 특정 단어의 하위발성과 연관되고, 상기 생성된 출력은 상기 하위발성된 단어의 비-사적인 청각적 제시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>299. 얼굴 움직임에 기초하여 장애가 있는(impaired) 스피치를 해석하기 위한 방법에 있어서,개인이 복수의 단어를 발음하는 방식에 영향을 미치는 스피치 장애를 가진 개인의 특정 얼굴 피부 움직임과 연관된 신호를 수신하는 단계; 상기 복수의 단어와, 개인이 복수의 단어를 발음하는 방식에 대응하는 복수의 얼굴 피부 움직임 사이의 상관 관계를 포함하는 데이터 구조에 액세스하는 단계; 상기 수신된 신호와 상기 상관 관계에 기초하여, 상기 특정 얼굴 피부 움직임과 연관된 특정 단어를 식별하는 단계; 및 제시를 위해 상기 특정 단어의 출력을 생성하는 단계 - 상기 출력은 상기 개인이 특정 단어를 발음하는 방법과는 상이함 - 를 포함하는, 얼굴 움직임에 기초하여 장애가 있는 스피치를 해석하기 위한 방법.</claim></claimInfo><claimInfo><claim>300. 얼굴 움직임에 기초하여 장애가 있는 스피치를 해석하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 개인이 복수의 단어를 발음하는 방식에 영향을 미치는 스피치 장애를 가진 개인의 특정 얼굴 피부 움직임과 연관된 신호를 수신하도록;  상기 복수의 단어와, 상기 개인이 상기 복수의 단어를 발음하는 방식에 대응하는 복수의 얼굴 피부 움직임 사이의 상관 관계를 포함하는 데이터 구조에 액세스하도록;  상기 수신된 신호와 상기 상관 관계에 기초하여, 상기 특정 얼굴 피부 움직임과 연관된 특정 단어를 식별하도록; 그리고  제시를 위해 상기 특정 단어의 출력을 생성하도록 - 상기 출력은 상기 개인이 상기 특정 단어를 발음하는 방법과는 상이함 - 구성되는 것인, 장애가 있는 스피치를 해석하기 위한 시스템.</claim></claimInfo><claimInfo><claim>301. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부로부터의 광 반사에 기초한 의사소통 진위(authenticity)에 대한 계속되는 검증을 위한 동작을 수행하게 하고, 상기 동작은:주체(subject)에 의한 의사소통(communication)을 나타내는 제1 데이터 스트림을 생성하는 단계 - 상기 의사소통은 지속기간을 가짐 - ;상기 의사소통의 지속기간 동안 캡처된 얼굴 피부 광 반사로부터 상기 주체의 신원을 입증하기 위한 제2 데이터 스트림을 생성하는 단계;상기 제1 데이터 스트림을 목적지로 송신하는 단계;상기 제2 데이터 스트림을 상기 목적지로 송신하는 단계를 포함하고, 상기 제2 데이터 스트림은, 상기 목적지에서 수신하면, 상기 제2 데이터 스트림이 상기 의사소통의 지속기간 동안 상기 의사소통이 상기 주체로부터 비롯된 것임을 반복적으로 확인하는 데 사용될 수 있게 하는 방식으로, 상기 제1 데이터 스트림과 상관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>302. 제301항에 있어서, 상기 의사소통이 상기 주체로부터 비롯된 것임을 확인하는 것은, 상기 의사소통에서의 모든 단어가 상기 주체로부터 비롯된 것임을 검증하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>303. 제301항에 있어서, 상기 의사소통이 상기 주체로부터 비롯된 것임을 확인하는 것은, 상기 대화의 지속기간 동안, 규칙적인 시간 간격으로 캡처된 스피치가 상기 주체로부터 비롯된 것임을, 상기 규칙적인 시간 간격으로 검증하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>304. 제301항에 있어서, 상기 제1 데이터 스트림 및 상기 제2 데이터 스트림은 공통 옴니버스 데이터 스트림에 혼합되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>305. 제301항에 있어서, 상기 목적지는 소셜 네트워크 서비스이고, 상기 제2 데이터 스트림은 소셜 네트워크 서비스가 진위 지표와 함께 상기 의사소통을 게시할 수 있게 하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>306. 제301항에 있어서, 상기 목적지는 상기 주체와의 실시간 거래에 관여되는 엔티티이고, 상기 제2 데이터 스트림은 상기 엔티티가 상기 의사소통의 지속기간 동안 상기 주체의 신원을 실시간으로 검증할 수 있게 하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>307. 제306항에 있어서, 상기 신원을 검증하는 것은, 상기 주체의 이름의 검증을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>308. 제306항에 있어서, 상기 신원을 검증하는 것은, 상기 주체가 상기 의사소통에서 제시된 단어를 말했다는 것을 상기 의사소통 전반에 걸쳐 적어도 주기적인 간격으로 검증하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>309. 제301항에 있어서, 상기 동작은, 상기 의사소통 전에 캡처된 얼굴 피부와 연관된 광 반사로부터 상기 주체의 생체 서명(biometric signature)을 결정하는 단계를 더 포함하고, 상기 주체의 신원은 상기 입증하는 얼굴 피부 광 반사 및 상기 생체 서명을 사용하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>310. 제309항에 있어서, 상기 생체 서명은 상기 얼굴 피부 내의 미세 정맥 패턴에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>311. 제309항에 있어서, 상기 생체 서명은 상기 주체에 의해 발화된 음소와 연관된 얼굴 피부 미세 움직임 시퀀스에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>312. 제301항에 있어서, 상기 제2 데이터 스트림은 상기 주체의 생동감 상태(liveliness status)를 나타내며, 상기 제2 데이터 스트림을 송신하는 것은, 상기 주체의 생동감 상태에 기초하여 상기 의사소통 진위의 검증을 할 수 있게 하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>313. 제301항에 있어서, 상기 제1 데이터 스트림은 상기 주체의 표정을 나타내고, 상기 제2 데이터 스트림은 상기 표정의 입증을 할 수 있게 하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>314. 제301항에 있어서, 상기 동작은, 패스프레이즈(passphrase)를 발성 또는 예비발성하는 상기 주체의 얼굴 피부 미세 움직임을 식별하는 것을 데이터 구조에 저장하는 단계, 및 상기 패스프레이즈의 발성 또는 예비발성에 기초하여 상기 주체를 식별하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>315. 제301항에 있어서, 상기 동작은, 얼굴 피부 미세 움직임의 패턴에 기초한 상기 주체의 프로파일을 데이터 구조에 저장하는 단계, 및 상기 패턴에 기초하여 상기 주체를 식별하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>316. 제301항에 있어서, 상기 제1 데이터 스트림은 상기 의사소통의 지속기간 동안 마이크에 의해 캡처된 소리와 연관된 신호에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>317. 제301항에 있어서, 상기 제1 데이터 스트림 및 상기 제2 데이터 스트림은 동일한 광 검출기로부터의 신호에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>318. 제317항에 있어서, 상기 주체에 의한 상기 의사소통을 나타내는 상기 제1 데이터 스트림을 생성하는 단계는, 상기 입증 얼굴 피부 광 반사에 기초하여 스피치를 재현(reproduce)하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>319. 얼굴 피부로부터의 광 반사에 기초한 의사소통 진위(authenticity)에 대한 계속되는 검증을 위한 방법에 있어서,주체(subject)에 의한 의사소통(communication)을 나타내는 제1 데이터 스트림을 생성하는 단계 - 상기 의사소통은 지속기간을 가짐 - ;상기 의사소통의 지속기간 동안 캡처된 얼굴 피부 광 반사로부터 상기 주체의 신원을 입증하기 위한 제2 데이터 스트림을 생성하는 단계;상기 제1 데이터 스트림을 목적지로 송신하는 단계;상기 제2 데이터 스트림을 상기 목적지로 송신하는 단계를 포함하고, 상기 제2 데이터 스트림은, 상기 목적지에서 수신하면, 상기 제2 데이터 스트림이 상기 의사소통의 지속기간 동안 상기 의사소통이 상기 주체로부터 비롯된 것임을 반복적으로 확인하는 데 사용될 수 있게 하는 방식으로, 상기 제1 데이터 스트림과 상관되는 것인, 의사소통 진위에 대한 계속되는 검증을 위한 방법.</claim></claimInfo><claimInfo><claim>320. 얼굴 피부 미세 움직임을 결정하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 주체(subject)에 의한 의사소통(communication)을 나타내는 제1 데이터 스트림을 생성하도록 - 상기 의사소통은 지속기간을 가짐 - ; 상기 의사소통의 지속기간 동안 캡처된 얼굴 피부 광 반사로부터 상기 주체의 신원을 입증하기 위한 제2 데이터 스트림을 생성하도록; 상기 제1 데이터 스트림을 목적지로 송신하도록; 상기 제2 데이터 스트림을 상기 목적지로 송신하도록 구성되고, 상기 제2 데이터 스트림은, 상기 목적지에서 수신하면, 상기 제2 데이터 스트림이 상기 의사소통 동안 상기 의사소통이 상기 주체로부터 비롯된 것임을 반복적으로 확인하는 데 사용될 수 있게 하는 방식으로, 상기 제1 데이터 스트림과 상관되는 것인, 얼굴 피부 미세 움직임을 결정하기 위한 시스템.</claim></claimInfo><claimInfo><claim>321. 노이즈 억제를 위한 머리 장착 가능 시스템에 있어서,착용자의 머리에 착용되도록 구성된 웨어러블 하우징;상기 웨어러블 하우징과 연관되고 상기 머리의 얼굴 영역을 향해 광을 투영하도록 구성된 적어도 하나의 코히어런트 광원;상기 웨어러블 하우징과 연관되고, 얼굴 피부 미세 움직임과 연관된 상기 얼굴 영역으로부터 코히어런트 광 반사를 수신하도록 그리고 연관된 반사 신호를 출력하도록 구성된 적어도 하나의 검출기; 및적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 반사 신호를 분석하여 상기 얼굴 영역 내의 상기 얼굴 피부 미세 움직임에 기초하여 스피치 타이밍을 결정하도록;  적어도 하나의 마이크로부터 오디오 신호를 수신하도록 - 상기 오디오 신호는 주변 소리와 함께 상기 착용자에 의해 발화된 단어의 소리를 포함함 - ; 상기 스피치 타이밍에 기초하여, 상기 반사 신호를, 상기 수신된 오디오 신호와 상관시켜, 상기 착용자에 의해 발화된 단어와 연관된 상기 오디오 신호의 부분을 결정하도록; 그리고  상기 착용자에 의해 발화된 단어를 포함하지 않는 상기 오디오 신호의 다른 부분의 출력은 생략하면서, 상기 착용자에 의해 발화된 단어와 연관된 상기 결정된 오디오 신호의 부분을 출력하도록 구성되는 것인, 노이즈 억제를 위한 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>322. 제321항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 오디오 신호의 결정된 부분을 레코드하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>323. 제321항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 오디오 신호의 다른 부분이 상기 착용자에 의해 발화된 단어와 연관되지 않음을 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>324. 제321항에 있어서, 상기 오디오 신호의 다른 부분은 주변 노이즈를 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>325. 제321항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 오디오 신호의 다른 부분이 상기 착용자 이외의 적어도 한 사람의 스피치를 포함한다고 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>326. 제325항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 적어도 한 사람의 스피치를 레코드하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>327. 제325항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 적어도 한 사람의 스피치를 출력하기 위한 착용자의 바람을 나타내는 입력을 수신하도록, 그리고 상기 적어도 한 사람의 스피치와 연관된 상기 오디오 신호의 부분을 출력하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>328. 제325항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 적어도 한 사람을 식별하도록, 상기 적어도 한 사람의 상기 착용자와의 관계를 결정하도록, 그리고 상기 결정된 관계에 기초하여 상기 적어도 한 사람의 스피치와 연관된 상기 오디오 신호의 부분을 자동으로 출력하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>329. 제321항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 오디오 신호 및 상기 반사 신호를 분석하여, 상기 착용자의 비언어적 감탄사를 식별하고 상기 출력으로부터 비언어적 감탄사를 생략하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>330. 제321항에 있어서, 상기 결정된 오디오 신호의 부분을 출력하는 것은, 상기 착용자에 의해 발화된 단어의 발성을 합성하는 것을 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>331. 제330항에 있어서, 상기 합성된 발성은 상기 착용자의 음성을 에뮬레이트하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>332. 제330항에 있어서, 상기 합성된 발성은 상기 착용자 이외의 특정 개인의 음성을 에뮬레이트하는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>333. 제330항에 있어서, 상기 합성된 발성은 상기 착용자에 의해 발화된 단어의 번역된 버전을 포함하는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>334. 제321항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 반사 신호를 분석하여 발화하려는 의도를 식별하고 상기 식별된 의도에 응답하여 적어도 하나의 마이크를 활성화하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>335. 제321항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 반사 신호를 분석하여 상기 착용자에 의해 발화된 단어에서 일시 정지(pause)를 식별하고 상기 식별된 일시 정지 동안 적어도 하나의 마이크를 비활성화하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>336. 제321항에 있어서, 적어도 하나의 마이크는 상기 머리 장착 가능 시스템과 무선으로 페어링되도록 구성된 통신 디바이스의 일부인 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>337. 제321항에 있어서, 적어도 하나의 마이크가 상기 웨어러블 하우징과 통합되고, 상기 웨어러블 하우징은, 착용될 때, 상기 적어도 하나의 코히어런트 광원이 상기 착용자의 뺨의 적어도 일부를 조명하기 위한 조준 방향을 취하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>338. 제337항에 있어서, 상기 웨어러블 하우징의 제1 부분은 상기 착용자의 외이도 내에 배치되도록 구성되고, 제2 부분은 상기 외이도 외부에 배치되도록 구성되며, 상기 적어도 하나의 마이크는 상기 제2 부분에 포함되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>339. 얼굴 피부 미세 움직임을 사용한 노이즈 억제를 위한 방법에 있어서,착용자의 머리의 얼굴 영역을 향해 광을 투영하도록 구성된 웨어러블 코히어런트 광원을 동작시키는 단계;얼굴 피부 미세 움직임과 연관된 상기 얼굴 영역으로부터 코히어런트 광 반사를 수신하도록 그리고 연관된 반사 신호를 출력하도록 구성된 적어도 하나의 검출기를 동작시키는 단계;상기 반사 신호를 분석하여 상기 얼굴 영역 내의 얼굴 피부 미세 움직임에 기초하여 스피치 타이밍을 결정하는 단계; 적어도 하나의 마이크로부터 오디오 신호를 수신하는 단계 - 상기 오디오 신호는 주변 소리와 함께 상기 착용자에 의해 발화된 단어의 소리를 포함함 - ;상기 스피치 타이밍에 기초하여, 상기 반사 신호를, 상기 수신된 오디오 신호와 상관시켜, 상기 착용자에 의해 발화된 단어와 연관된 상기 오디오 신호의 부분을 결정하는 단계; 및 상기 착용자에 의해 발화된 단어를 포함하지 않는 오디오 신호의 다른 부분의 출력은 생략하면서, 상기 착용자에 의해 발화된 단어와 연관된 상기 결정된 오디오 신호의 부분을 출력하는 단계를 포함하는, 얼굴 피부 미세 움직임을 사용한 노이즈 억제를 위한 방법. </claim></claimInfo><claimInfo><claim>340. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임을 사용하여 노이즈 억제를 위한 동작을 수행하게 하고, 상기 동작은:착용자의 머리의 얼굴 영역을 향해 광을 투영하도록 구성된 웨어러블 코히어런트 광원을 동작시키는 단계;얼굴 피부 미세 움직임과 연관된 상기 얼굴 영역으로부터 코히어런트 광 반사를 수신하도록 그리고 연관된 반사 신호를 출력하도록 구성된 적어도 하나의 검출기를 동작시키는 단계;상기 반사 신호를 분석하여 상기 얼굴 영역 내의 얼굴 피부 미세 움직임에 기초하여 스피치 타이밍을 결정하는 단계; 적어도 하나의 마이크로부터 오디오 신호를 수신하는 것 - 오디오 신호는 주변 소리와 함께 상기 착용자에 의해 발화된 단어의 소리를 포함함 - ;상기 스피치 타이밍에 기초하여, 상기 반사 신호를, 상기 수신된 오디오 신호와 상관시켜, 상기 착용자에 의해 발화된 단어와 연관된 상기 오디오 신호의 부분을 결정하는 단계; 및 상기 착용자에 의해 발화된 단어를 포함하지 않는 오디오 신호의 다른 부분의 출력은 생략하면서, 상기 착용자에 의해 발화된 단어와 연관된 상기 결정된 오디오 신호의 부분을 출력하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>341. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 무성 질문(silent question)에 대한 사적 답변을 제공하기 위한 동작을 수행하게 하고, 상기 동작은:인식 가능한 발성 없이 특정 얼굴 미세 움직임을 나타내는 신호를 수신하는 단계; 얼굴 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하는 단계;상기 수신된 신호를 사용하여, 상기 데이터 구조에서, 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 단어의 조회를 수행하는 단계;상기 특정 단어로부터 쿼리를 결정하는 단계;상기 쿼리에 대한 답변에 대한 조회를 수행하기 위해 적어도 하나의 데이터 구조에 액세스하는 단계; 및상기 쿼리에 대한 답변을 포함하는 신중한 출력을 생성하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>342. 제341항에 있어서, 상기 수신된 신호는 머리 장착 가능 광 검출기를 통해 획득되고 입 이외의 얼굴 부분의 피부 미세 움직임으로부터 도출되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>343. 제342항에 있어서, 상기 머리 장착 가능 광 검출기는 상기 얼굴 부분으로부터 비코히어런트 광 반사를 검출하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>344. 제342항에 있어서, 상기 동작은, 상기 얼굴 부분을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 제어하는 단계를 더 포함하고, 상기 머리 장착 가능 광 검출기는 상기 얼굴 부분으로부터 코히어런트 광 반사를 검출하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>345. 제342항에 있어서, 상기 신중한 출력은 적어도 하나의 이어버드를 통해 상기 머리 장착 가능 광 검출기의 착용자에게 전달되는 청각적 출력을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>346. 제342항에 있어서, 상기 신중한 출력은 상기 머리 장착 가능 광 검출기의 착용자에게 전달되는 텍스트 출력을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>347. 제342항에 있어서, 상기 신중한 출력은 상기 머리 장착 가능 광 검출기의 착용자에게 전달되는 촉각 출력을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>348. 제341항에 있어서, 상기 얼굴 미세 움직임은, 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 턱끝혀근(genioglossus muscle), 및 위입술콧방울올림근(levator labii superioris alaeque nasi muscle) 중, 적어도 하나의 근육 활성화에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>349. 제341항에 있어서, 상기 동작은, 이미지 데이터를 수신하는 단계를 더 포함하고, 상기 쿼리는 상기 이미지 데이터 및 상기 특정 단어의 비발성 조음(articulation)에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>350. 제349항에 있어서, 상기 이미지 데이터는 웨어러블 이미지 센서로부터 획득되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>351. 제349항에 있어서, 상기 이미지 데이터는 사람의 신원을 반영하고, 상기 쿼리는 상기 사람의 이름에 대한 것이며, 상기 신중한 출력은 상기 사람의 이름을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>352. 제349항에 있어서, 상기 이미지 데이터는 식용 제품의 정체(identity)를 반영하고, 상기 쿼리는 상기 식용 제품에 포함된 알레르겐(allergen)의 목록에 대한 것이며, 상기 신중한 출력은 상기 알레르겐의 목록을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>353. 제349항에 있어서, 상기 이미지 데이터는 무생물의 정체를 반영하고, 상기 쿼리는 상기 무생물에 대한 세부 사항에 대한 것이며, 상기 신중한 출력은 상기 무생물에 대한 요청된 세부 사항을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>354. 제341항에 있어서, 상기 동작은, 상기 특정 얼굴 미세 움직임을 사용하여 상기 특정 얼굴 미세 움직임과 연관된 개인을 인증하도록 시도하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>355. 제354항에 있어서,상기 개인이 인증될 때, 상기 동작은, 상기 쿼리에 대한 제1 답변을 제공하는 단계를 더 포함하고, 상기 제1 답변은 사적 정보를 포함하며;상기 개인이 인증되지 않을 때, 상기 동작은, 상기 쿼리에 대한 제2 답변을 제공하는 단계를 더 포함하고, 상기 제2 답변은 상기 사적 정보를 생략하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>356. 제354항에 있어서, 상기 동작은, 상기 개인과 연관된 개인 데이터에 액세스하는 단계 및 상기 개인 데이터를 사용하여 상기 쿼리에 대한 답변을 포함하는 상기 신중한 출력을 생성하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>357. 제356항에 있어서, 상기 개인 데이터는, 상기 개인의 나이, 상기 개인의 젠더, 상기 개인의 현재 위치, 상기 개인의 직업, 상기 개인의 집 주소, 상기 개인의 교육 레벨, 또는 상기 개인의 건강 상태 중, 적어도 하나를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>358. 제341항에 있어서, 상기 동작은, 상기 얼굴 미세 움직임을 사용하여 상기 얼굴 미세 움직임과 연관된 개인의 감정 상태를 결정하는 단계를 더 포함하고, 부분적으로 상기 결정된 감정 상태에 기초하여 상기 쿼리에 대한 답변이 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>359. 무성 질문(silent question)에 대한 사적 답변을 제공하기 위한 방법에 있어서,인식 가능한 발성 없이 특정 얼굴 미세 움직임을 나타내는 신호를 수신하는 단계; 얼굴 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하는 단계;상기 수신된 신호를 사용하여, 상기 데이터 구조에서, 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 단어의 조회를 수행하는 단계;상기 특정 단어로부터 쿼리를 결정하는 단계;상기 쿼리에 대한 답변에 대한 조회를 수행하기 위해 적어도 하나의 데이터 구조에 액세스하는 단계; 및상기 쿼리에 대한 답변을 포함하는 신중한 출력을 생성하는 단계를 포함하는, 무성 질문에 대한 사적 답변을 제공하기 위한 방법.</claim></claimInfo><claimInfo><claim>360. 무성 질문(silent question)에 대한 사적 답변을 제공하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 인식 가능한 발성 없이 특정 얼굴 미세 움직임을 나타내는 신호를 수신하도록;  얼굴 미세 움직임과 단어를 상관시키는 데이터 구조에 액세스하도록; 상기 수신된 신호를 사용하여, 상기 데이터 구조에서, 상기 특정 얼굴 피부 미세 움직임과 연관된 특정 단어의 조회를 수행하도록; 상기 특정 단어로부터 쿼리를 결정하도록; 상기 쿼리에 대한 답변에 대한 조회를 수행하기 위해 적어도 하나의 데이터 구조에 액세스하도록; 그리고 상기 쿼리에 대한 답변을 포함하는 신중한 출력을 생성하도록 구성되는 것인, 무성 질문에 대한 사적 답변을 제공하기 위한 시스템.</claim></claimInfo><claimInfo><claim>361. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임에 기초하여 제어 커맨드를 수행하게 하고, 상기 동작은:얼굴의 비입술 부분을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 동작시키는 단계;특정 비입술 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 특정 신호를 수신하는 단계;복수의 비입술 얼굴 피부 미세 움직임을 제어 커맨드와 연관시키는 데이터 구조에 액세스하는 단계;상기 데이터 구조에서, 상기 특정 비입술 얼굴 피부 미세 움직임과 연관된 상기 특정 신호와 연관된 특정 제어 커맨드를 식별하는 단계; 및상기 특정 제어 커맨드를 실행하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>362. 제361항에 있어서, 상기 얼굴 피부 미세 움직임은 상기 특정 제어 커맨드와 연관된 적어도 하나의 단어의 비발성 조음에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>363. 제361항에 있어서, 상기 얼굴 피부 미세 움직임은 적어도 하나의 특정 근육의 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>364. 제363항에 있어서, 상기 적어도 하나의 특정 근육은 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>365. 제361항에 있어서, 상기 얼굴 피부 미세 움직임은 상기 특정 제어 커맨드가 도출되는 얼굴 피부 미세 움직임의 시퀀스를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>366. 제361항에 있어서, 상기 얼굴 피부 미세 움직임은 비자발적 미세 움직임을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>367. 제366항에 있어서, 상기 비자발적 미세 움직임은 상기 특정 제어 커맨드를 발화하는 것을 생각하는 개인에 의해 트리거되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>368. 제366항에 있어서, 상기 비자발적 미세 움직임은 인간의 눈에 대해 눈에 띄지 않는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>369. 제361항에 있어서, 상기 적어도 하나의 코히어런트 광원을 동작시키는 단계는, 상기 얼굴의 비입술 부분을 조명하기 위한 강도 또는 광 패턴을 결정하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>370. 제361항에 있어서, 상기 특정 신호는 50Hz와 200Hz 사이의 속도로 수신되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>371. 제361항에 있어서, 상기 동작은, 상기 얼굴의 비입술 부분으로부터의 광 반사에 의해 생성된 스페클의 시간적 변화 및 강도 변화를 식별하기 위해 상기 특정 신호를 분석하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>372. 제361항에 있어서, 상기 동작은, 상기 특정 비입술 얼굴 피부 미세 움직임에 대한 맥락을 결정하기 위해 적어도 하나의 센서로부터 데이터를 프로세싱하는 단계, 및 상기 특정 제어 커맨드 및 상기 결정된 맥락에 기초하여 개시할 액션을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>373. 제361항에 있어서, 상기 특정 제어 커맨드는 원래의 언어로부터 상기 원래의 언어 이외의 적어도 하나의 타겟 언어로의 단어의 청각적 번역을 야기하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>374. 제361항에 있어서, 상기 특정 제어 커맨드는 미디어 플레이어 애플리케이션에서 액션을 야기하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>375. 제361항에 있어서, 상기 특정 제어 커맨드는 수신 통화와 연관된 액션을 야기하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>376. 제361항에 있어서, 상기 특정 제어 커맨드는 계속되는 통화(call)와 연관된 액션을 야기하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>377. 제361항에 있어서, 상기 특정 제어 커맨드는 문자 메시지와 연관된 액션을 야기하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>378. 제361항에 있어서, 상기 특정 제어 커맨드는 가상 개인 어시스턴트의 활성화를 야기하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>379. 얼굴 피부 미세 움직임에 기초하여 제어 커맨드를 실행하기 위한 방법에 있어서,얼굴의 비입술 부분을 조명할 수 있는 방식으로 적어도 하나의 코히어런트 광원을 동작시키는 단계;특정 비입술 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 특정 신호를 수신하는 단계;복수의 비입술 얼굴 피부 미세 움직임을 제어 커맨드와 연관시키는 데이터 구조에 액세스하는 단계;상기 데이터 구조에서, 상기 특정 비입술 얼굴 피부 미세 움직임과 연관된 상기 특정 신호와 연관된 특정 제어 커맨드를 식별하는 단계; 및상기 특정 제어 커맨드를 실행하는 단계를 포함하는, 얼굴 피부 미세 움직임에 기초하여 제어 커맨드를 실행하기 위한 방법.</claim></claimInfo><claimInfo><claim>380. 얼굴 피부 미세 움직임에 기초하여 제어 커맨드를 실행하기 위한 머리 장착 가능 시스템에 있어서,개인의 머리에 착용되도록 구성된 웨어러블 하우징;상기 웨어러블 하우징과 연관되고 상기 개인의 얼굴의 비입술 부분을 조명하도록 구성된 적어도 하나의 코히어런트 광원;상기 웨어러블 하우징과 연관되고, 특정 비입술 얼굴 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 특정 신호를 수신하도록 구성된 적어도 하나의 검출기; 및적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 복수의 비입술 얼굴 피부 미세 움직임을 제어 커맨드와 연관시키는 데이터 구조에 액세스하도록; 상기 데이터 구조에서, 상기 특정 비입술 얼굴 피부 미세 움직임과 연관된 상기 특정 신호와 연관된 특정 제어 커맨드를 식별하도록; 그리고 상기 특정 제어 커맨드를 실행하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>381. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 시간이 지남에 따른 신경 근육 활동의 변화를 검출하기 위한 동작을 개시하게 하고, 상기 동작은:과거(historical) 피부 미세 움직임과 연관된 코히어런트 광 반사로부터 신경 근육 활동의 기준선을 확립하는 단계;개인의 현재 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 현재 신호를 수신하는 단계; 상기 현재 피부 미세 움직임의, 상기 신경 근육 활동의 기준선으로부터의 편차를 식별하는 단계; 및상기 편차의 지표를 출력하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>382. 제381항에 있어서, 상기 동작은, 상기 개인 이외의 사람과 연관된 이전의 코히어런트 광 반사를 나타내는 과거 신호로부터 상기 기준선을 확립하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>383. 제381항에 있어서, 상기 동작은, 상기 개인과 연관된 이전의 코히어런트 광 반사를 나타내는 과거 신호로부터 상기 기준선을 확립하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>384. 제383항에 있어서, 상기 과거 신호는 하루보다 더 많은 시간 기간에 걸쳐 발생된 피부 미세 움직임에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>385. 제383항에 있어서, 상기 과거 신호는 상기 현재 신호의 수신 적어도 1년 전에 발생된 피부 미세 움직임에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>386. 제381항에 있어서, 상기 동작은, 웨어러블 광 검출기가 상기 개인에 의해 착용되는 동안, 상기 웨어러블 광 검출기로부터 상기 현재 신호를 수신하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>387. 제386항에 있어서, 상기 동작은, 상기 개인의 얼굴의 일부를 조명할 수 있는 방식으로 적어도 하나의 웨어러블 코히어런트 광원을 제어하는 단계를 더 포함하고, 상기 현재 신호는 상기 적어도 하나의 웨어러블 코히어런트 광원에 의해 조명되는 상기 얼굴의 일부로부터의 코히어런트 광 반사와 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>388. 제381항에 있어서, 상기 현재 피부 미세 움직임은 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 턱끝혀근(genioglossus muscle), 입꼬리당김근(risorius muscle), 및 위입술콧방울올림근(levator labii superioris alaeque nasi muscle) 중, 적어도 하나의 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>389. 제381항에 있어서, 상기 동작은, 비-웨어러블 광 검출기로부터 상기 현재 신호를 수신하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>390. 제389항에 있어서, 상기 현재 피부 미세 움직임과 연관된 상기 코히어런트 광 반사는 얼굴 피부 이외의 피부로부터 수신되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>391. 제390항에 있어서, 상기 얼굴 피부 이외의 피부는 상기 개인의 목, 손목, 또는 가슴으로부터의 피부인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>392. 제381항에 있어서, 상기 동작은, 상기 현재 피부 미세 움직임 이전의 시간 기간 동안 상기 개인의 피부 미세 움직임과 연관된 추가적인 신호를 수신하는 단계, 상기 현재 신호 및 상기 추가적인 신호에 기초하여 상기 개인의 신경 근육 활동의 변화의 추세를 결정하는 단계를 더 포함하고, 상기 지표는 상기 변화의 추세를 나타내는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>393. 제381항에 있어서, 상기 동작은, 신경 근육 활동의 상기 기준선으로부터 상기 현재 피부 미세 움직임의 편차에 대한 가능한 원인을 결정하는 단계를 더 포함하며, 상기 지표는 가능한 원인을 나타내는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>394. 제393항에 있어서, 상기 동작은, 상기 편차에 대한 가능한 원인의 추가적인 지표를 출력하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>395. 제393항에 있어서, 상기 동작은, 적어도 하나의 환경 조건을 나타내는 데이터를 수신하는 단계를 더 포함하고, 상기 편차에 대한 가능한 원인을 결정하는 단계는 상기 적어도 하나의 환경 조건 및 상기 식별된 편차에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>396. 제393항에 있어서, 상기 동작은, 상기 개인의 적어도 하나의 신체적 상태를 나타내는 데이터를 수신하는 단계를 더 포함하고, 상기 편차에 대한 가능한 원인을 결정하는 단계는 상기 적어도 하나의 신체적 상태 및 상기 식별된 편차에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>397. 제393항에 있어서, 상기 가능한 원인은 영향, 피로, 또는 스트레스 하에 있는 것을 포함하는 적어도 하나의 신체적 상태에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>398. 제393항에 있어서, 상기 가능한 원인은, 심장 마비, 다발성 경화증(Multiple Sclerosis; MS), 파킨슨병, 간질 또는 뇌졸중을 포함하는 적어도 하나의 건강 상태에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>399. 시간이 지남에 따른 신경 근육 활동의 변화를 검출하기 위한 방법에 있어서,개인의 과거(historical) 피부 미세 움직임과 연관된 코히어런트 광 반사로부터 신경 근육 활동의 기준선을 확립하는 단계;개인의 현재 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 신호를 수신하는 단계; 상기 현재 피부 미세 움직임의 상기 신경 근육 활동의 기준선으로부터의 편차를 식별하는 단계; 및상기 편차의 지표를 출력하는 단계를 포함하는, 신경 근육 활동의 변화를 검출하기 위한 방법. </claim></claimInfo><claimInfo><claim>400. 시간이 지남에 따른 신경 근육 활동의 변화를 검출하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 개인의 과거(historical) 피부 미세 움직임과 연관된 코히어런트 광 반사로부터 신경 근육 활동의 기준선을 확립하도록; 상기 개인의 현재 피부 미세 움직임과 연관된 코히어런트 광 반사를 나타내는 신호를 수신하도록;  상기 현재 피부 미세 움직임의, 상기 신경 근육 활동의 기준선으로부터의 편차를 식별하도록; 그리고 상기 편차의 지표를 출력하도록 구성되는 것인, 신경 근육 활동의 변화를 검출하기 위한 시스템. </claim></claimInfo><claimInfo><claim>401. 그래픽 콘텐츠를 투영하기 위한 그리고 비언어적 스피치를 해석하기 위한 이중 용도 머리 장착 가능 시스템에 있어서,개인의 머리에 착용되도록 구성된 웨어러블 하우징;상기 웨어러블 하우징과 연관되고, 상기 개인의 얼굴 영역에 그래픽 패턴으로 광을 투영하도록 구성된 적어도 하나의 광원 - 상기 그래픽 패턴은 정보를 시각적으로 전달하도록 구성됨 - ;상기 얼굴 영역으로부터 반사되는 광의 일부를 검출하기 위한 센서; 및적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 상기 센서로부터 출력 신호를 수신하도록; 상기 출력 신호로부터, 비언어화(non-verbalization)와 연관된 얼굴 피부 미세 움직임을 결정하도록; 그리고 상기 출력 신호를 프로세싱하여 상기 얼굴 피부 미세 움직임을 해석하도록구성되는 것인, 이중 용도 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>402. 제401항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 그래픽 패턴의 선택을 수신하도록, 그리고 상기 선택된 그래픽 패턴을 투영하기 위해 상기 적어도 하나의 광원을 제어하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>403. 제401항에 있어서, 상기 그래픽 패턴은 스페클 분석을 통해 상기 얼굴 피부 미세 움직임을 결정하는 데 사용하기 위한 복수의 스폿으로 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>404. 제401항에 있어서, 상기 투영된 광은 상기 개인 이외의 개인에게 인간의 눈을 통해 보이도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>405. 제401항에 있어서, 상기 투영된 광은 적외선 센서를 통해 볼 수 있는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>406. 제401항에 있어서, 상기 투영된 광원은 레이저를 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>407. 제401항에 있어서, 상기 적어도 하나의 프로세서는 시간이 지남에 따라 상기 그래픽 패턴을 변경하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>408. 제401항에 있어서, 상기 적어도 하나의 프로세서는 위치 정보를 수신하도록 그리고 상기 수신된 위치 정보에 기초하여 상기 그래픽 패턴을 변경하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>409. 제401항에 있어서, 상기 그래픽 패턴은 스크롤링 메시지를 포함하고 상기 적어도 하나의 프로세서는 상기 메시지가 스크롤되게 하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>410. 제401항에 있어서, 상기 적어도 하나의 프로세서는 또한, 트리거를 검출하도록 그리고 상기 트리거에 응답하여 상기 그래픽 패턴이 디스플레이되게 하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>411. 제401항에 있어서, 상기 출력 신호를 프로세싱하여 상기 얼굴 피부 미세 움직임을 해석하는 것은, 상기 얼굴 피부 미세 움직임으로부터 비언어화된 스피치를 결정하는 것을 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>412. 제411항에 있어서, 상기 적어도 하나의 프로세서는 상기 비언어화된 스피치로부터 상기 그래픽 패턴을 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>413. 제401항에 있어서, 상기 출력 신호를 프로세싱하여 상기 얼굴 피부 미세 움직임을 해석하는 것은, 상기 얼굴 피부 미세 움직임으로부터 감정 상태를 결정하는 것을 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>414. 제413항에 있어서, 상기 적어도 하나의 프로세서는 상기 결정된 감정 상태로부터 상기 그래픽 패턴을 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>415. 제401항에 있어서, 통합 오디오 출력을 더 포함하고, 상기 적어도 하나의 프로세서는 상기 오디오 출력을 통해 오디오를 출력하는 것을 수반하는 액션을 개시하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>416. 제401항에 있어서, 상기 적어도 하나의 프로세서는 트리거를 식별하도록 그리고 상기 트리거에 기초하여 상기 패턴을 수정하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>417. 제416항에 있어서, 상기 적어도 하나의 프로세서는 상기 트리거를 식별하기 위해 상기 얼굴 피부 미세 움직임을 분석하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>418. 제416항에 있어서, 상기 패턴을 수정하는 것은 상기 그래픽 패턴의 투영을 중단하는 것을 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>419. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 그래픽 콘텐츠를 투영하기 위한 그리고 비언어적 스피치를 해석하기 위한 동작을 수행하게 하고, 상기 동작은:개인의 얼굴 영역에 그래픽 패턴으로 광을 투영하도록 구성된 웨어러블 광원을 동작시키는 단계 - 상기 그래픽 패턴은 정보를 시각적으로 전달하도록 구성됨 - ;센서로부터, 상기 얼굴 영역으로부터 반사되는 광의 일부에 대응하는 출력 신호를 수신하는 단계;상기 출력 신호로부터, 비언어화(non-verbalization)와 연관된 얼굴 피부 미세 움직임을 결정하는 단계; 및상기 출력 신호를 프로세싱하여 상기 얼굴 피부 미세 움직임을 해석하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>420. 그래픽 콘텐츠를 투영하기 위한 그리고 비언어적 스피치를 해석하기 위한 방법에 있어서,개인의 얼굴 영역에 그래픽 패턴으로 광을 투영하는 단계 - 상기 그래픽 패턴은 정보를 시각적으로 전달하도록 구성됨 - ;상기 얼굴 영역으로부터 반사된 광을 수신하는 단계;상기 반사된 광으로부터, 비언어화(non-verbalization)와 연관된 피부 미세 움직임을 결정하는 단계; 및상기 출력 신호를 프로세싱하여 상기 얼굴 피부 미세 움직임을 해석하는 단계를 포함하는, 그래픽 콘텐츠를 투영하기 위한 그리고 비언어적 스피치를 해석하기 위한 방법.</claim></claimInfo><claimInfo><claim>421. 얼굴 피부 미세 움직임을 해석하기 위한 머리 장착 가능 시스템에 있어서,착용자의 머리에 착용되도록 구성된 하우징;상기 하우징과 통합되고, 상기 머리의 얼굴 영역으로부터 광 반사를 수신하도록 그리고 연관된 반사 신호를 출력하도록 구성된 적어도 하나의 검출기;상기 하우징과 연관되고, 상기 착용자에 의해 생성된 소리를 캡처하도록 그리고 연관된 오디오 신호를 출력하도록 구성된 적어도 하나의 마이크; 및상기 반사 신호와 상기 오디오 신호를 모두 사용하여 상기 착용자에 의해 조음된 단어에 대응하는 출력을 생성하도록 구성된, 하우징 내의 적어도 하나의 프로세서를 포함하는, 얼굴 피부 미세 움직임을 해석하기 위한 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>422. 제421항에 있어서, 상기 하우징과 통합되고, 상기 머리의 얼굴 영역을 향해 코히어런트 광을 투영하도록 구성된 적어도 하나의 광원을 더 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>423. 제421항에 있어서, 상기 적어도 하나의 프로세서는 상기 단어의 발성된 형태를 수신하도록 그리고 상기 적어도 하나의 단어의 발성 전에 상기 단어 중 적어도 하나를 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>424. 제421항에 있어서, 상기 착용자에 의해 조음된 단어는 비발성 방식으로 조음되는 적어도 하나의 단어를 포함하고, 상기 적어도 하나의 프로세서는 상기 오디오 신호를 사용하지 않고 상기 적어도 하나의 단어를 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>425. 제421항에 있어서, 상기 적어도 하나의 프로세서는 상기 반사 신호를 사용하여 인식 가능한 발성 없이 조음된 하나 이상의 단어를 식별하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>426. 제425항에 있어서, 상기 적어도 하나의 프로세서는 상기 반사 신호를 사용하여 특정 얼굴 피부 미세 움직임을 결정하도록, 그리고 상기 특정 얼굴 피부 미세 움직임을 상기 단어에 대응하는 참조 피부 미세 움직임과 상관시키도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>427. 제426항에 있어서, 상기 적어도 하나의 프로세서는 상기 오디오 신호를 사용하여 상기 참조 피부 미세 움직임을 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>428. 제421항에 있어서, 상기 하우징과 통합되고 오디오 출력을 생성하도록 구성된 스피커를 더 포함하는, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>429. 제421항에 있어서, 상기 출력은 상기 착용자에 의해 조음된 단어의 청각적 제시를 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>430. 제429항에 있어서, 상기 청각적 제시는 상기 착용자 이외의 개인의 음성의 합성을 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>431. 제429항에 있어서, 상기 청각적 제시는 상기 착용자의 음성의 합성을 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>432. 제431항에 있어서, 상기 착용자에 의해 조음된 단어는 제1 언어로 되어 있고, 상기 생성된 출력은 제2 언어로 발화된 단어를 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>433. 제431항에 있어서, 상기 적어도 하나의 프로세서는 인식 가능한 발성 없이 발화된 단어의 합성을 위해 상기 개인의 음성을 결정하기 위해 상기 오디오 신호를 사용하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>434. 제421항에 있어서, 상기 출력은 상기 착용자에 의해 조음된 단어의 텍스트 제시를 포함하는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>435. 제434항에 있어서, 상기 적어도 하나의 프로세서는 무선 통신 채널을 통해 원격 컴퓨팅 디바이스로 단어의 텍스트 제시가 송신되게 하도록 구성되는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>436. 제421항에 있어서, 상기 적어도 하나의 프로세서는 상기 생성된 출력이 상기 착용자에 의해 조음된 단어에 대응하는 제어 커맨드를 실행하기 위해 원격 컴퓨팅 디바이스로 송신되게 하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>437. 제421항에 있어서, 상기 적어도 하나의 프로세서는 또한, 상기 반사 신호를 분석하여 적어도 하나의 특정 근육의 동원에 대응하는 얼굴 피부 미세 움직임을 결정하도록 구성되는 것인, 머리 장착 가능 시스템.</claim></claimInfo><claimInfo><claim>438. 제437항에 있어서, 상기 적어도 하나의 특정 근육은 광대근(zygomaticus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)을 포함하는 것인, 머리 장착 가능 시스템. </claim></claimInfo><claimInfo><claim>439. 얼굴 피부 미세 움직임을 해석하기 위한 방법에 있어서,개인의 얼굴 피부 미세 움직임과 연관된 얼굴 영역으로부터 코히어런트 광 반사를 수신하는 단계;상기 광 반사와 연관된 반사 신호를 출력하는 단계;상기 개인에 의해 생성된 소리를 캡처하는 단계;상기 캡처된 소리와 연관된 오디오 신호를 출력하는 단계; 및상기 반사 신호 및 상기 오디오 신호를 모두 사용하여 상기 개인에 의해 조음된 단어에 대응하는 출력을 생성하는 단계를 포함하는, 얼굴 피부 미세 움직임을 해석하기 위한 방법. </claim></claimInfo><claimInfo><claim>440. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임을 해석하기 위한 동작을 수행하게 하고, 상기 동작은:개인의 얼굴 피부 미세 움직임과 연관된 얼굴 영역으로부터 코히어런트 광 반사를 수신하는 단계;상기 광 반사와 연관된 반사 신호를 출력하는 단계;상기 개인에 의해 생성된 소리를 캡처하는 단계;상기 캡처된 소리와 연관된 오디오 신호를 출력하는 단계; 및상기 반사 신호 및 상기 오디오 신호를 모두 사용하여 상기 개인에 의해 조음된 단어에 대응하는 출력을 생성하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>441. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임을 해석하기 위한 훈련 동작을 개시하게 하고, 상기 동작은: 제1 시간 기간 동안, 예비발성 얼굴 피부 미세 움직임을 나타내는 제1 신호를 수신하는 단계;상기 제1 시간 기간 다음의 제2 시간 기간 동안, 소리를 나타내는 제2 신호를 수신하는 단계; 상기 소리를 분석하여 상기 제2 시간 기간 동안 발화된 단어를 식별하는 단계;상기 제2 시간 기간 동안 발화된 단어를, 상기 제1 시간 기간 동안 수신된 상기 예비발성 얼굴 피부 미세 움직임과 상관시키는 단계; 상기 상관 관계를 저장하는 단계;제3 시간 기간 동안, 발성 없이 수신되는 얼굴 피부 미세 움직임을 나타내는 제3 신호를 수신하는 단계;상기 저장된 상관 관계를 사용하여 상기 제3 신호와 연관된 언어를 식별하는 단계; 및상기 언어를 출력하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>442. 제441항에 있어서, 상기 동작은, 추가적인 연장된 시간 기간에 걸쳐 발화된 추가적인 단어의, 상기 추가적인 연장된 시간 기간 동안 검출된 추가적인 예비발성 얼굴 피부 미세 움직임과의 추가적인 상관 관계를 식별하는 단계, 및 상기 추가적인 상관 관계를 사용하여 신경망을 훈련시키는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>443. 제441항에 있어서, 상기 출력된 언어는 상기 제2 시간 기간 동안 발화된 단어의 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>444. 제441항에 있어서, 상기 출력된 언어는 상기 제2 시간 기간 동안 발화된 단어와 상이한 적어도 하나의 단어의 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>445. 제444항에 있어서, 상기 적어도 하나의 단어는 상기 제2 시간 기간 동안 발화된 상기 적어도 하나의 단어와 유사한 음소 시퀀스를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>446. 제441항에 있어서, 상기 제1 신호는 제1 개인과 연관되고, 상기 제3 신호는 제2 개인과 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>447. 제441항에 있어서, 상기 제1 신호 및 상기 제3 신호는 동일한 개인과 연관되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>448. 제447항에 있어서, 상기 동작은, 상기 상관 관계를 사용하여 상기 개인과 연관된 사용자 프로필을 연속적으로 업데이트하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>449. 제441항에 있어서, 상기 상관 관계는 클라우드 기반 데이터 구조에 저장되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>450. 제441항에 있어서, 상기 동작은, 상기 얼굴 피부 미세 움직임과 연관된 개인의 음성 서명에 액세스하는 단계를 더 포함하고, 상기 소리를 분석하여 상기 제2 시간 기간 동안 발화된 단어를 식별하는 것은, 상기 음성 서명에 기초하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>451. 제441항에 있어서, 상기 제2 시간 기간은 상기 제1 시간 기간 후 350밀리초 미만으로 시작되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>452. 제451항에 있어서, 상기 제3 시간 기간은 상기 제2 시간 기간의 적어도 하루 후에 시작되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>453. 제441항에 있어서, 상기 제1 신호는 코히어런트 광 반사에 기초하고, 상기 동작은, 상기 광 반사가 수신되는 개인의 얼굴 영역에 코히어런트 광을 투영하기 위한 적어도 하나의 코히어런트 광원을 제어하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>454. 제453항에 있어서, 상기 제1 신호는 광 검출기로부터 수신되고, 상기 광 검출기 및 상기 코히어런트 광원은 웨어러블 어셈블리의 일부인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>455. 제454항에 있어서, 소리를 나타내는 상기 제2 신호는 상기 웨어러블 어셈블리의 일부인 마이크로부터 수신되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>456. 제441항에 있어서, 상기 언어를 출력하는 것은 상기 제3 신호와 연관된 단어를 텍스트로 제시하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>457. 제441항에 있어서, 상기 동작은, 상기 제3 신호와 연관된 언어를 식별하기 위한 확실성 레벨이 임계치 미만일 때, 상기 확실성 레벨을 높이기 위해 상기 제3 시간 기간 다음의 제4 시간 기간 동안 캡처된 추가적인 신호를 프로세싱하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>458. 제441항에 있어서, 상기 동작은, 제4 시간 기간 동안 추가적인 예비발성 얼굴 피부 미세 움직임을 나타내는 제4 신호를 수신하는 단계, 상기 제4 시간 기간 다음의 제5 시간 기간 동안 소리를 나타내는 제5 신호를 수신하는 단계, 및 상기 제4 신호를 사용하여 상기 제5 시간 기간에 발화된 단어를 식별하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>459. 얼굴 피부 미세 움직임을 해석하기 위한 방법에 있어서,제1 시간 기간 동안, 예비발성 얼굴 피부 미세 움직임을 나타내는 제1 신호를 수신하는 단계;상기 제1 시간 기간 다음의 제2 시간 기간 동안, 소리를 나타내는 제2 신호를 수신하는 단계; 상기 소리를 분석하여 상기 제2 시간 기간 동안 발화된 단어를 식별하는 단계;상기 제2 시간 기간 동안 발화된 단어를, 상기 제1 시간 기간 동안 수신된 예비발성 얼굴 피부 미세 움직임과 상관시키는 단계; 상기 상관 관계를 저장하는 단계;제3 시간 기간 동안, 발성 없이 수신되는 얼굴 피부 미세 움직임을 나타내는 제3 신호를 수신하는 단계;상기 저장된 상관 관계를 사용하여 상기 제3 신호와 연관된 언어를 식별하는 단계; 및 상기 언어를 출력하는 단계를 포함하는, 얼굴 피부 미세 움직임을 해석하기 위한 방법. </claim></claimInfo><claimInfo><claim>460. 얼굴 피부 미세 움직임을 해석하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 제1 시간 기간 동안, 예비발성 얼굴 피부 미세 움직임을 나타내는 제1 신호를 수신하도록; 상기 제1 시간 기간 다음의 제2 시간 기간 동안, 소리를 나타내는 제2 신호를 수신하도록;  상기 소리를 분석하여 상기 제2 시간 기간 동안 발화된 단어를 식별하도록; 상기 제2 시간 기간 동안 발화된 단어를, 상기 제1 시간 기간 동안 수신된 예비발성 얼굴 피부 미세 움직임과 상관시키도록;  상기 상관 관계를 저장하도록; 제3 시간 기간 동안, 발성 없이 수신되는 얼굴 피부 미세 움직임을 나타내는 제3 신호를 수신하도록; 상기 저장된 상관 관계를 사용하여 상기 제3 신호와 연관된 언어를 식별하도록; 그리고 상기 언어를 출력하도록 구성된 것인, 얼굴 피부 미세 움직임을 해석하기 위한 시스템. </claim></claimInfo><claimInfo><claim>461. 다기능 이어피스에 있어서,귀에 장착 가능한 하우징;소리를 제시하기 위해 상기 귀에 장착 가능한 하우징과 통합된 스피커;착용자의 얼굴의 피부를 향해 광을 투영하기 위해 상기 귀에 장착 가능한 하우징과 통합된 광원; 및상기 귀에 장착 가능한 하우징과 통합되고, 상기 착용자의 예비발성된 단어를 나타내는 얼굴 피부 미세 움직임에 대응하는 상기 피부로부터의 반사를 수신하도록 구성된 광 검출기를 포함하고,상기 다기능 이어피스는 상기 스피커를 통해 상기 소리를 동시에 제시하도록, 상기 피부를 향해 상기 광을 투영하도록, 그리고 상기 예비발성된 단어를 나타내는 상기 수신된 반사를 검출하도록 구성되는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>462. 제461항에 있어서, 상기 귀에 장착 가능한 하우징의 적어도 일부가 외이도에 배치되도록 구성되는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>463. 제461항에 있어서, 상기 귀에 장착 가능한 하우징의 적어도 일부가 귀 위에 또는 뒤에 배치되도록 구성되는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>464. 제461항에 있어서, 상기 반사로부터 도출된 상기 예비발성된 단어의 청각적 시뮬레이션을 스피커를 통해 출력하도록 구성된 적어도 하나의 프로세서를 더 포함하는, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>465. 제464항에 있어서, 상기 예비발성된 단어의 상기 청각적 시뮬레이션은 상기 착용자 이외의 개인의 음성의 합성을 포함하는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>466. 제464항에 있어서, 상기 예비발성된 단어의 상기 청각적 시뮬레이션은 상기 예비발성된 단어의 제2 언어가 아닌 제1 언어로 상기 예비발성된 단어의 합성을 포함하는 것인, 다기능 이어피스. </claim></claimInfo><claimInfo><claim>467. 제461항에 있어서, 상기 착용자의 스피치를 나타내는 오디오를 수신하기 위해 상기 귀에 장착 가능한 하우징과 통합된 마이크를 더 포함하는, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>468. 제461항에 있어서, 상기 광원은 상기 착용자의 얼굴의 피부를 향해 코히어런트 광의 패턴을 투영하도록 구성되고, 상기 패턴은 복수의 스폿을 포함하는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>469. 제461항에 있어서, 상기 광 검출기는 근육 섬유 동원을 나타내는 연관된 반사 신호를 출력하도록 구성되는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>470. 제469항에 있어서, 상기 동원된 근육 섬유는 광대근(zygomaticus muscle) 섬유, 입둘레근(orbicularis oris muscle) 섬유, 입꼬리당김근(risorius muscle) 섬유, 및 위입술콧방울올림근(levator labii superioris alaeque nasi muscle) 섬유 중, 적어도 하나를 포함하는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>471. 제461항에 있어서, 상기 얼굴 피부 미세 움직임을 결정하기 위해 상기 광 반사를 분석하도록 구성된 적어도 하나의 프로세서를 더 포함하는, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>472. 제471항에 있어서, 상기 분석은 스페클 분석을 포함하는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>473. 제471항에 있어서, 착용자의 스피치를 나타내는 오디오를 수신하기 위해 상기 귀에 장착 가능한 하우징과 통합된 마이크를 더 포함하고, 상기 적어도 하나의 프로세서는, 상기 마이크를 통해 수신된 오디오 및 상기 광 검출기를 통해 수신된 반사를 사용하여 얼굴 피부 미세 움직임을 발화된 단어와 상관시키도록 그리고 후속 얼굴 피부 미세 움직임으로부터 후속 예비발성된 단어를 결정하기 위해 신경망을 훈련시키도록 구성되는 것인, 다기능 이어피스. </claim></claimInfo><claimInfo><claim>474. 제471항에 있어서, 상기 적어도 하나의 프로세서는 상기 마이크를 활성화하기 위해 상기 결정된 얼굴 피부 미세 움직임에서 트리거를 식별하도록 구성되는 것인, 다기능 이어피스. </claim></claimInfo><claimInfo><claim>475. 제471항에 있어서, 통신 디바이스와 페어링하기 위한 페어링 인터페이스를 더 포함하고, 상기 적어도 하나의 프로세서는 상기 예비발성된 단어의 청각적 시뮬레이션을 상기 통신 디바이스로 송신하도록 구성되는 것인, 다기능 이어피스. </claim></claimInfo><claimInfo><claim>476. 제471항에 있어서, 통신 디바이스와 페어링하기 위한 페어링 인터페이스를 더 포함하고, 상기 적어도 하나의 프로세서는 상기 예비발성된 단어의 텍스트 제시를 상기 통신 디바이스로 송신하도록 구성되는 것인, 다기능 이어피스. </claim></claimInfo><claimInfo><claim>477. 제461항에 있어서, 상기 광원은 상기 착용자의 얼굴의 피부를 향해 코히어런트 광을 투영하도록 구성되는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>478. 제461항에 있어서, 상기 광원은 상기 착용자의 얼굴의 피부를 향해 비코히어런트 광을 투영하도록 구성되는 것인, 다기능 이어피스.</claim></claimInfo><claimInfo><claim>479. 다기능 이어피스를 동작시키기 위한 방법에 있어서,소리를 제시하기 위해 상기 다기능 이어피스와 연관된 귀에 장착 가능한 하우징과 통합된 스피커를 동작시키는 단계;착용자의 얼굴의 피부를 향해 광을 투영하기 위해 상기 귀에 장착 가능한 하우징과 통합된 광원을 동작시키는 단계;상기 귀에 장착 가능한 하우징과 통합되고, 상기 착용자의 예비발성된(prevocalized) 단어를 나타내는 얼굴 피부 미세 움직임에 대응하는 상기 피부로부터의 반사를 수신하도록 구성된 광 검출기를 동작시키는 단계; 및상기 스피커를 통해 상기 소리를 동시에 제시하고, 상기 피부를 향해 광을 투영하고, 상기 예비발성된 단어를 나타내는 상기 수신된 반사를 검출하는 단계를 포함하는, 다기능 이어피스를 동작시키기 위한 방법.</claim></claimInfo><claimInfo><claim>480. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 다기능 이어피스를 동작시키기 위한 동작을 수행하게 하고, 상기 동작은:소리를 제시하기 위해 상기 다기능 이어피스와 연관된 귀에 장착 가능한 하우징과 통합된 스피커를 동작시키는 단계;착용자의 얼굴의 피부를 향해 광을 투영하기 위해 상기 귀에 장착 가능한 하우징과 통합된 광원을 동작시키는 단계; 상기 귀에 장착 가능한 하우징과 통합되고, 상기 착용자의 예비발성된 단어를 나타내는 얼굴 피부 미세 움직임에 대응하는 상기 피부로부터의 반사를 수신하도록 구성된 광 검출기를 동작시키는 단계; 및상기 스피커를 통해 상기 소리를 동시에 제시하고, 상기 피부를 향해 광을 투영하고, 상기 예비발성된 단어를 나타내는 상기 수신된 반사를 검출하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>481. 소프트웨어 프로그램과의 통합을 위한 그리고 신경 근육 검출 디바이스가 상기 소프트웨어 프로그램과 인터페이스할 수 있도록 하기 위한 드라이버로서,상기 신경 근육 검출 디바이스로부터 비청각적 근육 활성화 신호를 수신하기 위한 입력 핸들러;상기 비청각적 활성화 신호 중 특정 신호를 상기 소프트웨어 프로그램에서의 대응하는 커맨드에 매핑하기 위한 조회(lookup) 컴포넌트;상기 입력 핸들러로부터 상기 비청각적 근육 활성화 신호를 수신하고, 상기 비청각적 근육 활성화 신호 중 특정 신호를 상기 조회 컴포넌트에 공급하고, 상기 대응하는 커맨드로서 출력을 수신하기 위한 신호 프로세싱 모듈; 및상기 대응하는 커맨드를 소프트웨어 프로그램에 전달하고, 이에 의해 상기 신경 근육 검출 디바이스에 의해 검출된, 비청각적 근육 활동에 기초하여, 상기 소프트웨어 프로그램 내에서의 제어를 가능하게 하는 통신 모듈을 포함하는, 드라이버.</claim></claimInfo><claimInfo><claim>482. 제481항에 있어서, 상기 입력 핸들러, 상기 조회 컴포넌트, 상기 신호 프로세싱 모듈, 및 상기 제어 코드는 상기 소프트웨어 프로그램에 임베딩된 것인, 드라이버.</claim></claimInfo><claimInfo><claim>483. 제481항에 있어서, 상기 입력 핸들러, 상기 조회 컴포넌트, 상기 신호 프로세싱 모듈, 및 상기 제어 코드는 상기 신경 근육 검출 디바이스에 임베딩된 것인, 드라이버.</claim></claimInfo><claimInfo><claim>484. 제481항에 있어서, 상기 입력 핸들러, 상기 조회 컴포넌트, 상기 신호 프로세싱 모듈, 및 상기 제어 코드는 애플리케이션 프로그래밍 인터페이스(application programming interface; API)에 임베딩된 것인, 드라이버.</claim></claimInfo><claimInfo><claim>485. 제483항에 있어서, 상기 신경 근육 검출 디바이스는 피부를 향해 광을 투영하도록 구성된 광원, 상기 피부로부터의 광의 반사를 감지하도록 구성된 광 검출기, 및 상기 감지된 광 반사에 기초하여 비청각적 근육 활성화 신호를 생성하도록 구성된 적어도 하나의 프로세서를 포함하는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>486. 제485항에 있어서, 상기 피부로부터의 상기 감지된 광 반사는 상기 피부의 미세 움직임에 대응하는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>487. 제481항에 있어서, 상기 조회 컴포넌트는 상기 비청각적 근육 활성화 신호를 상기 대응하는 커맨드와 상관시키는 훈련 데이터에 기초하여 미리 채워지는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>488. 제481항에 있어서, 상기 비청각적 근육 활성화 신호와 상기 대응하는 커맨드 사이의 상관 관계를 결정하기 위한 그리고 상기 조회 컴포넌트를 채우기 위한 훈련 모듈을 포함하는, 드라이버.</claim></claimInfo><claimInfo><claim>489. 제481항에 있어서, 상기 조회 컴포넌트는 조회 테이블을 포함하는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>490. 제481항에 있어서, 상기 조회 컴포넌트는 인공 지능 데이터 구조를 포함하는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>491. 제481항에 있어서, 상기 신경 근육 검출 디바이스는 피부를 향해 광을 투영하기 위한 광원, 상기 피부로부터의 광의 반사를 감지하도록 구성된 광 검출기, 및 상기 감지된 광의 반사에 기초하여 상기 비청각적 근육 활성화 신호를 생성하도록 구성된 적어도 하나의 프로세서를 포함하는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>492. 제491항에 있어서, 상기 광원은 코히어런트 광을 출력하도록 구성되는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>493. 제492항에 있어서, 상기 적어도 하나의 프로세서는 상기 코히어런트 광의 수신된 반사에 대한 스페클 분석에 기초하여 상기 비청각적 근육 활성화 신호를 생성하도록 구성되는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>494. 제481항에 있어서, 상기 조회 컴포넌트는 또한, 상기 비청각적 활성화 신호 중 상기 특정 신호의 일부를 텍스트에 매핑하도록 구성되는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>495. 제494항에 있어서, 상기 텍스트는 상기 비청각적 근육 활성화 신호로 나타나는 하위발성에 대응하는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>496. 제494항에 있어서, 상기 조회 컴포넌트는 또한, 상기 비청각적 근육 활성화 신호 중 상기 특정 신호의 일부를 상기 텍스트의 시각적 출력 및 상기 텍스트의 청각적 합성 중, 적어도 하나를 야기하기 위한 커맨드에 매핑하도록 구성되는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>497. 제481항에 있어서, 상기 신경 근육 검출 디바이스로 데이터를 송신하기 위한 복귀 경로 출력을 더 포함하는, 드라이버.</claim></claimInfo><claimInfo><claim>498. 제497항에 있어서, 상기 데이터는 상기 신경 근육 검출 디바이스를 통해 오디오, 햅틱 및 텍스트 출력 중, 적어도 하나를 야기하도록 구성되는 것인, 드라이버.</claim></claimInfo><claimInfo><claim>499. 제481항에 있어서, 데이터 송신 동안 발생하는 오류를 검출하고 정정하기 위한 검출 및 정정 루틴을 더 포함하는, 드라이버.</claim></claimInfo><claimInfo><claim>500. 제481항에 있어서, 상기 드라이버가 상기 소프트웨어 프로그램 이외의 애플리케이션에 구성되는 것을 허용하기 위한 구성 관리 루틴을 더 포함하는, 드라이버. </claim></claimInfo><claimInfo><claim>501. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 맥락 기반(context-driven) 얼굴 미세 움직임 동작을 수행하게 하고, 상기 동작은:제1 시간 기간 동안, 제1 얼굴 피부 미세 움직임과 연관된 제1 코히어런트 광 반사를 나타내는 제1 신호를 수신하는 단계; 상기 제1 코히어런트 광 반사를 분석하여 상기 제1 얼굴 피부 미세 움직임과 연관된 제1 복수의 단어를 결정하는 단계;상기 제1 얼굴 피부 미세 움직임이 발생한 제1 맥락 조건(contextual condition)을 나타내는 제1 정보를 수신하는 단계;제2 시간 기간 동안, 상기 제2 얼굴 피부 미세 움직임과 연관된 제2 코히어런트 광 반사를 나타내는 제2 신호를 수신하는 단계; 상기 제2 코히어런트 광 반사를 분석하여 상기 제2 얼굴 피부 미세 움직임과 연관된 제2 복수의 단어를 결정하는 단계;상기 제2 얼굴 피부 미세 움직임이 발생한 제2 맥락 조건을 나타내는 제2 정보를 수신하는 단계;복수의 액션을 복수의 맥락 조건과 상관시키는 복수의 제어 규칙에 액세스하는 단계 - 제1 제어 규칙은 상기 제1 맥락 조건에 기초하여 사적 제시의 형태를 규정하고, 제2 제어 규칙은 상기 제2 맥락 조건에 기초하여 비-사적 제시의 형태를 규정함- ; 상기 제1 정보를 수신하면, 상기 제1 제어 규칙을 구현하여 상기 제1 복수의 단어를 사적으로 출력하는 단계; 및상기 제2 정보를 수신하면, 상기 제2 제어 규칙을 구현하여 상기 제2 복수의 단어를 비-사적으로(non-privately) 출력하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>502. 제501항에 있어서, 제1 맥락 조건을 나타내는 상기 제1 정보는 상기 제1 얼굴 피부 미세 움직임이 사적인 생각과 연관된다는 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>503. 제501항에 있어서, 상기 제1 맥락 조건을 나타내는 상기 제1 정보는 상기 제1 얼굴 피부 미세 움직임이 사적인 상황에서 이루어진다는 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>504. 제501항에 있어서, 상기 제1 맥락 조건을 나타내는 상기 제1 정보는 상기 얼굴 미세 움직임을 생성하는 개인이 아래를 내려다보고 있다는 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>505. 제501항에 있어서, 상기 제2 맥락 조건을 나타내는 상기 제2 정보는 상기 제2 얼굴 피부 미세 움직임이 전화 통화 동안 이루어진다는 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>506. 제501항에 있어서, 상기 제2 맥락 조건을 나타내는 상기 제2 정보는 상기 제2 얼굴 피부 미세 움직임은 비디오 컨퍼런스 동안 이루어진다는 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>507. 제501항에 있어서, 상기 제2 맥락 조건을 나타내는 상기 제2 정보는 상기 제2 얼굴 피부 미세 움직임이 사회적 상호작용 동안 이루어진다는 표시를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>508. 제501항에 있어서, 상기 제1 정보 및 상기 제2 정보 중, 적어도 하나는 상기 얼굴 미세 움직임을 생성하는 개인의 활동을 나타내며, 상기 동작은, 상기 활동에 기초하여 상기 제1 제어 규칙 또는 상기 제2 제어 규칙 중 하나를 구현하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>509. 제501항에 있어서, 상기 제1 정보 및 상기 제2 정보 중, 적어도 하나는 상기 얼굴 미세 움직임을 생성하는 개인의 위치를 나타내며, 상기 동작은, 상기 위치에 기초하여 상기 제1 제어 규칙 또는 상기 제2 제어 규칙 중 하나를 구현하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>510. 제501항에 있어서, 상기 제1 정보 및 상기 제2 정보 중, 적어도 하나는 컴퓨팅 디바이스로 상기 얼굴 미세 움직임을 생성하는 개인의 관여 유형을 나타내며, 상기 동작은, 상기 관여 유형에 기초하여 상기 제1 제어 규칙 또는 상기 제2 제어 규칙 중 하나를 구현하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>511. 제501항에 있어서, 상기 제1 복수의 단어를 사적으로 출력하는 것은, 개인 소리 생성 디바이스로 오디오 출력을 생성하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>512. 제501항에 있어서, 상기 제1 복수의 단어를 사적으로 출력하는 것은, 개인 텍스트 생성 디바이스에 텍스트 출력을 생성하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>513. 제501항에 있어서, 상기 제2 복수의 단어를 비-사적으로 출력하는 것은, 모바일 통신 디바이스로 오디오 출력을 송신하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>514. 제501항에 있어서, 상기 제2 복수의 단어를 비-사적으로 출력하는 것은, 텍스트 출력이 공유 디스플레이에 제시되도록 하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>515. 제501항에 있어서, 상기 동작은, 사적 출력 모드와 비-사적 출력 모드 사이를 전환하기 위한 트리거를 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>516. 제515항에 있어서, 상기 동작은, 맥락 조건의 변화를 나타내는 제3 정보를 수신하는 단계를 더 포함하고, 상기 제3 정보로부터 상기 트리거가 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>517. 제515항에 있어서, 상기 동작은, 상기 제1 복수의 단어 또는 상기 제2 복수의 단어에 기초하여 상기 트리거를 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>518. 제515항에 있어서, 상기 동작은, 연관된 사용자 인터페이스로부터 출력 모드 선택을 수신하는 단계 및 상기 출력 모드 선택에 기초하여 상기 트리거를 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>519. 맥락 기반(context-driven) 얼굴 미세 움직임 출력을 생성하기 위한 방법에 있어서,제1 시간 기간 동안, 제1 얼굴 피부 미세 움직임과 연관된 제1 코히어런트 광 반사를 나타내는 제1 신호를 수신하는 단계; 상기 제1 코히어런트 광 반사를 분석하여 상기 제1 얼굴 피부 미세 움직임과 연관된 제1 복수의 단어를 결정하는 단계;상기 제1 얼굴 피부 미세 움직임이 발생한 제1 맥락 조건(contextual condition)을 나타내는 제1 정보를 수신하는 단계;제2 시간 기간 동안, 상기 제2 얼굴 피부 미세 움직임과 연관된 제2 코히어런트 광 반사를 나타내는 제2 신호를 수신하는 단계; 상기 제2 코히어런트 광 반사를 분석하여 상기 제2 얼굴 피부 미세 움직임과 연관된 제2 복수의 단어를 결정하는 단계;상기 제2 얼굴 피부 미세 움직임이 발생한 제2 맥락 조건을 나타내는 제2 정보를 수신하는 단계;복수의 액션을 복수의 맥락 조건과 상관시키는 복수의 제어 규칙에 액세스하는 단계 - 제1 제어 규칙은 상기 제1 맥락 조건에 기초하여 사적 제시의 형태를 규정하고, 제2 제어 규칙은 상기 제2 맥락 조건에 기초하여 비-사적 제시의 형태를 규정함- ; 상기 제1 정보를 수신하면, 상기 제1 제어 규칙을 구현하여 상기 제1 복수의 단어를 사적으로 출력하는 단계; 및상기 제2 정보를 수신하면, 상기 제2 제어 규칙을 구현하여 상기 제2 복수의 단어를 비-사적으로(non-privately) 출력하는 단계를 포함하는, 맥락 기반 얼굴 미세 움직임 출력을 생성하기 위한 방법.</claim></claimInfo><claimInfo><claim>520. 맥락 기반(context-driven) 얼굴 미세 움직임 출력을 생성하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 제1 시간 기간 동안, 제1 얼굴 피부 미세 움직임과 연관된 제1 코히어런트 광 반사를 나타내는 제1 신호를 수신하도록;  상기 제1 코히어런트 광 반사를 분석하여 상기 제1 얼굴 피부 미세 움직임과 연관된 제1 복수의 단어를 결정하도록; 상기 제1 얼굴 피부 미세 움직임이 발생한 제1 맥락 조건(contextual condition)을 나타내는 제1 정보를 수신하도록; 제2 시간 기간 동안, 제2 얼굴 피부 미세 움직임과 연관된 제2 코히어런트 광 반사를 나타내는 제2 신호를 수신하도록; 상기 제2 코히어런트 광 반사를 분석하여 상기 제2 얼굴 피부 미세 움직임과 연관된 제2 복수의 단어를 결정하도록; 상기 제2 얼굴 피부 미세 움직임이 발생한 제2 맥락 조건을 나타내는 제2 정보를 수신하도록; 복수의 액션을 복수의 맥락 조건과 상관시키는 복수의 제어 규칙에 액세스하도록 - 제1 제어 규칙은 상기 제1 맥락 조건에 기초하여 사적 제시의 형태를 규정하고, 제2 제어 규칙은 상기 제2 맥락 조건에 기초하여 비-사적 제시의 형태를 규정함- ;  상기 제1 정보를 수신하면, 상기 제1 제어 규칙을 구현하여 상기 제1 복수의 단어를 사적으로(privately) 출력하도록; 그리고 상기 제2 정보를 수신하면, 상기 제2 제어 규칙을 구현하여 상기 제2 복수의 단어를 비-사적으로(non-privately) 출력하도록 구성되는 것인, 맥락 기반 얼굴 미세 움직임 출력을 생성하기 위한 시스템.</claim></claimInfo><claimInfo><claim>521. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임에 기초하여 콘텐츠에 대한 반응을 추출하기 위한 동작을 수행하게 하고, 상기 동작은:개인이 콘텐츠를 소비하고 있을 때의 시간 기간 동안, 개인의 얼굴 영역으로부터의 코히어런트 광의 반사에 기초하여 개인의 얼굴 피부 미세 움직임을 결정하는 단계;상기 얼굴 피부 미세 움직임으로부터 적어도 하나의 특정 미세 표정을 결정하는 단계;복수의 미세 표정과 복수의 비언어화된 인식 간의 상관 관계를 포함하는 적어도 하나의 데이터 구조에 액세스하는 단계;상기 적어도 하나의 특정 미세 표정과 상기 데이터 구조 내의 상관 관계에 기초하여, 상기 개인에 의해 소비되는 상기 콘텐츠의 특정 비언어화된 인식을 결정하는 단계; 및상기 특정 비언어화된 인식과 연관된 액션을 개시하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>522. 제521항에 있어서, 상기 적어도 하나의 특정 미세 표정은 인간의 눈에 인식될 수 없는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>523. 제521항에 있어서, 상기 적어도 하나의 특정 미세 표정을 결정하기 위해 사용되는 상기 얼굴 피부 미세 움직임은, 광대근(zygomaticus muscle), 턱끝혀근(genioglossus muscle), 입둘레근(orbicularis oris muscle), 입꼬리당김근(risorius muscle), 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle)을 포함하는 근육의 그룹으로부터의 적어도 하나의 근육의 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>524. 제521항에 있어서, 상기 적어도 하나의 특정 미세 표정은 상기 특정 비언어화된 인식과 연관된 미세 표정의 시퀀스를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>525. 제524항에 있어서, 상기 동작은, 상기 미세 표정의 시퀀스에 기초하여 상기 특정 비언어화된 인식의 정도를 결정하는 단계, 및 상기 특정 비언어화된 인식의 정도에 기초하여 개시할 액션을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>526. 제521항에 있어서, 상기 적어도 하나의 데이터 구조는 이전에 소비된 콘텐츠의 과거의 비언어화된 인식을 포함하고, 상기 동작은, 상기 과거의 비언어화된 인식에 대한 상기 특정 비언어화된 인식의 정도를 결정하는 단계, 및 상기 특정 비언어화된 인식의 정도에 기초하여 개시할 액션을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>527. 제521항에 있어서, 상기 비언어화된 인식은 상기 개인의 감정 상태를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>528. 제521항에 있어서, 상기 동작은, 상기 소비된 콘텐츠 및 상기 특정 비언어화된 인식에 기초하여 개시할 액션을 결정하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>529. 제521항에 있어서, 상기 개시된 액션은 상기 특정 비언어화된 인식 및 상기 소비된 콘텐츠 사이의 상관 관계를 반영하는 메시지의 송신을 야기하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>530. 제521항에 있어서, 상기 개시된 액션은 상기 특정 비언어화된 인식 및 상기 소비된 콘텐츠 사이의 상관 관계를 메모리에 저장하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>531. 제521항에 있어서, 상기 액션은 상기 특정 비언어화된 인식 및 상기 소비된 콘텐츠에 기초하여 상기 개인에게 제시될 추가적인 콘텐츠를 결정하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>532. 제531항에 있어서, 상기 소비된 콘텐츠는 제1 유형이고 상기 추가적인 콘텐츠는 상기 제1 유형과는 상이한 제2 유형인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>533. 제521항에 있어서, 상기 소비된 콘텐츠는 적어도 하나의 다른 개인과의 채팅의 일부이고, 상기 액션은 상기 채팅에서 상기 특정 비언어화된 인식의 시각적 표현을 생성하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>534. 제521항에 있어서, 상기 액션은 상기 소비된 콘텐츠를 제시하기 위한 대체 방식을 선택하는 것을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>535. 제521항에 있어서, 상기 액션은 상기 소비된 콘텐츠의 유형에 기초하여 달라지는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>536. 제521항에 있어서, 상기 동작은, 상기 개인의 얼굴의 비입술 부분을 조명할 수 있는 방식으로 적어도 하나의 웨어러블 코히어런트 광원을 동작시키는 단계, 및 상기 얼굴의 비입술 부분으로부터의 코히어런트 광 반사를 나타내는 신호를 수신하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>537. 제536항에 있어서, 상기 얼굴 피부 미세 움직임은 상기 코히어런트 광 반사의 스페클 분석에 기초하여 결정되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>538. 제521항에 있어서, 상기 코히어런트 광의 반사는 웨어러블 광 검출기에 의해 수신되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>539. 얼굴 피부 미세 움직임에 기초하여 콘텐츠에 대한 반응을 추출하기 위한 방법에 있어서,개인이 콘텐츠를 소비하고 있을 때의 시간 기간 동안, 개인의 얼굴 영역으로부터의 코히어런트 광의 반사에 기초하여 개인의 얼굴 피부 미세 움직임을 결정하는 단계;상기 얼굴 피부 미세 움직임으로부터 적어도 하나의 특정 미세 표정을 결정하는 단계;복수의 미세 표정과 복수의 비언어화된 인식 간의 상관 관계를 포함하는 데이터 구조에 액세스하는 단계;상기 적어도 하나의 특정 미세 표정과 상기 데이터 구조 내의 상관 관계에 기초하여, 상기 개인에 의해 소비되는 상기 콘텐츠의 특정 비언어화된 인식을 결정하는 단계; 및상기 특정 비언어화된 인식과 연관된 액션을 개시하는 단계를 포함하는, 얼굴 피부 미세 움직임에 기초하여 콘텐츠에 대한 반응을 추출하기 위한 방법.</claim></claimInfo><claimInfo><claim>540. 얼굴 피부 미세 움직임에 기초하여 콘텐츠에 대한 반응을 추출하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 개인이 콘텐츠를 소비하고 있을 때의 시간 기간 동안, 상기 개인의 얼굴 영역으로부터의 코히어런트 광의 반사에 기초하여 상기 개인의 얼굴 피부 미세 움직임을 결정하도록; 상기 얼굴 피부 미세 움직임으로부터 적어도 하나의 특정 미세 표정을 결정하도록; 복수의 미세 표정과 복수의 비언어화된 인식 간의 상관 관계를 포함하는 데이터 구조에 액세스하도록; 상기 적어도 하나의 특정 미세 표정과 상기 데이터 구조 내의 상관 관계에 기초하여, 상기 개인에 의해 소비되는 상기 콘텐츠의 특정 비언어화된 인식을 결정하도록; 그리고 상기 특정 비언어화된 인식과 연관된 액션을 개시하도록 구성되는 것인, 콘텐츠에 대한 반응을 추출하기 위한 시스템.</claim></claimInfo><claimInfo><claim>541. 명령어를 포함하는 비일시적 컴퓨터 판독 가능 매체에 있어서, 상기 명령어는, 적어도 하나의 프로세서에 의해 실행될 때, 상기 적어도 하나의 프로세서로 하여금, 얼굴 피부 미세 움직임 신호로부터 노이즈를 제거하기 위한 동작을 수행하게 하고, 상기 동작은:개인이 적어도 하나의 스피치와 관련되지 않은(non-speech-related) 신체 활동에 관련될 때의 시간 기간 동안, 상기 개인의 얼굴 피부 영역을 조명할 수 있는 방식으로 광원을 동작시키는 단계;상기 얼굴 피부 영역으로부터의 광 반사를 나타내는 신호를 수신하는 단계; 상기 수신된 신호를 분석하여, 예비발성(prevocalization) 얼굴 피부 미세 움직임을 나타내는 제1 반사 성분 및 상기 적어도 하나의 스피치와 관련되지 않은 신체 활동과 연관된 제2 반사 성분을 식별하는 단계; 및상기 제2 반사 성분을 필터링하여 상기 예비발성 얼굴 피부 미세 움직임을 나타내는 상기 제1 반사 성분으로부터 단어의 해석을 가능하게 하는 단계를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>542. 제541항에 있어서, 상기 광원은 코히어런트 광원인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>543. 제541항에 있어서, 상기 제2 반사 성분은 걷기의 결과인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>544. 제541항에 있어서, 상기 제2 반사 성분은 달리기의 결과인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>545. 제541항에 있어서, 상기 제2 반사 성분은 호흡하기의 결과인 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>546. 제541항에 있어서, 상기 제2 반사 성분은 깜박임(blinking)의 결과이며 적어도 하나의 눈둘레근(orbicularis oculi muscle)의 신경 활성화에 기초하는　것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>547. 제541항에 있어서, 상기 개인이 제1 신체 활동 및 제2 신체 활동에 동시에 관련될 때, 상기 동작은, 상기 제1 신체 활동과 연관된 상기 제2 반사 성분의 제1 부분 및 상기 제2 신체 활동과 연관된 상기 제2 반사 성분의 제2 부분을 식별하는 단계, 및 상기 제1 성분으로부터 상기 제2 성분의 제1 부분 및 상기 제2 성분의 제2 부분을 필터링하여, 상기 제1 성분과 연관된 예비발성 얼굴 피부 미세 움직임으로부터 단어의 해석을 가능하게 하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>548. 제541항에 있어서, 상기 동작은, 모바일 통신 디바이스로부터 데이터를 수신하는 단계를 더 포함하며, 상기 데이터는 상기 적어도 하나의 스피치와 관련되지 않은 신체 활동을 나타내는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>549. 제548항에 있어서, 상기 모바일 통신 디바이스는 광 반사를 검출하기 위한 광 센서가 결여된 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>550. 제548항에 있어서, 상기 모바일 통신 디바이스로부터 수신된 데이터는, 상기 개인의 심박수를 나타내는 데이터, 상기 개인의 혈압을 나타내는 데이터, 또는 상기 개인의 움직임을 나타내는 데이터 중, 적어도 하나를 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>551. 제541항에 있어서, 상기 동작은, 합성된 음성으로 상기 단어를 제시하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>552. 제541항에 있어서, 상기 신호는 웨어러블 하우징과 연관된 센서로부터 수신되고, 상기 명령어는 상기 적어도 하나의 스피치와 관련되지 않은 신체 활동을 결정하기 위해 상기 신호를 분석하는 것을 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>553. 제552항에 있어서, 상기 센서는 상기 개인의 환경에서 적어도 하나의 이벤트를 캡처하도록 구성된 이미지 센서이고, 상기 적어도 하나의 프로세서는, 상기 이벤트가 상기 적어도 하나의 스피치와 관련되지 않은 신체 활동과 연관된다고 결정하도록 구성되는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>554. 제541항에 있어서, 상기 동작은, 신경망을 사용하여 상기 적어도 하나의 스피치와 관련되지 않은 신체 활동과 연관된 상기 제2 반사 성분을 식별하는 단계를 더 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체. </claim></claimInfo><claimInfo><claim>555. 제541항에 있어서, 상기 예비발성 얼굴 피부 미세 움직임은 하나 이상의 비자발적 근육 섬유 동원에 대응하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>556. 제555항에 있어서, 상기 비자발적 근육 섬유 동원은 개인이 상기 단어를 말하는 생각의 결과인 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>557. 제555항에 있어서, 상기 하나 이상의 근육 섬유 동원은 광대근(zygomaticus muscle) 섬유, 입둘레근(orbicularis oris muscle) 섬유, 턱끝혀근(genioglossus muscle) 섬유, 입꼬리당김근(risorius muscle) 섬유, 또는 위입술콧방울올림근(levator labii superioris alaeque nasi muscle) 섬유 중, 적어도 하나의 동원을 포함하는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>558. 제541항에 있어서, 상기 신호는 50Hz와 200Hz 사이의 속도로 수신되는 것인, 비일시적 컴퓨터 판독 가능 매체.</claim></claimInfo><claimInfo><claim>559. 얼굴 피부 미세 움직임 신호로부터 노이즈를 제거하기 위한 방법에 있어서,개인이 적어도 하나의 스피치와 관련되지 않은(non-speech-related) 신체 활동에 관련될 때의 시간 기간 동안, 상기 개인의 얼굴 피부 영역을 조명할 수 있는 방식으로 광원을 동작시키는 단계;상기 얼굴 피부 영역으로부터의 광 반사를 나타내는 신호를 수신하는 단계; 상기 수신된 신호를 분석하여, 예비발성(prevocalization) 얼굴 피부 미세 움직임을 나타내는 제1 반사 성분 및 상기 적어도 하나의 스피치와 관련되지 않은 신체 활동과 연관된 제2 반사 성분을 식별하는 단계; 및상기 제2 반사 성분을 필터링하여 상기 예비발성 얼굴 피부 미세 움직임을 나타내는 상기 제1 반사 성분으로부터 단어의 해석을 가능하게 하는 단계를 포함하는, 얼굴 피부 미세 움직임 신호로부터 노이즈를 제거하기 위한 방법.</claim></claimInfo><claimInfo><claim>560. 얼굴 피부 미세 움직임을 결정하기 위한 시스템에 있어서,적어도 하나의 프로세서를 포함하고, 상기 적어도 하나의 프로세서는, 개인이 적어도 하나의 스피치와 관련되지 않은(non-speech-related) 신체 활동에 관련될 때의 시간 기간 동안, 상기 개인의 얼굴 피부 영역을 조명할 수 있는 방식으로 광원을 동작시키도록; 상기 얼굴 피부 영역으로부터의 광 반사를 나타내는 신호를 수신하도록;  상기 수신된 신호를 분석하여, 예비발성(prevocalization) 얼굴 피부 미세 움직임을 나타내는 제1 반사 성분 및 상기 적어도 하나의 스피치와 관련되지 않은 신체 활동과 연관된 제2 반사 성분을 식별하도록; 그리고 상기 제2 반사 성분을 필터링하여 상기 예비발성 얼굴 피부 미세 움직임을 나타내는 상기 제1 반사 성분으로부터 단어의 해석을 가능하게 하도록 구성되는 것인, 얼굴 피부 미세 움직임을 결정하기 위한 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>이스라엘 라마트 간 ******* 원 타워 압바 힐렐 스트리트 **</address><code>520240088200</code><country>이스라엘</country><engName>Q (CUE) LTD.</engName><name>큐(큐) 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>이스라엘 ******* 라마트 하...</address><code> </code><country>이스라엘</country><engName>MAIZELS, Aviad</engName><name>마이젤스 아비아드</name></inventorInfo><inventorInfo><address>이스라엘 *******...</address><code> </code><country>이스라엘</country><engName>WEXLER, Yonatan</engName><name>웩슬러 요나탄</name></inventorInfo><inventorInfo><address>이스라엘 *******...</address><code> </code><country>이스라엘</country><engName>BARLIYA, Avi</engName><name>발리야 아비</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001573</code><country>대한민국</country><engName>Kim Jin Hoe</engName><name>김진회</name></agentInfo><agentInfo><address>서울 서대문구 충정로 ** (충정로*가) 풍산빌딩 **층(리인터내셔널특허법률사무소)</address><code>919980001580</code><country>대한민국</country><engName>Kim Tae Hong</engName><name>김태홍</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.07.20</priorityApplicationDate><priorityApplicationNumber>63/390,653</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.08.02</priorityApplicationDate><priorityApplicationNumber>63/394,329</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.01.10</priorityApplicationDate><priorityApplicationNumber>63/438,061</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.01.26</priorityApplicationDate><priorityApplicationNumber>63/441,183</priorityApplicationNumber></priorityInfo><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2023.02.28</priorityApplicationDate><priorityApplicationNumber>63/487,299</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.02.18</receiptDate><receiptNumber>1-1-2025-0186790-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[New Translation under Article 201 of Patent Act or Article 35 of Utility Model Act] Submission of Document</documentEngName><documentName>[특허법 제201조 또는 실용신안법 제35조에 따른 새로운 번역문]서류제출서</documentName><receiptDate>2025.03.17</receiptDate><receiptNumber>1-1-2025-0301987-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.03.21</receiptDate><receiptNumber>1-1-2025-0323671-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.03.26</receiptDate><receiptNumber>1-1-2025-0340965-75</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2025.03.31</receiptDate><receiptNumber>1-5-2025-0053168-31</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[지정기간연장]기간 연장신청서·기간 단축신청서·기간 경과 구제신청서·절차 계속신청서</documentName><receiptDate>2025.05.30</receiptDate><receiptNumber>1-1-2025-0608976-85</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[지정기간연장]기간 연장신청서·기간 단축신청서·기간 경과 구제신청서·절차 계속신청서</documentName><receiptDate>2025.06.30</receiptDate><receiptNumber>1-1-2025-0731363-60</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[지정기간연장]기간 연장신청서·기간 단축신청서·기간 경과 구제신청서·절차 계속신청서</documentName><receiptDate>2025.07.31</receiptDate><receiptNumber>1-1-2025-0871294-57</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.08.28</receiptDate><receiptNumber>1-1-2025-0989176-56</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.08.29</receiptDate><receiptNumber>1-5-2025-0146905-33</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257005245.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930cb50a342a061aa426b7c788dfda5a3540e737ac47a3b9170b5649bd5debe61fa9c1178bc481002a3a56a9a17848f2e7a331da14b2586bcb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfdfa8a4b3774c34727d6abb93f4eb1aff79629c7a1b754db400b66f577c59964518674a298aa794394f965b46fc61ee17c3437b6adfadbe20</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>