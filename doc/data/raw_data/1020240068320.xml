<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:38:04.384</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.05.27</applicationDate><applicationFlag>특허</applicationFlag><applicationNumber>10-2024-0068320</applicationNumber><claimCount>2</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>센서 데이터를 활용한 운동 자세 평가 시스템 및 방법</inventionTitle><inventionTitleEng>SPORTRS POSTURE EVALUATION SYSTEM AND METHOD USING SENSOR  DATA</inventionTitleEng><openDate>2025.01.21</openDate><openNumber>10-2025-0010524</openNumber><originalApplicationDate>2023.07.12</originalApplicationDate><originalApplicationKind>국내출원/분할</originalApplicationKind><originalApplicationNumber>10-2023-0090130</originalApplicationNumber><originalExaminationRequestDate>2024.05.27</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A63B 24/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>A63B 71/06</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/34</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo><familyApplicationNumber>1020230090130</familyApplicationNumber></familyInfo></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 센서 데이터를 활용한 운동 자세 평가 시스템 및 방법이 제공된다. 본 발명의 다양한 실시예에 따르면, 소정의 공간에서 진행되는 운동 심사에 참가한 응시자의 자세를 스캔함에 따라 적어도 하나의 센서 데이터를 생성하는 적어도 하나의 센서 모듈 및 기 학습된 인공지능 모델을 이용하여, 상기 센서 모듈로부터 생성된 상기 센서 데이터를 분석함에 따라 상기 응시자에 대한 점수를 산출하는 서버를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 센서 데이터를 활용한 운동 자세 평가 시스템에 있어서,소정의 공간에서 진행되는 운동 심사에 참가한 응시자의 자세를 스캔함에 따라 적어도 하나의 센서 데이터를 생성하는 적어도 하나의 센서 모듈; 및기 학습된 인공지능 모델을 이용하여, 상기 센서 모듈로부터 생성된 상기 센서 데이터를 분석함에 따라 상기 응시자에 대한 점수를 산출하는 서버;를 포함하고,상기 센서 모듈은 소정의 공간 내에 설치되며, 서로 다른 각도로 촬영하는 복수의 카메라 모듈을 포함하고,상기 센서 데이터는 적어도 하나의 영상 데이터를 포함하고,상기 영상 데이터는 상기 카메라 모듈이 상기 소정의 공간을 촬영함에 따라 생성되는 복수의 프레임을 포함하고,기 설정된 기준 데이터는 동작에 소요되는 시간 정보가 기 설정되고, 기 설정된 시계열 데이터를 신체 부위 별로 포함하고,상기 서버는,상기 복수의 프레임에서 상기 응시자에 대한 스켈레톤 정보를 추출하고, 추출된 상기 스켈레톤 정보를 이용해서 상기 응시자의 자세 정보를 생성하고, 생성된 상기 응시자의 자세 정보와 상기 기준 데이터에 의거하여 상기 응시자에게 점수를 부여하고,상기 프레임 간격을 이용해서 상기 응시자의 동작에 소요되는 시간 정보를 생성하고, 상기 응시자의 시간 정보와 상기 기준 데이터의 시간 정보를 고려하여 응시자에게 점수를 부여하고,상기 스켈레톤 정보를 이용해서 상기 응시자의 신체 각도를 상기 자세 정보로서 산출하고, 시간에 따라 변화하는 신체 각도의 정보가 포함된 상기 응시자의 시계열 데이터를 신체 부위 별로 생성하고, 신체 부위 별로 상기 응시자의 시계열 데이터와 기준 데이터를 비교한 결과에 의거하여 응시자에게 신체 부위 별로 점수를 부여하고,상기 서버는,상기 운동 심사가 품새 심사인 경우, 상기 스켈레톤 정보를 이용하여 상기 응시자의 신체 각도의 변화량을 산출하고, 상기 산출된 신체 각도의 변화량을 통해 상기 응시자의 동작들을 인식하되, 상기 인식된 동작들이 시작된 프레임과 상기 인식된 동작이 종료된 프레임의 간격을 이용하여 상기 인식된 동작들을 시간별로 분류하고, 상기 시간별로 분류된 동작들을 상기 품새에 포함된 복수의 동작 중 어느 하나의 동작으로 분류하고,상기 기준 데이터는 이상적인 품새 동작에서의 시간 별 신체 각도를 포함하고,상기 시간별로 분류된 동작들과 상기 기준 데이터에 포함된 이상적인 품새 동작에서의 시간 별 신체 각도가 일치하는 정도를 기반으로 상기 응시자에게 동작 별로 점수를 부여하고,상기 서버는,상기 응시자의 신체 각도를 상기 프레임 단위로 산출하고, 상기 프레임 간격을 이용해서 시간에 따라 변화하는 신체 각도의 변화량이 포함된 응시자의 시계열 데이터를 생성하고,상기 생성된 시계열 데이터에 포함된 시간에 따라 변화하는 신체 각도의 변화량과 상기 기준 데이터에 포함된 시간에 따라 변화하는 신체 각도의 변화량을 비교하여 상기 응시자에게 점수를 부여하고,상기 서버는,상기 복수의 카메라 모듈로부터 생성된 복수의 프레임 각각으로부터 상기 스켈레톤 정보를 추출하고, 상기 스켈레톤 정보를 병합하여 상기 응시자의 3차원 좌표 정보를 상기 자세 정보로서 생성하고, 상기 기준 데이터는 기 설정된 3차원 좌표 정보를 포함하고,상기 응시자의 3차원 좌표 정보와 기준 데이터를 비교한 결과에 의거하여 응시자에게 점수를 부여하고,상기 서버는,시간에 따른 3차원 좌표 변화량이 포함된 상기 응시자의 3차원 좌표 정보를 생성하고,상기 기준 데이터는 시간에 따른 3차원 좌표 변화량이 포함된 기 설정된 3차원 좌표 정보를 포함하고,상기 응시자의 3차원 좌표 정보에 포함된 시간에 따른 3차원 좌표 변화량과 상기 기준 데이터의 기 설정된 3차원 좌표 정보에 포함된 시간에 따른 3차원 좌표 변화량을 비교하여 응시자에게 점수를 부여하고,상기 카메라 모듈은 복수의 응시자를 동시에 촬영하고,상기 서버는 상기 영상 데이터로부터 복수의 응시자 각각을 인식하고, 각 응시자에 대한 점수를 독립적으로 산출하는,센서 데이터를 활용한 운동 자세 평가 시스템.</claim></claimInfo><claimInfo><claim>2. 센서 데이터를 활용한 운동 자세를 평가하는 방법에 있어서,적어도 하나의 센서 모듈을 통해 소정의 공간에서 진행되는 운동 심사에 참가한 응시자의 자세를 스캔함에 따라 적어도 하나의 센서 데이터를 생성하는 단계; 및서버에 기록된 기 학습된 인공지능 모델을 이용하여, 상기 센서 모듈로부터 생성된 적어도 하나의 센서 데이터를 분석한 결과에 기초하여 상기 응시자에 대한 점수를 산출하는 단계;를 포함하고,상기 센서 모듈은 소정의 공간 내에 설치되며, 서로 다른 각도로 촬영하는 복수의 카메라 모듈을 포함하고,상기 센서 데이터는 적어도 하나의 영상 데이터를 포함하고,상기 영상 데이터는 상기 카메라 모듈이 상기 소정의 공간을 촬영함에 따라 생성되는 복수의 프레임을 포함하고,기 설정된 기준 데이터는 동작에 소요되는 시간 정보가 기 설정되고, 기 설정된 시계열 데이터를 신체 부위 별로 포함하고,상기 점수를 산출하는 단계는,상기 복수의 프레임에서 상기 응시자에 대한 스켈레톤 정보를 추출하고, 추출된 상기 스켈레톤 정보를 이용해서 상기 응시자의 자세 정보를 생성하고, 생성된 상기 응시자의 자세 정보와 상기 기준 데이터에 의거하여 상기 응시자에게 점수를 부여하는 단계;상기 프레임 간격을 이용해서 상기 응시자의 동작에 소요되는 시간 정보를 생성하고, 상기 응시자의 시간 정보와 상기 기준 데이터의 시간 정보를 고려하여 응시자에게 점수를 부여하는 단계;상기 스켈레톤 정보를 이용해서 상기 응시자의 신체 각도를 상기 자세 정보로서 산출하고, 시간에 따라 변화하는 신체 각도의 정보가 포함된 상기 응시자의 시계열 데이터를 신체 부위 별로 생성하고, 신체 부위 별로 상기 응시자의 시계열 데이터와 기준 데이터를 비교한 결과에 의거하여 응시자에게 신체 부위 별로 점수를 부여하는 단계;상기 운동 심사가 품새 심사인 경우, 상기 스켈레톤 정보를 이용하여 상기 응시자의 신체 각도의 변화량을 산출하고, 상기 산출된 신체 각도의 변화량을 통해 상기 응시자의 동작들을 인식하되, 상기 인식된 동작들이 시작된 프레임과 상기 인식된 동작이 종료된 프레임의 간격을 이용하여 상기 인식된 동작들을 시간별로 분류하고, 상기 시간별로 분류된 동작들을 상기 품새에 포함된 복수의 동작 중 어느 하나의 동작으로 분류하고, 상기 기준 데이터는 이상적인 품새 동작에서의 시간 별 신체 각도를 포함하고, 상기 시간별로 분류된 동작들과 상기 기준 데이터에 포함된 이상적인 품새 동작에서의 시간 별 신체 각도가 일치하는 정도를 기반으로 상기 응시자에게 동작 별로 점수를 부여하는 단계;상기 응시자의 신체 각도를 상기 프레임 단위로 산출하고, 상기 프레임 간격을 이용해서 시간에 따라 변화하는 신체 각도의 변화량이 포함된 응시자의 시계열 데이터를 생성하고, 상기 생성된 시계열 데이터에 포함된 시간에 따라 변화하는 신체 각도의 변화량과 상기 기준 데이터에 포함된 시간에 따라 변화하는 신체 각도의 변화량을 비교하여 상기 응시자에게 점수를 부여하는 단계;상기 복수의 카메라 모듈로부터 생성된 복수의 프레임 각각으로부터 상기 스켈레톤 정보를 추출하고, 상기 스켈레톤 정보를 병합하여 상기 응시자의 3차원 좌표 정보를 상기 자세 정보로서 생성하고, 상기 기준 데이터는 기 설정된 3차원 좌표 정보를 포함하고, 상기 응시자의 3차원 좌표 정보와 기준 데이터를 비교한 결과에 의거하여 응시자에게 점수를 부여하는 단계; 및상기 카메라 모듈을 통해 복수의 응시자를 동시에 촬영한 영상 데이터로부터 복수의 응시자 각각을 인식하고, 각 응시자에 대한 점수를 독립적으로 산출하는 단계를 포함하며,상기 응시자의 3차원 좌표 정보와 기준 데이터를 비교한 결과에 의거하여 응시자에게 점수를 부여하는 단계는,시간에 따른 3차원 좌표 변화량이 포함된 상기 응시자의 3차원 좌표 정보를 생성하고, 상기 기준 데이터는 시간에 따른 3차원 좌표 변화량이 포함된 기 설정된 3차원 좌표 정보를 포함하고, 상기 응시자의 3차원 좌표 정보에 포함된 시간에 따른 3차원 좌표 변화량과 상기 기준 데이터의 기 설정된 3차원 좌표 정보에 포함된 시간에 따른 3차원 좌표 변화량을 비교하여 응시자에게 점수를 부여하는 단계를 포함하는,센서 데이터를 활용한 운동 자세 평가 방법.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 동작구...</address><code>120200868327</code><country>대한민국</country><engName>AIBIZ Co.,Ltd.</engName><name>주식회사 에이아이비즈</name></applicantInfo><applicantInfo><address>서울특별시 서대문구...</address><code>420160594756</code><country>대한민국</country><engName>CHOI, Hyun Jin</engName><name>최현진</name></applicantInfo><applicantInfo><address>경기도 수원시 권선구...</address><code>420230469008</code><country>대한민국</country><engName>Min Tae Nam</engName><name>민태남</name></applicantInfo><applicantInfo><address>서울특별시 강서구...</address><code>420190110563</code><country>대한민국</country><engName>LEE, Sang Hyuk</engName><name>이상혁</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울특별시 마포구...</address><code> </code><country> </country><engName>HA SEUNG JAE</engName><name>하승재</name></inventorInfo><inventorInfo><address>서울특별시 서대문구...</address><code>420160594756</code><country>대한민국</country><engName>CHOI, Hyun Jin</engName><name>최현진</name></inventorInfo><inventorInfo><address>경기도 수원시 권선구...</address><code>420230469008</code><country>대한민국</country><engName>Min Tae Nam</engName><name>민태남</name></inventorInfo><inventorInfo><address>서울특별시 강서구...</address><code>420190110563</code><country>대한민국</country><engName>LEE, Sang Hyuk</engName><name>이상혁</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 테헤란로 ***-*, *층(역삼동)</address><code>920201000818</code><country>대한민국</country><engName>RPM IP&amp;LAW FIRM</engName><name>특허법인알피엠</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Divisional Application] Patent Application</documentEngName><documentName>[분할출원]특허출원서</documentName><receiptDate>2024.05.27</receiptDate><receiptNumber>1-1-2024-0567880-60</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240068320.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93082149907f8200249ee6167e67d41812f8b8beeccd3175810600c8be446caf84ba62307e3e8d55f40a95e4e7ab900e3b2a5c2f3cbf9c68fb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf1131a4f5d4edd279bcae38aa167eec22dfb9a798e084a4738cda3cbe77cd9dce0ea66a0921597a7886366f6ecd8a2d164622fe47ec28b785</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>