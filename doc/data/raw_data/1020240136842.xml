<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:10:17.1017</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.10.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0136842</applicationNumber><claimCount>10</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>사람 객체의 감지 영역에 대한 표면 평균 곡률을 활용한 행동 인식 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR RECOGNIZING ACTION USING SURFACE  AVERAGE CURVATURE OF DETECTION AREA OF HUMAN OBJECT</inventionTitleEng><openDate>2025.05.09</openDate><openNumber>10-2025-0064587</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.10.08</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/46</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/62</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 일 실시예에 따른 행동 인식 장치는 분석 대상이 될 타겟 영상을 획득하는 동작; 상기 타겟 영상에서 사람 객체를 포함하는 경계 상자를 추출하는 동작; 상기 경계 상자 내 사람 객체의 자세에 대한 클래스 정보를 판별하는 제1 분류 모델을 기초로 상기 사람 객체에 대한 제1 특징 벡터를 추출하는 동작; 상기 경계 상자 내 사람 객체에 대한 표면 정보를 생성하는 메시 생성 모델을 기초로 상기 사람 객체에 대한 표면 정보를 특정하는 제2 특징 벡터를 추출하는 동작; 상기 제1 특징 벡터 및 제2 특징 벡터를 결합한 임베딩 벡터를 생성하는 동작; 및 사람 객체의 자세 정보와 표면 정보로부터 사람 객체가 취하는 행동을 판별하는 제2 분류 모델에 상기 임베딩 벡터를 입력하여 상기 사람 객체의 행동을 판별하는 동작을 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 프로세서에 의해 동작하는 행동 인식 장치가 수행하는 방법에 있어서,분석 대상이 될 타겟 영상을 획득하는 동작; 상기 타겟 영상에서 사람 객체를 포함하는 경계 상자를 추출하는 동작; 상기 경계 상자 내 사람 객체의 자세에 대한 클래스 정보를 판별하는 제1 분류 모델을 기초로 상기 사람 객체에 대한 제1 특징 벡터를 추출하는 동작; 상기 경계 상자 내 사람 객체에 대한 표면 정보를 생성하는 메시 생성 모델을 기초로 상기 사람 객체에 대한 표면 정보를 특정하는 제2 특징 벡터를 추출하는 동작; 상기 제1 특징 벡터 및 제2 특징 벡터를 결합한 임베딩 벡터를 생성하는 동작; 및 사람 객체의 자세 정보와 표면 정보로부터 사람 객체가 취하는 행동을 판별하는 제2 분류 모델에 상기 임베딩 벡터를 입력하여 상기 사람 객체의 행동을 판별하는 동작을 포함하는,방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제2 특징 벡터를 추출하는 동작은 메시 생성 모델 중 ROMP 모델을 이용하여 상기 사람 객체가 차지하는 영역의 3차원 메시 정보를 복원하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 메시 정보는 상기 사람 객체가 차지하는 영역에 대한 3차원 정보를 나타내는 복수의 정점 및 간선으로 구성된, 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 제2 특징 벡터를 추출하는 동작은 상기 복수의 정점 중 각 정점의 평균 곡률을 계산하는 동작; 및 상기 각 정점의 평균 곡률에 대한 정보를 벡터화한 제2 특징 벡터를 생성하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 평균 곡률을 계산하는 동작은 상기 복수의 정점 중 어느 하나인 제1 정점과, 상기 제1 정점의 1-링 주변부(1-ring neighborhood)에 해당하는 각 정점 간의 곡률값을 계산하는 동작; 및상기 곡률값 중 최대 곡률과 최소 곡률의 평균을 상기 제1 정점의 평균 곡률로 계산하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 임베딩 벡터를 생성하는 동작은 Concatenation, Addition, Averaging, Gate network 중 적어도 하나의 기법을 기초로 상기 제1 특징 벡터 및 제2 특징 벡터를 결합하여 임베딩 벡터를 생성하는 동작을 포함하는, 방법. </claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 제2 분류 모델은 시계열 데이터를 처리하는 LSTM 모델을 기반으로 사람 객체의 자세 정보와 표면 정보로부터 구성된 임베딩 벡터와 사람 객체의 행동을 특정하는 정답 클래스 간의 상관 관계에 대한 파라미터를 학습하도록 지도 학습된, 방법. </claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 제2 분류 모델은상기 타겟 영상 중의 복수의 프레임 각각으로부터 추출된 제1 특징 벡터와 제2 특징 벡터의 결합으로 생성된 복수의 임베딩 벡터를 입력받아 상기 타겟 영상에 포함된 사람 객체의 행동을 판별하는, 방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 복수의 프레임은 상기 타겟 영상의 프레임 중 시계열적인 순서에 따라 추출된 일련의 프레임을 포함하고,  상기 제2 분류 모델은 상기 복수의 임베딩 벡터를 각 임베딩 벡터의 프레임의 시계열적 순서에 따라 입력 받아, 상기 복수의 임베딩 벡터의 시계열적 순서를 반영하여 타겟 영상에 포함된 사람 객체의 행동을 판별하는 것이 특징인, 방법. </claim></claimInfo><claimInfo><claim>10. 명령어를 포함하는 메모리; 및상기 명령어를 기초로 소정의 동작을 수행하는 프로세서를 포함하고, 상기 프로세서의 동작은,분석 대상이 될 타겟 영상을 획득하는 동작; 상기 타겟 영상에서 사람 객체를 포함하는 경계 상자를 추출하는 동작; 상기 경계 상자 내 사람 객체의 자세에 대한 클래스 정보를 판별하는 제1 분류 모델을 기초로 상기 사람 객체에 대한 제1 특징 벡터를 추출하는 동작; 상기 경계 상자 내 사람 객체에 대한 표면 정보를 생성하는 메시 생성 모델을 기초로 상기 사람 객체에 대한 표면 정보를 특정하는 제2 특징 벡터를 추출하는 동작; 상기 제1 특징 벡터 및 제2 특징 벡터를 결합한 임베딩 벡터를 생성하는 동작; 및 사람 객체의 자세 정보와 표면 정보로부터 사람 객체가 취하는 행동을 판별하는 제2 분류 모델에 상기 임베딩 벡터를 입력하여 상기 사람 객체의 행동을 판별하는 동작을 포함하는,행동 인식 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>서울특별시 성북구...</address><code>220040170680</code><country>대한민국</country><engName>Korea University Research and Business Foundation</engName><name>고려대학교 산학협력단</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>서울시 성북구...</address><code> </code><country> </country><engName>KIM, Sang Pil</engName><name>김상필</name></inventorInfo><inventorInfo><address>서울시 성북구...</address><code> </code><country> </country><engName>SEO, Dong Yoon</engName><name>서동윤</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 송파구 송파대로 ***, 에이동 ***호(문정동, 문정역테라타워)</address><code>920221000019</code><country>대한민국</country><engName>WESOL IP Law Firm</engName><name>특허법인위솔</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>대한민국</priorityApplicationCountry><priorityApplicationDate>2023.10.30</priorityApplicationDate><priorityApplicationNumber>1020230146811</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.10.08</receiptDate><receiptNumber>1-1-2024-1094685-25</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[공지예외적용 보완 증명서류]서류제출서</documentName><receiptDate>2024.10.11</receiptDate><receiptNumber>1-1-2024-1107350-41</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[출원서 등 보완]보정서</documentName><receiptDate>2024.10.11</receiptDate><receiptNumber>1-1-2024-1107351-97</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240136842.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c938f458fcc1ada6988669b9b01aa52b1f391d3cc3b16830cc04003fdbe06f8e72019ad0ccdd32faf1f16de3fc8d845fc210fd9bc98c101162d</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf27df225b53af5c9d49c88487231f5dfac2fc9b2aa202ed6dd1a5c0c422adaad36275128e564fdc6ab29532ce2b30d6f8652eda014871ac39</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>