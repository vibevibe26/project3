<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:11:20.1120</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.06.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7039936</applicationNumber><claimCount>25</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>적응적 런타임 효율적 이미지 분류를 위한 입력 이미지 크기 전환 가능 네트워크</inventionTitle><inventionTitleEng>INPUT IMAGE SIZE SWITCHABLE NETWORK FOR ADAPTIVE RUNTIME EFFICIENT IMAGE CLASSIFICATION</inventionTitleEng><openDate>2023.02.16</openDate><openNumber>10-2023-0022843</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.06.15</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.11.15</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/32</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/764</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/82</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/44</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/75</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 이미지 분류 네트워크들을 구현하고 트레이닝시키는 것에 관련된 기술들이 논의된다. 그러한 기술들은 해상도에 관계없이 입력 이미지들에 공유 콘볼루션 계층들을 적용하는 것 및 입력 이미지 해상도에 기초하여 선택적으로 정규화를 적용하는 것을 포함한다. 그러한 기술들은 혼합 이미지 크기 병렬 트레이닝 및 혼합 이미지 크기 앙상블 증류를 사용한 트레이닝을 더 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2021.12.23</internationOpenDate><internationOpenNumber>WO2021253148</internationOpenNumber><internationalApplicationDate>2020.06.15</internationalApplicationDate><internationalApplicationNumber>PCT/CN2020/096035</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 이미지 분류를 위한 시스템으로서,제1 해상도의 제1 이미지 및 상기 제1 해상도보다 작은 제2 해상도의 제2 이미지를 저장하기 위한 메모리; 및상기 메모리에 결합되는 하나 이상의 프로세서를 포함하며, 상기 하나 이상의 프로세서는: 상기 제1 이미지에 대응하는 하나 이상의 제2 특징 맵을 생성하기 위해 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제1 이미지 또는 상기 제1 이미지에 대응하는 제1 특징 맵들에 콘볼루션 신경 네트워크 계층을 적용하고; 하나 이상의 제3 특징 맵을 생성하기 위해 복수의 제1 정규화 파라미터들을 사용하여 상기 하나 이상의 제2 특징 맵에 대해 제1 정규화를 수행하며; 상기 하나 이상의 제3 특징 맵을 사용하여 상기 제1 이미지에 대한 제1 라벨을 생성하고; 상기 제2 이미지에 대응하는 하나 이상의 제5 특징 맵을 생성하기 위해 상기 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제2 이미지 또는 상기 제2 이미지에 대응하는 제4 특징 맵들에 상기 콘볼루션 신경 네트워크 계층을 적용하며; 하나 이상의 제6 특징 맵을 생성하기 위해 상기 제1 정규화 파라미터들을 제외한 복수의 제2 정규화 파라미터들을 사용하여 상기 하나 이상의 제5 특징 맵에 대해 제2 정규화를 수행하고; 상기 하나 이상의 제6 특징 맵을 사용하여 상기 제2 이미지에 대한 제2 라벨을 생성하는, 시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 하나 이상의 프로세서가 상기 제1 라벨을 생성하는 것은 상기 하나 이상의 프로세서가 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 추가적인 제1 정규화를 적용하고 완전 연결 계층을 적용하는 것을 포함하고, 상기 하나 이상의 프로세서가 상기 제2 라벨을 생성하는 것은 상기 하나 이상의 프로세서가 상기 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 상기 추가적인 제1 정규화들에서 사용되는 파라미터들을 제외한 파라미터들을 사용하는 추가적인 제2 정규화를 적용하고 상기 완전 연결 계층을 적용하는 것을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서, 상기 제1 정규화 및 추가적인 제1 정규화들은 상기 제1 이미지가 상기 제1 해상도인 것에 응답하여 선택되고, 상기 제2 정규화 및 추가적인 제2 정규화들은 상기 제2 이미지가 상기 제2 해상도인 것에 응답하여 선택되는, 시스템.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 및 제2 해상도들 제각기에서의 제1 및 제2 트레이닝 이미지들 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1 및 제2 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -; 및트레이닝 반복에서, 상기 제1 및 제2 트레이닝 이미지들에 대한 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 적용에 기초하여 교차 엔트로피 손실들의 합을 포함하는 손실 항을 사용하여 병렬로 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 파라미터 조정에 기초하여 트레이닝되는 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서, 상기 파라미터 조정은 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 완전 연결 계층 파라미터들, 입력 이미지 크기들에 걸쳐 공유될 상기 콘볼루션 계층 파라미터들 및 완전 연결 계층 파라미터들, 및 상기 입력 이미지 크기들에 걸쳐 공유되지 않을 상기 제1 및 제2 정규화 파라미터들에 대한 조정을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 해상도, 상기 제2 해상도, 및 상기 제2 해상도보다 작은 제3 해상도의 제1, 제2, 및 제3 트레이닝 이미지들, 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1, 제2, 및 제3 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -;트레이닝 반복에서, 상기 제1, 제2, 및 제3 트레이닝 이미지들을, 제각기, 사용하여 이루어지는 제1, 제2, 및 제3 예측들에 기초한 앙상블 예측의 생성; 및상기 앙상블 예측과 상기 실측 라벨의 비교에 기초하여 트레이닝되는 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 상기 앙상블 예측은 상기 제1, 제2, 및 제3 트레이닝 이미지들 각각에 적용되는 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들에 대응하는 로짓들의 가중 평균 - 상기 로짓들의 가중 평균은 로짓 중요도 점수들을 사용하여 가중됨 - 을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서, 상기 트레이닝 반복에서, 파라미터들 업데이트는 상기 앙상블 예측을 사용한 분류 확률에 기초한 앙상블 손실 항과 상기 앙상블 예측으로부터의 상기 제1, 제2, 및 제3 예측들 각각의 발산에 기초한 증류 손실 항의 합을 포함하는 손실 함수의 최소화에 기초하는, 시스템.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서, 상기 증류 손실 항은 상기 제1 예측으로부터의 상기 제2 예측의 제1 발산, 상기 제3 예측으로부터의 상기 제2 예측의 제2 발산, 및 상기 제1 예측으로부터의 상기 제3 예측의 제3 발산을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>10. 제8항에 있어서, 상기 손실 함수는 상기 제1, 제2, 및 제3 트레이닝 이미지들에 대한 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 적용에 기초한 교차 엔트로피 손실들의 합을 더 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 콘볼루션 신경 네트워크 계층은 프루닝된 콘볼루션 신경 네트워크 계층 또는 양자화된 콘볼루션 신경 네트워크 계층 중 하나를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>12. 이미지 분류를 위한 방법으로서,제1 해상도의 제1 이미지 및 상기 제1 해상도보다 작은 제2 해상도의 제2 이미지를 수신하는 단계;상기 제1 이미지에 대응하는 하나 이상의 제2 특징 맵을 생성하기 위해 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제1 이미지 또는 상기 제1 이미지에 대응하는 제1 특징 맵들에 콘볼루션 신경 네트워크 계층을 적용하는 단계;하나 이상의 제3 특징 맵을 생성하기 위해 복수의 제1 정규화 파라미터들을 사용하여 상기 하나 이상의 제2 특징 맵에 대해 제1 정규화를 수행하는 단계;상기 하나 이상의 제3 특징 맵을 사용하여 상기 제1 이미지에 대한 제1 라벨을 생성하는 단계;상기 제2 이미지에 대응하는 하나 이상의 제5 특징 맵을 생성하기 위해 상기 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제2 이미지 또는 상기 제2 이미지에 대응하는 제4 특징 맵들에 상기 콘볼루션 신경 네트워크 계층을 적용하는 단계;하나 이상의 제6 특징 맵을 생성하기 위해 상기 제1 정규화 파라미터들을 제외한 복수의 제2 정규화 파라미터들을 사용하여 상기 하나 이상의 제5 특징 맵에 대해 제2 정규화를 수행하는 단계; 및상기 하나 이상의 제6 특징 맵을 사용하여 상기 제2 이미지에 대한 제2 라벨을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서, 상기 제1 라벨을 생성하는 단계는 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 추가적인 제1 정규화를 적용하고 완전 연결 계층을 적용하는 단계를 포함하고, 상기 제2 라벨을 생성하는 단계는 상기 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 상기 추가적인 제1 정규화들에서 사용되는 파라미터들을 제외한 파라미터들을 사용하는 추가적인 제2 정규화를 적용하고 상기 완전 연결 계층을 적용하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제12항 또는 제13항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 및 제2 해상도들 제각기에서의 제1 및 제2 트레이닝 이미지들 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1 및 제2 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -; 및트레이닝 반복에서, 상기 제1 및 제2 트레이닝 이미지들에 대한 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 적용에 기초하여 교차 엔트로피 손실들의 합을 포함하는 손실 항을 사용하여 병렬로 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 파라미터 조정에 기초하여 트레이닝되는 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>15. 제12항 또는 제13항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 해상도, 상기 제2 해상도, 및 상기 제2 해상도보다 작은 제3 해상도의 제1, 제2, 및 제3 트레이닝 이미지들, 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1, 제2, 및 제3 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -;트레이닝 반복에서, 상기 제1, 제2, 및 제3 트레이닝 이미지들을, 제각기, 사용하여 이루어지는 제1, 제2, 및 제3 예측들에 기초한 앙상블 예측의 생성; 및상기 앙상블 예측과 상기 실측 라벨의 비교에 기초하여 트레이닝되는 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서, 상기 트레이닝 반복에서, 파라미터들 업데이트는 상기 앙상블 예측을 사용한 분류 확률에 기초한 앙상블 손실 항과 상기 앙상블 예측으로부터의 상기 제1, 제2, 및 제3 예측들 각각의 발산에 기초한 증류 손실 항의 합을 포함하는 손실 함수의 최소화에 기초하는, 방법.</claim></claimInfo><claimInfo><claim>17. 복수의 명령어들을 포함하는 적어도 하나의 머신 판독 가능 매체로서, 상기 복수의 명령어들은, 디바이스 상에서 실행되는 것에 응답하여, 상기 디바이스로 하여금인간 얼굴의 표현들을 포함하는 복수의 순차적인 비디오 이미지들을 수신하는 단계;제1 해상도의 제1 이미지 및 상기 제1 해상도보다 작은 제2 해상도의 제2 이미지를 수신하는 단계;상기 제1 이미지에 대응하는 하나 이상의 제2 특징 맵을 생성하기 위해 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제1 이미지 또는 상기 제1 이미지에 대응하는 제1 특징 맵들에 콘볼루션 신경 네트워크 계층을 적용하는 단계;하나 이상의 제3 특징 맵을 생성하기 위해 복수의 제1 정규화 파라미터들을 사용하여 상기 하나 이상의 제2 특징 맵에 대해 제1 정규화를 수행하는 단계;상기 하나 이상의 제3 특징 맵을 사용하여 상기 제1 이미지에 대한 제1 라벨을 생성하는 단계;상기 제2 이미지에 대응하는 하나 이상의 제5 특징 맵을 생성하기 위해 상기 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제2 이미지 또는 상기 제2 이미지에 대응하는 제4 특징 맵들에 상기 콘볼루션 신경 네트워크 계층을 적용하는 단계;하나 이상의 제6 특징 맵을 생성하기 위해 상기 제1 정규화 파라미터들을 제외한 복수의 제2 정규화 파라미터들을 사용하여 상기 하나 이상의 제5 특징 맵에 대해 제2 정규화를 수행하는 단계; 및상기 하나 이상의 제6 특징 맵을 사용하여 상기 제2 이미지에 대한 제2 라벨을 생성하는 단계에 의해 이미지 분류를 수행하게 하는, 머신 판독 가능 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서, 상기 제1 라벨을 생성하는 단계는 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 추가적인 제1 정규화를 적용하고 완전 연결 계층을 적용하는 단계를 포함하고, 상기 제2 라벨을 생성하는 단계는 상기 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 상기 추가적인 제1 정규화들에서 사용되는 파라미터들을 제외한 파라미터들을 사용하는 추가적인 제2 정규화를 적용하고 상기 완전 연결 계층을 적용하는 단계를 포함하는, 머신 판독 가능 매체.</claim></claimInfo><claimInfo><claim>19. 제17항 또는 제18항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 및 제2 해상도들 제각기에서의 제1 및 제2 트레이닝 이미지들 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1 및 제2 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -; 및트레이닝 반복에서, 상기 제1 및 제2 트레이닝 이미지들에 대한 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 적용에 기초하여 교차 엔트로피 손실들의 합을 포함하는 손실 항을 사용하여 병렬로 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 파라미터 조정에 기초하여 트레이닝되는 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 머신 판독 가능 매체.</claim></claimInfo><claimInfo><claim>20. 제17항 또는 제18항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 해상도, 상기 제2 해상도, 및 상기 제2 해상도보다 작은 제3 해상도의 제1, 제2, 및 제3 트레이닝 이미지들, 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1, 제2, 및 제3 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -;트레이닝 반복에서, 상기 제1, 제2, 및 제3 트레이닝 이미지들을, 제각기, 사용하여 이루어지는 제1, 제2, 및 제3 예측들에 기초한 앙상블 예측의 생성; 및상기 앙상블 예측과 상기 실측 라벨의 비교에 기초하여 트레이닝되는 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 머신 판독 가능 매체.</claim></claimInfo><claimInfo><claim>21. 제20항에 있어서, 상기 트레이닝 반복에서, 파라미터들 업데이트는 상기 앙상블 예측을 사용한 분류 확률에 기초한 앙상블 손실 항과 상기 앙상블 예측으로부터의 상기 제1, 제2, 및 제3 예측들 각각의 발산에 기초한 증류 손실 항의 합을 포함하는 손실 함수의 최소화에 기초하는, 머신 판독 가능 매체.</claim></claimInfo><claimInfo><claim>22. 시스템으로서,제1 해상도의 제1 이미지 및 상기 제1 해상도보다 작은 제2 해상도의 제2 이미지를 수신하기 위한 수단;상기 제1 이미지에 대응하는 하나 이상의 제2 특징 맵을 생성하기 위해 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제1 이미지 또는 상기 제1 이미지에 대응하는 제1 특징 맵들에 콘볼루션 신경 네트워크 계층을 적용하기 위한 수단;하나 이상의 제3 특징 맵을 생성하기 위해 복수의 제1 정규화 파라미터들을 사용하여 상기 하나 이상의 제2 특징 맵에 대해 제1 정규화를 수행하기 위한 수단;상기 하나 이상의 제3 특징 맵을 사용하여 상기 제1 이미지에 대한 제1 라벨을 생성하기 위한 수단;상기 제2 이미지에 대응하는 하나 이상의 제5 특징 맵을 생성하기 위해 상기 복수의 콘볼루션 계층 파라미터들을 사용하여 상기 제2 이미지 또는 상기 제2 이미지에 대응하는 제4 특징 맵들에 상기 콘볼루션 신경 네트워크 계층을 적용하기 위한 수단;하나 이상의 제6 특징 맵을 생성하기 위해 상기 제1 정규화 파라미터들을 제외한 복수의 제2 정규화 파라미터들을 사용하여 상기 하나 이상의 제5 특징 맵에 대해 제2 정규화를 수행하기 위한 수단; 및상기 하나 이상의 제6 특징 맵을 사용하여 상기 제2 이미지에 대한 제2 라벨을 생성하기 위한 수단을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서, 상기 제1 라벨을 생성하기 위한 수단은 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 추가적인 제1 정규화를 적용하기 위한 수단 및 완전 연결 계층을 적용하기 위한 수단을 포함하고, 상기 제2 라벨을 생성하기 위한 수단은 상기 하나 이상의 추가적인 콘볼루션 신경 네트워크 계층 및 각각에 뒤이어서 상기 추가적인 제1 정규화들에서 사용되는 파라미터들을 제외한 파라미터들을 사용하는 추가적인 제2 정규화를 적용하기 위한 수단 및 상기 완전 연결 계층을 적용하기 위한 수단을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>24. 제22항 또는 제23항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 및 제2 해상도들 제각기에서의 제1 및 제2 트레이닝 이미지들 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1 및 제2 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -; 및트레이닝 반복에서, 상기 제1 및 제2 트레이닝 이미지들에 대한 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 적용에 기초하여 교차 엔트로피 손실들의 합을 포함하는 손실 항을 사용하여 병렬로 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들의 파라미터 조정에 기초하여 트레이닝되는 상기 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>25. 제22항 또는 제23항에 있어서, 상기 콘볼루션 계층 파라미터들, 상기 제1 정규화 파라미터들, 및 상기 제2 정규화 파라미터들은상기 제1 해상도, 상기 제2 해상도, 및 상기 제2 해상도보다 작은 제3 해상도의 제1, 제2, 및 제3 트레이닝 이미지들, 및 대응하는 실측 라벨을 포함하는 트레이닝 세트의 생성 - 상기 제1, 제2, 및 제3 트레이닝 이미지들은 동일한 이미지 인스턴스에 대응함 -;트레이닝 반복에서, 상기 제1, 제2, 및 제3 트레이닝 이미지들을, 제각기, 사용하여 이루어지는 제1, 제2, 및 제3 예측들에 기초한 앙상블 예측의 생성; 및상기 앙상블 예측과 상기 실측 라벨의 비교에 기초하여 트레이닝되는 사전 트레이닝된 콘볼루션 신경 네트워크 파라미터들을 포함하는, 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미합중국 캘리포니아 ***** 산타클라라 미션 칼리지 블러바드 ****</address><code>519980776869</code><country>미국</country><engName>Intel Corporation</engName><name>인텔 코포레이션</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 ****** 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>YAO, Anbang</engName><name>야오, 안방</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>WANG, Yikai</engName><name>왕, 이카이</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>LU, Ming</engName><name>루, 밍</name></inventorInfo><inventorInfo><address>중국 ****** 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>WANG, Shandong</engName><name>왕, 산둥</name></inventorInfo><inventorInfo><address>중국 ****** 상하이 푸둥 디스트...</address><code> </code><country> </country><engName>CHEN, Feng</engName><name>천, 펑</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.11.15</receiptDate><receiptNumber>1-1-2022-1214472-10</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2023.01.18</receiptDate><receiptNumber>1-5-2023-0010838-03</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.06.15</receiptDate><receiptNumber>1-1-2023-0658182-87</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.06.15</receiptDate><receiptNumber>1-1-2023-0658193-89</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.10.30</receiptDate><receiptNumber>9-5-2025-1056739-04</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227039936.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9384ae106a74182b30ee9628bb94a5bd7cd5ea9e3cf0bdc39e84c1fb5253f31b24d1af47e009a9fb6d0972ac728af343c0e31517879a0a9e02</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf763009c91bff606c148c348b48f494ab40c3c49c614ba4869233c9c5de76df2252093847026717cd03f2a72034a3526e928513bfcd7fe1c9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>