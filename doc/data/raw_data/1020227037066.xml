<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:15.5115</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.05.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-7037066</applicationNumber><claimCount>23</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오 태그 추천 모델의 트레이닝 방법 및 장치, 비디오 태그 확정 방법 및 장치, 전자장비, 저장매체 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>METHOD FOR TRAINING VIDEO LABEL RECOMMENDATION MODEL, AND METHOD FOR DETERMINING VIDEO LABEL</inventionTitleEng><openDate>2022.11.17</openDate><openNumber>10-2022-0153088</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2022.10.24</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2022.10.24</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 10/774</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/10</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 발명은 인식 모델의 트레이닝 방법, 인식 방법, 장치, 장비 및 저장매체에 관한 것으로서, 딥러닝, 컴퓨터 비전 기술 분야에 관한 것이다. 구체적인 구현 방안은, 처리하고자 하는 영상을 트레이닝하고자 하는 인식 모델에 입력하는 것, 상기 트레이닝하고자 하는 인식 모델의 특징 출력층을 통해, 상기 처리하고자 하는 영상의 적어도 한 장의 특징 맵을 출력하는 것, 상기 트레이닝하고자 하는 인식 모델의 헤드를 통해, 상기 적어도 한 장의 특징 맵에 따라 상기 처리하고자 하는 영상 중의 제1 목표 물체의 예측 데이터, 및 상기 처리하고자 하는 영상 중의 상기 제1 목표 물체의 예측 데이터와 연관되는 제2 목표 물체의 예측 데이터를 취득하는 것, 및 제1 목표 물체의 예측 데이터, 제2 목표 물체의 예측 데이터, 제1 목표 물체의 플래그 데이터 및 제2 목표 물체의 플래그 데이터에 따라, 상기 트레이닝하고자 하는 인식 모델을 최적화하여, 트레이닝된 인식 모델을 얻는 것을 포함한다. 본 개시의 실시는 인식 모델의 인식 효율 및 인식 효과를 향상시킬 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate>2022.05.31</internationalApplicationDate><internationalApplicationNumber>PCT/CN2022/096229</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 처리하고자 하는 영상을 트레이닝하고자 하는 인식 모델에 입력하는 것,상기 트레이닝하고자 하는 인식 모델의 특징 출력층을 통해, 상기 처리하고자 하는 영상의 적어도 한 장의 특징 맵을 출력하는 것,상기 트레이닝하고자 하는 인식 모델의 헤드를 통해, 상기 적어도 한 장의 특징 맵에 따라 상기 처리하고자 하는 영상 중의 제1 목표 물체의 예측 데이터, 및 상기 처리하고자 하는 영상 중의 상기 제1 목표 물체의 예측 데이터와 연관되는 제2 목표 물체의 예측 데이터를 취득하는 것, 및제1 목표 물체의 예측 데이터, 제2 목표 물체의 예측 데이터, 제1 목표 물체의 플래그 데이터 및 제2 목표 물체의 플래그 데이터에 따라, 상기 트레이닝하고자 하는 인식 모델을 최적화하여, 트레이닝된 인식 모델을 얻는 것을 포함하는인식 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 상기 제1 목표 물체의 예측 데이터는 상기 제1 목표 물체의 분류 예측 데이터와 상기 제1 목표 물체의 속성 예측 데이터를 포함하고, 상기 제2 목표 물체의 예측 데이터는 상기 제2 목표 물체의 예측 데이터와 상기 제2 목표 물체의 속성 예측 데이터를 포함하는인식 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항 중 어느 한 항에 있어서,상기 트레이닝하고자 하는 인식 모델의 헤드를 통해, 제1 목표 물체의 예측 데이터, 및 상기 제1 목표 물체의 예측 데이터와 연관되는 제2 목표 물체의 예측 데이터를 출력하는 것은,상기 특징 맵의 각 화소에 대해, 상기 제1 목표 물체의 앵커 박스 예측 데이터 및 상기 제2 목표 물체의 앵커 박스 예측 데이터를 출력하는 것, 및상기 제1 목표 물체의 앵커 박스 예측 데이터 및 상기 제2 목표 물체의 앵커 박스 예측 데이터에 따라, 상기 제1 목표 물체의 예측 데이터 및 상기 제2 목표 물체의 예측 데이터를 출력하는 것을 포함하는인식 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서,상기 제1 목표 물체는 사람의 얼굴이고,상기 제2 목표 물체는 인체인인식 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,상기 특징 출력층은 백본 네트워크 및 특징 피라미드 네트워크를 포함하고,상기 트레이닝하고자 하는 인식 모델의 특징 출력층을 통해, 상기 처리하고자 하는 영상의 적어도 한 장의 특징 맵을 출력하는 것은,상기 백본 네트워크를 통해, 상기 처리하고자 하는 영상의 복수 장의 제1 특징 맵을 출력하는 것,상기 복수 장의 제1 특징 맵 중의 N장의 제2 특징 맵을 상기 특징 피라미드 네트워크에 입력하는 것, 여기서, N은 1 이상의 정수이고,상기 특징 피라미드 네트워크를 통해, N장의 제3 특징 맵을 출력하는 것, 및상기 N장의 제3 특징 맵을 상기 특징 맵으로 하는 것을 포함하는인식 모델의 트레이닝 방법.</claim></claimInfo><claimInfo><claim>6. 인식하고자 하는 영상을 인식 모델에 입력하여, 상기 인식하고자 하는 영상 중의 제1 목표 물체의 예측 데이터 및 상기 제1 목표 물체와 연관되는 제2 목표 물체의 예측 데이터를 취득하는 것을 포함하고,상기 인식 모델은 제1항 내지 제5항 중 어느 한 항의 트레이닝된 인식 모델인인식 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 인식하고자 하는 영상은 인식하고자 하는 비디오 중의 프레임 영상이고,상기 방법은,상기 제1 목표 물체의 예측 데이터 및 상기 제2 목표 물체의 예측 데이터에 따라, 상기 인식하고자 하는 비디오 중의 키 프레임 영상을 취득하는 것을 더 포함하는인식 방법.</claim></claimInfo><claimInfo><claim>8. 처리하고자 하는 영상을 트레이닝하고자 하는 인식 모델에 입력하기 위한 제1 입력 모듈,상기 트레이닝하고자 하는 인식 모델의 특징 출력층을 통해, 상기 처리하고자 하는 영상의 적어도 한 장의 특징 맵을 출력하기 위한 특징 맵 모듈,상기 트레이닝하고자 하는 인식 모델의 헤드를 통해, 상기 적어도 한 장의 특징 맵에 따라 상기 처리하고자 하는 영상 중의 제1 목표 물체의 예측 데이터, 및 상기 처리하고자 하는 영상 중의 상기 제1 목표 물체의 예측 데이터와 연관되는 제2 목표 물체의 예측 데이터를 취득하기 위한 예측 데이터 모듈, 및제1 목표 물체의 예측 데이터, 제2 목표 물체의 예측 데이터, 제1 목표 물체의 플래그 데이터 및 제2 목표 물체의 플래그 데이터에 따라, 상기 트레이닝하고자 하는 인식 모델을 최적화하여, 트레이닝된 인식 모델을 얻기 위한 트레이닝 모듈을 포함하는인식 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 제1 목표 물체의 예측 데이터는 상기 제1 목표 물체의 분류 예측 데이터와 상기 제1 목표 물체의 속성 예측 데이터를 포함하고,상기 제2 목표 물체의 예측 데이터는 상기 제2 목표 물체의 예측 데이터와 상기 제2 목표 물체의 속성 예측 데이터를 포함하는인식 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>10. 제8항 또는 제9항 중 어느 한 항에 있어서,상기 예측 데이터 모듈은,상기 특징 맵의 각 화소에 대해, 상기 제1 목표 물체의 앵커 박스 예측 데이터 및 상기 제2 목표 물체의 앵커 박스 예측 데이터를 출력하기 위한 제1 예측 수단, 및상기 제1 목표 물체의 앵커 박스 예측 데이터 및 상기 제2 목표 물체의 앵커 박스 예측 데이터에 따라, 상기 제1 목표 물체의 예측 데이터 및 상기 제2 목표 물체의 예측 데이터를 출력하기 위한 제2 예측 수단을 포함하는인식 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>11. 제8항 내지 제10항 중 어느 한 항에 있어서,상기 제1 목표 물체는 사람의 얼굴이고,상기 제2 목표 물체는 인체인인식 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>12. 제8항 내지 제11항 중 어느 한 항에 있어서,상기 특징 출력층은 백본 네트워크 및 특징 피라미드 네트워크를 포함하고,상기 특징 맵 모듈은,상기 백본 네트워크를 통해, 처리하고자 하는 영상의 복수 장의 제1 특징 맵을 출력하기 위한 제1 특징 맵 수단,상기 복수 장의 제1 특징 맵 중의 N장의 제2 특징 맵을 상기 특징 피라미드 네트워크에 입력하기 위한 제1 특징 맵 입력 수단, 여기서, N은 1 이상의 정수이고,상기 특징 피라미드 네트워크를 통해, N장의 제3 특징 맵을 출력하기 위한 제2 특징 맵 수단, 및상기 N장의 제3 특징 맵을 상기 특징 맵으로 하기 위한 제2 특징 맵 처리 수단을 포함하는인식 모델의 트레이닝 장치.</claim></claimInfo><claimInfo><claim>13. 인식하고자 하는 영상을 인식 모델에 입력하여, 상기 인식하고자 하는 영상 중의 제1 목표 물체의 예측 데이터 및 상기 제1 목표 물체와 연관되는 제2 목표 물체의 예측 데이터를 취득하기 위한 제2 입력 모듈을 포함하고,상기 인식 모델은 제8항 내지 제12항 중 어느 한 항의 트레이닝된 인식 모델인인식 장치.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 인식하고자 하는 영상은 인식하고자 하는 비디오 중의 프레임 영상이고,상기 장치는,상기 제1 목표 물체의 예측 데이터 및 상기 제2 목표 물체의 예측 데이터에 따라, 상기 인식하고자 하는 비디오 중의 키 프레임 영상을 취득하기 위한 키 프레임 영상 모듈을 더 포함하는인식 장치.</claim></claimInfo><claimInfo><claim>15. 적어도 하나의 프로세서, 및상기 적어도 하나의 프로세서와 통신가능하게 연결되는 메모리를 포함하는 전자장비로서,상기 메모리에는 상기 적어도 하나의 프로세서에 의해 실행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 실행될 경우, 상기 적어도 하나의 프로세서로 하여금 제1항 내지 제7항 중 어느 한 항의 방법을 실행하도록 하는 것을 특징으로 하는전자장비.</claim></claimInfo><claimInfo><claim>16. 컴퓨터 명령이 저장되어 있는 비 일시적 컴퓨터 판독가능 저장매체로서,상기 컴퓨터 명령은 상기 컴퓨터로 하여금 제1항 내지 제7항 중 어느 한 항의 방법을 실행하도록 하는 것을 특징으로 하는비 일시적 컴퓨터 판독가능 저장매체.</claim></claimInfo><claimInfo><claim>17. 컴퓨터 프로그램을 포함한 컴퓨터 프로그램 제품으로서,상기 컴퓨터 프로그램이 프로세서에 의해 실행될 경우,제1항 내지 제7항 중 어느 한 항의 방법을 구현하는 컴퓨터 프로그램 제품.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>Zhi YE</engName><name>지 예</name></inventorInfo><inventorInfo><address>중국 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>Xin TANG</engName><name>신 탕</name></inventorInfo><inventorInfo><address>중국 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>Hewei WANG</engName><name>허웨이 왕</name></inventorInfo><inventorInfo><address>중국 베이징 하이디안 디스트릭트...</address><code> </code><country> </country><engName>Li GE</engName><name>리 게</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서대문구 경기대로 **,  진양빌딩 *층(충정로*가)</address><code>920191001412</code><country>대한민국</country><engName>WeThePeople IP &amp; Law Firm</engName><name>특허법인위더피플</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2021.07.01</priorityApplicationDate><priorityApplicationNumber>202110754370.4</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2022.10.24</receiptDate><receiptNumber>1-1-2022-1122606-62</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.10.25</receiptDate><receiptNumber>1-1-2022-1126148-45</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.11.07</receiptDate><receiptNumber>1-1-2022-1178512-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2022.11.07</receiptDate><receiptNumber>1-1-2022-1179817-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2022.11.08</receiptDate><receiptNumber>1-5-2022-0167312-02</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notification of reason for refusal</documentEngName><documentName>의견제출통지서</documentName><receiptDate>2025.09.30</receiptDate><receiptNumber>9-5-2025-0952806-14</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020227037066.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c930b4b8b70f55dbd806b081966d44a98cc6c51b96e13ec2dc0a6b26d920fe2c2da2322fe6d7afd14f1e86f3ef4e3c6c98ebd957d8be4a2e8f2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf39f9bb751af12ff4ef5cd47557c6bc003b0f22b997ceecfa0eaded9f3f0896f24b3a904391a80e8ea073c092e17a45003c295d4c4917d51a</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>