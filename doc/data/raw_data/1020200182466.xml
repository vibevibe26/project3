<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:11:22.1122</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.12.23</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0182466</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>딥 러닝을 사용하는 비디오 코덱 보조 실시간 비디오 향상</inventionTitle><inventionTitleEng>VIDEO CODEC ASSISTED REAL-TIME VIDEO ENHANCEMENT  USING DEEP LEARNING</inventionTitleEng><openDate>2022.01.04</openDate><openNumber>10-2022-0000796</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.12.20</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06T 9/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4046</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2024.01.01)</ipcDate><ipcNumber>G06T 3/4053</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/176</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/503</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/593</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/124</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2014.01.01)</ipcDate><ipcNumber>H04N 19/587</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 비디오 코덱 정보에 기반하여 선택적으로 적용되는 딥 러닝을 사용하는 가속화된 비디오 향상에 관련된 기법이 논의된다. 그러한 기법은 낮은 양자화 파라미터 프레임 내에 있는 디코딩된 비 스킵 블록에 선택적으로 딥 러닝 비디오 향상 네트워크를 적용하는 것과, 낮은 양자화 파라미터 프레임 내의 디코딩된 스킵 블록에 대해 딥 러닝 네트워크를 바이패스하는 것과, 높은 양자화 파라미터 프레임에 비 딥 러닝 비디오 향상을 적용하는 것을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적응적 향상 비디오 처리(adaptive enhancement video processing)를 제공하기 위한 시스템으로서,비트스트림(bitstream)을 저장하는 메모리와,상기 메모리에 커플링된 하나 이상의 프로세서를 포함하되, 상기 하나 이상의 프로세서는,비디오 프레임(video frame)의 제1 및 제2 블록을 생성하기 위해 비트스트림을 디코딩 - 상기 제1 및 제2 블록은 각각 제1 및 제2 비디오 코딩 모드를 포함함 - 하고,제1 출력 블록을 생성하기 위해 상기 제1 코딩 모드에 응답하여 상기 제1 블록에 딥 러닝 네트워크(deep learning network)를 적용하며,상기 제2 블록에의 상기 딥 러닝 네트워크의 적용을 바이패스하고(bypass) 상기 제2 코딩 모드에 응답하여 상기 제2 블록을 위해 사전의 제2 출력 블록을 인출하고(retrieve),상기 비디오 프레임에 대응하는 출력 비디오 프레임을, 상기 출력 비디오 프레임으로의 상기 제1 및 제2 출력 블록의 병합(merge)에 적어도 기반하여 생성하는,시스템.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 딥 러닝 네트워크는 딥 러닝 초해상도(super-resolution) 네트워크를 포함하고, 상기 비디오 프레임은 제1 해상도(resolution)에서의 것이며,상기 제1 출력 블록, 상기 제2 출력 블록 및 상기 출력 비디오 프레임은 상기 제1 해상도보다 큰 제2 해상도에서의 것인,시스템.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제2 비디오 코딩 모드는 어떤 코딩된 잔차 정보(coded residual information)도 없이 인터 코딩되고(inter coded), 상기 제2 블록은 대응하는 모션 벡터(motion vector)를 갖는,시스템.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 하나 이상의 프로세서가 상기 제2 출력 블록을 인출하는 것은 상기 하나 이상의 프로세서가 상기 모션 벡터를 사용하여 상기 비디오 프레임에 시간적으로 인접한(temporally adjacent) 제2 초해상도 비디오 프레임에 기반하여 상기 제2 출력 블록을 인출하는 것을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 하나 이상의 프로세서가 상기 제2 출력 블록을 인출하는 것은, 상기 하나 이상의 프로세서가, 상기 모션 벡터에 기반하여 조절되고 스케일링 인자(scaling factor)를 사용하여 스케일링된 상기 제2 블록의 수평 위치에서의 위치를 포함하고 상기 스케일링 인자를 사용하여 스케일링된 상기 제2 블록의 폭에 기반하여 크기를 갖는, 상기 제2 초해상도 비디오 프레임의 픽셀 샘플을 액세스하는 것을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>6. 제3항에 있어서,상기 제1 블록은 인트라 코딩되거나(intra coded), 코딩된 잔차 정보로써 인터 코딩된 것인,시스템.</claim></claimInfo><claimInfo><claim>7. 제2항에 있어서,상기 하나 이상의 프로세서는,제2 비디오 프레임의 제3 블록을 생성하기 위해 상기 비트스트림을 디코딩 - 상기 비디오 프레임은 제1 양자화 파라미터(quantization parameter)를 포함하고 상기 제2 프레임은 상기 제1 양자화 파라미터보다 작은 제2 양자화 파라미터를 포함함 - 하고,상기 제2 양자화 파라미터가 임계(threshold)보다 큰 것에 응답하여, 상기 제2 해상도로 제3 출력 블록을 생성하기 위해 상기 제3 블록에 보간(interpolation)을 적용하는,시스템.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 하나 이상의 프로세서가 상기 딥 러닝 네트워크를 상기 제1 블록에 적용하고, 상기 제2 블록에의 상기 딥 러닝 네트워크의 적용을 바이패스하고, 상기 제2 해상도로 상기 사전의 제2 출력 블록을 인출하는 것은 상기 제1 양자화 파라미터가 임계보다 작은 것에 응답하여서인,시스템.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 보간은 양선형(bilinear) 보간, 양입방(bicubic) 보간 또는 란초스(Lanczos) 보간 중 하나를 포함하고 상기 딥 러닝 네트워크는 적어도 하나의 콘볼루션 계층(convolutional layer)을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>10. 제7항에 있어서,상기 하나 이상의 프로세서는,상기 제1 및 제2 비디오 코딩 모드 및 상기 제1 및 제2 양자화 파라미터를 포함하는 메타데이터(metadata)를 생성하기 위해 상기 비트스트림을 디코딩하는,시스템.</claim></claimInfo><claimInfo><claim>11. 제2항에 있어서,상기 하나 이상의 프로세서는,상기 비디오 프레임의 제3 및 제4 블록을 생성하기 위해 상기 비트스트림을 디코딩 - 상기 제3 및 제4 블록은 각각 상기 제1 및 제2 비디오 코딩 모드를 포함하고, 상기 제1 및 제2 블록은 관심 영역 블록을 포함하고 상기 제3 및 제4 블록은 비 관심 영역 블록을 포함함 - 하고,상기 제2 해상도로 제3 출력 블록을 생성하기 위해 상기 제1 코딩 모드에 응답하여 상기 제3 블록에 상기 딥 러닝 네트워크를 적용하며,상기 제4 블록에의 상기 딥 러닝 초해상도 네트워크의 적용을 바이패스하고 상기 제2 코딩 모드에 응답하여 상기 제4 블록을 위해 상기 제2 해상도로 사전의 제4 출력 블록을 인출하되, 상기 하나 이상의 프로세서가 상기 출력 비디오 프레임을 생성하는 것은 상기 하나 이상의 프로세서가 상기 제3 및 제4 출력 블록을 상기 출력 비디오 프레임으로 병합하는 것을 포함하는,시스템.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 딥 러닝 네트워크는 딥 러닝 기반 안티에일리어싱(anti-aliasing) 네트워크 또는 딥 러닝 기반 잡음 감소(noise reduction) 네트워크 중 하나를 포함하는,시스템.</claim></claimInfo><claimInfo><claim>13. 적응적 향상 비디오 처리를 제공하기 위한 방법으로서,비디오 프레임의 제1 및 제2 블록을 생성하기 위해 비트스트림을 디코딩하는 단계 - 상기 제1 및 제2 블록은 각각 제1 및 제2 비디오 코딩 모드를 포함함 - 와,제1 출력 블록을 생성하기 위해 상기 제1 코딩 모드에 응답하여 상기 제1 블록에 딥 러닝 네트워크를 적용하는 단계와,상기 제2 블록에의 상기 딥 러닝 네트워크의 적용을 바이패스하고 상기 제2 코딩 모드에 응답하여 상기 제2 블록을 위해 사전의 제2 출력 블록을 인출하는 단계와,상기 비디오 프레임에 대응하는 출력 비디오 프레임을, 상기 제1 및 제2 출력 블록을 상기 출력 비디오 프레임으로 병합하는 것에 적어도 기반하여 생성하는 단계를 포함하는방법.</claim></claimInfo><claimInfo><claim>14. 제13항에 있어서,상기 딥 러닝 네트워크는 딥 러닝 초해상도 네트워크를 포함하고, 상기 비디오 프레임은 제1 해상도에서의 것이며, 상기 제1 출력 블록, 상기 제2 출력 블록 및 상기 출력 비디오 프레임은 상기 제1 해상도보다 큰 제2 해상도에서의 것이고, 상기 제2 비디오 코딩 모드는 어떤 코딩된 잔차 정보도 없이 인터 코딩되며 상기 제2 블록은 대응하는 모션 벡터를 갖고, 상기 제1 블록은 인트라 코딩되거나 코딩된 잔차 정보로써 인터 코딩된 것인,방법.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 제2 출력 블록을 인출하는 것은, 상기 모션 벡터를 사용하여 상기 비디오 프레임에 시간적으로 인접한 제2 초해상도 비디오 프레임에 기반하여 상기 제2 출력 블록을, 상기 모션 벡터에 기반하여 조절되고 스케일링 인자를 사용하여 스케일링된 상기 제2 블록의 수평 위치에서의 위치를 포함하고 상기 스케일링 인자를 사용하여 스케일링된 상기 제2 블록의 폭에 기반하여 크기를 갖는, 상기 제2 초해상도 비디오 프레임의 픽셀 샘플을 액세스함으로써, 인출하는 것을 포함하는,방법.</claim></claimInfo><claimInfo><claim>16. 제14항에 있어서,제2 비디오 프레임의 제3 블록을 생성하기 위해 상기 비트스트림을 디코딩하는 단계 - 상기 비디오 프레임은 제1 양자화 파라미터를 포함하고 상기 제2 프레임은 상기 제1 양자화 파라미터보다 작은 제2 양자화 파라미터를 포함함 - 와,상기 제2 양자화 파라미터가 임계보다 큰 것에 응답하여, 상기 제2 해상도로 제3 출력 블록을 생성하기 위해 상기 제3 블록에 보간을 적용하는 단계를 더 포함하는,방법.</claim></claimInfo><claimInfo><claim>17. 적어도 하나의 머신 판독가능 매체로서,컴퓨팅 디바이스 상에서 실행되는 것에 응답하여, 상기 컴퓨팅 디바이스로 하여금,비디오 프레임의 제1 및 제2 블록을 생성하기 위해 비트스트림을 디코딩하는 것 - 상기 제1 및 제2 블록은 각각 제1 및 제2 비디오 코딩 모드를 포함함 - 과,제1 출력 블록을 생성하기 위해 상기 제1 코딩 모드에 응답하여 상기 제1 블록에 딥 러닝 네트워크를 적용하는 것과,상기 제2 블록에의 상기 딥 러닝 네트워크의 적용을 바이패스하고 상기 제2 코딩 모드에 응답하여 상기 제2 블록을 위해 사전의 제2 출력 블록을 인출하는 것과,상기 비디오 프레임에 대응하는 출력 비디오 프레임을, 상기 제1 및 제2 출력 블록을 상기 출력 비디오 프레임으로 병합하는 것에 적어도 기반하여 생성하는 것에 의해 적응적 향상 비디오 처리를 제공하게 하는 복수의 명령어를 포함하는,머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 딥 러닝 네트워크는 딥 러닝 초해상도 네트워크를 포함하고, 상기 비디오 프레임은 제1 해상도에서의 것이며, 상기 제1 출력 블록, 상기 제2 출력 블록 및 상기 출력 비디오 프레임은 상기 제1 해상도보다 큰 제2 해상도에서의 것이고, 상기 제2 비디오 코딩 모드는 어떤 코딩된 잔차 정보도 없이 인터 코딩되며 상기 제2 블록은 대응하는 모션 벡터를 갖고, 상기 제1 블록은 인트라 코딩되거나 코딩된 잔차 정보로써 인터 코딩된 것인,머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 제2 출력 블록을 인출하는 것은, 상기 모션 벡터를 사용하여 상기 비디오 프레임에 시간적으로 인접한 제2 초해상도 비디오 프레임에 기반하여 상기 제2 출력 블록을, 상기 모션 벡터에 기반하여 조절되고 스케일링 인자를 사용하여 스케일링된 상기 제2 블록의 수평 위치에서의 위치를 포함하고 상기 스케일링 인자를 사용하여 스케일링된 상기 제2 블록의 폭에 기반하여 크기를 갖는, 상기 제2 초해상도 비디오 프레임의 픽셀 샘플을 액세스함으로써, 인출하는 것을 포함하는,머신 판독가능 매체.</claim></claimInfo><claimInfo><claim>20. 제18항에 있어서,상기 컴퓨팅 디바이스 상에서 실행되는 것에 응답하여, 상기 컴퓨팅 디바이스로 하여금,제2 비디오 프레임의 제3 블록을 생성하기 위해 상기 비트스트림을 디코딩하는 것 - 상기 비디오 프레임은 제1 양자화 파라미터를 포함하고 상기 제2 프레임은 상기 제1 양자화 파라미터보다 작은 제2 양자화 파라미터를 포함함 - 과,상기 제2 양자화 파라미터가 임계보다 큰 것에 응답하여, 상기 제2 해상도로 제3 출력 블록을 생성하기 위해 상기 제3 블록에 보간을 적용하는 것에 의해, 적응적 향상 비디오 처리를 제공하게 하는 명령어를 더 포함하는,머신 판독가능 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미합중국 캘리포니아 ***** 산타클라라 미션 칼리지 블러바드 ****</address><code>520000333491</code><country>미국</country><engName>Intel Corporation</engName><name>인텔 코포레이션</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 캘리포니아주 ***** 산 ...</address><code> </code><country> </country><engName>WANG, Chen</engName><name>왕 첸</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ****...</address><code> </code><country> </country><engName>ZHANG, Ximin</engName><name>장 시민</name></inventorInfo><inventorInfo><address>중국 베이징 ****** 하이디안 디스트...</address><code> </code><country> </country><engName>DOU, Huan</engName><name>도우 후안</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ****...</address><code> </code><country> </country><engName>CHIU, Yi-jen</engName><name>치우 이-젠</name></inventorInfo><inventorInfo><address>미국 캘리포니아주 ***...</address><code> </code><country> </country><engName>LEE, Sang-Hee</engName><name>이 상희</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 마방로 ** (양재동, 동원F&amp;B빌딩)</address><code>920101000812</code><country>대한민국</country><engName>FirstLaw P.C.</engName><name>제일특허법인(유)</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2020.06.26</priorityApplicationDate><priorityApplicationNumber>16/914,083</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.12.23</receiptDate><receiptNumber>1-1-2020-1405535-54</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>Submission of Priority Certificate(USPTO)</documentEngName><documentName>우선권주장증명서류제출서(USPTO)</documentName><receiptDate>2020.12.28</receiptDate><receiptNumber>9-1-2020-9012720-61</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2023.12.20</receiptDate><receiptNumber>1-1-2023-1432401-82</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.12.20</receiptDate><receiptNumber>1-1-2023-1432449-62</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200182466.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c934f67f7ad2d692c8124646e5296a38d8f49e434bd1b3fd4d59fcd4829a371ff43609352ac96f467ab9981e5f07a62a8eb9962dca33fa88feb</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf6718172fad852662b079265157da859005c7cda2ead1ce672ed26185e9df9b81fabeec59eea871d164d3b769099bd4767f77d42f4e94aac9</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>