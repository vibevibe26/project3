<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:51:18.5118</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.04.08</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0047575</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>신경망 흐름을 고려한 그래프 트랜스포머를 활용하여 인공신경망 성능을 예측하는 방법, 컴퓨터 장치, 및 컴퓨터 프로그램</inventionTitle><inventionTitleEng>METHOD, COMPUTER DEVICE, AND COMPUTER PROGRAM FOR NEURAL  ARCHITECTURE PERFORMANCE PREDICTION USING FLOW-AWARE GRAPH  TRANSFORMER</inventionTitleEng><openDate>2025.10.15</openDate><openNumber>10-2025-0149035</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.04.09</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/042</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 신경망 흐름을 고려한 그래프 트랜스포머를 활용하여 인공신경망 성능을 예측하는 방법, 컴퓨터 장치, 및 컴퓨터 프로그램이 개시된다. 인공신경망 성능 예측 방법은, 주어진 인공신경망의 구조를 그래프로 표현하는 단계; 및 상기 인공신경망의 성능 예측을 위해 상기 인공신경망에 대한 그래프 표현을 상기 인공신경망의 정보 흐름에 기반한 그래프 트랜스포머(graph transformer)를 통해 학습하는 단계를 포함할 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 적어도 하나의 프로세서를 포함하는 컴퓨터 장치의 인공신경망 성능 예측 방법에 있어서,상기 적어도 하나의 프로세서에 의해, 주어진 인공신경망의 구조를 그래프로 표현하는 단계; 및상기 적어도 하나의 프로세서에 의해, 상기 인공신경망의 성능 예측을 위해 상기 인공신경망에 대한 그래프 표현을 상기 인공신경망의 정보 흐름에 기반한 그래프 트랜스포머(graph transformer)를 통해 학습하는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 표현하는 단계는,상기 인공신경망의 구조를 DAG(directed acyclic graph)로 표현하는 것을 특징으로 하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>3. 제1항에 있어서,상기 표현하는 단계는,상기 인공신경망의 구조를 DAG(directed acyclic graph)로 표현하는 것으로,상기 인공신경망의 연산(operation)을 노드로 나타내고,연산 간의 정보 흐름(information flow)을 노드 간의 방향 엣지(directional edge)로 나타내고,상기 방향 엣지는 순방향 전파(forward pass) 동안 학습 전파 방향에 맞춰 정렬되는 것을 특징으로 하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 표현하는 단계는,상기 인공신경망의 그래프 표현을 노드 쌍 간의 연결을 인코딩하는 인접 행렬(adjacency matrix)과 상기 인공신경망의 연산에 해당되는 노드 특징 행렬(node feature matrix)로 나타내는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 학습하는 단계는,상기 인공신경망의 데이터가 순방향으로 전달되고 손실함수를 통해 구해진 손실 값의 기울기가 역방향으로 전달되는 흐름을 고려하여 상기 그래프 표현을 학습하는 것을 특징으로 하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에 있어서,상기 학습하는 단계는,각 레이어에 대해 양방향 비동기 메시지 전달을 이용하여 로컬 수준에서의 정보 흐름을 학습하는 흐름 인코딩 모듈(flow encode module), 및 흐름 기반 마스킹 방식을 이용하여 글로벌 수준에서의 정보 흐름을 학습하는 흐름 인식 글로벌 어텐션 모듈(flow-aware global attention module)로 구성된 상기 그래프 트랜스포머를 통해 상기 그래프 표현의 임베딩을 생성하는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서,상기 생성하는 단계는,상기 양방향 비동기 메시지 전달을 수행하여 제1 노드 임베딩 행렬을 생성하는 단계;상기 흐름 기반 마스킹 방식으로 어텐션을 계산하여 제2 노드 임베딩 행렬을 생성하는 단계; 및상기 제1 노드 임베딩 행렬과 상기 제2 노드 임베딩 행렬을 결합하여 업데이트된 노드 임베딩 행렬을 생성하는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>8. 제6항에 있어서,상기 생성하는 단계는,상기 흐름 인코딩 모듈을 통해 상기 인공신경망의 연산 순서에 따라 순차적으로 상기 인공신경망의 노드 표현을 갱신하는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>9. 제6항에 있어서,상기 생성하는 단계는,상기 흐름 인식 글로벌 어텐션 모듈을 통해 상기 인공신경망의 적어도 하나 이상의 경로에서 상호작용하는 연산 쌍으로 어텐션 범위를 한정하여 정보 흐름을 파악하는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>10. 제6항에 있어서,상기 흐름 인코딩 모듈은 메시지를 순방향으로 전달한 다음 역방향으로 전달하는 메시지 전달 신경망(message-passing neural network)으로 구성되고,상기 흐름 인식 글로벌 어텐션 모듈은 흐름 인식 마스킹 방식을 기반으로 한 셀프 어텐션 모듈(self-attention module)로 구성된 것을 특징으로 하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>11. 제7항에 있어서,상기 제1 노드 임베딩 행렬을 생성하는 단계는,상기 인공신경망의 연산을 나타내는 노드를 위상 세대(topological generation)로 나누는 단계;순방향 메시지 전달을 통해 노드 임베딩을 상기 위상 세대의 순방향 순서에 따라 업데이트하는 단계; 및역방향 메시지 전달을 통해 상기 노드 임베딩을 상기 위상 세대의 역방향 순서에 따라 업데이트하는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>12. 제7항에 있어서,상기 제2 노드 임베딩 행렬을 생성하는 단계는,마스크 멀티헤드 어텐션 모듈(masked multi-head attention module)을 통해 상기 인공신경망의 그래프 표현에 대한 입력 노드 임베딩 행렬과, 노드 간의 방향 경로(directed path) 유무에 따른 마스킹 전략이 정의된 마스크 행렬을 이용하여 출력 노드 임베딩 행렬을 계산하는 단계를 포함하는 인공신경망 성능 예측 방법.</claim></claimInfo><claimInfo><claim>13. 인공신경망 성능 예측 방법을 컴퓨터 장치에 실행시키기 위해 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램에 있어서,상기 인공신경망 성능 예측 방법은,주어진 인공신경망의 구조를 그래프로 표현하는 단계; 및상기 인공신경망의 성능 예측을 위해 상기 인공신경망에 대한 그래프 표현을 상기 인공신경망의 정보 흐름에 기반한 그래프 트랜스포머(graph transformer)를 통해 학습하는 단계를 포함하는, 컴퓨터 판독 가능한 기록매체에 저장된 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>14. 컴퓨터 장치에서 판독 가능한 명령을 실행하도록 구현되는 적어도 하나의 프로세서를 포함하고,상기 적어도 하나의 프로세서는,주어진 인공신경망의 구조를 그래프로 표현하고,상기 인공신경망의 성능 예측을 위해 상기 인공신경망에 대한 그래프 표현을 상기 인공신경망의 정보 흐름에 기반한 그래프 트랜스포머(graph transformer)를 통해 학습하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 그래프 트랜스포머는,양방향 비동기 메시지 전달을 이용하여 로컬 수준에서의 정보 흐름을 학습하는 흐름 인코딩 모듈(flow encode module), 및 흐름 기반 마스킹 방식을 이용하여 글로벌 수준에서의 정보 흐름을 학습하는 흐름 인식 글로벌 어텐션 모듈(flow-aware global attention module)로 구성되는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 흐름 인코딩 모듈은 상기 인공신경망의 연산 순서에 따라 순차적으로 상기 인공신경망의 노드 표현을 갱신하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>17. 제15항에 있어서,상기 흐름 인식 글로벌 어텐션 모듈은 상기 인공신경망의 적어도 하나 이상의 경로에서 상호작용하는 연산 쌍으로 어텐션 범위를 한정하여 정보 흐름을 파악하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>18. 제15항에 있어서,상기 흐름 인코딩 모듈은 메시지를 순방향으로 전달한 다음 역방향으로 전달하는 메시지 전달 신경망(message-passing neural network)으로 구성되고,상기 흐름 인식 글로벌 어텐션 모듈은 흐름 인식 마스킹 방식을 기반으로 한 셀프 어텐션 모듈(self-attention module)로 구성된 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>19. 제15항에 있어서,상기 흐름 인코딩 모듈은 상기 인공신경망의 연산을 나타내는 노드를 위상 세대(topological generation)로 나누어 순방향 메시지 전달을 통해 노드 임베딩을 상기 위상 세대의 순방향 순서에 따라 업데이트하고 역방향 메시지 전달을 통해 상기 노드 임베딩을 상기 위상 세대의 역방향 순서에 따라 업데이트하고,상기 흐름 인식 글로벌 어텐션 모듈은 마스크 멀티헤드 어텐션 모듈(masked multi-head attention module)을 통해 상기 인공신경망의 그래프 표현에 대한 입력 노드 임베딩 행렬과, 노드 간의 방향 경로(directed path) 유무에 따른 마스킹 전략이 정의된 마스크 행렬을 이용하여 출력 노드 임베딩 행렬을 계산하는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo><claimInfo><claim>20. 제15항에 있어서,상기 흐름 인코딩 모듈과 상기 흐름 인식 글로벌 어텐션 모듈에 스킵 연결(skip-connection)과 배치 정규화(batch normalization)가 포함되는 것을 특징으로 하는 컴퓨터 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980988661</code><country>대한민국</country><engName>Korea Advanced Institute of Science and Technology</engName><name>한국과학기술원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Shin, Kijung</engName><name>신기정</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Hwang, Dongyeong</engName><name>황동영</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Kim, Hyunju</engName><name>김현주</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>Kim, Sunwoo</engName><name>김선우</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 선릉로***길 ** (논현동) 삼성빌딩 *층(피앤티특허법률사무소)</address><code>920050004530</code><country>대한민국</country><engName>Yang,Sung Bo</engName><name>양성보</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.04.08</receiptDate><receiptNumber>1-1-2024-0389350-53</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2024.04.09</receiptDate><receiptNumber>1-1-2024-0392328-29</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240047575.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b1533be7776e569a96d7af6f2b18c5202486a5483ae1580e6b58f97f150ac7c8888f4f4e225ceb94b0f08d7e9e84ce52143a259795707992</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfbc9f22dbc6a44697d64d64e4efb2bdd5d1c672af2f7eeb410f0d1bee50d6116c3dda2f8ee7ee431c755bc0b430222c07b9e813d05360afec</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>