<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 17:53:54.5354</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.07.27</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7006947</applicationNumber><claimCount>30</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>오디오 컨퍼런싱에 대한 자동 음소거 및 음소거해제</inventionTitle><inventionTitleEng>AUTOMATIC MUTE AND UNMUTE FOR AUDIO CONFERENCING</inventionTitleEng><openDate>2024.05.10</openDate><openNumber>10-2024-0063108</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.07.10</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.02.28</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>H04L 65/4038</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06N 20/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/04</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2020.01.01)</ipcDate><ipcNumber>G06F 40/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2013.01.01)</ipcDate><ipcNumber>G10L 17/18</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 오디오 컨퍼런스를 제어하기 위한 기법들은 오디오 컨퍼런스에서의 참가자로부터 오디오 데이터를 수신하는 것, 오디오 데이터의 분석물을 생성하기 위해 오디오 데이터의 스피커 또는 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 오디오 데이터를 분석하는 것, 및 상기 오디오 데이터의 분석물에 기초하여 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하는 것을 포함한다. 마이크로폰은 스피커가 참가자가 아니거나 오디오의 컨텐츠가 오디오 컨퍼런스의 컨텍스트 외부에 있다는 결정에 기초하여 음소거될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.03.16</internationOpenDate><internationOpenNumber>WO2023039318</internationOpenNumber><internationalApplicationDate>2022.07.27</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/074205</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 오디오 컨퍼런스를 제어하도록 구성되는 장치로서,상기 오디오 컨퍼런스에서 참가자로부터 오디오 데이터를 수신하도록 구성된 메모리; 및상기 메모리와 통신하는 하나 이상의 프로세서들을 포함하고,상기 하나 이상의 프로세서들은: 상기 오디오 데이터의 분석물을 생성하기 위해 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하고; 그리고 상기 오디오 데이터의 상기 분석물에 기초하여 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>2. 제 1 항에 있어서, 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하기 위해, 상기 하나 이상의 프로세서들은:상기 오디오 데이터의 상기 분석물을 생성하기 위해 하나 이상의 인공 지능 기술들을 사용하여 상기 오디오 데이터를 분석하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>3. 제 2 항에 있어서, 상기 하나 이상의 인공 지능 기술들은 뉴럴 네트워크를 포함하는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>4. 제 2 항에 있어서, 상기 하나 이상의 인공 지능 기술들은 자연 언어 프로세싱을 포함하는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>5. 제 1 항에 있어서,상기 오디오 데이터의 상기 스피커를 결정하도록 상기 오디오 데이터를 분석하기 위해, 상기 하나 이상의 프로세서들은 또한:스피커 분류를 결정하기 위해 상기 참가자의 음성의 등록된 버전에 대한 상기 오디오 데이터를 분류하고; 그리고상기 오디오 데이터가 상기 스피커 분류에 기초하여 상기 참가자의 상기 음성을 나타내는지를 결정하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>6. 제 5 항에 있어서, 상기 오디오 데이터의 상기 분석물에 기초하여 상기 마이크로폰을 제어하거나 상기 참가자의 상기 오디오 데이터를 조정하기 위해, 상기 하나 이상의 프로세서들은:상기 오디오 데이터가 상기 참가자의 상기 음성을 나타내지 않는다는 결정에 기초하여 상기 마이크로폰을 음소거하거나 상기 참가자의 상기 오디오 데이터를 음소거하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>7. 제 5 항에 있어서, 상기 오디오 데이터의 상기 분석물에 기초하여 상기 마이크로폰을 제어하거나 상기 참가자의 상기 오디오 데이터를 조정하기 위해, 상기 하나 이상의 프로세서들은:상기 오디오 데이터가 상기 참가자의 상기 음성을 나타낸다는 결정에 기초하여 상기 마이크로폰을 음소거하지 않거나 상기 참가자의 상기 오디오 데이터를 음소거하지 않도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>8. 제 5 항에 있어서, 하나 이상의 프로세서들은:상기 참가자의 상기 음성의 상기 등록된 버전을 사용하여 뉴럴 네트워크를 트레이닝하도록 구성되고, 그리고 상기 오디오 데이터를 분류하기 위해, 상기 하나 이상의 프로세서들은 상기 뉴럴 네트워크를 사용하여 상기 오디오 데이터를 분류하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>9. 제 1 항에 있어서, 상기 오디오 데이터의 상기 컨텍스트를 결정하도록 상기 오디오 데이터를 분석하기 위해, 상기 하나 이상의 프로세서들은 또한:컨텍스트 분류를 결정하기 위해 트레이닝 데이터에 대해 상기 오디오 데이터의 컨텐츠를 분류하고;상기 오디오 데이터가 상기 컨텍스트 분류에 기초하여 상기 오디오 컨퍼런스의 컨텍스트를 나타내는지를 결정하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>10. 제 9 항에 있어서, 상기 오디오 데이터의 상기 분석물에 기초하여 상기 마이크로폰을 제어하거나 상기 참가자의 상기 오디오 데이터를 조정하기 위해, 상기 하나 이상의 프로세서들은:상기 오디오 데이터가 상기 오디오 컨퍼런스의 상기 컨텍스트를 나타내지 않는다는 결정에 기초하여 상기 마이크로폰을 음소거하거나 상기 참가자의 상기 오디오 데이터를 음소거하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>11. 제 9 항에 있어서, 상기 오디오 데이터의 상기 분석물에 기초하여 상기 마이크로폰을 제어하거나 상기 참가자의 상기 오디오 데이터를 조정하기 위해, 상기 하나 이상의 프로세서들은:상기 오디오 데이터가 상기 오디오 컨퍼런스의 상기 컨텍스트를 나타낸다는 결정에 기초하여 상기 마이크로폰을 음소거하지 않거나 상기 참가자의 상기 오디오 데이터를 음소거하지 않도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>12. 제 9 항에 있어서, 하나 이상의 프로세서들은:트레이닝 데이터를 사용하여 뉴럴 네트워크를 트레이닝하도록 구성되고, 상기 트레이닝 데이터는 오디오 컨퍼런스의 컨텍스트를 나타내는 문법을 포함하고, 상기 오디오 데이터를 분류하기 위해, 상기 하나 이상의 프로세서들은 상기 뉴럴 네트워크를 사용하여 상기 오디오 데이터를 분류하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>13. 제 1 항에 있어서, 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하기 위해, 상기 하나 이상의 프로세서들은 또한:스피커 분류를 결정하기 위해 상기 참가자의 음성의 등록된 버전에 대한 오디오 데이터를 분류하고; 상기 오디오 데이터가 상기 스피커 분류에 기초하여 상기 참가자의 상기 음성을 나타내는지를 결정하고;컨텍스트 분류를 결정하기 위해 트레이닝 데이터에 대해 상기 오디오 데이터의 컨텐츠를 분류하고;상기 오디오 데이터가 상기 컨텍스트 분류에 기초하여 상기 오디오 컨퍼런스의 컨텍스트를 나타내는지를 결정하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>14. 제 13 항에 있어서,상기 오디오 데이터의 상기 분석물에 기초하여 상기 마이크로폰을 제어하거나 상기 참가자의 상기 오디오 데이터를 조정하기 위해, 상기 하나 이상의 프로세서들은:상기 참가자의 상기 오디오 데이터가 음소거된다고 결정하고;상기 오디오 데이터가 상기 참가자의 상기 음성을 나타낸다는 결정에 기초하여 그리고 상기 오디오 데이터가 상기 오디오 컨퍼런스의 상기 컨텍스트를 나타낸다는 결정에 기초하여 상기 참가자의 상기 오디오 데이터를 음소거해제하도록 구성되는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo><claimInfo><claim>15. 오디오 컨퍼런스를 제어하기 위한 방법으로서,상기 오디오 컨퍼런스에서 참가자로부터 오디오 데이터를 수신하는 단계;상기 오디오 데이터의 분석물을 생성하기 위해 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하는 단계;상기 오디오 데이터의 분석물에 기초하여 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>16. 제 15 항에 있어서, 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하는 단계는:상기 오디오 데이터의 상기 분석물을 생성하기 위해 하나 이상의 인공 지능 기술들 또는 머신 러닝 기술들을 사용하여 상기 오디오 데이터를 분석하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>17. 제 16 항에 있어서, 상기 하나 이상의 인공 지능 기술들 또는 머신 러닝 기술들은 뉴럴 네트워크를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>18. 제 16 항에 있어서, 상기 하나 이상의 인공 지능 기술들 또는 머신 러닝 기술들은 자연 언어 프로세싱을 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>19. 제 15 항에 있어서, 상기 오디오 데이터의 스피커를 결정하도록 상기 오디오 데이터를 분석하는 단계는:스피커 분류를 결정하기 위해 상기 참가자의 음성의 등록된 버전에 대한 상기 오디오 데이터를 분류하는 단계; 및상기 오디오 데이터가 상기 스피커 분류에 기초하여 상기 참가자의 상기 음성을 나타내는지를 결정하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>20. 제 19 항에 있어서, 상기 오디오 데이터의 분석물에 기초하여 상기 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하는 단계는:상기 오디오 데이터가 상기 참가자의 상기 음성을 나타내지 않는다는 결정에 기초하여 상기 마이크로폰을 음소거하거나 상기 참가자의 상기 오디오 데이터를 음소거하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>21. 제 19 항에 있어서, 상기 오디오 데이터의 분석물에 기초하여 상기 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하는 단계는:상기 오디오 데이터가 상기 참가자의 상기 음성을 나타낸다는 결정에 기초하여 상기 마이크로폰을 음소거하지 않거나 상기 참가자의 상기 오디오 데이터를 음소거하지 않는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>22. 제 19 항에 있어서,상기 참가자의 상기 음성의 상기 등록된 버전을 사용하여 뉴럴 네트워크를 트레이닝하는 단계를 더 포함하고, 그리고 상기 오디오 데이터를 분류하는 단계는 상기 뉴럴 네트워크를 사용하여 상기 오디오 데이터를 분류하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>23. 제 15 항에 있어서, 상기 오디오 데이터의 상기 컨텍스트를 결정하기 위해 상기 오디오 데이터를 분석하는 단계는:컨텍스트 분류를 결정하기 위해 트레이닝 데이터에 대해 상기 오디오 데이터의 컨텐츠를 분류하는 단계; 및상기 오디오 데이터가 상기 컨텍스트 분류에 기초하여 상기 오디오 컨퍼런스의 컨텍스트를 나타내는지를 결정하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>24. 제 23 항에 있어서, 상기 오디오 데이터의 분석물에 기초하여 상기 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하는 단계는:상기 오디오 데이터가 상기 오디오 컨퍼런스의 상기 컨텍스트를 나타내지 않는다는 결정에 기초하여 상기 마이크로폰을 음소거하거나 상기 참가자의 상기 오디오 데이터를 음소거하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>25. 제 23 항에 있어서, 상기 오디오 데이터의 분석물에 기초하여 상기 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하는 단계는:상기 오디오 데이터가 상기 오디오 컨퍼런스의 상기 컨텍스트를 나타낸다는 상기 결정에 기초하여 상기 마이크로폰을 음소거하지 않거나 상기 참가자의 상기 오디오 데이터를 음소거하지 않는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>26. 제 23 항에 있어서,상기 트레이닝 데이터를 사용하여 뉴럴 네트워크를 트레이닝하는 단계를 더 포함하고, 상기 트레이닝 데이터는 상기 오디오 컨퍼런스의 컨텍스트를 나타내는 문법을 포함하고, 상기 오디오 데이터를 분류하는 단계는 상기 뉴럴 네트워크를 사용하여 상기 오디오 데이터를 분류하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>27. 제 15 항에 있어서, 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하는 단계는:스피커 분류를 결정하기 위해 상기 참가자의 음성의 등록된 버전에 대한 상기 오디오 데이터를 분류하는 단계; 상기 오디오 데이터가 스피커 분류에 기초하여 상기 참가자의 상기 음성을 나타내는지를 결정하는 단계;컨텍스트 분류를 결정하기 위해 트레이닝 데이터에 대해 상기 오디오 데이터의 컨텐츠를 분류하는 단계; 및상기 오디오 데이터가 상기 컨텍스트 분류에 기초하여 상기 오디오 컨퍼런스의 컨텍스트를 나타내는지를 결정하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>28. 제 27 항에 있어서, 상기 오디오 데이터의 분석물에 기초하여 상기 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하는 단계는:상기 참가자의 상기 오디오 데이터가 음소거된다고 결정하는 단계; 및상기 오디오 데이터가 상기 참가자의 음성을 나타낸다는 결정에 기초하여 그리고 상기 오디오 데이터가 상기 오디오 컨퍼런스의 상기 컨텍스트를 나타낸다는 결정에 기초하여 상기 참가자의 상기 오디오 데이터를 음소거해제하는 단계를 포함하는, 오디오 컨퍼런스를 제어하기 위한 방법.</claim></claimInfo><claimInfo><claim>29. 명령들을 저장한 비일시적 컴퓨터 판독가능 저장 매체로서,상기 명령들은 실행될 때 하나 이상의 프로세서들로 하여금: 오디오 컨퍼런스에서 참가자로부터 오디오 데이터를 수신하게 하고; 상기 오디오 데이터의 분석물을 생성하기 위해 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하게 하고; 그리고 상기 오디오 데이터의 상기 분석물에 기초하여 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하게 하는, 명령들을 저장한 비일시적 컴퓨터 판독가능 저장 매체.</claim></claimInfo><claimInfo><claim>30. 오디오 컨퍼런스를 제어하도록 구성되는 장치로서,상기 오디오 컨퍼런스에서 참가자로부터 오디오 데이터를 수신하기 위한 수단;상기 오디오 데이터의 분석물을 생성하기 위해 상기 오디오 데이터의 스피커 또는 상기 오디오 데이터의 컨텍스트 중 하나 이상을 결정하도록 상기 오디오 데이터를 분석하기 위한 수단; 및상기 오디오 데이터의 분석물에 기초하여 마이크로폰을 제어하거나 또는 상기 참가자의 상기 오디오 데이터를 조정하기 위한 수단을 포함하는, 오디오 컨퍼런스를 제어하도록 구성되는 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 *****-**** 캘리포니아주 샌 디에고 모어하우스 드라이브 ****</address><code>519980804600</code><country>미국</country><engName>Qualcomm Incorporated</engName><name>퀄컴 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>MEHTA, UMA</engName><name>메흐타 우마</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>GUJJULA, VISHNU PRIYANKA</engName><name>구줄라 비쉬누 프리얀카</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>KURAPATY, RAJESHWAR</engName><name>쿠라파티 라제쉬와르</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>GARODIA, VIKASH</engName><name>가로디아 비카쉬</name></inventorInfo><inventorInfo><address>미국 *****-**** 캘리...</address><code> </code><country> </country><engName>GOTTAM, MALATHI</engName><name>고탐 말라티</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 강남대로 **길 **(역삼동, 케이피빌딩)</address><code>920011000013</code><country>대한민국</country><engName>Koreana Patent Firm</engName><name>특허법인코리아나</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.09.07</priorityApplicationDate><priorityApplicationNumber>17/468,177</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.02.28</receiptDate><receiptNumber>1-1-2024-0232258-13</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.04.09</receiptDate><receiptNumber>1-5-2024-0060615-79</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2025.07.10</receiptDate><receiptNumber>1-1-2025-0781898-80</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사유예신청]결정 보류신청서·심사유예신청서</documentName><receiptDate>2025.07.10</receiptDate><receiptNumber>1-1-2025-0781899-25</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247006947.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93f6f528066bec197cab4c669a3623a1c3899e01ee05684a1eb2b3300484e8bd7829d9c1bce9647dfa515b1e56081b3cf7db9554c961b766c9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4e5e1b0533d94eef205488fe961fe8c2b08021758d9cb6623657336444328523e8cd8eef2804b2643ef0ee4f9861cdee21be28f543662bed</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>