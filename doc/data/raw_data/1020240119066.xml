<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:13:50.1350</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2024.09.03</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-0119066</applicationNumber><claimCount>29</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>디지털 휴먼의 생성 방법, 플랫폼, 전자 기기 및 기록 매체</inventionTitle><inventionTitleEng>DIGITAL HUMAN GENERATION METHOD AND PLATFORM, ELECTRONIC  EQUIPMENT AND STORAGE MEDIUM</inventionTitleEng><openDate>2024.09.20</openDate><openNumber>10-2024-0139029</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.09.03</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 13/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 16/583</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시는 증강 현실, 가상 현실, 컴퓨터 시각, 딥 러닝 등 기술 분야에 관한 것으로, 메타 우주, 가상 디지털 휴먼 등의 장면에 적용할 수 있는 디지털 휴먼의 생성 방법, 플랫폼, 전자 기기 및 저장 매체를 제공한다. 구체적인 구현 방안은 생성해야 할 디지털 휴먼의 화상에 기반하여, 대응하는 타겟 오브젝트 모델을 획득하는 단계; 상기 화상에서 헤드 키 특징에 기반하여, 하여, 미리 설정된 특징 라이브러리로부터 대응하는 헤드 키 특징의 포인트 클라우드를 획득하는 단계; 및 상기 헤드 키 특징의 포인트 클라우드를 상기 타겟 오브젝트 모델에 융합하여 디지털 휴먼 형상을 획득하는 단계를 포함한다. 개시의 기술은 디지털 휴먼의 제작을 자동으로 구현하여, 디지털 휴먼 형상을 획득할 수 있고, 디지털 휴먼 형상의 제작 비용과 주기를 효과적으로 절약할 수 있고, 또한 생성된 디지털 휴먼 형상의 정확성과 디지털 휴먼 형상의 생성 효율을 효과적으로 향상시킬 수도 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 디지털 휴먼의 생성 방법에 있어서,생성해야 할 디지털 휴먼의 화상에 기반하여, 대응하는 타겟 오브젝트 모델을 획득하는 단계;상기 화상 중의 헤드 키 특징에 기반하여, 미리 설정된 특징 라이브러리로부터, 대응하는 헤드 키 특징의 포인트 클라우드를 획득하는 단계; 및상기 헤드 키 특징의 포인트 클라우드를 상기 타겟 오브젝트 모델에 융합하여, 디지털 휴먼 형상을 획득하는 단계;를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 헤드 키 특징의 포인트 클라우드를 상기 타겟 오브젝트 모델에 융합한 후 디지털 휴먼 형상을 획득하는 단계의 전에, 상기 방법은,융합 후의 상기 타겟 오브젝트 모델 중의 헤드 키 특징과 상기 화상 중의 헤드 키 특징의 유사도가 미리 설정된 유사도 역치 이상인지 여부를 검출하는 단계; 및상기 유사도가 미리 설정된 유사도 역치보다 작은 것에 응답하여, 사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성(create avatar) 조작을 하는 단계;를 더 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 수행하는 단계는,미리 확립된 암묵적 제약면과 미리 설정된 동적 곡선을 제약 조건（constraint）으로 하고, 사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 수행하는 단계를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,미리 확립된 암묵적 제약면과 미리 설정된 동적 곡선을 제약 조건으로 하고, 사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 수행하는 단계는,상기 사용자에 의해 트리거된 상기 암묵적 제약면에 설정된 제1 컨트롤러의 동작 정보를 획득하는 단계 - 상기 암묵적 제약면은 제어되지 않기 전에 상기 타겟 오브젝트 모델의 표면 토폴로지 구조와 완전히 일치한 면이고, 상기 암묵적 제약면은 상기 사용자에게 보이지 않음 -;미리 확립된 상기 암묵적 제약면 중의 제1 컨트롤러와 상기 암묵적 제약면 중의 포인트의 제1 모션 매핑 관계 및 제1 컨트롤러의 동작 정보에 기반하여, 상기 암묵적 제약면 중의 트리거된 포인트의 동작 정보를 획득하는 단계;상기 암묵적 제약면 중의 트리거된 포인트의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델 중의 상기 포인트와 동일한 위치에 있는 제2 컨트롤러의 동작 정보를 결정하는 단계;미리 확립된 타겟 오브젝트 모델에 설정된 제2 컨트롤러와 상기 타겟 오브젝트 모델 중의 포인트의 제2 모션 매핑 관계 및 상기 제2 컨트롤러의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델 중의 포인트의 동작 정보를 제어하는 단계; 및미리 설정된 동적 곡선을 제약 조건으로 하고, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 수행하는 단계;를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,미리 설정된 동적 곡선을 제약 조건으로 하고, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 수행하는 단계는,상기 제2 컨트롤러가 미리 설정된 동적 곡선상에 있는지 여부를 검출하는 단계 - 각 미리 설정된 동적 곡선에 적어도 2개의 상기 제2 컨트롤러를 설정함 -;상기 제2 컨트롤러가 미리 설정된 동적 곡선상에 있는 것에 응답하여, 상기 제2 컨트롤러의 동작 정보에 기반하여, 상기 동적 곡선 중의 기타 제2 컨트롤러의 동작 정보를 획득하는 단계; 및상기 제2 컨트롤러의 동작 정보와 상기 동적 곡선 중의 기타 제2 컨트롤러의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 수행하는 단계;를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,미리 설정된 동적 곡선을 제약 조건으로 하고, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 수행하는 단계는,상기 제2 컨트롤러가 미리 설정된 동적 곡선상 없는 것에 응답하여, 상기 제2 컨트롤러의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 수행하는 단계를 더 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>7. 제2항 내지 제6항 중 어느 한 항에 있어서,사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 수행하는 단계의 후에, 상기 방법은,상기 타겟 오브젝트 모델의 첨부 템플릿이 상기 디지털 휴먼 형상에 적합한지 여부를 검출하는 단계; 및상기 타겟 오브젝트 모델의 첨부 템플릿이 상기 디지털 휴먼 형상에 적합한 것에 응답하여, 상기 디지털 휴먼 형상 중의 첨부 템플릿을 조정하는 단계;를 더 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>8. 제1항 내지 제6항 중 어느 한 항에 있어서,생성해야 할 디지털 휴먼의 화상에 기반하여, 대응하는 타겟 오브젝트 모델을 획득하는 단계는,상기 생성해야 할 디지털 휴먼의 화상에 기반하여, 상기 디지털 휴먼의 속성 특징을 추출하는 단계; 및상기 디지털 휴먼의 속성 특징에 기반하여, 미리 설정된 모델 라이브러리로부터 대응하는 상기 타겟 오브젝트 모델을 획득하는 단계 - 상기 모델 라이브러리는 복수의 오브젝트 모델을 포함함 -;를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,생성해야 할 디지털 휴먼의 화상에 기반하여, 대응하는 타겟 오브젝트 모델을 획득하는 단계는,상기 생성해야 할 디지털 휴먼의 화상에 기반하여, 상기 디지털 휴먼의 속성 특징이 추출되지 않을 경우, 미리 설정된 표준 모델을 타겟 오브젝트 모델로 하는 단계를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>10. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 화상 중의 헤드 키 특징에 기반하여, 미리 설정된 특징 라이브러리로부터, 대응하는 헤드 키 특징의 포인트 클라우드를 획득하는 단계는,상기 화상 중의 헤드 키 특징의 타겟 속성 정보를 획득하는 단계; 및상기 헤드 키 특징의 타겟 속성 정보에 기반하여, 상기 특징 라이브러리로부터 대응하는 헤드 키 특징의 포인트 클라우드를 획득하는 단계;를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 방법은,상기 특징 라이브러리에 상기 타겟 속성 정보에 대응하는 헤드 키 특징이 포함되어 있지 않을 경우, 사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델 중의 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 수행하는 단계를 더 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>12. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 화상 중의 헤드 키 특징에 기반하여, 미리 설정된 특징 라이브러리로부터, 대응하는 헤드 키 특징의 포인트 클라우드를 획득하는 단계의 전에, 상기 방법은,복수의 인물 중의 각 인물의 복수의 헤드 키 특징의 포인트 클라우드 및 각 헤드 키 특징의 속성 정보를 수집하고, 상기 특징 라이브러리에 저장하는 단계를 더 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>13. 제1항 내지 제6항 중 어느 한 항에 있어서,상기 헤드 키 특징의 포인트 클라우드를 상기 타겟 오브젝트 모델에 융합하는 단계는,상기 헤드 키 특징의 포인트 클라우드와 상기 타겟 오브젝트 모델에 대해 정합을 수행하는 단계; 및상기 헤드 키 특징의 포인트 클라우드를 상기 타겟 오브젝트 모델 중의 대응하는 헤드 키 특징의 영역으로 이전하는 단계;를 포함하는,디지털 휴먼의 생성 방법. </claim></claimInfo><claimInfo><claim>14. 디지털 휴먼의 생성 플랫폼에 있어서,생성해야 할 디지털 휴먼의 화상에 기반하여, 대응하는 타겟 오브젝트 모델을 획득하기 위한 모델 획득 모듈;상기 화상 중의 헤드 키 특징에 기반하여, 미리 설정된 특징 라이브러리로부터, 대응하는 헤드 키 특징의 포인트 클라우드를 획득하기 위한 특징 획득 모듈; 및상기 헤드 키 특징의 포인트 클라우드를 상기 타겟 오브젝트 모델에 융합하여, 디지털 휴먼 형상을 획득하기 위한 융합 모듈;을 포함하는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>15. 제14항에 있어서,상기 플랫폼은,융합 후의 상기 타겟 오브젝트 모델 중의 헤드 키 특징과 상기 화상 중의 헤드 키 특징의 유사도가 미리 설정된 유사도 역치 이상인지 여부를 검출하기 위한 제1 검출 모듈; 및상기 유사도가 미리 설정된 유사도 역치보다 작은 것에 응답하여, 사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 하기 위한 아바타 생성 모듈;을 더 포함하는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>16. 제15항에 있어서,상기 아바타 생성 모듈은,미리 확립된 암묵적 제약면과 미리 설정된 동적 곡선을 제약 조건으로 하고, 사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델에 융합한 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 수행하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 아바타 생성 모듈은,상기 사용자에 의해 트리거된 상기 암묵적 제약면에 설정된 제1 컨트롤러의 동작 정보를 획득하고, 상기 암묵적 제약면은 제어되지 않기 전에 상기 타겟 오브젝트 모델의 표면 토폴로지 구조와 완전히 일치한 면이고, 상기 암묵적 제약면은 상기 사용자에게 보이지 않고,미리 확립된 상기 암묵적 제약면 중의 제1 컨트롤러와 상기 암묵적 제약면 중의 포인트의 제1 모션 매핑 관계 및 제1 컨트롤러의 동작 정보에 기반하여, 상기 암묵적 제약면 중의 트리거된 포인트의 동작 정보를 획득하고,상기 암묵적 제약면 중의 트리거된 포인트의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델 중의 상기 포인트와 동일한 위치에 있는 제2 컨트롤러의 동작 정보를 결정하고,미리 확립된 타겟 오브젝트 모델에 설정된 제2 컨트롤러와 상기 타겟 오브젝트 모델 중의 포인트의 제2 모션 매핑 관계 및 상기 제2 컨트롤러의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델 중의 포인트의 동작 정보를 제어하고,미리 설정된 동적 곡선을 제약 조건으로 하고, 상기 타겟 오브젝트 모델에 융합한 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 수행하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>18. 제17항에 있어서,상기 아바타 생성 모듈은,상기 제2 컨트롤러가 미리 설정된 동적 곡선상에 있는지 여부를 검출하고, 각 미리 설정된 동적 곡선에 적어도 2개의 상기 제2 컨트롤러를 설정하고,상기 제2 컨트롤러가 미리 설정된 동적 곡선상에 있는 것에 응답하여, 상기 제2 컨트롤러의 동작 정보에 기반하여, 상기 동적 곡선 중의 기타 제2 컨트롤러의 동작 정보를 획득하고,상기 제2 컨트롤러의 동작 정보와 상기 동적 곡선 중의 기타 제2 컨트롤러의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>19. 제18항에 있어서,상기 아바타 생성 모듈은 또한,상기 제2 컨트롤러가 미리 설정된 동적 곡선상 없는 것에 응답하여, 상기 제2 컨트롤러의 동작 정보에 기반하여, 상기 타겟 오브젝트 모델에 융합된 상기 헤드 키 특징의 포인트 클라우드에 대해 위치 조정을 수행하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>20. 제15항 내지 제19항 중 어느 한 항에 있어서,상기 플랫폼은,상기 타겟 오브젝트 모델의 첨부 템플릿이 상기 디지털 휴먼 형상에 적합한지 여부를 검출하기 위한 제2 검출 모듈; 및상기 타겟 오브젝트 모델의 첨부 템플릿이 상기 디지털 휴먼 형상에 적합한 것에 응답하여, 상기 디지털 휴먼 형상 중의 첨부 템플릿을 조정하기 위한 조정 모듈;을 더 포함하는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>21. 제14항 내지 제19항 중 어느 한 항에 있어서,상기 모델 획득 모듈은,상기 생성해야 할 디지털 휴먼의 화상에 기반하여, 상기 디지털 휴먼의 속성 특징을 추출하고,상기 디지털 휴먼의 속성 특징에 기반하여, 미리 설정된 모델 라이브러리로부터 대응하는 상기 타겟 오브젝트 모델을 획득하는데 사용되고, 상기 모델 라이브러리는 복수의 오브젝트 모델을 포함하는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,상기 모델 획득 모듈은,상기 생성해야 할 디지털 휴먼의 화상에 기반하여, 상기 디지털 휴먼의 속성 특징이 추출되지 않을 경우, 미리 설정된 표준 모델을 타겟 오브젝트 모델로 하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>23. 제15항 내지 제19항 중 어느 한 항에 있어서,상기 특징 획득 모듈은,상기 화상 중의 헤드 키 특징의 타겟 속성 정보를 획득하고,상기 헤드 키 특징의 타겟 속성 정보에 기반하여, 상기 특징 라이브러리로부터 대응하는 헤드 키 특징의 포인트 클라우드를 획득하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>24. 제23항에 있어서,상기 아바타 생성 모듈은 또한,상기 특징 라이브러리에 상기 타겟 속성 정보에 대응하는 헤드 키 특징이 포함되어 있지 않을 경우, 사용자의 트리거에 기반하여, 상기 타겟 오브젝트 모델 중의 상기 헤드 키 특징의 포인트 클라우드에 대해 아바타 생성 조작을 수행하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>25. 제14항 내지 제19항 중 어느 한 항에 있어서,상기 플랫폼은,복수의 인물 중의 각 인물의 복수의 헤드 키 특징의 포인트 클라우드 및 각 헤드 키 특징의 속성 정보를 수집하고, 상기 특징 라이브러리에 저장하기 위한 수집 모듈을 더 포함하는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>26. 제14항 내지 제19항 중 어느 한 항에 있어서,상기 융합 모듈은,상기 헤드 키 특징의 포인트 클라우드와 상기 타겟 오브젝트 모델에 대해 정합을 수행하고,상기 헤드 키 특징의 포인트 클라우드를 상기 타겟 오브젝트 모델 중의 대응하는 헤드 키 특징의 영역으로 이전하는데 사용되는,디지털 휴먼의 생성 플랫폼. </claim></claimInfo><claimInfo><claim>27. 전자 기기에 있어서, 적어도 하나의 프로세서; 및 상기 적어도 하나의 프로세서에 통신 연결되는 메모리;를 포함하고, 상기 메모리에는 상기 적어도 하나의 프로세서에 의해 수행 가능한 명령이 저장되어 있고, 상기 명령이 상기 적어도 하나의 프로세서에 의해 수행되어, 상기 적어도 하나의 프로세서에 의해 제1항 내지 제13항 중 어느 한 항의 방법이 수행되도록 하는,전자 기기. </claim></claimInfo><claimInfo><claim>28. 컴퓨터 명령이 저장되어 있는 비일시적 컴퓨터 판독 가능 기록 매체에 있어서, 상기 컴퓨터 명령은 상기 컴퓨터가 제1항 내지 제13항 중 어느 한 항의 방법을 수행하도록 하는,비일시적 컴퓨터 판독 가능 기록 매체. </claim></claimInfo><claimInfo><claim>29. 비일시적 컴퓨터 판독 가능 기록 매체에 저장되어 있는 컴퓨터 프로그램에 있어서, 상기 컴퓨터 프로그램이 프로세서에 의해 수행될 때, 제1항 내지 제13항 중 어느 한 항의 방법을 구현하는,컴퓨터 프로그램. </claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>중국 베이징 하이디안 디스트릭트 샹디 **번가 넘버 **, 바이두 캠퍼스 *층</address><code>520190701941</code><country>중국</country><engName>BEIJING BAIDU NETCOM SCIENCE TECHNOLOGY CO., LTD.</engName><name>베이징 바이두 넷컴 사이언스 테크놀로지 컴퍼니 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>중국, 베이징 ******, 하이뎬 디스트...</address><code> </code><country> </country><engName>WANG, Lei</engName><name>왕, 레이</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디스트...</address><code> </code><country> </country><engName>ZHANG, Xiaodong</engName><name>장, 씨아오동</name></inventorInfo><inventorInfo><address>중국, 베이징 ******, 하이뎬 디스트...</address><code> </code><country> </country><engName>LI, Shiyan</engName><name>리, 시옌</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 서초구 사평대로 ***, *층 (반포동)</address><code>920161000615</code><country>대한민국</country><engName>Jipyong Intellectual Property Law Firm</engName><name>특허법인지평</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>중국</priorityApplicationCountry><priorityApplicationDate>2023.10.16</priorityApplicationDate><priorityApplicationNumber>202311338975.0</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2024.09.03</receiptDate><receiptNumber>1-1-2024-0965204-51</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>우선권주장증명서류제출서(CN)</documentName><receiptDate>2024.09.26</receiptDate><receiptNumber>9-1-2024-9010401-14</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020240119066.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93cfee614daddf932494916502aa543095a10e4e3c2fe6175d56c900f5e6ea9bbffed831a839aeab44a487d06b2031faa1d22ae779bd3f6352</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4cefca99ddc9543e1a76b5b06009e7cf166b517a96ac689ad9900a57fa47a4acf2759892fd0746a03eda1f65dbac34d2301390e239d0af22</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>