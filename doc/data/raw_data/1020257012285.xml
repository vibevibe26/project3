<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:23:07.237</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.09.15</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7012285</applicationNumber><claimCount>17</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>장면 합성 기계 학습 모델을 사용하여 시뮬레이션에서 정책 신경망 트레이닝</inventionTitle><inventionTitleEng>TRAINING POLICY NEURAL NETWORKS IN SIMULATION USING SCENE SYNTHESIS MACHINE LEARNING MODELS</inventionTitleEng><openDate>2025.07.24</openDate><openNumber>10-2025-0112751</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2025.04.15</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.04.15</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/006</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/092</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>H04N 5/265</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 로봇 제어에 사용하기 위한 정책 신경망을 트레이닝하기 위한 컴퓨터 저장 매체에 인코딩된 컴퓨터 프로그램을 포함하는 방법, 시스템 및 장치. 특히, 정책 신경망은 장면 합성 기계 학습 모델에 의해 생성된 이미지를 사용하여 시뮬레이션에서 트레이닝될 수 있다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.03.21</internationOpenDate><internationOpenNumber>WO2024056892</internationOpenNumber><internationalApplicationDate>2023.09.15</internationalApplicationDate><internationalApplicationNumber>PCT/EP2023/075514</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 하나 이상의 컴퓨터에 의해 수행되는 방법으로, 상기 방법은,로봇이 상호작용할 실제 세상 환경의 장면에 대한 복수의 이미지, 및 각각의 이미지에 대해, 상기 이미지를 캡처한 카메라의 관점을 포함하는 대응하는 카메라 데이터를 획득하는 단계;상기 복수의 이미지와 상기 대응하는 카메라 데이터를 사용하여 장면 합성 기계 학습 모델을 트레이닝하는 단계 - 상기 장면 합성 기계 학습 모델은 카메라 관점을 포함하는 장면 입력을 수신하고 상기 카메라 관점으로부터 상기 장면의 합성 이미지를 출력으로서 생성하도록 구성됨 -; 및적어도 상기 장면 합성 기계 학습 모델에 의해 생성된 합성 이미지를 사용하여, 상기 실제 세상 환경에서 상기 로봇을 제어하여 하나 이상의 작업을 수행하는 데 사용할 정책 신경망(policy neural network)을 트레이닝하기 위한 트레이닝 데이터를 생성하는 단계 - 상기 정책 신경망은 상기 환경의 현재 상태를 특징짓는 관찰을 포함하는 정책 입력을 수신하고 상기 관찰에 응답하여 상기 로봇에 의해 수행될 액션(action)을 정의하는 정책 출력을 출력으로서 생성하도록 구성되고, 상기 관찰은 상기 로봇의 로봇 카메라에 의해 캡처된 상기 환경의 이미지를 포함함 -를 포함하고, 상기 트레이닝 데이터를 생성하는 단계는,상기 장면 합성 기계 학습 모델에 의해 생성된 합성 이미지로부터, 상기 로봇의 모델이 상호작용하는 상기 환경의 시뮬레이션(simulation)의 장면에 대한 관찰을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 트레이닝 데이터에 대해 상기 정책 신경망을 트레이닝하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 트레이닝 후, 상기 정책 신경망을 사용하여 상기 실제 세상 환경에서 상기 로봇을 제어하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 복수의 이미지를 획득하는 단계는,상기 실제 세상 환경에서 상기 장면의 비디오를 획득하는 단계; 및상기 비디오로부터 복수의 비디오 프레임을 상기 복수의 이미지로서 선택하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,SfM(Structure-from-Motion)을 사용하여 상기 복수의 이미지의 각각에 대한 상기 카메라 데이터를 결정하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서, 상기 정책 신경망을 트레이닝하기 위한 상기 트레이닝 데이터를 생성하는 단계는,복수의 시간 단계의 각각에서 상기 정책 신경망을 사용하여 상기 환경의 시뮬레이션에서 상기 로봇의 모델을 제어하는 단계 - 상기 모델을 제어하는 단계는, 각각의 시간 단계에서, 시뮬레이터로부터, 상기 시간 단계에서 상기 실제 세상 환경의 시뮬레이션의 상태 내에서 상기 시간 단계에서 상기 로봇 카메라의 위치에 기초하여 입력 카메라 관점을 획득하는 단계; 상기 장면 합성 모델을 사용하여, 상기 입력 카메라 관점으로부터 상기 장면의 합성 이미지를 생성하는 단계; 적어도 상기 장면의 합성 이미지로부터 상기 시간 단계에 대한 입력 이미지를 생성하는 단계; 정책 신경망을 사용하여 상기 입력 이미지를 포함하는 관찰을 프로세싱하여 정책 출력을 생성하는 단계; 상기 정책 출력을 사용하여 액션을 선택하는 단계; 및 상기 시뮬레이션의 상태를 업데이트하기 위해 상기 로봇의 모델을 제어하는 데 사용할 상기 선택된 액션을 상기 시뮬레이터에 제공하는 단계를 포함함 -; 및 상기 시간 단계에 대한 관찰과 상기 시간 단계에 대한 상기 선택된 액션을 포함하는 상기 시간 단계의 각각에 대한 개별 트레이닝 예를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제6항에 있어서, 적어도 상기 장면의 합성 이미지로부터 상기 시간 단계에 대한 입력 이미지를 생성하는 단계는,상기 시뮬레이터로부터, 상기 시간 단계에서 상기 환경에 있는 하나 이상의 동적 객체의 개별 렌더링을 획득하는 단계; 및상기 장면의 합성 이미지와 상기 개별 렌더링을 조합함으로써 상기 시간 단계에 대한 상기 입력 이미지를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제6항 또는 제7항에 있어서, 상기 장면 합성 모델은 제1 참조 프레임에서 카메라 관점을 수신하도록 구성되고, 상기 시뮬레이터는 세상 참조 프레임에서 동작하고, 시뮬레이터로부터 상기 실제 세상 환경의 시뮬레이션 내의 상기 시간 단계에서 상기 로봇 카메라의 위치에 기초하여 입력 카메라 관점을 획득하는 단계는,상기 시뮬레이터로부터, 상기 세상 참조 프레임에서 초기 카메라 관점을 수신하는 단계; 및상기 초기 카메라 관점을 상기 세상 참조 프레임으로부터 상기 제1 참조 프레임으로 매핑함으로써 상기 입력 카메라 관점을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제6항 내지 제8항 중 어느 한 항에 있어서,각각의 시간 단계에서, 상기 시뮬레이터로부터, 상기 하나 이상의 작업의 각각에 대한 개별 리워드를 수신하는 단계 - 상기 트레이닝 예는 상기 개별 리워드를 포함함 -를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 제1항 내지 제9항 중 어느 한 항에 있어서,상기 트레이닝된 장면 합성 모델을 사용하여, 상기 장면의 메시를 생성하는 단계; 및상기 시뮬레이션의 상태를 업데이트할 때 충돌을 모델링하는 데 사용하기 위해 상기 시뮬레이터에 상기 메시를 제공하는 단계를 더 포함하는, 방법.</claim></claimInfo><claimInfo><claim>11. 제8항에 종속될 때 제10항에 있어서, 상기 메시를 생성하는 단계는,상기 제1 참조 프레임에서 초기 메시를 생성하는 단계; 및상기 제1 참조 프레임으로부터 상기 시뮬레이터의 상기 세상 참조 프레임에 상기 초기 메시의 정점을 매핑함으로써 메시를 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>12. 제1항 내지 제11항 중 어느 한 항에 있어서, 상기 관찰은 추가로 상기 로봇의 자이로스코프, 상기 로봇의 가속도계 또는 둘 모두로부터의 데이터를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>13. 제2항에 종속될 때 제1항 내지 제12항 중 어느 한 항에 있어서, 상기 정책 신경망을 트레이닝하는 단계는,도메인 랜덤화를 사용한 강화 학습을 통해 상기 정책 신경망을 트레이닝하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>14. 제1항 내지 제13항 중 어느 한 항에 있어서, 상기 장면 합성 모델은 NeRF(Neural Radiance Field) 모델인, 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서, 상기 복수의 이미지를 캡처한 카메라는 상기 로봇 카메라와 다르고, 상기 카메라 데이터는 상기 복수의 이미지를 캡처한 상기 카메라의 인트린직(intrinsics)을 지정하는 카메라 파라미터를 더 포함하고, 상기 장면 입력은 상기 장면 합성 기계 학습에 의해 생성된 상기 합성 이미지가 매칭되어야 하는 입력 카메라의 인트린직을 지정하는 입력 카메라 파라미터를 더 포함하고, 상기 장면 합성 기계 학습 모델에 의해 생성된 합성 이미지로부터, 상기 로봇의 모델이 상호작용하는 상기 환경의 시뮬레이션에서 장면의 관찰을 생성하는 단계는,상기 복수의 이미지를 캡처한 상기 카메라의 인트린직 대신 상기 로봇 카메라의 인트린직을 지정하는 입력 카메라 파라미터를 포함하는 장면 입력을 제공함으로써 상기 관찰의 각각을 생성하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>16. 시스템으로서,하나 이상의 컴퓨터; 및상기 하나 이상의 컴퓨터에 통신가능하게 결합된 하나 이상의 저장 디바이스 - 상기 하나 이상의 저장 디바이스는 상기 하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 제1항 내지 제15항 중 어느 한 항의 개별 방법의 동작을 수행하게 하는 명령어를 저장함 -를 포함하는, 시스템.</claim></claimInfo><claimInfo><claim>17. 명령어를 저장하는 하나 이상의 비일시적 컴퓨터 저장 매체로서, 상기 명령어는 하나 이상의 컴퓨터에 의해 실행될 때 상기 하나 이상의 컴퓨터로 하여금 제1항 내지 제15항 어느 한 항의 개별 방법의 동작을 수행하게 하는, 비일시적 컴퓨터 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>영국 런던 이씨*에이 *티더블유 뉴 스트리트 스퀘어 *</address><code>520170032411</code><country>영국</country><engName>DeepMind Technologies Limited</engName><name>딥마인드 테크놀로지스 리미티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>인도</country><engName>BYRAVAN, Arunkumar</engName><name>바이라반, 아룬쿠마르</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>체코</country><engName>HUMPLIK, Jan</engName><name>험플릭, 잔</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>독일</country><engName>HASENCLEVER, Leonard</engName><name>하센클레버, 레오나드</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>네덜란드</country><engName>BRUSSEE, Arthur Karl</engName><name>브뤼쎄, 아서 칼</name></inventorInfo><inventorInfo><address>영국 런던 엔*씨 ...</address><code> </code><country>이탈리아</country><engName>NORI, Francesco</engName><name>노리, 프란체스코</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 중구 남대문로 **, *층(소공동, 한진빌딩 본관)</address><code>920151000211</code><country>대한민국</country><engName>Lee &amp; Ko IP</engName><name>특허법인광장리앤고</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2022.09.15</priorityApplicationDate><priorityApplicationNumber>63/407,129</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.04.15</receiptDate><receiptNumber>1-1-2025-0424082-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2025.04.15</receiptDate><receiptNumber>1-1-2025-0424110-14</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Request for Amendment</documentEngName><documentName>보정요구서</documentName><receiptDate>2025.04.23</receiptDate><receiptNumber>1-5-2025-0068219-12</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Amendment to Patent Application, etc.] Amendment</documentEngName><documentName>[출원서 등 보정]보정서</documentName><receiptDate>2025.06.20</receiptDate><receiptNumber>1-1-2025-0695916-74</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.06.24</receiptDate><receiptNumber>1-5-2025-0104894-45</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257012285.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93dedaf8bbe799cae190f20f6fd4526b3da90c4ff73973a002a1637bdef4675f31f42cfa61fc76f5f7482fada2e3f46fdbb42e126d00bd69f2</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cfa7dc0766d6ef9add9e37f00c044df535aeeb7097e078d4d4dce4aa51f670eca81ed3a842f604961e5e15c1075c5b7ce615196569d3e6d153</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>