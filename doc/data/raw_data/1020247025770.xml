<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:01:02.12</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.13</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2024-7025770</applicationNumber><claimCount>20</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>비디오에서의 AR 아이템 배치</inventionTitle><inventionTitleEng>AR ITEM PLACEMENT IN A VIDEO</inventionTitleEng><openDate>2024.08.30</openDate><openNumber>10-2024-0131414</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2024.07.30</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2024.07.30</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/73</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/521</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06T 17/00</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/64</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/04815</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2006.01.01)</ipcDate><ipcNumber>G06F 3/01</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 20/20</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 본 개시내용의 양태들은 AR 아이템들을 제시하기 위한 시스템을 수반한다. 시스템은 현실 세계 환경에서 하나 이상의 현실 세계 객체의 묘사를 포함하는 비디오를 수신하는 동작 및 현실 세계 환경과 관련된 깊이 정보를 획득하는 동작; 및 현실 세계 환경의 3D 모델을 생성하는 동작을 포함하는 동작들을 수행한다. 동작들은 AR 아이템 및 현실 세계 환경의 3D 모델과 연관된 데이터에 기초하여 AR 아이템에 대한 3D 배치 및 오리엔테이션을 결정하는 동작, 및 AR 아이템의 3D 배치 및 오리엔테이션을 특정하는 비디오에서의 마커의 디스플레이를 야기하는 동작을 더 포함한다. 동작들은 비디오 내에서의 마커의 움직임에 응답하여 3D 배치 및 오리엔테이션에 따라 비디오 내에서의 AR 아이템의 디스플레이를 렌더링하는 동작을 추가로 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2023.07.06</internationOpenDate><internationOpenNumber>WO2023129372</internationOpenNumber><internationalApplicationDate>2022.12.13</internationalApplicationDate><internationalApplicationNumber>PCT/US2022/052696</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 방법으로서:하나 이상의 프로세서에 의해, 현실 세계 환경에서의 하나 이상의 현실 세계 객체의 묘사를 포함하는 비디오를 수신하는 단계;상기 현실 세계 환경에 관련된 깊이 데이터를 획득하는 단계;상기 비디오 및 상기 깊이 데이터에 기초하여 상기 현실 세계 환경의 3차원(3D) 모델을 생성하는 단계;AR(augmented reality) 아이템 및 상기 현실 세계 환경의 3D 모델과 연관된 데이터에 기초하여 상기 AR 아이템에 대한 3D 배치 및 오리엔테이션을 결정하는 단계; 상기 AR 아이템의 상기 3D 배치 및 오리엔테이션을 특정하는 상기 비디오에서의 그래픽의 디스플레이를 야기하는 단계; 및상기 비디오 내에서의 그래픽의 움직임에 응답하여 상기 3D 배치 및 오리엔테이션에 따라 상기 비디오 내에서의 상기 AR 아이템의 디스플레이를 렌더링하는 단계를 포함하는 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 현실 세계 환경에서 제1의 3D 배치 및 오리엔테이션에서 상기 비디오 상에 상기 그래픽을 오버레이하는 단계;상기 제1의 3D 배치 및 오리엔테이션이 상기 AR 아이템과 연관된 배치 및 오리엔테이션 파라미터들과 매칭되는데 실패한 것을 결정하는 단계; 및상기 제1의 3D 배치 및 오리엔테이션이 상기 AR 아이템과 연관된 배치 및 오리엔테이션 파라미터들과 매칭되는데 실패한 것을 결정한 것에 응답하여, 상기 그래픽의 디스플레이를 유지하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서,상기 현실 세계 환경에서 상기 그래픽을 제2의 3D 배치 및 오리엔테이션으로 이동시키는 입력을 수신하는 단계;상기 제2의 3D 배치 및 오리엔테이션이 상기 AR 아이템과 연관된 배치 및 오리엔테이션 파라미터들과 매칭되는 것을 결정하는 단계; 및상기 제2의 3D 배치 및 오리엔테이션이 상기 AR 아이템과 연관된 배치 및 오리엔테이션 파라미터들과 매칭되는 것을 결정한 것에 응답하여, 상기 그래픽의 디스플레이를 상기 AR 아이템의 디스플레이로 대체하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서, 상기 배치 및 오리엔테이션 파라미터들은 상기 AR 아이템에 대한 피팅 데이터를 특정하고, 상기 제2의 3D 배치 및 오리엔테이션은 상기 피팅 데이터에 대응하는 이용가능한 자유 공간을 포함하며, 상기 방법은:상기 비디오의 디스플레이의 중심에서 상기 그래픽의 디스플레이를 유지하는 단계; 및상기 현실 세계 환경에서 상기 디스플레이의 중심에서의 상기 그래픽을 상기 제2의 3D 배치 및 오리엔테이션으로 이동시키기 위해 상기 비디오를 캡처하고 있는 카메라를 이동시키는 단계를 추가로 포함하는 방법.  </claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서,깊이 데이터를 획득하기 위해 라이다 센서 데이터를 수신하는 단계; 상기 비디오에 묘사된 상기 하나 이상의 현실 세계 객체를 식별하기 위해 상기 3D 모델을 처리하는 단계 - 상기 3D 배치 및 오리엔테이션은 상기 식별된 하나 이상의 현실 세계 객체에 기초하여 결정됨 -;상기 데이터에 기초하여 상기 AR 아이템에 대한 복수의 배치 및 오리엔테이션 위치를 식별하는 단계; 및상기 현실 세계 환경에서의 하나 이상의 현실 세계 객체에 기초하여 상기 복수의 배치 및 오리엔테이션 위치 중 제1 배치 및 오리엔테이션 위치를 상기 3D 배치 및 오리엔테이션으로서 선택하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 현실 세계 환경에서 상기 하나 이상의 현실 세계 객체를 식별하는 단계; 및상기 하나 이상의 현실 세계 객체 중 주어진 것이 상기 AR 아이템의 복수의 배치 및 오리엔테이션 위치 중 제1 배치 및 오리엔테이션 위치와 연관된 하나 이상의 파라미터와 매칭되는 것을 결정하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>7. 제5항 또는 제6항에 있어서,상기 복수의 배치 및 오리엔테이션 위치에 대한 우선순위 값들을 획득하는 단계 - 상기 제1 배치 및 오리엔테이션 위치와 연관된 우선순위 값들 중 제1 우선순위 값은 상기 복수의 배치 및 오리엔테이션 위치 중 제2 배치 및 오리엔테이션 위치와 연관된 우선순위 값들의 제2 우선순위 값보다 낮음 -; 및상기 제2 배치 및 오리엔테이션 위치와 연관된 상기 현실 세계 객체와 매칭되는 제1 현실 세계 객체에 대해 상기 현실 세계 환경에서 상기 하나 이상의 현실 세계 객체를 탐색하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 현실 세계 환경에서의 하나 이상의 현실 세계 객체가 상기 제2 배치 및 오리엔테이션 위치와 연관된 상기 제1 현실 세계 객체와 매칭되는데 실패한 것을 결정하는 단계; 상기 제1 배치 및 오리엔테이션 위치와 연관된 상기 현실 세계 객체와 매칭되는 제2 현실 세계 객체에 대해 상기 현실 세계 환경에서 상기 하나 이상의 현실 세계 객체를 탐색하는 단계; 및상기 제2 현실 세계 객체가 상기 현실 세계 환경에서 상기 하나 이상의 현실 세계 객체 중에 포함되는 것을 결정한 것에 응답하여, 상기 제2 배치 및 오리엔테이션 위치 대신에 상기 제1 배치 및 오리엔테이션 위치를 상기 3D 배치 및 오리엔테이션으로서 선택하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>9. 제7항 또는 제8항에 있어서,상기 제2 배치 및 오리엔테이션 위치가 이용가능하지 않은 것을 결정하는 단계; 상기 제2 배치 및 오리엔테이션 위치가 이용가능하지 않은 것을 결정한 것에 응답하여, 상기 제2 배치 및 오리엔테이션 위치 대신에 상기 제1 배치 및 오리엔테이션 위치를 상기 3D 배치 및 오리엔테이션으로서 선택하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 제2 배치 및 오리엔테이션 위치에서 상기 비디오에 묘사된 간섭하는 현실 세계 객체의 존재를 검출하는 단계 - 이용가능하지 않은 상기 제2 배치 및 오리엔테이션 위치는 상기 간섭하는 현실 세계 객체의 존재를 검출한 것에 응답하여 결정됨 - 를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>11. 제1항 내지 제10항 중 어느 한 항에 있어서, 상기 AR 아이템은 텔레비전을 나타내고, 상기 방법은:상기 AR 아이템과 연관된 데이터가 가장 높은 우선순위 값을 갖는 배치 위치로서 벽을 특정하는 것을 결정하는 단계;현실 세계 텔레비전이 현재 상기 벽에 배치되어 있는 것을 결정하기 위해 상기 현실 세계 환경의 3D 모델에 액세스하는 단계; 상기 현실 세계 텔레비전이 현재 상기 벽에 배치되어 있는 것을 결정한 것에 응답하여, 텔레비전 스탠드를 포함하는 추가적인 AR 아이템을 선택하는 단계; 및상기 텔레비전을 나타내는 AR 아이템 및 상기 텔레비전 스탠드를 포함하는 추가적인 AR 아이템에 대한 3D 배치 및 오리엔테이션으로서 상기 현실 세계 환경의 바닥을 선택하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>12. 제11항에 있어서, 상기 텔레비전을 나타내는 AR 아이템을 상기 텔레비전 스탠드를 포함하는 추가적인 AR 아이템과 조합하여 조합된 AR 아이템을 생성하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>13. 제11항 또는 제12항에 있어서, 실시간으로 상기 비디오를 캡처하고 있는 카메라가 상기 현실 세계 환경 주위로 이동됨에 따라 상기 비디오 내에서 상기 조합된 AR 아이템의 디스플레이 위치를 유지하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>14. 제11항 내지 제13항 중 어느 한 항에 있어서, 상기 추가적인 AR 아이템은, 상기 하나 이상의 현실 세계 객체가 상기 텔레비전 스탠드를 포함하는데 실패한 것을 결정한 것에 응답하여 선택되고, 상기 추가적인 AR 아이템은 상기 현실 세계 환경의 3D 모델에서 상기 바닥의 치수들에 기초하여 선택되는 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항에 있어서,상기 AR 아이템의 상이한 크기를 선택하는 입력을 수신하는 단계; 및상기 상이한 크기를 선택하는 입력에 기초하여 상기 AR 아이템을 제자리에서 스케일링하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>16. 제1항 내지 제15항 중 어느 한 항에 있어서,상기 AR 아이템에 관련한 상호작용 데이터를 수신하는 단계 - 상기 상호작용 데이터는 상기 비디오의 3D 공간 내에서의 AR 아이템의 움직임을 포함함 -; 및상기 상호작용 데이터에 기초하여 상기 비디오 내에 상기 AR 아이템을 재위치시키는 단계; 상기 재위치시키는 것에 응답하여 상기 AR 아이템의 위치와 상기 현실 세계 객체의 위치 사이의 중첩을 검출한 것에 응답하여 상기 하나 이상의 현실 세계 객체 중 한 현실 세계 객체 배후에 상기 AR 아이템의 하나 이상의 부분을 숨기는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>17. 제1항 내지 제16항 중 어느 한 항에 있어서, 상기 AR 아이템은 어플라이언스(appliance)를 나타내고, 상기 방법은:상기 AR 아이템과 연관된 데이터가 가장 높은 우선순위 값을 갖는 배치 위치로서 제1 현실 세계 객체를 특정하는 것을 결정하는 단계;현실 세계 어플라이언스가 상기 제1 현실 세계 객체 상에 현재 배치된 것을 결정하기 위해 상기 현실 세계 환경의 3D 모델에 액세스하는 단계; 및상기 현실 세계 어플라이언스가 상기 제1 현실 세계 객체 상에 현재 배치된 것을 결정한 것에 응답하여, 상기 현실 세계 환경의 제2 현실 세계 객체를 상기 어플라이언스를 나타내는 상기 AR 아이템에 대한 3D 배치 및 오리엔테이션으로서 선택하는 단계를 추가로 포함하는 방법.</claim></claimInfo><claimInfo><claim>18. 제1항 내지 제17항 중 어느 한 항에 있어서, 현실 세계 환경 분류를 결정하기 위해 신경망 분류기를 훈련하는 단계를 추가로 포함하고, 상기 현실 세계 환경 분류는 상기 AR 아이템에 대한 3D 배치 및 오리엔테이션을 선택하기 위해 사용되고, 상기 신경망은 동작들을 수행함으로써 훈련되고, 상기 동작들은:복수의 훈련 이미지 및 상기 복수의 훈련 이미지 각각에 대한 그라운드 트루스 현실 세계 환경 분류들을 포함하는 훈련 데이터를 수신하는 동작 - 상기 복수의 훈련 단안 이미지 각각은 상이한 타입의 현실 세계 환경을 묘사함 -;상기 복수의 훈련 이미지 중 제1 훈련 이미지에 상기 신경망 분류기를 적용하여 상기 제1 훈련 이미지에 묘사된 상기 현실 세계 환경의 현실 세계 환경 분류를 추정하는 동작;상기 추정된 현실 세계 환경 분류와 상기 제1 훈련 이미지와 연관된 그라운드 트루스 현실 세계 환경 분류 사이의 편차를 계산하는 동작;상기 계산된 편차에 기초하여 상기 신경망 분류기의 파라미터들을 갱신하는 동작; 및상기 복수의 훈련 이미지 세트에 대해 상기 적용, 계산 및 갱신 동작들을 반복하는 동작을 포함하는 방법.</claim></claimInfo><claimInfo><claim>19. 시스템으로서:동작들을 수행하도록 구성된 프로세서를 포함하고, 상기 동작들은: 현실 세계 환경에서의 하나 이상의 현실 세계 객체의 묘사를 포함하는 비디오를 수신하는 동작; 상기 현실 세계 환경에 관련된 깊이 데이터를 획득하는 동작; 상기 비디오 및 상기 깊이 데이터에 기초하여 상기 현실 세계 환경의 3차원(3D) 모델을 생성하는 동작; AR(augmented reality) 아이템 및 상기 현실 세계 환경의 3D 모델과 연관된 데이터에 기초하여 상기 AR 아이템에 대한 3D 배치 및 오리엔테이션을 결정하는 동작;  상기 AR 아이템의 상기 3D 배치 및 오리엔테이션을 특정하는 상기 비디오에서의 그래픽의 디스플레이를 야기하는 동작; 및 상기 비디오 내에서의 그래픽의 움직임에 응답하여 상기 3D 배치 및 오리엔테이션에 따라 상기 비디오 내에서의 상기 AR 아이템의 디스플레이를 렌더링하는 동작을 포함하는 시스템.</claim></claimInfo><claimInfo><claim>20. 머신의 하나 이상의 프로세서에 의해 실행될 때, 상기 머신으로 하여금 동작들을 수행하게 야기하는 명령어들을 포함하는 머신 판독가능 저장 매체로서, 상기 동작들은:현실 세계 환경에서의 하나 이상의 현실 세계 객체의 묘사를 포함하는 비디오를 수신하는 동작;상기 현실 세계 환경에 관련된 깊이 데이터를 획득하는 동작;상기 비디오 및 상기 깊이 데이터에 기초하여 상기 현실 세계 환경의 3차원(3D) 모델을 생성하는 동작;AR(augmented reality) 아이템 및 상기 현실 세계 환경의 3D 모델과 연관된 데이터에 기초하여 상기 AR 아이템에 대한 3D 배치 및 오리엔테이션을 결정하는 동작; 상기 AR 아이템의 상기 3D 배치 및 오리엔테이션을 특정하는 상기 비디오에서의 그래픽의 디스플레이를 야기하는 동작; 및상기 비디오 내에서의 그래픽의 움직임에 응답하여 상기 3D 배치 및 오리엔테이션에 따라 상기 비디오 내에서의 상기 AR 아이템의 디스플레이를 렌더링하는 동작을 포함하는 머신 판독가능 저장 매체.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>미국 ***** 캘리포니아주 산타 모니카 써티퍼스트 스트리트 ****</address><code>520140253774</code><country>미국</country><engName>SNAP INC.</engName><name>스냅 인코포레이티드</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>ASSOULINE, Avihay</engName><name>아술린, 아비하이</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>BERGER, Itamar</engName><name>버거, 이타마르</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>DUDOVITCH, Gal</engName><name>두도비치, 갈</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>HAREL, Peleg</engName><name>하렐, 펠레그</name></inventorInfo><inventorInfo><address>미국 ***** 캘리포니아 ...</address><code> </code><country> </country><engName>SASSON, Gal</engName><name>사슨, 갈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>920010003368</code><country>대한민국</country><engName>Kim Yeon Song</engName><name>김연송</name></agentInfo><agentInfo><address>서울특별시 종로구 사직로*길 **, 세양빌딩 (내자동) *층(김.장법률사무소)</address><code>919980003619</code><country>대한민국</country><engName>YANG, Young June</engName><name>양영준</name></agentInfo><agentInfo><address>서울 중구 정동길 **-** (정동, 정동빌딩) **층(김.장법률사무소)</address><code>919990005000</code><country>대한민국</country><engName>PAIK MAN GI</engName><name>백만기</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>미국</priorityApplicationCountry><priorityApplicationDate>2021.12.30</priorityApplicationDate><priorityApplicationNumber>17/566,032</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2024.07.30</receiptDate><receiptNumber>1-1-2024-0829242-29</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>보정승인간주 (Regarded as an acceptance of amendment) </commonCodeName><documentEngName>[Amendment to Description, etc.] Amendment</documentEngName><documentName>[명세서등 보정]보정서</documentName><receiptDate>2024.07.30</receiptDate><receiptNumber>1-1-2024-0830505-67</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2024.08.01</receiptDate><receiptNumber>1-5-2024-0126252-24</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020247025770.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c9301b09aebc21c1e7b480ce447fe74752ffa958aebe6bff32692b62c8ca34d126446d6acde5d4b025f1e4354b362795898685187cb5c8310d7</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf71150f02a84517efe973757073a6dd76ce3d0b94589084ca35ce0da3bd0c83bbe8615d4ec9dbfc4fa70fa5887355f10b3d8c33bcff8177b6</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>