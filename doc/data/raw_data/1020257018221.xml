<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:00:46.046</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2023.10.24</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2025-7018221</applicationNumber><claimCount>12</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>증강 현실 디바이스</inventionTitle><inventionTitleEng>AUGMENTED REALITY DEVICES</inventionTitleEng><openDate>2025.07.14</openDate><openNumber>10-2025-0107859</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국제출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate> </originalExaminationRequestDate><originalExaminationRequestFlag>N</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate>2025.06.02</translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 15/40</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/246</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06F 3/0488</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2011.01.01)</ipcDate><ipcNumber>G06T 19/00</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 증강 현실 디바이스의 카메라에 의해 캡처된 장면의 이미지를 처리하는 방법이 제공된다. 피폐색 실제 세계 객체와 폐색 실제 세계 객체가 장면에서 식별되며, 적어도 피폐색 객체의 영역이 폐색 객체에 의해 폐색된다. 폐색 객체에 의해 폐색되는 영역을 포함하는 피폐색 객체의 표현은 피폐색 객체의 영역의 외관이 도출되는 이미지 데이터에 추가적인 정보를 사용함으로써 렌더링된다. 폐색 객체의 표현은 적어도 폐색 객체가 피폐색 객체의 영역을 커버하는 부분에 적어도 반투명하게 렌더링된다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate>2024.05.10</internationOpenDate><internationOpenNumber>WO2024094466</internationOpenNumber><internationalApplicationDate>2023.10.24</internationalApplicationDate><internationalApplicationNumber>PCT/EP2023/079522</internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 증강 현실 디바이스의 카메라에 의해 캡처된 장면의 현재 프레임을 처리하는 방법으로서, 상기 현재 프레임은 상기 장면 내의 실제 세계 객체들에 대한 이미지 데이터를 포함하고, 상기 방법은,시간 경과에 따른 상기 장면의 이미지 데이터 및 깊이 맵 데이터를 프레임들로서 저장하는 단계(206; 304)로서, 상기 프레임들은 상기 현재 프레임 및 이전 프레임들을 포함하는, 상기 시간 경과에 따른 상기 장면의 이미지 데이터 및 깊이 맵 데이터를 프레임들로서 저장하는 단계(206; 304);현재 프레임에서 상기 장면 내의 폐색 객체(occluding object)를 식별하고(104; 208; 306), 상기 현재 프레임에서 상기 장면 내의 피폐색 객체(occluded object)를 식별하는 단계(106)로서, 적어도 상기 피폐색 객체의 영역은 상기 폐색 객체에 의해 폐색되고, 상기 폐색 객체 및 상기 피폐색 객체를 식별하는 단계는 상기 현재 프레임의 상기 이미지 데이터 및 깊이 맵 데이터를 사용하여 수행되는, 상기 현재 프레임에서 상기 장면 내의 폐색 객체를 식별하고(104; 208; 306), 상기 현재 프레임에서 상기 장면 내의 피폐색 객체를 식별하는 단계(106);상기 폐색 객체가 위치되는 상기 현재 프레임 내의 구역을 식별하는 마스크를 생성하는 단계(210; 308);상기 마스크의 상기 구역에 대해, 상기 현재 프레임의 상기 깊이 맵을 상기 이전 프레임들의 상기 깊이 맵들과 비교하여, 상기 마스크 내의 선택된 픽셀이 상기 피폐색 객체를 폐색하고 있었던 시간들을 식별하는 단계(214; 312);상기 이전 프레임들의 상기 깊이 맵 데이터 및 이미지 데이터를 사용하여 상기 이전 프레임들에서 상기 피폐색 객체의 폐색되지 않은 부분을 식별하는 단계(314);상기 폐색되지 않은 부분으로부터 상기 피폐색 객체의 지오메트리(geometry)를 추정하는 단계(316);이전 프레임 또는 프레임들로부터 완전한 피폐색 객체의 이미지 데이터를 획득하는 단계(318);상기 이전 프레임 또는 프레임들과 상기 현재 프레임 사이의 상기 피폐색 객체의 포즈 변화를 추정하는 단계(320);상기 포즈 변화를 상기 완전한 피폐색 객체의 상기 이미지 데이터에 적용하는 단계(320);상기 적용된 포즈 변화와 함께, 이전 프레임 또는 프레임들로부터의 상기 완전한 피폐색 객체의 상기 이미지 데이터를 사용함으로써, 상기 폐색 객체에 의해 폐색되는 상기 영역을 포함하여, 상기 완전한 피폐색 객체의 표현을 상기 현재 프레임에 렌더링하는 단계(108; 220; 322); 및적어도 상기 폐색 객체가 상기 피폐색 객체의 상기 영역을 폐색하는 부분에 적어도 부분적으로 투명하게 상기 폐색 객체의 표현을 렌더링하는 단계(112; 222; 324)로서, 상기 폐색 객체의 상기 렌더링된 표현은 상기 피폐색 객체의 상기 렌더링된 표현을 오버레이하는, 상기 적어도 상기 폐색 객체가 상기 피폐색 객체의 상기 영역을 폐색하는 부분에 적어도 부분적으로 투명하게 상기 폐색 객체의 표현을 렌더링하는 단계(112; 222; 324)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서, 적어도 부분적으로 투명하게 상기 폐색 객체의 표현을 렌더링하는 단계는 상기 피폐색 객체의 상기 영역을 폐색하고 있는 상기 폐색 객체의 일부에서 국소적으로 수행되는, 방법.</claim></claimInfo><claimInfo><claim>3. 제1항 또는 제2항에 있어서, 상기 피폐색 객체의 상기 표현을 렌더링하는 단계는 상기 식별된 피폐색 객체에 대한 저장된 정보에 추가로 기초하는, 방법.</claim></claimInfo><claimInfo><claim>4. 제1항 내지 제3항 중 어느 한 항에 있어서, 상기 폐색 객체는 신체 부분 또는 도구를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>5. 제1항 내지 제4항 중 어느 한 항에 있어서, 상기 폐색 객체는 도구를 포함하고, 상기 방법은 상기 도구의 팁(tip)을 검출하고 추적하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>6. 제1항 내지 제5항 중 어느 한 항에 있어서,시간 경과에 따른 상기 카메라의 위치 및 배향을 추적하는 단계(204); 및상기 추적 정보를 사용하여 결정된 픽셀 컬러의 위치를 상기 현재 프레임으로 변환하는 단계(218)를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>7. 제1항 내지 제6항 중 어느 한 항에 있어서, 터치 이벤트를 검출하고 상기 터치 이벤트의 표시를 렌더링하는 단계를 추가로 포함하는, 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서, 상기 터치 이벤트를 검출하는 단계는 깊이 차이가 임계치 미만인지를 결정하기 위해 상기 마스크들 내부 및 외부의 국소 깊이 값들을 비교하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>9. 제1항 내지 제8항 중 어느 한 항에 있어서,조립될, 상기 이미지 데이터 내의 부분들의 세트를 식별하는 단계; 및조립 매뉴얼에 기초하여 상기 부분들 간의 연관성들을 예시하는 표현을 렌더링하는 단계를 포함하는, 방법.</claim></claimInfo><claimInfo><claim>10. 원격 지시 비디오들에서의 제1항 내지 제9항 중 어느 한 항의 방법의 사용.</claim></claimInfo><claimInfo><claim>11. 컴퓨터 프로그램으로서, 상기 프로그램이 컴퓨터 상에서 실행될 때, 제1항 내지 제9항 중 어느 한 항의 방법을 구현하도록 적응된 컴퓨터 프로그램 코드를 포함하는, 컴퓨터 프로그램.</claim></claimInfo><claimInfo><claim>12. 증강 현실 디바이스로서,장면의 프레임들을 캡처하기 위한 카메라;디스플레이; 및캡처된 프레임들을 처리하고, 상기 디스플레이 상에 현재 프레임을 렌더링하기 위한 프로세서를 포함하며,상기 프로세서는 제1항 내지 제9항 중 어느 한 항의 방법을 구현하도록 구성되는, 증강 현실 디바이스.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>네덜란드 아인트호벤 **** 에이쥐 하이 테크 캠퍼스 **</address><code>519981119581</code><country>네덜란드</country><engName>Koninklijke Philips N.V.</engName><name>코닌클리케 필립스 엔.브이.</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>네덜란드 아인트호벤 **** 에이지 하이 테크 캠퍼...</address><code> </code><country>네덜란드</country><engName>VAREKAMP, Christiaan</engName><name>바레캄프 크리스티안</name></inventorInfo><inventorInfo><address>네덜란드 아인트호벤 **...</address><code> </code><country>네덜란드</country><engName>OOMEN, Arnoldus Werner Johannes</engName><name>우멘 아르놀두스 베르너 요하네스</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 종로구 세종대로 ***, **층 (세종로, 광화문빌딩)(법무법인센트럴)</address><code>919990006014</code><country>대한민국</country><engName>HOON CHANG</engName><name>장훈</name></agentInfo></agentInfoArray><priorityInfoArray><priorityInfo><priorityApplicationCountry>유럽특허청(EPO)</priorityApplicationCountry><priorityApplicationDate>2022.11.03</priorityApplicationDate><priorityApplicationNumber>22205361.3</priorityApplicationNumber></priorityInfo></priorityInfoArray><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Document according to the Article 203 of Patent Act</documentEngName><documentName>[특허출원]특허법 제203조에 따른 서면</documentName><receiptDate>2025.06.02</receiptDate><receiptNumber>1-1-2025-0615351-24</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>발송처리완료 (Completion of Transmission) </commonCodeName><documentEngName>Notice of Acceptance</documentEngName><documentName>수리안내서</documentName><receiptDate>2025.06.12</receiptDate><receiptNumber>1-5-2025-0097214-64</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020257018221.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93b2c9a7eacf45e2a3a0bd32d790fa1095e91e9059d74d4c29405bec82f8da71466f8a7472eed1fd62c164c1b86c41fd85ee96c8b0b03aace9</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cf4539ac9dda6168bf3096c7a33ffcdf89c08528a75cb49af59d198e2e0084fc948681da65b206c31bb5812c29d91d22b6513f9d34a8e0f86f</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>