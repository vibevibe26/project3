<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:41:42.4142</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2022.12.29</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2022-0188249</applicationNumber><claimCount>14</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>전이학습 기반의 에이전트 학습 시스템 및 방법</inventionTitle><inventionTitleEng>SYSTEM AND METHOD FOR LEARNING OF AGENT BASED ON  TRANSFER-LEARNING</inventionTitleEng><openDate>2024.07.08</openDate><openNumber>10-2024-0105824</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.05.31</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/096</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/09</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/006</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 전이학습 기반의 에이전트 학습 방법이 제공된다. 상기 방법은 제1 환경 조건에서 기 학습된 에이전트(이하, 소스 에이전트)를 준비하는 단계; 상기 소스 에이전트를 이용하여 상기 제1 환경 조건과 상이한 제2 환경 조건에서 학습할 에이전트(이하, 타겟 에이전트)의 학습을 위한 학습 데이터를 획득하는 단계; 상기 학습 데이터를 기반으로 상기 타겟 에이전트를 사전 학습시키는 단계; 및 상기 사전 학습된 타겟 에이전트를 대상으로 상기 제2 환경 조건에서 심층 강화학습 기반의 학습을 수행하는 단계를 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 컴퓨터에 의해 수행되는 방법에 있어서,제1 환경 조건에서 기 학습된 에이전트(이하, 소스 에이전트)를 준비하는 단계;상기 소스 에이전트를 이용하여 상기 제1 환경 조건과 상이한 제2 환경 조건에서 학습할 에이전트(이하, 타겟 에이전트)의 학습을 위한 학습 데이터를 획득하는 단계;상기 학습 데이터를 기반으로 상기 타겟 에이전트를 사전 학습시키는 단계; 및상기 사전 학습된 타겟 에이전트를 대상으로 상기 제2 환경 조건에서 심층 강화학습 기반의 학습을 수행하는 단계를 포함하는,전이학습 기반의 에이전트 학습 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 소스 에이전트를 이용하여 상기 제1 환경 조건과 상이한 제2 환경 조건에서 타겟 에이전트의 학습을 위한 학습 데이터를 획득하는 단계는,상기 제1 환경 조건을 대상으로, 기 수집되는 소스 에이전트를 위한 제1 관측값에 더하여 상기 타겟 에이전트를 위한 제2 관측값을 수집하는 단계;상기 제1 환경 조건에서 상기 소스 에이전트를 동작시키는 단계; 및상기 제1 환경 조건에서의 동작 결과를 기반으로 상기 타겟 에이전트의 학습을 위한 학습 데이터를 수집하는 단계를 포함하는,전이학습 기반의 에이전트 학습 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 제1 환경 조건에서 상기 소스 에이전트를 동작시키는 단계는,정책 신경망에서의 상기 제1 관측값에 대한 최적 행동값을 획득하는 단계; 및가치 신경망에서의 상기 제1 관측값에 대한 현 상태의 가치값을 획득하는 단계를 포함하는,전이학습 기반의 에이전트 학습 방법.</claim></claimInfo><claimInfo><claim>4. 제3항에 있어서,상기 제1 환경 조건에서의 동작 결과를 기반으로 상기 타겟 에이전트의 학습을 위한 학습 데이터를 수집하는 단계는,상기 제2 관측값과, 상기 제1 관측값에 대한 최적 행동값 및 가치값을 상기 학습 데이터로 수집하는 것인,전이학습 기반의 에이전트 학습 방법.</claim></claimInfo><claimInfo><claim>5. 제1항에 있어서,상기 학습 데이터를 기반으로 상기 타겟 에이전트를 사전 학습시키는 단계는,상기 타겟 에이전트의 정책 신경망 및 가치 신경망을 초기화하는 단계;상기 초기화된 정책 신경망 및 가치 신경망을 대상으로 지도학습 기반의 학습을 위한 상기 학습 데이터를 설정하는 단계; 및상기 학습 데이터를 기반으로 정책 신경망 및 가치 신경망의 각 손실함수 계산 및 가중치 갱신 과정을 반복 수행하여 학습하는 단계를 포함하는,전이학습 기반의 에이전트 학습 방법.</claim></claimInfo><claimInfo><claim>6. 제5항에 있어서,상기 학습 데이터를 기반으로 정책 신경망 및 가치 신경망의 각 손실함수 계산 및 가중치 갱신 과정을 반복 수행하여 학습을 수행하는 단계는,상기 각 손실함수 값의 감소 정도에 따른 학습 조기 종료 조건 및 사전 정의된 반복 횟수 중 적어도 하나를 포함하는 학습 종료 조건을 만족할 때까지 상기 학습을 반복 수행하는 것인,전이학습 기반의 에이전트 학습 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 사전 학습된 타겟 에이전트를 대상으로 상기 제2 환경 조건에서 심층 강화학습 기반의 학습을 수행하는 단계는,상기 제2 환경 조건에 상응하는 문제 해결 성공률 및 사전 정의된 반복 횟수 중 적어도 하나를 포함하는 학습 조건을 만족할 때까지 상기 심층 강화학습 기반의 학습을 반복 수행하는 것인,전이학습 기반의 에이전트 학습 방법.</claim></claimInfo><claimInfo><claim>8. 제1 환경 조건에서 기 학습된 에이전트(이하, 소스 에이전트) 및 상기 소스 에이전트에 기반하여 상기 제1 환경 조건과 상이한 제2 환경 조건에서 학습할 에이전트(이하, 타겟 에이전트)의 학습을 위한 프로그램이 저장된 메모리 및상기 메모리에 저장된 프로그램을 실행시킴에 따라, 상기 타겟 에이전트의 학습을 위한 학습 데이터를 획득하고, 상기 학습 데이터를 기반으로 상기 타겟 에이전트를 사전 학습시킨 후, 상기 사전 학습된 타겟 에이전트를 대상으로 상기 제2 환경 조건에서 심층 강화학습 기반의 학습을 수행하는 프로세서를 포함하는,전이학습 기반의 에이전트 학습 시스템.</claim></claimInfo><claimInfo><claim>9. 제8항에 있어서,상기 프로세서는 상기 제1 환경 조건을 대상으로, 기 수집되는 소스 에이전트를 위한 제1 관측값에 더하여 상기 타겟 에이전트를 위한 제2 관측값을 상태값에 포함하여 반환하고, 상기 제1 환경 조건에서 상기 소스 에이전트를 동작시킨 후 동작 결과를 기반으로 상기 타겟 에이전트의 학습을 위한 학습 데이터를 수집하는 것인,전이학습 기반의 에이전트 학습 시스템.</claim></claimInfo><claimInfo><claim>10. 제9항에 있어서,상기 프로세서는 정책 신경망에서의 상기 제1 관측값에 대한 최적 행동값과, 가치 신경망에서의 상기 제1 관측값에 대한 현 상태의 가치값을 각각 획득하는 것인,전이학습 기반의 에이전트 학습 시스템.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 프로세서는 상기 제2 관측값과, 상기 제1 관측값에 대한 최적 행동값 및 가치값을 상기 학습 데이터로 수집하는 것인,전이학습 기반의 에이전트 학습 시스템.</claim></claimInfo><claimInfo><claim>12. 제8항에 있어서,상기 프로세서는 상기 타겟 에이전트의 정책 신경망 및 가치 신경망을 초기화시킨 후, 지도학습 기반으로 상기 초기화된 정책 신경망 및 가치 신경망을 학습시키기 위한 상기 학습 데이터를 설정한 후, 상기 설정된 학습 데이터를 기반으로 정책 신경망 및 가치 신경망의 각 손실함수 계산 및 가중치 갱신 과정을 반복 수행하여 학습을 수행하는 것인,전이학습 기반의 에이전트 학습 시스템.</claim></claimInfo><claimInfo><claim>13. 제12항에 있어서,상기 프로세서는 상기 각 손실함수 값의 감소 정도에 따른 학습 조기 종료 조건 및 사전 정의된 반복 횟수 중 적어도 하나를 포함하는 학습 종료 조건을 만족할 때까지 상기 학습을 반복 수행하는 것인,전이학습 기반의 에이전트 학습 시스템.</claim></claimInfo><claimInfo><claim>14. 제8항에 있어서,상기 프로세서는 상기 제2 환경 조건에 상응하는 문제 해결 성공률 및 사전 정의된 반복 횟수 중 적어도 하나를 포함하는 학습 조건을 만족할 때까지 상기 심층 강화학습 기반의 학습을 반복 수행하는 것인,전이학습 기반의 에이전트 학습 시스템.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>대전광역시 유성구...</address><code>319980077638</code><country>대한민국</country><engName>Electronics and Telecommunications Research Institute</engName><name>한국전자통신연구원</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>JANG, Soo Young</engName><name>장수영</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>LEE, Sang Yeoun</engName><name>이상연</name></inventorInfo><inventorInfo><address>대전광역시 유성구...</address><code> </code><country> </country><engName>JEON, Ji Hun</engName><name>전지훈</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 남부순환로**** 차우빌딩*층</address><code>920071000215</code><country>대한민국</country><engName>JIMYUNG Patent Firm</engName><name>특허법인지명</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2022.12.29</receiptDate><receiptNumber>1-1-2022-1416316-99</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.05.31</receiptDate><receiptNumber>1-1-2023-0601253-17</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020220188249.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93682c07fb8a838fae6ce52040beab13b701b4fd52ddf03127ee95e60a4518b205e15b71c163164d26d5b4f4edaa16c1207ffc47354c96e7df</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff99f7a23f3e0ea420f119d6cf18e753bdf8d3c61389c6c95f145c5c6183adf7a02d8a2a3f574f57b3d81ccc50075b9d5b5ce17ac8d9cf623</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>