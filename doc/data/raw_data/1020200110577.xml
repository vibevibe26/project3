<?xml version="1.0" encoding="UTF-8" standalone="yes"?><response><header><requestMsgID></requestMsgID><responseTime>2025-11-17 18:05:41.541</responseTime><responseMsgID></responseMsgID><successYN>Y</successYN><resultCode>00</resultCode><resultMsg>NORMAL SERVICE.</resultMsg></header><body><item><biblioSummaryInfoArray><biblioSummaryInfo><applicationDate>2020.08.31</applicationDate><applicationFlag> </applicationFlag><applicationNumber>10-2020-0110577</applicationNumber><claimCount>24</claimCount><examinerName> </examinerName><finalDisposal> </finalDisposal><inventionTitle>부분 영상 기반의 영상 처리 방법 및 장치</inventionTitle><inventionTitleEng>METHOD AND APPARATUS FOR PROCESSING IMAGE BASED ON  PARTIAL IMAGE</inventionTitleEng><openDate>2022.03.08</openDate><openNumber>10-2022-0028928</openNumber><originalApplicationDate> </originalApplicationDate><originalApplicationKind>국내출원/신규</originalApplicationKind><originalApplicationNumber> </originalApplicationNumber><originalExaminationRequestDate>2023.08.29</originalExaminationRequestDate><originalExaminationRequestFlag>Y</originalExaminationRequestFlag><publicationDate> </publicationDate><publicationNumber> </publicationNumber><registerDate> </registerDate><registerNumber> </registerNumber><registerStatus>공개</registerStatus><translationSubmitDate> </translationSubmitDate></biblioSummaryInfo></biblioSummaryInfoArray><ipcInfoArray><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/11</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2022.01.01)</ipcDate><ipcNumber>G06V 40/16</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2017.01.01)</ipcDate><ipcNumber>G06T 7/70</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/08</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/044</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/0464</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2023.01.01)</ipcDate><ipcNumber>G06N 3/045</ipcNumber></ipcInfo><ipcInfo><ipcDate>(2019.01.01)</ipcDate><ipcNumber>G06F 1/32</ipcNumber></ipcInfo></ipcInfoArray><familyInfoArray><familyInfo/></familyInfoArray><abstractInfoArray><abstractInfo><astrtCont> 부분 영상 단위 기반의 영상 처리 방법 및 장치가 개시된다. 일 실시예에 따르면, 영상 처리 방법은 입력 영상 프레임의 현재 부분 처리 영역의 픽셀 데이터를 CNN에 입력하여 현재 부분 처리 영역에 관한 특징을 추출하고, 추출된 특징을 RNN에 입력하여 현재 부분 처리 영역과 적어도 하나의 이전 부분 처리 영역 간의 컨텍스트에 관한 RNN의 히든 상태를 갱신하고, 갱신된 히든 상태에 기초하여 입력 영상 프레임에 관한 영상 처리 결과를 생성하는 단계들을 포함한다. </astrtCont></abstractInfo></abstractInfoArray><internationalInfoArray><internationalInfo><internationOpenDate> </internationOpenDate><internationOpenNumber> </internationOpenNumber><internationalApplicationDate> </internationalApplicationDate><internationalApplicationNumber> </internationalApplicationNumber></internationalInfo></internationalInfoArray><claimInfoArray><claimInfo><claim>1. 입력 영상 프레임의 현재 부분 처리 영역의 픽셀 데이터를 컨볼루셔널 뉴럴 네트워크(Convolutional Neural Network, CNN)에 입력하여, 상기 현재 부분 처리 영역에 관한 특징을 추출하는 단계;상기 추출된 특징을 리커런트 뉴럴 네트워크(Recurrent Neural Network, RNN)에 입력하여, 상기 현재 부분 처리 영역과 적어도 하나의 이전 부분 처리 영역 간의 컨텍스트에 관한 상기 RNN의 히든 상태를 갱신하는 단계; 및상기 갱신된 히든 상태에 기초하여, 상기 입력 영상 프레임에 관한 영상 처리 결과를 생성하는 단계를 포함하는 영상 처리 방법.</claim></claimInfo><claimInfo><claim>2. 제1항에 있어서,상기 CNN은 멀티-헤드 CNN(Multi-head CNN, MCNN)인,영상 처리 방법.</claim></claimInfo><claimInfo><claim>3. 제2항에 있어서,상기 특징을 추출하는 상기 단계는상기 현재 부분 처리 영역의 상기 픽셀 데이터를 상기 MCNN의 각 헤드에 입력하여, 상기 현재 부분 처리 영역에 관한 복수의 중간 특징들을 추출하는 단계; 및상기 추출된 복수의 중간 특징들을 융합하여, 상기 현재 부분 처리 영역에 관한 인코드된 특징을 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>4. 제1항에 있어서,상기 히든 상태를 갱신하는 상기 단계는상기 추출된 특징을 1차원 벡터로 변환하여, 상기 RNN에 입력하는 단계를 포함하는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>5. 제4항에 있어서,상기 1차원 벡터는 채널 방향의 벡터 및 폭 방향의 벡터 중 적어도 하나를 포함하는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>6. 제1항에있어서,상기 영상 처리 결과를 생성하는 상기 단계는상기 현재 부분 처리 영역이 상기 입력 영상 프레임의 마지막 부분 처리 영역에 해당하는 경우, 상기 갱신된 히든 상태에 기초하여 최종 컨텍스트 데이터를 생성하는 단계; 및상기 최종 컨텍스트 데이터에 기초하여, 상기 영상 처리 결과를 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>7. 제1항에 있어서,상기 영상 처리 결과는상기 입력 영상 프레임에 대상 객체가 존재하는지를 나타내는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>8. 제7항에 있어서,상기 대상 객체는 사람인,영상 처리 방법.</claim></claimInfo><claimInfo><claim>9. 제7항에 있어서,상기 대상 객체는 사람의 얼굴인,영상 처리 방법.</claim></claimInfo><claimInfo><claim>10. 제1항에 있어서,상기 영상 처리 결과를 생성하는 상기 단계는상기 현재 부분 처리 영역이 상기 입력 영상 프레임의 마지막 부분 처리 영역에 해당하지 않는 경우, 상기 갱신된 히든 상태에 기초하여 중간 컨텍스트 데이터를 생성하는 단계; 및상기 중간 컨텍스트 데이터에 기초하여, 중간 검출 결과를 생성하는 단계를 포함하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>11. 제10항에 있어서,상기 중간 검출 결과가 상기 입력 영상 프레임에 대상 객체가 존재함을 나타내는 경우, 적어도 하나의 다음 부분 처리 영역에 관한 추가적인 영상 처리 프로세스가 수행되지 않고, 상기 입력 영상 프레임에 관한 영상 처리 프로세스가 종료되는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>12. 제1항에 있어서,상기 현재 부분 처리 영역을 포함하는 각 부분 처리 영역은 이미지 센서의 영상 신호 처리(Image Signal Processing, ISP)를 위한 픽셀 라인 그룹에 대응하는, 영상 처리 방법.</claim></claimInfo><claimInfo><claim>13. 제1항에 있어서,상기 특징을 추출하는 상기 단계, 상기 히든 상태를 갱신하는 상기 단계, 및 상기 영상 처리 결과를 생성하는 상기 단계는 저전력 모드에서 수행되는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>14. 제1항에 있어서,상기 CNN은트레이닝 영상 프레임의 각 부분 처리 영역에 관한 객체 위치 정보를 이용하여 미리 트레이닝되는,영상 처리 방법.</claim></claimInfo><claimInfo><claim>15. 제1항 내지 제14항 중 어느 한 항의 방법을 수행하는 명령어들을 포함하는 하나 이상의 프로그램을 저장한 컴퓨터 판독 가능 저장매체.</claim></claimInfo><claimInfo><claim>16. 프로세서; 및상기 프로세서에서 실행가능한 명령어들을 저장하는 메모리를 포함하고,상기 명령어들이 상기 프로세서에서 실행되면, 상기 프로세서는입력 영상 프레임의 현재 부분 처리 영역의 픽셀 데이터를 컨볼루셔널 뉴럴 네트워크(Convolutional Neural Network, CNN)에 입력하여, 상기 현재 부분 처리 영역에 관한 특징을 추출하고,상기 추출된 특징을 리커런트 뉴럴 네트워크(Recurrent Neural Network, RNN)에 입력하여, 상기 현재 부분 처리 영역과 적어도 하나의 이전 부분 처리 영역 간의 컨텍스트에 관한 상기 RNN의 히든 상태를 갱신하고,상기 갱신된 히든 상태에 기초하여, 상기 입력 영상 프레임에 관한 영상 처리 결과를 생성하는,영상 처리 장치.</claim></claimInfo><claimInfo><claim>17. 제16항에 있어서,상기 CNN은 멀티-헤드 CNN(Multi-head CNN, MCNN)이고,상기 프로세서는상기 현재 부분 처리 영역의 상기 픽셀 데이터를 상기 MCNN의 각 헤드에 입력하여, 상기 현재 부분 처리 영역에 관한 복수의 중간 특징들을 추출하고, 상기 추출된 복수의 중간 특징들을 융합하여, 상기 현재 부분 처리 영역에 관한 인코드된 특징을 생성하는,영상 처리 장치.</claim></claimInfo><claimInfo><claim>18. 제16항에있어서,상기 프로세서는상기 현재 부분 처리 영역이 상기 입력 영상 프레임의 마지막 부분 처리 영역에 해당하는 경우, 상기 갱신된 히든 상태에 기초하여 최종 컨텍스트 데이터를 생성하고, 상기 최종 컨텍스트 데이터에 기초하여, 상기 영상 처리 결과를 생성하는,영상 처리 장치.</claim></claimInfo><claimInfo><claim>19. 제16항에 있어서,상기 프로세서는상기 현재 부분 처리 영역이 상기 입력 영상 프레임의 마지막 부분 처리 영역에 해당하지 않는 경우, 상기 갱신된 히든 상태에 기초하여 중간 컨텍스트 데이터를 생성하고, 상기 중간 컨텍스트 데이터에 기초하여, 중간 검출 결과를 생성하는,영상 처리 장치.</claim></claimInfo><claimInfo><claim>20. 제16항에 있어서,상기 현재 부분 처리 영역을 포함하는 각 부분 처리 영역은 이미지 센서의 영상 신호 처리(Image Signal Processing, ISP)를 위한 픽셀 라인 그룹에 대응하는, 영상 처리 장치.</claim></claimInfo><claimInfo><claim>21. 입력 영상 프레임을 생성하는 카메라;명령어들을 저장하는 메모리; 및상기 메모리에 저장된 명령어들을 실행하여,상기 입력 영상 프레임의 현재 부분 처리 영역의 픽셀 데이터를 컨볼루셔널 뉴럴 네트워크(Convolutional Neural Network, CNN)에 입력하여, 상기 현재 부분 처리 영역에 관한 특징을 추출하고,상기 추출된 특징을 리커런트 뉴럴 네트워크(Recurrent Neural Network, RNN)에 입력하여, 상기 현재 부분 처리 영역과 적어도 하나의 이전 부분 처리 영역 간의 컨텍스트에 관한 상기 RNN의 히든 상태를 갱신하고,상기 갱신된 히든 상태에 기초하여, 상기 입력 영상 프레임에 관한 영상 처리 결과를 생성하는, 프로세서를 포함하는, 전자 장치.</claim></claimInfo><claimInfo><claim>22. 제21항에 있어서,상기 현재 부분 처리 영역에 관한 특징을 추출하는 것, 상기 RNN의 히든 상태를 갱신하는 것, 상기 영상 처리 결과를 생성하는 것은 저전력 모드에서 수행되고,상기 입력 영상 프레임에서 대상 객체가 검출됨에 따라, 상기 전자 장치는 웨이크-업되어 일반 모드에서 영상 처리와 연계된 동작을 수행하는,전자 장치.</claim></claimInfo><claimInfo><claim>23. 제22항에 있어서,상기 저전력 모드는 올웨이즈-온 모드를 포함하는,전자 장치.</claim></claimInfo><claimInfo><claim>24. 제22항에 있어서,상기 영상 처리는 객체 검출을 포함하고,상기 영상 처리와 연계된 상기 동작은 객체 추적, 객체 인식, 잠금 해제 중 적어도 하나를 포함하는,전자 장치.</claim></claimInfo></claimInfoArray><applicantInfoArray><applicantInfo><address>경기도 수원시 영통구...</address><code>119981042713</code><country>대한민국</country><engName>SAMSUNG ELECTRONICS CO., LTD.</engName><name>삼성전자주식회사</name></applicantInfo></applicantInfoArray><inventorInfoArray><inventorInfo><address>경기도 수원시 영통구...</address><code>420190282445</code><country>대한민국</country><engName>YOO, Jae Hyoung</engName><name>유재형</name></inventorInfo><inventorInfo><address>경기도 안양시 동안구...</address><code>420170731095</code><country>대한민국</country><engName>SON, Chang Yong</engName><name>손창용</name></inventorInfo><inventorInfo><address>경기도 수원시 권선구...</address><code>420190482041</code><country>대한민국</country><engName>LEE, Dong Wook</engName><name>이동욱</name></inventorInfo><inventorInfo><address>서울특별시 서초구...</address><code>420170731631</code><country>대한민국</country><engName>Han, Jae Joon</engName><name>한재준</name></inventorInfo><inventorInfo><address>경기도 성남시 분당구...</address><code>420170475655</code><country>대한민국</country><engName>CHOI, Chang Kyu</engName><name>최창규</name></inventorInfo></inventorInfoArray><agentInfoArray><agentInfo><address>서울특별시 강남구 언주로 ***, *층(역삼동,화물재단빌딩)</address><code>920071000614</code><country>대한민국</country><engName>MUHANN PATENT &amp; LAW FIRM</engName><name>특허법인무한</name></agentInfo></agentInfoArray><priorityInfoArray/><designatedStateInfoArray/><priorArtDocumentsInfoArray/><legalStatusInfoArray><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName>[Patent Application] Patent Application</documentEngName><documentName>[특허출원]특허출원서</documentName><receiptDate>2020.08.31</receiptDate><receiptNumber>1-1-2020-0919528-77</receiptNumber></legalStatusInfo><legalStatusInfo><commonCodeName>수리 (Accepted) </commonCodeName><documentEngName> </documentEngName><documentName>[심사청구]심사청구서·우선심사신청서</documentName><receiptDate>2023.08.29</receiptDate><receiptNumber>1-1-2023-0954076-11</receiptNumber></legalStatusInfo></legalStatusInfoArray><imagePathInfo><docName>1020200110577.jpg</docName><largePath>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=6c650beb4cee9ce4122b704b88878c93020054ae5e1a718a3569ea9966b3c101615aa36ce59703048dad79703eae137f42c085a1baf4b5b3f4dc01590fde3b7add53e8a6d8542445</largePath><path>http://plus.kipris.or.kr/kiprisplusws/fileToss.jsp?arg=ed43a0609e94d6e22d01c5c32ba711cff2f9c5a5431a290782b2118adb99d0e58dcd12e1d580b1b93e86d3571186d4519ce5bcf28c20d8dd7f9b9cf8679fecbeab495df70c1affea</path></imagePathInfo><rndInfoArray/></item></body><count><numOfRows>1</numOfRows><pageNo>1</pageNo><totalCount>1</totalCount></count></response>