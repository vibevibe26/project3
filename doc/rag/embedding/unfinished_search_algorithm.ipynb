{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80bf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chromadb sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tower\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "모델 로드 중...\n",
      "✅ 데이터베이스 로드 완료! 총 데이터 수: 589049개\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. 설정 (GPU 확인 등)\n",
    "# ---------------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. 모델 로드 (저장할 때 썼던 그 모델!)\n",
    "# ---------------------------------------------------------\n",
    "print(\"모델 로드 중...\")\n",
    "model = SentenceTransformer(\"dragonkue/BGE-m3-ko\").to(device)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ChromaDB 연결 (다운로드 받은 폴더 경로 지정)\n",
    "# ---------------------------------------------------------\n",
    "# path=\"./chroma_db\" 는 압축 푼 폴더 이름과 같아야 합니다.\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# 컬렉션 가져오기 (create가 아니라 get_collection 사용)\n",
    "collection = client.get_collection(name=\"patent_claims\")\n",
    "\n",
    "print(f\"✅ 데이터베이스 로드 완료! 총 데이터 수: {collection.count()}개\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee944ab",
   "metadata": {},
   "source": [
    "### 특허 단위 점수 집계(Late Fusion Aggregated Scoring)\n",
    "- 출원번호 하나당 모든 ‘매칭된 청구항’들의 유사도 점수를 통계적으로 합성해서 특허 단위 점수를 만듦\n",
    "- 단점: 독립항이 핵심인데 종속항이 우연히 많이 매칭되면 점수가 잘못 올라갈 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165b7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def many_claim_dis(results, TOP_K):\n",
    "    # ----------------------------------------\n",
    "    # 0. Chroma 결과 파싱\n",
    "    # ----------------------------------------\n",
    "    ids        = results[\"ids\"][0]\n",
    "    docs       = results[\"documents\"][0]\n",
    "    metas      = results[\"metadatas\"][0]\n",
    "    distances  = results[\"distances\"][0]\n",
    "\n",
    "    parsed = []\n",
    "    for i in range(len(ids)):\n",
    "        parsed.append({\n",
    "            \"id\": ids[i],\n",
    "            \"document\": docs[i],\n",
    "            \"metadata\": metas[i],\n",
    "            \"distance\": distances[i]\n",
    "        })\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 1. 출원번호 기준 그룹화\n",
    "    # ----------------------------------------\n",
    "    grouped = defaultdict(list)\n",
    "    for r in parsed:\n",
    "        app_no = r[\"metadata\"][\"patent_id\"]\n",
    "        grouped[app_no].append(r)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 2. 특허 단위 점수 계산\n",
    "    #    방법: claim similarity들의 평균 + 대표 claim 보정\n",
    "    # ----------------------------------------\n",
    "\n",
    "    def similarity(d):\n",
    "        return 1-d\n",
    "\n",
    "\n",
    "    def compute_patent_score(claims):\n",
    "        sims = [similarity(c[\"distance\"]) for c in claims]   # 새로운 sim\n",
    "\n",
    "        sims_sorted = sorted(sims, reverse=True)\n",
    "        top3 = sims_sorted[:3]\n",
    "        top3_avg = sum(top3) / len(top3)\n",
    "        max_sim = sims_sorted[0]\n",
    "\n",
    "        claim_count = len(claims)\n",
    "        count_bonus = min(1.0, claim_count / 10.0)\n",
    "\n",
    "        final_score =  top3_avg * 0.6 + max_sim * 0.3 + count_bonus * 0.1\n",
    "    \n",
    "        return final_score\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 3. 특허 단위 재랭킹\n",
    "    # ----------------------------------------\n",
    "    aggregated = []\n",
    "    for app_no, claims in grouped.items():\n",
    "        score = compute_patent_score(claims)\n",
    "\n",
    "        # 대표 claim은 거리(distance)가 가장 낮은 claim 선택\n",
    "        rep_claim = sorted(claims, key=lambda x: x[\"distance\"])[0]\n",
    "         # claims에서 id와 metadata를 제외하고 document와 distance만 저장\n",
    "        \n",
    "        filtered_claims = [\n",
    "            {\n",
    "                \"id\": c[\"id\"],\n",
    "                \"document\": c[\"document\"],\n",
    "                \"distance\": c[\"distance\"]\n",
    "            }\n",
    "            for c in claims\n",
    "        ]\n",
    "\n",
    "        aggregated.append({\n",
    "            \"patent_id\": app_no,\n",
    "            \"score\": score,\n",
    "            \"top_claim\": rep_claim[\"document\"],\n",
    "            \"top_claim_no\": rep_claim[\"metadata\"][\"claim_no\"],\n",
    "            \"claims_found\": len(claims),\n",
    "            \"claims\": filtered_claims\n",
    "        })\n",
    "\n",
    "    # 점수 높은 순으로 재랭킹\n",
    "    aggregated = sorted(aggregated, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    final_response = aggregated[:TOP_K]\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9940e",
   "metadata": {},
   "source": [
    "### 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4a5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(results, ipc_list, TOP_K):\n",
    "    final_response = many_claim_dis(results, TOP_K)\n",
    "\n",
    "    # 비교\n",
    "    response_patent_id = [f['patent_id'] for f in final_response]\n",
    "\n",
    "    print(ipc_list & set(response_patent_id))\n",
    "\n",
    "    print(\"Precision:\", len(ipc_list & set(response_patent_id)) / TOP_K)\n",
    "    print(\"Recall:\", len(ipc_list & set(response_patent_id)) / len(ipc_list))\n",
    "\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2654508",
   "metadata": {},
   "source": [
    "### query가 2개 이상일 때 re-ranking해서 200건만 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200개 초과 검색되었을 때 re-ranking (z 정규화 수정ver)\n",
    "import numpy as np\n",
    "\n",
    "def multi_query_rerank(\n",
    "    collection,\n",
    "    model,\n",
    "    query_list,\n",
    "    per_query_top_k=200,\n",
    "    final_top_k=200\n",
    "):\n",
    "    #------------------------------------------\n",
    "    # 1) Q개의 query 문장 embedding\n",
    "    #------------------------------------------\n",
    "    query_embs = model.encode(query_list).tolist()\n",
    "\n",
    "\n",
    "    #------------------------------------------\n",
    "    # 2-1) query_list가 한 개일 경우, 검색 후 바로 return\n",
    "    #------------------------------------------\n",
    "    if len(query_list) == 1:\n",
    "        return collection.query(query_embeddings=query_embs, n_results=per_query_top_k)\n",
    "\n",
    "\n",
    "    #------------------------------------------\n",
    "    # 2-2) query별 검색\n",
    "    #------------------------------------------\n",
    "    candidates = []  # 전체 후보 저장\n",
    "    for emb in query_embs:\n",
    "        r = collection.query(\n",
    "            query_embeddings=[emb],\n",
    "            n_results=per_query_top_k\n",
    "        )\n",
    "    \n",
    "        distances = np.array(r[\"distances\"][0])\n",
    "        mean = distances.mean()\n",
    "        std = distances.std() + 1e-9\n",
    "\n",
    "        z_scores = (distances - mean) / std\n",
    "\n",
    "        ids = r[\"ids\"][0]\n",
    "        docs = r[\"documents\"][0]\n",
    "        distances = r[\"distances\"][0]\n",
    "        metas = r[\"metadatas\"][0]\n",
    "\n",
    "        # 후보를 통합 리스트에 추가\n",
    "        for pid, doc, meta, z, dist in zip(ids, docs, metas, z_scores, distances):\n",
    "            candidates.append({\n",
    "                \"id\": pid,\n",
    "                \"document\": doc,\n",
    "                'metadatas':meta,\n",
    "                'distance':dist,\n",
    "                'z-score':z\n",
    "            })\n",
    "\n",
    "    #------------------------------------------\n",
    "    # 3) z-score 기준 오름차순 정렬 후 상위 final_top_k만 선택\n",
    "    #------------------------------------------\n",
    "    top_candidates = sorted(candidates, key=lambda x: x[\"z-score\"])[:final_top_k]\n",
    "\n",
    "\n",
    "    #------------------------------------------\n",
    "    # 4) collection.query() 형식으로 재구성\n",
    "    #------------------------------------------\n",
    "    final_ids = [c[\"id\"] for c in top_candidates]\n",
    "    final_docs = [c[\"document\"] for c in top_candidates]\n",
    "    final_distances = [c[\"distance\"] for c in top_candidates]\n",
    "    final_metas = [c['metadatas'] for c in top_candidates]\n",
    "\n",
    "    final_results = {\n",
    "        \"ids\": [final_ids],\n",
    "        \"documents\": [final_docs],\n",
    "        \"distances\": [final_distances],\n",
    "        \"metadatas\": [final_metas]\n",
    "    }\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c303a2",
   "metadata": {},
   "source": [
    "### 정답 데이터 만들고 비교 1\n",
    "G05D1/243, G05D1/648\n",
    "환경에서 자연적으로 발생하는 신호를 캡처하는 수단, 예. 주변 광학, 음향, 중력 또는 자기 신호\n",
    "작업 영역이나 공간 내에서 작업 수행, 예. 청소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6f648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1020230193702', '1020240025833', '1020240075882'}\n",
      "Precision: 0.1\n",
      "Recall: 0.6\n"
     ]
    }
   ],
   "source": [
    "query = [\"청소 로봇 제어, 외부 전자 장치 소리 데이터 수집\"]\n",
    "\n",
    "results = multi_query_rerank(\n",
    "    collection=collection,\n",
    "    model=model,\n",
    "    query_list=query,\n",
    "    per_query_top_k=200,\n",
    "    final_top_k=200\n",
    ")\n",
    "\n",
    "ipc={\"1020230193702\", \"1020240075882\", \"1020240025833\", \"1020240009746\", \"1020230183389\"}\n",
    "\n",
    "TOP_K = 30\n",
    "final_results = eval(results, ipc, TOP_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f8d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1020230193702', '1020230183389'}\n",
      "Precision: 0.06666666666666667\n",
      "Recall: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'patent_id': '1020237013866',\n",
       "  'score': 0.6796000301837921,\n",
       "  'top_claim': '웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법으로서,웨어러블 장치의 이미지 센서로부터 시각적 데이터를 수신하는 단계; 객체 인식 모듈에 의해, 상기 시각적 데이터에 기초하여 식별 데이터를 생성하는 단계;상기 식별 데이터를 이용하여, 제1 3차원(3D) 지도 및 제2 3차원 지도를 포함하는 복수의 3차원 지도들을 저장하는 지도 데이터베이스로부터 제1 3차원 지도를 식별하는 단계 -상기 제1 3D 지도는 제1 제어가능한 장치와 연관되고, 상기 제2 3D 지도는 제2 제어가능한 장치와 연관됨-; 상기 제1 3차원 지도의 시각적 포지셔닝 데이터에 기초하여 물리적 공간에서 상기 제1 제어가능한 장치의 위치를 획득하는 단계; 그리고상기 제1 제어가능한 장치의 위치의 임계 거리 내의 위치에서 상기 웨어러블 장치의 디스플레이 상에 사용자 인터페이스(UI) 객체를 렌더링하는 단계를 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "  'top_claim_no': 1,\n",
       "  'claims_found': 16,\n",
       "  'claims': [{'id': '1020237013866_claim1',\n",
       "    'document': '웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법으로서,웨어러블 장치의 이미지 센서로부터 시각적 데이터를 수신하는 단계; 객체 인식 모듈에 의해, 상기 시각적 데이터에 기초하여 식별 데이터를 생성하는 단계;상기 식별 데이터를 이용하여, 제1 3차원(3D) 지도 및 제2 3차원 지도를 포함하는 복수의 3차원 지도들을 저장하는 지도 데이터베이스로부터 제1 3차원 지도를 식별하는 단계 -상기 제1 3D 지도는 제1 제어가능한 장치와 연관되고, 상기 제2 3D 지도는 제2 제어가능한 장치와 연관됨-; 상기 제1 3차원 지도의 시각적 포지셔닝 데이터에 기초하여 물리적 공간에서 상기 제1 제어가능한 장치의 위치를 획득하는 단계; 그리고상기 제1 제어가능한 장치의 위치의 임계 거리 내의 위치에서 상기 웨어러블 장치의 디스플레이 상에 사용자 인터페이스(UI) 객체를 렌더링하는 단계를 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.34189456701278687},\n",
       "   {'id': '1020237013866_claim5',\n",
       "    'document': '제1항 내지 제4항 중 어느 한 항에 있어서, 상기 식별 데이터는 상기 지도 데이터베이스에 상기 제1 3차원 지도와 연관되어 저장되는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.3540138006210327},\n",
       "   {'id': '1020237013866_claim17',\n",
       "    'document': '제어가능한 장치의 위치를 식별하기 위한 컴퓨팅 시스템으로서,시각적 데이터를 수신하도록 구성된 이미지 센서;상기 시각적 데이터에 기초하여 식별 데이터를 생성하도록 구성된 객체 인식 모듈;상기 식별 데이터를 사용하여, 제1 3차원(3D) 지도 및 제2 3차원 지도를 포함하는 복수의 3차원 지도들을 저장하고 있는 지도 데이터베이스로부터 제1 3차원 지도를 식별하도록 구성된 위치 식별자 -상기 제1 3D 지도는 제1 제어가능한 장치와 연관되고, 상기 제2 3D 지도는 제2 제어가능한 장치와 연관되고, 상기 위치 식별자는 상기 제1 3D 지도의 시각적 포지셔닝 데이터에 기초하여 물리적 공간에서 상기 제1 제어가능한 장치의 위치를 획득하도록 구성됨-; 그리고상기 제1 제어가능한 장치의 위치의 임계 거리 내에 있는 위치에서 웨어러블 장치의 디스플레이 상에 사용자 인터페이스(UI) 객체를 렌더링하도록 구성된 사용자 인터페이스(UI) 객체 렌더러를 포함하는 것을 특징으로 하는 제어가능한 장치의 위치를 식별하기 위한 컴퓨팅 시스템.',\n",
       "    'distance': 0.39324963092803955},\n",
       "   {'id': '1020237013866_claim7',\n",
       "    'document': '제1항 내지 제6항 중 어느 한 항에 있어서, 상기 방법은,상기 제1 제어가능한 장치와 연관된 설정 절차 동안 상기 제1 3D 지도를 생성하는 단계를 더 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.4080922603607178},\n",
       "   {'id': '1020237013866_claim11',\n",
       "    'document': '상기 지도 데이터베이스는 서버 컴퓨터에 저장되고, 상기 실행가능한 명령어는 상기 적어도 하나의 프로세서에 의해 실행될 때 상기 적어도 하나의 프로세서로 하여금 상기 서버 컴퓨터와 통신하여 상기 지도 데이터베이스에 액세스하게 하도록 구성되는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.40934324264526367},\n",
       "   {'id': '1020237013866_claim6',\n",
       "    'document': '제1항 내지 제5항 중 어느 한 항에 있어서, 상기 방법은,상기 시각적 데이터를 상기 제1 3D 지도와 비교하는 단계를 더 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.4134080410003662},\n",
       "   {'id': '1020237013866_claim3',\n",
       "    'document': '제1항 또는  상기 식별 데이터는 상기 제1 제어가능한 장치의 장치 이름 또는 장치 유형 중 적어도 하나를 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.42123961448669434},\n",
       "   {'id': '1020237013866_claim12',\n",
       "    'document': '상기 지도 데이터베이스는 상기 웨어러블 장치 또는 상기 웨어러블 장치에 통신가능하게 결합된 컴퓨팅 장치에 저장되고, 상기 실행가능한 명령어는 상기 적어도 하나의 프로세서에 의해 실행될 때 상기 적어도 하나의 프로세서로 하여금 상기 웨어러블 장치 또는 상기 컴퓨팅 시스템과 각각 통신하여 상기 지도 데이터베이스에 액세스하게 하도록 구성되는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.42333555221557617},\n",
       "   {'id': '1020237013866_claim2',\n",
       "    'document': '상기 위치는 상기 제어가능한 장치의 6자유도 위치(six degree of freedom position)를 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.42742955684661865},\n",
       "   {'id': '1020237013866_claim4',\n",
       "    'document': '제1항 내지 제3항 중 어느 한 항에 있어서, 상기 식별 데이터는 상기 제1 제어가능한 장치와 연관된 상기 물리적 공간의 공간 유형을 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.4396193027496338},\n",
       "   {'id': '1020237013866_claim14',\n",
       "    'document': '제10항 내지 제13항 중 어느 한 항에 있어서,  상기 식별 데이터는 상기 제1 제어가능한 장치와 연관된 장치 이름, 장치 유형 또는 공간 유형 중 적어도 하나를 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.44014400243759155},\n",
       "   {'id': '1020237013866_claim15',\n",
       "    'document': '제10항 내지 제14항 중 어느 한 항에 있어서, 상기 실행가능한 명령어는 상기 적어도 하나의 프로세서로 하여금:상기 제1 제어가능한 장치와 연관된 설정 절차 동안 상기 제1 3D 지도를 생성하게 하고; 그리고상기 제2 제어가능한 장치와 연관된 설정 절차 동안 상기 제2 3D 지도를 생성하게 하도록 하는 명령어를 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.44665855169296265},\n",
       "   {'id': '1020237013866_claim20',\n",
       "    'document': '제17항 내지 제18항 중 어느 한 항에 있어서, 상기 지도 데이터베이스는 서버 컴퓨터와 연관된 메모리 장치에 저장되며, 상기 컴퓨팅 시스템은:상기 서버 컴퓨터에서 상기 제1 3차원 지도를 식별하기 위해 상기 식별 데이터를 상기 서버 컴퓨터로 전송하는 안테나를 더 포함하며, 상기 안테나는 상기 서버 컴퓨터로부터 상기 시각적 포지셔닝 데이터를 수신하도록 구성되는 것을 특징으로 하는 제어가능한 장치의 위치를 식별하기 위한 컴퓨팅 시스템.',\n",
       "    'distance': 0.4582623243331909},\n",
       "   {'id': '1020237013866_claim10',\n",
       "    'document': '적어도 하나의 프로세서에 의해 실행될 때 상기 적어도 하나의 프로세서로 하여금 동작들을 수행하게 하는 실행가능한 명령어를 저장한 비일시적 컴퓨터 판독 가능 매체로서, 상기 동작들은, 웨어러블 장치의 이미지 센서로부터 시각적 데이터를 수신하는 동작; 객체 인식 모듈에 의해, 상기 시각적 데이터에 기초하여 식별 데이터를 생성하는 동작;상기 식별 데이터를 이용하여, 제1 3차원(3D) 지도 및 제2 3차원 지도를 포함하는 복수의 3차원 지도들을 저장하는 지도 데이터베이스로부터 제1 3차원 지도를 식별하는 동작 -상기 제1 3D 지도는 제1 제어가능한 장치와 연관되고, 상기 제2 3D 지도는 제2 제어가능한 장치와 연관됨-; 상기 제1 3D 지도의 시각적 포지셔닝 데이터에 기초하여 상기 시각적 데이터에 의해 적어도 부분적으로 표현되는 물리적 공간에서 상기 제1 제어가능한 장치의 위치를 획득하는 동작; 그리고 상기 제1 제어가능한 장치의 위치의 임계 거리 내에 있는 위치에서 상기 웨어러블 장치의 디스플레이 상에 사용자 인터페이스(UI) 객체를 렌더링하는 동작을 포함하며, 상기 UI 객체는 상기 제1 제어가능한 장치를 제어하기 위한 하나 이상의 대화형 제어(interactive control)를 포함하는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.4685460925102234},\n",
       "   {'id': '1020237013866_claim8',\n",
       "    'document': '제1항 내지 제7항 중 어느 한 항에 있어서, 상기 제1 3D 지도는 가상 클라우드 앵커에 대응하는 특징점 지도를 포함하고, 상기 가상 클라우드 앵커는 한 명 이상의 다른 사용자와 공유하도록 구성되는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.47343581914901733},\n",
       "   {'id': '1020237013866_claim13',\n",
       "    'document': '제10항 내지 제12항 중 어느 한 항에 있어서, 상기 UI 객체는 상기 제1 제어가능한 장치에 대한 정보를 제공하도록 구성되는 것을 특징으로 하는 웨어러블 장치를 이용하여 제어가능한 장치의 위치를 식별하는 방법.',\n",
       "    'distance': 0.4758610129356384}]},\n",
       " {'patent_id': '1020217027963',\n",
       "  'score': 0.5793642020225525,\n",
       "  'top_claim': '상기 증명 증거는 위치 기반인, 장치.',\n",
       "  'top_claim_no': 12,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020217027963_claim12',\n",
       "    'document': '상기 증명 증거는 위치 기반인, 장치.',\n",
       "    'distance': 0.36737310886383057}]},\n",
       " {'patent_id': '1020190159323',\n",
       "  'score': 0.5793266415596008,\n",
       "  'top_claim': '상기 사운드 스팟 정보는 사운드 스팟의 위치 정보를 더 포함하고,상기 프로세서는,상기 위치 정보에 기반하여 상기 탐색 영역에 위치한 상기 적어도 하나의 사운드 스팟을 결정하도록 더 구성되는,로봇.',\n",
       "  'top_claim_no': 4,\n",
       "  'claims_found': 12,\n",
       "  'claims': [{'id': '1020190159323_claim4',\n",
       "    'document': '상기 사운드 스팟 정보는 사운드 스팟의 위치 정보를 더 포함하고,상기 프로세서는,상기 위치 정보에 기반하여 상기 탐색 영역에 위치한 상기 적어도 하나의 사운드 스팟을 결정하도록 더 구성되는,로봇.',\n",
       "    'distance': 0.46353960037231445},\n",
       "   {'id': '1020190159323_claim16',\n",
       "    'document': '상기 사운드 스팟 정보는,사운드 스팟의 분포 정보, 식별 정보, 사운드 스팟 속성, 사운드 스팟 유형 및 사운드 스팟 스코어를 포함하는,음원 위치 추정 방법.',\n",
       "    'distance': 0.4681529998779297},\n",
       "   {'id': '1020190159323_claim8',\n",
       "    'document': '상기 프로세서는,상기 적어도 하나의 사운드 스팟의 식별 정보에 기반하여 상기 적어도 하나의 이미지 영역에서 상기 음원의 위치를 찾도록 더 구성되는,로봇.',\n",
       "    'distance': 0.47636479139328003},\n",
       "   {'id': '1020190159323_claim15',\n",
       "    'document': '입력 사운드의 유발이 가능한 잠재적인 공간적 위치에 대응하는 사운드 스팟에 대한 사운드 스팟 정보에 기반하여 상기 입력 사운드를 유발한 음원을 찾기 위한 탐색 영역을 결정하는 단계;상기 사운드 스팟 정보에 기반하여 정해진 탐색 순서에 따라 상기 탐색 영역에 위치한 적어도 하나의 사운드 스팟을 탐색하는 단계; 및상기 탐색의 결과에 기반하여 상기 적어도 하나의 사운드 스팟 중에서 상기 음원이 위치한 타겟 사운드 스팟을 결정하는 단계를 포함하는,음원 위치 추정 방법.',\n",
       "    'distance': 0.48419445753097534},\n",
       "   {'id': '1020190159323_claim20',\n",
       "    'document': '상기 타겟 사운드 스팟의 사운드 스팟 정보를 갱신하는 단계를 더 포함하는,음원 위치 추정 방법.',\n",
       "    'distance': 0.4849417805671692},\n",
       "   {'id': '1020190159323_claim17',\n",
       "    'document': '상기 탐색 영역을 결정하는 단계는,상기 입력 사운드의 속성과 매칭되는 사운드 스팟 속성을 가지는 사운드 스팟의 분포 정보에 기반하여 상기 탐색 영역을 결정하는 단계를 포함하는,음원 위치 추정 방법.',\n",
       "    'distance': 0.4853475093841553},\n",
       "   {'id': '1020190159323_claim1',\n",
       "    'document': '입력 사운드의 유발이 가능한 잠재적인 공간적 위치에 대응하는 사운드 스팟에 대한 사운드 스팟 정보를 저장하는 메모리; 및상기 메모리와 연결된 프로세서를 포함하고,상기 프로세서는,상기 사운드 스팟 정보에 기반하여 상기 입력 사운드를 유발한 음원을 찾기 위한 탐색 영역을 결정하고,상기 사운드 스팟 정보에 기반하여 정해진 탐색 순서에 따라 상기 탐색 영역에 위치한 적어도 하나의 사운드 스팟을 탐색하고,상기 탐색의 결과에 기반하여 상기 적어도 하나의 사운드 스팟 중에서 상기 음원이 위치한 타겟 사운드 스팟을 결정하도록 구성되는,로봇.',\n",
       "    'distance': 0.48645347356796265},\n",
       "   {'id': '1020190159323_claim7',\n",
       "    'document': '상기 사운드 스팟 정보는 사운드 스팟의 식별 정보를 더 포함하고,상기 프로세서는,상기 탐색 영역의 영상을 획득하고,상기 적어도 하나의 사운드 스팟의 식별 정보에 기반하여 상기 영상으로부터 상기 적어도 하나의 사운드 스팟에 각각 대응하는 적어도 하나의 이미지 영역을 추출하고,상기 적어도 하나의 이미지 영역 중에서 상기 음원이 위치한 상기 타겟 사운드 스팟을 결정하도록 더 구성되는,로봇.',\n",
       "    'distance': 0.4908236265182495},\n",
       "   {'id': '1020190159323_claim3',\n",
       "    'document': '상기 사운드 스팟 정보는 사운드 스팟 속성을 포함하고,상기 프로세서는,상기 입력 사운드의 속성과 매칭되는 사운드 스팟 속성을 가지는 사운드 스팟의 분포 정보에 기반하여 상기 탐색 영역을 결정하도록 더 구성되는,로봇.',\n",
       "    'distance': 0.49276286363601685},\n",
       "   {'id': '1020190159323_claim18',\n",
       "    'document': '상기 탐색하는 단계는,상기 적어도 하나의 사운드 스팟의 사운드 스팟 스코어에 기반하여 상기 적어도 하나의 사운드 스팟을 순차적으로 탐색하는 단계를 포함하는,음원 위치 추정 방법.',\n",
       "    'distance': 0.4975610375404358},\n",
       "   {'id': '1020190159323_claim9',\n",
       "    'document': '상기 프로세서는,상기 입력 사운드의 속성에 기반하여 상기 적어도 하나의 이미지 영역에서 상기 음원의 위치를 찾도록 더 구성되는,로봇.',\n",
       "    'distance': 0.5014715194702148},\n",
       "   {'id': '1020190159323_claim2',\n",
       "    'document': '상기 사운드 스팟 정보는 사운드 스팟의 분포 정보를 포함하고,상기 프로세서는,상기 탐색 영역을 결정하기 위하여,상기 분포 정보에 기반하여 상기 탐색 영역을 결정하도록 더 구성되는,로봇.',\n",
       "    'distance': 0.5096520781517029}]},\n",
       " {'patent_id': '1020257018982',\n",
       "  'score': 0.5577329075336457,\n",
       "  'top_claim': '무선 통신 시스템에서 장치가 위치를 측정하는 방법에 있어서,음파 신호에 기반한 위치 측정과 관련된 음파 측위 존에 대한 정보를 포함하는 설정 정보를 수신 받는 단계; 및상기 음파 측위 존에 진입한 것에 기초하여, 음파 센서를 통해 수신된 음파 신호들을 이용하여 상기 장치의 위치를 측정하는 단계를 포함하고,상기 음파 센서의 사용이 제한된 것에 기초하여, 상기 장치의 위치는 상기 음파 센서의 사용이 제한되기 직전에 상기 음파 신호들을 이용하여 산출된 위치 값에 관성 센서 및 GPS (Global Positioning System) 중 적어도 하나를 이용하여 산출된 위치 변화량을 적용하여 측정되는, 방법.',\n",
       "  'top_claim_no': 1,\n",
       "  'claims_found': 6,\n",
       "  'claims': [{'id': '1020257018982_claim1',\n",
       "    'document': '무선 통신 시스템에서 장치가 위치를 측정하는 방법에 있어서,음파 신호에 기반한 위치 측정과 관련된 음파 측위 존에 대한 정보를 포함하는 설정 정보를 수신 받는 단계; 및상기 음파 측위 존에 진입한 것에 기초하여, 음파 센서를 통해 수신된 음파 신호들을 이용하여 상기 장치의 위치를 측정하는 단계를 포함하고,상기 음파 센서의 사용이 제한된 것에 기초하여, 상기 장치의 위치는 상기 음파 센서의 사용이 제한되기 직전에 상기 음파 신호들을 이용하여 산출된 위치 값에 관성 센서 및 GPS (Global Positioning System) 중 적어도 하나를 이용하여 산출된 위치 변화량을 적용하여 측정되는, 방법.',\n",
       "    'distance': 0.4464506506919861},\n",
       "   {'id': '1020257018982_claim5',\n",
       "    'document': '상기 장치의 위치는 상기 제1 위치 값 및 상기 제2 위치 값의 차이가 미리 설정된 임계 이상인 것에 기초하여 상기 제1 위치 값 및 상기 제2 위치 값의 가중합에 기초하여 측정되는 것을 특징으로 하는, 방법.',\n",
       "    'distance': 0.44750696420669556},\n",
       "   {'id': '1020257018982_claim2',\n",
       "    'document': '상기 음파 센서의 사용에 대한 제한이 해제되는 것에 기초하여, 상기 장치의 위치는 상기 음파 신호들을 이용하여 산출된 위치 값에만 기반하여 측정되는 것을 특징으로 하는, 방법.',\n",
       "    'distance': 0.4477018713951111},\n",
       "   {'id': '1020257018982_claim12',\n",
       "    'document': '무선 통신 시스템에서 장치의 위치를 측정하는 장치를 제어하는 프로세싱 장치에 있어서,적어도 하나의 프로세서; 및상기 적어도 하나의 프로세서에 연결되고 명령어들을 저장하는 적어도 하나의 메모리를 포함하되, 상기 명령어들은 상기 적어도 하나의 프로세서에 의해 실행되는 것을 기반으로 상기 장치로 하여금:음파 신호에 기반한 위치 측정과 관련된 음파 측위 존에 대한 정보를 포함하는 설정 정보를 수신 받고, 상기 음파 측위 존에 진입한 것에 기초하여, 음파 센서를 통해 수신된 음파 신호들을 이용하여 상기 장치의 위치를 측정하도록 하며,상기 음파 센서의 사용이 제한된 것에 기초하여, 상기 장치의 위치는 상기 음파 센서의 사용이 제한되기 직전에 상기 음파 신호들을 이용하여 결정된 위치 값에 관성 센서 및 GPS (Global Positioning System) 중 적어도 하나를 이용하여 획득된 위치 변화량을 적용하여 측정되는, 프로세싱 장치.',\n",
       "    'distance': 0.4551923871040344},\n",
       "   {'id': '1020257018982_claim11',\n",
       "    'document': '무선 통신 시스템에서 장치의 위치를 측정하는 장치에 있어서,RF(Radio Frequency) 송수신기; 및상기 RF 송수신기와 연결되는 프로세서를 포함하고,상기 프로세서는 상기 RF 송수신기를 제어하여 음파 신호에 기반한 위치 측정과 관련된 음파 측위 존에 대한 정보를 포함하는 설정 정보를 수신 받고, 상기 음파 측위 존에 진입한 것에 기초하여, 음파 센서를 통해 수신된 음파 신호들을 이용하여 상기 장치의 위치를 측정하며,상기 음파 센서의 사용이 제한된 것에 기초하여, 상기 장치의 위치는 상기 음파 센서의 사용이 제한되기 직전에 상기 음파 신호들을 이용하여 결정된 위치 값에 관성 센서 및 GPS (Global Positioning System) 중 적어도 하나를 이용하여 획득된 위치 변화량을 적용하여 측정되는, 장치.',\n",
       "    'distance': 0.4661308526992798},\n",
       "   {'id': '1020257018982_claim3',\n",
       "    'document': '상기 장치의 위치는 상기 음파 측위 존에 진입한 시점으로부터 미리 설정된 시간 동안에 상기 GPS를 이용하여 산출된 제1 위치 값과 상기 음파 신호들을 이용하여 산출된 제2 위치 값 간의 가중합에 기반하여 측정되는 것을 특징으로 하는, 방법.',\n",
       "    'distance': 0.47034937143325806}]},\n",
       " {'patent_id': '1020247007118',\n",
       "  'score': 0.5572907221317291,\n",
       "  'top_claim': '상기 디바이스의 위치는 상기 전자 디바이스의 GPS를 사용하여 식별되는, 방법.',\n",
       "  'top_claim_no': 29,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020247007118_claim29',\n",
       "    'document': '상기 디바이스의 위치는 상기 전자 디바이스의 GPS를 사용하여 식별되는, 방법.',\n",
       "    'distance': 0.36912864446640015},\n",
       "   {'id': '1020247007118_claim24',\n",
       "    'document': '사용자가 전자 디바이스를 사용하여 위치를 식별할 수 있게 하는 방법으로서,상기 전자 디바이스의 사용자 인터페이스를 통해 영숫자 단축 코드 식별자를 수신하는 단계;상기 전자 디바이스의 위치를 식별하는 단계;상기 위치를 포함하는 지리적 대상 영역 내 상기 영숫자 단축 코드 식별자와 고유하게 연관된 스캔 가능 코드를 식별하기 위해 상기 영숫자 단축 코드 식별자와 상기 위치를 원격 서버로 전송하는 단계;상기 스캔 가능 코드와 관련된 정보를 수신하는 단계; 및상기 전자 디바이스의 출력 디바이스 상에 상기 사용자에게 상기 정보를 제시하는 단계를 포함하는, 방법.',\n",
       "    'distance': 0.4707736372947693}]},\n",
       " {'patent_id': '1020227025230',\n",
       "  'score': 0.5346269404888153,\n",
       "  'top_claim': '상기 단일 3D 지도에 기초하여, 상기 환경 내의 제3 클라이언트 장치의 위치를 판정하는 단계를 더 포함하는 것을 특징으로 하는 방법.',\n",
       "  'top_claim_no': 8,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020227025230_claim8',\n",
       "    'document': '상기 단일 3D 지도에 기초하여, 상기 환경 내의 제3 클라이언트 장치의 위치를 판정하는 단계를 더 포함하는 것을 특징으로 하는 방법.',\n",
       "    'distance': 0.41708117723464966}]},\n",
       " {'patent_id': '1020247006948',\n",
       "  'score': 0.5343303978443146,\n",
       "  'top_claim': '상기 하나 이상의 프로세서들은 추가로 상기 명령들을 실행하여:상기 음장 내 음성 소스의 제 1 위치 및 비음성 소스의 제 2 위치를 포함하도록 상기 오디오 데이터를 렌더링하고;하나 이상의 스피커들을 통해 상기 오디오 데이터의 제 1 재생 동작을 개시하는 것으로서, 상기 전기 활동 데이터는 상기 제 1 재생 동작 동안 상기 하나 이상의 전기 소스들로부터의 상기 전기 신호들에 기초하는, 상기 제 1 재생 동작을 개시하며; 그리고상기 전기 활동 데이터에 기초하여, 상기 음원의 사용자 선호 위치를 결정하는 것으로서, 상기 오디오 데이터는 상기 오디오 데이터의 제 2 재생 동작 동안 상기 음원의 상기 위치를 조정하기 위해 상기 사용자 선호 위치에 기초하여 렌더링되는, 상기 사용자 선호 위치를 결정하도록 구성되는, 디바이스.',\n",
       "  'top_claim_no': 18,\n",
       "  'claims_found': 5,\n",
       "  'claims': [{'id': '1020247006948_claim18',\n",
       "    'document': '상기 하나 이상의 프로세서들은 추가로 상기 명령들을 실행하여:상기 음장 내 음성 소스의 제 1 위치 및 비음성 소스의 제 2 위치를 포함하도록 상기 오디오 데이터를 렌더링하고;하나 이상의 스피커들을 통해 상기 오디오 데이터의 제 1 재생 동작을 개시하는 것으로서, 상기 전기 활동 데이터는 상기 제 1 재생 동작 동안 상기 하나 이상의 전기 소스들로부터의 상기 전기 신호들에 기초하는, 상기 제 1 재생 동작을 개시하며; 그리고상기 전기 활동 데이터에 기초하여, 상기 음원의 사용자 선호 위치를 결정하는 것으로서, 상기 오디오 데이터는 상기 오디오 데이터의 제 2 재생 동작 동안 상기 음원의 상기 위치를 조정하기 위해 상기 사용자 선호 위치에 기초하여 렌더링되는, 상기 사용자 선호 위치를 결정하도록 구성되는, 디바이스.',\n",
       "    'distance': 0.4507492184638977},\n",
       "   {'id': '1020247006948_claim8',\n",
       "    'document': '상기 하나 이상의 프로세서들은 추가로 상기 명령들을 실행하여:하나 이상의 스피커들을 통해 상기 오디오 데이터의 제 1 재생 동작을 개시하는 것으로서, 상기 오디오 데이터는 상기 제 1 재생 동작 동안 상기 음장 내의 상기 음원의 다수의 위치들을 포함하도록 렌더링되며, 상기 전기 활동 데이터는 상기 오디오 데이터의 상기 제 1 재생 동작 동안 상기 하나 이상의 전기 소스들로부터의 상기 전기 신호에 기초하는, 상기 제 1 재생 동작을 개시하고; 및 상기 전기 활동 데이터에 기초하여, 상기 음원의 사용자 선호 위치를 결정하는 것으로서, 상기 오디오 데이터는 상기 오디오 데이터의 제 2 재생 동작 동안 상기 위치를 조정하기 위해 상기 사용자 선호 위치에 기초하여 렌더링되는, 상기 사용자 선호 위치를 결정하도록 구성되는, 디바이스.',\n",
       "    'distance': 0.4727262258529663},\n",
       "   {'id': '1020247006948_claim22',\n",
       "    'document': '하나 이상의 스피커들을 통해 상기 오디오 데이터의 제 1 재생 동작을 개시하는 단계로서, 상기 오디오 데이터는 상기 제 1 재생 동작 동안 상기 음장 내의 상기 음원의 다수의 위치들을 포함하도록 렌더링되며, 상기 전기 활동 데이터는 상기 오디오 데이터의 상기 제 1 재생 동작 동안 상기 하나 이상의 전기 소스들로부터의 상기 전기 신호에 기초하는, 상기 제 1 재생 동작을 개시하는 단계; 및 상기 전기 활동 데이터에 기초하여, 상기 음원의 사용자 선호 위치를 결정하는 단계로서, 상기 오디오 데이터는 상기 오디오 데이터의 제 2 재생 동작 동안 상기 위치를 조정하기 위해 상기 사용자 선호 위치에 기초하여 렌더링되는, 상기 사용자 선호 위치를 결정하는 단계를 추가로 포함하되는, 방법.',\n",
       "    'distance': 0.47874873876571655},\n",
       "   {'id': '1020247006948_claim21',\n",
       "    'document': '방법으로서,디바이스에서, 사용자의 헤드 내의 하나 이상의 전기 소스들로부터의 전기 신호들에 대응하는 전기 활동 데이터를 획득하는 단계; 및 상기 전기 활동 데이터에 기초하여, 오디오 데이터의 재생 동안 음장 내의 음원의 위치를 조정하도록 상기 오디오 데이터를 렌더링하는 단계를 포함하는, 방법.',\n",
       "    'distance': 0.5106009840965271},\n",
       "   {'id': '1020247006948_claim9',\n",
       "    'document': '상기 하나 이상의 프로세서들은 상기 명령들을 실행하여, 위치 신뢰 수준이 신뢰 임계값보다 작은지 여부를 결정하는 것에 기초하여, 상기 다수의 위치들을 포함하도록 상기 오디오 데이터를 렌더링할지 여부를 결정하도록 구성되고, 상기 위치 신뢰 수준은 참조에 대한 상기 사용자의 추정된 위치와 연관되는, 디바이스.',\n",
       "    'distance': 0.5149431228637695}]},\n",
       " {'patent_id': '1020230193702',\n",
       "  'score': 0.5261229300498963,\n",
       "  'top_claim': '상기 인스트럭션들은, 상기 프로세서(120)에 의해 실행될 시, 상기 전자 장치(101)가,상기 통신 회로(290)를 통해, 상기 청소 로봇(210)으로부터 상기 청소 동안의 위치 정보를 위한 위치 데이터를 획득하고, 상기 위치 정보에서 식별되는 상기 청소 동안의 위치들 각각에서의 상기 소리 데이터에 따른 소리의 크기에 기반하여, 상기 지도(400) 상의 상기 적어도 하나의 외부 전자 장치(221, 223, 225)의 상기 위치를 식별하도록 야기하는, 전자 장치.',\n",
       "  'top_claim_no': 4,\n",
       "  'claims_found': 4,\n",
       "  'claims': [{'id': '1020230193702_claim14',\n",
       "    'document': '상기 통신 회로(290)를 통해, 상기 청소 로봇(210)으로부터 상기 청소 동안의 위치 정보를 위한 위치 데이터를 획득하는 동작, 및 상기 위치 정보에서 식별되는 상기 청소 동안의 위치들 각각에서의 상기 소리 데이터에 따른 소리의 크기에 기반하여, 상기 지도(400) 상의 상기 적어도 하나의 외부 전자 장치(221, 223, 225)의 상기 위치를 식별하는 동작을 포함하는 방법.',\n",
       "    'distance': 0.46076685190200806},\n",
       "   {'id': '1020230193702_claim4',\n",
       "    'document': '상기 인스트럭션들은, 상기 프로세서(120)에 의해 실행될 시, 상기 전자 장치(101)가,상기 통신 회로(290)를 통해, 상기 청소 로봇(210)으로부터 상기 청소 동안의 위치 정보를 위한 위치 데이터를 획득하고, 상기 위치 정보에서 식별되는 상기 청소 동안의 위치들 각각에서의 상기 소리 데이터에 따른 소리의 크기에 기반하여, 상기 지도(400) 상의 상기 적어도 하나의 외부 전자 장치(221, 223, 225)의 상기 위치를 식별하도록 야기하는, 전자 장치.',\n",
       "    'distance': 0.4484553337097168},\n",
       "   {'id': '1020230193702_claim16',\n",
       "    'document': '상기 통신 회로(290)를 통해, 상기 청소 로봇(210)으로부터 상기 청소 동안의 이벤트의 발생과 관련된 이벤트 데이터를 획득하는 동작, 및 상기 청소 동안의 위치들 중 상기 이벤트가 발생된 위치를 제외한 위치들 각각에서의 상기 소리 데이터에 따른 소리의 크기에 기반하여, 상기 지도(400) 상의 상기 적어도 하나의 외부 전자 장치(221, 223, 225)의 상기 위치를 식별하는 동작을 포함하는 방법.',\n",
       "    'distance': 0.4892599582672119},\n",
       "   {'id': '1020230193702_claim6',\n",
       "    'document': '상기 인스트럭션들은, 상기 프로세서(120)에 의해 실행될 시, 상기 전자 장치(101)가,상기 통신 회로(290)를 통해, 상기 청소 로봇(210)으로부터 상기 청소 동안의 이벤트의 발생과 관련된 이벤트 데이터를 획득하고,상기 청소 동안의 위치들 중 상기 이벤트가 발생된 위치를 제외한 위치들 각각에서의 상기 소리 데이터에 따른 소리의 크기에 기반하여, 상기 지도(400) 상의 상기 적어도 하나의 외부 전자 장치(221, 223, 225)의 상기 위치를 식별하도록 야기하는전자 장치.',\n",
       "    'distance': 0.48748016357421875}]},\n",
       " {'patent_id': '1020240037913',\n",
       "  'score': 0.5219051790237427,\n",
       "  'top_claim': '하나 이상의 위치 정보와 이에 대응하는 소스 장치를 포함하는 매핑 정보를 획득하고,상기 전자 장치가 상기 위치 정보에 대응하는 위치에 있는 것으로 검출함에 따라, 상기 소스 장치 리스트에 포함된 상기 적어도 하나의 소스 장치 중에서, 상기 위치 정보에 대응하는 것으로 매핑된 소스 장치를 상기 타겟 소스 장치로 선택하는 동작을 더 포함하는, 방법.',\n",
       "  'top_claim_no': 17,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020240037913_claim17',\n",
       "    'document': '하나 이상의 위치 정보와 이에 대응하는 소스 장치를 포함하는 매핑 정보를 획득하고,상기 전자 장치가 상기 위치 정보에 대응하는 위치에 있는 것으로 검출함에 따라, 상기 소스 장치 리스트에 포함된 상기 적어도 하나의 소스 장치 중에서, 상기 위치 정보에 대응하는 것으로 매핑된 소스 장치를 상기 타겟 소스 장치로 선택하는 동작을 더 포함하는, 방법.',\n",
       "    'distance': 0.42636024951934814},\n",
       "   {'id': '1020240037913_claim18',\n",
       "    'document': '위치 정보와 이에 대응하는 소스 장치를 설정할 수 있는 사용자 인터페이스를 제공하는 동작, 및상기 사용자 인터페이스를 통해서 수신된 사용자 입력에 기반하여 상기 매핑 정보를 저장하는 동작을 더 포함하는, 방법.',\n",
       "    'distance': 0.4742622375488281}]},\n",
       " {'patent_id': '1020230181991',\n",
       "  'score': 0.5212360107898711,\n",
       "  'top_claim': '상기 프로세서는,상기 카메라를 통해 촬영된 영상을 기반으로 상기 단말의 상기 차량 내 위치가 확인 가능한 경우,상기 단말의 상기 차량 내 위치를 상기 주차 공간 내 상기 차량의 위치 측정에 이용하는 것을 특징으로 하는,차량 위치 인식 장치.',\n",
       "  'top_claim_no': 6,\n",
       "  'claims_found': 4,\n",
       "  'claims': [{'id': '1020230181991_claim6',\n",
       "    'document': '상기 프로세서는,상기 카메라를 통해 촬영된 영상을 기반으로 상기 단말의 상기 차량 내 위치가 확인 가능한 경우,상기 단말의 상기 차량 내 위치를 상기 주차 공간 내 상기 차량의 위치 측정에 이용하는 것을 특징으로 하는,차량 위치 인식 장치.',\n",
       "    'distance': 0.45903927087783813},\n",
       "   {'id': '1020230181991_claim7',\n",
       "    'document': '상기 프로세서는,상기 수신되는 UWB 신호를 기반으로 상기 UWB 모듈과 상기 단말의 거리 및 각도를 각각 탐지하고, 거리 탐지 결과 및 각도 탐지 결과를 기반으로 상기 단말의 위치를 측정하되,상기 거리 탐지 결과에 N배의 가중치를 부여하여 상기 단말의 위치를 측정하는 것을 특징으로 하는,차량 위치 인식 장치.',\n",
       "    'distance': 0.46795445680618286},\n",
       "   {'id': '1020230181991_claim4',\n",
       "    'document': '상기 차량을 촬영하는 카메라를 더 포함하고,상기 프로세서는,상기 카메라를 통해 촬영된 이미지를 기반으로 상기 차량의 종류를 식별하고,상기 식별된 종류를 기반으로 상기 차량의 크기를 판단하고,상기 단말에 대하여 측정된 위치에 상기 판단된 차량의 크기를 적용하여 상기 주차 공간 내 상기 차량의 위치를 측정하는 것을 특징으로 하는,차량 위치 인식 장치.',\n",
       "    'distance': 0.4782673120498657},\n",
       "   {'id': '1020230181991_claim2',\n",
       "    'document': '상기 프로세서는,상기 단말로부터 수신되는 UWB 신호를 기반으로 상기 UWB 모듈과 상기 단말의 거리 및 각도를 산출하고,상기 산출한 단말의 거리 및 각도를 기반으로 상기 단말의 위치를 측정하는 것을 특징으로 하는,차량 위치 인식 장치.',\n",
       "    'distance': 0.4802172780036926}]},\n",
       " {'patent_id': '1020247037706',\n",
       "  'score': 0.5181815659999847,\n",
       "  'top_claim': '상기 비-이미지 데이터는 위치 데이터 및 오디오 데이터 중 하나 이상을 포함하는, 방법.',\n",
       "  'top_claim_no': 2,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020247037706_claim2',\n",
       "    'document': '상기 비-이미지 데이터는 위치 데이터 및 오디오 데이터 중 하나 이상을 포함하는, 방법.',\n",
       "    'distance': 0.4353538155555725}]},\n",
       " {'patent_id': '1020230183389',\n",
       "  'score': 0.5138823068141938,\n",
       "  'top_claim': '상기 타겟 위치는,상기 이미지 데이터에 기초하여 식별된 객체 인식 정보에 기초하여 결정되는, 제어 방법.',\n",
       "  'top_claim_no': 15,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020230183389_claim15',\n",
       "    'document': '상기 타겟 위치는,상기 이미지 데이터에 기초하여 식별된 객체 인식 정보에 기초하여 결정되는, 제어 방법.',\n",
       "    'distance': 0.4401307702064514}]},\n",
       " {'patent_id': '1020230156519',\n",
       "  'score': 0.5122802770137787,\n",
       "  'top_claim': '상기 위치 필드에 기초하여 다른 기하학적 특성들의 동일 클래스의 객체들이 구분되는,전자 장치.',\n",
       "  'top_claim_no': 14,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020230156519_claim14',\n",
       "    'document': '상기 위치 필드에 기초하여 다른 기하학적 특성들의 동일 클래스의 객체들이 구분되는,전자 장치.',\n",
       "    'distance': 0.4419108033180237}]},\n",
       " {'patent_id': '1020247003281',\n",
       "  'score': 0.5097059738636017,\n",
       "  'top_claim': '상기 식별 출력에 기초하여 상기 연결된 디바이스의 위치를 결정하는 단계; 및상기 연결된 디바이스의 상기 위치에 기초하여, 상기 전자 디바이스의 상기 좌표계에 상기 연결된 디바이스를 맵핑하는 단계를 추가로 포함하는, 하나 이상의 디바이스들을 로컬화하기 위한 방법.',\n",
       "  'top_claim_no': 30,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020247003281_claim30',\n",
       "    'document': '상기 식별 출력에 기초하여 상기 연결된 디바이스의 위치를 결정하는 단계; 및상기 연결된 디바이스의 상기 위치에 기초하여, 상기 전자 디바이스의 상기 좌표계에 상기 연결된 디바이스를 맵핑하는 단계를 추가로 포함하는, 하나 이상의 디바이스들을 로컬화하기 위한 방법.',\n",
       "    'distance': 0.45227372646331787},\n",
       "   {'id': '1020247003281_claim2',\n",
       "    'document': '상기 하나 이상의 프로세서들은,상기 식별 출력에 기초하여 상기 연결된 디바이스의 위치를 결정하고; 그리고상기 연결된 디바이스의 상기 위치에 기초하여, 상기 장치의 상기 좌표계에 상기 연결된 디바이스를 맵핑하도록 구성되는, 하나 이상의 디바이스들을 로컬화하기 위한 장치.',\n",
       "    'distance': 0.46309930086135864}]},\n",
       " {'patent_id': '1020227032872',\n",
       "  'score': 0.50849778175354,\n",
       "  'top_claim': '상기 포지션 데이터는, 음향 포지션 감지, 밀리미터파 기반 감지, 초음파 감지, 위성 기반 포지셔닝, 상기 제 2 디바이스로부터의 카메라 기반 추적, 또는 이들의 임의의 조합 중 적어도 하나에 기초하여 결정되는, 로케이션 기반 오디오 신호 보상을 수행하는 방법.',\n",
       "  'top_claim_no': 24,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020227032872_claim24',\n",
       "    'document': '상기 포지션 데이터는, 음향 포지션 감지, 밀리미터파 기반 감지, 초음파 감지, 위성 기반 포지셔닝, 상기 제 2 디바이스로부터의 카메라 기반 추적, 또는 이들의 임의의 조합 중 적어도 하나에 기초하여 결정되는, 로케이션 기반 오디오 신호 보상을 수행하는 방법.',\n",
       "    'distance': 0.45194631814956665},\n",
       "   {'id': '1020227032872_claim11',\n",
       "    'document': '상기 포지션 데이터는, 음향 포지션 감지, 밀리미터파 기반 감지, 초음파 감지, 위성 기반 포지셔닝, 상기 제 2 디바이스로부터의 카메라 기반 추적, 또는 이들의 임의의 조합 중 적어도 하나에 기초하여 결정되는, 로케이션 기반 오디오 신호 보상을 수행하기 위한 디바이스.',\n",
       "    'distance': 0.4677814245223999}]},\n",
       " {'patent_id': '1020170022529',\n",
       "  'score': 0.5084040117263794,\n",
       "  'top_claim': '상기 위치 정보는,  특정 지역 또는 현재 사용자의 위치에 관련된 정보이며, 상기 제어부는, 상기 수집된 오디오 데이터로부터, 상기 특정 지역이나 현재 사용자의 위치에 따른 지역의 명칭, 또는 상기 특정 지역 또는 현재 사용자의 위치에 따른 지역으로부터 기 설정된 거리 이내에 위치한 저명한 지역의 명칭과 관련된 오디오 데이터를 추출하는 것을 특징으로 하는 전자 장치.',\n",
       "  'top_claim_no': 9,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020170022529_claim9',\n",
       "    'document': '상기 위치 정보는,  특정 지역 또는 현재 사용자의 위치에 관련된 정보이며, 상기 제어부는, 상기 수집된 오디오 데이터로부터, 상기 특정 지역이나 현재 사용자의 위치에 따른 지역의 명칭, 또는 상기 특정 지역 또는 현재 사용자의 위치에 따른 지역으로부터 기 설정된 거리 이내에 위치한 저명한 지역의 명칭과 관련된 오디오 데이터를 추출하는 것을 특징으로 하는 전자 장치.',\n",
       "    'distance': 0.43253058195114136},\n",
       "   {'id': '1020170022529_claim8',\n",
       "    'document': '상기 제어부는, 상기 사용자 로그 정보 및 사용자 입력에 근거하여 사용자가 선호하는 오디오 데이터를 예측하며, 상기 사용자 입력은, 위치 정보 또는 시간 정보 중 적어도 하나임을 특징으로 하는 전자 장치.',\n",
       "    'distance': 0.5069254636764526}]},\n",
       " {'patent_id': '1020250044745',\n",
       "  'score': 0.5081276345252991,\n",
       "  'top_claim': '상기 프로세서는,상기 전자 장치의 위치가 상기 위치 탐지 모델을 통해 상기 사용자의 위치 정보를 획득할 수 있는 위치라고 식별된 후, 상기 사용자가 상기 전자 장치를 휴대하는 것으로 식별되면, 상기 전자 장치의 위치를 기준으로 상기 제1 센서를 통해 상기 전자 장치의 움직임 정보를 획득하고,상기 전자 장치의 움직임 정보 및 상기 AP로부터 상기 통신부를 통해 수신된 제3 신호의 특성 정보에 기초하여 상기 위치 탐지 모델을 학습시키는, 전자 장치.',\n",
       "  'top_claim_no': 11,\n",
       "  'claims_found': 3,\n",
       "  'claims': [{'id': '1020250044745_claim11',\n",
       "    'document': '상기 프로세서는,상기 전자 장치의 위치가 상기 위치 탐지 모델을 통해 상기 사용자의 위치 정보를 획득할 수 있는 위치라고 식별된 후, 상기 사용자가 상기 전자 장치를 휴대하는 것으로 식별되면, 상기 전자 장치의 위치를 기준으로 상기 제1 센서를 통해 상기 전자 장치의 움직임 정보를 획득하고,상기 전자 장치의 움직임 정보 및 상기 AP로부터 상기 통신부를 통해 수신된 제3 신호의 특성 정보에 기초하여 상기 위치 탐지 모델을 학습시키는, 전자 장치.',\n",
       "    'distance': 0.4643237590789795},\n",
       "   {'id': '1020250044745_claim9',\n",
       "    'document': '상기 프로세서는,상기 전자 장치의 배터리에 전력이 충전된다고 식별되면, 상기 제2 신호를 이용하여 상기 전자 장치의 위치를 식별하고,상기 전자 장치의 위치가 위치 탐지 모델을 통해 상기 사용자의 위치 정보를 획득할 수 있는 위치인지 식별하는, 전자 장치.',\n",
       "    'distance': 0.4718613624572754},\n",
       "   {'id': '1020250044745_claim10',\n",
       "    'document': '상기 프로세서는,상기 전자 장치의 위치가 상기 위치 탐지 모델을 통해 상기 사용자의 위치 정보를 획득할 수 있는 위치라고 식별되면, 상기 제2 신호에 기초하여 상기 사용자의 위치 정보를 획득하고,상기 전자 장치의 위치가 상기 위치 탐지 모델을 통해 상기 사용자의 위치 정보를 획득할 수 있는 위치가 아니라고 식별되지 않으면, 상기 제1 신호에 기초하여 상기 사용자의 위치 정보를 획득하는, 전자 장치.',\n",
       "    'distance': 0.4766910672187805}]},\n",
       " {'patent_id': '1020247030487',\n",
       "  'score': 0.5073304486274719,\n",
       "  'top_claim': '상기 포인트의 위치는 상기 고해상도 깊이 맵을 사용하여 획득되는, 장치.',\n",
       "  'top_claim_no': 12,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020247030487_claim12',\n",
       "    'document': '상기 포인트의 위치는 상기 고해상도 깊이 맵을 사용하여 획득되는, 장치.',\n",
       "    'distance': 0.4541236162185669},\n",
       "   {'id': '1020247030487_claim16',\n",
       "    'document': '상기 추가된 정점은 상기 고해상도 깊이 맵으로부터의 3차원 위치 정보에 기초하여 배치되는, 장치.',\n",
       "    'distance': 0.46731793880462646}]},\n",
       " {'patent_id': '1020210122732',\n",
       "  'score': 0.5071188759803772,\n",
       "  'top_claim': '상기 식별하는 단계는,상기 전자 장치가 동작하는 환경에 대응되는 라이다 지도를 획득하는 단계; 및상기 라이다 지도 및 상기 전자 장치의 현재 위치를 바탕으로, 상기 제1 주행 경로를 식별하는 단계;를 포함하는 제어 방법.',\n",
       "  'top_claim_no': 2,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020210122732_claim2',\n",
       "    'document': '상기 식별하는 단계는,상기 전자 장치가 동작하는 환경에 대응되는 라이다 지도를 획득하는 단계; 및상기 라이다 지도 및 상기 전자 장치의 현재 위치를 바탕으로, 상기 제1 주행 경로를 식별하는 단계;를 포함하는 제어 방법.',\n",
       "    'distance': 0.4520975947380066},\n",
       "   {'id': '1020210122732_claim1',\n",
       "    'document': '전자 장치의 제어 방법에 있어서,전자 장치가 동작하는 환경에 대응되는 지도를 바탕으로 기 설정된 목적지로 향하는 제1 주행 경로를 식별하는 단계;상기 제1 주행 경로에 따라 주행 도중, 적어도 하나의 센서를 바탕으로 상기 제1 주행 경로에 따른 주행에 방해되는 오브젝트를 식별하는 단계; 상기 식별된 오브젝트의 위치 및 속도 중 적어도 하나를 바탕으로 상기 오브젝트를 회피하기 위한 회피 경로를 식별하여, 상기 회피 경로에 따라 주행하는 단계; 및상기 회피 경로에 따라 주행하는 것을 바탕으로 상기 식별된 오브젝트가 기 설정 거리 이상 멀어지면, 상기 전자 장치의 현재 위치를 바탕으로 상기 제1 주행 경로에 따라 주행하도록 상기 전자 장치를 제어하는 단계;를 포함하는 제어 방법.',\n",
       "    'distance': 0.4720752239227295}]},\n",
       " {'patent_id': '1020237022044',\n",
       "  'score': 0.5067268621921539,\n",
       "  'top_claim': '상기 현재 포지션은 거리 정보를 포함하며, 상기 방법은,상기 사용자의 머리에 대한 상기 가상 객체의 거리 정보를 결정하는 단계; 및상기 결정된 거리 정보에 응답하여 상기 좌측 오디오 신호 및 상기 우측 오디오 신호의 진폭들을 조절하는 단계를 더 포함하는, 오디오 디바이스를 사용하여 사용자에게 오디오 신호들을 제시하기 위한 방법.',\n",
       "  'top_claim_no': 13,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020237022044_claim13',\n",
       "    'document': '상기 현재 포지션은 거리 정보를 포함하며, 상기 방법은,상기 사용자의 머리에 대한 상기 가상 객체의 거리 정보를 결정하는 단계; 및상기 결정된 거리 정보에 응답하여 상기 좌측 오디오 신호 및 상기 우측 오디오 신호의 진폭들을 조절하는 단계를 더 포함하는, 오디오 디바이스를 사용하여 사용자에게 오디오 신호들을 제시하기 위한 방법.',\n",
       "    'distance': 0.45496124029159546},\n",
       "   {'id': '1020237022044_claim5',\n",
       "    'document': '상기 현재 포지션은 거리 정보를 포함하며, 상기 프로세서는 상기 사용자의 머리에 대한 상기 가상 객체의 거리 정보를 결정하고 상기 결정된 거리 정보에 응답하여 상기 좌측 오디오 신호 및 상기 우측 오디오 신호의 진폭들을 조절하도록 추가로 구성되는, 오디오 신호들을 사용자에게 제시하기 위한 시스템.',\n",
       "    'distance': 0.46765464544296265}]},\n",
       " {'patent_id': '1020230038755',\n",
       "  'score': 0.5063508522510528,\n",
       "  'top_claim': '전자 장치가 위치 정보 기반 커뮤니케이션 서비스를 제공하는 방법에 있어서,위치부로부터 상기 전자 장치의 위치 정보를 획득하는 동작;카메라 및 센싱부를 이용하여 상기 전자 장치 주변에 존재하는 오브젝트의 특성 및 상기 오브젝트와 상기 전자 장치 사이의 거리를 확인하는 동작;상기 오브젝트의 특성에 기반하여 상기 오브젝트의 각 면에 제 1 매쉬를 생성하여 표시하는 동작;상기 제 1 매쉬 중에서 일부 영역을 선택하는 사용자의 입력에 기반하여, 상기 제 1 매쉬의 일부 영역에 제 2 매쉬를 생성하여 표시하는 동작;AR 메모지를 표시하여 상기 사용자로부터 상기 제 2 매쉬 영역에 게시할 사용자 메시지 입력을 획득하는 동작; 및상기 사용자 메시지와 상기 사용자의 아이디 및 상기 위치 정보를 포함하는 사용자 정보를 통신부를 통하여 서버에 전송하는 동작;을 포함하는방법.',\n",
       "  'top_claim_no': 6,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020230038755_claim6',\n",
       "    'document': '전자 장치가 위치 정보 기반 커뮤니케이션 서비스를 제공하는 방법에 있어서,위치부로부터 상기 전자 장치의 위치 정보를 획득하는 동작;카메라 및 센싱부를 이용하여 상기 전자 장치 주변에 존재하는 오브젝트의 특성 및 상기 오브젝트와 상기 전자 장치 사이의 거리를 확인하는 동작;상기 오브젝트의 특성에 기반하여 상기 오브젝트의 각 면에 제 1 매쉬를 생성하여 표시하는 동작;상기 제 1 매쉬 중에서 일부 영역을 선택하는 사용자의 입력에 기반하여, 상기 제 1 매쉬의 일부 영역에 제 2 매쉬를 생성하여 표시하는 동작;AR 메모지를 표시하여 상기 사용자로부터 상기 제 2 매쉬 영역에 게시할 사용자 메시지 입력을 획득하는 동작; 및상기 사용자 메시지와 상기 사용자의 아이디 및 상기 위치 정보를 포함하는 사용자 정보를 통신부를 통하여 서버에 전송하는 동작;을 포함하는방법.',\n",
       "    'distance': 0.4494783878326416},\n",
       "   {'id': '1020230038755_claim1',\n",
       "    'document': '위치 정보 기반 커뮤니케이션 서비스를 제공하는 전자 장치에 있어서,전자 장치는상기 전자 장치의 위치 정보를 획득하는 위치부;카메라;센싱부;사용자 입력부;서버와 정보를 송수신하는 통신부;제어부; 및제어부의 동작을 제어하는 프로세서를 포함하고,상기 프로세서는상기 위치부로부터 상기 전자 장치의 위치 정보를 획득하고,상기 카메라 및 상기 센싱부를 이용하여 상기 전자 장치 주변에 존재하는 오브젝트의 특성 및 상기 오브젝트와 상기 전자 장치 사이의 거리를 확인하고,상기 오브젝트의 특성에 기반하여 상기 오브젝트의 각 면에 제 1 매쉬를 생성하여 표시하고,상기 제 1 매쉬 중에서 일부 영역을 선택하는 사용자의 입력에 기반하여, 상기 제 1 매쉬의 일부 영역에 제 2 매쉬를 생성하여 표시하고,AR 메모지를 표시하여 상기 사용자로부터 상기 제 2 매쉬 영역에 게시할 사용자 메시지 입력을 획득하고,상기 사용자 메시지와 상기 사용자의 아이디 및 상기 위치 정보를 포함하는 사용자 정보를 상기 통신부를 통하여 상기 서버에 전송하는전자 장치.',\n",
       "    'distance': 0.4798737168312073}]},\n",
       " {'patent_id': '1020210100787',\n",
       "  'score': 0.5059142684936524,\n",
       "  'top_claim': '위치 추적 회로를 더 포함하고, 상기 무선 통신 칩셋은 상기 위치 추적 회로를 이용하여 상기 전자 장치의 상기 제2 위치를 식별하는, 전자 장치.',\n",
       "  'top_claim_no': 12,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020210100787_claim12',\n",
       "    'document': '위치 추적 회로를 더 포함하고, 상기 무선 통신 칩셋은 상기 위치 추적 회로를 이용하여 상기 전자 장치의 상기 제2 위치를 식별하는, 전자 장치.',\n",
       "    'distance': 0.44898414611816406}]},\n",
       " {'patent_id': '1020220103907',\n",
       "  'score': 0.5054750645160675,\n",
       "  'top_claim': '영상 정보, 음원 정보 및 센서 정보를 저장하는 메모리; 그리고,상기 영상 정보, 음원 정보 및 센서 정보 중 적어도 어느 하나를 기반으로 음원 위치를 추정하는 프로세서를 포함하고,상기 프로세서는,상기 영상 정보, 음원 정보 및 센서 정보 중 적어도 어느 하나를 전처리하여 테스트 데이터(test data)을 생성하고, 상기 테스트 데이터를 사전 학습한 인공지능 모델에 입력하여 음원 위치를 추정하며, 상기 테스트 데이터별로 상기 인공지능 모델의 음원 위치 추정 평가 스코어를 산출하고, 상기 산출한 음원 위치 추정 평가 스코어를 기반으로 상기 테스트 데이터를 검증 데이터(validation data)로 분류하며, 상기 분류한 검증 데이터를 기반으로 상기 인공지능 모델을 변경하고, 상기 변경한 인공지능 모델에 상기 테스트 데이터를 입력하여 업데이트하는 것을 특징으로 하는 인공 지능 장치.',\n",
       "  'top_claim_no': 1,\n",
       "  'claims_found': 4,\n",
       "  'claims': [{'id': '1020220103907_claim1',\n",
       "    'document': '영상 정보, 음원 정보 및 센서 정보를 저장하는 메모리; 그리고,상기 영상 정보, 음원 정보 및 센서 정보 중 적어도 어느 하나를 기반으로 음원 위치를 추정하는 프로세서를 포함하고,상기 프로세서는,상기 영상 정보, 음원 정보 및 센서 정보 중 적어도 어느 하나를 전처리하여 테스트 데이터(test data)을 생성하고, 상기 테스트 데이터를 사전 학습한 인공지능 모델에 입력하여 음원 위치를 추정하며, 상기 테스트 데이터별로 상기 인공지능 모델의 음원 위치 추정 평가 스코어를 산출하고, 상기 산출한 음원 위치 추정 평가 스코어를 기반으로 상기 테스트 데이터를 검증 데이터(validation data)로 분류하며, 상기 분류한 검증 데이터를 기반으로 상기 인공지능 모델을 변경하고, 상기 변경한 인공지능 모델에 상기 테스트 데이터를 입력하여 업데이트하는 것을 특징으로 하는 인공 지능 장치.',\n",
       "    'distance': 0.47891873121261597},\n",
       "   {'id': '1020220103907_claim15',\n",
       "    'document': '인공 지능 장치의 음원 위치 추정 방법에 있어서,실내에 위치하는 복수의 디바이스들로부터 영상 정보, 음원 정보 및 센서 정보 중 적어도 어느 하나를 획득하는 단계;상기 영상 정보, 음원 정보 및 센서 정보 중 적어도 어느 하나를 전처리하는 단계;상기 전처리한 영상 정보, 음원 정보 및 센서 정보를 기반으로 테스트 데이터(test data)을 생성하는 단계;상기 테스트 데이터를 사전 학습한 인공지능 모델에 입력하여 음원 위치를 추정하는 단계;상기 테스트 데이터별로 상기 인공지능 모델의 음원 위치 추정 평가 스코어를 산출하는 단계;상기 산출한 음원 위치 추정 평가 스코어를 기반으로 상기 테스트 데이터를 검증 데이터(validation data)로 분류하는 단계;상기 분류한 검증 데이터를 기반으로 상기 인공지능 모델을 변경하는 단계; 및상기 변경한 인공지능 모델에 상기 테스트 데이터를 입력하여 업데이트하는 단계를 포함하는 것을 특징으로 하는 음원 위치 추정 방법.',\n",
       "    'distance': 0.4857088327407837},\n",
       "   {'id': '1020220103907_claim8',\n",
       "    'document': '상기 프로세서는,상기 음원 위치를 추정할 때, 상기 테스트 데이터를 사전 학습한 인공지능 모델에 입력하여 음원 위치를 추정하고, 타겟 객체의 위치, 행동 및 이동 방향을 포함하는 음원 위치 추정 결과 정보를 제공하는 것을 특징으로 하는 인공 지능 장치.',\n",
       "    'distance': 0.48961901664733887},\n",
       "   {'id': '1020220103907_claim10',\n",
       "    'document': '상기 프로세서는,상기 음원 위치 추정 결과 정보를 기반으로 실내 환경 내에서의 상기 타겟 객체의 행동을 분석하고, 상기 타겟 객체의 행동에 상응하여 실내에 위치하는 디바이스 제어 서비스, 추천 정보 서비스, 그리고 미리 설정된 외부 서버 및 외부 단말로 알림 정보 전송 서비스 중 적어도 어느 하나를 제공하는 것을 특징으로 하는 인공 지능 장치.',\n",
       "    'distance': 0.5126436948776245}]},\n",
       " {'patent_id': '1020257028420',\n",
       "  'score': 0.5051679170131683,\n",
       "  'top_claim': '상기 타깃 디바이스의 상기 예상된 위치는 상기 타깃 디바이스의 이전 위치에 기초하는, 장치.',\n",
       "  'top_claim_no': 19,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020257028420_claim19',\n",
       "    'document': '상기 타깃 디바이스의 상기 예상된 위치는 상기 타깃 디바이스의 이전 위치에 기초하는, 장치.',\n",
       "    'distance': 0.4498134255409241}]},\n",
       " {'patent_id': '1020257017385',\n",
       "  'score': 0.5041439032554627,\n",
       "  'top_claim': 'X-선 장치의 윤곽을 사용하여 상기 X-선 장치의 위치 및 방향을 식별하는 단계를 더 포함하는, 방법.',\n",
       "  'top_claim_no': 35,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020257017385_claim35',\n",
       "    'document': 'X-선 장치의 윤곽을 사용하여 상기 X-선 장치의 위치 및 방향을 식별하는 단계를 더 포함하는, 방법.',\n",
       "    'distance': 0.4509512186050415}]},\n",
       " {'patent_id': '1020237033184',\n",
       "  'score': 0.5040366685390472,\n",
       "  'top_claim': '상기 타원 및 상기 쌍곡선이 교차되는 영역에 관한 정보를 기반으로, 상기 제 1 장치의 상기 위치에 관한 정보를 획득하는, 방법.',\n",
       "  'top_claim_no': 10,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020237033184_claim10',\n",
       "    'document': '상기 타원 및 상기 쌍곡선이 교차되는 영역에 관한 정보를 기반으로, 상기 제 1 장치의 상기 위치에 관한 정보를 획득하는, 방법.',\n",
       "    'distance': 0.4510703682899475}]},\n",
       " {'patent_id': '1020230169023',\n",
       "  'score': 0.5034982419013977,\n",
       "  'top_claim': '상기 전자 장치가 지정된 장소에 위치하는지 여부를 식별하는 동작을 더 포함하고,상기 전자 장치가 상기 지정된 장소에 위치하는 경우, 상기 사용자 인터페이스의 표시 및 상기 기기 제어 명령의 전송을 실행하는 방법.',\n",
       "  'top_claim_no': 19,\n",
       "  'claims_found': 1,\n",
       "  'claims': [{'id': '1020230169023_claim19',\n",
       "    'document': '상기 전자 장치가 지정된 장소에 위치하는지 여부를 식별하는 동작을 더 포함하고,상기 전자 장치가 상기 지정된 장소에 위치하는 경우, 상기 사용자 인터페이스의 표시 및 상기 기기 제어 명령의 전송을 실행하는 방법.',\n",
       "    'distance': 0.4516686201095581}]},\n",
       " {'patent_id': '1020227001719',\n",
       "  'score': 0.5031777405738831,\n",
       "  'top_claim': '상기 변경 시점 또는 변경 위치에 관련된 정보에 기초하여, 상기 제 1 오디오 데이터 및 상기 제 2 오디오 데이터는 끊김 없이 수신 및 디코딩되는,오디오 데이터 수신 방법.',\n",
       "  'top_claim_no': 12,\n",
       "  'claims_found': 4,\n",
       "  'claims': [{'id': '1020227001719_claim12',\n",
       "    'document': '상기 변경 시점 또는 변경 위치에 관련된 정보에 기초하여, 상기 제 1 오디오 데이터 및 상기 제 2 오디오 데이터는 끊김 없이 수신 및 디코딩되는,오디오 데이터 수신 방법.',\n",
       "    'distance': 0.47598886489868164},\n",
       "   {'id': '1020227001719_claim24',\n",
       "    'document': '상기 프로세서는, 상기 변경 시점 또는 변경 위치에 관련된 정보에 기초하여, 상기 제 1 오디오 데이터 및 상기 제 2 오디오 데이터는 끊김 없이 수신 및 디코딩하도록 설정되는,오디오 데이터 수신 장치.',\n",
       "    'distance': 0.4933982491493225},\n",
       "   {'id': '1020227001719_claim3',\n",
       "    'document': '상기 변경 시점 또는 변경 위치에 관련된 정보는,코덱 파라미터가 변경된 시점 또는 위치에 대한 정보, 변경 전의 코덱 파라미터에 기초하여 상기 제 2 디바이스가 수신하는 오디오 데이터의 시간 또는 위치에 대한 정보, 또는 변경 후의 코덱 파라미터에 기초하여 상기 제 2 디바이스가 수신하는 데이터의 시간 또는 위치에 대한 정보 중의 하나 이상을 포함하는, 오디오 데이터 전송 방법.',\n",
       "    'distance': 0.5007408857345581},\n",
       "   {'id': '1020227001719_claim9',\n",
       "    'document': '상기 변경 시점 또는 변경 위치에 관련된 정보는, 코덱 파라미터가 변경된 시점 또는 위치에 대한 정보, 변경 전의 코덱 파라미터에 기초하여 상기 제 2 디바이스가 수신하는 오디오 데이터의 시간 또는 위치에 대한 정보, 또는 변경 후의 코덱 파라미터에 기초하여 상기 제 2 디바이스가 수신하는 데이터의 시간 또는 위치에 대한 정보 중의 하나 이상을 포함하는,오디오 데이터 수신 방법.',\n",
       "    'distance': 0.5044006109237671}]},\n",
       " {'patent_id': '1020230074901',\n",
       "  'score': 0.5026563954353332,\n",
       "  'top_claim': '상기 장치의 위치를 식별하는 단계는:상기 장치의 위치의 초기 추정을 설정하는 과도 단계(transitory phase)를 수행하는 단계; 및상기 장치의 위치의 상기 초기 추정을 수정하는 안정 단계(steady phase)를 수행하는 단계를 포함하며, 상기 안정 단계는 상기 과도 단계에 후행하는, 방법.',\n",
       "  'top_claim_no': 4,\n",
       "  'claims_found': 2,\n",
       "  'claims': [{'id': '1020230074901_claim4',\n",
       "    'document': '상기 장치의 위치를 식별하는 단계는:상기 장치의 위치의 초기 추정을 설정하는 과도 단계(transitory phase)를 수행하는 단계; 및상기 장치의 위치의 상기 초기 추정을 수정하는 안정 단계(steady phase)를 수행하는 단계를 포함하며, 상기 안정 단계는 상기 과도 단계에 후행하는, 방법.',\n",
       "    'distance': 0.4592406749725342},\n",
       "   {'id': '1020230074901_claim11',\n",
       "    'document': '상기 장치의 위치를 식별하기 위해, 상기 프로세서는:상기 장치의 위치의 초기 추정을 설정하는 과도 단계(transitory phase)를 수행하고; 및상기 장치의 위치의 상기 초기 추정을 수정하는 안정 단계(steady phase)를 수행하도록 더 구성되며, 상기 안정 단계는 상기 과도 단계에 후행하는, 장치.',\n",
       "    'distance': 0.4726639986038208}]},\n",
       " {'patent_id': '1020210152830',\n",
       "  'score': 0.5023762929439545,\n",
       "  'top_claim': '상기 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터 상기 3차원 특징점 정보를 획득하는 단계는,상기 이동체의 위치 정보에 기초하여 고정밀 지도 데이터베이스로부터 상기 이동체 주변의 랜드마크에 대한 월드(world) 도메인 상의 3차원 특징점 정보를 수신하는 단계; 및상기 월드 도메인 상의 3차원 특징점 정보를 상기 촬영 장치에 대한 로컬 도메인으로 변환하는 단계를 포함하는,전자 장치의 동작 방법.',\n",
       "  'top_claim_no': 3,\n",
       "  'claims_found': 3,\n",
       "  'claims': [{'id': '1020210152830_claim3',\n",
       "    'document': '상기 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터 상기 3차원 특징점 정보를 획득하는 단계는,상기 이동체의 위치 정보에 기초하여 고정밀 지도 데이터베이스로부터 상기 이동체 주변의 랜드마크에 대한 월드(world) 도메인 상의 3차원 특징점 정보를 수신하는 단계; 및상기 월드 도메인 상의 3차원 특징점 정보를 상기 촬영 장치에 대한 로컬 도메인으로 변환하는 단계를 포함하는,전자 장치의 동작 방법.',\n",
       "    'distance': 0.47453874349594116},\n",
       "   {'id': '1020210152830_claim1',\n",
       "    'document': '전자 장치의 동작 방법에 있어서,이동체에 탑재된 촬영 장치로 획득한 주변 영상으로부터, 랜드마크(landmark) 기반 확률 맵(probability map) 형태의 2차원 특징점 정보를 획득하는 단계;상기 이동체 주변의 고정밀 지도(High Definition Map) 데이터로부터, 랜드마크 기반 3차원 특징점 정보를 획득하는 단계;상기 주변 영상의 2차원 특징점 정보와 상기 고정밀 지도 데이터의 3차원 특징점 정보 중 어느 하나의 차원(dimension)을 다른 하나의 차원으로 변환하는 단계;상기 주변 영상의 특징점 정보와 상기 고정밀 지도 데이터의 특징점 정보 사이의 대응도(likelihood)를 계산하는 단계; 및상기 대응도에 기초하여 상기 이동체의 위치를 추정하는 단계를 포함하는,전자 장치의 동작 방법.',\n",
       "    'distance': 0.47482234239578247},\n",
       "   {'id': '1020210152830_claim19',\n",
       "    'document': '전자 장치에 있어서,이동체 주변의 고정밀 지도(High Definition Map) 데이터 및 상기 이동체에 탑재된 촬영 장치로 획득한 주변 영상을 수신하는 통신 모듈;컴퓨터로 실행 가능한 명령어들(computer-executable instructions)이 저장된 메모리; 및상기 메모리에 억세스(access)하여 상기 명령어들을 실행하는 프로세서를 포함하고,상기 명령어들은,상기 주변 영상으로부터, 랜드마크(landmark) 기반 확률 맵(probability map) 형태의 2차원 특징점 정보를 획득하고,상기 고정밀 지도 데이터로부터, 랜드마크 기반 3차원 특징점 정보를 획득하고,상기 주변 영상의 2차원 특징점 정보와 상기 고정밀 지도 데이터의 3차원 특징점 정보 중 어느 하나의 차원(dimension)을 다른 하나의 차원으로 변환하고,상기 주변 영상의 특징점 정보와 상기 고정밀 지도 데이터의 특징점 정보 사이의 대응도(likelihood)를 계산하고,상기 대응도에 기초하여 상기 이동체의 위치를 추정하도록 구성되는,전자 장치.',\n",
       "    'distance': 0.4769493341445923}]}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = [ '소리 데이터와 위치 정보를 이용해', '지도 기반으로 장치 위치를 식별하는 기술']\n",
    "\n",
    "results = multi_query_rerank(\n",
    "    collection=collection,\n",
    "    model=model,\n",
    "    query_list=query,\n",
    "    per_query_top_k=200,\n",
    "    final_top_k=200\n",
    ")\n",
    "\n",
    "ipc={\"1020230193702\", \"1020240075882\", \"1020240025833\", \"1020240009746\", \"1020230183389\"}\n",
    "\n",
    "TOP_K = 30\n",
    "eval(results, ipc, TOP_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1e873",
   "metadata": {},
   "source": [
    "### 정답 데이터 만들고 비교 2\n",
    "G05D 1/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c690017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 ipcNumber을 가진 출원번호\n",
    "ipc_g05d143 = {\"1020240014135\",\n",
    "\"1020230114322\",\n",
    "\"1020250071099\",\n",
    "\"1020257016601\",\n",
    "\"1020240039664\",\n",
    "\"1020240037602\",\n",
    "\"1020240024079\",\n",
    "\"1020230147397\",\n",
    "\"1020257029654\",\n",
    "\"1020240062392\",\n",
    "\"1020257011052\",\n",
    "\"1020220110142\",\n",
    "\"1020220132771\",\n",
    "\"1020230173300\",\n",
    "\"1020240085547\",\n",
    "\"1020250040520\",\n",
    "\"1020240013189\",\n",
    "\"1020247037212\",\n",
    "\"1020257009077\",\n",
    "\"1020247018578\",\n",
    "\"1020247018568\",\n",
    "\"1020247018428\",\n",
    "\"1020240079243\",\n",
    "\"1020237031214\",\n",
    "\"1020240026208\",\n",
    "\"1020230177082\",\n",
    "\"1020220120962\",\n",
    "\"1020240003758\",\n",
    "\"1020230134552\",\n",
    "\"1020230127447\",\n",
    "\"1020230127436\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e38d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1020240003758', '1020247037212', '1020220120962'}\n",
      "Precision: 0.1\n",
      "Recall: 0.0967741935483871\n"
     ]
    }
   ],
   "source": [
    "query = [\n",
    "    \"주행 로봇의 위치·방향을 판단하고 제어하는 알고리즘\",\n",
    "    \"지도 기반 위치 결정 및 경로 추종 제어 로직\"\n",
    "]\n",
    "\n",
    "results = multi_query_rerank(\n",
    "    collection=collection,\n",
    "    model=model,\n",
    "    query_list=query,\n",
    "    per_query_top_k=200,\n",
    "    final_top_k=200\n",
    ")\n",
    "\n",
    "TOP_K =30\n",
    "final_results = eval(results, ipc_g05d143, TOP_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec9e7d",
   "metadata": {},
   "source": [
    "### 정답 데이터 만들고 비교 3\n",
    "\n",
    "G06Q50/10, G06K19/07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4793edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_g06 = {\n",
    "\"1020220016944\",\n",
    "\"1020240059583\",\n",
    "\"1020240000411\",\n",
    "\"1020220046632\",\n",
    "\"1020230135386\",\n",
    "\"1020230129173\",\n",
    "\"1020230123448\",\n",
    "\"1020220154077\",\n",
    "\"1020230066241\",\n",
    "\"1020240046742\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a253e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "query = [\n",
    "    \"사용자 단말 및 서버 간의 연동을 기반\",\n",
    "    \"매핑 정보, DB 기반 서비스 실행\",\n",
    "    \"식별 정보의 자동 수집, 전송 및 처리 과정을 통합\"\n",
    "]\n",
    "\n",
    "results = multi_query_rerank(\n",
    "    collection=collection,\n",
    "    model=model,\n",
    "    query_list=query,\n",
    "    per_query_top_k=200,\n",
    "    final_top_k=200\n",
    ")\n",
    "\n",
    "TOP_K = 30\n",
    "f=eval(results, ipc_g06, TOP_K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f9f907",
   "metadata": {},
   "source": [
    "### 정답 데이터 만들고 비교 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7232612",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_g09g300_g09g33208 = {\"1020230123509\",\n",
    "\"1020230015809\",\n",
    "\"1020230011205\",\n",
    "\"1020230114342\",\n",
    "\"1020220166481\",\n",
    "\"1020220053782\",\n",
    "\"1020210194515\",\n",
    "\"1020240017940\",\n",
    "\"1020210101348\",\n",
    "\"1020240045365\",\n",
    "\"1020240041098\",\n",
    "\"1020240009599\",\n",
    "\"1020240009333\",\n",
    "\"1020240008829\",\n",
    "\"1020220078865\",\n",
    "\"1020230174203\",\n",
    "\"1020220037942\",\n",
    "\"1020230126254\",\n",
    "\"1020230029941\",\n",
    "\"1020230064399\",\n",
    "\"1020240029529\",\n",
    "\"1020230143723\",\n",
    "\"1020230134748\",\n",
    "\"1020230080308\",\n",
    "\"1020230001366\",\n",
    "\"1020230174009\",\n",
    "\"1020240027415\",\n",
    "\"1020220188338\",\n",
    "\"1020220075085\",\n",
    "\"1020210141296\",\n",
    "\"1020240034098\",\n",
    "\"1020237020882\",\n",
    "\"1020240011182\",\n",
    "\"1020230187763\",\n",
    "\"1020230061180\",\n",
    "\"1020247031712\",\n",
    "\"1020230000119\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1020230187763'}\n",
      "Precision: 0.03333333333333333\n",
      "Recall: 0.02702702702702703\n"
     ]
    }
   ],
   "source": [
    "query = ['사용자 피로도 감지 기반 디스플레이 화면 조절', '휴먼 센서 통합 사용자 상태 분석', '디스플레이 자율 변형 조작']\n",
    "\n",
    "results = multi_query_rerank(\n",
    "    collection=collection,\n",
    "    model=model,\n",
    "    query_list=query,\n",
    "    per_query_top_k=200,\n",
    "    final_top_k=200\n",
    ")\n",
    "\n",
    "TOP_K = 30\n",
    "final_results = eval(results, ipc_g09g300_g09g33208, TOP_K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
